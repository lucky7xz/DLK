{"dta.poem.11329": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auf die Linck- und Regiu\u00dfische  \n verm\u00e4hlung,  \n den 8 Junii  anno  1700.  \n  B. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr Musen! helfft mir doch! Ich soll schon wieder singen,", "tokens": ["Ihr", "Mu\u00b7sen", "!", "helfft", "mir", "doch", "!", "Ich", "soll", "schon", "wie\u00b7der", "sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "ADV", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ein verliebtes paar in Teutsche verse bringen:", "tokens": ["Und", "ein", "ver\u00b7lieb\u00b7tes", "paar", "in", "Teut\u00b7sche", "ver\u00b7se", "brin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und zwar in Schlesien. Jhr kennt di\u00df land und mich,", "tokens": ["Und", "zwar", "in", "Schle\u00b7si\u00b7en", ".", "Ihr", "kennt", "di\u00df", "land", "und", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "$.", "PPER", "VVFIN", "PDS", "NN", "KON", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jhr wi\u00dft auch, wenn ihr wolt, wie vor Budorgis sich", "tokens": ["Ihr", "wi\u00dft", "auch", ",", "wenn", "ihr", "wolt", ",", "wie", "vor", "Bu\u00b7dor\u00b7gis", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$,", "PWAV", "APPR", "NN", "PRF"], "meter": "-+-+-+-++-+-", "measure": "unknown.measure.hexa"}, "line.5": {"text": "Zum theil an mir ergetzt. Jetzt scheinen meine lieder", "tokens": ["Zum", "theil", "an", "mir", "er\u00b7getzt", ".", "Jetzt", "schei\u00b7nen", "mei\u00b7ne", "lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "PPER", "VVPP", "$.", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Jhm, wo nicht gantz veracht, doch mehr, als sonst zuwider.", "tokens": ["Jhm", ",", "wo", "nicht", "gantz", "ver\u00b7acht", ",", "doch", "mehr", ",", "als", "sonst", "zu\u00b7wi\u00b7der", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAV", "PTKNEG", "ADV", "VVPP", "$,", "ADV", "ADV", "$,", "KOUS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mein reim klingt vielen schon sehr matt und ohne krafft,", "tokens": ["Mein", "reim", "klingt", "vie\u00b7len", "schon", "sehr", "matt", "und", "oh\u00b7ne", "krafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "ADV", "ADV", "ADJD", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Warum? Ich tr\u00e4uck ihn nicht in muscateller-safft;", "tokens": ["Wa\u00b7rum", "?", "Ich", "tr\u00e4uck", "ihn", "nicht", "in", "mus\u00b7ca\u00b7tel\u00b7ler\u00b7\u00b7safft", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich speis\u2019 ihn auch nicht mehr mit theuren amber-kuchen:", "tokens": ["Ich", "speis'", "ihn", "auch", "nicht", "mehr", "mit", "theu\u00b7ren", "am\u00b7ber\u00b7ku\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn er ist alt genung, die nahrung selbst zu suchen.", "tokens": ["Denn", "er", "ist", "alt", "ge\u00b7nung", ",", "die", "nah\u00b7rung", "selbst", "zu", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ADV", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Zibeth und bisam hat ihm manchen dienst gethan:", "tokens": ["Zi\u00b7beth", "und", "bi\u00b7sam", "hat", "ihm", "man\u00b7chen", "dienst", "ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VAFIN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nun will ich einmahl sehn, was er alleine kan.", "tokens": ["Nun", "will", "ich", "ein\u00b7mahl", "sehn", ",", "was", "er", "al\u00b7lei\u00b7ne", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,", "PWS", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Alleine? fraget ihr: Ja, wie gedacht, alleine.", "tokens": ["Al\u00b7lei\u00b7ne", "?", "fra\u00b7get", "ihr", ":", "Ja", ",", "wie", "ge\u00b7dacht", ",", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPER", "$.", "PTKANT", "$,", "PWAV", "VVPP", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Denn was ich ehmahls schrieb, war weder mein noch seine,", "tokens": ["Denn", "was", "ich", "eh\u00b7mahls", "schrieb", ",", "war", "we\u00b7der", "mein", "noch", "sei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "KON", "PPOSAT", "ADV", "PPOSAT", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Hier hatte Seneca, dort Plato was gesagt;", "tokens": ["Hier", "hat\u00b7te", "Se\u00b7ne\u00b7ca", ",", "dort", "Pla\u00b7to", "was", "ge\u00b7sagt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$,", "ADV", "NE", "PWS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da hatt\u2019 ich einen spruch dem Plautus abgejagt;", "tokens": ["Da", "hatt'", "ich", "ei\u00b7nen", "spruch", "dem", "Plau\u00b7tus", "ab\u00b7ge\u00b7jagt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und etwan anderswo den Tacitus bestohlen.", "tokens": ["Und", "et\u00b7wan", "an\u00b7ders\u00b7wo", "den", "Ta\u00b7ci\u00b7tus", "be\u00b7stoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Auf diesem schwachen grund, ich sag es unverholen,", "tokens": ["Auf", "die\u00b7sem", "schwa\u00b7chen", "grund", ",", "ich", "sag", "es", "un\u00b7ver\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Baut\u2019 ich von versen offt damahls ein gantzes hau\u00df,", "tokens": ["Baut'", "ich", "von", "ver\u00b7sen", "offt", "da\u00b7mahls", "ein", "gant\u00b7zes", "hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und ziert\u2019 es noch dazu mit sinne-bildern aus.", "tokens": ["Und", "ziert'", "es", "noch", "da\u00b7zu", "mit", "sin\u00b7ne\u00b7bil\u00b7dern", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PAV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Wie \u00f6ffters mu\u00df ich doch der abgeschmackten sachen,", "tokens": ["Wie", "\u00f6ff\u00b7ters", "mu\u00df", "ich", "doch", "der", "ab\u00b7ge\u00b7schmack\u00b7ten", "sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ADV", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wenn ich zur\u00fccke seh\u2019, noch bey mir selber lachen;", "tokens": ["Wenn", "ich", "zu\u00b7r\u00fc\u00b7cke", "seh'", ",", "noch", "bey", "mir", "sel\u00b7ber", "la\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VVFIN", "$,", "ADV", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Gleichwohl gefielen sie, und nahmen durch den schein,", "tokens": ["Gleich\u00b7wohl", "ge\u00b7fie\u00b7len", "sie", ",", "und", "nah\u00b7men", "durch", "den", "schein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Wie schlecht er immer war, viel hundert leser ein.", "tokens": ["Wie", "schlecht", "er", "im\u00b7mer", "war", ",", "viel", "hun\u00b7dert", "le\u00b7ser", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "VAFIN", "$,", "ADV", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ha! schrie man hier und da; f\u00fcr dem mu\u00df Opitz weichen", "tokens": ["Ha", "!", "schrie", "man", "hier", "und", "da", ";", "f\u00fcr", "dem", "mu\u00df", "O\u00b7pitz", "wei\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VVFIN", "PIS", "ADV", "KON", "ADV", "$.", "APPR", "ART", "VMFIN", "NE", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Ja, dacht ich, wenn ich ihn nur erstlich k\u00f6nt\u2019 erreichen!", "tokens": ["Ja", ",", "dacht", "ich", ",", "wenn", "ich", "ihn", "nur", "erst\u00b7lich", "k\u00f6nt'", "er\u00b7rei\u00b7chen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PPER", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Den willen h\u00e4tt\u2019 ich wohl. So, wie ich es gedacht,", "tokens": ["Den", "wil\u00b7len", "h\u00e4tt'", "ich", "wohl", ".", "So", ",", "wie", "ich", "es", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$.", "ADV", "$,", "PWAV", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So ist es auch geschehn. Ich habe manche nacht", "tokens": ["So", "ist", "es", "auch", "ge\u00b7schehn", ".", "Ich", "ha\u00b7be", "man\u00b7che", "nacht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PPER", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und manchen tag geschwitzt; allein ich mu\u00df gestehen,", "tokens": ["Und", "man\u00b7chen", "tag", "ge\u00b7schwitzt", ";", "al\u00b7lein", "ich", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVPP", "$.", "ADV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Da\u00df ich ihm noch umsonst versuche nachzugehen.", "tokens": ["Da\u00df", "ich", "ihm", "noch", "um\u00b7sonst", "ver\u00b7su\u00b7che", "nach\u00b7zu\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "O grausamer Horaz! was hat dich doch bewegt,", "tokens": ["O", "grau\u00b7sa\u00b7mer", "Ho\u00b7raz", "!", "was", "hat", "dich", "doch", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.32": {"text": "Da\u00df du uns so viel last im tichten aufgelegt?", "tokens": ["Da\u00df", "du", "uns", "so", "viel", "last", "im", "tich\u00b7ten", "auf\u00b7ge\u00b7legt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "VVFIN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.33": {"text": "So bald ich nur dein buch mit nutz und ernst gelesen;", "tokens": ["So", "bald", "ich", "nur", "dein", "buch", "mit", "nutz", "und", "ernst", "ge\u00b7le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So ist mir auch nicht mehr im schreiben wohl gewesen.", "tokens": ["So", "ist", "mir", "auch", "nicht", "mehr", "im", "schrei\u00b7ben", "wohl", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPRART", "VVFIN", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Vor kamen wort und reim; itzt lauff ich ihnen nach:", "tokens": ["Vor", "ka\u00b7men", "wort", "und", "reim", ";", "itzt", "lauff", "ich", "ih\u00b7nen", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "NN", "KON", "ADJD", "$.", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Vor flog ich himmel-an; itzt thu ich gantz gemach.", "tokens": ["Vor", "flog", "ich", "him\u00b7mel\u00b7an", ";", "itzt", "thu", "ich", "gantz", "ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "NE", "$.", "ADV", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ich schleiche, wie ein dachs, aus dem poeten-orden,", "tokens": ["Ich", "schlei\u00b7che", ",", "wie", "ein", "dachs", ",", "aus", "dem", "po\u00b7e\u00b7ten\u00b7or\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ART", "ADJA", "$,", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Und bin mit grosser m\u00fch kaum noch dein sch\u00fcler worden.", "tokens": ["Und", "bin", "mit", "gros\u00b7ser", "m\u00fch", "kaum", "noch", "dein", "sch\u00fc\u00b7ler", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "ADJD", "ADV", "ADV", "PPOSAT", "ADJA", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Kommt, sprech ich offtermahls, gold, marmel und porphir!", "tokens": ["Kommt", ",", "sprech", "ich", "off\u00b7ter\u00b7mahls", ",", "gold", ",", "mar\u00b7mel", "und", "por\u00b7phir", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "NN", "KON", "NE", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.40": {"text": "Nein, deuck\u2019 ich wiederum, flieht, fliehet weit von mir!", "tokens": ["Nein", ",", "deuck'", "ich", "wie\u00b7de\u00b7rum", ",", "flieht", ",", "flie\u00b7het", "weit", "von", "mir", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "PPER", "ADV", "$,", "VVFIN", "$,", "VVFIN", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Jhr seyd mir viel zu theur bey diesen schweren jahren,", "tokens": ["Ihr", "seyd", "mir", "viel", "zu", "theur", "bey", "die\u00b7sen", "schwe\u00b7ren", "jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Ich habe jung verschwendt, ich will im alter spahren.", "tokens": ["Ich", "ha\u00b7be", "jung", "ver\u00b7schwendt", ",", "ich", "will", "im", "al\u00b7ter", "spah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$,", "PPER", "VMFIN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und also bin ich nicht mehr nach der neuen welt:", "tokens": ["Und", "al\u00b7so", "bin", "ich", "nicht", "mehr", "nach", "der", "neu\u00b7en", "welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Denn ich erfinde nichts, was in die augen f\u00e4llt.", "tokens": ["Denn", "ich", "er\u00b7fin\u00b7de", "nichts", ",", "was", "in", "die", "au\u00b7gen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Was wird denn Schlesien zu meinen versen sagen?", "tokens": ["Was", "wird", "denn", "Schle\u00b7si\u00b7en", "zu", "mei\u00b7nen", "ver\u00b7sen", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Es sage, was es will; Ich mu\u00df es dennoch wagen.", "tokens": ["Es", "sa\u00b7ge", ",", "was", "es", "will", ";", "Ich", "mu\u00df", "es", "den\u00b7noch", "wa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VMFIN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Wir haben hier ein paar, bey dessen liebes-gluth", "tokens": ["Wir", "ha\u00b7ben", "hier", "ein", "paar", ",", "bey", "des\u00b7sen", "lie\u00b7bes\u00b7gluth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "PIAT", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Cupidens blinder rath nicht das geringste thut.", "tokens": ["Cu\u00b7pi\u00b7dens", "blin\u00b7der", "rath", "nicht", "das", "ge\u00b7rings\u00b7te", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PTKNEG", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Denn beyde wissen schon, wie man sich mu\u00df verm\u00e4hlen;", "tokens": ["Denn", "bey\u00b7de", "wis\u00b7sen", "schon", ",", "wie", "man", "sich", "mu\u00df", "ver\u00b7m\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$,", "PWAV", "PIS", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Drum brauchen sie kein kind zum f\u00fchrer zu erwehlen.", "tokens": ["Drum", "brau\u00b7chen", "sie", "kein", "kind", "zum", "f\u00fch\u00b7rer", "zu", "er\u00b7weh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN", "APPRART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ja, sprichst du, ist es wahr? so sind sie nicht verliebt.", "tokens": ["Ja", ",", "sprichst", "du", ",", "ist", "es", "wahr", "?", "so", "sind", "sie", "nicht", "ver\u00b7liebt", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Sie sind es und weit mehr, als andre, die betr\u00fcbt", "tokens": ["Sie", "sind", "es", "und", "weit", "mehr", ",", "als", "and\u00b7re", ",", "die", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "KON", "ADJD", "ADV", "$,", "KOUS", "PIS", "$,", "PRELS", "VVPP"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.53": {"text": "Und voller herben quaal in Venus h\u00f6lle schwitzen,", "tokens": ["Und", "vol\u00b7ler", "her\u00b7ben", "qua\u00b7al", "in", "Ve\u00b7nus", "h\u00f6l\u00b7le", "schwit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "APPR", "NE", "ADJA", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.54": {"text": "Die bey der gr\u00f6sten freud in tausend sorgen sitzen,", "tokens": ["Die", "bey", "der", "gr\u00f6s\u00b7ten", "freud", "in", "tau\u00b7send", "sor\u00b7gen", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "VVFIN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Des morgens halb verr\u00fcckt, des abends n\u00e4rrisch seyn,", "tokens": ["Des", "mor\u00b7gens", "halb", "ver\u00b7r\u00fcckt", ",", "des", "a\u00b7bends", "n\u00e4r\u00b7risch", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVPP", "$,", "ART", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Von ihrer Margaris auf allen gassen schreyn:", "tokens": ["Von", "ih\u00b7rer", "Mar\u00b7ga\u00b7ris", "auf", "al\u00b7len", "gas\u00b7sen", "schreyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und dennoch weder sie, noch auch sich selber kennen.", "tokens": ["Und", "den\u00b7noch", "we\u00b7der", "sie", ",", "noch", "auch", "sich", "sel\u00b7ber", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "PPER", "$,", "ADV", "ADV", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Ach! solche leute sind ja billich arm zu nennen,", "tokens": ["Ach", "!", "sol\u00b7che", "leu\u00b7te", "sind", "ja", "bil\u00b7lich", "arm", "zu", "nen\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PIAT", "NN", "VAFIN", "ADV", "ADJD", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Denn sie verhandeln offt, o trauriger gewinn!", "tokens": ["Denn", "sie", "ver\u00b7han\u00b7deln", "offt", ",", "o", "trau\u00b7ri\u00b7ger", "ge\u00b7winn", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "F\u00fcr eine kleine lust ihr gantzes gl\u00fccke hin.", "tokens": ["F\u00fcr", "ei\u00b7ne", "klei\u00b7ne", "lust", "ihr", "gant\u00b7zes", "gl\u00fc\u00b7cke", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PPOSAT", "ADJA", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Hochwerth-gesch\u00e4tzte braut! wie wohl ist ihr geschehen,", "tokens": ["Hoch\u00b7wert\u00b7hge\u00b7sch\u00e4tz\u00b7te", "braut", "!", "wie", "wohl", "ist", "ihr", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "PWAV", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Da\u00df sie in ihrer lieb auf nichts, als GOtt, gesehen.", "tokens": ["Da\u00df", "sie", "in", "ih\u00b7rer", "lieb", "auf", "nichts", ",", "als", "Gott", ",", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJD", "APPR", "PIS", "$,", "KOUS", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Er that allein den spruch bey ihrer ersten wahl;", "tokens": ["Er", "that", "al\u00b7lein", "den", "spruch", "bey", "ih\u00b7rer", "ers\u00b7ten", "wahl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Er thut, nach allem schein, es auch das zweyte mahl.", "tokens": ["Er", "thut", ",", "nach", "al\u00b7lem", "schein", ",", "es", "auch", "das", "zwey\u00b7te", "mahl", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PIS", "PTKVZ", "$,", "PPER", "ADV", "ART", "ADJA", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Cupid und Venus sind gemahlte fabel-g\u00f6tzen,", "tokens": ["Cu\u00b7pid", "und", "Ve\u00b7nus", "sind", "ge\u00b7mahl\u00b7te", "fa\u00b7bel\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Die wir, ich wei\u00df nicht wie, in unsre lieder setzen,", "tokens": ["Die", "wir", ",", "ich", "wei\u00df", "nicht", "wie", ",", "in", "uns\u00b7re", "lie\u00b7der", "set\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Offt aber nicht verstehn. Sie sind die b\u00f6se lust,", "tokens": ["Offt", "a\u00b7ber", "nicht", "ver\u00b7stehn", ".", "Sie", "sind", "die", "b\u00f6\u00b7se", "lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "VVINF", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Wenn ich es sagen soll, die manchen unbewust", "tokens": ["Wenn", "ich", "es", "sa\u00b7gen", "soll", ",", "die", "man\u00b7chen", "un\u00b7be\u00b7wust"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VMFIN", "$,", "PRELS", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Aus seinen schrancken rei\u00dft. Und doch will man sich m\u00fchen,", "tokens": ["Aus", "sei\u00b7nen", "schran\u00b7cken", "rei\u00dft", ".", "Und", "doch", "will", "man", "sich", "m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVINF", "VVFIN", "$.", "KON", "ADV", "VMFIN", "PIS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.70": {"text": "Durch weit-gesuchten ruhm sie allem vorzuziehen.", "tokens": ["Durch", "weit\u00b7ge\u00b7such\u00b7ten", "ruhm", "sie", "al\u00b7lem", "vor\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Es wird kein paar getraut, sie haben es entz\u00fcndt;", "tokens": ["Es", "wird", "kein", "paar", "ge\u00b7traut", ",", "sie", "ha\u00b7ben", "es", "ent\u00b7z\u00fcndt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVPP", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wie aber schickt sich GOtt, wo Belial sich sindt?", "tokens": ["Wie", "a\u00b7ber", "schickt", "sich", "Gott", ",", "wo", "Be\u00b7li\u00b7al", "sich", "sindt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PRF", "NN", "$,", "PWAV", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Bey heyden gieng es hin, weil doch die gantzen schaaren", "tokens": ["Bey", "hey\u00b7den", "gieng", "es", "hin", ",", "weil", "doch", "die", "gant\u00b7zen", "schaa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "ADV", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Der g\u00f6tter halb erticht und halb von menschen waren:", "tokens": ["Der", "g\u00f6t\u00b7ter", "halb", "er\u00b7ticht", "und", "halb", "von", "men\u00b7schen", "wa\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVPP", "KON", "ADJD", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Allein nachdem die schrifft sie alle l\u00e4ngst zerstreut,", "tokens": ["Al\u00b7lein", "nach\u00b7dem", "die", "schrifft", "sie", "al\u00b7le", "l\u00e4ngst", "zer\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "VVFIN", "PPER", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "So sind wir ja wohl blind, da\u00df uns ihr lob erfreut.", "tokens": ["So", "sind", "wir", "ja", "wohl", "blind", ",", "da\u00df", "uns", "ihr", "lob", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Wir siegen \u00fcber sie und treten sie mit f\u00fcssen,", "tokens": ["Wir", "sie\u00b7gen", "\u00fc\u00b7ber", "sie", "und", "tre\u00b7ten", "sie", "mit", "f\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KON", "VVFIN", "PPER", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Weil wir nunmehr den weg zur liebe besser wissen.", "tokens": ["Weil", "wir", "nun\u00b7mehr", "den", "weg", "zur", "lie\u00b7be", "bes\u00b7ser", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADV", "APPRART", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Geehrt\u2019ster br\u00e4utigam! ich wei\u00df, er f\u00e4llt mir bey:", "tokens": ["Ge\u00b7ehrt'\u00b7ster", "br\u00e4u\u00b7ti\u00b7gam", "!", "ich", "wei\u00df", ",", "er", "f\u00e4llt", "mir", "bey", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Denn sein exempel zeigt, was kluge liebe sey.", "tokens": ["Denn", "sein", "ex\u00b7em\u00b7pel", "zeigt", ",", "was", "klu\u00b7ge", "lie\u00b7be", "sey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,", "PWS", "ADJA", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Es war in einer frau viel gutes ihm verschwunden;", "tokens": ["Es", "war", "in", "ei\u00b7ner", "frau", "viel", "gu\u00b7tes", "ihm", "ver\u00b7schwun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PIAT", "ADJA", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Heut hat er alles das in seiner braut gefunden,", "tokens": ["Heut", "hat", "er", "al\u00b7les", "das", "in", "sei\u00b7ner", "braut", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "ART", "APPR", "PPOSAT", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Und warlich noch weit mehr. Denn wer ist, der nicht sp\u00fchrt,", "tokens": ["Und", "war\u00b7lich", "noch", "weit", "mehr", ".", "Denn", "wer", "ist", ",", "der", "nicht", "sp\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "ADV", "$.", "KON", "PWS", "VAFIN", "$,", "PRELS", "PTKNEG", "VVFIN", "$,"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.84": {"text": "Da\u00df sie der himmel selbst mit seinen h\u00e4nden f\u00fchrt?", "tokens": ["Da\u00df", "sie", "der", "him\u00b7mel", "selbst", "mit", "sei\u00b7nen", "h\u00e4n\u00b7den", "f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Als sie und Regius vereint zusammen kamen,", "tokens": ["Als", "sie", "und", "Re\u00b7gius", "ver\u00b7eint", "zu\u00b7sam\u00b7men", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KON", "NE", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.86": {"text": "So wuste sie, als kind, noch nicht der liebe nahmen;", "tokens": ["So", "wus\u00b7te", "sie", ",", "als", "kind", ",", "noch", "nicht", "der", "lie\u00b7be", "nah\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "NN", "$,", "ADV", "PTKNEG", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Jtzt da sie es versteht, so sieht man sie getraut,", "tokens": ["Jtzt", "da", "sie", "es", "ver\u00b7steht", ",", "so", "sieht", "man", "sie", "ge\u00b7traut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Eh sie sich nach der welt im lieben umgeschaut.", "tokens": ["Eh", "sie", "sich", "nach", "der", "welt", "im", "lie\u00b7ben", "um\u00b7ge\u00b7schaut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Was kan ich anders denn als gutes prophezeyen?", "tokens": ["Was", "kan", "ich", "an\u00b7ders", "denn", "als", "gu\u00b7tes", "pro\u00b7phe\u00b7ze\u00b7yen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "KOUS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.90": {"text": "Gott hat allhier gepflantzt, GOtt hat auch das gedeyen", "tokens": ["Gott", "hat", "all\u00b7hier", "ge\u00b7pflantzt", ",", "Gott", "hat", "auch", "das", "ge\u00b7de\u00b7yen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ADV", "VVPP", "$,", "NN", "VAFIN", "ADV", "ART", "NN"], "meter": "+-+--+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.91": {"text": "Schon l\u00e4ngsten abgezielt: Jhr solt stets so begl\u00fcckt,", "tokens": ["Schon", "l\u00e4ngs\u00b7ten", "ab\u00b7ge\u00b7zielt", ":", "Ihr", "solt", "stets", "so", "be\u00b7gl\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVPP", "$.", "PPER", "VMFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Als diesen tag verliebt, und immer so entz\u00fcckt,", "tokens": ["Als", "die\u00b7sen", "tag", "ver\u00b7liebt", ",", "und", "im\u00b7mer", "so", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "VVPP", "$,", "KON", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Als heute gl\u00fccklich seyn! Ich wolte zwar was schreiben;", "tokens": ["Als", "heu\u00b7te", "gl\u00fcck\u00b7lich", "seyn", "!", "Ich", "wol\u00b7te", "zwar", "was", "schrei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "VAINF", "$.", "PPER", "VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Allein wo k\u00e4m ich hin? Wo w\u00fcrd ich endlich bleiben?", "tokens": ["Al\u00b7lein", "wo", "k\u00e4m", "ich", "hin", "?", "Wo", "w\u00fcrd", "ich", "end\u00b7lich", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "VVFIN", "PPER", "PTKVZ", "$.", "PWAV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Mein Ph\u00f6bus z\u00fcrnt ohn dem, da\u00df ich zu frey getr\u00e4umt,", "tokens": ["Mein", "Ph\u00f6\u00b7bus", "z\u00fcrnt", "ohn", "dem", ",", "da\u00df", "ich", "zu", "frey", "ge\u00b7tr\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "$,", "KOUS", "PPER", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und so viel zeilen hier so fl\u00fcchtig hingereimt.", "tokens": ["Und", "so", "viel", "zei\u00b7len", "hier", "so", "fl\u00fcch\u00b7tig", "hin\u00b7ge\u00b7reimt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}