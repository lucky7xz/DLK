{"textgrid.poem.49917": {"metadata": {"author": {"name": "M\u00f6rike, Eduard", "birth": "N.A.", "death": "N.A."}, "title": "An Longus", "genre": "verse", "period": "N.A.", "pub_year": 1841, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Von Widerwarten eine Sorte kennen wir", "tokens": ["Von", "Wi\u00b7der\u00b7war\u00b7ten", "ei\u00b7ne", "Sor\u00b7te", "ken\u00b7nen", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Genau und haben \u00e4rgerlich sie oft belacht,", "tokens": ["Ge\u00b7nau", "und", "ha\u00b7ben", "\u00e4r\u00b7ger\u00b7lich", "sie", "oft", "be\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VAFIN", "ADJD", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja einen eignen Namen ihr erschufest du,", "tokens": ["Ja", "ei\u00b7nen", "eig\u00b7nen", "Na\u00b7men", "ihr", "er\u00b7schu\u00b7fest", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "ADJA", "NN", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und heute noch beneid ich dir den k\u00fchnen Fund.", "tokens": ["Und", "heu\u00b7te", "noch", "be\u00b7neid", "ich", "dir", "den", "k\u00fch\u00b7nen", "Fund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Zur Kurzweil gestern in der alten Handelsstadt,", "tokens": ["Zur", "Kurz\u00b7weil", "ge\u00b7stern", "in", "der", "al\u00b7ten", "Han\u00b7dels\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die mich herbergend einen Tag langweilete,", "tokens": ["Die", "mich", "her\u00b7ber\u00b7gend", "ei\u00b7nen", "Tag", "lang\u00b7wei\u00b7le\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Ging ich vor Tisch, der Schiffe Ankunft mit zu sehn,", "tokens": ["Ging", "ich", "vor", "Tisch", ",", "der", "Schif\u00b7fe", "An\u00b7kunft", "mit", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,", "ART", "NN", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nach dem Kanal, wo im Get\u00fcmmel und Geschrei", "tokens": ["Nach", "dem", "Ka\u00b7nal", ",", "wo", "im", "Ge\u00b7t\u00fcm\u00b7mel", "und", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "APPRART", "NN", "KON", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Von tausendh\u00e4ndig aufgeregter Packmannschaft,", "tokens": ["Von", "tau\u00b7send\u00b7h\u00e4n\u00b7dig", "auf\u00b7ge\u00b7reg\u00b7ter", "Pack\u00b7mann\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Fa\u00dfw\u00e4lzender, um Kist und Ballen fluchender,", "tokens": ["Fa\u00df\u00b7w\u00e4l\u00b7zen\u00b7der", ",", "um", "Kist", "und", "Bal\u00b7len", "flu\u00b7chen\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUI", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der t\u00e4tige Faktor sich zeigt und, Gaffens halb,", "tokens": ["Der", "t\u00e4\u00b7ti\u00b7ge", "Fak\u00b7tor", "sich", "zeigt", "und", ",", "Gaf\u00b7fens", "halb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "KON", "$,", "NN", "ADJD", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Der Stra\u00dfenjunge, beide H\u00e4nd im Latze, steht.", "tokens": ["Der", "Stra\u00b7\u00dfen\u00b7jun\u00b7ge", ",", "bei\u00b7de", "H\u00e4nd", "im", "Lat\u00b7ze", ",", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch auf dem reinen Quaderdamme ab und zu", "tokens": ["Doch", "auf", "dem", "rei\u00b7nen", "Qua\u00b7der\u00b7dam\u00b7me", "ab", "und", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Spaziert' ein P\u00e4rchen; dieses fa\u00dft' ich mir ins Aug.", "tokens": ["Spa\u00b7ziert'", "ein", "P\u00e4r\u00b7chen", ";", "die\u00b7ses", "fa\u00dft'", "ich", "mir", "ins", "Aug."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "ART", "NN", "$.", "PDS", "VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Im gr\u00fcnen, goldbekn\u00f6pften Frack ein junger Herr", "tokens": ["Im", "gr\u00fc\u00b7nen", ",", "gold\u00b7be\u00b7kn\u00f6pf\u00b7ten", "Frack", "ein", "jun\u00b7ger", "Herr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit einer h\u00fcbschen Dame, modisch aufgepfauscht.", "tokens": ["Mit", "ei\u00b7ner", "h\u00fcb\u00b7schen", "Da\u00b7me", ",", "mo\u00b7disch", "auf\u00b7ge\u00b7pfauscht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Schnurrbartsbewu\u00dftsein trug und hob den ganzen Mann", "tokens": ["Schnurr\u00b7barts\u00b7be\u00b7wu\u00df\u00b7tsein", "trug", "und", "hob", "den", "gan\u00b7zen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und glattgespannter Hosen Sicherheitsgef\u00fchl,", "tokens": ["Und", "glatt\u00b7ge\u00b7spann\u00b7ter", "Ho\u00b7sen", "Si\u00b7cher\u00b7heits\u00b7ge\u00b7f\u00fchl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kurz, von dem H\u00fctchen bis hinab zum kleinen Sporn", "tokens": ["Kurz", ",", "von", "dem", "H\u00fct\u00b7chen", "bis", "hin\u00b7ab", "zum", "klei\u00b7nen", "Sporn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ART", "NN", "APPR", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Belebet' ihn vollendete Pers\u00f6nlichkeit.", "tokens": ["Be\u00b7le\u00b7bet'", "ihn", "voll\u00b7en\u00b7de\u00b7te", "Per\u00b7s\u00f6n\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Sie aber lachte p\u00fcnktlich jedem d\u00fcrftgen Scherz.", "tokens": ["Sie", "a\u00b7ber", "lach\u00b7te", "p\u00fcnkt\u00b7lich", "je\u00b7dem", "d\u00fcrft\u00b7gen", "Scherz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der treue Pudel, an des Herren Knie gelockt,", "tokens": ["Der", "treu\u00b7e", "Pu\u00b7del", ",", "an", "des", "Her\u00b7ren", "Knie", "ge\u00b7lockt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wird, ihr zum Spa\u00dfe, schmerzlich in das Ohr gekneipt,", "tokens": ["Wird", ",", "ihr", "zum", "Spa\u00b7\u00dfe", ",", "schmerz\u00b7lich", "in", "das", "Ohr", "ge\u00b7kneipt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PPER", "APPRART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Bis er im hohen Fistelton gehorsam heult,", "tokens": ["Bis", "er", "im", "ho\u00b7hen", "Fis\u00b7tel\u00b7ton", "ge\u00b7hor\u00b7sam", "heult", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zu Nachahmung ich wei\u00df nicht welcher S\u00e4ngerin.", "tokens": ["Zu", "Nac\u00b7hah\u00b7mung", "ich", "wei\u00df", "nicht", "wel\u00b7cher", "S\u00e4n\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "PTKNEG", "PWAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nun, dieser Liebenswerte, d\u00e4cht ich, ist doch schon", "tokens": ["Nun", ",", "die\u00b7ser", "Lie\u00b7bens\u00b7wer\u00b7te", ",", "d\u00e4cht", "ich", ",", "ist", "doch", "schon"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PDAT", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beinahe was mein Longus einen ", "tokens": ["Bei\u00b7na\u00b7he", "was", "mein", "Lon\u00b7gus", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPOSAT", "NE", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und auch die Dame war in hohem Grade ", "tokens": ["Und", "auch", "die", "Da\u00b7me", "war", "in", "ho\u00b7hem", "Gra\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch nicht die affektierte Fratze, nicht allein", "tokens": ["Doch", "nicht", "die", "af\u00b7fek\u00b7tier\u00b7te", "Frat\u00b7ze", ",", "nicht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKNEG", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den Gecken zeichnet dieses einzge Wort, vielmehr,", "tokens": ["Den", "Ge\u00b7cken", "zeich\u00b7net", "die\u00b7ses", "einz\u00b7ge", "Wort", ",", "viel\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was sich mit Selbstgef\u00e4lligkeit Bedeutung gibt,", "tokens": ["Was", "sich", "mit", "Selbst\u00b7ge\u00b7f\u00e4l\u00b7lig\u00b7keit", "Be\u00b7deu\u00b7tung", "gibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Amtliches Air, vornehm ablehnende Manier,", "tokens": ["Amt\u00b7li\u00b7ches", "Air", ",", "vor\u00b7nehm", "ab\u00b7leh\u00b7nen\u00b7de", "Ma\u00b7nier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Dies und noch manches andere begreifet es.", "tokens": ["Dies", "und", "noch", "man\u00b7ches", "an\u00b7de\u00b7re", "be\u00b7grei\u00b7fet", "es", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "ADV", "PIS", "PIS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der Prinzipal vom Comptoir und der Kanzellei", "tokens": ["Der", "Prin\u00b7zi\u00b7pal", "vom", "Comp\u00b7toir", "und", "der", "Kan\u00b7zel\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Empf\u00e4ngt den Assistenten oder Kommis \u2013 denkt,", "tokens": ["Emp\u00b7f\u00e4ngt", "den", "As\u00b7sis\u00b7ten\u00b7ten", "o\u00b7der", "Kom\u00b7mis", "\u2013", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "NE", "$(", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Er kam nach elfe gestern nacht zu Hause erst \u2013", "tokens": ["Er", "kam", "nach", "el\u00b7fe", "ge\u00b7stern", "nacht", "zu", "Hau\u00b7se", "erst", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "APPR", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den andern Tag mit einem langen Sehrgesicht.", "tokens": ["Den", "an\u00b7dern", "Tag", "mit", "ei\u00b7nem", "lan\u00b7gen", "Sehr\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Kammerzofe, die kokette Kellnerin,", "tokens": ["Die", "Kam\u00b7mer\u00b7zo\u00b7fe", ",", "die", "ko\u00b7ket\u00b7te", "Kell\u00b7ne\u00b7rin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Nachdem sie erst den Sch\u00e4ker k\u00fchn gemacht, tut b\u00f6s,", "tokens": ["Nach\u00b7dem", "sie", "erst", "den", "Sch\u00e4\u00b7ker", "k\u00fchn", "ge\u00b7macht", ",", "tut", "b\u00f6s", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "VVPP", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da er nun vom geraubten Kusse weitergeht:", "tokens": ["Da", "er", "nun", "vom", "ge\u00b7raub\u00b7ten", "Kus\u00b7se", "wei\u00b7ter\u00b7geht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u00bbich mu\u00df recht, recht sehr bitten!\u00ab sagt sie wiederholt", "tokens": ["\u00bb", "ich", "mu\u00df", "recht", ",", "recht", "sehr", "bit\u00b7ten", "!", "\u00ab", "sagt", "sie", "wie\u00b7der\u00b7holt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADJD", "$,", "ADV", "ADV", "VVINF", "$.", "$(", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit seri\u00f6sem Nachdruck zum Verlegenen.", "tokens": ["Mit", "se\u00b7ri\u00b7\u00f6\u00b7sem", "Nach\u00b7druck", "zum", "Ver\u00b7le\u00b7ge\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "---+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Die Tugend selber zeiget sich in Sehrheit gern.", "tokens": ["Die", "Tu\u00b7gend", "sel\u00b7ber", "zei\u00b7get", "sich", "in", "Sehr\u00b7heit", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O h\u00e4ttest du den jungen Geistlichen gesehn,", "tokens": ["O", "h\u00e4t\u00b7test", "du", "den", "jun\u00b7gen", "Geist\u00b7li\u00b7chen", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem ich nur neulich an der Kircht\u00fcr hospitiert!", "tokens": ["Dem", "ich", "nur", "neu\u00b7lich", "an", "der", "Kirch\u00b7t\u00fcr", "hos\u00b7pi\u00b7tiert", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Milch und Blut ein M\u00e4nnchen, durchaus musterhaft;", "tokens": ["Wie", "Milch", "und", "Blut", "ein", "M\u00e4nn\u00b7chen", ",", "durc\u00b7haus", "mus\u00b7ter\u00b7haft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ART", "NN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er wu\u00dft es auch; im wohlgezognen Backenbart,", "tokens": ["Er", "wu\u00dft", "es", "auch", ";", "im", "wohl\u00b7ge\u00b7zog\u00b7nen", "Ba\u00b7cken\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im blonden, war kein H\u00e4rchen, wett ich, ungez\u00e4hlt.", "tokens": ["Im", "blon\u00b7den", ",", "war", "kein", "H\u00e4r\u00b7chen", ",", "wett", "ich", ",", "un\u00b7ge\u00b7z\u00e4hlt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "VAFIN", "PIAT", "NN", "$,", "VVFIN", "PPER", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Predigt roch mir seltsamlich nach Leier und Schwert,", "tokens": ["Die", "Pre\u00b7digt", "roch", "mir", "selt\u00b7sam\u00b7lich", "nach", "Lei\u00b7er", "und", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Er kam nicht weg vom sch\u00f6nen Tod f\u00fcrs Vaterland;", "tokens": ["Er", "kam", "nicht", "weg", "vom", "sch\u00f6\u00b7nen", "Tod", "f\u00fcrs", "Va\u00b7ter\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "APPRART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein paarmal gar riskiert' er liberal zu sein,", "tokens": ["Ein", "paar\u00b7mal", "gar", "ris\u00b7ki\u00b7ert'", "er", "li\u00b7be\u00b7ral", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "H\u00f6chst liberal \u2013 nun, halsgef\u00e4hrlich macht' er's nicht,", "tokens": ["H\u00f6chst", "li\u00b7be\u00b7ral", "\u2013", "nun", ",", "hals\u00b7ge\u00b7f\u00e4hr\u00b7lich", "macht'", "er's", "nicht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "$,", "ADJD", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Doch wurden ihm die Ohren sichtlich warm dabei.", "tokens": ["Doch", "wur\u00b7den", "ihm", "die", "Oh\u00b7ren", "sicht\u00b7lich", "warm", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "PRF", "ADJD", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zuletzt, herabgestiegen von der Kanzel, rauscht", "tokens": ["Zu\u00b7letzt", ",", "her\u00b7ab\u00b7ge\u00b7stie\u00b7gen", "von", "der", "Kan\u00b7zel", ",", "rauscht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "VVPP", "APPR", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er strahlend, Kopf und Schultern wiegend, rasch vorbei", "tokens": ["Er", "strah\u00b7lend", ",", "Kopf", "und", "Schul\u00b7tern", "wie\u00b7gend", ",", "rasch", "vor\u00b7bei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADJD", "$,", "NN", "KON", "NN", "VVPP", "$,", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dem duftgen Reihen tief bewegter Jungfr\u00e4ulein.", "tokens": ["Dem", "duft\u00b7gen", "Rei\u00b7hen", "tief", "be\u00b7weg\u00b7ter", "Jung\u00b7fr\u00e4u\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und richtig macht er ihnen ein Sehrkompliment.", "tokens": ["Und", "rich\u00b7tig", "macht", "er", "ih\u00b7nen", "ein", "Sehr\u00b7kom\u00b7pli\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Besonders ist die Gro\u00dfmut ungemein sehrhaft.", "tokens": ["Be\u00b7son\u00b7ders", "ist", "die", "Gro\u00df\u00b7mut", "un\u00b7ge\u00b7mein", "sehr\u00b7haft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn der Student, von edlem Burschentum ergl\u00fcht,", "tokens": ["Denn", "der", "Stu\u00b7dent", ",", "von", "ed\u00b7lem", "Bur\u00b7schen\u00b7tum", "er\u00b7gl\u00fcht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der hochgesinnte Leutnant, schreibet seinem Feind", "tokens": ["Der", "hoch\u00b7ge\u00b7sinn\u00b7te", "Leut\u00b7nant", ",", "schrei\u00b7bet", "sei\u00b7nem", "Feind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(ach ", "tokens": ["(", "ach"], "token_info": ["punct", "word"], "pos": ["$(", "XY"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Nach schon erkl\u00e4rtem Ehrenkampfe, schnell vers\u00f6hnt,", "tokens": ["Nach", "schon", "er\u00b7kl\u00e4r\u00b7tem", "Eh\u00b7ren\u00b7kamp\u00b7fe", ",", "schnell", "ver\u00b7s\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Lakonisch sch\u00f6n ein Sehrbillett \u2013 es r\u00fchrt ihn selbst.", "tokens": ["La\u00b7ko\u00b7nisch", "sch\u00f6n", "ein", "Sehr\u00b7bil\u00b7lett", "\u2013", "es", "r\u00fchrt", "ihn", "selbst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ART", "NN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So ein Herr X, so ein Herr Z, als Rezensent,", "tokens": ["So", "ein", "Herr", "X", ",", "so", "ein", "Herr", "Z", ",", "als", "Re\u00b7zen\u00b7sent", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "XY", "$,", "ADV", "ART", "NN", "NN", "$,", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist gro\u00dfer Sehrmann, Sehr-Sehrmann, just wenn er dir", "tokens": ["Ist", "gro\u00b7\u00dfer", "Sehr\u00b7mann", ",", "Sehr\u00b7Sehr\u00b7mann", ",", "just", "wenn", "er", "dir"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJA", "NN", "$,", "NE", "$,", "ADV", "KOUS", "PPER", "PPER"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Den Lorbeer reicht, beinahe mehr noch als wenn er", "tokens": ["Den", "Lor\u00b7beer", "reicht", ",", "bei\u00b7na\u00b7he", "mehr", "noch", "als", "wenn", "er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "ADV", "ADV", "KOKOM", "KOUS", "PPER"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Sein h\u00f6hnisch Sic! und Sapienti sat! hintrumpft.", "tokens": ["Sein", "h\u00f6h\u00b7nisch", "Sic", "!", "und", "Sa\u00b7pi\u00b7en\u00b7ti", "sat", "!", "hin\u00b7trumpft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NE", "$.", "KON", "NE", "VVFIN", "$.", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Hiern\u00e4chst versteht sich allerdings, da\u00df viele auch", "tokens": ["Hier\u00b7n\u00e4chst", "ver\u00b7steht", "sich", "al\u00b7ler\u00b7dings", ",", "da\u00df", "vie\u00b7le", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "$,", "KOUS", "PIS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur teilweis und gelegentlich Sehrleute sind.", "tokens": ["Nur", "teil\u00b7weis", "und", "ge\u00b7le\u00b7gent\u00b7lich", "Sehr\u00b7leu\u00b7te", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "NN", "VAFIN", "$."], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So haben wir an manchem herzlich lieben Freund", "tokens": ["So", "ha\u00b7ben", "wir", "an", "man\u00b7chem", "herz\u00b7lich", "lie\u00b7ben", "Freund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein unzweideutig \u00c4derchen der Art bemerkt,", "tokens": ["Ein", "un\u00b7zwei\u00b7deu\u00b7tig", "\u00c4\u00b7der\u00b7chen", "der", "Art", "be\u00b7merkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Und freilich immer eine Faust im Sack gemacht.", "tokens": ["Und", "frei\u00b7lich", "im\u00b7mer", "ei\u00b7ne", "Faust", "im", "Sack", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch wenn es nun vollendet erst erscheint, es sei", "tokens": ["Doch", "wenn", "es", "nun", "voll\u00b7en\u00b7det", "erst", "er\u00b7scheint", ",", "es", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "ADV", "VVFIN", "$,", "PPER", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mann oder Weib, der Menschheit Afterbild \u2013 o wer,", "tokens": ["Mann", "o\u00b7der", "Weib", ",", "der", "Menschheit", "Af\u00b7ter\u00b7bild", "\u2013", "o", "wer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "ART", "NN", "NN", "$(", "FM", "PWS", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Dem sich im Busen ein gesundes Herz bewegt,", "tokens": ["Dem", "sich", "im", "Bu\u00b7sen", "ein", "ge\u00b7sun\u00b7des", "Herz", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ertr\u00e4gt es wohl? wem kr\u00fcmmte sich im Innern nicht", "tokens": ["Er\u00b7tr\u00e4gt", "es", "wohl", "?", "wem", "kr\u00fcmm\u00b7te", "sich", "im", "In\u00b7nern", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "PWS", "VVFIN", "PRF", "APPRART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das Eingeweide? Gift und Operment ist mir's!", "tokens": ["Das", "Ein\u00b7ge\u00b7wei\u00b7de", "?", "Gift", "und", "O\u00b7per\u00b7ment", "ist", "mir's", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "KON", "NN", "VAFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Denn w\u00e4ren sie nur l\u00e4cherlich! sie sind zumeist", "tokens": ["Denn", "w\u00e4\u00b7ren", "sie", "nur", "l\u00e4\u00b7cher\u00b7lich", "!", "sie", "sind", "zu\u00b7meist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADJD", "$.", "PPER", "VAFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Verrucht, abscheulich, wenn du sie beim Licht besiehst.", "tokens": ["Ver\u00b7rucht", ",", "ab\u00b7scheu\u00b7lich", ",", "wenn", "du", "sie", "beim", "Licht", "be\u00b7siehst", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Kein Mensch beleidigt wie der Sehrmann und verletzt", "tokens": ["Kein", "Mensch", "be\u00b7lei\u00b7digt", "wie", "der", "Sehr\u00b7mann", "und", "ver\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVPP", "KOKOM", "ART", "NN", "KON", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Empfindlicher; w\u00e4r's auch nur durch die Art wie er", "tokens": ["Emp\u00b7find\u00b7li\u00b7cher", ";", "w\u00e4r's", "auch", "nur", "durch", "die", "Art", "wie", "er"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "KOKOM", "PPER"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Dich im Gespr\u00e4ch am Rockknopf fa\u00dft. Du schn\u00f6de Brut!", "tokens": ["Dich", "im", "Ge\u00b7spr\u00e4ch", "am", "Rock\u00b7knopf", "fa\u00dft", ".", "Du", "schn\u00f6\u00b7de", "Brut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$.", "PPER", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Wo einer auftritt, jedes Edle ist sogleich", "tokens": ["Wo", "ei\u00b7ner", "auf\u00b7tritt", ",", "je\u00b7des", "Ed\u00b7le", "ist", "sog\u00b7leich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PIAT", "ADJA", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Gel\u00e4hmt, vernichtet neben ihnen, nichts beh\u00e4lt", "tokens": ["Ge\u00b7l\u00e4hmt", ",", "ver\u00b7nich\u00b7tet", "ne\u00b7ben", "ih\u00b7nen", ",", "nichts", "be\u00b7h\u00e4lt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "APPR", "PPER", "$,", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den eignen, unbedingten Wert. Geht dir einmal", "tokens": ["Den", "eig\u00b7nen", ",", "un\u00b7be\u00b7ding\u00b7ten", "Wert", ".", "Geht", "dir", "ein\u00b7mal"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$.", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der Mund in seiner Gegenwart begeistert auf,", "tokens": ["Der", "Mund", "in", "sei\u00b7ner", "Ge\u00b7gen\u00b7wart", "be\u00b7geis\u00b7tert", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Um was es sei \u2013 der Mann besitzt ein bleiernes,", "tokens": ["Um", "was", "es", "sei", "\u2013", "der", "Mann", "be\u00b7sitzt", "ein", "blei\u00b7er\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PWS", "PPER", "VAFIN", "$(", "ART", "NN", "VVFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.21": {"text": "Grausames Schweigen; v\u00f6llig bringt dich's auf den Hund.", "tokens": ["Grau\u00b7sa\u00b7mes", "Schwei\u00b7gen", ";", "v\u00f6l\u00b7lig", "bringt", "dich's", "auf", "den", "Hund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.22": {"text": "\u2013 Was hie\u00dfe gottlos, wenn es dies Geschlecht nicht ist?", "tokens": ["\u2013", "Was", "hie\u00b7\u00dfe", "gott\u00b7los", ",", "wenn", "es", "dies", "Ge\u00b7schlecht", "nicht", "ist", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "PDS", "NN", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und nicht im Schlaf auch fiel es ihnen ein, da\u00df sie", "tokens": ["Und", "nicht", "im", "Schlaf", "auch", "fiel", "es", "ih\u00b7nen", "ein", ",", "da\u00df", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKNEG", "APPRART", "NN", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Mit Haut und Haar des Teufels sind. Ich scherze nicht.", "tokens": ["Mit", "Haut", "und", "Haar", "des", "Teu\u00b7fels", "sind", ".", "Ich", "scher\u00b7ze", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "VAFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Durch Bu\u00dfe kommt ein Arger wohl zum Himmelreich:", "tokens": ["Durch", "Bu\u00b7\u00dfe", "kommt", "ein", "Ar\u00b7ger", "wohl", "zum", "Him\u00b7mel\u00b7reich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Doch kann der Sehrmann Bu\u00dfe tun? O nimmermehr!", "tokens": ["Doch", "kann", "der", "Sehr\u00b7mann", "Bu\u00b7\u00dfe", "tun", "?", "O", "nim\u00b7mer\u00b7mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "VVINF", "$.", "NE", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Drum f\u00fcrcht ich, wenn sein abgeschiedner Geist dereinst", "tokens": ["Drum", "f\u00fcrcht", "ich", ",", "wenn", "sein", "ab\u00b7ge\u00b7schied\u00b7ner", "Geist", "de\u00b7reinst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Sich, frech genug, des Paradieses Pforte naht,", "tokens": ["Sich", ",", "frech", "ge\u00b7nug", ",", "des", "Pa\u00b7ra\u00b7die\u00b7ses", "Pfor\u00b7te", "naht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "ADJD", "ADV", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der rosigen, wo, Wache haltend, hellgelockt", "tokens": ["Der", "ro\u00b7si\u00b7gen", ",", "wo", ",", "Wa\u00b7che", "hal\u00b7tend", ",", "hell\u00b7ge\u00b7lockt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "PWAV", "$,", "NN", "VVPP", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ein Engel lehnet, hingesenkt ein tr\u00e4umend Ohr", "tokens": ["Ein", "En\u00b7gel", "leh\u00b7net", ",", "hin\u00b7ge\u00b7senkt", "ein", "tr\u00e4u\u00b7mend", "Ohr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Den ewgen Melodien, die im Innern sind:", "tokens": ["Den", "ew\u00b7gen", "Me\u00b7lo\u00b7dien", ",", "die", "im", "In\u00b7nern", "sind", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Aufschaut der W\u00e4chter, misset ruhig die Gestalt", "tokens": ["Auf\u00b7schaut", "der", "W\u00e4ch\u00b7ter", ",", "mis\u00b7set", "ru\u00b7hig", "die", "Ge\u00b7stalt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NE", "$,", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Von Kopf zu Fu\u00df, die fragende, und sch\u00fcttelt jetzt", "tokens": ["Von", "Kopf", "zu", "Fu\u00df", ",", "die", "fra\u00b7gen\u00b7de", ",", "und", "sch\u00fct\u00b7telt", "jetzt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "ART", "ADJA", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mit sanftem Ernst, mitleidig fast, das sch\u00f6ne Haupt,", "tokens": ["Mit", "sanf\u00b7tem", "Ernst", ",", "mit\u00b7lei\u00b7dig", "fast", ",", "das", "sch\u00f6\u00b7ne", "Haupt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Links deutend, ungern, mit der Hand, abw\u00e4rts den Pfad.", "tokens": ["Links", "deu\u00b7tend", ",", "un\u00b7gern", ",", "mit", "der", "Hand", ",", "ab\u00b7w\u00e4rts", "den", "Pfad", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "$,", "APPR", "ART", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.36": {"text": "Befremdet, ja beleidigt stellt mein Mann sich an,", "tokens": ["Be\u00b7frem\u00b7det", ",", "ja", "be\u00b7lei\u00b7digt", "stellt", "mein", "Mann", "sich", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADJD", "VVFIN", "PPOSAT", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Und zaudert noch; doch da er sieht, hier sei es Ernst,", "tokens": ["Und", "zau\u00b7dert", "noch", ";", "doch", "da", "er", "sieht", ",", "hier", "sei", "es", "Ernst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$.", "ADV", "KOUS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Schwenkt er in h\u00f6chster Sehrheit trotziglich, getrost", "tokens": ["Schwenkt", "er", "in", "h\u00f6chs\u00b7ter", "Sehr\u00b7heit", "trot\u00b7zig\u00b7lich", ",", "ge\u00b7trost"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "ADJD", "$,", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Sich ab und schw\u00e4nzelt unges\u00e4umt der H\u00f6lle zu.", "tokens": ["Sich", "ab", "und", "schw\u00e4n\u00b7zelt", "un\u00b7ge\u00b7s\u00e4umt", "der", "H\u00f6l\u00b7le", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKVZ", "KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Von Widerwarten eine Sorte kennen wir", "tokens": ["Von", "Wi\u00b7der\u00b7war\u00b7ten", "ei\u00b7ne", "Sor\u00b7te", "ken\u00b7nen", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Genau und haben \u00e4rgerlich sie oft belacht,", "tokens": ["Ge\u00b7nau", "und", "ha\u00b7ben", "\u00e4r\u00b7ger\u00b7lich", "sie", "oft", "be\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VAFIN", "ADJD", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja einen eignen Namen ihr erschufest du,", "tokens": ["Ja", "ei\u00b7nen", "eig\u00b7nen", "Na\u00b7men", "ihr", "er\u00b7schu\u00b7fest", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "ADJA", "NN", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und heute noch beneid ich dir den k\u00fchnen Fund.", "tokens": ["Und", "heu\u00b7te", "noch", "be\u00b7neid", "ich", "dir", "den", "k\u00fch\u00b7nen", "Fund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Zur Kurzweil gestern in der alten Handelsstadt,", "tokens": ["Zur", "Kurz\u00b7weil", "ge\u00b7stern", "in", "der", "al\u00b7ten", "Han\u00b7dels\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Die mich herbergend einen Tag langweilete,", "tokens": ["Die", "mich", "her\u00b7ber\u00b7gend", "ei\u00b7nen", "Tag", "lang\u00b7wei\u00b7le\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Ging ich vor Tisch, der Schiffe Ankunft mit zu sehn,", "tokens": ["Ging", "ich", "vor", "Tisch", ",", "der", "Schif\u00b7fe", "An\u00b7kunft", "mit", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,", "ART", "NN", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nach dem Kanal, wo im Get\u00fcmmel und Geschrei", "tokens": ["Nach", "dem", "Ka\u00b7nal", ",", "wo", "im", "Ge\u00b7t\u00fcm\u00b7mel", "und", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "APPRART", "NN", "KON", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Von tausendh\u00e4ndig aufgeregter Packmannschaft,", "tokens": ["Von", "tau\u00b7send\u00b7h\u00e4n\u00b7dig", "auf\u00b7ge\u00b7reg\u00b7ter", "Pack\u00b7mann\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Fa\u00dfw\u00e4lzender, um Kist und Ballen fluchender,", "tokens": ["Fa\u00df\u00b7w\u00e4l\u00b7zen\u00b7der", ",", "um", "Kist", "und", "Bal\u00b7len", "flu\u00b7chen\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUI", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der t\u00e4tige Faktor sich zeigt und, Gaffens halb,", "tokens": ["Der", "t\u00e4\u00b7ti\u00b7ge", "Fak\u00b7tor", "sich", "zeigt", "und", ",", "Gaf\u00b7fens", "halb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "KON", "$,", "NN", "ADJD", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Der Stra\u00dfenjunge, beide H\u00e4nd im Latze, steht.", "tokens": ["Der", "Stra\u00b7\u00dfen\u00b7jun\u00b7ge", ",", "bei\u00b7de", "H\u00e4nd", "im", "Lat\u00b7ze", ",", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Doch auf dem reinen Quaderdamme ab und zu", "tokens": ["Doch", "auf", "dem", "rei\u00b7nen", "Qua\u00b7der\u00b7dam\u00b7me", "ab", "und", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Spaziert' ein P\u00e4rchen; dieses fa\u00dft' ich mir ins Aug.", "tokens": ["Spa\u00b7ziert'", "ein", "P\u00e4r\u00b7chen", ";", "die\u00b7ses", "fa\u00dft'", "ich", "mir", "ins", "Aug."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "ART", "NN", "$.", "PDS", "VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Im gr\u00fcnen, goldbekn\u00f6pften Frack ein junger Herr", "tokens": ["Im", "gr\u00fc\u00b7nen", ",", "gold\u00b7be\u00b7kn\u00f6pf\u00b7ten", "Frack", "ein", "jun\u00b7ger", "Herr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit einer h\u00fcbschen Dame, modisch aufgepfauscht.", "tokens": ["Mit", "ei\u00b7ner", "h\u00fcb\u00b7schen", "Da\u00b7me", ",", "mo\u00b7disch", "auf\u00b7ge\u00b7pfauscht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Schnurrbartsbewu\u00dftsein trug und hob den ganzen Mann", "tokens": ["Schnurr\u00b7barts\u00b7be\u00b7wu\u00df\u00b7tsein", "trug", "und", "hob", "den", "gan\u00b7zen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und glattgespannter Hosen Sicherheitsgef\u00fchl,", "tokens": ["Und", "glatt\u00b7ge\u00b7spann\u00b7ter", "Ho\u00b7sen", "Si\u00b7cher\u00b7heits\u00b7ge\u00b7f\u00fchl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kurz, von dem H\u00fctchen bis hinab zum kleinen Sporn", "tokens": ["Kurz", ",", "von", "dem", "H\u00fct\u00b7chen", "bis", "hin\u00b7ab", "zum", "klei\u00b7nen", "Sporn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ART", "NN", "APPR", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Belebet' ihn vollendete Pers\u00f6nlichkeit.", "tokens": ["Be\u00b7le\u00b7bet'", "ihn", "voll\u00b7en\u00b7de\u00b7te", "Per\u00b7s\u00f6n\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Sie aber lachte p\u00fcnktlich jedem d\u00fcrftgen Scherz.", "tokens": ["Sie", "a\u00b7ber", "lach\u00b7te", "p\u00fcnkt\u00b7lich", "je\u00b7dem", "d\u00fcrft\u00b7gen", "Scherz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der treue Pudel, an des Herren Knie gelockt,", "tokens": ["Der", "treu\u00b7e", "Pu\u00b7del", ",", "an", "des", "Her\u00b7ren", "Knie", "ge\u00b7lockt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wird, ihr zum Spa\u00dfe, schmerzlich in das Ohr gekneipt,", "tokens": ["Wird", ",", "ihr", "zum", "Spa\u00b7\u00dfe", ",", "schmerz\u00b7lich", "in", "das", "Ohr", "ge\u00b7kneipt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PPER", "APPRART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Bis er im hohen Fistelton gehorsam heult,", "tokens": ["Bis", "er", "im", "ho\u00b7hen", "Fis\u00b7tel\u00b7ton", "ge\u00b7hor\u00b7sam", "heult", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zu Nachahmung ich wei\u00df nicht welcher S\u00e4ngerin.", "tokens": ["Zu", "Nac\u00b7hah\u00b7mung", "ich", "wei\u00df", "nicht", "wel\u00b7cher", "S\u00e4n\u00b7ge\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "PTKNEG", "PWAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Nun, dieser Liebenswerte, d\u00e4cht ich, ist doch schon", "tokens": ["Nun", ",", "die\u00b7ser", "Lie\u00b7bens\u00b7wer\u00b7te", ",", "d\u00e4cht", "ich", ",", "ist", "doch", "schon"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PDAT", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beinahe was mein Longus einen ", "tokens": ["Bei\u00b7na\u00b7he", "was", "mein", "Lon\u00b7gus", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPOSAT", "NE", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und auch die Dame war in hohem Grade ", "tokens": ["Und", "auch", "die", "Da\u00b7me", "war", "in", "ho\u00b7hem", "Gra\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch nicht die affektierte Fratze, nicht allein", "tokens": ["Doch", "nicht", "die", "af\u00b7fek\u00b7tier\u00b7te", "Frat\u00b7ze", ",", "nicht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKNEG", "ART", "ADJA", "NN", "$,", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den Gecken zeichnet dieses einzge Wort, vielmehr,", "tokens": ["Den", "Ge\u00b7cken", "zeich\u00b7net", "die\u00b7ses", "einz\u00b7ge", "Wort", ",", "viel\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was sich mit Selbstgef\u00e4lligkeit Bedeutung gibt,", "tokens": ["Was", "sich", "mit", "Selbst\u00b7ge\u00b7f\u00e4l\u00b7lig\u00b7keit", "Be\u00b7deu\u00b7tung", "gibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Amtliches Air, vornehm ablehnende Manier,", "tokens": ["Amt\u00b7li\u00b7ches", "Air", ",", "vor\u00b7nehm", "ab\u00b7leh\u00b7nen\u00b7de", "Ma\u00b7nier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Dies und noch manches andere begreifet es.", "tokens": ["Dies", "und", "noch", "man\u00b7ches", "an\u00b7de\u00b7re", "be\u00b7grei\u00b7fet", "es", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "ADV", "PIS", "PIS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Der Prinzipal vom Comptoir und der Kanzellei", "tokens": ["Der", "Prin\u00b7zi\u00b7pal", "vom", "Comp\u00b7toir", "und", "der", "Kan\u00b7zel\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Empf\u00e4ngt den Assistenten oder Kommis \u2013 denkt,", "tokens": ["Emp\u00b7f\u00e4ngt", "den", "As\u00b7sis\u00b7ten\u00b7ten", "o\u00b7der", "Kom\u00b7mis", "\u2013", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "NE", "$(", "VVFIN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Er kam nach elfe gestern nacht zu Hause erst \u2013", "tokens": ["Er", "kam", "nach", "el\u00b7fe", "ge\u00b7stern", "nacht", "zu", "Hau\u00b7se", "erst", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "APPR", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den andern Tag mit einem langen Sehrgesicht.", "tokens": ["Den", "an\u00b7dern", "Tag", "mit", "ei\u00b7nem", "lan\u00b7gen", "Sehr\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Kammerzofe, die kokette Kellnerin,", "tokens": ["Die", "Kam\u00b7mer\u00b7zo\u00b7fe", ",", "die", "ko\u00b7ket\u00b7te", "Kell\u00b7ne\u00b7rin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Nachdem sie erst den Sch\u00e4ker k\u00fchn gemacht, tut b\u00f6s,", "tokens": ["Nach\u00b7dem", "sie", "erst", "den", "Sch\u00e4\u00b7ker", "k\u00fchn", "ge\u00b7macht", ",", "tut", "b\u00f6s", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ADJD", "VVPP", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da er nun vom geraubten Kusse weitergeht:", "tokens": ["Da", "er", "nun", "vom", "ge\u00b7raub\u00b7ten", "Kus\u00b7se", "wei\u00b7ter\u00b7geht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "\u00bbich mu\u00df recht, recht sehr bitten!\u00ab sagt sie wiederholt", "tokens": ["\u00bb", "ich", "mu\u00df", "recht", ",", "recht", "sehr", "bit\u00b7ten", "!", "\u00ab", "sagt", "sie", "wie\u00b7der\u00b7holt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADJD", "$,", "ADV", "ADV", "VVINF", "$.", "$(", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit seri\u00f6sem Nachdruck zum Verlegenen.", "tokens": ["Mit", "se\u00b7ri\u00b7\u00f6\u00b7sem", "Nach\u00b7druck", "zum", "Ver\u00b7le\u00b7ge\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "---+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Die Tugend selber zeiget sich in Sehrheit gern.", "tokens": ["Die", "Tu\u00b7gend", "sel\u00b7ber", "zei\u00b7get", "sich", "in", "Sehr\u00b7heit", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "O h\u00e4ttest du den jungen Geistlichen gesehn,", "tokens": ["O", "h\u00e4t\u00b7test", "du", "den", "jun\u00b7gen", "Geist\u00b7li\u00b7chen", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dem ich nur neulich an der Kircht\u00fcr hospitiert!", "tokens": ["Dem", "ich", "nur", "neu\u00b7lich", "an", "der", "Kirch\u00b7t\u00fcr", "hos\u00b7pi\u00b7tiert", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie Milch und Blut ein M\u00e4nnchen, durchaus musterhaft;", "tokens": ["Wie", "Milch", "und", "Blut", "ein", "M\u00e4nn\u00b7chen", ",", "durc\u00b7haus", "mus\u00b7ter\u00b7haft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ART", "NN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er wu\u00dft es auch; im wohlgezognen Backenbart,", "tokens": ["Er", "wu\u00dft", "es", "auch", ";", "im", "wohl\u00b7ge\u00b7zog\u00b7nen", "Ba\u00b7cken\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im blonden, war kein H\u00e4rchen, wett ich, ungez\u00e4hlt.", "tokens": ["Im", "blon\u00b7den", ",", "war", "kein", "H\u00e4r\u00b7chen", ",", "wett", "ich", ",", "un\u00b7ge\u00b7z\u00e4hlt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "VAFIN", "PIAT", "NN", "$,", "VVFIN", "PPER", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Predigt roch mir seltsamlich nach Leier und Schwert,", "tokens": ["Die", "Pre\u00b7digt", "roch", "mir", "selt\u00b7sam\u00b7lich", "nach", "Lei\u00b7er", "und", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Er kam nicht weg vom sch\u00f6nen Tod f\u00fcrs Vaterland;", "tokens": ["Er", "kam", "nicht", "weg", "vom", "sch\u00f6\u00b7nen", "Tod", "f\u00fcrs", "Va\u00b7ter\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "APPRART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein paarmal gar riskiert' er liberal zu sein,", "tokens": ["Ein", "paar\u00b7mal", "gar", "ris\u00b7ki\u00b7ert'", "er", "li\u00b7be\u00b7ral", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "H\u00f6chst liberal \u2013 nun, halsgef\u00e4hrlich macht' er's nicht,", "tokens": ["H\u00f6chst", "li\u00b7be\u00b7ral", "\u2013", "nun", ",", "hals\u00b7ge\u00b7f\u00e4hr\u00b7lich", "macht'", "er's", "nicht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "$,", "ADJD", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Doch wurden ihm die Ohren sichtlich warm dabei.", "tokens": ["Doch", "wur\u00b7den", "ihm", "die", "Oh\u00b7ren", "sicht\u00b7lich", "warm", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "PRF", "ADJD", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zuletzt, herabgestiegen von der Kanzel, rauscht", "tokens": ["Zu\u00b7letzt", ",", "her\u00b7ab\u00b7ge\u00b7stie\u00b7gen", "von", "der", "Kan\u00b7zel", ",", "rauscht"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "VVPP", "APPR", "ART", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er strahlend, Kopf und Schultern wiegend, rasch vorbei", "tokens": ["Er", "strah\u00b7lend", ",", "Kopf", "und", "Schul\u00b7tern", "wie\u00b7gend", ",", "rasch", "vor\u00b7bei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADJD", "$,", "NN", "KON", "NN", "VVPP", "$,", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dem duftgen Reihen tief bewegter Jungfr\u00e4ulein.", "tokens": ["Dem", "duft\u00b7gen", "Rei\u00b7hen", "tief", "be\u00b7weg\u00b7ter", "Jung\u00b7fr\u00e4u\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und richtig macht er ihnen ein Sehrkompliment.", "tokens": ["Und", "rich\u00b7tig", "macht", "er", "ih\u00b7nen", "ein", "Sehr\u00b7kom\u00b7pli\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Besonders ist die Gro\u00dfmut ungemein sehrhaft.", "tokens": ["Be\u00b7son\u00b7ders", "ist", "die", "Gro\u00df\u00b7mut", "un\u00b7ge\u00b7mein", "sehr\u00b7haft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn der Student, von edlem Burschentum ergl\u00fcht,", "tokens": ["Denn", "der", "Stu\u00b7dent", ",", "von", "ed\u00b7lem", "Bur\u00b7schen\u00b7tum", "er\u00b7gl\u00fcht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der hochgesinnte Leutnant, schreibet seinem Feind", "tokens": ["Der", "hoch\u00b7ge\u00b7sinn\u00b7te", "Leut\u00b7nant", ",", "schrei\u00b7bet", "sei\u00b7nem", "Feind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(ach ", "tokens": ["(", "ach"], "token_info": ["punct", "word"], "pos": ["$(", "XY"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Nach schon erkl\u00e4rtem Ehrenkampfe, schnell vers\u00f6hnt,", "tokens": ["Nach", "schon", "er\u00b7kl\u00e4r\u00b7tem", "Eh\u00b7ren\u00b7kamp\u00b7fe", ",", "schnell", "ver\u00b7s\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Lakonisch sch\u00f6n ein Sehrbillett \u2013 es r\u00fchrt ihn selbst.", "tokens": ["La\u00b7ko\u00b7nisch", "sch\u00f6n", "ein", "Sehr\u00b7bil\u00b7lett", "\u2013", "es", "r\u00fchrt", "ihn", "selbst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ART", "NN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So ein Herr X, so ein Herr Z, als Rezensent,", "tokens": ["So", "ein", "Herr", "X", ",", "so", "ein", "Herr", "Z", ",", "als", "Re\u00b7zen\u00b7sent", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "XY", "$,", "ADV", "ART", "NN", "NN", "$,", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist gro\u00dfer Sehrmann, Sehr-Sehrmann, just wenn er dir", "tokens": ["Ist", "gro\u00b7\u00dfer", "Sehr\u00b7mann", ",", "Sehr\u00b7Sehr\u00b7mann", ",", "just", "wenn", "er", "dir"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJA", "NN", "$,", "NE", "$,", "ADV", "KOUS", "PPER", "PPER"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Den Lorbeer reicht, beinahe mehr noch als wenn er", "tokens": ["Den", "Lor\u00b7beer", "reicht", ",", "bei\u00b7na\u00b7he", "mehr", "noch", "als", "wenn", "er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "ADV", "ADV", "KOKOM", "KOUS", "PPER"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Sein h\u00f6hnisch Sic! und Sapienti sat! hintrumpft.", "tokens": ["Sein", "h\u00f6h\u00b7nisch", "Sic", "!", "und", "Sa\u00b7pi\u00b7en\u00b7ti", "sat", "!", "hin\u00b7trumpft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NE", "$.", "KON", "NE", "VVFIN", "$.", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Hiern\u00e4chst versteht sich allerdings, da\u00df viele auch", "tokens": ["Hier\u00b7n\u00e4chst", "ver\u00b7steht", "sich", "al\u00b7ler\u00b7dings", ",", "da\u00df", "vie\u00b7le", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "$,", "KOUS", "PIS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nur teilweis und gelegentlich Sehrleute sind.", "tokens": ["Nur", "teil\u00b7weis", "und", "ge\u00b7le\u00b7gent\u00b7lich", "Sehr\u00b7leu\u00b7te", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "NN", "VAFIN", "$."], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So haben wir an manchem herzlich lieben Freund", "tokens": ["So", "ha\u00b7ben", "wir", "an", "man\u00b7chem", "herz\u00b7lich", "lie\u00b7ben", "Freund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein unzweideutig \u00c4derchen der Art bemerkt,", "tokens": ["Ein", "un\u00b7zwei\u00b7deu\u00b7tig", "\u00c4\u00b7der\u00b7chen", "der", "Art", "be\u00b7merkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Und freilich immer eine Faust im Sack gemacht.", "tokens": ["Und", "frei\u00b7lich", "im\u00b7mer", "ei\u00b7ne", "Faust", "im", "Sack", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch wenn es nun vollendet erst erscheint, es sei", "tokens": ["Doch", "wenn", "es", "nun", "voll\u00b7en\u00b7det", "erst", "er\u00b7scheint", ",", "es", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "ADV", "VVFIN", "$,", "PPER", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mann oder Weib, der Menschheit Afterbild \u2013 o wer,", "tokens": ["Mann", "o\u00b7der", "Weib", ",", "der", "Menschheit", "Af\u00b7ter\u00b7bild", "\u2013", "o", "wer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "ART", "NN", "NN", "$(", "FM", "PWS", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Dem sich im Busen ein gesundes Herz bewegt,", "tokens": ["Dem", "sich", "im", "Bu\u00b7sen", "ein", "ge\u00b7sun\u00b7des", "Herz", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ertr\u00e4gt es wohl? wem kr\u00fcmmte sich im Innern nicht", "tokens": ["Er\u00b7tr\u00e4gt", "es", "wohl", "?", "wem", "kr\u00fcmm\u00b7te", "sich", "im", "In\u00b7nern", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "PWS", "VVFIN", "PRF", "APPRART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das Eingeweide? Gift und Operment ist mir's!", "tokens": ["Das", "Ein\u00b7ge\u00b7wei\u00b7de", "?", "Gift", "und", "O\u00b7per\u00b7ment", "ist", "mir's", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "KON", "NN", "VAFIN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Denn w\u00e4ren sie nur l\u00e4cherlich! sie sind zumeist", "tokens": ["Denn", "w\u00e4\u00b7ren", "sie", "nur", "l\u00e4\u00b7cher\u00b7lich", "!", "sie", "sind", "zu\u00b7meist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADJD", "$.", "PPER", "VAFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Verrucht, abscheulich, wenn du sie beim Licht besiehst.", "tokens": ["Ver\u00b7rucht", ",", "ab\u00b7scheu\u00b7lich", ",", "wenn", "du", "sie", "beim", "Licht", "be\u00b7siehst", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "KOUS", "PPER", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Kein Mensch beleidigt wie der Sehrmann und verletzt", "tokens": ["Kein", "Mensch", "be\u00b7lei\u00b7digt", "wie", "der", "Sehr\u00b7mann", "und", "ver\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVPP", "KOKOM", "ART", "NN", "KON", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Empfindlicher; w\u00e4r's auch nur durch die Art wie er", "tokens": ["Emp\u00b7find\u00b7li\u00b7cher", ";", "w\u00e4r's", "auch", "nur", "durch", "die", "Art", "wie", "er"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "KOKOM", "PPER"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Dich im Gespr\u00e4ch am Rockknopf fa\u00dft. Du schn\u00f6de Brut!", "tokens": ["Dich", "im", "Ge\u00b7spr\u00e4ch", "am", "Rock\u00b7knopf", "fa\u00dft", ".", "Du", "schn\u00f6\u00b7de", "Brut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$.", "PPER", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.16": {"text": "Wo einer auftritt, jedes Edle ist sogleich", "tokens": ["Wo", "ei\u00b7ner", "auf\u00b7tritt", ",", "je\u00b7des", "Ed\u00b7le", "ist", "sog\u00b7leich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PIAT", "ADJA", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Gel\u00e4hmt, vernichtet neben ihnen, nichts beh\u00e4lt", "tokens": ["Ge\u00b7l\u00e4hmt", ",", "ver\u00b7nich\u00b7tet", "ne\u00b7ben", "ih\u00b7nen", ",", "nichts", "be\u00b7h\u00e4lt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$,", "VVPP", "APPR", "PPER", "$,", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den eignen, unbedingten Wert. Geht dir einmal", "tokens": ["Den", "eig\u00b7nen", ",", "un\u00b7be\u00b7ding\u00b7ten", "Wert", ".", "Geht", "dir", "ein\u00b7mal"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$.", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der Mund in seiner Gegenwart begeistert auf,", "tokens": ["Der", "Mund", "in", "sei\u00b7ner", "Ge\u00b7gen\u00b7wart", "be\u00b7geis\u00b7tert", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Um was es sei \u2013 der Mann besitzt ein bleiernes,", "tokens": ["Um", "was", "es", "sei", "\u2013", "der", "Mann", "be\u00b7sitzt", "ein", "blei\u00b7er\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PWS", "PPER", "VAFIN", "$(", "ART", "NN", "VVFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.21": {"text": "Grausames Schweigen; v\u00f6llig bringt dich's auf den Hund.", "tokens": ["Grau\u00b7sa\u00b7mes", "Schwei\u00b7gen", ";", "v\u00f6l\u00b7lig", "bringt", "dich's", "auf", "den", "Hund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJD", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.22": {"text": "\u2013 Was hie\u00dfe gottlos, wenn es dies Geschlecht nicht ist?", "tokens": ["\u2013", "Was", "hie\u00b7\u00dfe", "gott\u00b7los", ",", "wenn", "es", "dies", "Ge\u00b7schlecht", "nicht", "ist", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "PDS", "NN", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und nicht im Schlaf auch fiel es ihnen ein, da\u00df sie", "tokens": ["Und", "nicht", "im", "Schlaf", "auch", "fiel", "es", "ih\u00b7nen", "ein", ",", "da\u00df", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PTKNEG", "APPRART", "NN", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Mit Haut und Haar des Teufels sind. Ich scherze nicht.", "tokens": ["Mit", "Haut", "und", "Haar", "des", "Teu\u00b7fels", "sind", ".", "Ich", "scher\u00b7ze", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "NN", "VAFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Durch Bu\u00dfe kommt ein Arger wohl zum Himmelreich:", "tokens": ["Durch", "Bu\u00b7\u00dfe", "kommt", "ein", "Ar\u00b7ger", "wohl", "zum", "Him\u00b7mel\u00b7reich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Doch kann der Sehrmann Bu\u00dfe tun? O nimmermehr!", "tokens": ["Doch", "kann", "der", "Sehr\u00b7mann", "Bu\u00b7\u00dfe", "tun", "?", "O", "nim\u00b7mer\u00b7mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "VVINF", "$.", "NE", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Drum f\u00fcrcht ich, wenn sein abgeschiedner Geist dereinst", "tokens": ["Drum", "f\u00fcrcht", "ich", ",", "wenn", "sein", "ab\u00b7ge\u00b7schied\u00b7ner", "Geist", "de\u00b7reinst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Sich, frech genug, des Paradieses Pforte naht,", "tokens": ["Sich", ",", "frech", "ge\u00b7nug", ",", "des", "Pa\u00b7ra\u00b7die\u00b7ses", "Pfor\u00b7te", "naht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$,", "ADJD", "ADV", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der rosigen, wo, Wache haltend, hellgelockt", "tokens": ["Der", "ro\u00b7si\u00b7gen", ",", "wo", ",", "Wa\u00b7che", "hal\u00b7tend", ",", "hell\u00b7ge\u00b7lockt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "PWAV", "$,", "NN", "VVPP", "$,", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ein Engel lehnet, hingesenkt ein tr\u00e4umend Ohr", "tokens": ["Ein", "En\u00b7gel", "leh\u00b7net", ",", "hin\u00b7ge\u00b7senkt", "ein", "tr\u00e4u\u00b7mend", "Ohr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Den ewgen Melodien, die im Innern sind:", "tokens": ["Den", "ew\u00b7gen", "Me\u00b7lo\u00b7dien", ",", "die", "im", "In\u00b7nern", "sind", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "Aufschaut der W\u00e4chter, misset ruhig die Gestalt", "tokens": ["Auf\u00b7schaut", "der", "W\u00e4ch\u00b7ter", ",", "mis\u00b7set", "ru\u00b7hig", "die", "Ge\u00b7stalt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NE", "$,", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Von Kopf zu Fu\u00df, die fragende, und sch\u00fcttelt jetzt", "tokens": ["Von", "Kopf", "zu", "Fu\u00df", ",", "die", "fra\u00b7gen\u00b7de", ",", "und", "sch\u00fct\u00b7telt", "jetzt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "ART", "ADJA", "$,", "KON", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mit sanftem Ernst, mitleidig fast, das sch\u00f6ne Haupt,", "tokens": ["Mit", "sanf\u00b7tem", "Ernst", ",", "mit\u00b7lei\u00b7dig", "fast", ",", "das", "sch\u00f6\u00b7ne", "Haupt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Links deutend, ungern, mit der Hand, abw\u00e4rts den Pfad.", "tokens": ["Links", "deu\u00b7tend", ",", "un\u00b7gern", ",", "mit", "der", "Hand", ",", "ab\u00b7w\u00e4rts", "den", "Pfad", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "$,", "APPR", "ART", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.36": {"text": "Befremdet, ja beleidigt stellt mein Mann sich an,", "tokens": ["Be\u00b7frem\u00b7det", ",", "ja", "be\u00b7lei\u00b7digt", "stellt", "mein", "Mann", "sich", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ADJD", "VVFIN", "PPOSAT", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Und zaudert noch; doch da er sieht, hier sei es Ernst,", "tokens": ["Und", "zau\u00b7dert", "noch", ";", "doch", "da", "er", "sieht", ",", "hier", "sei", "es", "Ernst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$.", "ADV", "KOUS", "PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Schwenkt er in h\u00f6chster Sehrheit trotziglich, getrost", "tokens": ["Schwenkt", "er", "in", "h\u00f6chs\u00b7ter", "Sehr\u00b7heit", "trot\u00b7zig\u00b7lich", ",", "ge\u00b7trost"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "ADJD", "$,", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Sich ab und schw\u00e4nzelt unges\u00e4umt der H\u00f6lle zu.", "tokens": ["Sich", "ab", "und", "schw\u00e4n\u00b7zelt", "un\u00b7ge\u00b7s\u00e4umt", "der", "H\u00f6l\u00b7le", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKVZ", "KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}