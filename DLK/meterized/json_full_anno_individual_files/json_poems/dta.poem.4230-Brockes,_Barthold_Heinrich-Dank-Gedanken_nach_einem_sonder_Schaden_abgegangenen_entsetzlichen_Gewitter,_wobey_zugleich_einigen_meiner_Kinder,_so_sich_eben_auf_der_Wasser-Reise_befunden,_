{"dta.poem.4230": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Dank-Gedanken  \n nach einem  \n  sonder Schaden  \n abgegangenen entsetzlichen Gewitter,  \n wobey zugleich  \n  einigen meiner Kinder,  \n so  \n sich eben auf der Wasser-Reise befunden,  \n dieselbe Gnade wiederfahren.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Vor allen aber gieb, wenn die Gefahr vorbey,", "tokens": ["Vor", "al\u00b7len", "a\u00b7ber", "gieb", ",", "wenn", "die", "Ge\u00b7fahr", "vor\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "VVIMP", "$,", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df, so f\u00fcr Nutz als Schutz, Dir jeder dankbar sey!", "tokens": ["Da\u00df", ",", "so", "f\u00fcr", "Nutz", "als", "Schutz", ",", "Dir", "je\u00b7der", "dank\u00b7bar", "sey", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "APPR", "NN", "KOUS", "NN", "$,", "PPER", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Den Schlu\u00df von meinem Donner-Liede sang ich, mit", "tokens": ["Den", "Schlu\u00df", "von", "mei\u00b7nem", "Don\u00b7ner\u00b7Lie\u00b7de", "sang", "ich", ",", "mit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "$,", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "einer innern Regung,", "tokens": ["ei\u00b7ner", "in\u00b7nern", "Re\u00b7gung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Zur Zeit, als, durch ein grausam Wetter, die Luft in heftiger", "tokens": ["Zur", "Zeit", ",", "als", ",", "durch", "ein", "grau\u00b7sam", "Wet\u00b7ter", ",", "die", "Luft", "in", "hef\u00b7ti\u00b7ger"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "$,", "APPR", "ART", "ADJD", "NN", "$,", "ART", "NN", "APPR", "ADJA"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Bewegung,", "tokens": ["Be\u00b7we\u00b7gung", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "In einer allgemeinen Gluht, ein zackigt Heer von Strahlen", "tokens": ["In", "ei\u00b7ner", "all\u00b7ge\u00b7mei\u00b7nen", "Gluht", ",", "ein", "za\u00b7ckigt", "Heer", "von", "Strah\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "scho\u00df,", "tokens": ["scho\u00df", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Und, mit Ersch\u00fcttrung aller Herzen, zugleich in Gluht und", "tokens": ["Und", ",", "mit", "Er\u00b7sch\u00fct\u00b7trung", "al\u00b7ler", "Her\u00b7zen", ",", "zu\u00b7gleich", "in", "Gluht", "und"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "APPR", "NN", "PIAT", "NN", "$,", "ADV", "APPR", "NN", "KON"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Fluht zerflo\u00df.", "tokens": ["Fluht", "zer\u00b7flo\u00df", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Es flog nicht, wie es oft geschicht, nur etwan hie und dort", "tokens": ["Es", "flog", "nicht", ",", "wie", "es", "oft", "ge\u00b7schicht", ",", "nur", "et\u00b7wan", "hie", "und", "dort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "ADV", "VVPP", "$,", "ADV", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "ein Strahl;", "tokens": ["ein", "Strahl", ";"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "In allen Himmels-Theilen fuhren die Blitz\u2019 in Schaaren auf", "tokens": ["In", "al\u00b7len", "Him\u00b7mels\u00b7T\u00b7hei\u00b7len", "fuh\u00b7ren", "die", "Blitz'", "in", "Schaa\u00b7ren", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "APPR", "NN", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "einmahl,", "tokens": ["ein\u00b7mahl", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}}, "stanza.3": {"line.1": {"text": "Hier rund, dort zackigt durch einander. Es brach; durch", "tokens": ["Hier", "rund", ",", "dort", "za\u00b7ckigt", "durch", "ein\u00b7an\u00b7der", ".", "Es", "brach", ";", "durch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "VVFIN", "APPR", "PRF", "$.", "PPER", "VVFIN", "$.", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Finsterni\u00df und Schatten,", "tokens": ["Fins\u00b7ter\u00b7ni\u00df", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die alle Farben und Figuren geraubet und verschlungen", "tokens": ["Die", "al\u00b7le", "Far\u00b7ben", "und", "Fi\u00b7gu\u00b7ren", "ge\u00b7rau\u00b7bet", "und", "ver\u00b7schlun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "VVPP", "KON", "VVINF"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "hatten,", "tokens": ["hat\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["VAFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Ein Feuer, recht wie eine Fluht, es ward die sonst so sch\u00f6ne", "tokens": ["Ein", "Feu\u00b7er", ",", "recht", "wie", "ei\u00b7ne", "Fluht", ",", "es", "ward", "die", "sonst", "so", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ADJD", "KOKOM", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "ADV", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Welt,", "tokens": ["Welt", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Durch ein entsetzlich helles Leuchten, uns zwar gezeigt und", "tokens": ["Durch", "ein", "ent\u00b7setz\u00b7lich", "hel\u00b7les", "Leuch\u00b7ten", ",", "uns", "zwar", "ge\u00b7zeigt", "und"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,", "PPER", "ADV", "VVPP", "KON"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "vorgestellt;", "tokens": ["vor\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Allein, bey solchem gr\u00e4\u00dflichen bla\u00df-blauen Feur und Schwe-", "tokens": ["Al\u00b7lein", ",", "bey", "sol\u00b7chem", "gr\u00e4\u00df\u00b7li\u00b7chen", "bla\u00df\u00b7blau\u00b7en", "Feur", "und", "Schwe"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "APPR", "PIAT", "ADJA", "ADJA", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "fel-Licht", "tokens": ["fel\u00b7Licht"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Fiel jeder Vorwurf f\u00fcrchterlich und recht entsetzlich ins", "tokens": ["Fiel", "je\u00b7der", "Vor\u00b7wurf", "f\u00fcrch\u00b7ter\u00b7lich", "und", "recht", "ent\u00b7setz\u00b7lich", "ins"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "KON", "ADJD", "ADJD", "APPRART"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.12": {"text": "Gesicht.", "tokens": ["Ge\u00b7sicht", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.13": {"text": "Man w\u00fcnschte lieber sich und alles in schwarzer Dunkelheit", "tokens": ["Man", "w\u00fcnschte", "lie\u00b7ber", "sich", "und", "al\u00b7les", "in", "schwar\u00b7zer", "Dun\u00b7kel\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "PRF", "KON", "PIS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.14": {"text": "begraben,", "tokens": ["be\u00b7gra\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "In tiefer Finsterni\u00df verhohlen, und selbst verdecket, nichts zu", "tokens": ["In", "tie\u00b7fer", "Fins\u00b7ter\u00b7ni\u00df", "ver\u00b7hoh\u00b7len", ",", "und", "selbst", "ver\u00b7de\u00b7cket", ",", "nichts", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,", "KON", "ADV", "VVFIN", "$,", "PIS", "PTKZU"], "meter": "-+-+-+-+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "sehn;", "tokens": ["sehn", ";"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Als von den sch\u00f6nsten Creaturen den Blick, der recht erschreck-", "tokens": ["Als", "von", "den", "sch\u00f6ns\u00b7ten", "Crea\u00b7tu\u00b7ren", "den", "Blick", ",", "der", "recht", "er\u00b7schreck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$,", "PRELS", "ADV", "TRUNC"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "lich sch\u00f6n,", "tokens": ["lich", "sch\u00f6n", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.19": {"text": "Bey solchem f\u00fcrchterlichen Licht und Schrecken-reichen", "tokens": ["Bey", "sol\u00b7chem", "f\u00fcrch\u00b7ter\u00b7li\u00b7chen", "Licht", "und", "Schre\u00b7cken\u00b7rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Glanz, zu haben.", "tokens": ["Glanz", ",", "zu", "ha\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PTKZU", "VAINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "In diesem Wittern war die Furcht bey uns so un- als", "tokens": ["In", "die\u00b7sem", "Wit\u00b7tern", "war", "die", "Furcht", "bey", "uns", "so", "un", "als"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "NN", "APPR", "PPER", "ADV", "TRUNC", "KOKOM"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "allgemein,", "tokens": ["all\u00b7ge\u00b7mein", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Auch den Beherzten \u00fcbert\u00e4ubten des Donners Knall, der", "tokens": ["Auch", "den", "Be\u00b7herz\u00b7ten", "\u00fc\u00b7bert\u00b7\u00e4ub\u00b7ten", "des", "Don\u00b7ners", "Knall", ",", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "NN", "$,", "PRELS"], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Strahlen Schein,", "tokens": ["Strah\u00b7len", "Schein", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Des ausgest\u00fcrzten Regens Rauschen, der Gluht- und", "tokens": ["Des", "aus\u00b7ge\u00b7st\u00fcrz\u00b7ten", "Re\u00b7gens", "Rau\u00b7schen", ",", "der", "Gluht", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "TRUNC", "KON"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Flammen-schwangre Himmel,", "tokens": ["Flam\u00b7men\u00b7schwan\u00b7gre", "Him\u00b7mel", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Das schmetternde Gebr\u00fcll der Wolken, das zisch- und kra-", "tokens": ["Das", "schmet\u00b7tern\u00b7de", "Ge\u00b7br\u00fcll", "der", "Wol\u00b7ken", ",", "das", "zisch", "und", "kra"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,", "ART", "TRUNC", "KON", "TRUNC"], "meter": "-+---+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "chende Get\u00fcmmel.", "tokens": ["chen\u00b7de", "Ge\u00b7t\u00fcm\u00b7mel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "Doch war das, was ich h\u00f6rt und sah\u2019 und f\u00fcrchtet, es noch", "tokens": ["Doch", "war", "das", ",", "was", "ich", "h\u00f6rt", "und", "sah'", "und", "f\u00fcrch\u00b7tet", ",", "es", "noch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PDS", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "PPER", "ADV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "nicht allein,", "tokens": ["nicht", "al\u00b7lein", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Was mich mit bangem Schrecken f\u00fcllte, und mein Entsetzen", "tokens": ["Was", "mich", "mit", "ban\u00b7gem", "Schre\u00b7cken", "f\u00fcll\u00b7te", ",", "und", "mein", "Ent\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "h\u00e4uft. Ein Paar", "tokens": ["h\u00e4uft", ".", "Ein", "Paar"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Von meinen Kindern, Marian und meine kleinste Tochter,", "tokens": ["Von", "mei\u00b7nen", "Kin\u00b7dern", ",", "Ma\u00b7ri\u00b7an", "und", "mei\u00b7ne", "kleins\u00b7te", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NE", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "war", "tokens": ["war"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Zu Schiff nach Hamburg abgegangen, und, auf dem Wasser,", "tokens": ["Zu", "Schiff", "nach", "Ham\u00b7burg", "ab\u00b7ge\u00b7gan\u00b7gen", ",", "und", ",", "auf", "dem", "Was\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NE", "VVPP", "$,", "KON", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "ungefehr,", "tokens": ["un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Dem Ansehn nach, recht an dem Ort, woselbst der Blitz und", "tokens": ["Dem", "An\u00b7sehn", "nach", ",", "recht", "an", "dem", "Ort", ",", "wo\u00b7selbst", "der", "Blitz", "und"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADJD", "APPR", "ART", "NN", "$,", "PWAV", "ART", "NN", "KON"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Strahlen Heer", "tokens": ["Strah\u00b7len", "Heer"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Am st\u00e4rksten hinzuziehen schien. Hier stellt\u2019 ich mir nun", "tokens": ["Am", "st\u00e4rks\u00b7ten", "hin\u00b7zu\u00b7zie\u00b7hen", "schien", ".", "Hier", "stellt'", "ich", "mir", "nun"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VVIZU", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PPER", "ADV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "ihren Schrecken,", "tokens": ["ih\u00b7ren", "Schre\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "In so entsetzlichem Gewitter, recht lebhaft vor, und die\u00df", "tokens": ["In", "so", "ent\u00b7setz\u00b7li\u00b7chem", "Ge\u00b7wit\u00b7ter", ",", "recht", "leb\u00b7haft", "vor", ",", "und", "die\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,", "ADV", "ADJD", "PTKVZ", "$,", "KON", "PDS"], "meter": "+--+-+-+--+-+-+", "measure": "iambic.septa.invert"}, "line.12": {"text": "vermehrte", "tokens": ["ver\u00b7mehr\u00b7te"], "token_info": ["word"], "pos": ["ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.13": {"text": "In mir die Blitze, die ich sah, des Donners Schl\u00e4ge, die ich", "tokens": ["In", "mir", "die", "Blit\u00b7ze", ",", "die", "ich", "sah", ",", "des", "Don\u00b7ners", "Schl\u00e4\u00b7ge", ",", "die", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "NN", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.14": {"text": "h\u00f6rte.", "tokens": ["h\u00f6r\u00b7te", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.6": {"line.1": {"text": "Wie nun zuletzt, nach GOttes G\u00fcte, was lang\u2019 im Firma-", "tokens": ["Wie", "nun", "zu\u00b7letzt", ",", "nach", "Got\u00b7tes", "G\u00fc\u00b7te", ",", "was", "lang'", "im", "Fir\u00b7ma"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "$,", "APPR", "NN", "NN", "$,", "PRELS", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "ment gebr\u00fcllt,", "tokens": ["ment", "ge\u00b7br\u00fcllt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Zusammt dem Blitzen, aufgeh\u00f6rt, und sich des Wetters Wut", "tokens": ["Zu\u00b7sammt", "dem", "Blit\u00b7zen", ",", "auf\u00b7ge\u00b7h\u00f6rt", ",", "und", "sich", "des", "Wet\u00b7ters", "Wut"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "VVPP", "$,", "KON", "PRF", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "gestillt;", "tokens": ["ge\u00b7stillt", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "War ich des andern Morgens fr\u00fch, nach eben abgewichner", "tokens": ["War", "ich", "des", "an\u00b7dern", "Mor\u00b7gens", "fr\u00fch", ",", "nach", "e\u00b7ben", "ab\u00b7ge\u00b7wich\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADV", "ADJD", "$,", "APPR", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Nacht,", "tokens": ["Nacht", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Den Schlu\u00df von meinem Donner-Liede, nach mein\u2019n und aller", "tokens": ["Den", "Schlu\u00df", "von", "mei\u00b7nem", "Don\u00b7ner\u00b7Lie\u00b7de", ",", "nach", "mein'n", "und", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,", "APPR", "NE", "KON", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Menschen Pflichten,", "tokens": ["Men\u00b7schen", "Pflich\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "In einem Andacht-vollen Dank, mit froher Ehrfurcht, aus-", "tokens": ["In", "ei\u00b7nem", "An\u00b7dacht\u00b7vol\u00b7len", "Dank", ",", "mit", "fro\u00b7her", "Ehr\u00b7furcht", ",", "aus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "zurichten,", "tokens": ["zu\u00b7rich\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Und, des geno\u00dfnen Schutzes wegen, den Sch\u00f6pfer zu erh\u00f6h\u2019n,", "tokens": ["Und", ",", "des", "ge\u00b7no\u00df\u00b7nen", "Schut\u00b7zes", "we\u00b7gen", ",", "den", "Sch\u00f6p\u00b7fer", "zu", "er\u00b7h\u00f6h'n", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "ADJA", "NN", "APPR", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "bedacht;", "tokens": ["be\u00b7dacht", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+", "measure": "iambic.single"}, "line.13": {"text": "Zumahl ich auch von meinen Kindern die gute Nachricht bald", "tokens": ["Zu\u00b7mahl", "ich", "auch", "von", "mei\u00b7nen", "Kin\u00b7dern", "die", "gu\u00b7te", "Nach\u00b7richt", "bald"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "empfing,", "tokens": ["emp\u00b7fing", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Da\u00df sie auch unverletzt geblieben. Allein, bevor ich weiter", "tokens": ["Da\u00df", "sie", "auch", "un\u00b7ver\u00b7letzt", "ge\u00b7blie\u00b7ben", ".", "Al\u00b7lein", ",", "be\u00b7vor", "ich", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVPP", "$.", "ADV", "$,", "KOUS", "PPER", "ADV"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "ging,", "tokens": ["ging", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.17": {"text": "So legt\u2019 ich billig bey mir \u00fcber, worinn ein wahrer Dank", "tokens": ["So", "legt'", "ich", "bil\u00b7lig", "bey", "mir", "\u00fc\u00b7ber", ",", "wo\u00b7rinn", "ein", "wah\u00b7rer", "Dank"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "APPR", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+----+-+", "measure": "unknown.measure.hexa"}, "line.18": {"text": "bestehe,", "tokens": ["be\u00b7ste\u00b7he", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.19": {"text": "Ob er mit vielen Worten besser, als wie mit wenigern,", "tokens": ["Ob", "er", "mit", "vie\u00b7len", "Wor\u00b7ten", "bes\u00b7ser", ",", "als", "wie", "mit", "we\u00b7ni\u00b7gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "ADJD", "$,", "KOUS", "KOKOM", "APPR", "PIS", "$,"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "geschehe?", "tokens": ["ge\u00b7sche\u00b7he", "?"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.7": {"line.1": {"text": "Ich schreibe selber viel vom Danken, und tadle, da\u00df fast", "tokens": ["Ich", "schrei\u00b7be", "sel\u00b7ber", "viel", "vom", "Dan\u00b7ken", ",", "und", "tad\u00b7le", ",", "da\u00df", "fast"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,", "KON", "VVFIN", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "niemand recht,", "tokens": ["nie\u00b7mand", "recht", ","], "token_info": ["word", "word", "punct"], "pos": ["PIS", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Nach seiner Pflicht, vern\u00fcnftig dankt. Wenn man mich", "tokens": ["Nach", "sei\u00b7ner", "Pflicht", ",", "ver\u00b7n\u00fcnf\u00b7tig", "dankt", ".", "Wenn", "man", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADJD", "VVFIN", "$.", "KOUS", "PIS", "PRF"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "selber fragen m\u00f6gt',", "tokens": ["sel\u00b7ber", "fra\u00b7gen", "m\u00f6gt'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wie dankst denn du? wie mu\u00df man danken? so stutz ich, und", "tokens": ["Wie", "dankst", "denn", "du", "?", "wie", "mu\u00df", "man", "dan\u00b7ken", "?", "so", "stutz", "ich", ",", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "VVFIN", "KON", "PPER", "$.", "PWAV", "VMFIN", "PIS", "VVINF", "$.", "ADV", "VVFIN", "PPER", "$,", "KON"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "es f\u00e4llt mir schwehr,", "tokens": ["es", "f\u00e4llt", "mir", "schwehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Dir etwas bessers gleich zu zeigen, als wenn man insgemein", "tokens": ["Dir", "et\u00b7was", "bes\u00b7sers", "gleich", "zu", "zei\u00b7gen", ",", "als", "wenn", "man", "ins\u00b7ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$,", "KOKOM", "KOUS", "PIS", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "daher:", "tokens": ["da\u00b7her", ":"], "token_info": ["word", "punct"], "pos": ["PAV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Ich danke Dir, mein Sch\u00f6pfer! spricht. Die Wort':", "tokens": ["Ich", "dan\u00b7ke", "Dir", ",", "mein", "Sch\u00f6p\u00b7fer", "!", "spricht", ".", "Die", "Wort'", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$.", "VVFIN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ich lobe, r\u00fchm' und preise,", "tokens": ["Ich", "lo\u00b7be", ",", "r\u00fchm'", "und", "prei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Die scheinen, als ob man der Gottheit viel minder Dank, als", "tokens": ["Die", "schei\u00b7nen", ",", "als", "ob", "man", "der", "Got\u00b7theit", "viel", "min\u00b7der", "Dank", ",", "als"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "$,", "KOKOM", "KOUS", "PIS", "ART", "NN", "PIAT", "ADJA", "NN", "$,", "KOUS"], "meter": "-+--+---+-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Ehr', erweise.", "tokens": ["Ehr'", ",", "er\u00b7wei\u00b7se", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Zum Bethen fehlt es nicht an Ausdruck, und Regeln,", "tokens": ["Zum", "Be\u00b7then", "fehlt", "es", "nicht", "an", "Aus\u00b7druck", ",", "und", "Re\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "vieler B\u00fccher Schaar", "tokens": ["vie\u00b7ler", "B\u00fc\u00b7cher", "Schaar"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Reicht uns zum Bethen Formularen, in ungez\u00e4hlter Menge,", "tokens": ["Reicht", "uns", "zum", "Be\u00b7then", "For\u00b7mu\u00b7la\u00b7ren", ",", "in", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "dar;", "tokens": ["dar", ";"], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$."], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Vom Danken trifft man weniger, und zwar noch minder,", "tokens": ["Vom", "Dan\u00b7ken", "trifft", "man", "we\u00b7ni\u00b7ger", ",", "und", "zwar", "noch", "min\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "ADV", "$,", "KON", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "solche an,", "tokens": ["sol\u00b7che", "an", ","], "token_info": ["word", "word", "punct"], "pos": ["PIS", "PTKVZ", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Worinn man, ohn\u2019: ", "tokens": ["Wo\u00b7rinn", "man", ",", "ohn'", ":"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PIS", "$,", "KOUI", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "finden kann.", "tokens": ["fin\u00b7den", "kann", "."], "token_info": ["word", "word", "punct"], "pos": ["VVINF", "VMFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Nachdem ich etwas nachgesonnen, vermeyn\u2019 ich, da\u00df in einer", "tokens": ["Nach\u00b7dem", "ich", "et\u00b7was", "nach\u00b7ge\u00b7son\u00b7nen", ",", "ver\u00b7meyn'", "ich", ",", "da\u00df", "in", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "VVIZU", "$,", "VVFIN", "PPER", "$,", "KOUS", "APPR", "ART"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "Menge", "tokens": ["Men\u00b7ge"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Von W\u00f6rtern, in dem Ueberflu\u00df von Liedern, und in ihrer", "tokens": ["Von", "W\u00f6r\u00b7tern", ",", "in", "dem", "Ue\u00b7berf\u00b7lu\u00df", "von", "Lie\u00b7dern", ",", "und", "in", "ih\u00b7rer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "ART", "NN", "APPR", "NN", "$,", "KON", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.12": {"text": "L\u00e4nge", "tokens": ["L\u00e4n\u00b7ge"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Kein Danken eigentlich bestehe, und da\u00df des Dankens wah-", "tokens": ["Kein", "Dan\u00b7ken", "ei\u00b7gent\u00b7lich", "be\u00b7ste\u00b7he", ",", "und", "da\u00df", "des", "Dan\u00b7kens", "wah"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$,", "KON", "KOUS", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "rer Kern", "tokens": ["rer", "Kern"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Ein Herz von Freuden angef\u00fcllt, ein Herz, das inniglich", "tokens": ["Ein", "Herz", "von", "Freu\u00b7den", "an\u00b7ge\u00b7f\u00fcllt", ",", "ein", "Herz", ",", "das", "in\u00b7nig\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$,", "ART", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "ger\u00fchret", "tokens": ["ge\u00b7r\u00fch\u00b7ret"], "token_info": ["word"], "pos": ["VVPP"], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "Von einer ihm geschenkten Wohlthat, die es auf eine Weise", "tokens": ["Von", "ei\u00b7ner", "ihm", "ge\u00b7schenk\u00b7ten", "Wohlt\u00b7hat", ",", "die", "es", "auf", "ei\u00b7ne", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PPER", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "sp\u00fchret,", "tokens": ["sp\u00fch\u00b7ret", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Da\u00df es zu einer heissen Liebe zum Geber dadurch angef\u00fchret,", "tokens": ["Da\u00df", "es", "zu", "ei\u00b7ner", "heis\u00b7sen", "Lie\u00b7be", "zum", "Ge\u00b7ber", "da\u00b7durch", "an\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN", "APPRART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.20": {"text": "Kurz: eine frohe Seele sey, die man mit Freuden GOtt dem", "tokens": ["Kurz", ":", "ei\u00b7ne", "fro\u00b7he", "See\u00b7le", "sey", ",", "die", "man", "mit", "Freu\u00b7den", "Gott", "dem"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "ART", "ADJA", "NN", "VAFIN", "$,", "PRELS", "PIS", "APPR", "NN", "NN", "ART"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.21": {"text": "Herrn,", "tokens": ["Herrn", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}}, "stanza.9": {"line.1": {"text": "In einem willig-fr\u00f6hlichen und angenehmen Ueberdenken", "tokens": ["In", "ei\u00b7nem", "wil\u00b7lig\u00b7fr\u00f6h\u00b7li\u00b7chen", "und", "an\u00b7ge\u00b7neh\u00b7men", "Ue\u00b7ber\u00b7den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Des Guten, welches er, aus Gnaden, uns hat gew\u00fcrdigt", "tokens": ["Des", "Gu\u00b7ten", ",", "wel\u00b7ches", "er", ",", "aus", "Gna\u00b7den", ",", "uns", "hat", "ge\u00b7w\u00fcr\u00b7digt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "$,", "APPR", "NN", "$,", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "uns zu schenken,", "tokens": ["uns", "zu", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "In einem fr\u00f6hlichen Bewundern der Macht, der Weisheit", "tokens": ["In", "ei\u00b7nem", "fr\u00f6h\u00b7li\u00b7chen", "Be\u00b7wun\u00b7dern", "der", "Macht", ",", "der", "Weis\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "und der Liebe,", "tokens": ["und", "der", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.6": {"text": "In einem sanft- doch eifrigen Verlangen, und im s\u00fcssen", "tokens": ["In", "ei\u00b7nem", "sanft", "doch", "eif\u00b7ri\u00b7gen", "Ver\u00b7lan\u00b7gen", ",", "und", "im", "s\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "TRUNC", "KON", "ADJA", "NN", "$,", "KON", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.7": {"text": "Triebe,", "tokens": ["Trie\u00b7be", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "Wenns m\u00f6glich, in vergn\u00fcgter Ehrfurcht, in GOtt sich selber", "tokens": ["Wenns", "m\u00f6g\u00b7lich", ",", "in", "ver\u00b7gn\u00fcg\u00b7ter", "Ehr\u00b7furcht", ",", "in", "Gott", "sich", "sel\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "NN", "PRF", "ADV"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "zu versenken.", "tokens": ["zu", "ver\u00b7sen\u00b7ken", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.10": {"line.1": {"text": "Die\u00df scheinet mir ein eigentlich- und wesentlicher Dank zu", "tokens": ["Die\u00df", "schei\u00b7net", "mir", "ein", "ei\u00b7gent\u00b7lich", "und", "we\u00b7sent\u00b7li\u00b7cher", "Dank", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "TRUNC", "KON", "ADJA", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "seyn,", "tokens": ["seyn", ","], "token_info": ["word", "punct"], "pos": ["VAINF", "$,"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Nicht eine Menge vieler Worte, weil Worte, nur f\u00fcr uns", "tokens": ["Nicht", "ei\u00b7ne", "Men\u00b7ge", "vie\u00b7ler", "Wor\u00b7te", ",", "weil", "Wor\u00b7te", ",", "nur", "f\u00fcr", "uns"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ART", "NN", "PIAT", "NN", "$,", "KOUS", "NN", "$,", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "allein,", "tokens": ["al\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "F\u00fcr GOtt nicht eigentlich geh\u00f6ren. Es bleibet die\u00df demnach", "tokens": ["F\u00fcr", "Gott", "nicht", "ei\u00b7gent\u00b7lich", "ge\u00b7h\u00f6\u00b7ren", ".", "Es", "blei\u00b7bet", "die\u00df", "dem\u00b7nach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PTKNEG", "ADV", "VVINF", "$.", "PPER", "VVFIN", "PDS", "PAV"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.6": {"text": "dabey,", "tokens": ["da\u00b7bey", ","], "token_info": ["word", "punct"], "pos": ["PAV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Da\u00df Danken ein vergn\u00fcgt Erinnern, von GOtt geno\u00dfner", "tokens": ["Da\u00df", "Dan\u00b7ken", "ein", "ver\u00b7gn\u00fcgt", "E\u00b7rin\u00b7nern", ",", "von", "Gott", "ge\u00b7no\u00df\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "ART", "VVPP", "NN", "$,", "APPR", "NN", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Wohlthat, sey.", "tokens": ["Wohlt\u00b7hat", ",", "sey", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Vergn\u00fcgen ist der wahre Grund, das wesentlichste Theil vom", "tokens": ["Ver\u00b7gn\u00fc\u00b7gen", "ist", "der", "wah\u00b7re", "Grund", ",", "das", "we\u00b7sent\u00b7lichs\u00b7te", "Theil", "vom"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "APPRART"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "Danken.", "tokens": ["Dan\u00b7ken", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Nun kann man das Ged\u00e4chtni\u00df sch\u00e4rfen durch Uebung.", "tokens": ["Nun", "kann", "man", "das", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "sch\u00e4r\u00b7fen", "durch", "Ue\u00b7bung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "La\u00dft uns uns denn \u00fcben,", "tokens": ["La\u00dft", "uns", "uns", "denn", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Durch Ueberdenken alles de\u00df, was wir vom Sch\u00f6pfer auf", "tokens": ["Durch", "Ue\u00b7ber\u00b7den\u00b7ken", "al\u00b7les", "de\u00df", ",", "was", "wir", "vom", "Sch\u00f6p\u00b7fer", "auf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PIS", "ART", "$,", "PRELS", "PPER", "APPRART", "NN", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.14": {"text": "der Erden", "tokens": ["der", "Er\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "F\u00fcr vieles Guts empfangen haben, um froh und dankbar so", "tokens": ["F\u00fcr", "vie\u00b7les", "Guts", "emp\u00b7fan\u00b7gen", "ha\u00b7ben", ",", "um", "froh", "und", "dank\u00b7bar", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "NN", "VVPP", "VAINF", "$,", "KOUI", "ADJD", "KON", "ADJD", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "zu werden.", "tokens": ["zu", "wer\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VAINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "Die\u00df ist zugleich der beste Weg und st\u00e4rkste Trieb, um GOtt zu", "tokens": ["Die\u00df", "ist", "zu\u00b7gleich", "der", "bes\u00b7te", "Weg", "und", "st\u00e4rks\u00b7te", "Trieb", ",", "um", "Gott", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "KON", "ADJA", "NN", "$,", "KOUI", "NN", "PTKZU"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.18": {"text": "lieben.", "tokens": ["lie\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.11": {"line.1": {"text": "Doch fiel mir noch, bey Ueberlegung des Schlusses, der", "tokens": ["Doch", "fiel", "mir", "noch", ",", "bey", "Ue\u00b7ber\u00b7le\u00b7gung", "des", "Schlus\u00b7ses", ",", "der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Gedanke ein:", "tokens": ["Ge\u00b7dan\u00b7ke", "ein", ":"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Da\u00df Worte zwar nicht f\u00fcr die Gottheit, jedoch f\u00fcr uns", "tokens": ["Da\u00df", "Wor\u00b7te", "zwar", "nicht", "f\u00fcr", "die", "Got\u00b7theit", ",", "je\u00b7doch", "f\u00fcr", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "APPR", "ART", "NN", "$,", "ADV", "APPR", "PPER"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "nohtwendig seyn.", "tokens": ["noht\u00b7wen\u00b7dig", "seyn", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Die Seel\u2019 ist zwar der W\u00f6rter Ursprung, doch werden wir in", "tokens": ["Die", "Seel'", "ist", "zwar", "der", "W\u00f6r\u00b7ter", "Ur\u00b7sprung", ",", "doch", "wer\u00b7den", "wir", "in"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$,", "ADV", "VAFIN", "PPER", "APPR"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "uns befinden,", "tokens": ["uns", "be\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Da\u00df, so wie Feuer-reiche Theile einander mehr und mehr", "tokens": ["Da\u00df", ",", "so", "wie", "Feu\u00b7er\u00b7rei\u00b7che", "Thei\u00b7le", "ein\u00b7an\u00b7der", "mehr", "und", "mehr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "ADV", "KOKOM", "ADJA", "NN", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "entz\u00fcnden;", "tokens": ["ent\u00b7z\u00fcn\u00b7den", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "So auch die Worte Trieb\u2019 und Andacht in uns verl\u00e4ngern", "tokens": ["So", "auch", "die", "Wor\u00b7te", "Trieb'", "und", "An\u00b7dacht", "in", "uns", "ver\u00b7l\u00e4n\u00b7gern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "KON", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "und vermehren,", "tokens": ["und", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Und diese wiederum die Worte, so da\u00df wir zwar nicht recht", "tokens": ["Und", "die\u00b7se", "wie\u00b7de\u00b7rum", "die", "Wor\u00b7te", ",", "so", "da\u00df", "wir", "zwar", "nicht", "recht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "ADV", "ART", "NN", "$,", "ADV", "KOUS", "PPER", "ADV", "PTKNEG", "ADJD"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "begreifen,", "tokens": ["be\u00b7grei\u00b7fen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Wie doch in uns Gedanken Worte, und Worte die Gedanken", "tokens": ["Wie", "doch", "in", "uns", "Ge\u00b7dan\u00b7ken", "Wor\u00b7te", ",", "und", "Wor\u00b7te", "die", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "PPER", "NN", "NN", "$,", "KON", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "h\u00e4ufen;", "tokens": ["h\u00e4u\u00b7fen", ";"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Doch finden wir aus der Erfahrung, da\u00df beyde bey einander", "tokens": ["Doch", "fin\u00b7den", "wir", "aus", "der", "Er\u00b7fah\u00b7rung", ",", "da\u00df", "bey\u00b7de", "bey", "ein\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KOUS", "PIS", "APPR", "PRF"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.12": {"text": "h\u00f6ren.", "tokens": ["h\u00f6\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Ein \u00fcberzeugendes Exempel von dieser Wechsel-Handel-", "tokens": ["Ein", "\u00fc\u00b7berz\u00b7eu\u00b7gen\u00b7des", "Ex\u00b7em\u00b7pel", "von", "die\u00b7ser", "Wech\u00b7sel\u00b7Han\u00b7del"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PDAT", "TRUNC"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.14": {"text": "schaft,", "tokens": ["schaft", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-", "measure": "single.down"}, "line.15": {"text": "Und von der, durch den Band von beyden, noch mehr ver-", "tokens": ["Und", "von", "der", ",", "durch", "den", "Band", "von", "bey\u00b7den", ",", "noch", "mehr", "ver"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "$,", "APPR", "ART", "NN", "APPR", "PIAT", "$,", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.16": {"text": "mehrten Seelen-Kraft,", "tokens": ["mehr\u00b7ten", "See\u00b7len\u00b7Kraft", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.17": {"text": "Hat mir ein Geist- und Lehr-reich Buch, voll Lust und An-", "tokens": ["Hat", "mir", "ein", "Geist", "und", "Lehr\u00b7reich", "Buch", ",", "voll", "Lust", "und", "An"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "TRUNC", "KON", "NN", "NN", "$,", "ADJD", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "dacht, Geist und Leben,", "tokens": ["dacht", ",", "Geist", "und", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Durch lauter wohlgef\u00fcgte W\u00f6rter, und s\u00fcsse Reimen,", "tokens": ["Durch", "lau\u00b7ter", "wohl\u00b7ge\u00b7f\u00fcg\u00b7te", "W\u00f6r\u00b7ter", ",", "und", "s\u00fcs\u00b7se", "Rei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "abgegeben.", "tokens": ["ab\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.13": {"line.1": {"text": "Bey dieser Schrecken- reichen, bangen, gef\u00e4hrlichen Gele-", "tokens": ["Bey", "die\u00b7ser", "Schre\u00b7cken", "rei\u00b7chen", ",", "ban\u00b7gen", ",", "ge\u00b7f\u00e4hr\u00b7li\u00b7chen", "Ge\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "TRUNC", "VVINF", "$,", "VVFIN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "genheit", "tokens": ["ge\u00b7nheit"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Las\u2019 ich von Dir, ber\u00fchmter ", "tokens": ["Las'", "ich", "von", "Dir", ",", "be\u00b7r\u00fchm\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVIMP", "PPER", "APPR", "PPER", "$,", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Deinen Dank,", "tokens": ["Dei\u00b7nen", "Dank", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Und den, f\u00fcr den geno\u00dfnen Schutz, von Dir verfertigten", "tokens": ["Und", "den", ",", "f\u00fcr", "den", "ge\u00b7no\u00df\u00b7nen", "Schutz", ",", "von", "Dir", "ver\u00b7fer\u00b7tig\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "$,", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "Gesang,", "tokens": ["Ge\u00b7sang", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Voll Geist, voll Nachdruck, Andacht, Ehrfurcht und br\u00fcnsti-", "tokens": ["Voll", "Geist", ",", "voll", "Nach\u00b7druck", ",", "An\u00b7dacht", ",", "Ehr\u00b7furcht", "und", "br\u00fcns\u00b7ti"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "NN", "$,", "ADJD", "NN", "$,", "NN", "$,", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "ger Erkenntlichkeit.", "tokens": ["ger", "Er\u00b7kennt\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "--+-+", "measure": "anapaest.init"}, "line.9": {"text": "Ich ward, so wie durch Deine Lieder gemeiniglich, dadurch", "tokens": ["Ich", "ward", ",", "so", "wie", "durch", "Dei\u00b7ne", "Lie\u00b7der", "ge\u00b7mei\u00b7nig\u00b7lich", ",", "da\u00b7durch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "$,", "ADV", "KOKOM", "APPR", "PPOSAT", "NN", "ADJD", "$,", "PAV"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "ger\u00fchrt,", "tokens": ["ge\u00b7r\u00fchrt", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Und, solchem r\u00fchmlichen Exempel zu folgen, kr\u00e4ftig ange-", "tokens": ["Und", ",", "sol\u00b7chem", "r\u00fchm\u00b7li\u00b7chen", "Ex\u00b7em\u00b7pel", "zu", "fol\u00b7gen", ",", "kr\u00e4f\u00b7tig", "an\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "PIAT", "ADJA", "NN", "PTKZU", "VVINF", "$,", "ADJD", "TRUNC"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "f\u00fchrt.", "tokens": ["f\u00fchrt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}}}}}