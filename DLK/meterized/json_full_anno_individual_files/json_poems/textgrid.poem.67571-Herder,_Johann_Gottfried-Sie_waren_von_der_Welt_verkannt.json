{"textgrid.poem.67571": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Sie waren von der Welt verkannt", "genre": "verse", "period": "N.A.", "pub_year": 1770, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bber ruft Elias!\u00ab O Freund, o Freund, da stehn", "tokens": ["\u00bb", "er", "ruft", "E\u00b7lias", "!", "\u00ab", "O", "Freund", ",", "o", "Freund", ",", "da", "stehn"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "NE", "$.", "$(", "NE", "NN", "$,", "FM", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie ums Kreuz in dunkler H\u00fclle! verstehen's nicht!", "tokens": ["Sie", "ums", "Kreuz", "in", "dunk\u00b7ler", "H\u00fcl\u00b7le", "!", "ver\u00b7ste\u00b7hen's", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$.", "NE", "PTKNEG", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Horchen in dunkler H\u00fcll' und spotten", "tokens": ["Hor\u00b7chen", "in", "dunk\u00b7ler", "H\u00fcll'", "und", "spot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ADJA", "NN", "KON", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "In ihrem Dunkel: \u00bbEr ruft Elias!\u00ab", "tokens": ["In", "ih\u00b7rem", "Dun\u00b7kel", ":", "\u00bb", "Er", "ruft", "E\u00b7lias", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "PPER", "VVFIN", "NE", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "O Freund, o Freund! sie verstehn uns nicht", "tokens": ["O", "Freund", ",", "o", "Freund", "!", "sie", "ver\u00b7stehn", "uns", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "FM", "NN", "$.", "PPER", "VVFIN", "PPER", "PTKNEG"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In ihrer H\u00fclle! da stehn sie, horchen", "tokens": ["In", "ih\u00b7rer", "H\u00fcl\u00b7le", "!", "da", "stehn", "sie", ",", "hor\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "$,", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und schreien, als ob wir, Thoren, Elias hofften,", "tokens": ["Und", "schrei\u00b7en", ",", "als", "ob", "wir", ",", "Tho\u00b7ren", ",", "E\u00b7lias", "hoff\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOKOM", "KOUS", "PPER", "$,", "NN", "$,", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und Gott hab' uns verlassen!", "tokens": ["Und", "Gott", "hab'", "uns", "ver\u00b7las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Er hat uns nicht verlassen! verkannt,", "tokens": ["Er", "hat", "uns", "nicht", "ver\u00b7las\u00b7sen", "!", "ver\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$.", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In Spott verstorben, am Kreuz verstorben!", "tokens": ["In", "Spott", "ver\u00b7stor\u00b7ben", ",", "am", "Kreuz", "ver\u00b7stor\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und k\u00e4m' auch keine bessere Nachwelt,", "tokens": ["Und", "k\u00e4m'", "auch", "kei\u00b7ne", "bes\u00b7se\u00b7re", "Nach\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er versteht uns.", "tokens": ["Er", "ver\u00b7steht", "uns", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Und s\u00e4h's auch bessere Nachwelt nie!", "tokens": ["Und", "s\u00e4h's", "auch", "bes\u00b7se\u00b7re", "Nach\u00b7welt", "nie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er ist's, der uns mit Preis der Engel kr\u00f6nt,", "tokens": ["Er", "ist's", ",", "der", "uns", "mit", "Preis", "der", "En\u00b7gel", "kr\u00f6nt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df wir am Tage der Noth Gebet und Flehn", "tokens": ["Da\u00df", "wir", "am", "Ta\u00b7ge", "der", "Noth", "Ge\u00b7bet", "und", "Flehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und stark Geschrei und Thr\u00e4ne geopfert.", "tokens": ["Und", "stark", "Ge\u00b7schrei", "und", "Thr\u00e4\u00b7ne", "ge\u00b7o\u00b7pfert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Er wei\u00df, es war nicht Menschenangst,", "tokens": ["Er", "wei\u00df", ",", "es", "war", "nicht", "Men\u00b7schen\u00b7angst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Tod des Leibes! der arme Tod!", "tokens": ["Nicht", "Tod", "des", "Lei\u00b7bes", "!", "der", "ar\u00b7me", "Tod", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ART", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da wir vorm Schicksalskelche zagten,", "tokens": ["Da", "wir", "vorm", "Schick\u00b7sals\u00b7kel\u00b7che", "zag\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Uns einsam f\u00fchlten in der Welt,", "tokens": ["Uns", "ein\u00b7sam", "f\u00fchl\u00b7ten", "in", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und Menschenruhe st\u00f6rten, war nicht Menschenha\u00df.", "tokens": ["Und", "Men\u00b7schen\u00b7ru\u00b7he", "st\u00f6r\u00b7ten", ",", "war", "nicht", "Men\u00b7schen\u00b7ha\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da wir sie schwach Gesch\u00f6pf erkannten! 's war", "tokens": ["Da", "wir", "sie", "schwach", "Ge\u00b7sch\u00f6pf", "er\u00b7kann\u00b7ten", "!", "'s", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "NN", "VVINF", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Menschliche, freundliche Thr\u00e4ne,", "tokens": ["Menschli\u00b7che", ",", "freund\u00b7li\u00b7che", "Thr\u00e4\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Da wir aus Tr\u00e4umen, ach! einsam kamen", "tokens": ["Da", "wir", "aus", "Tr\u00e4u\u00b7men", ",", "ach", "!", "ein\u00b7sam", "ka\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "ITJ", "$.", "ADJD", "VVFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Und suchten und fanden Menschen und weinten;", "tokens": ["Und", "such\u00b7ten", "und", "fan\u00b7den", "Men\u00b7schen", "und", "wein\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie verstanden uns nicht! das hohe Graun der Nacht", "tokens": ["Sie", "ver\u00b7stan\u00b7den", "uns", "nicht", "!", "das", "ho\u00b7he", "Graun", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "ART", "ADJA", "NN", "ART", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Mit ihren Sch\u00f6pfungs-Mitternachtsgedanken,", "tokens": ["Mit", "ih\u00b7ren", "Sch\u00f6p\u00b7fungs\u00b7Mit\u00b7ter\u00b7nachts\u00b7ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie verstanden's nicht und wandten sich:", "tokens": ["Sie", "ver\u00b7stan\u00b7den's", "nicht", "und", "wand\u00b7ten", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "KON", "VVFIN", "PRF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "\u00bbmitternacht ist zur Ruhe geschaffen!\u00ab und schliefen neu!", "tokens": ["\u00bb", "mit\u00b7ter\u00b7nacht", "ist", "zur", "Ru\u00b7he", "ge\u00b7schaf\u00b7fen", "!", "\u00ab", "und", "schlie\u00b7fen", "neu", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "APPRART", "NN", "VVPP", "$.", "$(", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+--+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Wir gingen einsam f\u00fcrder; es kam", "tokens": ["Wir", "gin\u00b7gen", "ein\u00b7sam", "f\u00fcr\u00b7der", ";", "es", "kam"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$.", "PPER", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ein Tr\u00f6stungs-, kam ein Labungsengel,", "tokens": ["Ein", "Tr\u00f6s\u00b7tungs", ",", "kam", "ein", "La\u00b7bung\u00b7sen\u00b7gel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unserer Seele geschaffenes Bild kam,", "tokens": ["Un\u00b7se\u00b7rer", "See\u00b7le", "ge\u00b7schaf\u00b7fe\u00b7nes", "Bild", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.9": {"line.1": {"text": "Und wollte tr\u00f6sten! Freundverlassene! Weltverkannt!", "tokens": ["Und", "woll\u00b7te", "tr\u00f6s\u00b7ten", "!", "Freund\u00b7ver\u00b7las\u00b7se\u00b7ne", "!", "Welt\u00b7ver\u00b7kannt", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da kam der falsche Freundesku\u00df mit Heer", "tokens": ["Da", "kam", "der", "fal\u00b7sche", "Freun\u00b7des\u00b7ku\u00df", "mit", "Heer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und Fackel und Spie\u00df und Unschuldsfessel! das tr\u00f6stete!", "tokens": ["Und", "Fa\u00b7ckel", "und", "Spie\u00df", "und", "Un\u00b7schulds\u00b7fes\u00b7sel", "!", "das", "tr\u00f6s\u00b7te\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "$.", "PDS", "VVFIN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Unschuldsfessel und falscher Freundeku\u00df", "tokens": ["Die", "Un\u00b7schulds\u00b7fes\u00b7sel", "und", "fal\u00b7scher", "Freun\u00b7de\u00b7ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Den Welt- und Freundverlassenen! ward Labung ihm,", "tokens": ["Den", "Welt", "und", "Freund\u00b7ver\u00b7las\u00b7se\u00b7nen", "!", "ward", "La\u00b7bung", "ihm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$.", "VAFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Galle ward ihm Labung! \u00bbIch bin's!\u00ab Ihm ward", "tokens": ["Die", "Gal\u00b7le", "ward", "ihm", "La\u00b7bung", "!", "\u00bb", "Ich", "bin's", "!", "\u00ab", "Ihm", "ward"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "NN", "$.", "$(", "PPER", "VAFIN", "$.", "$(", "PPER", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Fessel Triumphkranz! \u00bbSucht Ihr mich? nichts mehr?\u00ab", "tokens": ["Die", "Fes\u00b7sel", "Tri\u00b7umph\u00b7kranz", "!", "\u00bb", "Sucht", "Ihr", "mich", "?", "nichts", "mehr", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$.", "$(", "VVFIN", "PPER", "PRF", "$.", "PIS", "ADV", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und f\u00fchrten den prangenden K\u00f6nig,", "tokens": ["Und", "f\u00fchr\u00b7ten", "den", "pran\u00b7gen\u00b7den", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.11": {"line.1": {"text": "Voll hohen Unschuldsgef\u00fchls. \u00bbIhr greift mich in der Nacht.", "tokens": ["Voll", "ho\u00b7hen", "Un\u00b7schulds\u00b7ge\u00b7f\u00fchls", ".", "\u00bb", "Ihr", "greift", "mich", "in", "der", "Nacht", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$.", "$(", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich hab' am Tage gelehrt, Ihr griffet mich nicht!", "tokens": ["Ich", "hab'", "am", "Ta\u00b7ge", "ge\u00b7lehrt", ",", "Ihr", "grif\u00b7fet", "mich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich bin's, und dies ist Eure Stunde,", "tokens": ["Ich", "bin's", ",", "und", "dies", "ist", "Eu\u00b7re", "Stun\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KON", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Dunkeln!\u00ab", "tokens": ["Im", "Dun\u00b7keln", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.12": {"line.1": {"text": "Und f\u00fchrten den Siegprangenden:", "tokens": ["Und", "f\u00fchr\u00b7ten", "den", "Sieg\u00b7pran\u00b7gen\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--++--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u00bbich bin ein K\u00f6nig!\u00ab und gei\u00dfelten, spotteten sein:", "tokens": ["\u00bb", "ich", "bin", "ein", "K\u00f6\u00b7nig", "!", "\u00ab", "und", "gei\u00b7\u00dfel\u00b7ten", ",", "spot\u00b7te\u00b7ten", "sein", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$.", "$(", "KON", "ADJA", "$,", "VVFIN", "VAINF", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.3": {"text": "\u00bbseht, welch ein Mensch!\u00ab in Dornenkrone", "tokens": ["\u00bb", "seht", ",", "welch", "ein", "Mensch", "!", "\u00ab", "in", "Dor\u00b7nen\u00b7kro\u00b7ne"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "VVFIN", "$,", "PWAT", "ART", "NN", "$.", "$(", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit der Miene der Thronesunschuld.", "tokens": ["Mit", "der", "Mie\u00b7ne", "der", "Thro\u00b7ne\u00b7sun\u00b7schuld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.13": {"line.1": {"text": "\u00bbin den Wolken komm' ich!\u00ab \u00bbEr l\u00e4stert Gott!\u00ab", "tokens": ["\u00bb", "in", "den", "Wol\u00b7ken", "komm'", "ich", "!", "\u00ab", "\u00bb", "Er", "l\u00e4s\u00b7tert", "Gott", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ART", "NN", "VVFIN", "PPER", "$.", "$(", "$(", "PPER", "VVFIN", "NN", "$.", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zerrissen die Kleider, huben ihn empor aufs Kreuz!", "tokens": ["Zer\u00b7ris\u00b7sen", "die", "Klei\u00b7der", ",", "hu\u00b7ben", "ihn", "em\u00b7por", "aufs", "Kreuz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbheut soll mein Paradies Dir sein!\u00ab", "tokens": ["\u00bb", "heut", "soll", "mein", "Pa\u00b7ra\u00b7dies", "Dir", "sein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPOSAT", "NN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gaben ihm Galle! er trank der Labung", "tokens": ["Und", "ga\u00b7ben", "ihm", "Gal\u00b7le", "!", "er", "trank", "der", "La\u00b7bung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "NN", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "Triumphstrank. \u00bb's ist, ist vollbracht!\u00ab", "tokens": ["Tri\u00b7umph\u00b7strank", ".", "\u00bb", "'s", "ist", ",", "ist", "voll\u00b7bracht", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VAFIN", "$,", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und starb verkannt! \u2013 War nicht verkannt!", "tokens": ["Und", "starb", "ver\u00b7kannt", "!", "\u2013", "War", "nicht", "ver\u00b7kannt", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$.", "$(", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Thr\u00e4n' und Blut, am Berge zu Staub geweint,", "tokens": ["Die", "Thr\u00e4n'", "und", "Blut", ",", "am", "Ber\u00b7ge", "zu", "Staub", "ge\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "APPRART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ward Perl' der Krone! ", "tokens": ["Ward", "Perl'", "der", "Kro\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Er lebt, und alle Welten beseliget", "tokens": ["Er", "lebt", ",", "und", "al\u00b7le", "Wel\u00b7ten", "be\u00b7se\u00b7li\u00b7get"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Nam', \u00fcberwindet die H\u00f6lle, giebt sanften Tod!", "tokens": ["Sein", "Nam'", ",", "\u00fc\u00b7berw\u00b7in\u00b7det", "die", "H\u00f6l\u00b7le", ",", "giebt", "sanf\u00b7ten", "Tod", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$,", "VVFIN", "ADJA", "NN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.3": {"text": "Von der Welt verkannt, wir sehn ihn einst", "tokens": ["Von", "der", "Welt", "ver\u00b7kannt", ",", "wir", "sehn", "ihn", "einst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "PPER", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "In Wolken wiederkommen!", "tokens": ["In", "Wol\u00b7ken", "wie\u00b7der\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Verkennt, die ihn verkannten! erkennt,", "tokens": ["Ver\u00b7kennt", ",", "die", "ihn", "ver\u00b7kann\u00b7ten", "!", "er\u00b7kennt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$.", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die ihn noch wiederfinden! O Freund, wie er,", "tokens": ["Die", "ihn", "noch", "wie\u00b7der\u00b7fin\u00b7den", "!", "O", "Freund", ",", "wie", "er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "$.", "NE", "NN", "$,", "PWAV", "PPER", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Rufe Dein ", "tokens": ["Ru\u00b7fe", "Dein"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Das Geschrei der Dunkeln in \u00f6der H\u00fclle!", "tokens": ["Das", "Ge\u00b7schrei", "der", "Dun\u00b7keln", "in", "\u00f6\u00b7der", "H\u00fcl\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bber ruft Elias!\u00ab O Freund, o Freund, da stehn", "tokens": ["\u00bb", "er", "ruft", "E\u00b7lias", "!", "\u00ab", "O", "Freund", ",", "o", "Freund", ",", "da", "stehn"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "NE", "$.", "$(", "NE", "NN", "$,", "FM", "NN", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie ums Kreuz in dunkler H\u00fclle! verstehen's nicht!", "tokens": ["Sie", "ums", "Kreuz", "in", "dunk\u00b7ler", "H\u00fcl\u00b7le", "!", "ver\u00b7ste\u00b7hen's", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$.", "NE", "PTKNEG", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Horchen in dunkler H\u00fcll' und spotten", "tokens": ["Hor\u00b7chen", "in", "dunk\u00b7ler", "H\u00fcll'", "und", "spot\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "ADJA", "NN", "KON", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "In ihrem Dunkel: \u00bbEr ruft Elias!\u00ab", "tokens": ["In", "ih\u00b7rem", "Dun\u00b7kel", ":", "\u00bb", "Er", "ruft", "E\u00b7lias", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "PPER", "VVFIN", "NE", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "O Freund, o Freund! sie verstehn uns nicht", "tokens": ["O", "Freund", ",", "o", "Freund", "!", "sie", "ver\u00b7stehn", "uns", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "FM", "NN", "$.", "PPER", "VVFIN", "PPER", "PTKNEG"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In ihrer H\u00fclle! da stehn sie, horchen", "tokens": ["In", "ih\u00b7rer", "H\u00fcl\u00b7le", "!", "da", "stehn", "sie", ",", "hor\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "$,", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und schreien, als ob wir, Thoren, Elias hofften,", "tokens": ["Und", "schrei\u00b7en", ",", "als", "ob", "wir", ",", "Tho\u00b7ren", ",", "E\u00b7lias", "hoff\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOKOM", "KOUS", "PPER", "$,", "NN", "$,", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und Gott hab' uns verlassen!", "tokens": ["Und", "Gott", "hab'", "uns", "ver\u00b7las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Er hat uns nicht verlassen! verkannt,", "tokens": ["Er", "hat", "uns", "nicht", "ver\u00b7las\u00b7sen", "!", "ver\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$.", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In Spott verstorben, am Kreuz verstorben!", "tokens": ["In", "Spott", "ver\u00b7stor\u00b7ben", ",", "am", "Kreuz", "ver\u00b7stor\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und k\u00e4m' auch keine bessere Nachwelt,", "tokens": ["Und", "k\u00e4m'", "auch", "kei\u00b7ne", "bes\u00b7se\u00b7re", "Nach\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Er versteht uns.", "tokens": ["Er", "ver\u00b7steht", "uns", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.20": {"line.1": {"text": "Und s\u00e4h's auch bessere Nachwelt nie!", "tokens": ["Und", "s\u00e4h's", "auch", "bes\u00b7se\u00b7re", "Nach\u00b7welt", "nie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er ist's, der uns mit Preis der Engel kr\u00f6nt,", "tokens": ["Er", "ist's", ",", "der", "uns", "mit", "Preis", "der", "En\u00b7gel", "kr\u00f6nt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df wir am Tage der Noth Gebet und Flehn", "tokens": ["Da\u00df", "wir", "am", "Ta\u00b7ge", "der", "Noth", "Ge\u00b7bet", "und", "Flehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und stark Geschrei und Thr\u00e4ne geopfert.", "tokens": ["Und", "stark", "Ge\u00b7schrei", "und", "Thr\u00e4\u00b7ne", "ge\u00b7o\u00b7pfert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Er wei\u00df, es war nicht Menschenangst,", "tokens": ["Er", "wei\u00df", ",", "es", "war", "nicht", "Men\u00b7schen\u00b7angst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Tod des Leibes! der arme Tod!", "tokens": ["Nicht", "Tod", "des", "Lei\u00b7bes", "!", "der", "ar\u00b7me", "Tod", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ART", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da wir vorm Schicksalskelche zagten,", "tokens": ["Da", "wir", "vorm", "Schick\u00b7sals\u00b7kel\u00b7che", "zag\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Uns einsam f\u00fchlten in der Welt,", "tokens": ["Uns", "ein\u00b7sam", "f\u00fchl\u00b7ten", "in", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und Menschenruhe st\u00f6rten, war nicht Menschenha\u00df.", "tokens": ["Und", "Men\u00b7schen\u00b7ru\u00b7he", "st\u00f6r\u00b7ten", ",", "war", "nicht", "Men\u00b7schen\u00b7ha\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da wir sie schwach Gesch\u00f6pf erkannten! 's war", "tokens": ["Da", "wir", "sie", "schwach", "Ge\u00b7sch\u00f6pf", "er\u00b7kann\u00b7ten", "!", "'s", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "NN", "VVINF", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Menschliche, freundliche Thr\u00e4ne,", "tokens": ["Menschli\u00b7che", ",", "freund\u00b7li\u00b7che", "Thr\u00e4\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Da wir aus Tr\u00e4umen, ach! einsam kamen", "tokens": ["Da", "wir", "aus", "Tr\u00e4u\u00b7men", ",", "ach", "!", "ein\u00b7sam", "ka\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "ITJ", "$.", "ADJD", "VVFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "Und suchten und fanden Menschen und weinten;", "tokens": ["Und", "such\u00b7ten", "und", "fan\u00b7den", "Men\u00b7schen", "und", "wein\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie verstanden uns nicht! das hohe Graun der Nacht", "tokens": ["Sie", "ver\u00b7stan\u00b7den", "uns", "nicht", "!", "das", "ho\u00b7he", "Graun", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "ART", "ADJA", "NN", "ART", "NN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Mit ihren Sch\u00f6pfungs-Mitternachtsgedanken,", "tokens": ["Mit", "ih\u00b7ren", "Sch\u00f6p\u00b7fungs\u00b7Mit\u00b7ter\u00b7nachts\u00b7ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie verstanden's nicht und wandten sich:", "tokens": ["Sie", "ver\u00b7stan\u00b7den's", "nicht", "und", "wand\u00b7ten", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "KON", "VVFIN", "PRF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.24": {"line.1": {"text": "\u00bbmitternacht ist zur Ruhe geschaffen!\u00ab und schliefen neu!", "tokens": ["\u00bb", "mit\u00b7ter\u00b7nacht", "ist", "zur", "Ru\u00b7he", "ge\u00b7schaf\u00b7fen", "!", "\u00ab", "und", "schlie\u00b7fen", "neu", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "APPRART", "NN", "VVPP", "$.", "$(", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+--+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Wir gingen einsam f\u00fcrder; es kam", "tokens": ["Wir", "gin\u00b7gen", "ein\u00b7sam", "f\u00fcr\u00b7der", ";", "es", "kam"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$.", "PPER", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Ein Tr\u00f6stungs-, kam ein Labungsengel,", "tokens": ["Ein", "Tr\u00f6s\u00b7tungs", ",", "kam", "ein", "La\u00b7bung\u00b7sen\u00b7gel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unserer Seele geschaffenes Bild kam,", "tokens": ["Un\u00b7se\u00b7rer", "See\u00b7le", "ge\u00b7schaf\u00b7fe\u00b7nes", "Bild", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.25": {"line.1": {"text": "Und wollte tr\u00f6sten! Freundverlassene! Weltverkannt!", "tokens": ["Und", "woll\u00b7te", "tr\u00f6s\u00b7ten", "!", "Freund\u00b7ver\u00b7las\u00b7se\u00b7ne", "!", "Welt\u00b7ver\u00b7kannt", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da kam der falsche Freundesku\u00df mit Heer", "tokens": ["Da", "kam", "der", "fal\u00b7sche", "Freun\u00b7des\u00b7ku\u00df", "mit", "Heer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und Fackel und Spie\u00df und Unschuldsfessel! das tr\u00f6stete!", "tokens": ["Und", "Fa\u00b7ckel", "und", "Spie\u00df", "und", "Un\u00b7schulds\u00b7fes\u00b7sel", "!", "das", "tr\u00f6s\u00b7te\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "$.", "PDS", "VVFIN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Unschuldsfessel und falscher Freundeku\u00df", "tokens": ["Die", "Un\u00b7schulds\u00b7fes\u00b7sel", "und", "fal\u00b7scher", "Freun\u00b7de\u00b7ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.26": {"line.1": {"text": "Den Welt- und Freundverlassenen! ward Labung ihm,", "tokens": ["Den", "Welt", "und", "Freund\u00b7ver\u00b7las\u00b7se\u00b7nen", "!", "ward", "La\u00b7bung", "ihm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$.", "VAFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Galle ward ihm Labung! \u00bbIch bin's!\u00ab Ihm ward", "tokens": ["Die", "Gal\u00b7le", "ward", "ihm", "La\u00b7bung", "!", "\u00bb", "Ich", "bin's", "!", "\u00ab", "Ihm", "ward"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "NN", "$.", "$(", "PPER", "VAFIN", "$.", "$(", "PPER", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Fessel Triumphkranz! \u00bbSucht Ihr mich? nichts mehr?\u00ab", "tokens": ["Die", "Fes\u00b7sel", "Tri\u00b7umph\u00b7kranz", "!", "\u00bb", "Sucht", "Ihr", "mich", "?", "nichts", "mehr", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$.", "$(", "VVFIN", "PPER", "PRF", "$.", "PIS", "ADV", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und f\u00fchrten den prangenden K\u00f6nig,", "tokens": ["Und", "f\u00fchr\u00b7ten", "den", "pran\u00b7gen\u00b7den", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.27": {"line.1": {"text": "Voll hohen Unschuldsgef\u00fchls. \u00bbIhr greift mich in der Nacht.", "tokens": ["Voll", "ho\u00b7hen", "Un\u00b7schulds\u00b7ge\u00b7f\u00fchls", ".", "\u00bb", "Ihr", "greift", "mich", "in", "der", "Nacht", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$.", "$(", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich hab' am Tage gelehrt, Ihr griffet mich nicht!", "tokens": ["Ich", "hab'", "am", "Ta\u00b7ge", "ge\u00b7lehrt", ",", "Ihr", "grif\u00b7fet", "mich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ich bin's, und dies ist Eure Stunde,", "tokens": ["Ich", "bin's", ",", "und", "dies", "ist", "Eu\u00b7re", "Stun\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KON", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Dunkeln!\u00ab", "tokens": ["Im", "Dun\u00b7keln", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "$.", "$("], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.28": {"line.1": {"text": "Und f\u00fchrten den Siegprangenden:", "tokens": ["Und", "f\u00fchr\u00b7ten", "den", "Sieg\u00b7pran\u00b7gen\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--++--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u00bbich bin ein K\u00f6nig!\u00ab und gei\u00dfelten, spotteten sein:", "tokens": ["\u00bb", "ich", "bin", "ein", "K\u00f6\u00b7nig", "!", "\u00ab", "und", "gei\u00b7\u00dfel\u00b7ten", ",", "spot\u00b7te\u00b7ten", "sein", ":"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$.", "$(", "KON", "ADJA", "$,", "VVFIN", "VAINF", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.3": {"text": "\u00bbseht, welch ein Mensch!\u00ab in Dornenkrone", "tokens": ["\u00bb", "seht", ",", "welch", "ein", "Mensch", "!", "\u00ab", "in", "Dor\u00b7nen\u00b7kro\u00b7ne"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "VVFIN", "$,", "PWAT", "ART", "NN", "$.", "$(", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit der Miene der Thronesunschuld.", "tokens": ["Mit", "der", "Mie\u00b7ne", "der", "Thro\u00b7ne\u00b7sun\u00b7schuld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.29": {"line.1": {"text": "\u00bbin den Wolken komm' ich!\u00ab \u00bbEr l\u00e4stert Gott!\u00ab", "tokens": ["\u00bb", "in", "den", "Wol\u00b7ken", "komm'", "ich", "!", "\u00ab", "\u00bb", "Er", "l\u00e4s\u00b7tert", "Gott", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ART", "NN", "VVFIN", "PPER", "$.", "$(", "$(", "PPER", "VVFIN", "NN", "$.", "$("], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zerrissen die Kleider, huben ihn empor aufs Kreuz!", "tokens": ["Zer\u00b7ris\u00b7sen", "die", "Klei\u00b7der", ",", "hu\u00b7ben", "ihn", "em\u00b7por", "aufs", "Kreuz", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "PPER", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbheut soll mein Paradies Dir sein!\u00ab", "tokens": ["\u00bb", "heut", "soll", "mein", "Pa\u00b7ra\u00b7dies", "Dir", "sein", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPOSAT", "NN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gaben ihm Galle! er trank der Labung", "tokens": ["Und", "ga\u00b7ben", "ihm", "Gal\u00b7le", "!", "er", "trank", "der", "La\u00b7bung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "NN", "$.", "PPER", "VVFIN", "ART", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.30": {"line.1": {"text": "Triumphstrank. \u00bb's ist, ist vollbracht!\u00ab", "tokens": ["Tri\u00b7umph\u00b7strank", ".", "\u00bb", "'s", "ist", ",", "ist", "voll\u00b7bracht", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VAFIN", "$,", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und starb verkannt! \u2013 War nicht verkannt!", "tokens": ["Und", "starb", "ver\u00b7kannt", "!", "\u2013", "War", "nicht", "ver\u00b7kannt", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$.", "$(", "VAFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Thr\u00e4n' und Blut, am Berge zu Staub geweint,", "tokens": ["Die", "Thr\u00e4n'", "und", "Blut", ",", "am", "Ber\u00b7ge", "zu", "Staub", "ge\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "APPRART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ward Perl' der Krone! ", "tokens": ["Ward", "Perl'", "der", "Kro\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.31": {"line.1": {"text": "Er lebt, und alle Welten beseliget", "tokens": ["Er", "lebt", ",", "und", "al\u00b7le", "Wel\u00b7ten", "be\u00b7se\u00b7li\u00b7get"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sein Nam', \u00fcberwindet die H\u00f6lle, giebt sanften Tod!", "tokens": ["Sein", "Nam'", ",", "\u00fc\u00b7berw\u00b7in\u00b7det", "die", "H\u00f6l\u00b7le", ",", "giebt", "sanf\u00b7ten", "Tod", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$,", "VVFIN", "ADJA", "NN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.3": {"text": "Von der Welt verkannt, wir sehn ihn einst", "tokens": ["Von", "der", "Welt", "ver\u00b7kannt", ",", "wir", "sehn", "ihn", "einst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "PPER", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "In Wolken wiederkommen!", "tokens": ["In", "Wol\u00b7ken", "wie\u00b7der\u00b7kom\u00b7men", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Verkennt, die ihn verkannten! erkennt,", "tokens": ["Ver\u00b7kennt", ",", "die", "ihn", "ver\u00b7kann\u00b7ten", "!", "er\u00b7kennt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$.", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die ihn noch wiederfinden! O Freund, wie er,", "tokens": ["Die", "ihn", "noch", "wie\u00b7der\u00b7fin\u00b7den", "!", "O", "Freund", ",", "wie", "er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "$.", "NE", "NN", "$,", "PWAV", "PPER", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Rufe Dein ", "tokens": ["Ru\u00b7fe", "Dein"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Das Geschrei der Dunkeln in \u00f6der H\u00fclle!", "tokens": ["Das", "Ge\u00b7schrei", "der", "Dun\u00b7keln", "in", "\u00f6\u00b7der", "H\u00fcl\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}