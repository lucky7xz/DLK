{"textgrid.poem.33802": {"metadata": {"author": {"name": "Lingg, Hermann von", "birth": "N.A.", "death": "N.A."}, "title": "Das Grab der Aturen", "genre": "verse", "period": "N.A.", "pub_year": 1862, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbwenn dieser wei\u00dfe Strom einst seine Fluten", "tokens": ["\u00bb", "wenn", "die\u00b7ser", "wei\u00b7\u00dfe", "Strom", "einst", "sei\u00b7ne", "Flu\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PDAT", "ADJA", "NN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Einm\u00fcnden wird in diesen blauen See,", "tokens": ["Ein\u00b7m\u00fcn\u00b7den", "wird", "in", "die\u00b7sen", "blau\u00b7en", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann wird das Herz der alten Krieger bluten,", "tokens": ["Dann", "wird", "das", "Herz", "der", "al\u00b7ten", "Krie\u00b7ger", "blu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und eurer S\u00f6hne Bart wird sein wie Schnee.", "tokens": ["Und", "eu\u00b7rer", "S\u00f6h\u00b7ne", "Bart", "wird", "sein", "wie", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAFIN", "VAINF", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Schlaff wird die Sehne sein an eurem Bogen", "tokens": ["Schlaff", "wird", "die", "Seh\u00b7ne", "sein", "an", "eu\u00b7rem", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN", "PPOSAT", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wirkungslos entfliegen euer Pfeil.", "tokens": ["Und", "wir\u00b7kungs\u00b7los", "ent\u00b7flie\u00b7gen", "eu\u00b7er", "Pfeil", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann wird mein Antlitz sein von Schmerz umzogen,", "tokens": ["Dann", "wird", "mein", "Ant\u00b7litz", "sein", "von", "Schmerz", "um\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPOSAT", "APPR", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und an den Fremdling kommt der Ahnenteil.\u00ab", "tokens": ["Und", "an", "den", "Fremd\u00b7ling", "kommt", "der", "Ah\u00b7nen\u00b7teil", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "So sprach zu unsern V\u00e4tern einst die Schlange", "tokens": ["So", "sprach", "zu", "un\u00b7sern", "V\u00e4\u00b7tern", "einst", "die", "Schlan\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des wei\u00dfen Lichts; erf\u00fcllt ist nun ihr Wort.", "tokens": ["Des", "wei\u00b7\u00dfen", "Lichts", ";", "er\u00b7f\u00fcllt", "ist", "nun", "ihr", "Wort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVPP", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von Hof und Flur, vom Licht und vom Gesange", "tokens": ["Von", "Hof", "und", "Flur", ",", "vom", "Licht", "und", "vom", "Ge\u00b7san\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NN", "$,", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Heimathains treibt uns der Sieger fort.", "tokens": ["Des", "Hei\u00b7mat\u00b7hains", "treibt", "uns", "der", "Sie\u00b7ger", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Doch hat der Gott ein Grabmal uns bereitet;", "tokens": ["Doch", "hat", "der", "Gott", "ein", "Grab\u00b7mal", "uns", "be\u00b7rei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umsp\u00fclt von Wassern, vom Gebirg umzackt,", "tokens": ["Um\u00b7sp\u00fclt", "von", "Was\u00b7sern", ",", "vom", "Ge\u00b7birg", "um\u00b7zackt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Liegt eine H\u00f6hle, grufttief ausgeweitet,", "tokens": ["Liegt", "ei\u00b7ne", "H\u00f6h\u00b7le", ",", "gruft\u00b7tief", "aus\u00b7ge\u00b7wei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Um ihren Eingang braust der Katarakt.", "tokens": ["Um", "ih\u00b7ren", "Ein\u00b7gang", "braust", "der", "Ka\u00b7ta\u00b7rakt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Dorthin hie\u00df er uns letzte S\u00f6hne ziehen,", "tokens": ["Dor\u00b7thin", "hie\u00df", "er", "uns", "letz\u00b7te", "S\u00f6h\u00b7ne", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Des Stammes \u00dcberrest, der Tugend wert,", "tokens": ["Des", "Stam\u00b7mes", "\u00dc\u00b7ber\u00b7rest", ",", "der", "Tu\u00b7gend", "wert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die unsrer Ahnen war, denn wir entfliehen", "tokens": ["Die", "uns\u00b7rer", "Ah\u00b7nen", "war", ",", "denn", "wir", "ent\u00b7flie\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "KON", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit \u00fcberwundnem, nicht beflecktem Schwert.", "tokens": ["Mit", "\u00fc\u00b7berw\u00b7und\u00b7nem", ",", "nicht", "be\u00b7fleck\u00b7tem", "Schwert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Auf eure H\u00e4upter nehmt die Aschenkr\u00fcge,", "tokens": ["Auf", "eu\u00b7re", "H\u00e4up\u00b7ter", "nehmt", "die", "A\u00b7schen\u00b7kr\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Staub, der unsrer V\u00e4ter Staub umschlie\u00dft;", "tokens": ["Den", "Staub", ",", "der", "uns\u00b7rer", "V\u00e4\u00b7ter", "Staub", "um\u00b7schlie\u00dft", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch nehmt von Frucht und \u00d6l, so viel gen\u00fcge", "tokens": ["Auch", "nehmt", "von", "Frucht", "und", "\u00d6l", ",", "so", "viel", "ge\u00b7n\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN", "$,", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zum Opfermahl, das ihr zuletzt genie\u00dft.", "tokens": ["Zum", "Op\u00b7fer\u00b7mahl", ",", "das", "ihr", "zu\u00b7letzt", "ge\u00b7nie\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Dann la\u00dft uns ruhn auf Steinen um die Flamme", "tokens": ["Dann", "la\u00dft", "uns", "ruhn", "auf", "Stei\u00b7nen", "um", "die", "Flam\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Sterbehaus, das unsrer Leichen harrt,", "tokens": ["Im", "Ster\u00b7be\u00b7haus", ",", "das", "uns\u00b7rer", "Lei\u00b7chen", "harrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Stumm, bis dem Letzten vom Aturenstamme", "tokens": ["Stumm", ",", "bis", "dem", "Letz\u00b7ten", "vom", "A\u00b7tu\u00b7ren\u00b7stam\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der letzte Pulsschlag in der Brust erstarrt.", "tokens": ["Der", "letz\u00b7te", "Puls\u00b7schlag", "in", "der", "Brust", "er\u00b7starrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "\u00bbwenn dieser wei\u00dfe Strom einst seine Fluten", "tokens": ["\u00bb", "wenn", "die\u00b7ser", "wei\u00b7\u00dfe", "Strom", "einst", "sei\u00b7ne", "Flu\u00b7ten"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PDAT", "ADJA", "NN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Einm\u00fcnden wird in diesen blauen See,", "tokens": ["Ein\u00b7m\u00fcn\u00b7den", "wird", "in", "die\u00b7sen", "blau\u00b7en", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann wird das Herz der alten Krieger bluten,", "tokens": ["Dann", "wird", "das", "Herz", "der", "al\u00b7ten", "Krie\u00b7ger", "blu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und eurer S\u00f6hne Bart wird sein wie Schnee.", "tokens": ["Und", "eu\u00b7rer", "S\u00f6h\u00b7ne", "Bart", "wird", "sein", "wie", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VAFIN", "VAINF", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Schlaff wird die Sehne sein an eurem Bogen", "tokens": ["Schlaff", "wird", "die", "Seh\u00b7ne", "sein", "an", "eu\u00b7rem", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN", "PPOSAT", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wirkungslos entfliegen euer Pfeil.", "tokens": ["Und", "wir\u00b7kungs\u00b7los", "ent\u00b7flie\u00b7gen", "eu\u00b7er", "Pfeil", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann wird mein Antlitz sein von Schmerz umzogen,", "tokens": ["Dann", "wird", "mein", "Ant\u00b7litz", "sein", "von", "Schmerz", "um\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPOSAT", "APPR", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und an den Fremdling kommt der Ahnenteil.\u00ab", "tokens": ["Und", "an", "den", "Fremd\u00b7ling", "kommt", "der", "Ah\u00b7nen\u00b7teil", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "So sprach zu unsern V\u00e4tern einst die Schlange", "tokens": ["So", "sprach", "zu", "un\u00b7sern", "V\u00e4\u00b7tern", "einst", "die", "Schlan\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des wei\u00dfen Lichts; erf\u00fcllt ist nun ihr Wort.", "tokens": ["Des", "wei\u00b7\u00dfen", "Lichts", ";", "er\u00b7f\u00fcllt", "ist", "nun", "ihr", "Wort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVPP", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von Hof und Flur, vom Licht und vom Gesange", "tokens": ["Von", "Hof", "und", "Flur", ",", "vom", "Licht", "und", "vom", "Ge\u00b7san\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NN", "$,", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Des Heimathains treibt uns der Sieger fort.", "tokens": ["Des", "Hei\u00b7mat\u00b7hains", "treibt", "uns", "der", "Sie\u00b7ger", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Doch hat der Gott ein Grabmal uns bereitet;", "tokens": ["Doch", "hat", "der", "Gott", "ein", "Grab\u00b7mal", "uns", "be\u00b7rei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umsp\u00fclt von Wassern, vom Gebirg umzackt,", "tokens": ["Um\u00b7sp\u00fclt", "von", "Was\u00b7sern", ",", "vom", "Ge\u00b7birg", "um\u00b7zackt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Liegt eine H\u00f6hle, grufttief ausgeweitet,", "tokens": ["Liegt", "ei\u00b7ne", "H\u00f6h\u00b7le", ",", "gruft\u00b7tief", "aus\u00b7ge\u00b7wei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Um ihren Eingang braust der Katarakt.", "tokens": ["Um", "ih\u00b7ren", "Ein\u00b7gang", "braust", "der", "Ka\u00b7ta\u00b7rakt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Dorthin hie\u00df er uns letzte S\u00f6hne ziehen,", "tokens": ["Dor\u00b7thin", "hie\u00df", "er", "uns", "letz\u00b7te", "S\u00f6h\u00b7ne", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Des Stammes \u00dcberrest, der Tugend wert,", "tokens": ["Des", "Stam\u00b7mes", "\u00dc\u00b7ber\u00b7rest", ",", "der", "Tu\u00b7gend", "wert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die unsrer Ahnen war, denn wir entfliehen", "tokens": ["Die", "uns\u00b7rer", "Ah\u00b7nen", "war", ",", "denn", "wir", "ent\u00b7flie\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "KON", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit \u00fcberwundnem, nicht beflecktem Schwert.", "tokens": ["Mit", "\u00fc\u00b7berw\u00b7und\u00b7nem", ",", "nicht", "be\u00b7fleck\u00b7tem", "Schwert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Auf eure H\u00e4upter nehmt die Aschenkr\u00fcge,", "tokens": ["Auf", "eu\u00b7re", "H\u00e4up\u00b7ter", "nehmt", "die", "A\u00b7schen\u00b7kr\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Staub, der unsrer V\u00e4ter Staub umschlie\u00dft;", "tokens": ["Den", "Staub", ",", "der", "uns\u00b7rer", "V\u00e4\u00b7ter", "Staub", "um\u00b7schlie\u00dft", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Auch nehmt von Frucht und \u00d6l, so viel gen\u00fcge", "tokens": ["Auch", "nehmt", "von", "Frucht", "und", "\u00d6l", ",", "so", "viel", "ge\u00b7n\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN", "$,", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zum Opfermahl, das ihr zuletzt genie\u00dft.", "tokens": ["Zum", "Op\u00b7fer\u00b7mahl", ",", "das", "ihr", "zu\u00b7letzt", "ge\u00b7nie\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Dann la\u00dft uns ruhn auf Steinen um die Flamme", "tokens": ["Dann", "la\u00dft", "uns", "ruhn", "auf", "Stei\u00b7nen", "um", "die", "Flam\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Sterbehaus, das unsrer Leichen harrt,", "tokens": ["Im", "Ster\u00b7be\u00b7haus", ",", "das", "uns\u00b7rer", "Lei\u00b7chen", "harrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Stumm, bis dem Letzten vom Aturenstamme", "tokens": ["Stumm", ",", "bis", "dem", "Letz\u00b7ten", "vom", "A\u00b7tu\u00b7ren\u00b7stam\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der letzte Pulsschlag in der Brust erstarrt.", "tokens": ["Der", "letz\u00b7te", "Puls\u00b7schlag", "in", "der", "Brust", "er\u00b7starrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}