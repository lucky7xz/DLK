{"textgrid.poem.40891": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "Der F\u00fcrstenbund", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zwei Bundesheere lagern bei Terouanne im Feld,", "tokens": ["Zwei", "Bun\u00b7des\u00b7hee\u00b7re", "la\u00b7gern", "bei", "Te\u00b7rou\u00b7an\u00b7ne", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "NE", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dorthin hat ihre Zelte Franzosenha\u00df gestellt;", "tokens": ["Dor\u00b7thin", "hat", "ih\u00b7re", "Zel\u00b7te", "Fran\u00b7zo\u00b7sen\u00b7ha\u00df", "ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ha, wie da Englands Banner die L\u00fcfte z\u00fcngelnd leckt,", "tokens": ["Ha", ",", "wie", "da", "En\u00b7glands", "Ban\u00b7ner", "die", "L\u00fcf\u00b7te", "z\u00fcn\u00b7gelnd", "leckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "ADV", "NE", "NN", "ART", "NN", "VVPP", "VVFIN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und Deutschlands Doppeladler die m\u00e4cht'gen Fl\u00fcgel streckt!", "tokens": ["Und", "Deutschlands", "Dop\u00b7pe\u00b7lad\u00b7ler", "die", "m\u00e4cht'\u00b7gen", "Fl\u00fc\u00b7gel", "streckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.2": {"line.1": {"text": "Der Rhein trennt Deutsch' und Franken. Ei, Deutscher, welch Wunderpferd", "tokens": ["Der", "Rhein", "trennt", "Deut\u00b7sch'", "und", "Fran\u00b7ken", ".", "Ei", ",", "Deut\u00b7scher", ",", "welch", "Wun\u00b7der\u00b7pferd"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NE", "VVFIN", "NE", "KON", "NN", "$.", "NN", "$,", "NN", "$,", "PWAT", "NN"], "meter": "-+-+--+-++--+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Trug k\u00fchnen Sprungs hin\u00fcber dich und dein Racheschwert?", "tokens": ["Trug", "k\u00fch\u00b7nen", "Sprungs", "hin\u00b7\u00fc\u00b7ber", "dich", "und", "dein", "Ra\u00b7ch\u00b7e\u00b7schwert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADV", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Ha\u00df war der k\u00fchne Springer, das schwarze Fl\u00fcgelro\u00df!", "tokens": ["Ha\u00df", "war", "der", "k\u00fch\u00b7ne", "Sprin\u00b7ger", ",", "das", "schwar\u00b7ze", "Fl\u00fc\u00b7gel\u00b7ro\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und weiter fliegt nur Liebe, die Taube mit gr\u00fcnem Spro\u00df.", "tokens": ["Und", "wei\u00b7ter", "fliegt", "nur", "Lie\u00b7be", ",", "die", "Tau\u00b7be", "mit", "gr\u00fc\u00b7nem", "Spro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Ein Meer trennt Franken und Britten. Wer hat die Br\u00fccke gespannt,", "tokens": ["Ein", "Meer", "trennt", "Fran\u00b7ken", "und", "Brit\u00b7ten", ".", "Wer", "hat", "die", "Br\u00fc\u00b7cke", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Drauf Englands eh'rne Heere hinziehn ins Franzenland?", "tokens": ["Drauf", "En\u00b7glands", "eh'r\u00b7ne", "Hee\u00b7re", "hin\u00b7ziehn", "ins", "Fran\u00b7zen\u00b7land", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "ADJA", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ha\u00df nennt sich der Br\u00fcckenmeister, der b\u00e4ndigt Strom und Belt,", "tokens": ["Ha\u00df", "nennt", "sich", "der", "Br\u00fc\u00b7cken\u00b7meis\u00b7ter", ",", "der", "b\u00e4n\u00b7digt", "Strom", "und", "Belt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ART", "NN", "$,", "PRELS", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und Gr\u00f6\u00df'res baut nur Liebe, seht ihren Dom, die Welt!", "tokens": ["Und", "Gr\u00f6\u00df'\u00b7res", "baut", "nur", "Lie\u00b7be", ",", "seht", "ih\u00b7ren", "Dom", ",", "die", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}}, "stanza.4": {"line.1": {"text": "Vor's Lager hinaus lustwandelt der V\u00f6lker F\u00fcrstenpaar,", "tokens": ["Vor's", "La\u00b7ger", "hin\u00b7aus", "lust\u00b7wan\u00b7delt", "der", "V\u00f6l\u00b7ker", "F\u00fcrs\u00b7ten\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heinrich, der junge Britte, und Max, schon grau von Haar;", "tokens": ["Hein\u00b7rich", ",", "der", "jun\u00b7ge", "Brit\u00b7te", ",", "und", "Max", ",", "schon", "grau", "von", "Haar", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,", "KON", "NE", "$,", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Vor ihren Blicken dehnt sich, wie 'n See, so weit und glatt,", "tokens": ["Vor", "ih\u00b7ren", "Bli\u00b7cken", "dehnt", "sich", ",", "wie", "'n", "See", ",", "so", "weit", "und", "glatt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF", "$,", "PWAV", "ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Die Ebne von Terouanne fernhin bis Guinegat'.", "tokens": ["Die", "Eb\u00b7ne", "von", "Te\u00b7rou\u00b7an\u00b7ne", "fern\u00b7hin", "bis", "Gu\u00b7i\u00b7ne\u00b7gat'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ADV", "APPR", "NE", "$."], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.5": {"line.1": {"text": "Talbot schritt neben Heinrich, als h\u00e4tt' am Himmelszelt", "tokens": ["Tal\u00b7bot", "schritt", "ne\u00b7ben", "Hein\u00b7rich", ",", "als", "h\u00e4tt'", "am", "Him\u00b7mels\u00b7zelt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NE", "$,", "KOKOM", "VAFIN", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Sich Mars, das blut'ge Sternbild, zum hehren Mond gesellt;", "tokens": ["Sich", "Mars", ",", "das", "blut'\u00b7ge", "Stern\u00b7bild", ",", "zum", "heh\u00b7ren", "Mond", "ge\u00b7sellt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "$,", "ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kunz von der Rosen wallte zur Seite seinem Herrn,", "tokens": ["Kunz", "von", "der", "Ro\u00b7sen", "wall\u00b7te", "zur", "Sei\u00b7te", "sei\u00b7nem", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Wie mit dem Sonnengotte der heitre Morgenstern.", "tokens": ["Wie", "mit", "dem", "Son\u00b7nen\u00b7got\u00b7te", "der", "heit\u00b7re", "Mor\u00b7gens\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+--+--", "measure": "iambic.penta.invert"}}, "stanza.6": {"line.1": {"text": "Max blickte ringsum sinnend; da ward sein Herz so weich:", "tokens": ["Max", "blick\u00b7te", "ring\u00b7sum", "sin\u00b7nend", ";", "da", "ward", "sein", "Herz", "so", "weich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "VVPP", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbwie ist im Leben Alles so alt und neu zugleich!", "tokens": ["\u00bb", "wie", "ist", "im", "Le\u00b7ben", "Al\u00b7les", "so", "alt", "und", "neu", "zu\u00b7gleich", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "VAFIN", "APPRART", "NN", "PIS", "ADV", "ADJD", "KON", "ADJD", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hier k\u00e4mpft' ich vor drei\u00dfig Jahren, \u2013 es war mein erster Sieg!", "tokens": ["Hier", "k\u00e4mpft'", "ich", "vor", "drei\u00b7\u00dfig", "Jah\u00b7ren", ",", "\u2013", "es", "war", "mein", "ers\u00b7ter", "Sieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "CARD", "NN", "$,", "$(", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Hier f\u00fchr' ich morgen die Schaaren, \u2013 wohl wird's mein letzter Sieg!", "tokens": ["Hier", "f\u00fchr'", "ich", "mor\u00b7gen", "die", "Schaa\u00b7ren", ",", "\u2013", "wohl", "wird's", "mein", "letz\u00b7ter", "Sieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "$(", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Seht dort der Veste Bollwerk, die Warten, Thurm und Thor", "tokens": ["Seht", "dort", "der", "Ves\u00b7te", "Boll\u00b7werk", ",", "die", "War\u00b7ten", ",", "Thurm", "und", "Thor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und hier die weiten Fluren, noch ist die\u00df Alles wie vor;", "tokens": ["Und", "hier", "die", "wei\u00b7ten", "Flu\u00b7ren", ",", "noch", "ist", "die\u00df", "Al\u00b7les", "wie", "vor", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "PDS", "PIS", "KOKOM", "APPR", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Luft und Erden Antlitz ist noch wie's damals war,", "tokens": ["Der", "Luft", "und", "Er\u00b7den", "Ant\u00b7litz", "ist", "noch", "wie's", "da\u00b7mals", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "NN", "VAFIN", "ADV", "VVFIN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nur gr\u00f6\u00dfer ward der Kirchhof, und bleicher ward mein Haar.", "tokens": ["Nur", "gr\u00f6\u00b7\u00dfer", "ward", "der", "Kirch\u00b7hof", ",", "und", "blei\u00b7cher", "ward", "mein", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "$,", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Und doch, wie anders Alles! Manch neu Geschlecht entstand,", "tokens": ["Und", "doch", ",", "wie", "an\u00b7ders", "Al\u00b7les", "!", "Manch", "neu", "Ge\u00b7schlecht", "ent\u00b7stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "ADV", "PIS", "$.", "PIAT", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Herbst hat oft gem\u00e4het, der Lenz bes\u00e4t das Land,", "tokens": ["Der", "Herbst", "hat", "oft", "ge\u00b7m\u00e4\u00b7het", ",", "der", "Lenz", "be\u00b7s\u00e4t", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Luft hat gest\u00fcrmt und ges\u00e4uselt, die Sonn' erlosch und schien,", "tokens": ["Die", "Luft", "hat", "ge\u00b7st\u00fcrmt", "und", "ge\u00b7s\u00e4u\u00b7selt", ",", "die", "Sonn'", "er\u00b7losch", "und", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "KON", "VVPP", "$,", "ART", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "Der alte Ha\u00df nur schreitet noch durchs Gefilde hin!\u00ab", "tokens": ["Der", "al\u00b7te", "Ha\u00df", "nur", "schrei\u00b7tet", "noch", "durchs", "Ge\u00b7fil\u00b7de", "hin", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Da fiel ins Wort ihm Heinrich: \u00bbVergi\u00df die Liebe nicht!", "tokens": ["Da", "fiel", "ins", "Wort", "ihm", "Hein\u00b7rich", ":", "\u00bb", "Ver\u00b7gi\u00df", "die", "Lie\u00b7be", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PPER", "NE", "$.", "$(", "VVIMP", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie ist's, die unsre Arme zu festem Bunde flicht;", "tokens": ["Sie", "ist's", ",", "die", "uns\u00b7re", "Ar\u00b7me", "zu", "fes\u00b7tem", "Bun\u00b7de", "flicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O lasse fort ihn dauern in ferne ew'ge Zeit!\u00ab", "tokens": ["O", "las\u00b7se", "fort", "ihn", "dau\u00b7ern", "in", "fer\u00b7ne", "ew'\u00b7ge", "Zeit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "PPER", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da dr\u00fcckte Max ans Herz ihn: \u00bbJa, Bruder, in Ewigkeit!\u00ab", "tokens": ["Da", "dr\u00fcck\u00b7te", "Max", "ans", "Herz", "ihn", ":", "\u00bb", "Ja", ",", "Bru\u00b7der", ",", "in", "E\u00b7wig\u00b7keit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPRART", "NN", "PPER", "$.", "$(", "PTKANT", "$,", "NN", "$,", "APPR", "NN", "$.", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "In feierlichem Schweigen stand jetzt das F\u00fcrstenpaar,", "tokens": ["In", "fei\u00b7er\u00b7li\u00b7chem", "Schwei\u00b7gen", "stand", "jetzt", "das", "F\u00fcrs\u00b7ten\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es schwieg der ew'ge Aether, so tief und blau und klar,", "tokens": ["Es", "schwieg", "der", "ew'\u00b7ge", "A\u00b7e\u00b7ther", ",", "so", "tief", "und", "blau", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Es schwiegen rings die Fluren, so eben und so weit,", "tokens": ["Es", "schwie\u00b7gen", "rings", "die", "Flu\u00b7ren", ",", "so", "e\u00b7ben", "und", "so", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "ADV", "ADV", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gleichwie ein stummes Echo des Wortes: Ewigkeit!", "tokens": ["Gleich\u00b7wie", "ein", "stum\u00b7mes", "E\u00b7cho", "des", "Wor\u00b7tes", ":", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Denkt euch in den Dom, wo leise des Hochamts Orgel verhallt", "tokens": ["Denkt", "euch", "in", "den", "Dom", ",", "wo", "lei\u00b7se", "des", "Hoc\u00b7hamts", "Or\u00b7gel", "ver\u00b7hallt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "ADJD", "ART", "NN", "NN", "VVPP"], "meter": "+---+-+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und feierlich beim Sanctus wie Fr\u00fchlingss\u00e4useln wallt.", "tokens": ["Und", "fei\u00b7er\u00b7lich", "beim", "Sanc\u00b7tus", "wie", "Fr\u00fch\u00b7lings\u00b7s\u00e4u\u00b7seln", "wallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nun nies't dazwischen Einer, da\u00df tief der Dom erbebt!", "tokens": ["Nun", "nies't", "da\u00b7zwi\u00b7schen", "Ei\u00b7ner", ",", "da\u00df", "tief", "der", "Dom", "er\u00b7bebt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PIS", "$,", "KOUS", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wohin ist die Verkl\u00e4rung, die zu den Sternen schwebt?", "tokens": ["Wo\u00b7hin", "ist", "die", "Ver\u00b7kl\u00e4\u00b7rung", ",", "die", "zu", "den", "Ster\u00b7nen", "schwebt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}}, "stanza.12": {"line.1": {"text": "So zuckt jetzt Kunz und blinzelt und zieht die Stirne kraus,", "tokens": ["So", "zuckt", "jetzt", "Kunz", "und", "blin\u00b7zelt", "und", "zieht", "die", "Stir\u00b7ne", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gern dr\u00e4ngt' er's noch zur\u00fccke, umsonst, es mu\u00df heraus!", "tokens": ["Gern", "dr\u00e4ngt'", "er's", "noch", "zu\u00b7r\u00fc\u00b7cke", ",", "um\u00b7sonst", ",", "es", "mu\u00df", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PTKVZ", "$,", "ADV", "$,", "PPER", "VMFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da sch\u00fcttelt er laut klingend den Schellenhut am Haupt:", "tokens": ["Da", "sch\u00fct\u00b7telt", "er", "laut", "klin\u00b7gend", "den", "Schel\u00b7len\u00b7hut", "am", "Haupt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "VVPP", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbihr Herrn, la\u00dft mich doch h\u00f6ren, wie alt ihr mich wohl glaubt!\u00ab", "tokens": ["\u00bb", "ihr", "Herrn", ",", "la\u00dft", "mich", "doch", "h\u00f6\u00b7ren", ",", "wie", "alt", "ihr", "mich", "wohl", "glaubt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVIMP", "PPER", "ADV", "VVINF", "$,", "PWAV", "ADJD", "PPER", "PRF", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "\u00bbzu alt, zweibein'ge Thorheit, um je zu werden klug,", "tokens": ["\u00bb", "zu", "alt", ",", "zwei\u00b7bein'\u00b7ge", "Thor\u00b7heit", ",", "um", "je", "zu", "wer\u00b7den", "klug", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKA", "ADJD", "$,", "ADJA", "NN", "$,", "KOUI", "ADV", "PTKZU", "VAINF", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und doch zu jeder Stunde zum H\u00e4ngen alt genug!\u00ab", "tokens": ["Und", "doch", "zu", "je\u00b7der", "Stun\u00b7de", "zum", "H\u00e4n\u00b7gen", "alt", "ge\u00b7nug", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "APPRART", "NN", "ADJD", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So schnarrte Kunzen grimmig der derbe Talbot an,", "tokens": ["So", "schnarr\u00b7te", "Kun\u00b7zen", "grim\u00b7mig", "der", "der\u00b7be", "Tal\u00b7bot", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch freundlicher und milder sprach K\u00f6nig Heinrich dann:", "tokens": ["Doch", "freund\u00b7li\u00b7cher", "und", "mil\u00b7der", "sprach", "K\u00f6\u00b7nig", "Hein\u00b7rich", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "NE", "NE", "ADV", "$."], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.14": {"line.1": {"text": "\u00bbauf das Geweih dem Hirsche, dem Gaule auf den Zahn,", "tokens": ["\u00bb", "auf", "das", "Ge\u00b7weih", "dem", "Hir\u00b7sche", ",", "dem", "Gau\u00b7le", "auf", "den", "Zahn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Dem Menschen schrieb aufs Antlitz Natur sein Alter an;", "tokens": ["Dem", "Men\u00b7schen", "schrieb", "aufs", "Ant\u00b7litz", "Na\u00b7tur", "sein", "Al\u00b7ter", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kind! schrieb sie auf die Stirne, Mann! auf die Wange dir,", "tokens": ["Kind", "!", "schrieb", "sie", "auf", "die", "Stir\u00b7ne", ",", "Mann", "!", "auf", "die", "Wan\u00b7ge", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "NN", "$.", "APPR", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Liegt Wahrheit in der Mitte? Sprich, Freund, wem glaub' ich hier?\u00ab", "tokens": ["Liegt", "Wahr\u00b7heit", "in", "der", "Mit\u00b7te", "?", "Sprich", ",", "Freund", ",", "wem", "glaub'", "ich", "hier", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "$.", "NN", "$,", "NN", "$,", "PWS", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "Drauf Kaiser Max mit L\u00e4cheln: \u00bbSpricht unser Sprichwort wahr,", "tokens": ["Drauf", "Kai\u00b7ser", "Max", "mit", "L\u00e4\u00b7cheln", ":", "\u00bb", "Spricht", "un\u00b7ser", "Sprich\u00b7wort", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "NE", "APPR", "NN", "$.", "$(", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So soll der Mensch sich \u00e4ndern nach jedem siebenten Jahr;", "tokens": ["So", "soll", "der", "Mensch", "sich", "\u00e4n\u00b7dern", "nach", "je\u00b7dem", "sie\u00b7ben\u00b7ten", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PRF", "VVINF", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Doch du, seit ich dich kenne, bist immer Narr geblieben,", "tokens": ["Doch", "du", ",", "seit", "ich", "dich", "ken\u00b7ne", ",", "bist", "im\u00b7mer", "Narr", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,", "VAFIN", "ADV", "NN", "VVPP", "$,"], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Drum mein' ich stets, du z\u00e4hlest der Jahre noch nicht sieben.\u00ab", "tokens": ["Drum", "mein'", "ich", "stets", ",", "du", "z\u00e4h\u00b7lest", "der", "Jah\u00b7re", "noch", "nicht", "sie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbei, wie ihr schmeichelt! Ich z\u00e4hle mehr als zweihundert doch!", "tokens": ["\u00bb", "ei", ",", "wie", "ihr", "schmei\u00b7chelt", "!", "Ich", "z\u00e4h\u00b7le", "mehr", "als", "zwei\u00b7hun\u00b7dert", "doch", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PWAV", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PIS", "KOKOM", "VVFIN", "ADV", "$."], "meter": "+--+--+-+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Die B\u00fcnde von Blois und Cambray, die \u00fcberlebt' ich noch!", "tokens": ["Die", "B\u00fcn\u00b7de", "von", "Blois", "und", "Camb\u00b7ray", ",", "die", "\u00fc\u00b7ber\u00b7lebt'", "ich", "noch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "NE", "$,", "PRELS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Geschlossen ward doch jeder auf volle hundert Jahr'!", "tokens": ["Ge\u00b7schlos\u00b7sen", "ward", "doch", "je\u00b7der", "auf", "vol\u00b7le", "hun\u00b7dert", "Jahr'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "PIS", "APPR", "ADJA", "CARD", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und jetzt macht ihr mir Hoffnung auf Ewigkeiten gar!\u00ab", "tokens": ["Und", "jetzt", "macht", "ihr", "mir", "Hoff\u00b7nung", "auf", "E\u00b7wig\u00b7kei\u00b7ten", "gar", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "NN", "APPR", "NN", "ADV", "$.", "$("], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}}, "stanza.17": {"line.1": {"text": "Zwei Bundesheere lagern bei Terouanne im Feld,", "tokens": ["Zwei", "Bun\u00b7des\u00b7hee\u00b7re", "la\u00b7gern", "bei", "Te\u00b7rou\u00b7an\u00b7ne", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPR", "NE", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dorthin hat ihre Zelte Franzosenha\u00df gestellt;", "tokens": ["Dor\u00b7thin", "hat", "ih\u00b7re", "Zel\u00b7te", "Fran\u00b7zo\u00b7sen\u00b7ha\u00df", "ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ha, wie da Englands Banner die L\u00fcfte z\u00fcngelnd leckt,", "tokens": ["Ha", ",", "wie", "da", "En\u00b7glands", "Ban\u00b7ner", "die", "L\u00fcf\u00b7te", "z\u00fcn\u00b7gelnd", "leckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "ADV", "NE", "NN", "ART", "NN", "VVPP", "VVFIN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und Deutschlands Doppeladler die m\u00e4cht'gen Fl\u00fcgel streckt!", "tokens": ["Und", "Deutschlands", "Dop\u00b7pe\u00b7lad\u00b7ler", "die", "m\u00e4cht'\u00b7gen", "Fl\u00fc\u00b7gel", "streckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.18": {"line.1": {"text": "Der Rhein trennt Deutsch' und Franken. Ei, Deutscher, welch Wunderpferd", "tokens": ["Der", "Rhein", "trennt", "Deut\u00b7sch'", "und", "Fran\u00b7ken", ".", "Ei", ",", "Deut\u00b7scher", ",", "welch", "Wun\u00b7der\u00b7pferd"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NE", "VVFIN", "NE", "KON", "NN", "$.", "NN", "$,", "NN", "$,", "PWAT", "NN"], "meter": "-+-+--+-++--+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Trug k\u00fchnen Sprungs hin\u00fcber dich und dein Racheschwert?", "tokens": ["Trug", "k\u00fch\u00b7nen", "Sprungs", "hin\u00b7\u00fc\u00b7ber", "dich", "und", "dein", "Ra\u00b7ch\u00b7e\u00b7schwert", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADV", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Ha\u00df war der k\u00fchne Springer, das schwarze Fl\u00fcgelro\u00df!", "tokens": ["Ha\u00df", "war", "der", "k\u00fch\u00b7ne", "Sprin\u00b7ger", ",", "das", "schwar\u00b7ze", "Fl\u00fc\u00b7gel\u00b7ro\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und weiter fliegt nur Liebe, die Taube mit gr\u00fcnem Spro\u00df.", "tokens": ["Und", "wei\u00b7ter", "fliegt", "nur", "Lie\u00b7be", ",", "die", "Tau\u00b7be", "mit", "gr\u00fc\u00b7nem", "Spro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Ein Meer trennt Franken und Britten. Wer hat die Br\u00fccke gespannt,", "tokens": ["Ein", "Meer", "trennt", "Fran\u00b7ken", "und", "Brit\u00b7ten", ".", "Wer", "hat", "die", "Br\u00fc\u00b7cke", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Drauf Englands eh'rne Heere hinziehn ins Franzenland?", "tokens": ["Drauf", "En\u00b7glands", "eh'r\u00b7ne", "Hee\u00b7re", "hin\u00b7ziehn", "ins", "Fran\u00b7zen\u00b7land", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "ADJA", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ha\u00df nennt sich der Br\u00fcckenmeister, der b\u00e4ndigt Strom und Belt,", "tokens": ["Ha\u00df", "nennt", "sich", "der", "Br\u00fc\u00b7cken\u00b7meis\u00b7ter", ",", "der", "b\u00e4n\u00b7digt", "Strom", "und", "Belt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ART", "NN", "$,", "PRELS", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und Gr\u00f6\u00df'res baut nur Liebe, seht ihren Dom, die Welt!", "tokens": ["Und", "Gr\u00f6\u00df'\u00b7res", "baut", "nur", "Lie\u00b7be", ",", "seht", "ih\u00b7ren", "Dom", ",", "die", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}}, "stanza.20": {"line.1": {"text": "Vor's Lager hinaus lustwandelt der V\u00f6lker F\u00fcrstenpaar,", "tokens": ["Vor's", "La\u00b7ger", "hin\u00b7aus", "lust\u00b7wan\u00b7delt", "der", "V\u00f6l\u00b7ker", "F\u00fcrs\u00b7ten\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heinrich, der junge Britte, und Max, schon grau von Haar;", "tokens": ["Hein\u00b7rich", ",", "der", "jun\u00b7ge", "Brit\u00b7te", ",", "und", "Max", ",", "schon", "grau", "von", "Haar", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,", "KON", "NE", "$,", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Vor ihren Blicken dehnt sich, wie 'n See, so weit und glatt,", "tokens": ["Vor", "ih\u00b7ren", "Bli\u00b7cken", "dehnt", "sich", ",", "wie", "'n", "See", ",", "so", "weit", "und", "glatt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF", "$,", "PWAV", "ART", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Die Ebne von Terouanne fernhin bis Guinegat'.", "tokens": ["Die", "Eb\u00b7ne", "von", "Te\u00b7rou\u00b7an\u00b7ne", "fern\u00b7hin", "bis", "Gu\u00b7i\u00b7ne\u00b7gat'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ADV", "APPR", "NE", "$."], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.21": {"line.1": {"text": "Talbot schritt neben Heinrich, als h\u00e4tt' am Himmelszelt", "tokens": ["Tal\u00b7bot", "schritt", "ne\u00b7ben", "Hein\u00b7rich", ",", "als", "h\u00e4tt'", "am", "Him\u00b7mels\u00b7zelt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NE", "$,", "KOKOM", "VAFIN", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Sich Mars, das blut'ge Sternbild, zum hehren Mond gesellt;", "tokens": ["Sich", "Mars", ",", "das", "blut'\u00b7ge", "Stern\u00b7bild", ",", "zum", "heh\u00b7ren", "Mond", "ge\u00b7sellt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "$,", "ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kunz von der Rosen wallte zur Seite seinem Herrn,", "tokens": ["Kunz", "von", "der", "Ro\u00b7sen", "wall\u00b7te", "zur", "Sei\u00b7te", "sei\u00b7nem", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Wie mit dem Sonnengotte der heitre Morgenstern.", "tokens": ["Wie", "mit", "dem", "Son\u00b7nen\u00b7got\u00b7te", "der", "heit\u00b7re", "Mor\u00b7gens\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+--+--", "measure": "iambic.penta.invert"}}, "stanza.22": {"line.1": {"text": "Max blickte ringsum sinnend; da ward sein Herz so weich:", "tokens": ["Max", "blick\u00b7te", "ring\u00b7sum", "sin\u00b7nend", ";", "da", "ward", "sein", "Herz", "so", "weich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "VVPP", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbwie ist im Leben Alles so alt und neu zugleich!", "tokens": ["\u00bb", "wie", "ist", "im", "Le\u00b7ben", "Al\u00b7les", "so", "alt", "und", "neu", "zu\u00b7gleich", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "VAFIN", "APPRART", "NN", "PIS", "ADV", "ADJD", "KON", "ADJD", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hier k\u00e4mpft' ich vor drei\u00dfig Jahren, \u2013 es war mein erster Sieg!", "tokens": ["Hier", "k\u00e4mpft'", "ich", "vor", "drei\u00b7\u00dfig", "Jah\u00b7ren", ",", "\u2013", "es", "war", "mein", "ers\u00b7ter", "Sieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "CARD", "NN", "$,", "$(", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Hier f\u00fchr' ich morgen die Schaaren, \u2013 wohl wird's mein letzter Sieg!", "tokens": ["Hier", "f\u00fchr'", "ich", "mor\u00b7gen", "die", "Schaa\u00b7ren", ",", "\u2013", "wohl", "wird's", "mein", "letz\u00b7ter", "Sieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "$(", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.23": {"line.1": {"text": "Seht dort der Veste Bollwerk, die Warten, Thurm und Thor", "tokens": ["Seht", "dort", "der", "Ves\u00b7te", "Boll\u00b7werk", ",", "die", "War\u00b7ten", ",", "Thurm", "und", "Thor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und hier die weiten Fluren, noch ist die\u00df Alles wie vor;", "tokens": ["Und", "hier", "die", "wei\u00b7ten", "Flu\u00b7ren", ",", "noch", "ist", "die\u00df", "Al\u00b7les", "wie", "vor", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,", "ADV", "VAFIN", "PDS", "PIS", "KOKOM", "APPR", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Luft und Erden Antlitz ist noch wie's damals war,", "tokens": ["Der", "Luft", "und", "Er\u00b7den", "Ant\u00b7litz", "ist", "noch", "wie's", "da\u00b7mals", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "NN", "VAFIN", "ADV", "VVFIN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nur gr\u00f6\u00dfer ward der Kirchhof, und bleicher ward mein Haar.", "tokens": ["Nur", "gr\u00f6\u00b7\u00dfer", "ward", "der", "Kirch\u00b7hof", ",", "und", "blei\u00b7cher", "ward", "mein", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "NN", "$,", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Und doch, wie anders Alles! Manch neu Geschlecht entstand,", "tokens": ["Und", "doch", ",", "wie", "an\u00b7ders", "Al\u00b7les", "!", "Manch", "neu", "Ge\u00b7schlecht", "ent\u00b7stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "ADV", "PIS", "$.", "PIAT", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Herbst hat oft gem\u00e4het, der Lenz bes\u00e4t das Land,", "tokens": ["Der", "Herbst", "hat", "oft", "ge\u00b7m\u00e4\u00b7het", ",", "der", "Lenz", "be\u00b7s\u00e4t", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Luft hat gest\u00fcrmt und ges\u00e4uselt, die Sonn' erlosch und schien,", "tokens": ["Die", "Luft", "hat", "ge\u00b7st\u00fcrmt", "und", "ge\u00b7s\u00e4u\u00b7selt", ",", "die", "Sonn'", "er\u00b7losch", "und", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "KON", "VVPP", "$,", "ART", "NN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "Der alte Ha\u00df nur schreitet noch durchs Gefilde hin!\u00ab", "tokens": ["Der", "al\u00b7te", "Ha\u00df", "nur", "schrei\u00b7tet", "noch", "durchs", "Ge\u00b7fil\u00b7de", "hin", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Da fiel ins Wort ihm Heinrich: \u00bbVergi\u00df die Liebe nicht!", "tokens": ["Da", "fiel", "ins", "Wort", "ihm", "Hein\u00b7rich", ":", "\u00bb", "Ver\u00b7gi\u00df", "die", "Lie\u00b7be", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "PPER", "NE", "$.", "$(", "VVIMP", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie ist's, die unsre Arme zu festem Bunde flicht;", "tokens": ["Sie", "ist's", ",", "die", "uns\u00b7re", "Ar\u00b7me", "zu", "fes\u00b7tem", "Bun\u00b7de", "flicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O lasse fort ihn dauern in ferne ew'ge Zeit!\u00ab", "tokens": ["O", "las\u00b7se", "fort", "ihn", "dau\u00b7ern", "in", "fer\u00b7ne", "ew'\u00b7ge", "Zeit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "PPER", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da dr\u00fcckte Max ans Herz ihn: \u00bbJa, Bruder, in Ewigkeit!\u00ab", "tokens": ["Da", "dr\u00fcck\u00b7te", "Max", "ans", "Herz", "ihn", ":", "\u00bb", "Ja", ",", "Bru\u00b7der", ",", "in", "E\u00b7wig\u00b7keit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPRART", "NN", "PPER", "$.", "$(", "PTKANT", "$,", "NN", "$,", "APPR", "NN", "$.", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.26": {"line.1": {"text": "In feierlichem Schweigen stand jetzt das F\u00fcrstenpaar,", "tokens": ["In", "fei\u00b7er\u00b7li\u00b7chem", "Schwei\u00b7gen", "stand", "jetzt", "das", "F\u00fcrs\u00b7ten\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es schwieg der ew'ge Aether, so tief und blau und klar,", "tokens": ["Es", "schwieg", "der", "ew'\u00b7ge", "A\u00b7e\u00b7ther", ",", "so", "tief", "und", "blau", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Es schwiegen rings die Fluren, so eben und so weit,", "tokens": ["Es", "schwie\u00b7gen", "rings", "die", "Flu\u00b7ren", ",", "so", "e\u00b7ben", "und", "so", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "ADV", "ADV", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gleichwie ein stummes Echo des Wortes: Ewigkeit!", "tokens": ["Gleich\u00b7wie", "ein", "stum\u00b7mes", "E\u00b7cho", "des", "Wor\u00b7tes", ":", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.27": {"line.1": {"text": "Denkt euch in den Dom, wo leise des Hochamts Orgel verhallt", "tokens": ["Denkt", "euch", "in", "den", "Dom", ",", "wo", "lei\u00b7se", "des", "Hoc\u00b7hamts", "Or\u00b7gel", "ver\u00b7hallt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "ADJD", "ART", "NN", "NN", "VVPP"], "meter": "+---+-+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und feierlich beim Sanctus wie Fr\u00fchlingss\u00e4useln wallt.", "tokens": ["Und", "fei\u00b7er\u00b7lich", "beim", "Sanc\u00b7tus", "wie", "Fr\u00fch\u00b7lings\u00b7s\u00e4u\u00b7seln", "wallt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "NN", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nun nies't dazwischen Einer, da\u00df tief der Dom erbebt!", "tokens": ["Nun", "nies't", "da\u00b7zwi\u00b7schen", "Ei\u00b7ner", ",", "da\u00df", "tief", "der", "Dom", "er\u00b7bebt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PIS", "$,", "KOUS", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wohin ist die Verkl\u00e4rung, die zu den Sternen schwebt?", "tokens": ["Wo\u00b7hin", "ist", "die", "Ver\u00b7kl\u00e4\u00b7rung", ",", "die", "zu", "den", "Ster\u00b7nen", "schwebt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}}, "stanza.28": {"line.1": {"text": "So zuckt jetzt Kunz und blinzelt und zieht die Stirne kraus,", "tokens": ["So", "zuckt", "jetzt", "Kunz", "und", "blin\u00b7zelt", "und", "zieht", "die", "Stir\u00b7ne", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NE", "KON", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gern dr\u00e4ngt' er's noch zur\u00fccke, umsonst, es mu\u00df heraus!", "tokens": ["Gern", "dr\u00e4ngt'", "er's", "noch", "zu\u00b7r\u00fc\u00b7cke", ",", "um\u00b7sonst", ",", "es", "mu\u00df", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PTKVZ", "$,", "ADV", "$,", "PPER", "VMFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da sch\u00fcttelt er laut klingend den Schellenhut am Haupt:", "tokens": ["Da", "sch\u00fct\u00b7telt", "er", "laut", "klin\u00b7gend", "den", "Schel\u00b7len\u00b7hut", "am", "Haupt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "VVPP", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbihr Herrn, la\u00dft mich doch h\u00f6ren, wie alt ihr mich wohl glaubt!\u00ab", "tokens": ["\u00bb", "ihr", "Herrn", ",", "la\u00dft", "mich", "doch", "h\u00f6\u00b7ren", ",", "wie", "alt", "ihr", "mich", "wohl", "glaubt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVIMP", "PPER", "ADV", "VVINF", "$,", "PWAV", "ADJD", "PPER", "PRF", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.29": {"line.1": {"text": "\u00bbzu alt, zweibein'ge Thorheit, um je zu werden klug,", "tokens": ["\u00bb", "zu", "alt", ",", "zwei\u00b7bein'\u00b7ge", "Thor\u00b7heit", ",", "um", "je", "zu", "wer\u00b7den", "klug", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKA", "ADJD", "$,", "ADJA", "NN", "$,", "KOUI", "ADV", "PTKZU", "VAINF", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und doch zu jeder Stunde zum H\u00e4ngen alt genug!\u00ab", "tokens": ["Und", "doch", "zu", "je\u00b7der", "Stun\u00b7de", "zum", "H\u00e4n\u00b7gen", "alt", "ge\u00b7nug", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "APPRART", "NN", "ADJD", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So schnarrte Kunzen grimmig der derbe Talbot an,", "tokens": ["So", "schnarr\u00b7te", "Kun\u00b7zen", "grim\u00b7mig", "der", "der\u00b7be", "Tal\u00b7bot", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch freundlicher und milder sprach K\u00f6nig Heinrich dann:", "tokens": ["Doch", "freund\u00b7li\u00b7cher", "und", "mil\u00b7der", "sprach", "K\u00f6\u00b7nig", "Hein\u00b7rich", "dann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "NE", "NE", "ADV", "$."], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.30": {"line.1": {"text": "\u00bbauf das Geweih dem Hirsche, dem Gaule auf den Zahn,", "tokens": ["\u00bb", "auf", "das", "Ge\u00b7weih", "dem", "Hir\u00b7sche", ",", "dem", "Gau\u00b7le", "auf", "den", "Zahn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Dem Menschen schrieb aufs Antlitz Natur sein Alter an;", "tokens": ["Dem", "Men\u00b7schen", "schrieb", "aufs", "Ant\u00b7litz", "Na\u00b7tur", "sein", "Al\u00b7ter", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kind! schrieb sie auf die Stirne, Mann! auf die Wange dir,", "tokens": ["Kind", "!", "schrieb", "sie", "auf", "die", "Stir\u00b7ne", ",", "Mann", "!", "auf", "die", "Wan\u00b7ge", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "NN", "$.", "APPR", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Liegt Wahrheit in der Mitte? Sprich, Freund, wem glaub' ich hier?\u00ab", "tokens": ["Liegt", "Wahr\u00b7heit", "in", "der", "Mit\u00b7te", "?", "Sprich", ",", "Freund", ",", "wem", "glaub'", "ich", "hier", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "$.", "NN", "$,", "NN", "$,", "PWS", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.31": {"line.1": {"text": "Drauf Kaiser Max mit L\u00e4cheln: \u00bbSpricht unser Sprichwort wahr,", "tokens": ["Drauf", "Kai\u00b7ser", "Max", "mit", "L\u00e4\u00b7cheln", ":", "\u00bb", "Spricht", "un\u00b7ser", "Sprich\u00b7wort", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "NE", "APPR", "NN", "$.", "$(", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So soll der Mensch sich \u00e4ndern nach jedem siebenten Jahr;", "tokens": ["So", "soll", "der", "Mensch", "sich", "\u00e4n\u00b7dern", "nach", "je\u00b7dem", "sie\u00b7ben\u00b7ten", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PRF", "VVINF", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Doch du, seit ich dich kenne, bist immer Narr geblieben,", "tokens": ["Doch", "du", ",", "seit", "ich", "dich", "ken\u00b7ne", ",", "bist", "im\u00b7mer", "Narr", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,", "VAFIN", "ADV", "NN", "VVPP", "$,"], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Drum mein' ich stets, du z\u00e4hlest der Jahre noch nicht sieben.\u00ab", "tokens": ["Drum", "mein'", "ich", "stets", ",", "du", "z\u00e4h\u00b7lest", "der", "Jah\u00b7re", "noch", "nicht", "sie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.32": {"line.1": {"text": "\u00bbei, wie ihr schmeichelt! Ich z\u00e4hle mehr als zweihundert doch!", "tokens": ["\u00bb", "ei", ",", "wie", "ihr", "schmei\u00b7chelt", "!", "Ich", "z\u00e4h\u00b7le", "mehr", "als", "zwei\u00b7hun\u00b7dert", "doch", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PWAV", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PIS", "KOKOM", "VVFIN", "ADV", "$."], "meter": "+--+--+-+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Die B\u00fcnde von Blois und Cambray, die \u00fcberlebt' ich noch!", "tokens": ["Die", "B\u00fcn\u00b7de", "von", "Blois", "und", "Camb\u00b7ray", ",", "die", "\u00fc\u00b7ber\u00b7lebt'", "ich", "noch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "KON", "NE", "$,", "PRELS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Geschlossen ward doch jeder auf volle hundert Jahr'!", "tokens": ["Ge\u00b7schlos\u00b7sen", "ward", "doch", "je\u00b7der", "auf", "vol\u00b7le", "hun\u00b7dert", "Jahr'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "PIS", "APPR", "ADJA", "CARD", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und jetzt macht ihr mir Hoffnung auf Ewigkeiten gar!\u00ab", "tokens": ["Und", "jetzt", "macht", "ihr", "mir", "Hoff\u00b7nung", "auf", "E\u00b7wig\u00b7kei\u00b7ten", "gar", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "NN", "APPR", "NN", "ADV", "$.", "$("], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}}}}}