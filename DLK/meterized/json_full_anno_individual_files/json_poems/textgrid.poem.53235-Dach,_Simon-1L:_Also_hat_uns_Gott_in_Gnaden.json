{"textgrid.poem.53235": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Also hat uns Gott in Gnaden", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Also hat uns Gott in Gnaden", "tokens": ["Al\u00b7so", "hat", "uns", "Gott", "in", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nun auch dieser Furcht entladen,", "tokens": ["Nun", "auch", "die\u00b7ser", "Furcht", "ent\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heldinn, durch den thewren Gast,", "tokens": ["Hel\u00b7dinn", ",", "durch", "den", "thew\u00b7ren", "Gast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den du zwar besorgt getragen,", "tokens": ["Den", "du", "zwar", "be\u00b7sorgt", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber in den Meyen-Tagen", "tokens": ["A\u00b7ber", "in", "den", "Meyen\u00b7Ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Newlich froh gebohren hast.", "tokens": ["New\u00b7lich", "froh", "ge\u00b7boh\u00b7ren", "hast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "O der so gew\u00fcnschten Stunden,", "tokens": ["O", "der", "so", "ge\u00b7w\u00fcnschten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die, O Churf\u00fcrstinn, entbunden", "tokens": ["Die", ",", "O", "Chur\u00b7f\u00fcrs\u00b7tinn", ",", "ent\u00b7bun\u00b7den"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "$,", "NE", "NN", "$,", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dich der B\u00fcrd' und uns der Noht,", "tokens": ["Dich", "der", "B\u00fcrd'", "und", "uns", "der", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "KON", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns, die unser grosse K\u00f6nig", "tokens": ["Uns", ",", "die", "un\u00b7ser", "gros\u00b7se", "K\u00f6\u00b7nig"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eben dazumahl nicht wenig", "tokens": ["E\u00b7ben", "da\u00b7zu\u00b7mahl", "nicht", "we\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat betr\u00fcbt durch seinen Todt.", "tokens": ["Hat", "be\u00b7tr\u00fcbt", "durch", "sei\u00b7nen", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Das Verlangen, so wir trieben,", "tokens": ["Das", "Ver\u00b7lan\u00b7gen", ",", "so", "wir", "trie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird durch keines Faust beschrieben,", "tokens": ["Wird", "durch", "kei\u00b7nes", "Faust", "be\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "St\u00fcndlich fast kam Zeitung ein,", "tokens": ["St\u00fcnd\u00b7lich", "fast", "kam", "Zei\u00b7tung", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja, es ist in dreyen Wochen", "tokens": ["Ja", ",", "es", "ist", "in", "drey\u00b7en", "Wo\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nichts ohn die\u00df allein gesprochen:", "tokens": ["Nichts", "ohn", "die\u00df", "al\u00b7lein", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PDS", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Geburt soll richtig seyn.", "tokens": ["Die", "Ge\u00b7burt", "soll", "rich\u00b7tig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer hat aber unterdessen", "tokens": ["Wer", "hat", "a\u00b7ber", "un\u00b7ter\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Des Gebehtes hie vergessen?", "tokens": ["Des", "Ge\u00b7beh\u00b7tes", "hie", "ver\u00b7ges\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die\u00df war aller Kirchen Thon,", "tokens": ["Die\u00df", "war", "al\u00b7ler", "Kir\u00b7chen", "Thon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Unsre Seufftzer, unsre Lieder,", "tokens": ["Uns\u00b7re", "Seufft\u00b7zer", ",", "uns\u00b7re", "Lie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die wir sungen hin und wieder,", "tokens": ["Die", "wir", "sun\u00b7gen", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PTKVZ", "KON", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Waren nur umb diesen Sohn.", "tokens": ["Wa\u00b7ren", "nur", "umb", "die\u00b7sen", "Sohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Gott hab' jetzund unser Flehen", "tokens": ["Gott", "hab'", "je\u00b7tzund", "un\u00b7ser", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder sonst was angesehen,", "tokens": ["O\u00b7der", "sonst", "was", "an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wol, du hohe Mutter, dir!", "tokens": ["Wol", ",", "du", "ho\u00b7he", "Mut\u00b7ter", ",", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PPER", "ADJA", "NN", "$,", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den du untter keuschem Hertzen,", "tokens": ["Den", "du", "unt\u00b7ter", "keu\u00b7schem", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gott und du weist mit was Schmertzen,", "tokens": ["Gott", "und", "du", "weist", "mit", "was", "Schmert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PPER", "VVFIN", "APPR", "PRELS", "NN", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.6": {"text": "So viel Monden trugst, ist hier.", "tokens": ["So", "viel", "Mon\u00b7den", "trugst", ",", "ist", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "VAFIN", "ADV", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Wol auch uns und unserm Lande,", "tokens": ["Wol", "auch", "uns", "und", "un\u00b7serm", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dem sich Gott in diesem Pfande", "tokens": ["Dem", "sich", "Gott", "in", "die\u00b7sem", "Pfan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "NN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner Gunst versichert h\u00e4lt,", "tokens": ["Sei\u00b7ner", "Gunst", "ver\u00b7si\u00b7chert", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nun unsrer Hoffnung Tritten,", "tokens": ["Und", "nun", "uns\u00b7rer", "Hoff\u00b7nung", "Trit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die bi\u00dfher so sehr geglitten,", "tokens": ["Die", "bi\u00df\u00b7her", "so", "sehr", "ge\u00b7glit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen festen Grund gestellt.", "tokens": ["Ei\u00b7nen", "fes\u00b7ten", "Grund", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Seine Huld wil uns nicht lassen,", "tokens": ["Sei\u00b7ne", "Huld", "wil", "uns", "nicht", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Recht als wir bek\u00fcmmert sassen,", "tokens": ["Recht", "als", "wir", "be\u00b7k\u00fcm\u00b7mert", "sas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weinten: Unsers Hauptes Pracht", "tokens": ["Wein\u00b7ten", ":", "Un\u00b7sers", "Haup\u00b7tes", "Pracht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat uns gute Nacht gegeben,", "tokens": ["Hat", "uns", "gu\u00b7te", "Nacht", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ward' uns dein' Entbindung eben", "tokens": ["Ward'", "uns", "dein'", "Ent\u00b7bin\u00b7dung", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fern aus Cleve zugebracht.", "tokens": ["Fern", "aus", "Cle\u00b7ve", "zu\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie in starcken Donnerschl\u00e4gen,", "tokens": ["Wie", "in", "star\u00b7cken", "Don\u00b7ner\u00b7schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In Gew\u00f6lck', in Sturm und Regen", "tokens": ["In", "Ge\u00b7w\u00f6lck'", ",", "in", "Sturm", "und", "Re\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns die liebe Sonne thut,", "tokens": ["Uns", "die", "lie\u00b7be", "Son\u00b7ne", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Also mitten in dem Leide", "tokens": ["Al\u00b7so", "mit\u00b7ten", "in", "dem", "Lei\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "War uns \u00fcber dieser Frewde", "tokens": ["War", "uns", "\u00fc\u00b7ber", "die\u00b7ser", "Frew\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch umb selbe Zeit zu muth.", "tokens": ["Auch", "umb", "sel\u00b7be", "Zeit", "zu", "muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Anfangs wolte man nicht trawen,", "tokens": ["An\u00b7fangs", "wol\u00b7te", "man", "nicht", "tra\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Was wir mit Verlangen schawen,", "tokens": ["Was", "wir", "mit", "Ver\u00b7lan\u00b7gen", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wird mit Sorg' und Furcht gegl\u00e4ubt,", "tokens": ["Wird", "mit", "Sor\u00b7g'", "und", "Furcht", "ge\u00b7gl\u00e4ubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Bi\u00df die Warheit wird erlesen,", "tokens": ["Bi\u00df", "die", "War\u00b7heit", "wird", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und von diesem lieben Wesen", "tokens": ["Und", "von", "die\u00b7sem", "lie\u00b7ben", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eine Post die andre treibt.", "tokens": ["Ei\u00b7ne", "Post", "die", "and\u00b7re", "treibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Als sie aber nun erschollen,", "tokens": ["Als", "sie", "a\u00b7ber", "nun", "er\u00b7schol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tte man hie sehen sollen", "tokens": ["H\u00e4t\u00b7te", "man", "hie", "se\u00b7hen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles Land in Frewde stehn,", "tokens": ["Al\u00b7les", "Land", "in", "Frew\u00b7de", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich mit diesen wehrten Sachen", "tokens": ["Sich", "mit", "die\u00b7sen", "wehr\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hin und Her beheglich machen,", "tokens": ["Hin", "und", "Her", "be\u00b7heg\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Freund zum andern gehn.", "tokens": ["Ei\u00b7nen", "Freund", "zum", "an\u00b7dern", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Niemand kan was anders sprechen", "tokens": ["Nie\u00b7mand", "kan", "was", "an\u00b7ders", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PIS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff der B\u00f6r\u00df', in den Gel\u00e4chen.", "tokens": ["Auff", "der", "B\u00f6r\u00df'", ",", "in", "den", "Ge\u00b7l\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Krancken selbs ist hievon woll,", "tokens": ["Kran\u00b7cken", "selbs", "ist", "hie\u00b7von", "woll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PAV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie Krafft und Leben fassen,", "tokens": ["Da\u00df", "sie", "Krafft", "und", "Le\u00b7ben", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "G\u00e4rtten, Junckerh\u00f6ff' und Gassen", "tokens": ["G\u00e4rt\u00b7ten", ",", "Jun\u00b7cker\u00b7h\u00f6ff'", "und", "Gas\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind von dieser Zeitung voll.", "tokens": ["Sind", "von", "die\u00b7ser", "Zei\u00b7tung", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Erst ist in der Frommen Orden", "tokens": ["Erst", "ist", "in", "der", "From\u00b7men", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Gott hievor gepriesen worden,", "tokens": ["Gott", "hie\u00b7vor", "ge\u00b7prie\u00b7sen", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "VVPP", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gesagt, da\u00df seiner Trew", "tokens": ["Und", "ge\u00b7sagt", ",", "da\u00df", "sei\u00b7ner", "Trew"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVPP", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einig die\u00dffals sey zu dancken,", "tokens": ["Ei\u00b7nig", "die\u00df\u00b7fals", "sey", "zu", "dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die H\u00e4user, so schon wancken,", "tokens": ["Als", "die", "H\u00e4u\u00b7ser", ",", "so", "schon", "wan\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder durch Geburt erfrew'.", "tokens": ["Wie\u00b7der", "durch", "Ge\u00b7burt", "er\u00b7fre\u00b7w'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "Hierauff geben ungehewer", "tokens": ["Hier\u00b7auff", "ge\u00b7ben", "un\u00b7ge\u00b7he\u00b7wer"], "token_info": ["word", "word", "word"], "pos": ["PAV", "VVINF", "ADJD"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Beydes Schloss und Freyheit Fewer.", "tokens": ["Bey\u00b7des", "Schloss", "und", "Frey\u00b7heit", "Fe\u00b7wer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lochst\u00e4t, Pillaw, See, die Fluth", "tokens": ["Lochs\u00b7t\u00e4t", ",", "Pil\u00b7law", ",", "See", ",", "die", "Fluth"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Beyder H\u00e4b' und ihre Tieffe,", "tokens": ["Bey\u00b7der", "H\u00e4b'", "und", "ih\u00b7re", "Tief\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die tausent frembden Schiffe", "tokens": ["Und", "die", "tau\u00b7sent", "fremb\u00b7den", "Schif\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stehn in Nebel, Dampff und Glut.", "tokens": ["Stehn", "in", "Ne\u00b7bel", ",", "Dampff", "und", "Glut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Wa\u00df? der Br\u00fcckenreiche Pregel", "tokens": ["Wa\u00df", "?", "der", "Br\u00fc\u00b7cken\u00b7rei\u00b7che", "Pre\u00b7gel"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hebt durch Flaggen, M\u00e4st' und Segel", "tokens": ["Hebt", "durch", "Flag\u00b7gen", ",", "M\u00e4st'", "und", "Se\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein beschilfftes Haupt empor,", "tokens": ["Sein", "be\u00b7schilff\u00b7tes", "Haupt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nachdem er angesehen,", "tokens": ["Und", "nach\u00b7dem", "er", "an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was und warumb es geschehen,", "tokens": ["Was", "und", "wa\u00b7rumb", "es", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "KON", "PWAV", "PPER", "VVPP", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "L\u00e4ufft er schneller als zuvor.", "tokens": ["L\u00e4ufft", "er", "schnel\u00b7ler", "als", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "KOKOM", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Thetis schickt die Germawinnen", "tokens": ["The\u00b7tis", "schickt", "die", "Ger\u00b7ma\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die sch\u00f6nen Dirschkeiminnen", "tokens": ["Und", "die", "sch\u00f6\u00b7nen", "Dirschkei\u00b7min\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Au\u00df den Wellen an das Land,", "tokens": ["Au\u00df", "den", "Wel\u00b7len", "an", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die an ihrem West sich k\u00fchlen", "tokens": ["Die", "an", "ih\u00b7rem", "West", "sich", "k\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch seine Freundschafft sp\u00fclen", "tokens": ["Und", "durch", "sei\u00b7ne", "Freund\u00b7schafft", "sp\u00fc\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grossen Birnstein an den Rand.", "tokens": ["Gros\u00b7sen", "Birn\u00b7stein", "an", "den", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Phyllis schickt Sylvanen Kr\u00e4ntze,", "tokens": ["Phyl\u00b7lis", "schickt", "Syl\u00b7va\u00b7nen", "Kr\u00e4nt\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Nymfen f\u00fchren T\u00e4ntze,", "tokens": ["Al\u00b7le", "Nym\u00b7fen", "f\u00fch\u00b7ren", "T\u00e4nt\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre Furcht, der geile Pan,", "tokens": ["Ih\u00b7re", "Furcht", ",", "der", "gei\u00b7le", "Pan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Geht nicht minder stets im Reyen", "tokens": ["Geht", "nicht", "min\u00b7der", "stets", "im", "Re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ADV", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und auff seiner Wald-Schalmeyen", "tokens": ["Und", "auff", "sei\u00b7ner", "Wald\u00b7Schal\u00b7meyen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Singt er hievon was er kan.", "tokens": ["Singt", "er", "hie\u00b7von", "was", "er", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PWS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Der Lust noch nicht zu gedencken,", "tokens": ["Der", "Lust", "noch", "nicht", "zu", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Die sich in Gesundheit-Tr\u00e4ncken,", "tokens": ["Die", "sich", "in", "Ge\u00b7sund\u00b7heit\u00b7Tr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und im Frewden-Brand' erregt,", "tokens": ["Und", "im", "Fre\u00b7wden\u00b7Brand'", "er\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "So die gantze Nacht durch wehrte", "tokens": ["So", "die", "gant\u00b7ze", "Nacht", "durch", "wehr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und, weil ihn der P\u00f6fel n\u00e4hrte,", "tokens": ["Und", ",", "weil", "ihn", "der", "P\u00f6\u00b7fel", "n\u00e4hr\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Kaum fr\u00fch Morgens sich gelegt!", "tokens": ["Kaum", "fr\u00fch", "Mor\u00b7gens", "sich", "ge\u00b7legt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Lasst uns treiben was wir k\u00f6nnen,", "tokens": ["Lasst", "uns", "trei\u00b7ben", "was", "wir", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil es Gott uns scheint zu g\u00f6nnen,", "tokens": ["Weil", "es", "Gott", "uns", "scheint", "zu", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Also mu\u00df die Furcht und Pein,", "tokens": ["Al\u00b7so", "mu\u00df", "die", "Furcht", "und", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der wir in verwichnen Jahren", "tokens": ["Der", "wir", "in", "ver\u00b7wich\u00b7nen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gnug uns pflagen zu befahren,", "tokens": ["Gnug", "uns", "pfla\u00b7gen", "zu", "be\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nun einmal bezahlet seyn.", "tokens": ["Nun", "ein\u00b7mal", "be\u00b7zah\u00b7let", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.19": {"line.1": {"text": "Auch du, K\u00f6niglicher Schatten,", "tokens": ["Auch", "du", ",", "K\u00f6\u00b7nig\u00b7li\u00b7cher", "Schat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirst uns diese Lust verstatten,", "tokens": ["Wirst", "uns", "die\u00b7se", "Lust", "ver\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unser Hertz ist dir bekant,", "tokens": ["Un\u00b7ser", "Hertz", "ist", "dir", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Himmel, deine Wonne,", "tokens": ["Und", "der", "Him\u00b7mel", ",", "dei\u00b7ne", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da dich kr\u00f6hnet Licht und Sonne,", "tokens": ["Da", "dich", "kr\u00f6h\u00b7net", "Licht", "und", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wei\u00df umb unsern Trawer-Standt.", "tokens": ["Wei\u00df", "umb", "un\u00b7sern", "Tra\u00b7wer\u00b7Standt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Allzeit wird man dir gewehren", "tokens": ["All\u00b7zeit", "wird", "man", "dir", "ge\u00b7weh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jammer, Hertzens-Angst und Zehren,", "tokens": ["Jam\u00b7mer", ",", "Hert\u00b7zens\u00b7Angst", "und", "Zeh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unsre Mawer wahrest du,", "tokens": ["Uns\u00b7re", "Ma\u00b7wer", "wah\u00b7rest", "du", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Trost in M\u00fch und Sorgen,", "tokens": ["Un\u00b7ser", "Trost", "in", "M\u00fch", "und", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wider Mitternacht und Morgen", "tokens": ["Wi\u00b7der", "Mit\u00b7ter\u00b7nacht", "und", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Halffst du uns mit Schutz und Ruh.", "tokens": ["Halffst", "du", "uns", "mit", "Schutz", "und", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Nur verzeih, da\u00df man die Klage", "tokens": ["Nur", "ver\u00b7zeih", ",", "da\u00df", "man", "die", "Kla\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PIS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was verscheubt an diesem Tage,", "tokens": ["Was", "ver\u00b7scheubt", "an", "die\u00b7sem", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ein newes Licht uns strahlt,", "tokens": ["Da", "ein", "ne\u00b7wes", "Licht", "uns", "strahlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und die Nacht bekr\u00e4nckter Hertzen", "tokens": ["Und", "die", "Nacht", "be\u00b7kr\u00e4nck\u00b7ter", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch die angenehme Kertzen", "tokens": ["Durch", "die", "an\u00b7ge\u00b7neh\u00b7me", "Kert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wolgegr\u00fcndter Hoffnung mahlt.", "tokens": ["Wol\u00b7ge\u00b7gr\u00fcnd\u00b7ter", "Hoff\u00b7nung", "mahlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Denn von nun an wird sich Leben,", "tokens": ["Denn", "von", "nun", "an", "wird", "sich", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "APZR", "VAFIN", "PRF", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Geist und Muth erst recht erheben,", "tokens": ["Geist", "und", "Muth", "erst", "recht", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun verj\u00fcngt sich jedermann,", "tokens": ["Nun", "ver\u00b7j\u00fcngt", "sich", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kan von allen seinen Sachen", "tokens": ["Kan", "von", "al\u00b7len", "sei\u00b7nen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihm gewisse Rechnung machen,", "tokens": ["Ihm", "ge\u00b7wis\u00b7se", "Rech\u00b7nung", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Greifft sich mehr als vormahls an.", "tokens": ["Greifft", "sich", "mehr", "als", "vor\u00b7mahls", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "KOKOM", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Nun wird man nach Nahrung schawen,", "tokens": ["Nun", "wird", "man", "nach", "Nah\u00b7rung", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Felder, G\u00e4rten, H\u00e4user bawen,", "tokens": ["Fel\u00b7der", ",", "G\u00e4r\u00b7ten", ",", "H\u00e4u\u00b7ser", "ba\u00b7wen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Nun nach s\u00fcsser Heyraht stehn,", "tokens": ["Nun", "nach", "s\u00fcs\u00b7ser", "Hey\u00b7raht", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun wird hie in Glaubens-Wercken", "tokens": ["Nun", "wird", "hie", "in", "Glau\u00b7bens\u00b7\u00b7Wer\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch der Gottesdienst sich st\u00e4rcken", "tokens": ["Auch", "der", "Got\u00b7tes\u00b7dienst", "sich", "st\u00e4r\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das Recht im Schwange gehn.", "tokens": ["Und", "das", "Recht", "im", "Schwan\u00b7ge", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Hierbey trawren oder klagen", "tokens": ["Hier\u00b7bey", "traw\u00b7ren", "o\u00b7der", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVINF", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein Undanck so zu sagen,", "tokens": ["Ist", "ein", "Un\u00b7danck", "so", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutschland mu\u00df den langen Streit", "tokens": ["Deutschland", "mu\u00df", "den", "lan\u00b7gen", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "ART", "ADJA", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Wider Danck und Willen hegen,", "tokens": ["Wi\u00b7der", "Danck", "und", "Wil\u00b7len", "he\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist doch \u00fcber deinem Segen,", "tokens": ["Ist", "doch", "\u00fc\u00b7ber", "dei\u00b7nem", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "O ChurBrandenburgk, erfrewt.", "tokens": ["O", "Chur", "Bran\u00b7den\u00b7burgk", ",", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "NE", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Fleust der edle Rein gleich blutig,", "tokens": ["Fleust", "der", "ed\u00b7le", "Rein", "gleich", "blu\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die\u00dffals ist er dennoch muhtig,", "tokens": ["Die\u00df\u00b7fals", "ist", "er", "den\u00b7noch", "muh\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zieht es ihm zum Rhum und Pracht,", "tokens": ["Zieht", "es", "ihm", "zum", "Rhum", "und", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPRART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df der Trost so vieler Lande", "tokens": ["Da\u00df", "der", "Trost", "so", "vie\u00b7ler", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eben jetzt an seinem Rande", "tokens": ["E\u00b7ben", "jetzt", "an", "sei\u00b7nem", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist an dieses Licht gebracht.", "tokens": ["Ist", "an", "die\u00b7ses", "Licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Cleve kan sich nicht ergr\u00fcnden", "tokens": ["Cle\u00b7ve", "kan", "sich", "nicht", "er\u00b7gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch in dieses Gl\u00fcck recht finden,", "tokens": ["Noch", "in", "die\u00b7ses", "Gl\u00fcck", "recht", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wolte Rom nicht hie vor seyn,", "tokens": ["Wol\u00b7te", "Rom", "nicht", "hie", "vor", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PTKNEG", "ADV", "APPR", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es hat f\u00fcrwar zu prangen,", "tokens": ["Und", "es", "hat", "f\u00fcr\u00b7war", "zu", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn es stellte das Verlangen", "tokens": ["Denn", "es", "stell\u00b7te", "das", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grosser V\u00f6lcker hie sich ein.", "tokens": ["Gros\u00b7ser", "V\u00f6l\u00b7cker", "hie", "sich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PRF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Sey gegr\u00fcsst, O Prei\u00df der St\u00e4dte,", "tokens": ["Sey", "ge\u00b7gr\u00fcs\u00b7st", ",", "O", "Prei\u00df", "der", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "NE", "NN", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Gott erh\u00f6ret die Gebehte", "tokens": ["Gott", "er\u00b7h\u00f6\u00b7ret", "die", "Ge\u00b7beh\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner lieben Schar in dir,", "tokens": ["Sei\u00b7ner", "lie\u00b7ben", "Schar", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat mang tausent dich erkohren,", "tokens": ["Hat", "mang", "tau\u00b7sent", "dich", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schaw, es wird in dir gebohren,", "tokens": ["Schaw", ",", "es", "wird", "in", "dir", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsre Lust, der Helden Zier.", "tokens": ["Uns\u00b7re", "Lust", ",", "der", "Hel\u00b7den", "Zier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Gott m\u00fcss' allzeit dich erwehlen,", "tokens": ["Gott", "m\u00fcss'", "all\u00b7zeit", "dich", "er\u00b7weh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nie dir etwas lassen fehlen,", "tokens": ["Nie", "dir", "et\u00b7was", "las\u00b7sen", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werde seines Segens Zelt,", "tokens": ["Wer\u00b7de", "sei\u00b7nes", "Se\u00b7gens", "Zelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wachs an Ansehn, Leuten, Wahren", "tokens": ["Wachs", "an", "An\u00b7sehn", ",", "Leu\u00b7ten", ",", "Wah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und verkehr' in wenig Jahren", "tokens": ["Und", "ver\u00b7kehr'", "in", "we\u00b7nig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich, O Stadt, in eine Welt.", "tokens": ["Dich", ",", "O", "Stadt", ",", "in", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Schaw, wie sich an deinen Frewden", "tokens": ["Schaw", ",", "wie", "sich", "an", "dei\u00b7nen", "Frew\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PRF", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel grosse H\u00e4user weiden,", "tokens": ["So", "viel", "gros\u00b7se", "H\u00e4u\u00b7ser", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die Gro\u00df-Fraw-Mutter thut,", "tokens": ["Wie", "die", "Gro\u00df\u00b7Fra\u00b7wMut\u00b7ter", "thut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott ihr Lippen-Opffer bringet", "tokens": ["Gott", "ihr", "Lip\u00b7pen\u00b7Opf\u00b7fer", "brin\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und der Sternen Hitze zwinget", "tokens": ["Und", "der", "Ster\u00b7nen", "Hit\u00b7ze", "zwin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch der Andacht heisse Glut.", "tokens": ["Durch", "der", "An\u00b7dacht", "heis\u00b7se", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "C\u00f6lln erdencket newe Weisen,", "tokens": ["C\u00f6lln", "er\u00b7den\u00b7cket", "ne\u00b7we", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Wie Berlin auch Gott zu preisen,", "tokens": ["Wie", "Ber\u00b7lin", "auch", "Gott", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "NN", "PTKZU", "VVINF", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Holland wei\u00df jetzt keinen Streit", "tokens": ["Hol\u00b7land", "wei\u00df", "jetzt", "kei\u00b7nen", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wil aller Noht vergessen,", "tokens": ["Und", "wil", "al\u00b7ler", "Noht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wo bleibt Neuburgk, Churland, Hessen", "tokens": ["Wo", "bleibt", "Neu\u00b7burgk", ",", "Chur\u00b7land", ",", "Hes\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "VVFIN", "NN", "$,", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und was mehr sich hierob frewt?", "tokens": ["Und", "was", "mehr", "sich", "hier\u00b7ob", "frewt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PRF", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Jetzund thut mir erst von n\u00f6hten", "tokens": ["Je\u00b7tzund", "thut", "mir", "erst", "von", "n\u00f6h\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Zieraht der Poeten,", "tokens": ["Al\u00b7le", "Zier\u00b7aht", "der", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "O wer l\u00e4st mich Claudian,", "tokens": ["O", "wer", "l\u00e4st", "mich", "Clau\u00b7di\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Flaccus oder Maro werden?", "tokens": ["Flac\u00b7cus", "o\u00b7der", "Ma\u00b7ro", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich verliesse Volck und Erden,", "tokens": ["Ich", "ver\u00b7lies\u00b7se", "Volck", "und", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00fcrde stracks ein weisser Schwan.", "tokens": ["W\u00fcr\u00b7de", "stracks", "ein", "weis\u00b7ser", "Schwan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Oder hett' ich Ceres Drachen,", "tokens": ["O\u00b7der", "hett'", "ich", "Ce\u00b7res", "Dra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die mir w\u00fcsten Bahn zu machen,", "tokens": ["Die", "mir", "w\u00fcs\u00b7ten", "Bahn", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weg durch Wolcken, Lufft und Wind,", "tokens": ["Weg", "durch", "Wol\u00b7cken", ",", "Lufft", "und", "Wind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sollt ich nicht auff schnellem Wagen", "tokens": ["Sollt", "ich", "nicht", "auff", "schnel\u00b7lem", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00dcber Stern und Himmel tragen", "tokens": ["\u00dc\u00b7ber", "Stern", "und", "Him\u00b7mel", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich, du s\u00fcsses F\u00fcrsten-Kind?", "tokens": ["Dich", ",", "du", "s\u00fcs\u00b7ses", "F\u00fcrs\u00b7ten\u00b7Kind", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Deiner hohen Ahnen M\u00e4nge", "tokens": ["Dei\u00b7ner", "ho\u00b7hen", "Ah\u00b7nen", "M\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrden erstlich mein Gepr\u00e4nge,", "tokens": ["W\u00fcr\u00b7den", "erst\u00b7lich", "mein", "Ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deines Vaters Pracht st\u00fcnd hie", "tokens": ["Dei\u00b7nes", "Va\u00b7ters", "Pracht", "st\u00fcnd", "hie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deiner Mutter gegen\u00fcber,", "tokens": ["Dei\u00b7ner", "Mut\u00b7ter", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4re mir auch etwas lieber", "tokens": ["W\u00e4\u00b7re", "mir", "auch", "et\u00b7was", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als die Anmut solcher M\u00fch?", "tokens": ["Als", "die", "An\u00b7mut", "sol\u00b7cher", "M\u00fch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Hierauff s\u00e4ng ich das Verlangen", "tokens": ["Hier\u00b7auff", "s\u00e4ng", "ich", "das", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und den Wunsch, dich zu empfangen,", "tokens": ["Und", "den", "Wunsch", ",", "dich", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der nicht zu ergr\u00fcnden ist,", "tokens": ["Der", "nicht", "zu", "er\u00b7gr\u00fcn\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn du nicht k\u00f6mpst ungebehten,", "tokens": ["Denn", "du", "nicht", "k\u00f6mpst", "un\u00b7ge\u00b7beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "VVFIN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sondern wol in tausent St\u00e4dten", "tokens": ["Son\u00b7dern", "wol", "in", "tau\u00b7sent", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie von Gott erzwungen bist.", "tokens": ["Wie", "von", "Gott", "er\u00b7zwun\u00b7gen", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Nachmals r\u00fchmt' ich das Begn\u00fcgen", "tokens": ["Nach\u00b7mals", "r\u00fchmt'", "ich", "das", "Be\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Eltern, deine Wiegen,", "tokens": ["Dei\u00b7ner", "El\u00b7tern", ",", "dei\u00b7ne", "Wie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner Pflege grosse Trew,", "tokens": ["Dei\u00b7ner", "Pfle\u00b7ge", "gros\u00b7se", "Trew", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie erfrewt du angekommen,", "tokens": ["Wie", "er\u00b7frewt", "du", "an\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie man dich hab' auffgenommen", "tokens": ["Wie", "man", "dich", "hab'", "auff\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur mit Lieb' und Lust-Geschrey.", "tokens": ["Nur", "mit", "Lieb'", "und", "Lust\u00b7Ge\u00b7schrey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Nachmals wolt' ich k\u00fcndig machen,", "tokens": ["Nach\u00b7mals", "wolt'", "ich", "k\u00fcn\u00b7dig", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was von deines Lebens-Sachen", "tokens": ["Was", "von", "dei\u00b7nes", "Le\u00b7bens\u00b7Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das Verh\u00e4ngn\u00fc\u00df-Buch enth\u00e4lt,", "tokens": ["Das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df\u00b7Buch", "ent\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deinen Auffwachs, deine Jugend,", "tokens": ["Dei\u00b7nen", "Auff\u00b7wachs", ",", "dei\u00b7ne", "Ju\u00b7gend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deine ritterliche Tugend,", "tokens": ["Dei\u00b7ne", "rit\u00b7ter\u00b7li\u00b7che", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dein Verdienst in dieser Welt.", "tokens": ["Dein", "Ver\u00b7dienst", "in", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Aber die\u00df sind hohe Dinge,", "tokens": ["A\u00b7ber", "die\u00df", "sind", "ho\u00b7he", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich bin ihnen zu geringe,", "tokens": ["Ich", "bin", "ih\u00b7nen", "zu", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch Barleus Wissenschaft,", "tokens": ["Auch", "Bar\u00b7leus", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die nicht gnugsam zu erheben,", "tokens": ["Die", "nicht", "gnug\u00b7sam", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrd' er ietzt gleich wieder leben,", "tokens": ["W\u00fcrd'", "er", "ietzt", "gleich", "wie\u00b7der", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fehlt' es hie an Geist und Krafft.", "tokens": ["Fehlt'", "es", "hie", "an", "Geist", "und", "Krafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Wachs, O Kind, die gr\u00fcnen W\u00e4lder", "tokens": ["Wachs", ",", "O", "Kind", ",", "die", "gr\u00fc\u00b7nen", "W\u00e4l\u00b7der"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NE", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Frucht der schwangren Felder", "tokens": ["Und", "die", "Frucht", "der", "schwang\u00b7ren", "Fel\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4chst zu Wolgefallen dir,", "tokens": ["W\u00e4chst", "zu", "Wol\u00b7ge\u00b7fal\u00b7len", "dir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dann nicht, wann es pflegt zu schneyen,", "tokens": ["Dann", "nicht", ",", "wann", "es", "pflegt", "zu", "schne\u00b7yen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sondern in dem sch\u00f6nen Meyen", "tokens": ["Son\u00b7dern", "in", "dem", "sch\u00f6\u00b7nen", "Me\u00b7yen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Bistu, Wunsch der Sternen, hier.", "tokens": ["Bis\u00b7tu", ",", "Wunsch", "der", "Ster\u00b7nen", ",", "hier", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "ART", "NN", "$,", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Blumen, Gr\u00e4ser, Kr\u00e4uter, Bienen", "tokens": ["Blu\u00b7men", ",", "Gr\u00e4\u00b7ser", ",", "Kr\u00e4u\u00b7ter", ",", "Bie\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind bem\u00fcht dir auff zu dienen,", "tokens": ["Sind", "be\u00b7m\u00fcht", "dir", "auff", "zu", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "PPER", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heissen dich willkommen seyn,", "tokens": ["Heis\u00b7sen", "dich", "will\u00b7kom\u00b7men", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchen dich als ihrem Herren", "tokens": ["Su\u00b7chen", "dich", "als", "ih\u00b7rem", "Her\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle Lust-Th\u00f6r' auffzusperren,", "tokens": ["Al\u00b7le", "Lust\u00b7\u00b7T\u00b7h\u00f6r'", "auff\u00b7zu\u00b7sper\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Also gehst du zu uns ein.", "tokens": ["Al\u00b7so", "gehst", "du", "zu", "uns", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Da\u00df Gefl\u00fcgel l\u00e4sst sich h\u00f6ren,", "tokens": ["Da\u00df", "Ge\u00b7fl\u00fc\u00b7gel", "l\u00e4sst", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Singt auff unterschiednen Ch\u00f6ren,", "tokens": ["Singt", "auff", "un\u00b7ter\u00b7schied\u00b7nen", "Ch\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dich Kind, seinen Hertzog, an,", "tokens": ["Dich", "Kind", ",", "sei\u00b7nen", "Hert\u00b7zog", ",", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Kunst der Nachtigalen", "tokens": ["Und", "die", "Kunst", "der", "Nach\u00b7ti\u00b7ga\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kriegt den Prei\u00df f\u00fcr andern allen,", "tokens": ["Kriegt", "den", "Prei\u00df", "f\u00fcr", "an\u00b7dern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PIS", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und erhebt dich, wie sie kan.", "tokens": ["Und", "er\u00b7hebt", "dich", ",", "wie", "sie", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Werden wir durch deine Gaben", "tokens": ["Wer\u00b7den", "wir", "durch", "dei\u00b7ne", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Nicht ein stetes Vor-Jahr haben,", "tokens": ["Nicht", "ein", "ste\u00b7tes", "Vor\u00b7Jahr", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht ein Leben aller Ruh?", "tokens": ["Nicht", "ein", "Le\u00b7ben", "al\u00b7ler", "Ruh", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn die angenehme Zeiten,", "tokens": ["Denn", "die", "an\u00b7ge\u00b7neh\u00b7me", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche dich, O Kind, begleiten,", "tokens": ["Wel\u00b7che", "dich", ",", "O", "Kind", ",", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "$,", "NE", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sagen dieses gut' uns zu?", "tokens": ["Sa\u00b7gen", "die\u00b7ses", "gut'", "uns", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Eben jetzt wird allenthalben", "tokens": ["E\u00b7ben", "jetzt", "wird", "al\u00b7len\u00b7thal\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich der Geist von oben salben", "tokens": ["Dich", "der", "Geist", "von", "o\u00b7ben", "sal\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "APPR", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch das heilig-hohe Bad,", "tokens": ["Durch", "das", "hei\u00b7lig\u00b7ho\u00b7he", "Bad", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da sich Gott mit allem Segen", "tokens": ["Da", "sich", "Gott", "mit", "al\u00b7lem", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "NN", "APPR", "PIS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird in dein Gem\u00fcte legen,", "tokens": ["Wird", "in", "dein", "Ge\u00b7m\u00fc\u00b7te", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df du wandelst seinen Pfad.", "tokens": ["Da\u00df", "du", "wan\u00b7delst", "sei\u00b7nen", "Pfad", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Du entsagst den b\u00f6sen L\u00fcsten,", "tokens": ["Du", "ent\u00b7sagst", "den", "b\u00f6\u00b7sen", "L\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4ssest dich mit Warheit r\u00fcsten", "tokens": ["L\u00e4s\u00b7sest", "dich", "mit", "War\u00b7heit", "r\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wieder Satans Tyranney,", "tokens": ["Wie\u00b7der", "Sa\u00b7tans", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hebst dein Hertz von aller Erden", "tokens": ["Hebst", "dein", "Hertz", "von", "al\u00b7ler", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gar ein newer Mensch zu werden,", "tokens": ["Gar", "ein", "ne\u00b7wer", "Mensch", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Der nach Gott geschaffen sey.", "tokens": ["Der", "nach", "Gott", "ge\u00b7schaf\u00b7fen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Bist ein F\u00fcrst zwar von Gebl\u00fcte,", "tokens": ["Bist", "ein", "F\u00fcrst", "zwar", "von", "Ge\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ein Keyser im Gem\u00fcte,", "tokens": ["Doch", "ein", "Key\u00b7ser", "im", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlachtst du deinem Vater nach,", "tokens": ["Schlachtst", "du", "dei\u00b7nem", "Va\u00b7ter", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dessen unbeflecktes Leben", "tokens": ["Des\u00b7sen", "un\u00b7be\u00b7fleck\u00b7tes", "Le\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Glimpff und Wei\u00dfheit zu erheben", "tokens": ["Glimpff", "und", "Wei\u00df\u00b7heit", "zu", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Redner Kunst zu schwach.", "tokens": ["Al\u00b7ler", "Red\u00b7ner", "Kunst", "zu", "schwach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "PTKZU", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Der wird dich in gleichen Sachen", "tokens": ["Der", "wird", "dich", "in", "glei\u00b7chen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Durch die Zucht Ihm \u00e4hnlich machen,", "tokens": ["Durch", "die", "Zucht", "Ihm", "\u00e4hn\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch der Mutter hoher Flei\u00df", "tokens": ["Auch", "der", "Mut\u00b7ter", "ho\u00b7her", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird zu allem Wesen sehen:", "tokens": ["Wird", "zu", "al\u00b7lem", "We\u00b7sen", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIS", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was wir bitten oder flehen", "tokens": ["Was", "wir", "bit\u00b7ten", "o\u00b7der", "fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVINF", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist dein Auffwachs, Zier und Prei\u00df.", "tokens": ["Ist", "dein", "Auff\u00b7wachs", ",", "Zier", "und", "Prei\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Also wirstu Ruh' und Frommen", "tokens": ["Al\u00b7so", "wirs\u00b7tu", "Ruh'", "und", "From\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denen seyn, die nach uns kommen,", "tokens": ["De\u00b7nen", "seyn", ",", "die", "nach", "uns", "kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAINF", "$,", "PRELS", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zwar hie im Segen stehn,", "tokens": ["Und", "zwar", "hie", "im", "Se\u00b7gen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Aber dort, wenn du in Frieden,", "tokens": ["A\u00b7ber", "dort", ",", "wenn", "du", "in", "Frie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alt und Welt-satt abgeschieden,", "tokens": ["Alt", "und", "Welt\u00b7satt", "ab\u00b7ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcber alle Hoheit gehn.", "tokens": ["\u00dc\u00b7ber", "al\u00b7le", "Ho\u00b7heit", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Und du Blume von Nassowen,", "tokens": ["Und", "du", "Blu\u00b7me", "von", "Nas\u00b7so\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "APPR", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Als die Welt ie k\u00f6nnen schauen,", "tokens": ["Als", "die", "Welt", "ie", "k\u00f6n\u00b7nen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "O Loyse, sey erfrewt,", "tokens": ["O", "Loy\u00b7se", ",", "sey", "er\u00b7frewt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und la\u00df neben uns den deinen", "tokens": ["Und", "la\u00df", "ne\u00b7ben", "uns", "den", "dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "APPR", "PPER", "ART", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ehr' und Danck vor Gott' erscheinen", "tokens": ["Ehr'", "und", "Danck", "vor", "Gott'", "er\u00b7schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wegen deiner Fruchtbarheit.", "tokens": ["We\u00b7gen", "dei\u00b7ner", "Frucht\u00b7bar\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Also wirst du nun un\u00df Preussen", "tokens": ["Al\u00b7so", "wirst", "du", "nun", "un\u00df", "Preus\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch so hoch gesegnet heissen.", "tokens": ["Noch", "so", "hoch", "ge\u00b7seg\u00b7net", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVPP", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird es denn nicht bald geschehn?", "tokens": ["Wird", "es", "denn", "nicht", "bald", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6mmt die Stunde nicht geschwinde,", "tokens": ["K\u00f6mmt", "die", "Stun\u00b7de", "nicht", "ge\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df wir dich sampt deinem Kinde,", "tokens": ["Da\u00df", "wir", "dich", "sampt", "dei\u00b7nem", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grosse Mutter, werden sehn?", "tokens": ["Gros\u00b7se", "Mut\u00b7ter", ",", "wer\u00b7den", "sehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "K\u00fcss' indessen auff die Schmertzen", "tokens": ["K\u00fcss'", "in\u00b7des\u00b7sen", "auff", "die", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deinen liebsten Sohn von Hertzen,", "tokens": ["Dei\u00b7nen", "liebs\u00b7ten", "Sohn", "von", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Er bezahlt dir gnug die Noht,", "tokens": ["Er", "be\u00b7zahlt", "dir", "gnug", "die", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er verbindet auch die Wunden,", "tokens": ["Er", "ver\u00b7bin\u00b7det", "auch", "die", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die du, Heldinn, hast empfunden", "tokens": ["Die", "du", ",", "Hel\u00b7dinn", ",", "hast", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "$,", "NN", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch des hohen Vaters Todt.", "tokens": ["Durch", "des", "ho\u00b7hen", "Va\u00b7ters", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Gott wird ferner uns erh\u00f6ren,", "tokens": ["Gott", "wird", "fer\u00b7ner", "uns", "er\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Brandenburgk durch dich vermehren", "tokens": ["Bran\u00b7den\u00b7burgk", "durch", "dich", "ver\u00b7meh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als die Stern' am Himmels-Saal,", "tokens": ["Als", "die", "Stern'", "am", "Him\u00b7mels\u00b7Saal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil es zimlich abgenommen,", "tokens": ["Weil", "es", "zim\u00b7lich", "ab\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber nun empor sol kommen,", "tokens": ["A\u00b7ber", "nun", "em\u00b7por", "sol", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist mir recht, zum dritten mal.", "tokens": ["Ist", "mir", "recht", ",", "zum", "drit\u00b7ten", "mal", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "APPRART", "ADJA", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Du nur wollest dieses Wesen", "tokens": ["Du", "nur", "wol\u00b7lest", "die\u00b7ses", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner trewen Einfalt lesen", "tokens": ["Mei\u00b7ner", "tre\u00b7wen", "Ein\u00b7falt", "le\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fr\u00f6lich, gn\u00e4digst, ohn Verdru\u00df,", "tokens": ["Fr\u00f6\u00b7lich", ",", "gn\u00e4\u00b7digst", ",", "ohn", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach den Niederl\u00e4nder-Schw\u00e4nen", "tokens": ["Nach", "den", "Nie\u00b7der\u00b7l\u00e4n\u00b7der\u00b7Schw\u00e4\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich nun einer Gan\u00df gewehnen,", "tokens": ["Dich", "nun", "ei\u00b7ner", "Gan\u00df", "ge\u00b7weh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die in Preussen schnattern mu\u00df.", "tokens": ["Die", "in", "Preus\u00b7sen", "schnat\u00b7tern", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Aber auch von Dir zu sagen,", "tokens": ["A\u00b7ber", "auch", "von", "Dir", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ChurF\u00fcrst, s\u00fcsses Wolbehagen", "tokens": ["Chur", "F\u00fcrst", ",", "s\u00fcs\u00b7ses", "Wol\u00b7be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deines Himmels und der Welt,", "tokens": ["Dei\u00b7nes", "Him\u00b7mels", "und", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was f\u00fcr Pflicht ist zu erdencken,", "tokens": ["Was", "f\u00fcr", "Pflicht", "ist", "zu", "er\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So wir deiner Gnade schencken,", "tokens": ["So", "wir", "dei\u00b7ner", "Gna\u00b7de", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die uns so umbschlossen h\u00e4lt?", "tokens": ["Die", "uns", "so", "umbsc\u00b7hlos\u00b7sen", "h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.53": {"line.1": {"text": "Dich der blossen Wollust wegen", "tokens": ["Dich", "der", "blos\u00b7sen", "Wol\u00b7lust", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Liebe Joch zu legen,", "tokens": ["In", "der", "Lie\u00b7be", "Joch", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist von dir ein falscher Wahn,", "tokens": ["Ist", "von", "dir", "ein", "fal\u00b7scher", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn wer hat nicht gnug erfahren,", "tokens": ["Denn", "wer", "hat", "nicht", "gnug", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df du in den zarten Jahren", "tokens": ["Da\u00df", "du", "in", "den", "zar\u00b7ten", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Solche Lust von dir gethan?", "tokens": ["Sol\u00b7che", "Lust", "von", "dir", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Kuntte dir nicht dies zu treiben", "tokens": ["Kunt\u00b7te", "dir", "nicht", "dies", "zu", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "PDS", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fug' und Freyheit gnug erl\u00e4uben", "tokens": ["Fug'", "und", "Frey\u00b7heit", "gnug", "er\u00b7l\u00e4u\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als kaum einem? aber nein.", "tokens": ["Als", "kaum", "ei\u00b7nem", "?", "a\u00b7ber", "nein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "$.", "ADV", "PTKANT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Du gedachtst dich einzuschliessen,", "tokens": ["Du", "ge\u00b7dachtst", "dich", "ein\u00b7zu\u00b7schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und dir selber im Gewissen", "tokens": ["Und", "dir", "sel\u00b7ber", "im", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Aller L\u00fcste Zwang zu seyn.", "tokens": ["Al\u00b7ler", "L\u00fcs\u00b7te", "Zwang", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Darumb trugst du dich mit Sorgen", "tokens": ["Da\u00b7rumb", "trugst", "du", "dich", "mit", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "APPR", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Deiner Herrschaft von dem Morgen", "tokens": ["Dei\u00b7ner", "Herr\u00b7schaft", "von", "dem", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bi\u00df auf sp\u00e4ten Abend zu:", "tokens": ["Bi\u00df", "auf", "sp\u00e4\u00b7ten", "A\u00b7bend", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchtst du aber dein Ergetzen,", "tokens": ["Suchtst", "du", "a\u00b7ber", "dein", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+++-", "measure": "unknown.measure.penta"}, "line.5": {"text": "So war reiten, jagen, hetzen", "tokens": ["So", "war", "rei\u00b7ten", ",", "ja\u00b7gen", ",", "het\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "VVFIN", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der Garten deine Ruh.", "tokens": ["Und", "der", "Gar\u00b7ten", "dei\u00b7ne", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.56": {"line.1": {"text": "Venus gab schon gantz verlohren,", "tokens": ["Ve\u00b7nus", "gab", "schon", "gantz", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Amor hielte sich beschworen,", "tokens": ["A\u00b7mor", "hiel\u00b7te", "sich", "be\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir erschracken und dein Hau\u00df,", "tokens": ["Wir", "er\u00b7schra\u00b7cken", "und", "dein", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bi\u00df dein Hertz zur\u00fcck gedencket,", "tokens": ["Bi\u00df", "dein", "Hertz", "zu\u00b7r\u00fcck", "ge\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sich zu s\u00fcsser Heyraht lencket", "tokens": ["Sich", "zu", "s\u00fcs\u00b7ser", "Hey\u00b7raht", "len\u00b7cket"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und macht diesen Schlu\u00df darau\u00df.", "tokens": ["Und", "macht", "die\u00b7sen", "Schlu\u00df", "dar\u00b7au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.57": {"line.1": {"text": "Sonst ist auch dein Thun und Sinnen,", "tokens": ["Sonst", "ist", "auch", "dein", "Thun", "und", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Held, dein lassen und Beginnen", "tokens": ["Held", ",", "dein", "las\u00b7sen", "und", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "VVINF", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts als Gottes Ehr' und wir,", "tokens": ["Nichts", "als", "Got\u00b7tes", "Ehr'", "und", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "NN", "NN", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ein Welt-Buch von zu schreiben,", "tokens": ["Da", "ein", "Welt\u00b7Buch", "von", "zu", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich mu\u00df solches lassen bleiben", "tokens": ["Ich", "mu\u00df", "sol\u00b7ches", "las\u00b7sen", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dein Ernst verbeut es mir.", "tokens": ["Und", "dein", "Ernst", "ver\u00b7beut", "es", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Herr, was haben wir dir dessen", "tokens": ["Herr", ",", "was", "ha\u00b7ben", "wir", "dir", "des\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "VAFIN", "PPER", "PPER", "PDS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcr Vergeltung zuzum\u00e4ssen?", "tokens": ["F\u00fcr", "Ver\u00b7gel\u00b7tung", "zu\u00b7zu\u00b7m\u00e4s\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gott bezahl' es umb und an,", "tokens": ["Gott", "be\u00b7zahl'", "es", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dessen Hertz' in deinen Gaben,", "tokens": ["Des\u00b7sen", "Hertz'", "in", "dei\u00b7nen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als auch F\u00fcrsten k\u00f6nnen haben,", "tokens": ["Als", "auch", "F\u00fcrs\u00b7ten", "k\u00f6n\u00b7nen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich vergn\u00fcget spiegeln kan!", "tokens": ["Sich", "ver\u00b7gn\u00fc\u00b7get", "spie\u00b7geln", "kan", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Wie da\u00df der Himmel sich vernewert sampt der Erden?", "tokens": ["Wie", "da\u00df", "der", "Him\u00b7mel", "sich", "ver\u00b7ne\u00b7wert", "sampt", "der", "Er\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "PRF", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ein F\u00fcrst, die Lust der Welt, wird an dies Licht gebracht.", "tokens": ["Ein", "F\u00fcrst", ",", "die", "Lust", "der", "Welt", ",", "wird", "an", "dies", "Licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,", "VAFIN", "APPR", "PDS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wendstu das Vor-Jahr ein? Er k\u00e4m' umb l\u00e4ngste Nacht,", "tokens": ["Wend\u00b7stu", "das", "Vor\u00b7Jahr", "ein", "?", "Er", "k\u00e4m'", "umb", "l\u00e4ngs\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Winter w\u00fcrd' ihm stracks ein sch\u00f6ner Fr\u00fcling werden.", "tokens": ["Der", "Win\u00b7ter", "w\u00fcrd'", "ihm", "stracks", "ein", "sch\u00f6\u00b7ner", "Fr\u00fc\u00b7ling", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "Also hat uns Gott in Gnaden", "tokens": ["Al\u00b7so", "hat", "uns", "Gott", "in", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nun auch dieser Furcht entladen,", "tokens": ["Nun", "auch", "die\u00b7ser", "Furcht", "ent\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heldinn, durch den thewren Gast,", "tokens": ["Hel\u00b7dinn", ",", "durch", "den", "thew\u00b7ren", "Gast", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den du zwar besorgt getragen,", "tokens": ["Den", "du", "zwar", "be\u00b7sorgt", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber in den Meyen-Tagen", "tokens": ["A\u00b7ber", "in", "den", "Meyen\u00b7Ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.6": {"text": "Newlich froh gebohren hast.", "tokens": ["New\u00b7lich", "froh", "ge\u00b7boh\u00b7ren", "hast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "O der so gew\u00fcnschten Stunden,", "tokens": ["O", "der", "so", "ge\u00b7w\u00fcnschten", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die, O Churf\u00fcrstinn, entbunden", "tokens": ["Die", ",", "O", "Chur\u00b7f\u00fcrs\u00b7tinn", ",", "ent\u00b7bun\u00b7den"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "$,", "NE", "NN", "$,", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dich der B\u00fcrd' und uns der Noht,", "tokens": ["Dich", "der", "B\u00fcrd'", "und", "uns", "der", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "KON", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns, die unser grosse K\u00f6nig", "tokens": ["Uns", ",", "die", "un\u00b7ser", "gros\u00b7se", "K\u00f6\u00b7nig"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eben dazumahl nicht wenig", "tokens": ["E\u00b7ben", "da\u00b7zu\u00b7mahl", "nicht", "we\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat betr\u00fcbt durch seinen Todt.", "tokens": ["Hat", "be\u00b7tr\u00fcbt", "durch", "sei\u00b7nen", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Das Verlangen, so wir trieben,", "tokens": ["Das", "Ver\u00b7lan\u00b7gen", ",", "so", "wir", "trie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird durch keines Faust beschrieben,", "tokens": ["Wird", "durch", "kei\u00b7nes", "Faust", "be\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "St\u00fcndlich fast kam Zeitung ein,", "tokens": ["St\u00fcnd\u00b7lich", "fast", "kam", "Zei\u00b7tung", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVFIN", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja, es ist in dreyen Wochen", "tokens": ["Ja", ",", "es", "ist", "in", "drey\u00b7en", "Wo\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nichts ohn die\u00df allein gesprochen:", "tokens": ["Nichts", "ohn", "die\u00df", "al\u00b7lein", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PDS", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die Geburt soll richtig seyn.", "tokens": ["Die", "Ge\u00b7burt", "soll", "rich\u00b7tig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Wer hat aber unterdessen", "tokens": ["Wer", "hat", "a\u00b7ber", "un\u00b7ter\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Des Gebehtes hie vergessen?", "tokens": ["Des", "Ge\u00b7beh\u00b7tes", "hie", "ver\u00b7ges\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die\u00df war aller Kirchen Thon,", "tokens": ["Die\u00df", "war", "al\u00b7ler", "Kir\u00b7chen", "Thon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Unsre Seufftzer, unsre Lieder,", "tokens": ["Uns\u00b7re", "Seufft\u00b7zer", ",", "uns\u00b7re", "Lie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die wir sungen hin und wieder,", "tokens": ["Die", "wir", "sun\u00b7gen", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "PTKVZ", "KON", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Waren nur umb diesen Sohn.", "tokens": ["Wa\u00b7ren", "nur", "umb", "die\u00b7sen", "Sohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Gott hab' jetzund unser Flehen", "tokens": ["Gott", "hab'", "je\u00b7tzund", "un\u00b7ser", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder sonst was angesehen,", "tokens": ["O\u00b7der", "sonst", "was", "an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wol, du hohe Mutter, dir!", "tokens": ["Wol", ",", "du", "ho\u00b7he", "Mut\u00b7ter", ",", "dir", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PPER", "ADJA", "NN", "$,", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Den du untter keuschem Hertzen,", "tokens": ["Den", "du", "unt\u00b7ter", "keu\u00b7schem", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gott und du weist mit was Schmertzen,", "tokens": ["Gott", "und", "du", "weist", "mit", "was", "Schmert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PPER", "VVFIN", "APPR", "PRELS", "NN", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.6": {"text": "So viel Monden trugst, ist hier.", "tokens": ["So", "viel", "Mon\u00b7den", "trugst", ",", "ist", "hier", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "VAFIN", "ADV", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.65": {"line.1": {"text": "Wol auch uns und unserm Lande,", "tokens": ["Wol", "auch", "uns", "und", "un\u00b7serm", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dem sich Gott in diesem Pfande", "tokens": ["Dem", "sich", "Gott", "in", "die\u00b7sem", "Pfan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRF", "NN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner Gunst versichert h\u00e4lt,", "tokens": ["Sei\u00b7ner", "Gunst", "ver\u00b7si\u00b7chert", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nun unsrer Hoffnung Tritten,", "tokens": ["Und", "nun", "uns\u00b7rer", "Hoff\u00b7nung", "Trit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die bi\u00dfher so sehr geglitten,", "tokens": ["Die", "bi\u00df\u00b7her", "so", "sehr", "ge\u00b7glit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen festen Grund gestellt.", "tokens": ["Ei\u00b7nen", "fes\u00b7ten", "Grund", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "Seine Huld wil uns nicht lassen,", "tokens": ["Sei\u00b7ne", "Huld", "wil", "uns", "nicht", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Recht als wir bek\u00fcmmert sassen,", "tokens": ["Recht", "als", "wir", "be\u00b7k\u00fcm\u00b7mert", "sas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weinten: Unsers Hauptes Pracht", "tokens": ["Wein\u00b7ten", ":", "Un\u00b7sers", "Haup\u00b7tes", "Pracht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat uns gute Nacht gegeben,", "tokens": ["Hat", "uns", "gu\u00b7te", "Nacht", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ward' uns dein' Entbindung eben", "tokens": ["Ward'", "uns", "dein'", "Ent\u00b7bin\u00b7dung", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fern aus Cleve zugebracht.", "tokens": ["Fern", "aus", "Cle\u00b7ve", "zu\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Wie in starcken Donnerschl\u00e4gen,", "tokens": ["Wie", "in", "star\u00b7cken", "Don\u00b7ner\u00b7schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In Gew\u00f6lck', in Sturm und Regen", "tokens": ["In", "Ge\u00b7w\u00f6lck'", ",", "in", "Sturm", "und", "Re\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns die liebe Sonne thut,", "tokens": ["Uns", "die", "lie\u00b7be", "Son\u00b7ne", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Also mitten in dem Leide", "tokens": ["Al\u00b7so", "mit\u00b7ten", "in", "dem", "Lei\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "War uns \u00fcber dieser Frewde", "tokens": ["War", "uns", "\u00fc\u00b7ber", "die\u00b7ser", "Frew\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch umb selbe Zeit zu muth.", "tokens": ["Auch", "umb", "sel\u00b7be", "Zeit", "zu", "muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Anfangs wolte man nicht trawen,", "tokens": ["An\u00b7fangs", "wol\u00b7te", "man", "nicht", "tra\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Was wir mit Verlangen schawen,", "tokens": ["Was", "wir", "mit", "Ver\u00b7lan\u00b7gen", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wird mit Sorg' und Furcht gegl\u00e4ubt,", "tokens": ["Wird", "mit", "Sor\u00b7g'", "und", "Furcht", "ge\u00b7gl\u00e4ubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Bi\u00df die Warheit wird erlesen,", "tokens": ["Bi\u00df", "die", "War\u00b7heit", "wird", "er\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und von diesem lieben Wesen", "tokens": ["Und", "von", "die\u00b7sem", "lie\u00b7ben", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Eine Post die andre treibt.", "tokens": ["Ei\u00b7ne", "Post", "die", "and\u00b7re", "treibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "Als sie aber nun erschollen,", "tokens": ["Als", "sie", "a\u00b7ber", "nun", "er\u00b7schol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tte man hie sehen sollen", "tokens": ["H\u00e4t\u00b7te", "man", "hie", "se\u00b7hen", "sol\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Alles Land in Frewde stehn,", "tokens": ["Al\u00b7les", "Land", "in", "Frew\u00b7de", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich mit diesen wehrten Sachen", "tokens": ["Sich", "mit", "die\u00b7sen", "wehr\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Hin und Her beheglich machen,", "tokens": ["Hin", "und", "Her", "be\u00b7heg\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Einen Freund zum andern gehn.", "tokens": ["Ei\u00b7nen", "Freund", "zum", "an\u00b7dern", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Niemand kan was anders sprechen", "tokens": ["Nie\u00b7mand", "kan", "was", "an\u00b7ders", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PIS", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff der B\u00f6r\u00df', in den Gel\u00e4chen.", "tokens": ["Auff", "der", "B\u00f6r\u00df'", ",", "in", "den", "Ge\u00b7l\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Krancken selbs ist hievon woll,", "tokens": ["Kran\u00b7cken", "selbs", "ist", "hie\u00b7von", "woll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PAV", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie Krafft und Leben fassen,", "tokens": ["Da\u00df", "sie", "Krafft", "und", "Le\u00b7ben", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "G\u00e4rtten, Junckerh\u00f6ff' und Gassen", "tokens": ["G\u00e4rt\u00b7ten", ",", "Jun\u00b7cker\u00b7h\u00f6ff'", "und", "Gas\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind von dieser Zeitung voll.", "tokens": ["Sind", "von", "die\u00b7ser", "Zei\u00b7tung", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Erst ist in der Frommen Orden", "tokens": ["Erst", "ist", "in", "der", "From\u00b7men", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Gott hievor gepriesen worden,", "tokens": ["Gott", "hie\u00b7vor", "ge\u00b7prie\u00b7sen", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "VVPP", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gesagt, da\u00df seiner Trew", "tokens": ["Und", "ge\u00b7sagt", ",", "da\u00df", "sei\u00b7ner", "Trew"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVPP", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einig die\u00dffals sey zu dancken,", "tokens": ["Ei\u00b7nig", "die\u00df\u00b7fals", "sey", "zu", "dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als die H\u00e4user, so schon wancken,", "tokens": ["Als", "die", "H\u00e4u\u00b7ser", ",", "so", "schon", "wan\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder durch Geburt erfrew'.", "tokens": ["Wie\u00b7der", "durch", "Ge\u00b7burt", "er\u00b7fre\u00b7w'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.72": {"line.1": {"text": "Hierauff geben ungehewer", "tokens": ["Hier\u00b7auff", "ge\u00b7ben", "un\u00b7ge\u00b7he\u00b7wer"], "token_info": ["word", "word", "word"], "pos": ["PAV", "VVINF", "ADJD"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Beydes Schloss und Freyheit Fewer.", "tokens": ["Bey\u00b7des", "Schloss", "und", "Frey\u00b7heit", "Fe\u00b7wer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lochst\u00e4t, Pillaw, See, die Fluth", "tokens": ["Lochs\u00b7t\u00e4t", ",", "Pil\u00b7law", ",", "See", ",", "die", "Fluth"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Beyder H\u00e4b' und ihre Tieffe,", "tokens": ["Bey\u00b7der", "H\u00e4b'", "und", "ih\u00b7re", "Tief\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und die tausent frembden Schiffe", "tokens": ["Und", "die", "tau\u00b7sent", "fremb\u00b7den", "Schif\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stehn in Nebel, Dampff und Glut.", "tokens": ["Stehn", "in", "Ne\u00b7bel", ",", "Dampff", "und", "Glut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.73": {"line.1": {"text": "Wa\u00df? der Br\u00fcckenreiche Pregel", "tokens": ["Wa\u00df", "?", "der", "Br\u00fc\u00b7cken\u00b7rei\u00b7che", "Pre\u00b7gel"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hebt durch Flaggen, M\u00e4st' und Segel", "tokens": ["Hebt", "durch", "Flag\u00b7gen", ",", "M\u00e4st'", "und", "Se\u00b7gel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein beschilfftes Haupt empor,", "tokens": ["Sein", "be\u00b7schilff\u00b7tes", "Haupt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nachdem er angesehen,", "tokens": ["Und", "nach\u00b7dem", "er", "an\u00b7ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was und warumb es geschehen,", "tokens": ["Was", "und", "wa\u00b7rumb", "es", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "KON", "PWAV", "PPER", "VVPP", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "L\u00e4ufft er schneller als zuvor.", "tokens": ["L\u00e4ufft", "er", "schnel\u00b7ler", "als", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "KOKOM", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "Thetis schickt die Germawinnen", "tokens": ["The\u00b7tis", "schickt", "die", "Ger\u00b7ma\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die sch\u00f6nen Dirschkeiminnen", "tokens": ["Und", "die", "sch\u00f6\u00b7nen", "Dirschkei\u00b7min\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Au\u00df den Wellen an das Land,", "tokens": ["Au\u00df", "den", "Wel\u00b7len", "an", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die an ihrem West sich k\u00fchlen", "tokens": ["Die", "an", "ih\u00b7rem", "West", "sich", "k\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch seine Freundschafft sp\u00fclen", "tokens": ["Und", "durch", "sei\u00b7ne", "Freund\u00b7schafft", "sp\u00fc\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grossen Birnstein an den Rand.", "tokens": ["Gros\u00b7sen", "Birn\u00b7stein", "an", "den", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "Phyllis schickt Sylvanen Kr\u00e4ntze,", "tokens": ["Phyl\u00b7lis", "schickt", "Syl\u00b7va\u00b7nen", "Kr\u00e4nt\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Nymfen f\u00fchren T\u00e4ntze,", "tokens": ["Al\u00b7le", "Nym\u00b7fen", "f\u00fch\u00b7ren", "T\u00e4nt\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre Furcht, der geile Pan,", "tokens": ["Ih\u00b7re", "Furcht", ",", "der", "gei\u00b7le", "Pan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Geht nicht minder stets im Reyen", "tokens": ["Geht", "nicht", "min\u00b7der", "stets", "im", "Re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ADV", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und auff seiner Wald-Schalmeyen", "tokens": ["Und", "auff", "sei\u00b7ner", "Wald\u00b7Schal\u00b7meyen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Singt er hievon was er kan.", "tokens": ["Singt", "er", "hie\u00b7von", "was", "er", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "PWS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.76": {"line.1": {"text": "Der Lust noch nicht zu gedencken,", "tokens": ["Der", "Lust", "noch", "nicht", "zu", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Die sich in Gesundheit-Tr\u00e4ncken,", "tokens": ["Die", "sich", "in", "Ge\u00b7sund\u00b7heit\u00b7Tr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und im Frewden-Brand' erregt,", "tokens": ["Und", "im", "Fre\u00b7wden\u00b7Brand'", "er\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "So die gantze Nacht durch wehrte", "tokens": ["So", "die", "gant\u00b7ze", "Nacht", "durch", "wehr\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und, weil ihn der P\u00f6fel n\u00e4hrte,", "tokens": ["Und", ",", "weil", "ihn", "der", "P\u00f6\u00b7fel", "n\u00e4hr\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Kaum fr\u00fch Morgens sich gelegt!", "tokens": ["Kaum", "fr\u00fch", "Mor\u00b7gens", "sich", "ge\u00b7legt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.77": {"line.1": {"text": "Lasst uns treiben was wir k\u00f6nnen,", "tokens": ["Lasst", "uns", "trei\u00b7ben", "was", "wir", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil es Gott uns scheint zu g\u00f6nnen,", "tokens": ["Weil", "es", "Gott", "uns", "scheint", "zu", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Also mu\u00df die Furcht und Pein,", "tokens": ["Al\u00b7so", "mu\u00df", "die", "Furcht", "und", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der wir in verwichnen Jahren", "tokens": ["Der", "wir", "in", "ver\u00b7wich\u00b7nen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gnug uns pflagen zu befahren,", "tokens": ["Gnug", "uns", "pfla\u00b7gen", "zu", "be\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nun einmal bezahlet seyn.", "tokens": ["Nun", "ein\u00b7mal", "be\u00b7zah\u00b7let", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.78": {"line.1": {"text": "Auch du, K\u00f6niglicher Schatten,", "tokens": ["Auch", "du", ",", "K\u00f6\u00b7nig\u00b7li\u00b7cher", "Schat\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirst uns diese Lust verstatten,", "tokens": ["Wirst", "uns", "die\u00b7se", "Lust", "ver\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unser Hertz ist dir bekant,", "tokens": ["Un\u00b7ser", "Hertz", "ist", "dir", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Himmel, deine Wonne,", "tokens": ["Und", "der", "Him\u00b7mel", ",", "dei\u00b7ne", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da dich kr\u00f6hnet Licht und Sonne,", "tokens": ["Da", "dich", "kr\u00f6h\u00b7net", "Licht", "und", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wei\u00df umb unsern Trawer-Standt.", "tokens": ["Wei\u00df", "umb", "un\u00b7sern", "Tra\u00b7wer\u00b7Standt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "Allzeit wird man dir gewehren", "tokens": ["All\u00b7zeit", "wird", "man", "dir", "ge\u00b7weh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jammer, Hertzens-Angst und Zehren,", "tokens": ["Jam\u00b7mer", ",", "Hert\u00b7zens\u00b7Angst", "und", "Zeh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unsre Mawer wahrest du,", "tokens": ["Uns\u00b7re", "Ma\u00b7wer", "wah\u00b7rest", "du", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unser Trost in M\u00fch und Sorgen,", "tokens": ["Un\u00b7ser", "Trost", "in", "M\u00fch", "und", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wider Mitternacht und Morgen", "tokens": ["Wi\u00b7der", "Mit\u00b7ter\u00b7nacht", "und", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Halffst du uns mit Schutz und Ruh.", "tokens": ["Halffst", "du", "uns", "mit", "Schutz", "und", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "Nur verzeih, da\u00df man die Klage", "tokens": ["Nur", "ver\u00b7zeih", ",", "da\u00df", "man", "die", "Kla\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PIS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was verscheubt an diesem Tage,", "tokens": ["Was", "ver\u00b7scheubt", "an", "die\u00b7sem", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da ein newes Licht uns strahlt,", "tokens": ["Da", "ein", "ne\u00b7wes", "Licht", "uns", "strahlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und die Nacht bekr\u00e4nckter Hertzen", "tokens": ["Und", "die", "Nacht", "be\u00b7kr\u00e4nck\u00b7ter", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch die angenehme Kertzen", "tokens": ["Durch", "die", "an\u00b7ge\u00b7neh\u00b7me", "Kert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wolgegr\u00fcndter Hoffnung mahlt.", "tokens": ["Wol\u00b7ge\u00b7gr\u00fcnd\u00b7ter", "Hoff\u00b7nung", "mahlt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.81": {"line.1": {"text": "Denn von nun an wird sich Leben,", "tokens": ["Denn", "von", "nun", "an", "wird", "sich", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "APZR", "VAFIN", "PRF", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Geist und Muth erst recht erheben,", "tokens": ["Geist", "und", "Muth", "erst", "recht", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nun verj\u00fcngt sich jedermann,", "tokens": ["Nun", "ver\u00b7j\u00fcngt", "sich", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kan von allen seinen Sachen", "tokens": ["Kan", "von", "al\u00b7len", "sei\u00b7nen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihm gewisse Rechnung machen,", "tokens": ["Ihm", "ge\u00b7wis\u00b7se", "Rech\u00b7nung", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Greifft sich mehr als vormahls an.", "tokens": ["Greifft", "sich", "mehr", "als", "vor\u00b7mahls", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "KOKOM", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.82": {"line.1": {"text": "Nun wird man nach Nahrung schawen,", "tokens": ["Nun", "wird", "man", "nach", "Nah\u00b7rung", "scha\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Felder, G\u00e4rten, H\u00e4user bawen,", "tokens": ["Fel\u00b7der", ",", "G\u00e4r\u00b7ten", ",", "H\u00e4u\u00b7ser", "ba\u00b7wen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Nun nach s\u00fcsser Heyraht stehn,", "tokens": ["Nun", "nach", "s\u00fcs\u00b7ser", "Hey\u00b7raht", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nun wird hie in Glaubens-Wercken", "tokens": ["Nun", "wird", "hie", "in", "Glau\u00b7bens\u00b7\u00b7Wer\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch der Gottesdienst sich st\u00e4rcken", "tokens": ["Auch", "der", "Got\u00b7tes\u00b7dienst", "sich", "st\u00e4r\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und das Recht im Schwange gehn.", "tokens": ["Und", "das", "Recht", "im", "Schwan\u00b7ge", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.83": {"line.1": {"text": "Hierbey trawren oder klagen", "tokens": ["Hier\u00b7bey", "traw\u00b7ren", "o\u00b7der", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVINF", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein Undanck so zu sagen,", "tokens": ["Ist", "ein", "Un\u00b7danck", "so", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutschland mu\u00df den langen Streit", "tokens": ["Deutschland", "mu\u00df", "den", "lan\u00b7gen", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "ART", "ADJA", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Wider Danck und Willen hegen,", "tokens": ["Wi\u00b7der", "Danck", "und", "Wil\u00b7len", "he\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist doch \u00fcber deinem Segen,", "tokens": ["Ist", "doch", "\u00fc\u00b7ber", "dei\u00b7nem", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "O ChurBrandenburgk, erfrewt.", "tokens": ["O", "Chur", "Bran\u00b7den\u00b7burgk", ",", "er\u00b7frewt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NE", "NE", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.84": {"line.1": {"text": "Fleust der edle Rein gleich blutig,", "tokens": ["Fleust", "der", "ed\u00b7le", "Rein", "gleich", "blu\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die\u00dffals ist er dennoch muhtig,", "tokens": ["Die\u00df\u00b7fals", "ist", "er", "den\u00b7noch", "muh\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zieht es ihm zum Rhum und Pracht,", "tokens": ["Zieht", "es", "ihm", "zum", "Rhum", "und", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPRART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df der Trost so vieler Lande", "tokens": ["Da\u00df", "der", "Trost", "so", "vie\u00b7ler", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eben jetzt an seinem Rande", "tokens": ["E\u00b7ben", "jetzt", "an", "sei\u00b7nem", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist an dieses Licht gebracht.", "tokens": ["Ist", "an", "die\u00b7ses", "Licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.85": {"line.1": {"text": "Cleve kan sich nicht ergr\u00fcnden", "tokens": ["Cle\u00b7ve", "kan", "sich", "nicht", "er\u00b7gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch in dieses Gl\u00fcck recht finden,", "tokens": ["Noch", "in", "die\u00b7ses", "Gl\u00fcck", "recht", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wolte Rom nicht hie vor seyn,", "tokens": ["Wol\u00b7te", "Rom", "nicht", "hie", "vor", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PTKNEG", "ADV", "APPR", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es hat f\u00fcrwar zu prangen,", "tokens": ["Und", "es", "hat", "f\u00fcr\u00b7war", "zu", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKZU", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn es stellte das Verlangen", "tokens": ["Denn", "es", "stell\u00b7te", "das", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grosser V\u00f6lcker hie sich ein.", "tokens": ["Gros\u00b7ser", "V\u00f6l\u00b7cker", "hie", "sich", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "PRF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.86": {"line.1": {"text": "Sey gegr\u00fcsst, O Prei\u00df der St\u00e4dte,", "tokens": ["Sey", "ge\u00b7gr\u00fcs\u00b7st", ",", "O", "Prei\u00df", "der", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "NE", "NN", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Gott erh\u00f6ret die Gebehte", "tokens": ["Gott", "er\u00b7h\u00f6\u00b7ret", "die", "Ge\u00b7beh\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner lieben Schar in dir,", "tokens": ["Sei\u00b7ner", "lie\u00b7ben", "Schar", "in", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat mang tausent dich erkohren,", "tokens": ["Hat", "mang", "tau\u00b7sent", "dich", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schaw, es wird in dir gebohren,", "tokens": ["Schaw", ",", "es", "wird", "in", "dir", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsre Lust, der Helden Zier.", "tokens": ["Uns\u00b7re", "Lust", ",", "der", "Hel\u00b7den", "Zier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.87": {"line.1": {"text": "Gott m\u00fcss' allzeit dich erwehlen,", "tokens": ["Gott", "m\u00fcss'", "all\u00b7zeit", "dich", "er\u00b7weh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nie dir etwas lassen fehlen,", "tokens": ["Nie", "dir", "et\u00b7was", "las\u00b7sen", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PIS", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werde seines Segens Zelt,", "tokens": ["Wer\u00b7de", "sei\u00b7nes", "Se\u00b7gens", "Zelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wachs an Ansehn, Leuten, Wahren", "tokens": ["Wachs", "an", "An\u00b7sehn", ",", "Leu\u00b7ten", ",", "Wah\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und verkehr' in wenig Jahren", "tokens": ["Und", "ver\u00b7kehr'", "in", "we\u00b7nig", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich, O Stadt, in eine Welt.", "tokens": ["Dich", ",", "O", "Stadt", ",", "in", "ei\u00b7ne", "Welt", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.88": {"line.1": {"text": "Schaw, wie sich an deinen Frewden", "tokens": ["Schaw", ",", "wie", "sich", "an", "dei\u00b7nen", "Frew\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PRF", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel grosse H\u00e4user weiden,", "tokens": ["So", "viel", "gros\u00b7se", "H\u00e4u\u00b7ser", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die Gro\u00df-Fraw-Mutter thut,", "tokens": ["Wie", "die", "Gro\u00df\u00b7Fra\u00b7wMut\u00b7ter", "thut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott ihr Lippen-Opffer bringet", "tokens": ["Gott", "ihr", "Lip\u00b7pen\u00b7Opf\u00b7fer", "brin\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und der Sternen Hitze zwinget", "tokens": ["Und", "der", "Ster\u00b7nen", "Hit\u00b7ze", "zwin\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch der Andacht heisse Glut.", "tokens": ["Durch", "der", "An\u00b7dacht", "heis\u00b7se", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.89": {"line.1": {"text": "C\u00f6lln erdencket newe Weisen,", "tokens": ["C\u00f6lln", "er\u00b7den\u00b7cket", "ne\u00b7we", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Wie Berlin auch Gott zu preisen,", "tokens": ["Wie", "Ber\u00b7lin", "auch", "Gott", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "NN", "PTKZU", "VVINF", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Holland wei\u00df jetzt keinen Streit", "tokens": ["Hol\u00b7land", "wei\u00df", "jetzt", "kei\u00b7nen", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wil aller Noht vergessen,", "tokens": ["Und", "wil", "al\u00b7ler", "Noht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Wo bleibt Neuburgk, Churland, Hessen", "tokens": ["Wo", "bleibt", "Neu\u00b7burgk", ",", "Chur\u00b7land", ",", "Hes\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "VVFIN", "NN", "$,", "NE", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und was mehr sich hierob frewt?", "tokens": ["Und", "was", "mehr", "sich", "hier\u00b7ob", "frewt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "PRF", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.90": {"line.1": {"text": "Jetzund thut mir erst von n\u00f6hten", "tokens": ["Je\u00b7tzund", "thut", "mir", "erst", "von", "n\u00f6h\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Zieraht der Poeten,", "tokens": ["Al\u00b7le", "Zier\u00b7aht", "der", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "O wer l\u00e4st mich Claudian,", "tokens": ["O", "wer", "l\u00e4st", "mich", "Clau\u00b7di\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Flaccus oder Maro werden?", "tokens": ["Flac\u00b7cus", "o\u00b7der", "Ma\u00b7ro", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich verliesse Volck und Erden,", "tokens": ["Ich", "ver\u00b7lies\u00b7se", "Volck", "und", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00fcrde stracks ein weisser Schwan.", "tokens": ["W\u00fcr\u00b7de", "stracks", "ein", "weis\u00b7ser", "Schwan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.91": {"line.1": {"text": "Oder hett' ich Ceres Drachen,", "tokens": ["O\u00b7der", "hett'", "ich", "Ce\u00b7res", "Dra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die mir w\u00fcsten Bahn zu machen,", "tokens": ["Die", "mir", "w\u00fcs\u00b7ten", "Bahn", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weg durch Wolcken, Lufft und Wind,", "tokens": ["Weg", "durch", "Wol\u00b7cken", ",", "Lufft", "und", "Wind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sollt ich nicht auff schnellem Wagen", "tokens": ["Sollt", "ich", "nicht", "auff", "schnel\u00b7lem", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00dcber Stern und Himmel tragen", "tokens": ["\u00dc\u00b7ber", "Stern", "und", "Him\u00b7mel", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dich, du s\u00fcsses F\u00fcrsten-Kind?", "tokens": ["Dich", ",", "du", "s\u00fcs\u00b7ses", "F\u00fcrs\u00b7ten\u00b7Kind", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.92": {"line.1": {"text": "Deiner hohen Ahnen M\u00e4nge", "tokens": ["Dei\u00b7ner", "ho\u00b7hen", "Ah\u00b7nen", "M\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fcrden erstlich mein Gepr\u00e4nge,", "tokens": ["W\u00fcr\u00b7den", "erst\u00b7lich", "mein", "Ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deines Vaters Pracht st\u00fcnd hie", "tokens": ["Dei\u00b7nes", "Va\u00b7ters", "Pracht", "st\u00fcnd", "hie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deiner Mutter gegen\u00fcber,", "tokens": ["Dei\u00b7ner", "Mut\u00b7ter", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00e4re mir auch etwas lieber", "tokens": ["W\u00e4\u00b7re", "mir", "auch", "et\u00b7was", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Als die Anmut solcher M\u00fch?", "tokens": ["Als", "die", "An\u00b7mut", "sol\u00b7cher", "M\u00fch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.93": {"line.1": {"text": "Hierauff s\u00e4ng ich das Verlangen", "tokens": ["Hier\u00b7auff", "s\u00e4ng", "ich", "das", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und den Wunsch, dich zu empfangen,", "tokens": ["Und", "den", "Wunsch", ",", "dich", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der nicht zu ergr\u00fcnden ist,", "tokens": ["Der", "nicht", "zu", "er\u00b7gr\u00fcn\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn du nicht k\u00f6mpst ungebehten,", "tokens": ["Denn", "du", "nicht", "k\u00f6mpst", "un\u00b7ge\u00b7beh\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "VVFIN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sondern wol in tausent St\u00e4dten", "tokens": ["Son\u00b7dern", "wol", "in", "tau\u00b7sent", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie von Gott erzwungen bist.", "tokens": ["Wie", "von", "Gott", "er\u00b7zwun\u00b7gen", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.94": {"line.1": {"text": "Nachmals r\u00fchmt' ich das Begn\u00fcgen", "tokens": ["Nach\u00b7mals", "r\u00fchmt'", "ich", "das", "Be\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Eltern, deine Wiegen,", "tokens": ["Dei\u00b7ner", "El\u00b7tern", ",", "dei\u00b7ne", "Wie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner Pflege grosse Trew,", "tokens": ["Dei\u00b7ner", "Pfle\u00b7ge", "gros\u00b7se", "Trew", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie erfrewt du angekommen,", "tokens": ["Wie", "er\u00b7frewt", "du", "an\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie man dich hab' auffgenommen", "tokens": ["Wie", "man", "dich", "hab'", "auff\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur mit Lieb' und Lust-Geschrey.", "tokens": ["Nur", "mit", "Lieb'", "und", "Lust\u00b7Ge\u00b7schrey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.95": {"line.1": {"text": "Nachmals wolt' ich k\u00fcndig machen,", "tokens": ["Nach\u00b7mals", "wolt'", "ich", "k\u00fcn\u00b7dig", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was von deines Lebens-Sachen", "tokens": ["Was", "von", "dei\u00b7nes", "Le\u00b7bens\u00b7Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das Verh\u00e4ngn\u00fc\u00df-Buch enth\u00e4lt,", "tokens": ["Das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df\u00b7Buch", "ent\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deinen Auffwachs, deine Jugend,", "tokens": ["Dei\u00b7nen", "Auff\u00b7wachs", ",", "dei\u00b7ne", "Ju\u00b7gend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Deine ritterliche Tugend,", "tokens": ["Dei\u00b7ne", "rit\u00b7ter\u00b7li\u00b7che", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dein Verdienst in dieser Welt.", "tokens": ["Dein", "Ver\u00b7dienst", "in", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.96": {"line.1": {"text": "Aber die\u00df sind hohe Dinge,", "tokens": ["A\u00b7ber", "die\u00df", "sind", "ho\u00b7he", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich bin ihnen zu geringe,", "tokens": ["Ich", "bin", "ih\u00b7nen", "zu", "ge\u00b7rin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch Barleus Wissenschaft,", "tokens": ["Auch", "Bar\u00b7leus", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die nicht gnugsam zu erheben,", "tokens": ["Die", "nicht", "gnug\u00b7sam", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrd' er ietzt gleich wieder leben,", "tokens": ["W\u00fcrd'", "er", "ietzt", "gleich", "wie\u00b7der", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fehlt' es hie an Geist und Krafft.", "tokens": ["Fehlt'", "es", "hie", "an", "Geist", "und", "Krafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.97": {"line.1": {"text": "Wachs, O Kind, die gr\u00fcnen W\u00e4lder", "tokens": ["Wachs", ",", "O", "Kind", ",", "die", "gr\u00fc\u00b7nen", "W\u00e4l\u00b7der"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NE", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Frucht der schwangren Felder", "tokens": ["Und", "die", "Frucht", "der", "schwang\u00b7ren", "Fel\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4chst zu Wolgefallen dir,", "tokens": ["W\u00e4chst", "zu", "Wol\u00b7ge\u00b7fal\u00b7len", "dir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dann nicht, wann es pflegt zu schneyen,", "tokens": ["Dann", "nicht", ",", "wann", "es", "pflegt", "zu", "schne\u00b7yen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sondern in dem sch\u00f6nen Meyen", "tokens": ["Son\u00b7dern", "in", "dem", "sch\u00f6\u00b7nen", "Me\u00b7yen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Bistu, Wunsch der Sternen, hier.", "tokens": ["Bis\u00b7tu", ",", "Wunsch", "der", "Ster\u00b7nen", ",", "hier", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "ART", "NN", "$,", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.98": {"line.1": {"text": "Blumen, Gr\u00e4ser, Kr\u00e4uter, Bienen", "tokens": ["Blu\u00b7men", ",", "Gr\u00e4\u00b7ser", ",", "Kr\u00e4u\u00b7ter", ",", "Bie\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind bem\u00fcht dir auff zu dienen,", "tokens": ["Sind", "be\u00b7m\u00fcht", "dir", "auff", "zu", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "PPER", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heissen dich willkommen seyn,", "tokens": ["Heis\u00b7sen", "dich", "will\u00b7kom\u00b7men", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchen dich als ihrem Herren", "tokens": ["Su\u00b7chen", "dich", "als", "ih\u00b7rem", "Her\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle Lust-Th\u00f6r' auffzusperren,", "tokens": ["Al\u00b7le", "Lust\u00b7\u00b7T\u00b7h\u00f6r'", "auff\u00b7zu\u00b7sper\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Also gehst du zu uns ein.", "tokens": ["Al\u00b7so", "gehst", "du", "zu", "uns", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.99": {"line.1": {"text": "Da\u00df Gefl\u00fcgel l\u00e4sst sich h\u00f6ren,", "tokens": ["Da\u00df", "Ge\u00b7fl\u00fc\u00b7gel", "l\u00e4sst", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Singt auff unterschiednen Ch\u00f6ren,", "tokens": ["Singt", "auff", "un\u00b7ter\u00b7schied\u00b7nen", "Ch\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dich Kind, seinen Hertzog, an,", "tokens": ["Dich", "Kind", ",", "sei\u00b7nen", "Hert\u00b7zog", ",", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Kunst der Nachtigalen", "tokens": ["Und", "die", "Kunst", "der", "Nach\u00b7ti\u00b7ga\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Kriegt den Prei\u00df f\u00fcr andern allen,", "tokens": ["Kriegt", "den", "Prei\u00df", "f\u00fcr", "an\u00b7dern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PIS", "PIAT", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und erhebt dich, wie sie kan.", "tokens": ["Und", "er\u00b7hebt", "dich", ",", "wie", "sie", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.100": {"line.1": {"text": "Werden wir durch deine Gaben", "tokens": ["Wer\u00b7den", "wir", "durch", "dei\u00b7ne", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Nicht ein stetes Vor-Jahr haben,", "tokens": ["Nicht", "ein", "ste\u00b7tes", "Vor\u00b7Jahr", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht ein Leben aller Ruh?", "tokens": ["Nicht", "ein", "Le\u00b7ben", "al\u00b7ler", "Ruh", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn die angenehme Zeiten,", "tokens": ["Denn", "die", "an\u00b7ge\u00b7neh\u00b7me", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche dich, O Kind, begleiten,", "tokens": ["Wel\u00b7che", "dich", ",", "O", "Kind", ",", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "$,", "NE", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sagen dieses gut' uns zu?", "tokens": ["Sa\u00b7gen", "die\u00b7ses", "gut'", "uns", "zu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.101": {"line.1": {"text": "Eben jetzt wird allenthalben", "tokens": ["E\u00b7ben", "jetzt", "wird", "al\u00b7len\u00b7thal\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich der Geist von oben salben", "tokens": ["Dich", "der", "Geist", "von", "o\u00b7ben", "sal\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "APPR", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch das heilig-hohe Bad,", "tokens": ["Durch", "das", "hei\u00b7lig\u00b7ho\u00b7he", "Bad", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da sich Gott mit allem Segen", "tokens": ["Da", "sich", "Gott", "mit", "al\u00b7lem", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "NN", "APPR", "PIS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird in dein Gem\u00fcte legen,", "tokens": ["Wird", "in", "dein", "Ge\u00b7m\u00fc\u00b7te", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df du wandelst seinen Pfad.", "tokens": ["Da\u00df", "du", "wan\u00b7delst", "sei\u00b7nen", "Pfad", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.102": {"line.1": {"text": "Du entsagst den b\u00f6sen L\u00fcsten,", "tokens": ["Du", "ent\u00b7sagst", "den", "b\u00f6\u00b7sen", "L\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4ssest dich mit Warheit r\u00fcsten", "tokens": ["L\u00e4s\u00b7sest", "dich", "mit", "War\u00b7heit", "r\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wieder Satans Tyranney,", "tokens": ["Wie\u00b7der", "Sa\u00b7tans", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hebst dein Hertz von aller Erden", "tokens": ["Hebst", "dein", "Hertz", "von", "al\u00b7ler", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gar ein newer Mensch zu werden,", "tokens": ["Gar", "ein", "ne\u00b7wer", "Mensch", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Der nach Gott geschaffen sey.", "tokens": ["Der", "nach", "Gott", "ge\u00b7schaf\u00b7fen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.103": {"line.1": {"text": "Bist ein F\u00fcrst zwar von Gebl\u00fcte,", "tokens": ["Bist", "ein", "F\u00fcrst", "zwar", "von", "Ge\u00b7bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ein Keyser im Gem\u00fcte,", "tokens": ["Doch", "ein", "Key\u00b7ser", "im", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlachtst du deinem Vater nach,", "tokens": ["Schlachtst", "du", "dei\u00b7nem", "Va\u00b7ter", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dessen unbeflecktes Leben", "tokens": ["Des\u00b7sen", "un\u00b7be\u00b7fleck\u00b7tes", "Le\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Glimpff und Wei\u00dfheit zu erheben", "tokens": ["Glimpff", "und", "Wei\u00df\u00b7heit", "zu", "er\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Redner Kunst zu schwach.", "tokens": ["Al\u00b7ler", "Red\u00b7ner", "Kunst", "zu", "schwach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "PTKZU", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.104": {"line.1": {"text": "Der wird dich in gleichen Sachen", "tokens": ["Der", "wird", "dich", "in", "glei\u00b7chen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Durch die Zucht Ihm \u00e4hnlich machen,", "tokens": ["Durch", "die", "Zucht", "Ihm", "\u00e4hn\u00b7lich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch der Mutter hoher Flei\u00df", "tokens": ["Auch", "der", "Mut\u00b7ter", "ho\u00b7her", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird zu allem Wesen sehen:", "tokens": ["Wird", "zu", "al\u00b7lem", "We\u00b7sen", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIS", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was wir bitten oder flehen", "tokens": ["Was", "wir", "bit\u00b7ten", "o\u00b7der", "fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVINF", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist dein Auffwachs, Zier und Prei\u00df.", "tokens": ["Ist", "dein", "Auff\u00b7wachs", ",", "Zier", "und", "Prei\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.105": {"line.1": {"text": "Also wirstu Ruh' und Frommen", "tokens": ["Al\u00b7so", "wirs\u00b7tu", "Ruh'", "und", "From\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denen seyn, die nach uns kommen,", "tokens": ["De\u00b7nen", "seyn", ",", "die", "nach", "uns", "kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAINF", "$,", "PRELS", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und zwar hie im Segen stehn,", "tokens": ["Und", "zwar", "hie", "im", "Se\u00b7gen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Aber dort, wenn du in Frieden,", "tokens": ["A\u00b7ber", "dort", ",", "wenn", "du", "in", "Frie\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alt und Welt-satt abgeschieden,", "tokens": ["Alt", "und", "Welt\u00b7satt", "ab\u00b7ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00dcber alle Hoheit gehn.", "tokens": ["\u00dc\u00b7ber", "al\u00b7le", "Ho\u00b7heit", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.106": {"line.1": {"text": "Und du Blume von Nassowen,", "tokens": ["Und", "du", "Blu\u00b7me", "von", "Nas\u00b7so\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "APPR", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Als die Welt ie k\u00f6nnen schauen,", "tokens": ["Als", "die", "Welt", "ie", "k\u00f6n\u00b7nen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "O Loyse, sey erfrewt,", "tokens": ["O", "Loy\u00b7se", ",", "sey", "er\u00b7frewt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und la\u00df neben uns den deinen", "tokens": ["Und", "la\u00df", "ne\u00b7ben", "uns", "den", "dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "APPR", "PPER", "ART", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ehr' und Danck vor Gott' erscheinen", "tokens": ["Ehr'", "und", "Danck", "vor", "Gott'", "er\u00b7schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wegen deiner Fruchtbarheit.", "tokens": ["We\u00b7gen", "dei\u00b7ner", "Frucht\u00b7bar\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.107": {"line.1": {"text": "Also wirst du nun un\u00df Preussen", "tokens": ["Al\u00b7so", "wirst", "du", "nun", "un\u00df", "Preus\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch so hoch gesegnet heissen.", "tokens": ["Noch", "so", "hoch", "ge\u00b7seg\u00b7net", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVPP", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird es denn nicht bald geschehn?", "tokens": ["Wird", "es", "denn", "nicht", "bald", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6mmt die Stunde nicht geschwinde,", "tokens": ["K\u00f6mmt", "die", "Stun\u00b7de", "nicht", "ge\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df wir dich sampt deinem Kinde,", "tokens": ["Da\u00df", "wir", "dich", "sampt", "dei\u00b7nem", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Grosse Mutter, werden sehn?", "tokens": ["Gros\u00b7se", "Mut\u00b7ter", ",", "wer\u00b7den", "sehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.108": {"line.1": {"text": "K\u00fcss' indessen auff die Schmertzen", "tokens": ["K\u00fcss'", "in\u00b7des\u00b7sen", "auff", "die", "Schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deinen liebsten Sohn von Hertzen,", "tokens": ["Dei\u00b7nen", "liebs\u00b7ten", "Sohn", "von", "Hert\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Er bezahlt dir gnug die Noht,", "tokens": ["Er", "be\u00b7zahlt", "dir", "gnug", "die", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Er verbindet auch die Wunden,", "tokens": ["Er", "ver\u00b7bin\u00b7det", "auch", "die", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die du, Heldinn, hast empfunden", "tokens": ["Die", "du", ",", "Hel\u00b7dinn", ",", "hast", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "$,", "NN", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Durch des hohen Vaters Todt.", "tokens": ["Durch", "des", "ho\u00b7hen", "Va\u00b7ters", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.109": {"line.1": {"text": "Gott wird ferner uns erh\u00f6ren,", "tokens": ["Gott", "wird", "fer\u00b7ner", "uns", "er\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Brandenburgk durch dich vermehren", "tokens": ["Bran\u00b7den\u00b7burgk", "durch", "dich", "ver\u00b7meh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als die Stern' am Himmels-Saal,", "tokens": ["Als", "die", "Stern'", "am", "Him\u00b7mels\u00b7Saal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil es zimlich abgenommen,", "tokens": ["Weil", "es", "zim\u00b7lich", "ab\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber nun empor sol kommen,", "tokens": ["A\u00b7ber", "nun", "em\u00b7por", "sol", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist mir recht, zum dritten mal.", "tokens": ["Ist", "mir", "recht", ",", "zum", "drit\u00b7ten", "mal", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "APPRART", "ADJA", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.110": {"line.1": {"text": "Du nur wollest dieses Wesen", "tokens": ["Du", "nur", "wol\u00b7lest", "die\u00b7ses", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner trewen Einfalt lesen", "tokens": ["Mei\u00b7ner", "tre\u00b7wen", "Ein\u00b7falt", "le\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fr\u00f6lich, gn\u00e4digst, ohn Verdru\u00df,", "tokens": ["Fr\u00f6\u00b7lich", ",", "gn\u00e4\u00b7digst", ",", "ohn", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$,", "KOUI", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach den Niederl\u00e4nder-Schw\u00e4nen", "tokens": ["Nach", "den", "Nie\u00b7der\u00b7l\u00e4n\u00b7der\u00b7Schw\u00e4\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich nun einer Gan\u00df gewehnen,", "tokens": ["Dich", "nun", "ei\u00b7ner", "Gan\u00df", "ge\u00b7weh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die in Preussen schnattern mu\u00df.", "tokens": ["Die", "in", "Preus\u00b7sen", "schnat\u00b7tern", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.111": {"line.1": {"text": "Aber auch von Dir zu sagen,", "tokens": ["A\u00b7ber", "auch", "von", "Dir", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ChurF\u00fcrst, s\u00fcsses Wolbehagen", "tokens": ["Chur", "F\u00fcrst", ",", "s\u00fcs\u00b7ses", "Wol\u00b7be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deines Himmels und der Welt,", "tokens": ["Dei\u00b7nes", "Him\u00b7mels", "und", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was f\u00fcr Pflicht ist zu erdencken,", "tokens": ["Was", "f\u00fcr", "Pflicht", "ist", "zu", "er\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "So wir deiner Gnade schencken,", "tokens": ["So", "wir", "dei\u00b7ner", "Gna\u00b7de", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die uns so umbschlossen h\u00e4lt?", "tokens": ["Die", "uns", "so", "umbsc\u00b7hlos\u00b7sen", "h\u00e4lt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.112": {"line.1": {"text": "Dich der blossen Wollust wegen", "tokens": ["Dich", "der", "blos\u00b7sen", "Wol\u00b7lust", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ADJA", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Liebe Joch zu legen,", "tokens": ["In", "der", "Lie\u00b7be", "Joch", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist von dir ein falscher Wahn,", "tokens": ["Ist", "von", "dir", "ein", "fal\u00b7scher", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn wer hat nicht gnug erfahren,", "tokens": ["Denn", "wer", "hat", "nicht", "gnug", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df du in den zarten Jahren", "tokens": ["Da\u00df", "du", "in", "den", "zar\u00b7ten", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Solche Lust von dir gethan?", "tokens": ["Sol\u00b7che", "Lust", "von", "dir", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.113": {"line.1": {"text": "Kuntte dir nicht dies zu treiben", "tokens": ["Kunt\u00b7te", "dir", "nicht", "dies", "zu", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PTKNEG", "PDS", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fug' und Freyheit gnug erl\u00e4uben", "tokens": ["Fug'", "und", "Frey\u00b7heit", "gnug", "er\u00b7l\u00e4u\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als kaum einem? aber nein.", "tokens": ["Als", "kaum", "ei\u00b7nem", "?", "a\u00b7ber", "nein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "$.", "ADV", "PTKANT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Du gedachtst dich einzuschliessen,", "tokens": ["Du", "ge\u00b7dachtst", "dich", "ein\u00b7zu\u00b7schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und dir selber im Gewissen", "tokens": ["Und", "dir", "sel\u00b7ber", "im", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Aller L\u00fcste Zwang zu seyn.", "tokens": ["Al\u00b7ler", "L\u00fcs\u00b7te", "Zwang", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.114": {"line.1": {"text": "Darumb trugst du dich mit Sorgen", "tokens": ["Da\u00b7rumb", "trugst", "du", "dich", "mit", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "APPR", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Deiner Herrschaft von dem Morgen", "tokens": ["Dei\u00b7ner", "Herr\u00b7schaft", "von", "dem", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bi\u00df auf sp\u00e4ten Abend zu:", "tokens": ["Bi\u00df", "auf", "sp\u00e4\u00b7ten", "A\u00b7bend", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchtst du aber dein Ergetzen,", "tokens": ["Suchtst", "du", "a\u00b7ber", "dein", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+++-", "measure": "unknown.measure.penta"}, "line.5": {"text": "So war reiten, jagen, hetzen", "tokens": ["So", "war", "rei\u00b7ten", ",", "ja\u00b7gen", ",", "het\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "VVFIN", "$,", "VVFIN", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der Garten deine Ruh.", "tokens": ["Und", "der", "Gar\u00b7ten", "dei\u00b7ne", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.115": {"line.1": {"text": "Venus gab schon gantz verlohren,", "tokens": ["Ve\u00b7nus", "gab", "schon", "gantz", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Amor hielte sich beschworen,", "tokens": ["A\u00b7mor", "hiel\u00b7te", "sich", "be\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir erschracken und dein Hau\u00df,", "tokens": ["Wir", "er\u00b7schra\u00b7cken", "und", "dein", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bi\u00df dein Hertz zur\u00fcck gedencket,", "tokens": ["Bi\u00df", "dein", "Hertz", "zu\u00b7r\u00fcck", "ge\u00b7den\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sich zu s\u00fcsser Heyraht lencket", "tokens": ["Sich", "zu", "s\u00fcs\u00b7ser", "Hey\u00b7raht", "len\u00b7cket"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und macht diesen Schlu\u00df darau\u00df.", "tokens": ["Und", "macht", "die\u00b7sen", "Schlu\u00df", "dar\u00b7au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.116": {"line.1": {"text": "Sonst ist auch dein Thun und Sinnen,", "tokens": ["Sonst", "ist", "auch", "dein", "Thun", "und", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Held, dein lassen und Beginnen", "tokens": ["Held", ",", "dein", "las\u00b7sen", "und", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "VVINF", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nichts als Gottes Ehr' und wir,", "tokens": ["Nichts", "als", "Got\u00b7tes", "Ehr'", "und", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "NN", "NN", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ein Welt-Buch von zu schreiben,", "tokens": ["Da", "ein", "Welt\u00b7Buch", "von", "zu", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ich mu\u00df solches lassen bleiben", "tokens": ["Ich", "mu\u00df", "sol\u00b7ches", "las\u00b7sen", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dein Ernst verbeut es mir.", "tokens": ["Und", "dein", "Ernst", "ver\u00b7beut", "es", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.117": {"line.1": {"text": "Herr, was haben wir dir dessen", "tokens": ["Herr", ",", "was", "ha\u00b7ben", "wir", "dir", "des\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "VAFIN", "PPER", "PPER", "PDS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcr Vergeltung zuzum\u00e4ssen?", "tokens": ["F\u00fcr", "Ver\u00b7gel\u00b7tung", "zu\u00b7zu\u00b7m\u00e4s\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gott bezahl' es umb und an,", "tokens": ["Gott", "be\u00b7zahl'", "es", "umb", "und", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "KON", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dessen Hertz' in deinen Gaben,", "tokens": ["Des\u00b7sen", "Hertz'", "in", "dei\u00b7nen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als auch F\u00fcrsten k\u00f6nnen haben,", "tokens": ["Als", "auch", "F\u00fcrs\u00b7ten", "k\u00f6n\u00b7nen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "VMFIN", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sich vergn\u00fcget spiegeln kan!", "tokens": ["Sich", "ver\u00b7gn\u00fc\u00b7get", "spie\u00b7geln", "kan", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.118": {"line.1": {"text": "Wie da\u00df der Himmel sich vernewert sampt der Erden?", "tokens": ["Wie", "da\u00df", "der", "Him\u00b7mel", "sich", "ver\u00b7ne\u00b7wert", "sampt", "der", "Er\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "PRF", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ein F\u00fcrst, die Lust der Welt, wird an dies Licht gebracht.", "tokens": ["Ein", "F\u00fcrst", ",", "die", "Lust", "der", "Welt", ",", "wird", "an", "dies", "Licht", "ge\u00b7bracht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,", "VAFIN", "APPR", "PDS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wendstu das Vor-Jahr ein? Er k\u00e4m' umb l\u00e4ngste Nacht,", "tokens": ["Wend\u00b7stu", "das", "Vor\u00b7Jahr", "ein", "?", "Er", "k\u00e4m'", "umb", "l\u00e4ngs\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Winter w\u00fcrd' ihm stracks ein sch\u00f6ner Fr\u00fcling werden.", "tokens": ["Der", "Win\u00b7ter", "w\u00fcrd'", "ihm", "stracks", "ein", "sch\u00f6\u00b7ner", "Fr\u00fc\u00b7ling", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}