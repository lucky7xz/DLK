{"textgrid.poem.57896": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Harzk\u00e4se ist nicht jedermanns Sache,", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Harzk\u00e4se ist nicht jedermanns Sache,", "tokens": ["Harz\u00b7k\u00e4\u00b7se", "ist", "nicht", "je\u00b7der\u00b7manns", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich aber finde riesig nett", "tokens": ["Ich", "a\u00b7ber", "fin\u00b7de", "rie\u00b7sig", "nett"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Zubi\u00df zu der kleinen Lage", "tokens": ["Als", "Zu\u00b7bi\u00df", "zu", "der", "klei\u00b7nen", "La\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ein sogenanntes Schneider-Kot'lett.", "tokens": ["Ein", "so\u00b7ge\u00b7nann\u00b7tes", "Schnei\u00b7der\u00b7Kot'", "let\u00b7t."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["ART", "ADJA", "NN", "NE"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Harzk\u00e4se mit Schmalzbrot nennt man n\u00e4mlich", "tokens": ["Harz\u00b7k\u00e4\u00b7se", "mit", "Schmalz\u00b7brot", "nennt", "man", "n\u00e4m\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "VVFIN", "PIS", "ADV"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Volke so; und ich bestellt'", "tokens": ["Im", "Vol\u00b7ke", "so", ";", "und", "ich", "be\u00b7stellt'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "$.", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir k\u00fcrzlich das; kurz vor dem Ersten,", "tokens": ["Mir", "k\u00fcrz\u00b7lich", "das", ";", "kurz", "vor", "dem", "Ers\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PDS", "$.", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Denn weiter langte nicht das Geld.", "tokens": ["Denn", "wei\u00b7ter", "lang\u00b7te", "nicht", "das", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbwoll'n Sie nun Vietz'schen oder Noah'schen?\u00ab", "tokens": ["\u00bb", "woll'n", "Sie", "nun", "Vietz'\u00b7schen", "o\u00b7der", "No\u00b7ah'\u00b7schen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "CARD", "KON", "NN", "$.", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So sprach der Wirt, und langte her", "tokens": ["So", "sprach", "der", "Wirt", ",", "und", "lang\u00b7te", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die K\u00e4se: \u00bbIch kann Ihnen versichern,", "tokens": ["Die", "K\u00e4\u00b7se", ":", "\u00bb", "Ich", "kann", "Ih\u00b7nen", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df durchgebrannt sie beide sehr.\u00ab", "tokens": ["Da\u00df", "durch\u00b7ge\u00b7brannt", "sie", "bei\u00b7de", "sehr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich \u00fcberlegte, dann streckte ich zeigend", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7leg\u00b7te", ",", "dann", "streck\u00b7te", "ich", "zei\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "VVPP"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nach der Marke Noah aus meine Hand:", "tokens": ["Nach", "der", "Mar\u00b7ke", "Noah", "aus", "mei\u00b7ne", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u00bbvon diesem geben Sie mir, Herr Gastrat,", "tokens": ["\u00bb", "von", "die\u00b7sem", "ge\u00b7ben", "Sie", "mir", ",", "Herr", "Gast\u00b7rat", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "VVFIN", "PPER", "PPER", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn der ist schon l\u00e4nger durchgebrannt!\u00ab", "tokens": ["Denn", "der", "ist", "schon", "l\u00e4n\u00b7ger", "durch\u00b7ge\u00b7brannt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "VAFIN", "ADV", "ADJD", "VVPP", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Harzk\u00e4se ist nicht jedermanns Sache,", "tokens": ["Harz\u00b7k\u00e4\u00b7se", "ist", "nicht", "je\u00b7der\u00b7manns", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich aber finde riesig nett", "tokens": ["Ich", "a\u00b7ber", "fin\u00b7de", "rie\u00b7sig", "nett"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Zubi\u00df zu der kleinen Lage", "tokens": ["Als", "Zu\u00b7bi\u00df", "zu", "der", "klei\u00b7nen", "La\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ein sogenanntes Schneider-Kot'lett.", "tokens": ["Ein", "so\u00b7ge\u00b7nann\u00b7tes", "Schnei\u00b7der\u00b7Kot'", "let\u00b7t."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["ART", "ADJA", "NN", "NE"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Harzk\u00e4se mit Schmalzbrot nennt man n\u00e4mlich", "tokens": ["Harz\u00b7k\u00e4\u00b7se", "mit", "Schmalz\u00b7brot", "nennt", "man", "n\u00e4m\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "VVFIN", "PIS", "ADV"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Im Volke so; und ich bestellt'", "tokens": ["Im", "Vol\u00b7ke", "so", ";", "und", "ich", "be\u00b7stellt'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "$.", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir k\u00fcrzlich das; kurz vor dem Ersten,", "tokens": ["Mir", "k\u00fcrz\u00b7lich", "das", ";", "kurz", "vor", "dem", "Ers\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PDS", "$.", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Denn weiter langte nicht das Geld.", "tokens": ["Denn", "wei\u00b7ter", "lang\u00b7te", "nicht", "das", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbwoll'n Sie nun Vietz'schen oder Noah'schen?\u00ab", "tokens": ["\u00bb", "woll'n", "Sie", "nun", "Vietz'\u00b7schen", "o\u00b7der", "No\u00b7ah'\u00b7schen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "CARD", "KON", "NN", "$.", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So sprach der Wirt, und langte her", "tokens": ["So", "sprach", "der", "Wirt", ",", "und", "lang\u00b7te", "her"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die K\u00e4se: \u00bbIch kann Ihnen versichern,", "tokens": ["Die", "K\u00e4\u00b7se", ":", "\u00bb", "Ich", "kann", "Ih\u00b7nen", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df durchgebrannt sie beide sehr.\u00ab", "tokens": ["Da\u00df", "durch\u00b7ge\u00b7brannt", "sie", "bei\u00b7de", "sehr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PIS", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich \u00fcberlegte, dann streckte ich zeigend", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7leg\u00b7te", ",", "dann", "streck\u00b7te", "ich", "zei\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "VVPP"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nach der Marke Noah aus meine Hand:", "tokens": ["Nach", "der", "Mar\u00b7ke", "Noah", "aus", "mei\u00b7ne", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u00bbvon diesem geben Sie mir, Herr Gastrat,", "tokens": ["\u00bb", "von", "die\u00b7sem", "ge\u00b7ben", "Sie", "mir", ",", "Herr", "Gast\u00b7rat", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "APPR", "PDAT", "VVFIN", "PPER", "PPER", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn der ist schon l\u00e4nger durchgebrannt!\u00ab", "tokens": ["Denn", "der", "ist", "schon", "l\u00e4n\u00b7ger", "durch\u00b7ge\u00b7brannt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "VAFIN", "ADV", "ADJD", "VVPP", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}