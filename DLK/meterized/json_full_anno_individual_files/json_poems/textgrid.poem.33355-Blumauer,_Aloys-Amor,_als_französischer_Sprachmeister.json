{"textgrid.poem.33355": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Amor, als franz\u00f6sischer Sprachmeister", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als Amor j\u00fcngst kam aus Paris,", "tokens": ["Als", "A\u00b7mor", "j\u00fcngst", "kam", "aus", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lehrt' er die sch\u00f6ne Dorilis", "tokens": ["Lehrt'", "er", "die", "sch\u00f6\u00b7ne", "Do\u00b7ri\u00b7lis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sprache aller Sprachen:", "tokens": ["Die", "Spra\u00b7che", "al\u00b7ler", "Spra\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Courage, rief er, liebes Kind,", "tokens": ["Cou\u00b7ra\u00b7ge", ",", "rief", "er", ",", "lie\u00b7bes", "Kind", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Sie werden unter mir geschwind", "tokens": ["Sie", "wer\u00b7den", "un\u00b7ter", "mir", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den besten Fortgang machen.", "tokens": ["Den", "bes\u00b7ten", "Fort\u00b7gang", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wie die gesammten Sterblichen", "tokens": ["Wie", "die", "ge\u00b7samm\u00b7ten", "Sterb\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus m\u00e4nnlichen und weiblichen", "tokens": ["Aus", "m\u00e4nn\u00b7li\u00b7chen", "und", "weib\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gesch\u00f6pfen nur bestehen;", "tokens": ["Ge\u00b7sch\u00f6p\u00b7fen", "nur", "be\u00b7ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So sind auch die Buchstaben all',", "tokens": ["So", "sind", "auch", "die", "Buch\u00b7sta\u00b7ben", "all'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der \u2013 Consonant und der \u2013 Vokal,", "tokens": ["Der", "\u2013", "Con\u00b7so\u00b7nant", "und", "der", "\u2013", "Vo\u00b7kal", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "NE", "KON", "ART", "$(", "NN", "$,"], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.6": {"text": "Wie wir im Curas sehen.", "tokens": ["Wie", "wir", "im", "Cu\u00b7ras", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der Consonant, beraubt des Schalls,", "tokens": ["Der", "Con\u00b7so\u00b7nant", ",", "be\u00b7raubt", "des", "Schalls", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kann ohne H\u00fclfe des Vokals", "tokens": ["Kann", "oh\u00b7ne", "H\u00fcl\u00b7fe", "des", "Vo\u00b7kals"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nicht ausgesprochen werden.", "tokens": ["Nicht", "aus\u00b7ge\u00b7spro\u00b7chen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "D'rum ist der Mann stets der Vokal,", "tokens": ["D'\u00b7rum", "ist", "der", "Mann", "stets", "der", "Vo\u00b7kal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Das Weibchen aber \u00fcberall", "tokens": ["Das", "Weib\u00b7chen", "a\u00b7ber", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Consonant auf Erden.", "tokens": ["Der", "Con\u00b7so\u00b7nant", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Bei jedem Substantivo wird", "tokens": ["Bei", "je\u00b7dem", "Subs\u00b7tan\u00b7ti\u00b7vo", "wird"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Nur der Artikel declinirt,", "tokens": ["Nur", "der", "Ar\u00b7ti\u00b7kel", "de\u00b7cli\u00b7nirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "So wie in mehrern Sprachen,", "tokens": ["So", "wie", "in", "meh\u00b7rern", "Spra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und aus dem Singularis kann", "tokens": ["Und", "aus", "dem", "Sin\u00b7gu\u00b7la\u00b7ris", "kann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NE", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit einem kleinen Schl\u00e4ngchen man", "tokens": ["Mit", "ei\u00b7nem", "klei\u00b7nen", "Schl\u00e4ng\u00b7chen", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Leicht den Pluralis machen.", "tokens": ["Leicht", "den", "Plu\u00b7ra\u00b7lis", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "Und jedes noch so m\u00e4nnliche", "tokens": ["Und", "je\u00b7des", "noch", "so", "m\u00e4nn\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADV", "ADV", "ADJA"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Hauptwort kann durch einzig E", "tokens": ["Haupt\u00b7wort", "kann", "durch", "ein\u00b7zig", "E"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "APPR", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zum Femininum werden:", "tokens": ["Zum", "Fe\u00b7mi\u00b7ni\u00b7num", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Regel ist sehr general;", "tokens": ["Die", "Re\u00b7gel", "ist", "sehr", "ge\u00b7ne\u00b7ral", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn durch die Ee wird \u00fcberall", "tokens": ["Denn", "durch", "die", "E\u00b7e", "wird", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der Mann zum Weib auf Erden.", "tokens": ["Der", "Mann", "zum", "Weib", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und wissen sie dies alles schon,", "tokens": ["Und", "wis\u00b7sen", "sie", "dies", "al\u00b7les", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will ich zur Conjugation", "tokens": ["Will", "ich", "zur", "Con\u00b7ju\u00b7ga\u00b7ti\u00b7on"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun mehr sie weiter f\u00fchren,", "tokens": ["Nun", "mehr", "sie", "wei\u00b7ter", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und da f\u00fcr's erste, merken Sie:", "tokens": ["Und", "da", "f\u00fcr's", "ers\u00b7te", ",", "mer\u00b7ken", "Sie", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ganz ohne H\u00fclfswort l\u00e4\u00dft sich nie", "tokens": ["Ganz", "oh\u00b7ne", "H\u00fclfs\u00b7wort", "l\u00e4\u00dft", "sich", "nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf Erden conjugiren.", "tokens": ["Auf", "Er\u00b7den", "con\u00b7ju\u00b7gi\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Nur der Indicativ erkiest", "tokens": ["Nur", "der", "In\u00b7di\u00b7ca\u00b7tiv", "er\u00b7kiest"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Den Mann, mit dem ihr M\u00e4dchen m\u00fc\u00dft", "tokens": ["Den", "Mann", ",", "mit", "dem", "ihr", "M\u00e4d\u00b7chen", "m\u00fc\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "ART", "PPOSAT", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Conjunctivus schliessen:", "tokens": ["Den", "Con\u00b7junc\u00b7ti\u00b7vus", "schlies\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und aus dem Conjunctivus wird", "tokens": ["Und", "aus", "dem", "Con\u00b7junc\u00b7ti\u00b7vus", "wird"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NE", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Dann der Imperativ formirt,", "tokens": ["Dann", "der", "Im\u00b7pe\u00b7ra\u00b7tiv", "for\u00b7mirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie alle M\u00e4nner wissen.", "tokens": ["Wie", "al\u00b7le", "M\u00e4n\u00b7ner", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und kaum sind oft neun Monden um,", "tokens": ["Und", "kaum", "sind", "oft", "neun", "Mon\u00b7den", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So setzt es ein Gerundium;", "tokens": ["So", "setzt", "es", "ein", "Ge\u00b7run\u00b7di\u00b7um", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da l\u00e4\u00dft der Mann sich h\u00f6ren:", "tokens": ["Da", "l\u00e4\u00dft", "der", "Mann", "sich", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gern wollt' ich die Gerundia,", "tokens": ["Gern", "wollt'", "ich", "die", "Ge\u00b7run\u00b7dia", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur die Participia", "tokens": ["Wenn", "nur", "die", "Par\u00b7ti\u00b7ci\u00b7pia"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Nicht gar so nahe w\u00e4ren.", "tokens": ["Nicht", "gar", "so", "na\u00b7he", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Was die Madam la Roche doch", "tokens": ["Was", "die", "Ma\u00b7dam", "la", "Ro\u00b7che", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NE", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Interjectionen noch", "tokens": ["Von", "In\u00b7ter\u00b7jec\u00b7ti\u00b7o\u00b7nen", "noch"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu guter Letzt uns lehret,", "tokens": ["Zu", "gu\u00b7ter", "Letzt", "uns", "leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist dies: da\u00df man im Brautstand ", "tokens": ["Ist", "dies", ":", "da\u00df", "man", "im", "Brauts\u00b7tand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "$.", "KOUS", "PIS", "APPRART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Und! ", "tokens": ["Und", "!"], "token_info": ["word", "punct"], "pos": ["KON", "$."], "meter": "+", "measure": "single.up"}}, "stanza.10": {"line.1": {"text": "Als Amor j\u00fcngst kam aus Paris,", "tokens": ["Als", "A\u00b7mor", "j\u00fcngst", "kam", "aus", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lehrt' er die sch\u00f6ne Dorilis", "tokens": ["Lehrt'", "er", "die", "sch\u00f6\u00b7ne", "Do\u00b7ri\u00b7lis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sprache aller Sprachen:", "tokens": ["Die", "Spra\u00b7che", "al\u00b7ler", "Spra\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Courage, rief er, liebes Kind,", "tokens": ["Cou\u00b7ra\u00b7ge", ",", "rief", "er", ",", "lie\u00b7bes", "Kind", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Sie werden unter mir geschwind", "tokens": ["Sie", "wer\u00b7den", "un\u00b7ter", "mir", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den besten Fortgang machen.", "tokens": ["Den", "bes\u00b7ten", "Fort\u00b7gang", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wie die gesammten Sterblichen", "tokens": ["Wie", "die", "ge\u00b7samm\u00b7ten", "Sterb\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus m\u00e4nnlichen und weiblichen", "tokens": ["Aus", "m\u00e4nn\u00b7li\u00b7chen", "und", "weib\u00b7li\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gesch\u00f6pfen nur bestehen;", "tokens": ["Ge\u00b7sch\u00f6p\u00b7fen", "nur", "be\u00b7ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So sind auch die Buchstaben all',", "tokens": ["So", "sind", "auch", "die", "Buch\u00b7sta\u00b7ben", "all'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der \u2013 Consonant und der \u2013 Vokal,", "tokens": ["Der", "\u2013", "Con\u00b7so\u00b7nant", "und", "der", "\u2013", "Vo\u00b7kal", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "$(", "NE", "KON", "ART", "$(", "NN", "$,"], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.6": {"text": "Wie wir im Curas sehen.", "tokens": ["Wie", "wir", "im", "Cu\u00b7ras", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Der Consonant, beraubt des Schalls,", "tokens": ["Der", "Con\u00b7so\u00b7nant", ",", "be\u00b7raubt", "des", "Schalls", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kann ohne H\u00fclfe des Vokals", "tokens": ["Kann", "oh\u00b7ne", "H\u00fcl\u00b7fe", "des", "Vo\u00b7kals"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nicht ausgesprochen werden.", "tokens": ["Nicht", "aus\u00b7ge\u00b7spro\u00b7chen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "D'rum ist der Mann stets der Vokal,", "tokens": ["D'\u00b7rum", "ist", "der", "Mann", "stets", "der", "Vo\u00b7kal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Das Weibchen aber \u00fcberall", "tokens": ["Das", "Weib\u00b7chen", "a\u00b7ber", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Consonant auf Erden.", "tokens": ["Der", "Con\u00b7so\u00b7nant", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Bei jedem Substantivo wird", "tokens": ["Bei", "je\u00b7dem", "Subs\u00b7tan\u00b7ti\u00b7vo", "wird"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Nur der Artikel declinirt,", "tokens": ["Nur", "der", "Ar\u00b7ti\u00b7kel", "de\u00b7cli\u00b7nirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "So wie in mehrern Sprachen,", "tokens": ["So", "wie", "in", "meh\u00b7rern", "Spra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und aus dem Singularis kann", "tokens": ["Und", "aus", "dem", "Sin\u00b7gu\u00b7la\u00b7ris", "kann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NE", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit einem kleinen Schl\u00e4ngchen man", "tokens": ["Mit", "ei\u00b7nem", "klei\u00b7nen", "Schl\u00e4ng\u00b7chen", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Leicht den Pluralis machen.", "tokens": ["Leicht", "den", "Plu\u00b7ra\u00b7lis", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.14": {"line.1": {"text": "Und jedes noch so m\u00e4nnliche", "tokens": ["Und", "je\u00b7des", "noch", "so", "m\u00e4nn\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADV", "ADV", "ADJA"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Hauptwort kann durch einzig E", "tokens": ["Haupt\u00b7wort", "kann", "durch", "ein\u00b7zig", "E"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "APPR", "ADJD", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zum Femininum werden:", "tokens": ["Zum", "Fe\u00b7mi\u00b7ni\u00b7num", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Regel ist sehr general;", "tokens": ["Die", "Re\u00b7gel", "ist", "sehr", "ge\u00b7ne\u00b7ral", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn durch die Ee wird \u00fcberall", "tokens": ["Denn", "durch", "die", "E\u00b7e", "wird", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VAFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Der Mann zum Weib auf Erden.", "tokens": ["Der", "Mann", "zum", "Weib", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Und wissen sie dies alles schon,", "tokens": ["Und", "wis\u00b7sen", "sie", "dies", "al\u00b7les", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will ich zur Conjugation", "tokens": ["Will", "ich", "zur", "Con\u00b7ju\u00b7ga\u00b7ti\u00b7on"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun mehr sie weiter f\u00fchren,", "tokens": ["Nun", "mehr", "sie", "wei\u00b7ter", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und da f\u00fcr's erste, merken Sie:", "tokens": ["Und", "da", "f\u00fcr's", "ers\u00b7te", ",", "mer\u00b7ken", "Sie", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ganz ohne H\u00fclfswort l\u00e4\u00dft sich nie", "tokens": ["Ganz", "oh\u00b7ne", "H\u00fclfs\u00b7wort", "l\u00e4\u00dft", "sich", "nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf Erden conjugiren.", "tokens": ["Auf", "Er\u00b7den", "con\u00b7ju\u00b7gi\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Nur der Indicativ erkiest", "tokens": ["Nur", "der", "In\u00b7di\u00b7ca\u00b7tiv", "er\u00b7kiest"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Den Mann, mit dem ihr M\u00e4dchen m\u00fc\u00dft", "tokens": ["Den", "Mann", ",", "mit", "dem", "ihr", "M\u00e4d\u00b7chen", "m\u00fc\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "ART", "PPOSAT", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Conjunctivus schliessen:", "tokens": ["Den", "Con\u00b7junc\u00b7ti\u00b7vus", "schlies\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und aus dem Conjunctivus wird", "tokens": ["Und", "aus", "dem", "Con\u00b7junc\u00b7ti\u00b7vus", "wird"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NE", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Dann der Imperativ formirt,", "tokens": ["Dann", "der", "Im\u00b7pe\u00b7ra\u00b7tiv", "for\u00b7mirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie alle M\u00e4nner wissen.", "tokens": ["Wie", "al\u00b7le", "M\u00e4n\u00b7ner", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Und kaum sind oft neun Monden um,", "tokens": ["Und", "kaum", "sind", "oft", "neun", "Mon\u00b7den", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So setzt es ein Gerundium;", "tokens": ["So", "setzt", "es", "ein", "Ge\u00b7run\u00b7di\u00b7um", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da l\u00e4\u00dft der Mann sich h\u00f6ren:", "tokens": ["Da", "l\u00e4\u00dft", "der", "Mann", "sich", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gern wollt' ich die Gerundia,", "tokens": ["Gern", "wollt'", "ich", "die", "Ge\u00b7run\u00b7dia", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn nur die Participia", "tokens": ["Wenn", "nur", "die", "Par\u00b7ti\u00b7ci\u00b7pia"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Nicht gar so nahe w\u00e4ren.", "tokens": ["Nicht", "gar", "so", "na\u00b7he", "w\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Was die Madam la Roche doch", "tokens": ["Was", "die", "Ma\u00b7dam", "la", "Ro\u00b7che", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NE", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Interjectionen noch", "tokens": ["Von", "In\u00b7ter\u00b7jec\u00b7ti\u00b7o\u00b7nen", "noch"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu guter Letzt uns lehret,", "tokens": ["Zu", "gu\u00b7ter", "Letzt", "uns", "leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist dies: da\u00df man im Brautstand ", "tokens": ["Ist", "dies", ":", "da\u00df", "man", "im", "Brauts\u00b7tand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "$.", "KOUS", "PIS", "APPRART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Und! ", "tokens": ["Und", "!"], "token_info": ["word", "punct"], "pos": ["KON", "$."], "meter": "+", "measure": "single.up"}}}}}