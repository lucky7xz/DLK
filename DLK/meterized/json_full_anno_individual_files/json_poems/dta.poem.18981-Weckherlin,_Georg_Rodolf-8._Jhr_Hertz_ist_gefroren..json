{"dta.poem.18981": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "8.  \n  Jhr Hertz ist gefroren.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Gleich wie ein armer mensch/ au\u00df jrrdischem ver-", "tokens": ["Gleich", "wie", "ein", "ar\u00b7mer", "mensch", "/", "au\u00df", "jrr\u00b7di\u00b7schem", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$(", "APPR", "ADJA", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "stand/", "tokens": ["stand", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Vermeinet/ horchend zu des Aberglaubens lehren/", "tokens": ["Ver\u00b7mei\u00b7net", "/", "hor\u00b7chend", "zu", "des", "A\u00b7berg\u00b7lau\u00b7bens", "leh\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADJD", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein sch\u00f6n-gemahltes bild/ als seines gaists hay-", "tokens": ["Ein", "sch\u00f6n\u00b7ge\u00b7mahl\u00b7tes", "bild", "/", "als", "sei\u00b7nes", "gaists", "hay"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KOUS", "PPOSAT", "ADJA", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "land/", "tokens": ["land", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Mit bitten/ opfern/ lob vnd anderm dienst zu ehren:", "tokens": ["Mit", "bit\u00b7ten", "/", "op\u00b7fern", "/", "lob", "vnd", "an\u00b7derm", "dienst", "zu", "eh\u00b7ren", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVINF", "$(", "VVINF", "$(", "NN", "KON", "PIS", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Also/ vn\u0303 mehr fehl Ich (witzlo\u00df) durch mein begehren/", "tokens": ["Al\u00b7so", "/", "v\u00f1", "mehr", "fehl", "Ich", "(", "witz\u00b7lo\u00df", ")", "durch", "mein", "be\u00b7geh\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "ADV", "ADJD", "PPER", "$(", "VVFIN", "$(", "APPR", "PPOSAT", "VVINF", "$("], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wan ich f\u00fcr euch erh\u00f6b mein hertz/ gesicht vn\u0303 ha\u0303d/", "tokens": ["Wan", "ich", "f\u00fcr", "euch", "er\u00b7h\u00f6b", "mein", "hertz", "/", "ge\u00b7sicht", "v\u00f1", "h\u00e3d", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVFIN", "PPOSAT", "NN", "$(", "FM.la", "FM.la", "FM.la", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wan ich mich darff ab euch beklagen vnnd be-", "tokens": ["Wan", "ich", "mich", "darff", "ab", "euch", "be\u00b7kla\u00b7gen", "vnnd", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "PAV", "PTKVZ", "PPER", "VVINF", "KON", "TRUNC"], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "schwehren/", "tokens": ["schweh\u00b7ren", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Da schuldig doch allein mein aigner vnverstand.", "tokens": ["Da", "schul\u00b7dig", "doch", "al\u00b7lein", "mein", "aig\u00b7ner", "vn\u00b7ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ja. G\u00f6ttin/ deren gnad mich k\u00f6nt allein erlaben/", "tokens": ["Ja", ".", "G\u00f6t\u00b7tin", "/", "de\u00b7ren", "gnad", "mich", "k\u00f6nt", "al\u00b7lein", "er\u00b7la\u00b7ben", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "$(", "PRELAT", "NN", "PPER", "VMFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Euch klag ich an vmbsunst/ vmbsunst hoff ich den", "tokens": ["Euch", "klag", "ich", "an", "vmbsunst", "/", "vmbsunst", "hoff", "ich", "den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NE", "$(", "ADV", "VVFIN", "PPER", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "lust/", "tokens": ["lust", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Da\u00df ewer hertz mit lieb werd meine lieb begaben.", "tokens": ["Da\u00df", "e\u00b7wer", "hertz", "mit", "lieb", "werd", "mei\u00b7ne", "lieb", "be\u00b7ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ADJD", "VAFIN", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Dan/ solt ich/ als ich sah ewrer schnee-weissen brust", "tokens": ["Dan", "/", "solt", "ich", "/", "als", "ich", "sah", "ew\u00b7rer", "schnee\u00b7weis\u00b7sen", "brust"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "VMFIN", "PPER", "$(", "KOUS", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bezauberende b\u00fchl/ nicht (kl\u00fcger) gedacht haben/", "tokens": ["Be\u00b7zau\u00b7be\u00b7ren\u00b7de", "b\u00fchl", "/", "nicht", "(", "kl\u00fc\u00b7ger", ")", "ge\u00b7dacht", "ha\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PTKNEG", "$(", "ADJD", "$(", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Da\u00df vnder solchem schnee ein hertz von ey\u00df sein", "tokens": ["Da\u00df", "vn\u00b7der", "sol\u00b7chem", "schnee", "ein", "hertz", "von", "ey\u00df", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "NN", "ART", "NN", "APPR", "NE", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "must?", "tokens": ["must", "?"], "token_info": ["word", "punct"], "pos": ["VMFIN", "$."], "meter": "+", "measure": "single.up"}}}}}