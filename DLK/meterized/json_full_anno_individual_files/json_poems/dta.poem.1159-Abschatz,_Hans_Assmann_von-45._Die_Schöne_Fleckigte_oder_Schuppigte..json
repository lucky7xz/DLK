{"dta.poem.1159": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "45. Die Sch\u00f6ne Fleckigte oder Schuppigte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Als dem Neptolemus die Ceres reichte dar ", "tokens": ["Als", "dem", "Nep\u00b7to\u00b7le\u00b7mus", "die", "Ce\u00b7res", "reich\u00b7te", "dar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "NE", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Kornes edle Frucht/ die uns kan St\u00e4rcke bringen/", "tokens": ["Des", "Kor\u00b7nes", "ed\u00b7le", "Frucht", "/", "die", "uns", "kan", "St\u00e4r\u00b7cke", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$(", "PRELS", "PPER", "VMFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Versuchte/ wie es sey in leichten Staub zu zwingen/", "tokens": ["Ver\u00b7such\u00b7te", "/", "wie", "es", "sey", "in", "leich\u00b7ten", "Staub", "zu", "zwin\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWAV", "PPER", "VAFIN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df draus gebacknes Brodt erquickt der Menschen Schaar/", "tokens": ["Da\u00df", "draus", "ge\u00b7back\u00b7nes", "Brodt", "er\u00b7quickt", "der", "Men\u00b7schen", "Schaar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sah sie Kleyh\u2019 und Mehl/ und ward alsbald gewahr/", "tokens": ["So", "sah", "sie", "Kley\u00b7h'", "und", "Mehl", "/", "und", "ward", "als\u00b7bald", "ge\u00b7wahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$(", "KON", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wie von derselben Ruhm die Nachwelt w\u00fcrd\u2019 erklingen/", "tokens": ["Wie", "von", "der\u00b7sel\u00b7ben", "Ruhm", "die", "Nach\u00b7welt", "w\u00fcrd'", "er\u00b7klin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PDAT", "NN", "ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Darum bezierte sie ihr Kind mit solchen Dingen.", "tokens": ["Da\u00b7rum", "be\u00b7zier\u00b7te", "sie", "ihr", "Kind", "mit", "sol\u00b7chen", "Din\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dianens Angesicht ist nicht durchgehends klar.", "tokens": ["Di\u00b7a\u00b7nens", "An\u00b7ge\u00b7sicht", "ist", "nicht", "durch\u00b7ge\u00b7hends", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Mein sch\u00f6nes Schuppen-Kind/ daher sind auch entsprossen", "tokens": ["Mein", "sch\u00f6\u00b7nes", "Schup\u00b7pen\u00b7Kind", "/", "da\u00b7her", "sind", "auch", "ent\u00b7spros\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "PAV", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Zeichen/ die dir hin und wieder auffgeschossen/", "tokens": ["Die", "Zei\u00b7chen", "/", "die", "dir", "hin", "und", "wie\u00b7der", "auff\u00b7ge\u00b7schos\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "PTKVZ", "KON", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Sternen/ derer Glantz dein Antlitz hat bebl\u00fcmt.", "tokens": ["Die", "Ster\u00b7nen", "/", "de\u00b7rer", "Glantz", "dein", "Ant\u00b7litz", "hat", "be\u00b7bl\u00fcmt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PDS", "NN", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Du bist drum nicht so sehr verachtet als ber\u00fchmt:", "tokens": ["Du", "bist", "drum", "nicht", "so", "sehr", "ver\u00b7ach\u00b7tet", "als", "be\u00b7r\u00fchmt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "PTKNEG", "ADV", "ADV", "VVFIN", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die kluge Kleyhen-Schaar h\u00f6rt alle Welt erheben/", "tokens": ["Die", "klu\u00b7ge", "Kley\u00b7hen\u00b7Schaar", "h\u00f6rt", "al\u00b7le", "Welt", "er\u00b7he\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Du w\u00fcrdest unter ihr das sch\u00f6nste Bild abgeben.", "tokens": ["Du", "w\u00fcr\u00b7dest", "un\u00b7ter", "ihr", "das", "sch\u00f6ns\u00b7te", "Bild", "ab\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-++--", "measure": "unknown.measure.hexa"}}}}}