{"textgrid.poem.47288": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Bestrafte Ungen\u00fcgsamkeit", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war das Kloster Grabow im Lande Usedom,", "tokens": ["Es", "war", "das", "Klos\u00b7ter", "Gra\u00b7bow", "im", "Lan\u00b7de", "Us\u00b7e\u00b7dom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NE", "APPRART", "NN", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das n\u00e4hrte Gott vorzeiten aus seiner Gnade Strom.", "tokens": ["Das", "n\u00e4hr\u00b7te", "Gott", "vor\u00b7zei\u00b7ten", "aus", "sei\u00b7ner", "Gna\u00b7de", "Strom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Es schwammen an der K\u00fcste, da\u00df es die Nahrung sei", "tokens": ["Es", "schwam\u00b7men", "an", "der", "K\u00fcs\u00b7te", ",", "da\u00df", "es", "die", "Nah\u00b7rung", "sei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den M\u00f6nchen in dem Kloster, j\u00e4hrlich zwei Fisch' herbei.", "tokens": ["Den", "M\u00f6n\u00b7chen", "in", "dem", "Klos\u00b7ter", ",", "j\u00e4hr\u00b7lich", "zwei", "Fisch'", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADJD", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "Zwei St\u00f6re, gro\u00df gewaltig; dabei war das Gesetz,", "tokens": ["Zwei", "St\u00f6\u00b7re", ",", "gro\u00df", "ge\u00b7wal\u00b7tig", ";", "da\u00b7bei", "war", "das", "Ge\u00b7setz", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADJD", "ADJD", "$.", "PAV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Da\u00df j\u00e4hrlich sie den einen fingen davon im Netz.", "tokens": ["Da\u00df", "j\u00e4hr\u00b7lich", "sie", "den", "ei\u00b7nen", "fin\u00b7gen", "da\u00b7von", "im", "Netz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ART", "PIS", "VVFIN", "PAV", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Der andre schwamm von dannen, bis auf das andre Jahr,", "tokens": ["Der", "and\u00b7re", "schwamm", "von", "dan\u00b7nen", ",", "bis", "auf", "das", "and\u00b7re", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "ADV", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da bracht' er einen neuen Gesellen mit sich dar.", "tokens": ["Da", "bracht'", "er", "ei\u00b7nen", "neu\u00b7en", "Ge\u00b7sel\u00b7len", "mit", "sich", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.5": {"line.1": {"text": "Da fingen wieder einen sie sich f\u00fcr ihren Tisch;", "tokens": ["Da", "fin\u00b7gen", "wie\u00b7der", "ei\u00b7nen", "sie", "sich", "f\u00fcr", "ih\u00b7ren", "Tisch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie fingen regelm\u00e4\u00dfig jahraus jahrein den Fisch.", "tokens": ["Sie", "fin\u00b7gen", "re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "ja\u00b7hraus", "ja\u00b7hrein", "den", "Fisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Einst kamen zwei so gro\u00dfe in einem Jahr herbei;", "tokens": ["Einst", "ka\u00b7men", "zwei", "so", "gro\u00b7\u00dfe", "in", "ei\u00b7nem", "Jahr", "her\u00b7bei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "ADV", "ADJA", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schwer ward die Wahl den M\u00f6nchen, welcher zu fangen sei?", "tokens": ["Schwer", "ward", "die", "Wahl", "den", "M\u00f6n\u00b7chen", ",", "wel\u00b7cher", "zu", "fan\u00b7gen", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PRELS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.7": {"line.1": {"text": "Sie fingen alle beide; den Lohn man da erwarb,", "tokens": ["Sie", "fin\u00b7gen", "al\u00b7le", "bei\u00b7de", ";", "den", "Lohn", "man", "da", "er\u00b7warb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "PIS", "$.", "ART", "NN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df sich das ganze Kloster den Magen dran verdarb.", "tokens": ["Da\u00df", "sich", "das", "gan\u00b7ze", "Klos\u00b7ter", "den", "Ma\u00b7gen", "dran", "ver\u00b7darb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "ART", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.8": {"line.1": {"text": "Der Schaden war der kleinste, der gr\u00f6\u00dfte kam nachher:", "tokens": ["Der", "Scha\u00b7den", "war", "der", "kleins\u00b7te", ",", "der", "gr\u00f6\u00df\u00b7te", "kam", "nach\u00b7her", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "$,", "ART", "ADJA", "VVFIN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es kam nun gar zum Kloster kein Fisch geschwommen mehr.", "tokens": ["Es", "kam", "nun", "gar", "zum", "Klos\u00b7ter", "kein", "Fisch", "ge\u00b7schwom\u00b7men", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "PIAT", "NN", "VVPP", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.9": {"line.1": {"text": "Sie hat so lange gn\u00e4dig gespeiset Gottes Huld;", "tokens": ["Sie", "hat", "so", "lan\u00b7ge", "gn\u00e4\u00b7dig", "ge\u00b7spei\u00b7set", "Got\u00b7tes", "Huld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "VVPP", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df sie nun des sind ledig, ist ihre eigne Schuld.", "tokens": ["Da\u00df", "sie", "nun", "des", "sind", "le\u00b7dig", ",", "ist", "ih\u00b7re", "eig\u00b7ne", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "VAFIN", "ADJD", "$,", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.10": {"line.1": {"text": "Es war das Kloster Grabow im Lande Usedom,", "tokens": ["Es", "war", "das", "Klos\u00b7ter", "Gra\u00b7bow", "im", "Lan\u00b7de", "Us\u00b7e\u00b7dom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NE", "APPRART", "NN", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das n\u00e4hrte Gott vorzeiten aus seiner Gnade Strom.", "tokens": ["Das", "n\u00e4hr\u00b7te", "Gott", "vor\u00b7zei\u00b7ten", "aus", "sei\u00b7ner", "Gna\u00b7de", "Strom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.11": {"line.1": {"text": "Es schwammen an der K\u00fcste, da\u00df es die Nahrung sei", "tokens": ["Es", "schwam\u00b7men", "an", "der", "K\u00fcs\u00b7te", ",", "da\u00df", "es", "die", "Nah\u00b7rung", "sei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den M\u00f6nchen in dem Kloster, j\u00e4hrlich zwei Fisch' herbei.", "tokens": ["Den", "M\u00f6n\u00b7chen", "in", "dem", "Klos\u00b7ter", ",", "j\u00e4hr\u00b7lich", "zwei", "Fisch'", "her\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADJD", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.12": {"line.1": {"text": "Zwei St\u00f6re, gro\u00df gewaltig; dabei war das Gesetz,", "tokens": ["Zwei", "St\u00f6\u00b7re", ",", "gro\u00df", "ge\u00b7wal\u00b7tig", ";", "da\u00b7bei", "war", "das", "Ge\u00b7setz", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADJD", "ADJD", "$.", "PAV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Da\u00df j\u00e4hrlich sie den einen fingen davon im Netz.", "tokens": ["Da\u00df", "j\u00e4hr\u00b7lich", "sie", "den", "ei\u00b7nen", "fin\u00b7gen", "da\u00b7von", "im", "Netz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "ART", "PIS", "VVFIN", "PAV", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.13": {"line.1": {"text": "Der andre schwamm von dannen, bis auf das andre Jahr,", "tokens": ["Der", "and\u00b7re", "schwamm", "von", "dan\u00b7nen", ",", "bis", "auf", "das", "and\u00b7re", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "ADV", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da bracht' er einen neuen Gesellen mit sich dar.", "tokens": ["Da", "bracht'", "er", "ei\u00b7nen", "neu\u00b7en", "Ge\u00b7sel\u00b7len", "mit", "sich", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.14": {"line.1": {"text": "Da fingen wieder einen sie sich f\u00fcr ihren Tisch;", "tokens": ["Da", "fin\u00b7gen", "wie\u00b7der", "ei\u00b7nen", "sie", "sich", "f\u00fcr", "ih\u00b7ren", "Tisch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sie fingen regelm\u00e4\u00dfig jahraus jahrein den Fisch.", "tokens": ["Sie", "fin\u00b7gen", "re\u00b7gel\u00b7m\u00e4\u00b7\u00dfig", "ja\u00b7hraus", "ja\u00b7hrein", "den", "Fisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.15": {"line.1": {"text": "Einst kamen zwei so gro\u00dfe in einem Jahr herbei;", "tokens": ["Einst", "ka\u00b7men", "zwei", "so", "gro\u00b7\u00dfe", "in", "ei\u00b7nem", "Jahr", "her\u00b7bei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "ADV", "ADJA", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schwer ward die Wahl den M\u00f6nchen, welcher zu fangen sei?", "tokens": ["Schwer", "ward", "die", "Wahl", "den", "M\u00f6n\u00b7chen", ",", "wel\u00b7cher", "zu", "fan\u00b7gen", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PRELS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.16": {"line.1": {"text": "Sie fingen alle beide; den Lohn man da erwarb,", "tokens": ["Sie", "fin\u00b7gen", "al\u00b7le", "bei\u00b7de", ";", "den", "Lohn", "man", "da", "er\u00b7warb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "PIS", "$.", "ART", "NN", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df sich das ganze Kloster den Magen dran verdarb.", "tokens": ["Da\u00df", "sich", "das", "gan\u00b7ze", "Klos\u00b7ter", "den", "Ma\u00b7gen", "dran", "ver\u00b7darb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "ART", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.17": {"line.1": {"text": "Der Schaden war der kleinste, der gr\u00f6\u00dfte kam nachher:", "tokens": ["Der", "Scha\u00b7den", "war", "der", "kleins\u00b7te", ",", "der", "gr\u00f6\u00df\u00b7te", "kam", "nach\u00b7her", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "$,", "ART", "ADJA", "VVFIN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es kam nun gar zum Kloster kein Fisch geschwommen mehr.", "tokens": ["Es", "kam", "nun", "gar", "zum", "Klos\u00b7ter", "kein", "Fisch", "ge\u00b7schwom\u00b7men", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "PIAT", "NN", "VVPP", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.18": {"line.1": {"text": "Sie hat so lange gn\u00e4dig gespeiset Gottes Huld;", "tokens": ["Sie", "hat", "so", "lan\u00b7ge", "gn\u00e4\u00b7dig", "ge\u00b7spei\u00b7set", "Got\u00b7tes", "Huld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "VVPP", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da\u00df sie nun des sind ledig, ist ihre eigne Schuld.", "tokens": ["Da\u00df", "sie", "nun", "des", "sind", "le\u00b7dig", ",", "ist", "ih\u00b7re", "eig\u00b7ne", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "VAFIN", "ADJD", "$,", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Sie h\u00e4tten sich sollen begn\u00fcgen!", "tokens": ["Sie", "h\u00e4t\u00b7ten", "sich", "sol\u00b7len", "be\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}