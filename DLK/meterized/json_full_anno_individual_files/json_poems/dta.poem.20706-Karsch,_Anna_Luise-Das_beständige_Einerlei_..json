{"dta.poem.20706": {"metadata": {"author": {"name": "Karsch, Anna Luise", "birth": "N.A.", "death": "N.A."}, "title": "Das best\u00e4ndige Einerlei .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1792", "urn": "urn:nbn:de:kobv:b4-200905193016", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Aspan, ein Edelmann, gewohnt zum Zeitvertreib,                 ", "tokens": ["As\u00b7pan", ",", "ein", "E\u00b7del\u00b7mann", ",", "ge\u00b7wohnt", "zum", "Zeit\u00b7ver\u00b7treib", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verirrte dann und wann sich zu des Dieners Weib,", "tokens": ["Ver\u00b7irr\u00b7te", "dann", "und", "wann", "sich", "zu", "des", "Die\u00b7ners", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "PWAV", "PRF", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn sie war jung und sch\u00f6n \u2014 Wie? Was trieb denn", "tokens": ["Denn", "sie", "war", "jung", "und", "sch\u00f6n", "Wie", "?", "Was", "trieb", "denn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "KON", "ADJD", "$(", "PWAV", "$.", "PWS", "VVFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aspanen", "tokens": ["As\u00b7pa\u00b7nen"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Zu Weibern seiner Unterthanen?", "tokens": ["Zu", "Wei\u00b7bern", "sei\u00b7ner", "Un\u00b7ter\u00b7tha\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hat er denn selbst kein Weib? Ja, er hat eine Frau;", "tokens": ["Hat", "er", "denn", "selbst", "kein", "Weib", "?", "Ja", ",", "er", "hat", "ei\u00b7ne", "Frau", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PIAT", "NN", "$.", "PTKANT", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "---+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Doch welcher Mensch wird alt und grau,", "tokens": ["Doch", "wel\u00b7cher", "Mensch", "wird", "alt", "und", "grau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ohn\u2019 mehr als einerlei von Speise zu genie\u00dfen?", "tokens": ["Ohn'", "mehr", "als", "ei\u00b7ner\u00b7lei", "von", "Spei\u00b7se", "zu", "ge\u00b7nie\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KOKOM", "ADV", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wer kann denn ewig nur auf Einem Munde k\u00fcssen?", "tokens": ["Wer", "kann", "denn", "e\u00b7wig", "nur", "auf", "Ei\u00b7nem", "Mun\u00b7de", "k\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ADJD", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zum wenigsten kann dieses nicht Aspan.", "tokens": ["Zum", "we\u00b7nigs\u00b7ten", "kann", "die\u00b7ses", "nicht", "As\u00b7pan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "VMFIN", "PDS", "PTKNEG", "NE", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Einst trift sein Diener ihn bei seinem Weibe an:", "tokens": ["Einst", "trift", "sein", "Die\u00b7ner", "ihn", "bei", "sei\u00b7nem", "Wei\u00b7be", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Herr! spricht er, sagt mir doch, was euch zu Andern", "tokens": ["Herr", "!", "spricht", "er", ",", "sagt", "mir", "doch", ",", "was", "euch", "zu", "An\u00b7dern"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "$,", "PRELS", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "treibet,", "tokens": ["trei\u00b7bet", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Warum ihr mit dem Ku\u00df bei eurer Frau nicht bleibet?", "tokens": ["Wa\u00b7rum", "ihr", "mit", "dem", "Ku\u00df", "bei", "eu\u00b7rer", "Frau", "nicht", "blei\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Edelmann lacht laut und spricht: du bist ein Thor,", "tokens": ["Der", "E\u00b7del\u00b7mann", "lacht", "laut", "und", "spricht", ":", "du", "bist", "ein", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein neuer Ku\u00df kommt uns wie neue Speise vor,", "tokens": ["Ein", "neu\u00b7er", "Ku\u00df", "kommt", "uns", "wie", "neu\u00b7e", "Spei\u00b7se", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KOKOM", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Wechsel ist gewi\u00df das sch\u00f6nste Ding auf Erden,", "tokens": ["Der", "Wech\u00b7sel", "ist", "ge\u00b7wi\u00df", "das", "sch\u00f6ns\u00b7te", "Ding", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Denn immer einerlei mu\u00df uns zum Ekel werden.", "tokens": ["Denn", "im\u00b7mer", "ei\u00b7ner\u00b7lei", "mu\u00df", "uns", "zum", "E\u00b7kel", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VMFIN", "PPER", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Hans h\u00f6rt es an und sch\u00fcttelt mit dem Kopf,", "tokens": ["Hans", "h\u00f6rt", "es", "an", "und", "sch\u00fct\u00b7telt", "mit", "dem", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Denn Hanns der war ein dummer Tropf.", "tokens": ["Denn", "Hanns", "der", "war", "ein", "dum\u00b7mer", "Tropf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ART", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Sein Herr war listig und verschlagen,", "tokens": ["Sein", "Herr", "war", "lis\u00b7tig", "und", "ver\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Er hei\u00dft dem Koch, zu Hannsens Mittagsmahl", "tokens": ["Er", "hei\u00dft", "dem", "Koch", ",", "zu", "Hann\u00b7sens", "Mit\u00b7tags\u00b7mahl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NE", "$,", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Die besten Aalpasteten tragen.", "tokens": ["Die", "bes\u00b7ten", "Aal\u00b7pas\u00b7te\u00b7ten", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Das Essen war f\u00fcr Hannsens Wahl,", "tokens": ["Das", "Es\u00b7sen", "war", "f\u00fcr", "Hann\u00b7sens", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Er a\u00df sein Tage nicht vom Aal;", "tokens": ["Er", "a\u00df", "sein", "Ta\u00b7ge", "nicht", "vom", "Aal", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Das Ding war ihm so neu, wie alle neue Dinger.", "tokens": ["Das", "Ding", "war", "ihm", "so", "neu", ",", "wie", "al\u00b7le", "neu\u00b7e", "Din\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,", "PWAV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Genug er i\u00dft und leckt die Finger ", "tokens": ["Ge\u00b7nug", "er", "i\u00dft", "und", "leckt", "die", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Der Koch tr\u00e4gts wieder auf den andern, dritten Tag.", "tokens": ["Der", "Koch", "tr\u00e4gts", "wie\u00b7der", "auf", "den", "an\u00b7dern", ",", "drit\u00b7ten", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So lange bis es Hanns gar nicht mehr essen mag.", "tokens": ["So", "lan\u00b7ge", "bis", "es", "Hanns", "gar", "nicht", "mehr", "es\u00b7sen", "mag."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ADV", "KOUS", "PPER", "NE", "ADV", "PTKNEG", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Er sitzt und stochert mit dem Messer:", "tokens": ["Er", "sitzt", "und", "sto\u00b7chert", "mit", "dem", "Mes\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Wo blieb nun der Pastetenesser?", "tokens": ["Wo", "blieb", "nun", "der", "Pas\u00b7te\u00b7te\u00b7nes\u00b7ser", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.32": {"text": "Sein Herr tritt hinter ihn und spricht", "tokens": ["Sein", "Herr", "tritt", "hin\u00b7ter", "ihn", "und", "spricht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Und fr\u00e4gt: wie ists, Hanns! schmeckt die Aalpastete", "tokens": ["Und", "fr\u00e4gt", ":", "wie", "ists", ",", "Hanns", "!", "schmeckt", "die", "Aal\u00b7pas\u00b7te\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "PWAV", "VAFIN", "$,", "NE", "$.", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.34": {"text": "nicht?", "tokens": ["nicht", "?"], "token_info": ["word", "punct"], "pos": ["PTKNEG", "$."], "meter": "-", "measure": "single.down"}, "line.35": {"text": "O! spricht der gute Hans mit ziemlichem Err\u00f6then,", "tokens": ["O", "!", "spricht", "der", "gu\u00b7te", "Hans", "mit", "ziem\u00b7li\u00b7chem", "Er\u00b7r\u00f6\u00b7then", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "ART", "ADJA", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wer Henker i\u00dft denn gern nur immer Aalpasteten?", "tokens": ["Wer", "Hen\u00b7ker", "i\u00dft", "denn", "gern", "nur", "im\u00b7mer", "Aal\u00b7pas\u00b7te\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "ADV", "ADV", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Man sehnt sich auch einmal nach Fleisch und Zugem\u00fc\u00df!", "tokens": ["Man", "sehnt", "sich", "auch", "ein\u00b7mal", "nach", "Fleisch", "und", "Zu\u00b7ge\u00b7m\u00fc\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.38": {"text": "Ho ho! spricht Hannsens Herr, Ver\u00e4nderung ist s\u00fc\u00df;", "tokens": ["Ho", "ho", "!", "spricht", "Hann\u00b7sens", "Herr", ",", "Ver\u00b7\u00e4n\u00b7de\u00b7rung", "ist", "s\u00fc\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "VVFIN", "NE", "NN", "$,", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Wie du nicht jeden Tag magst Aalpastet genie\u00dfen,", "tokens": ["Wie", "du", "nicht", "je\u00b7den", "Tag", "magst", "Aal\u00b7pas\u00b7tet", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKNEG", "PIAT", "NN", "VMFIN", "NE", "VVINF", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.40": {"text": "So mag auch ich mein Weib nicht alle Tage k\u00fcssen.", "tokens": ["So", "mag", "auch", "ich", "mein", "Weib", "nicht", "al\u00b7le", "Ta\u00b7ge", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPER", "PPOSAT", "NN", "PTKNEG", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Hanns h\u00e4ngt den Kopf, sch\u00e4mt sich und schweigt,", "tokens": ["Hanns", "h\u00e4ngt", "den", "Kopf", ",", "sch\u00e4mt", "sich", "und", "schweigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "VVFIN", "PRF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Und krazt sich hinter beiden Ohren,", "tokens": ["Und", "krazt", "sich", "hin\u00b7ter", "bei\u00b7den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Ganz von der Wahrheit \u00fcberzeugt,", "tokens": ["Ganz", "von", "der", "Wahr\u00b7heit", "\u00fc\u00b7berz\u00b7eugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Da\u00df wir zum Wechsel sind geboren!", "tokens": ["Da\u00df", "wir", "zum", "Wech\u00b7sel", "sind", "ge\u00b7bo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}