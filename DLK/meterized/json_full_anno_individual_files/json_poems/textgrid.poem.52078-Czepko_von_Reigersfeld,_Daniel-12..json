{"textgrid.poem.52078": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "12.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bringt der Frantzose dann nicht eine Tracht herf\u00fcr,", "tokens": ["Bringt", "der", "Frant\u00b7zo\u00b7se", "dann", "nicht", "ei\u00b7ne", "Tracht", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die uns unnachge\u00e4fft von Weibern k\u00f6nne bleiben?", "tokens": ["Die", "uns", "un\u00b7nach\u00b7ge\u00b7\u00e4fft", "von", "Wei\u00b7bern", "k\u00f6n\u00b7ne", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie wollen uns wol gar aus unsern Kleidern treiben,", "tokens": ["Sie", "wol\u00b7len", "uns", "wol", "gar", "aus", "un\u00b7sern", "Klei\u00b7dern", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sacken so in W\u00e4mst und Hosen ihre Zier.", "tokens": ["Und", "sa\u00b7cken", "so", "in", "W\u00e4mst", "und", "Ho\u00b7sen", "ih\u00b7re", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Viel Federn stecken sie auff ihre H\u00fctte hin,", "tokens": ["Viel", "Fe\u00b7dern", "ste\u00b7cken", "sie", "auff", "ih\u00b7re", "H\u00fct\u00b7te", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihr Haar mu\u00df der Barbier nach unsrer Art verschneiden:", "tokens": ["Ihr", "Haar", "mu\u00df", "der", "Bar\u00b7bier", "nach", "uns\u00b7rer", "Art", "ver\u00b7schnei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nichts mangelt als das Theil, das uns kan unterscheiden,", "tokens": ["Nichts", "man\u00b7gelt", "als", "das", "Theil", ",", "das", "uns", "kan", "un\u00b7ter\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "ART", "NN", "$,", "PRELS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sonst suchten sie sich uns in allem vorzuziehn.", "tokens": ["Sonst", "such\u00b7ten", "sie", "sich", "uns", "in", "al\u00b7lem", "vor\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PPER", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch glaubt, da\u00df ihnen auch das Ding noch nicht gebricht,", "tokens": ["Doch", "glaubt", ",", "da\u00df", "ih\u00b7nen", "auch", "das", "Ding", "noch", "nicht", "ge\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und solten sie den Sammt aus Josephs Hosen trennen,", "tokens": ["Und", "sol\u00b7ten", "sie", "den", "Sammt", "aus", "Jo\u00b7se\u00b7phs", "Ho\u00b7sen", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O Gott! Vor konte man ja Frau und Jungfer kennen,", "tokens": ["O", "Gott", "!", "Vor", "kon\u00b7te", "man", "ja", "Frau", "und", "Jung\u00b7fer", "ken\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "APPR", "VMFIN", "PIS", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Itzt kennt man Mann und Weib schier von einander nicht.", "tokens": ["Itzt", "kennt", "man", "Mann", "und", "Weib", "schier", "von", "ein\u00b7an\u00b7der", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "KON", "NN", "ADJD", "APPR", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Was bleibet? Blo\u00df der Barth, doch kommt es ihnen ein,", "tokens": ["Was", "blei\u00b7bet", "?", "Blo\u00df", "der", "Barth", ",", "doch", "kommt", "es", "ih\u00b7nen", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "ADV", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So werden wir ihn auch, drauff man schon ist befli\u00dfen,", "tokens": ["So", "wer\u00b7den", "wir", "ihn", "auch", ",", "drauff", "man", "schon", "ist", "be\u00b7fli\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "$,", "PAV", "PIS", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "In kurtzem, wie es scheint, vor ihnen legen m\u00fc\u00dfen,", "tokens": ["In", "kurt\u00b7zem", ",", "wie", "es", "scheint", ",", "vor", "ih\u00b7nen", "le\u00b7gen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "PWAV", "PPER", "VVFIN", "$,", "APPR", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als denen viel an Muth und Hertzen \u00e4hnlich seyn.", "tokens": ["Als", "de\u00b7nen", "viel", "an", "Muth", "und", "Hert\u00b7zen", "\u00e4hn\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "APPR", "NN", "KON", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Bringt der Frantzose dann nicht eine Tracht herf\u00fcr,", "tokens": ["Bringt", "der", "Frant\u00b7zo\u00b7se", "dann", "nicht", "ei\u00b7ne", "Tracht", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die uns unnachge\u00e4fft von Weibern k\u00f6nne bleiben?", "tokens": ["Die", "uns", "un\u00b7nach\u00b7ge\u00b7\u00e4fft", "von", "Wei\u00b7bern", "k\u00f6n\u00b7ne", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie wollen uns wol gar aus unsern Kleidern treiben,", "tokens": ["Sie", "wol\u00b7len", "uns", "wol", "gar", "aus", "un\u00b7sern", "Klei\u00b7dern", "trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sacken so in W\u00e4mst und Hosen ihre Zier.", "tokens": ["Und", "sa\u00b7cken", "so", "in", "W\u00e4mst", "und", "Ho\u00b7sen", "ih\u00b7re", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Viel Federn stecken sie auff ihre H\u00fctte hin,", "tokens": ["Viel", "Fe\u00b7dern", "ste\u00b7cken", "sie", "auff", "ih\u00b7re", "H\u00fct\u00b7te", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihr Haar mu\u00df der Barbier nach unsrer Art verschneiden:", "tokens": ["Ihr", "Haar", "mu\u00df", "der", "Bar\u00b7bier", "nach", "uns\u00b7rer", "Art", "ver\u00b7schnei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nichts mangelt als das Theil, das uns kan unterscheiden,", "tokens": ["Nichts", "man\u00b7gelt", "als", "das", "Theil", ",", "das", "uns", "kan", "un\u00b7ter\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "ART", "NN", "$,", "PRELS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sonst suchten sie sich uns in allem vorzuziehn.", "tokens": ["Sonst", "such\u00b7ten", "sie", "sich", "uns", "in", "al\u00b7lem", "vor\u00b7zu\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PPER", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Doch glaubt, da\u00df ihnen auch das Ding noch nicht gebricht,", "tokens": ["Doch", "glaubt", ",", "da\u00df", "ih\u00b7nen", "auch", "das", "Ding", "noch", "nicht", "ge\u00b7bricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und solten sie den Sammt aus Josephs Hosen trennen,", "tokens": ["Und", "sol\u00b7ten", "sie", "den", "Sammt", "aus", "Jo\u00b7se\u00b7phs", "Ho\u00b7sen", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "APPR", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "O Gott! Vor konte man ja Frau und Jungfer kennen,", "tokens": ["O", "Gott", "!", "Vor", "kon\u00b7te", "man", "ja", "Frau", "und", "Jung\u00b7fer", "ken\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "APPR", "VMFIN", "PIS", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Itzt kennt man Mann und Weib schier von einander nicht.", "tokens": ["Itzt", "kennt", "man", "Mann", "und", "Weib", "schier", "von", "ein\u00b7an\u00b7der", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "KON", "NN", "ADJD", "APPR", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Was bleibet? Blo\u00df der Barth, doch kommt es ihnen ein,", "tokens": ["Was", "blei\u00b7bet", "?", "Blo\u00df", "der", "Barth", ",", "doch", "kommt", "es", "ih\u00b7nen", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$.", "ADV", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So werden wir ihn auch, drauff man schon ist befli\u00dfen,", "tokens": ["So", "wer\u00b7den", "wir", "ihn", "auch", ",", "drauff", "man", "schon", "ist", "be\u00b7fli\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADV", "$,", "PAV", "PIS", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "In kurtzem, wie es scheint, vor ihnen legen m\u00fc\u00dfen,", "tokens": ["In", "kurt\u00b7zem", ",", "wie", "es", "scheint", ",", "vor", "ih\u00b7nen", "le\u00b7gen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "PWAV", "PPER", "VVFIN", "$,", "APPR", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als denen viel an Muth und Hertzen \u00e4hnlich seyn.", "tokens": ["Als", "de\u00b7nen", "viel", "an", "Muth", "und", "Hert\u00b7zen", "\u00e4hn\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "APPR", "NN", "KON", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}