{"dta.poem.19493": {"metadata": {"author": {"name": "Meyer, Conrad Ferdinand", "birth": "N.A.", "death": "N.A."}, "title": "Begegnung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1882", "urn": "urn:nbn:de:kobv:b4-200905193933", "language": ["de:0.99"], "booktitle": "Meyer, Conrad Ferdinand: Gedichte. Leipzig, 1882."}, "poem": {"stanza.1": {"line.1": {"text": "Mich f\u00fchrte durch den Tannenwald", "tokens": ["Mich", "f\u00fchr\u00b7te", "durch", "den", "Tan\u00b7nen\u00b7wald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein stiller Pfad, ein tief verschneiter,", "tokens": ["Ein", "stil\u00b7ler", "Pfad", ",", "ein", "tief", "ver\u00b7schnei\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da, ohne da\u00df ein Huf gehallt,", "tokens": ["Da", ",", "oh\u00b7ne", "da\u00df", "ein", "Huf", "ge\u00b7hallt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUI", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erblickt' ich pl\u00f6tzlich einen Reiter.", "tokens": ["Er\u00b7blickt'", "ich", "pl\u00f6tz\u00b7lich", "ei\u00b7nen", "Rei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Nicht zugewandt, nicht abgewandt,", "tokens": ["Nicht", "zu\u00b7ge\u00b7wandt", ",", "nicht", "ab\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "$,", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kam er, den Mantel umgeschlagen,", "tokens": ["Kam", "er", ",", "den", "Man\u00b7tel", "um\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mir d\u00e4uchte, da\u00df ich ihn gekannt", "tokens": ["Mir", "d\u00e4uch\u00b7te", ",", "da\u00df", "ich", "ihn", "ge\u00b7kannt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In alten, l\u00e4ngst verschollnen Tagen.", "tokens": ["In", "al\u00b7ten", ",", "l\u00e4ngst", "ver\u00b7scholl\u00b7nen", "Ta\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der jungen Augen wilde Kraft,", "tokens": ["Der", "jun\u00b7gen", "Au\u00b7gen", "wil\u00b7de", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Mundes Trotz und herbes Schweigen,", "tokens": ["Des", "Mun\u00b7des", "Trotz", "und", "her\u00b7bes", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Zug von Traum und Leidenschaft", "tokens": ["Ein", "Zug", "von", "Traum", "und", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ber\u00fchrte mich so tief und eigen.", "tokens": ["Be\u00b7r\u00fchr\u00b7te", "mich", "so", "tief", "und", "ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sein R\u00f6sslein zog auf wei\u00dfer Bahn", "tokens": ["Sein", "R\u00f6ss\u00b7lein", "zog", "auf", "wei\u00b7\u00dfer", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vorbei mit ungeh\u00f6rten Hufen.", "tokens": ["Vor\u00b7bei", "mit", "un\u00b7ge\u00b7h\u00f6r\u00b7ten", "Hu\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mich fa\u00dft's mit Lust und Grauen an", "tokens": ["Mich", "fa\u00dft's", "mit", "Lust", "und", "Grau\u00b7en", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm Gru\u00df und Namen nachzurufen.", "tokens": ["Ihm", "Gru\u00df", "und", "Na\u00b7men", "nach\u00b7zu\u00b7ru\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch keinen Namen hab' ich dann", "tokens": ["Doch", "kei\u00b7nen", "Na\u00b7men", "hab'", "ich", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als meinen eigenen gefunden,", "tokens": ["Als", "mei\u00b7nen", "ei\u00b7ge\u00b7nen", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da Ro\u00df und Reiter schon im Tann", "tokens": ["Da", "Ro\u00df", "und", "Rei\u00b7ter", "schon", "im", "Tann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hinterm Schneegeflock verschwunden.", "tokens": ["Und", "hin\u00b7term", "Schnee\u00b7ge\u00b7flock", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}