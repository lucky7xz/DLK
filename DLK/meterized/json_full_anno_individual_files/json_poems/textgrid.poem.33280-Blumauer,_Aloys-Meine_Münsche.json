{"textgrid.poem.33280": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Meine M\u00fcnsche", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Erde ist so gro\u00df und hehr,", "tokens": ["Die", "Er\u00b7de", "ist", "so", "gro\u00df", "und", "hehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man sieht mit Lust sie an,", "tokens": ["Man", "sieht", "mit", "Lust", "sie", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wer sie ganz bes\u00e4sse, w\u00e4r'", "tokens": ["Und", "wer", "sie", "ganz", "be\u00b7s\u00e4s\u00b7se", ",", "w\u00e4r'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein \u00fcberreicher Mann:", "tokens": ["Ein", "\u00fc\u00b7berr\u00b7ei\u00b7cher", "Mann", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch h\u00e4tt' ich g'nug f\u00fcr meinen Sinn", "tokens": ["Doch", "h\u00e4tt'", "ich", "g'\u00b7nug", "f\u00fcr", "mei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "An einem kleinen Fleckchen d'rin.", "tokens": ["An", "ei\u00b7nem", "klei\u00b7nen", "Fleck\u00b7chen", "d'\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Und dieses Fleckchen w\u00e4hlte ich", "tokens": ["Und", "die\u00b7ses", "Fleck\u00b7chen", "w\u00e4hl\u00b7te", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf einem H\u00fcgelchen,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Von dem ich k\u00f6nnte rund um mich", "tokens": ["Von", "dem", "ich", "k\u00f6nn\u00b7te", "rund", "um", "mich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "VMFIN", "ADJD", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So recht in's Freie sehn,", "tokens": ["So", "recht", "in's", "Frei\u00b7e", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und von der lieben Erde Plan", "tokens": ["Und", "von", "der", "lie\u00b7ben", "Er\u00b7de", "Plan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So viel zu sehen, als ich kann.", "tokens": ["So", "viel", "zu", "se\u00b7hen", ",", "als", "ich", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Auf diesem Fleckchen st\u00fcnde dann", "tokens": ["Auf", "die\u00b7sem", "Fleck\u00b7chen", "st\u00fcn\u00b7de", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein H\u00e4uschen nett und klein;", "tokens": ["Ein", "H\u00e4usc\u00b7hen", "nett", "und", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da nistet' ich, zufried'ner Mann,", "tokens": ["Da", "nis\u00b7tet'", "ich", ",", "zu\u00b7frie\u00b7d'\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit Weib und Kind mich ein:", "tokens": ["Mit", "Weib", "und", "Kind", "mich", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn leben ohne Weib und Kind,", "tokens": ["Denn", "le\u00b7ben", "oh\u00b7ne", "Weib", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hei\u00dft \u2013 m\u00fchsam segeln ohne Wind.", "tokens": ["Hei\u00dft", "\u2013", "m\u00fch\u00b7sam", "se\u00b7geln", "oh\u00b7ne", "Wind", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADJD", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und h\u00e4tt' ich noch ein G\u00e4rtchen d'ran,", "tokens": ["Und", "h\u00e4tt'", "ich", "noch", "ein", "G\u00e4rt\u00b7chen", "d'\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "So baut' ich es mit Flei\u00df;", "tokens": ["So", "baut'", "ich", "es", "mit", "Flei\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das g\u00e4be Kraut und Kohl mir dann", "tokens": ["Das", "g\u00e4\u00b7be", "Kraut", "und", "Kohl", "mir", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr meinen baaren Schwei\u00df,", "tokens": ["F\u00fcr", "mei\u00b7nen", "baa\u00b7ren", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Auch legt' ich manchen Pfirsichkern;", "tokens": ["Auch", "legt'", "ich", "man\u00b7chen", "Pfir\u00b7sich\u00b7kern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Denn Weib und Kinder naschen gern.", "tokens": ["Denn", "Weib", "und", "Kin\u00b7der", "na\u00b7schen", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und h\u00e4tt' ich auch so nebenbei", "tokens": ["Und", "h\u00e4tt'", "ich", "auch", "so", "ne\u00b7ben\u00b7bei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein gutes F\u00e4\u00dfchen Wein,", "tokens": ["Mein", "gu\u00b7tes", "F\u00e4\u00df\u00b7chen", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So reiste wohl kein Freund vorbei,", "tokens": ["So", "reis\u00b7te", "wohl", "kein", "Freund", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er spr\u00e4che bei mir ein:", "tokens": ["Er", "spr\u00e4\u00b7che", "bei", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wir s\u00e4hen froh ihm in's Gesicht,", "tokens": ["Wir", "s\u00e4\u00b7hen", "froh", "ihm", "in's", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und z\u00e4hlten ihm die Gl\u00e4ser nicht.", "tokens": ["Und", "z\u00e4hl\u00b7ten", "ihm", "die", "Gl\u00e4\u00b7ser", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nur sei, um mich de\u00df' all' zu freu'n,", "tokens": ["Nur", "sei", ",", "um", "mich", "de\u00df'", "all'", "zu", "freu'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "KOUI", "PRF", "PAV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Mir noch ein Gut beschert,", "tokens": ["Mir", "noch", "ein", "Gut", "be\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Gut \u2013 o mehr als Freund und Wein,", "tokens": ["Ein", "Gut", "\u2013", "o", "mehr", "als", "Freund", "und", "Wein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "FM", "ADV", "KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Hans und G\u00e4rtchen werth! \u2013", "tokens": ["Und", "Hans", "und", "G\u00e4rt\u00b7chen", "werth", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "KON", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die Freiheit! \u2013 wenn mir die gebricht, \u2013", "tokens": ["Die", "Frei\u00b7heit", "!", "\u2013", "wenn", "mir", "die", "ge\u00b7bricht", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "$(", "KOUS", "PPER", "ART", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So brauch' ich alles and're nicht!", "tokens": ["So", "brauch'", "ich", "al\u00b7les", "an\u00b7d'\u00b7re", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PIS", "PTKNEG", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Die Erde ist so gro\u00df und hehr,", "tokens": ["Die", "Er\u00b7de", "ist", "so", "gro\u00df", "und", "hehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man sieht mit Lust sie an,", "tokens": ["Man", "sieht", "mit", "Lust", "sie", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wer sie ganz bes\u00e4sse, w\u00e4r'", "tokens": ["Und", "wer", "sie", "ganz", "be\u00b7s\u00e4s\u00b7se", ",", "w\u00e4r'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein \u00fcberreicher Mann:", "tokens": ["Ein", "\u00fc\u00b7berr\u00b7ei\u00b7cher", "Mann", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Doch h\u00e4tt' ich g'nug f\u00fcr meinen Sinn", "tokens": ["Doch", "h\u00e4tt'", "ich", "g'\u00b7nug", "f\u00fcr", "mei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "An einem kleinen Fleckchen d'rin.", "tokens": ["An", "ei\u00b7nem", "klei\u00b7nen", "Fleck\u00b7chen", "d'\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Und dieses Fleckchen w\u00e4hlte ich", "tokens": ["Und", "die\u00b7ses", "Fleck\u00b7chen", "w\u00e4hl\u00b7te", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf einem H\u00fcgelchen,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Von dem ich k\u00f6nnte rund um mich", "tokens": ["Von", "dem", "ich", "k\u00f6nn\u00b7te", "rund", "um", "mich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "VMFIN", "ADJD", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So recht in's Freie sehn,", "tokens": ["So", "recht", "in's", "Frei\u00b7e", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und von der lieben Erde Plan", "tokens": ["Und", "von", "der", "lie\u00b7ben", "Er\u00b7de", "Plan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So viel zu sehen, als ich kann.", "tokens": ["So", "viel", "zu", "se\u00b7hen", ",", "als", "ich", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Auf diesem Fleckchen st\u00fcnde dann", "tokens": ["Auf", "die\u00b7sem", "Fleck\u00b7chen", "st\u00fcn\u00b7de", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein H\u00e4uschen nett und klein;", "tokens": ["Ein", "H\u00e4usc\u00b7hen", "nett", "und", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da nistet' ich, zufried'ner Mann,", "tokens": ["Da", "nis\u00b7tet'", "ich", ",", "zu\u00b7frie\u00b7d'\u00b7ner", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit Weib und Kind mich ein:", "tokens": ["Mit", "Weib", "und", "Kind", "mich", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn leben ohne Weib und Kind,", "tokens": ["Denn", "le\u00b7ben", "oh\u00b7ne", "Weib", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hei\u00dft \u2013 m\u00fchsam segeln ohne Wind.", "tokens": ["Hei\u00dft", "\u2013", "m\u00fch\u00b7sam", "se\u00b7geln", "oh\u00b7ne", "Wind", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADJD", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und h\u00e4tt' ich noch ein G\u00e4rtchen d'ran,", "tokens": ["Und", "h\u00e4tt'", "ich", "noch", "ein", "G\u00e4rt\u00b7chen", "d'\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "So baut' ich es mit Flei\u00df;", "tokens": ["So", "baut'", "ich", "es", "mit", "Flei\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das g\u00e4be Kraut und Kohl mir dann", "tokens": ["Das", "g\u00e4\u00b7be", "Kraut", "und", "Kohl", "mir", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NN", "KON", "NN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr meinen baaren Schwei\u00df,", "tokens": ["F\u00fcr", "mei\u00b7nen", "baa\u00b7ren", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Auch legt' ich manchen Pfirsichkern;", "tokens": ["Auch", "legt'", "ich", "man\u00b7chen", "Pfir\u00b7sich\u00b7kern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Denn Weib und Kinder naschen gern.", "tokens": ["Denn", "Weib", "und", "Kin\u00b7der", "na\u00b7schen", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und h\u00e4tt' ich auch so nebenbei", "tokens": ["Und", "h\u00e4tt'", "ich", "auch", "so", "ne\u00b7ben\u00b7bei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein gutes F\u00e4\u00dfchen Wein,", "tokens": ["Mein", "gu\u00b7tes", "F\u00e4\u00df\u00b7chen", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So reiste wohl kein Freund vorbei,", "tokens": ["So", "reis\u00b7te", "wohl", "kein", "Freund", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er spr\u00e4che bei mir ein:", "tokens": ["Er", "spr\u00e4\u00b7che", "bei", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wir s\u00e4hen froh ihm in's Gesicht,", "tokens": ["Wir", "s\u00e4\u00b7hen", "froh", "ihm", "in's", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und z\u00e4hlten ihm die Gl\u00e4ser nicht.", "tokens": ["Und", "z\u00e4hl\u00b7ten", "ihm", "die", "Gl\u00e4\u00b7ser", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Nur sei, um mich de\u00df' all' zu freu'n,", "tokens": ["Nur", "sei", ",", "um", "mich", "de\u00df'", "all'", "zu", "freu'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "KOUI", "PRF", "PAV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Mir noch ein Gut beschert,", "tokens": ["Mir", "noch", "ein", "Gut", "be\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Gut \u2013 o mehr als Freund und Wein,", "tokens": ["Ein", "Gut", "\u2013", "o", "mehr", "als", "Freund", "und", "Wein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "FM", "ADV", "KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Hans und G\u00e4rtchen werth! \u2013", "tokens": ["Und", "Hans", "und", "G\u00e4rt\u00b7chen", "werth", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "KON", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die Freiheit! \u2013 wenn mir die gebricht, \u2013", "tokens": ["Die", "Frei\u00b7heit", "!", "\u2013", "wenn", "mir", "die", "ge\u00b7bricht", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "$(", "KOUS", "PPER", "ART", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So brauch' ich alles and're nicht!", "tokens": ["So", "brauch'", "ich", "al\u00b7les", "an\u00b7d'\u00b7re", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PIS", "PTKNEG", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}