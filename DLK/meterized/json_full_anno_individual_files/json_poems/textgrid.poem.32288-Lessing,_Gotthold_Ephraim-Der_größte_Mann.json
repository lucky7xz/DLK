{"textgrid.poem.32288": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "Der gr\u00f6\u00dfte Mann", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "La\u00dft uns den Priester Orgon fragen:", "tokens": ["La\u00dft", "uns", "den", "Pries\u00b7ter", "Or\u00b7gon", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit stolzen Mienen wird er sagen:", "tokens": ["Mit", "stol\u00b7zen", "Mie\u00b7nen", "wird", "er", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer sich zum kleinsten machen kann.", "tokens": ["Wer", "sich", "zum", "kleins\u00b7ten", "ma\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "La\u00dft uns den Dichter Kriton h\u00f6ren:", "tokens": ["La\u00dft", "uns", "den", "Dich\u00b7ter", "Kri\u00b7ton", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er wird es uns in Versen schw\u00f6ren:", "tokens": ["Er", "wird", "es", "uns", "in", "Ver\u00b7sen", "schw\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer ohne M\u00fche reimen kann.", "tokens": ["Wer", "oh\u00b7ne", "M\u00fc\u00b7he", "rei\u00b7men", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "La\u00dft uns den Hofmann Damis fragen:", "tokens": ["La\u00dft", "uns", "den", "Hof\u00b7mann", "Da\u00b7mis", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NE", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er b\u00fcckt sich l\u00e4chelnd; das will sagen:", "tokens": ["Er", "b\u00fcckt", "sich", "l\u00e4\u00b7chelnd", ";", "das", "will", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$.", "PDS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer l\u00e4cheln und sich b\u00fccken kann.", "tokens": ["Wer", "l\u00e4\u00b7cheln", "und", "sich", "b\u00fc\u00b7cken", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wollt ihr vom Philosophen wissen,", "tokens": ["Wollt", "ihr", "vom", "Phi\u00b7lo\u00b7so\u00b7phen", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Aus dunkeln Reden m\u00fc\u00dft ihr schlie\u00dfen:", "tokens": ["Aus", "dun\u00b7keln", "Re\u00b7den", "m\u00fc\u00dft", "ihr", "schlie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer ihn verstehn und gr\u00fcbeln kann.", "tokens": ["Wer", "ihn", "ver\u00b7stehn", "und", "gr\u00fc\u00b7beln", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "KON", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was darf ich jeden Toren fragen:", "tokens": ["Was", "darf", "ich", "je\u00b7den", "To\u00b7ren", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr seht, die Toren alle sagen:", "tokens": ["Ihr", "seht", ",", "die", "To\u00b7ren", "al\u00b7le", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer mir am n\u00e4chsten kommen kann.", "tokens": ["Wer", "mir", "am", "n\u00e4chs\u00b7ten", "kom\u00b7men", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wollt ihr den kl\u00fcgsten Toren fragen:", "tokens": ["Wollt", "ihr", "den", "kl\u00fcgs\u00b7ten", "To\u00b7ren", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So fraget mich; ich will euch sagen:", "tokens": ["So", "fra\u00b7get", "mich", ";", "ich", "will", "euch", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer trunken sie verlachen kann.", "tokens": ["Wer", "trun\u00b7ken", "sie", "ver\u00b7la\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "La\u00dft uns den Priester Orgon fragen:", "tokens": ["La\u00dft", "uns", "den", "Pries\u00b7ter", "Or\u00b7gon", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit stolzen Mienen wird er sagen:", "tokens": ["Mit", "stol\u00b7zen", "Mie\u00b7nen", "wird", "er", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer sich zum kleinsten machen kann.", "tokens": ["Wer", "sich", "zum", "kleins\u00b7ten", "ma\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "La\u00dft uns den Dichter Kriton h\u00f6ren:", "tokens": ["La\u00dft", "uns", "den", "Dich\u00b7ter", "Kri\u00b7ton", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er wird es uns in Versen schw\u00f6ren:", "tokens": ["Er", "wird", "es", "uns", "in", "Ver\u00b7sen", "schw\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer ohne M\u00fche reimen kann.", "tokens": ["Wer", "oh\u00b7ne", "M\u00fc\u00b7he", "rei\u00b7men", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "La\u00dft uns den Hofmann Damis fragen:", "tokens": ["La\u00dft", "uns", "den", "Hof\u00b7mann", "Da\u00b7mis", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NE", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er b\u00fcckt sich l\u00e4chelnd; das will sagen:", "tokens": ["Er", "b\u00fcckt", "sich", "l\u00e4\u00b7chelnd", ";", "das", "will", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$.", "PDS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer l\u00e4cheln und sich b\u00fccken kann.", "tokens": ["Wer", "l\u00e4\u00b7cheln", "und", "sich", "b\u00fc\u00b7cken", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wollt ihr vom Philosophen wissen,", "tokens": ["Wollt", "ihr", "vom", "Phi\u00b7lo\u00b7so\u00b7phen", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Aus dunkeln Reden m\u00fc\u00dft ihr schlie\u00dfen:", "tokens": ["Aus", "dun\u00b7keln", "Re\u00b7den", "m\u00fc\u00dft", "ihr", "schlie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer ihn verstehn und gr\u00fcbeln kann.", "tokens": ["Wer", "ihn", "ver\u00b7stehn", "und", "gr\u00fc\u00b7beln", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "KON", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was darf ich jeden Toren fragen:", "tokens": ["Was", "darf", "ich", "je\u00b7den", "To\u00b7ren", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ihr seht, die Toren alle sagen:", "tokens": ["Ihr", "seht", ",", "die", "To\u00b7ren", "al\u00b7le", "sa\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer mir am n\u00e4chsten kommen kann.", "tokens": ["Wer", "mir", "am", "n\u00e4chs\u00b7ten", "kom\u00b7men", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wollt ihr den kl\u00fcgsten Toren fragen:", "tokens": ["Wollt", "ihr", "den", "kl\u00fcgs\u00b7ten", "To\u00b7ren", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der gr\u00f6\u00dfte Mann?", "tokens": ["Wer", "ist", "der", "gr\u00f6\u00df\u00b7te", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So fraget mich; ich will euch sagen:", "tokens": ["So", "fra\u00b7get", "mich", ";", "ich", "will", "euch", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer trunken sie verlachen kann.", "tokens": ["Wer", "trun\u00b7ken", "sie", "ver\u00b7la\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}