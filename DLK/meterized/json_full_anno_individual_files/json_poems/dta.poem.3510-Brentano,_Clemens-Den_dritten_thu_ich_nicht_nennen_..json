{"dta.poem.3510": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Den dritten thu ich nicht nennen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519172", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein B\u00fcbli isch e Stricker,               ", "tokens": ["Mein", "B\u00fcb\u00b7li", "isch", "e", "Stri\u00b7cker", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Er strickt e manche Nacht,", "tokens": ["Er", "strickt", "e", "man\u00b7che", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er strickt an einer Haube,", "tokens": ["Er", "strickt", "an", "ei\u00b7ner", "Hau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Haube, Haube,", "tokens": ["Hau\u00b7be", ",", "Hau\u00b7be", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Sisch noch nit ausgemacht.", "tokens": ["Sisch", "noch", "nit", "aus\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Von Seiden isch die Haube,", "tokens": ["Von", "Sei\u00b7den", "isch", "die", "Hau\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von Sammet isch die Schnur,", "tokens": ["Von", "Sam\u00b7met", "isch", "die", "Schnur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bisch du ein wackres M\u00e4dle,", "tokens": ["Bisch", "du", "ein", "wack\u00b7res", "M\u00e4d\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "M\u00e4dle, M\u00e4dle,", "tokens": ["M\u00e4d\u00b7le", ",", "M\u00e4d\u00b7le", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Bind du dein H\u00e4rle zu.", "tokens": ["Bind", "du", "dein", "H\u00e4r\u00b7le", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ach nein, will sie nit binden,", "tokens": ["Ach", "nein", ",", "will", "sie", "nit", "bin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wills noch mehr fliegen lahn,", "tokens": ["Wills", "noch", "mehr", "flie\u00b7gen", "lahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "VVINF", "VVINF", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Bis ander Jahr im Sommer,", "tokens": ["Bis", "an\u00b7der", "Jahr", "im", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sommer, Sommer,", "tokens": ["Som\u00b7mer", ",", "Som\u00b7mer", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Will zu dem Tanze gahn.", "tokens": ["Will", "zu", "dem", "Tan\u00b7ze", "gahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "Mit Freuden zu dem Tanze,", "tokens": ["Mit", "Freu\u00b7den", "zu", "dem", "Tan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit Trauren wieder heim,", "tokens": ["Mit", "Trau\u00b7ren", "wie\u00b7der", "heim", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So geht es jedem M\u00e4dle,", "tokens": ["So", "geht", "es", "je\u00b7dem", "M\u00e4d\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "M\u00e4dle, M\u00e4dle,", "tokens": ["M\u00e4d\u00b7le", ",", "M\u00e4d\u00b7le", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Und nit nur mir allein.", "tokens": ["Und", "nit", "nur", "mir", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Dort droben auf jenem Berge,", "tokens": ["Dort", "dro\u00b7ben", "auf", "je\u00b7nem", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da steht ein sch\u00f6nes Haus,", "tokens": ["Da", "steht", "ein", "sch\u00f6\u00b7nes", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da schauen alle Morgen,", "tokens": ["Da", "schau\u00b7en", "al\u00b7le", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Morgen, Morgen,", "tokens": ["Mor\u00b7gen", ",", "Mor\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Drey sch\u00f6ne Herren raus.", "tokens": ["Drey", "sch\u00f6\u00b7ne", "Her\u00b7ren", "raus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der Erst der ist mein Bruder,", "tokens": ["Der", "Erst", "der", "ist", "mein", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Zweite geht mich an,", "tokens": ["Der", "Zwei\u00b7te", "geht", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den Dritten thu ich nicht nennen,", "tokens": ["Den", "Drit\u00b7ten", "thu", "ich", "nicht", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Nennen, nennen,", "tokens": ["Nen\u00b7nen", ",", "nen\u00b7nen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Der ist euch wohl bekannt.", "tokens": ["Der", "ist", "euch", "wohl", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und unten an dem Berge,", "tokens": ["Und", "un\u00b7ten", "an", "dem", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da geht ein rothe Kuh.", "tokens": ["Da", "geht", "ein", "ro\u00b7the", "Kuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie die Magd thut melken,", "tokens": ["Wenn", "sie", "die", "Magd", "thut", "mel\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Melken, melken,", "tokens": ["Mel\u00b7ken", ",", "mel\u00b7ken", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Schaun ihr die Herren zu.", "tokens": ["Schaun", "ihr", "die", "Her\u00b7ren", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Sie th\u00e4t die Milch versch\u00fctten,", "tokens": ["Sie", "th\u00e4t", "die", "Milch", "ver\u00b7sch\u00fct\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mit Wasser f\u00fcllt sie zu:", "tokens": ["Mit", "Was\u00b7ser", "f\u00fcllt", "sie", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach Mutter, liebe Mutter,", "tokens": ["Ach", "Mut\u00b7ter", ",", "lie\u00b7be", "Mut\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mutter, Mutter,", "tokens": ["Mut\u00b7ter", ",", "Mut\u00b7ter", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Die Milch giebt unser Kuh.", "tokens": ["Die", "Milch", "giebt", "un\u00b7ser", "Kuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wir wollen die Kuh verkaufen,", "tokens": ["Wir", "wol\u00b7len", "die", "Kuh", "ver\u00b7kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "So kommt der Gstank vom Haus;", "tokens": ["So", "kommt", "der", "Gs\u00b7tank", "vom", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "So k\u00f6nnen h\u00fcbsch die Herren,", "tokens": ["So", "k\u00f6n\u00b7nen", "h\u00fcbsch", "die", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herren, Herren", "tokens": ["Her\u00b7ren", ",", "Her\u00b7ren"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Spazieren um unser Haus.", "tokens": ["Spa\u00b7zie\u00b7ren", "um", "un\u00b7ser", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Und dr\u00fcben an dem Berge,", "tokens": ["Und", "dr\u00fc\u00b7ben", "an", "dem", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da stehn zwey B\u00e4umelein,", "tokens": ["Da", "stehn", "zwey", "B\u00e4u\u00b7me\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das eine tr\u00e4gt Muskate,", "tokens": ["Das", "ei\u00b7ne", "tr\u00e4gt", "Mus\u00b7ka\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Muskate, Muskate,", "tokens": ["Mus\u00b7ka\u00b7te", ",", "Mus\u00b7ka\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Das zweyt braun N\u00e4gelein.", "tokens": ["Das", "zweyt", "braun", "N\u00e4\u00b7ge\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Muskatennu\u00df sind s\u00fc\u00dfe,", "tokens": ["Mus\u00b7ka\u00b7ten\u00b7nu\u00df", "sind", "s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Braun N\u00e4glein die sind r\u00e4\u00df (scharf),", "tokens": ["Braun", "N\u00e4g\u00b7lein", "die", "sind", "r\u00e4\u00df", "(", "scharf", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$(", "VVFIN", "$(", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Die geb ich meinem Liebchen,", "tokens": ["Die", "geb", "ich", "mei\u00b7nem", "Lieb\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Liebchen, Liebchen,", "tokens": ["Lieb\u00b7chen", ",", "Lieb\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Da\u00df es mich nicht verge\u00df.", "tokens": ["Da\u00df", "es", "mich", "nicht", "ver\u00b7ge\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Hab deiner nie vergessen,", "tokens": ["Hab", "dei\u00b7ner", "nie", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hab alle Zeit an dich gedenkt;", "tokens": ["Hab", "al\u00b7le", "Zeit", "an", "dich", "ge\u00b7denkt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du liegst mir stets am Herzen,", "tokens": ["Du", "liegst", "mir", "stets", "am", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herzen, Herzen,", "tokens": ["Her\u00b7zen", ",", "Her\u00b7zen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Wie d'Ros' am Stiele h\u00e4ngt.", "tokens": ["Wie", "d'\u00b7Ros", "'", "am", "Stie\u00b7le", "h\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$(", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Dort unten auf der Wiese,", "tokens": ["Dort", "un\u00b7ten", "auf", "der", "Wie\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da geht ein M\u00fchlen Rad,", "tokens": ["Da", "geht", "ein", "M\u00fch\u00b7len", "Rad", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das mahlet nichts als Liebe,", "tokens": ["Das", "mah\u00b7let", "nichts", "als", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Liebe, Liebe,", "tokens": ["Lie\u00b7be", ",", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Vom Abend bis zum Tag.", "tokens": ["Vom", "A\u00b7bend", "bis", "zum", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Das M\u00fchlenrad isch brochen,", "tokens": ["Das", "M\u00fch\u00b7len\u00b7rad", "isch", "bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Lieb hat noch kein End;", "tokens": ["Die", "Lieb", "hat", "noch", "kein", "End", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wann zwey Liebchen scheiden,", "tokens": ["Und", "wann", "zwey", "Lieb\u00b7chen", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Scheiden, scheiden,", "tokens": ["Schei\u00b7den", ",", "schei\u00b7den", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "So geben sie sich die H\u00e4nd.", "tokens": ["So", "ge\u00b7ben", "sie", "sich", "die", "H\u00e4nd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Ach Scheiden \u00fcber Scheiden,", "tokens": ["Ach", "Schei\u00b7den", "\u00fc\u00b7ber", "Schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Isch gar ein bittres Kraut;", "tokens": ["Isch", "gar", "ein", "bitt\u00b7res", "Kraut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wann ich w\u00fc\u00dfte, wo es w\u00fcchse,", "tokens": ["Wann", "ich", "w\u00fc\u00df\u00b7te", ",", "wo", "es", "w\u00fcch\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fcchse, w\u00fcchse,", "tokens": ["W\u00fcch\u00b7se", ",", "w\u00fcch\u00b7se", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Wollt graben Wurzel raus.", "tokens": ["Wollt", "gra\u00b7ben", "Wur\u00b7zel", "raus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Grab raus, grab raus mit Freuden,", "tokens": ["Grab", "raus", ",", "grab", "raus", "mit", "Freu\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Und nimm sie mit dir heim;", "tokens": ["Und", "nimm", "sie", "mit", "dir", "heim", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Leg sie in dein Schlafk\u00e4mmerlein,", "tokens": ["Leg", "sie", "in", "dein", "Schlaf\u00b7k\u00e4m\u00b7mer\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schlafk\u00e4mmerlein,", "tokens": ["Schlaf\u00b7k\u00e4m\u00b7mer\u00b7lein", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "So hast du W\u00fcrzelein.", "tokens": ["So", "hast", "du", "W\u00fcr\u00b7zel\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}