{"textgrid.poem.51384": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "Dem durchlauchtigen Ober-Haupte Fruchtbringender Gesellschafft. Dem Schmackhafften", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nicht blo\u00df \u00fcber viel Festen, St\u00e4dt und Flecken,", "tokens": ["Nicht", "blo\u00df", "\u00fc\u00b7ber", "viel", "Fes\u00b7ten", ",", "St\u00e4dt", "und", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PIAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Was vor Leute die Stern auch drunter decken:", "tokens": ["Was", "vor", "Leu\u00b7te", "die", "Stern", "auch", "drun\u00b7ter", "de\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ART", "NN", "ADV", "PAV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Sondern \u00fcber viel K\u00fcnst' und weise Schrifften,", "tokens": ["Son\u00b7dern", "\u00fc\u00b7ber", "viel", "K\u00fcnst'", "und", "wei\u00b7se", "Schriff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "So die Deutsche Gesellschafft wei\u00df zu stifften:", "tokens": ["So", "die", "Deut\u00b7sche", "Ge\u00b7sell\u00b7schafft", "wei\u00df", "zu", "stiff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "/: O ein \u00fcberaus herrliches Gebiete!:/", "tokens": ["/", ":", "O", "ein", "\u00fc\u00b7be\u00b7raus", "herr\u00b7li\u00b7ches", "Ge\u00b7bie\u00b7te", "!", ":/"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "punct", "emoticon"], "pos": ["$(", "$.", "NE", "ART", "ADV", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Hertzog vom Wittikindischen Gebl\u00fcte!", "tokens": ["Hert\u00b7zog", "vom", "Wit\u00b7ti\u00b7kin\u00b7di\u00b7schen", "Ge\u00b7bl\u00fc\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Da\u00df die Fackel vom Ober Sachsen Creisse", "tokens": ["Da\u00df", "die", "Fa\u00b7ckel", "vom", "O\u00b7ber", "Sach\u00b7sen", "Creis\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN", "NE", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Euer Weinmar mich also weichen heisse,", "tokens": ["Eu\u00b7er", "Wein\u00b7mar", "mich", "al\u00b7so", "wei\u00b7chen", "heis\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADV", "VVINF", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Als vermessen durch eures Schlosses Bogen", "tokens": ["Als", "ver\u00b7mes\u00b7sen", "durch", "eu\u00b7res", "Schlos\u00b7ses", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VVPP", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Dieser deutsche Phaleucus kommt gezogen.", "tokens": ["Die\u00b7ser", "deut\u00b7sche", "Pha\u00b7leu\u00b7cus", "kommt", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}}, "stanza.3": {"line.1": {"text": "Jedoch, unter so hocherlauchten Helden,", "tokens": ["Je\u00b7doch", ",", "un\u00b7ter", "so", "ho\u00b7cher\u00b7lauch\u00b7ten", "Hel\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "So von Alpen bi\u00df an Codan zu melden,", "tokens": ["So", "von", "Al\u00b7pen", "bi\u00df", "an", "Co\u00b7dan", "zu", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lasset Eure Trabanten, Euch zu gr\u00fcssen,", "tokens": ["Las\u00b7set", "Eu\u00b7re", "Tra\u00b7ban\u00b7ten", ",", "Euch", "zu", "gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Mir die unterste Staffel nicht verschliessen.", "tokens": ["Mir", "die", "un\u00b7ters\u00b7te", "Staf\u00b7fel", "nicht", "ver\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Von dem Zobten Berg und der Oder Rande", "tokens": ["Von", "dem", "Zob\u00b7ten", "Berg", "und", "der", "O\u00b7der", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "ART", "NE", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Komm an Ettersberg ich zur Sala Strande:", "tokens": ["Komm", "an", "Et\u00b7ters\u00b7berg", "ich", "zur", "Sa\u00b7la", "Stran\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PPER", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Von der Stadt, die genannt wird von dem Schweine:", "tokens": ["Von", "der", "Stadt", ",", "die", "ge\u00b7nannt", "wird", "von", "dem", "Schwei\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVPP", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Zu der Stadt, die genannt wird von dem Weine.", "tokens": ["Zu", "der", "Stadt", ",", "die", "ge\u00b7nannt", "wird", "von", "dem", "Wei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVPP", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Derowegen, o Haupt der kl\u00fcgsten Sinnen,", "tokens": ["De\u00b7ro\u00b7we\u00b7gen", ",", "o", "Haupt", "der", "kl\u00fcgs\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So die Crone der Wissenschafft beginnen:", "tokens": ["So", "die", "Cro\u00b7ne", "der", "Wis\u00b7sen\u00b7schafft", "be\u00b7gin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und den Weinmarischen Hof weit vor Iberen,", "tokens": ["Und", "den", "Wein\u00b7ma\u00b7ri\u00b7schen", "Hof", "weit", "vor", "I\u00b7be\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJD", "APPR", "NE", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Weit vor Gallien, weit vor Rom verehren.", "tokens": ["Weit", "vor", "Gal\u00b7li\u00b7en", ",", "weit", "vor", "Rom", "ver\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "$,", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Untern B\u00fcchern und Schrifften, so zu preisen,", "tokens": ["Un\u00b7tern", "B\u00fc\u00b7chern", "und", "Schriff\u00b7ten", ",", "so", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Unter K\u00fcnsten und Sachen alter Weisen:", "tokens": ["Un\u00b7ter", "K\u00fcns\u00b7ten", "und", "Sa\u00b7chen", "al\u00b7ter", "Wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Unter Sprachen und Lehren, so zu mercken,", "tokens": ["Un\u00b7ter", "Spra\u00b7chen", "und", "Leh\u00b7ren", ",", "so", "zu", "mer\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Unter Meistern von Deutscher Art und Wercken.", "tokens": ["Un\u00b7ter", "Meis\u00b7tern", "von", "Deut\u00b7scher", "Art", "und", "Wer\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.7": {"line.1": {"text": "Es sey: da\u00df sie den Geist der Tichter f\u00fchlen,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "den", "Geist", "der", "Tich\u00b7ter", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie sie an der gelehrten Pegnitz spielen:", "tokens": ["Wie", "sie", "an", "der", "ge\u00b7lehr\u00b7ten", "Peg\u00b7nitz", "spie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und in der Hecatombe recht betrachten,", "tokens": ["Und", "in", "der", "He\u00b7ca\u00b7tom\u00b7be", "recht", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo die Eitelkeit Balde bald wil schlachten.", "tokens": ["Wo", "die", "Ei\u00b7tel\u00b7keit", "Bal\u00b7de", "bald", "wil", "schlach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "ADV", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.8": {"line.1": {"text": "Es sey: da\u00df sie die Sonn an Himmel zwecken,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "die", "Sonn", "an", "Him\u00b7mel", "zwe\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihren Thier Circkel umb das Mittel stecken,", "tokens": ["Ih\u00b7ren", "Thier", "Cir\u00b7ckel", "umb", "das", "Mit\u00b7tel", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und die Irrstern in ihre Bogen schliessen,", "tokens": ["Und", "die", "Irrs\u00b7tern", "in", "ih\u00b7re", "Bo\u00b7gen", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Was nach hundert Jahrn sol geschehn, draus wissen:", "tokens": ["Was", "nach", "hun\u00b7dert", "Jahrn", "sol", "ge\u00b7schehn", ",", "draus", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "CARD", "NN", "VMFIN", "VVINF", "$,", "PAV", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Wie es Cunitia die Zier der Frauen", "tokens": ["Wie", "es", "Cu\u00b7ni\u00b7tia", "die", "Zier", "der", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "NE", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "In unsterbliche Taffeln hat gehauen:", "tokens": ["In", "uns\u00b7terb\u00b7li\u00b7che", "Taf\u00b7feln", "hat", "ge\u00b7hau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Es sey: da\u00df sie durch Stern und Fern Gesichte", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "durch", "Stern", "und", "Fern", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "APPR", "NN", "KON", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns die Ewigkeit machen hell und lichte:", "tokens": ["Uns", "die", "E\u00b7wig\u00b7keit", "ma\u00b7chen", "hell", "und", "lich\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und im Monden eine andre Welt beweisen,", "tokens": ["Und", "im", "Mon\u00b7den", "ei\u00b7ne", "and\u00b7re", "Welt", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "In die wir mit Gem\u00fcth und Augen reisen:", "tokens": ["In", "die", "wir", "mit", "Ge\u00b7m\u00fcth", "und", "Au\u00b7gen", "rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Drinnen Landschafften, Meer und Berge mercken,", "tokens": ["Drin\u00b7nen", "Land\u00b7schaff\u00b7ten", ",", "Meer", "und", "Ber\u00b7ge", "mer\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und den Sch\u00f6pffer verehrn in seinen Wercken:", "tokens": ["Und", "den", "Sch\u00f6pf\u00b7fer", "ver\u00b7ehrn", "in", "sei\u00b7nen", "Wer\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Wie es Hewelcke vor den Mund gerissen,", "tokens": ["Wie", "es", "He\u00b7wel\u00b7cke", "vor", "den", "Mund", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und vorf\u00fchret mit Grundgerechten Schl\u00fcssen:", "tokens": ["Und", "vor\u00b7f\u00fch\u00b7ret", "mit", "Grund\u00b7ge\u00b7rech\u00b7ten", "Schl\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Es sey: da\u00df der verborgene Grund der Erden", "tokens": ["Es", "sey", ":", "da\u00df", "der", "ver\u00b7bor\u00b7ge\u00b7ne", "Grund", "der", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch den Me\u00df Stab erkundiget sol werden:", "tokens": ["Durch", "den", "Me\u00df", "Stab", "er\u00b7kun\u00b7di\u00b7get", "sol", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "VMFIN", "VAINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und die Welt, die im Mittel noch sol stecken:", "tokens": ["Und", "die", "Welt", ",", "die", "im", "Mit\u00b7tel", "noch", "sol", "ste\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Die der Fuldische Kircher wil erwecken,", "tokens": ["Die", "der", "Ful\u00b7di\u00b7sche", "Kir\u00b7cher", "wil", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Der die Ursachen kan vom Licht und Schatten,", "tokens": ["Der", "die", "Ur\u00b7sa\u00b7chen", "kan", "vom", "Licht", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VMFIN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und vom Z\u00fcgstein und Einklang uns erstatten.", "tokens": ["Und", "vom", "Z\u00fcgs\u00b7tein", "und", "Ein\u00b7klang", "uns", "er\u00b7stat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.11": {"line.1": {"text": "Es sey: da\u00df das Geheimn\u00fcs in den Zahlen", "tokens": ["Es", "sey", ":", "da\u00df", "das", "Ge\u00b7heim\u00b7n\u00fcs", "in", "den", "Zah\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aus der Algebra uns sol \u00fcberstrahlen:", "tokens": ["Aus", "der", "Al\u00b7ge\u00b7bra", "uns", "sol", "\u00fc\u00b7bers\u00b7trah\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "PPER", "VMFIN", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und der Staub aus des Epicurus B\u00fcchern,", "tokens": ["Und", "der", "Staub", "aus", "des", "E\u00b7pi\u00b7cu\u00b7rus", "B\u00fc\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Den Gassendus so k\u00fcnstlich wei\u00df zu sichern.", "tokens": ["Den", "Gas\u00b7sen\u00b7dus", "so", "k\u00fcnst\u00b7lich", "wei\u00df", "zu", "si\u00b7chern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Es sey: da\u00df sie die Gottheit angeglommen,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "die", "Got\u00b7theit", "an\u00b7ge\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wie Paulus vom dritten Himmel kommen:", "tokens": ["Und", "wie", "Pau\u00b7lus", "vom", "drit\u00b7ten", "Him\u00b7mel", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und den Schl\u00fcssel zu den geheimen Gr\u00fcnden", "tokens": ["Und", "den", "Schl\u00fcs\u00b7sel", "zu", "den", "ge\u00b7hei\u00b7men", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--++-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "In dem Pathmoschen Offenbahrer finden:", "tokens": ["In", "dem", "Path\u00b7mo\u00b7schen", "Of\u00b7fen\u00b7bah\u00b7rer", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Welchen unter den vier und zwantzig Alten", "tokens": ["Wel\u00b7chen", "un\u00b7ter", "den", "vier", "und", "zwant\u00b7zig", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAT", "APPR", "ART", "CARD", "KON", "CARD", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Unser Mach\u00e6ropoeus wil erhalten.", "tokens": ["Un\u00b7ser", "Mach\u00e6ro\u00b7poeus", "wil", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Es sey: da\u00df sie Gericht und Recht verstehen,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "Ge\u00b7richt", "und", "Recht", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und nach Wissen und nach Gewissen gehen:", "tokens": ["Und", "nach", "Wis\u00b7sen", "und", "nach", "Ge\u00b7wis\u00b7sen", "ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Weder Schulen noch Kirchen in nichts trennen:", "tokens": ["We\u00b7der", "Schu\u00b7len", "noch", "Kir\u00b7chen", "in", "nichts", "tren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "NN", "APPR", "PIS", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Jedem seines /: Der Welt und Gott :/ zu nennen.", "tokens": ["Je\u00b7dem", "sei\u00b7nes", "/", ":", "Der", "Welt", "und", "Gott", ":/", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "emoticon", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "$(", "$.", "ART", "NN", "KON", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.14": {"line.1": {"text": "Es sey: da\u00df sie die Hand auf Artzney richten,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "die", "Hand", "auf", "Artz\u00b7ney", "rich\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und das Meisterthum in dem Glase schlichten:", "tokens": ["Und", "das", "Meis\u00b7ter\u00b7thum", "in", "dem", "Gla\u00b7se", "schlich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Und vom Ertzte, von Kra\u00fctern und von Thieren,", "tokens": ["Und", "vom", "Ertz\u00b7te", ",", "von", "Kr\u00b7a\u00fc\u00b7tern", "und", "von", "Thie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+-+--++-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Durch ihr Alkahest Geist und Wesen f\u00fchren,", "tokens": ["Durch", "ihr", "Al\u00b7ka\u00b7hest", "Geist", "und", "We\u00b7sen", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie Montanus das f\u00fcnffte von den Dingen", "tokens": ["Wie", "Mon\u00b7ta\u00b7nus", "das", "f\u00fcnff\u00b7te", "von", "den", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "ART", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Konte machen, und sich damit verj\u00fcngen.", "tokens": ["Kon\u00b7te", "ma\u00b7chen", ",", "und", "sich", "da\u00b7mit", "ver\u00b7j\u00fcn\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "KON", "PRF", "PAV", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Und was Hellas, was vor der Zeit zum minsten;", "tokens": ["Und", "was", "Hel\u00b7las", ",", "was", "vor", "der", "Zeit", "zum", "mins\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "$,", "PRELS", "APPR", "ART", "NN", "APPRART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Egyptier wust an weisen K\u00fcnsten:", "tokens": ["Der", "E\u00b7gyp\u00b7tier", "wust", "an", "wei\u00b7sen", "K\u00fcns\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und die Cabala uns bisher verhalten,", "tokens": ["Und", "die", "Ca\u00b7ba\u00b7la", "uns", "bis\u00b7her", "ver\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "ADV", "VVINF", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So von Engeln empfiengen unsre Alten:", "tokens": ["So", "von", "En\u00b7geln", "emp\u00b7fi\u00b7en\u00b7gen", "uns\u00b7re", "Al\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Es sey, da\u00df an des Deutschen Palmbaums Rinden", "tokens": ["Es", "sey", ",", "da\u00df", "an", "des", "Deut\u00b7schen", "Palm\u00b7baums", "Rin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es gepr\u00e4get steht, oder sich wird finden.", "tokens": ["Es", "ge\u00b7pr\u00e4\u00b7get", "steht", ",", "o\u00b7der", "sich", "wird", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VVFIN", "$,", "KON", "PRF", "VAFIN", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Herr, nu unter so hochgepreisten Sachen,", "tokens": ["Herr", ",", "nu", "un\u00b7ter", "so", "hoch\u00b7ge\u00b7preis\u00b7ten", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die zum Deutschlande Deutschland ersten machen:", "tokens": ["Die", "zum", "Deutschlan\u00b7de", "Deutschland", "ers\u00b7ten", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "ADJA", "NN", "VVFIN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Unter kunstreichen Wercken, die dem Orden", "tokens": ["Un\u00b7ter", "kuns\u00b7trei\u00b7chen", "Wer\u00b7cken", ",", "die", "dem", "Or\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Der fruchtbringenden Ritterschafft sind worden:", "tokens": ["Der", "frucht\u00b7brin\u00b7gen\u00b7den", "Rit\u00b7ter\u00b7schafft", "sind", "wor\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VAPP", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.17": {"line.1": {"text": "Nehmet: weit von den wichtigen Gesch\u00e4fften,", "tokens": ["Neh\u00b7met", ":", "weit", "von", "den", "wich\u00b7ti\u00b7gen", "Ge\u00b7sch\u00e4ff\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die das F\u00fcrstliche Hertz an Sorgen hefften:", "tokens": ["Die", "das", "F\u00fcrst\u00b7li\u00b7che", "Hertz", "an", "Sor\u00b7gen", "heff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wie die Wolfarth der Deutschen zu versichern,", "tokens": ["Wie", "die", "Wolf\u00b7arth", "der", "Deut\u00b7schen", "zu", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Auf dem Reichstag an Waffen und an B\u00fcchern:", "tokens": ["Auf", "dem", "Reichs\u00b7tag", "an", "Waf\u00b7fen", "und", "an", "B\u00fc\u00b7chern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Auf dem Reichstag: auf dem das Wolvertrauen", "tokens": ["Auf", "dem", "Reichs\u00b7tag", ":", "auf", "dem", "das", "Wol\u00b7ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "APPR", "PRELS", "ART", "NN"], "meter": "--+-++-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "\u00dcber Deutschland wird von dem Himmel schauen.", "tokens": ["\u00dc\u00b7ber", "Deutschland", "wird", "von", "dem", "Him\u00b7mel", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "Nehmet: Draus wir noch sehn das Feuer schrauben,", "tokens": ["Neh\u00b7met", ":", "Draus", "wir", "noch", "sehn", "das", "Feu\u00b7er", "schrau\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PAV", "PPER", "ADV", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Weit von Schlacht Schwerdtern, weit von Pickelhauben,", "tokens": ["Weit", "von", "Schlacht", "Schwerd\u00b7tern", ",", "weit", "von", "Pi\u00b7ckel\u00b7hau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die der Deutsche Carl und dann, als sie schlugen,", "tokens": ["Die", "der", "Deut\u00b7sche", "Carl", "und", "dann", ",", "als", "sie", "schlu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NE", "KON", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wittikindus an Haubt und Fa\u00fcsten trugen,", "tokens": ["Wit\u00b7ti\u00b7kin\u00b7dus", "an", "Haubt", "und", "Fa\u00fcs\u00b7ten", "tru\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und zur Erbschafft verliessen, wie sie lauten,", "tokens": ["Und", "zur", "Erb\u00b7schafft", "ver\u00b7lies\u00b7sen", ",", "wie", "sie", "lau\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Dessen Enckeln gekr\u00f6nt mir gr\u00fcner Rauten.", "tokens": ["Des\u00b7sen", "En\u00b7ckeln", "ge\u00b7kr\u00f6nt", "mir", "gr\u00fc\u00b7ner", "Rau\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVPP", "PPER", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "Nehmet: weit sag ich von dem frommen Sorgen,", "tokens": ["Neh\u00b7met", ":", "weit", "sag", "ich", "von", "dem", "from\u00b7men", "Sor\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADJD", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+----+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "So die Sonne zu Abend und zu Morgen", "tokens": ["So", "die", "Son\u00b7ne", "zu", "A\u00b7bend", "und", "zu", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Vor die Kirche, vor euer Land und Leute,", "tokens": ["Vor", "die", "Kir\u00b7che", ",", "vor", "eu\u00b7er", "Land", "und", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Euch zutheilet als eures Standes Beute.", "tokens": ["Euch", "zu\u00b7thei\u00b7let", "als", "eu\u00b7res", "Stan\u00b7des", "Beu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.20": {"line.1": {"text": "Wann ein Lang \u00d6rchen unterm raschen Hetzen", "tokens": ["Wann", "ein", "Lang", "\u00d6r\u00b7chen", "un\u00b7term", "ra\u00b7schen", "Het\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das erlauchte Gem\u00fcthe wird erg\u00f6tzen:", "tokens": ["Das", "er\u00b7lauch\u00b7te", "Ge\u00b7m\u00fc\u00b7the", "wird", "er\u00b7g\u00f6t\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wann ein Schwartz- oder Roth-Wild unterm Sterben", "tokens": ["Wann", "ein", "Schwartz", "o\u00b7der", "Ro\u00b7th\u00b7Wild", "un\u00b7term", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "TRUNC", "KON", "NN", "APPRART", "NN"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wird das theilende Weide Messer f\u00e4rben:", "tokens": ["Wird", "das", "thei\u00b7len\u00b7de", "Wei\u00b7de", "Mes\u00b7ser", "f\u00e4r\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.21": {"line.1": {"text": "Wann die Zwiebeln von so viel bunten Arten", "tokens": ["Wann", "die", "Zwie\u00b7beln", "von", "so", "viel", "bun\u00b7ten", "Ar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ADV", "PIAT", "ADJA", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie die Tulipen mahlen in dem Garten,", "tokens": ["Sie", "die", "Tu\u00b7li\u00b7pen", "mah\u00b7len", "in", "dem", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und Carnarische Zei\u00dfgen untern Zweigen", "tokens": ["Und", "Car\u00b7na\u00b7ri\u00b7sche", "Zei\u00df\u00b7gen", "un\u00b7tern", "Zwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Gesicht und Geh\u00f6r werden neigen:", "tokens": ["Das", "Ge\u00b7sicht", "und", "Ge\u00b7h\u00f6r", "wer\u00b7den", "nei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAINF", "VVFIN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.22": {"line.1": {"text": "Hertzog, wann die gelehrten Eitelkeiten", "tokens": ["Hert\u00b7zog", ",", "wann", "die", "ge\u00b7lehr\u00b7ten", "Ei\u00b7tel\u00b7kei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach der Taffel euch eine Lust bereiten,", "tokens": ["Nach", "der", "Taf\u00b7fel", "euch", "ei\u00b7ne", "Lust", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und der Traurigkeit suchen zu entladen:", "tokens": ["Und", "der", "Trau\u00b7rig\u00b7keit", "su\u00b7chen", "zu", "ent\u00b7la\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Alsdenn Nehmet die Schlu\u00df-Reim an in Gnaden.", "tokens": ["Als\u00b7denn", "Neh\u00b7met", "die", "Schlu\u00df\u00b7Reim", "an", "in", "Gna\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.23": {"line.1": {"text": "Sie sind: Alle setz ich daf\u00fcr zu Pfande:", "tokens": ["Sie", "sind", ":", "Al\u00b7le", "setz", "ich", "da\u00b7f\u00fcr", "zu", "Pfan\u00b7de", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "PIS", "VVFIN", "PPER", "PAV", "APPR", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Kurtz an Worten, lang aber am Verstande,", "tokens": ["Kurtz", "an", "Wor\u00b7ten", ",", "lang", "a\u00b7ber", "am", "Ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Herb an Wurtzeln, s\u00fc\u00df aber an den Keimen,", "tokens": ["Herb", "an", "Wurt\u00b7zeln", ",", "s\u00fc\u00df", "a\u00b7ber", "an", "den", "Kei\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Schwer an Lehren, leicht aber an den Reimen.", "tokens": ["Schwer", "an", "Leh\u00b7ren", ",", "leicht", "a\u00b7ber", "an", "den", "Rei\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.24": {"line.1": {"text": "Kurtz: man kan sie bald nehmen, bald hinlegen:", "tokens": ["Kurtz", ":", "man", "kan", "sie", "bald", "neh\u00b7men", ",", "bald", "hin\u00b7le\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$.", "PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lang: man sol sie stets lesen, stets erwegen:", "tokens": ["Lang", ":", "man", "sol", "sie", "stets", "le\u00b7sen", ",", "stets", "er\u00b7we\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Herbe: wer sie wil nach den Worten setzen:", "tokens": ["Her\u00b7be", ":", "wer", "sie", "wil", "nach", "den", "Wor\u00b7ten", "set\u00b7zen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "S\u00fcsse: wer sie kan nach dem Geiste sch\u00e4tzen:", "tokens": ["S\u00fcs\u00b7se", ":", "wer", "sie", "kan", "nach", "dem", "Geis\u00b7te", "sch\u00e4t\u00b7zen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Schwer: ein ieder sol nach den Lehren leben:", "tokens": ["Schwer", ":", "ein", "ie\u00b7der", "sol", "nach", "den", "Leh\u00b7ren", "le\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ART", "PIS", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Leicht: ein ieder darff sich blo\u00df Gott ergeben.", "tokens": ["Leicht", ":", "ein", "ie\u00b7der", "darff", "sich", "blo\u00df", "Gott", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "PIS", "VMFIN", "PRF", "ADV", "NN", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.25": {"line.1": {"text": "Statt der leutseeligen Erg\u00f6tzlichkeiten:", "tokens": ["Statt", "der", "leut\u00b7see\u00b7li\u00b7gen", "Er\u00b7g\u00f6tz\u00b7lich\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Statt der kargen Vergessenheit der Zeiten:", "tokens": ["Statt", "der", "kar\u00b7gen", "Ver\u00b7ges\u00b7sen\u00b7heit", "der", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Statt der fleissigen M\u00fcssigg\u00e4ng und Wesen:", "tokens": ["Statt", "der", "fleis\u00b7si\u00b7gen", "M\u00fcs\u00b7sig\u00b7g\u00e4ng", "und", "We\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sind die Reime zwar aufgesetzt zu lesen.", "tokens": ["Sind", "die", "Rei\u00b7me", "zwar", "auf\u00b7ge\u00b7setzt", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.26": {"line.1": {"text": "Aber: Er: wann er gl\u00fcht von Abendtheuern,", "tokens": ["A\u00b7ber", ":", "Er", ":", "wann", "er", "gl\u00fcht", "von", "A\u00b7bendt\u00b7heu\u00b7ern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "PPER", "$.", "PWAV", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Die sein hitziges Hertz und Haubt durchfeuern:", "tokens": ["Die", "sein", "hit\u00b7zi\u00b7ges", "Hertz", "und", "Haubt", "durch\u00b7feu\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wann die G\u00f6ttliche Regung reitzt die Sinnen,", "tokens": ["Wann", "die", "G\u00f6tt\u00b7li\u00b7che", "Re\u00b7gung", "reitzt", "die", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Mag der Tichter die Schlu\u00df Reim auch beginnen:", "tokens": ["Mag", "der", "Tich\u00b7ter", "die", "Schlu\u00df", "Reim", "auch", "be\u00b7gin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Er sol leben viel eh, als Reimen lernen,", "tokens": ["Er", "sol", "le\u00b7ben", "viel", "eh", ",", "als", "Rei\u00b7men", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "ADV", "KOUS", "$,", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nicht nach Schaalen sich sehnen, sondern Kernen.", "tokens": ["Nicht", "nach", "Schaa\u00b7len", "sich", "seh\u00b7nen", ",", "son\u00b7dern", "Ker\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "PRF", "VVINF", "$,", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.27": {"line.1": {"text": "Er: wann Er: und was Er? wann sie vor Andern", "tokens": ["Er", ":", "wann", "Er", ":", "und", "was", "Er", "?", "wann", "sie", "vor", "An\u00b7dern"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$.", "PWAV", "PPER", "$.", "KON", "PWS", "PPER", "$.", "PWAV", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Cunitia wird auf Sternen wandern,", "tokens": ["Die", "Cu\u00b7ni\u00b7tia", "wird", "auf", "Ster\u00b7nen", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und den Ticho de Brahe \u00fcbersteigen,", "tokens": ["Und", "den", "Ti\u00b7cho", "de", "Bra\u00b7he", "\u00fc\u00b7bers\u00b7tei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "NE", "NE", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Mag ihr Antlitz sie auf die Staffel neigen.", "tokens": ["Mag", "ihr", "Ant\u00b7litz", "sie", "auf", "die", "Staf\u00b7fel", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Was sol jene thun? Es zeigt andre Wonne", "tokens": ["Was", "sol", "je\u00b7ne", "thun", "?", "Es", "zeigt", "and\u00b7re", "Won\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PDS", "VVINF", "$.", "PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Die am Creutzes Stamm angezweckte Sonne.", "tokens": ["Die", "am", "Creut\u00b7zes", "Stamm", "an\u00b7ge\u00b7zweck\u00b7te", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "Er: wann er durch das Fern Glas auf den H\u00f6hen", "tokens": ["Er", ":", "wann", "er", "durch", "das", "Fern", "Glas", "auf", "den", "H\u00f6\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$.", "PWAV", "PPER", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In die Sterne des Himmels sucht zu gehen,", "tokens": ["In", "die", "Ster\u00b7ne", "des", "Him\u00b7mels", "sucht", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die Raumstadt, ein Reich von keinen Gr\u00e4ntzen", "tokens": ["Und", "die", "Raum\u00b7stadt", ",", "ein", "Reich", "von", "kei\u00b7nen", "Gr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "In Gesicht und Gem\u00fcthe siehet gl\u00e4ntzen;", "tokens": ["In", "Ge\u00b7sicht", "und", "Ge\u00b7m\u00fc\u00b7the", "sie\u00b7het", "gl\u00e4nt\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Mag die Reime, durchf\u00e4rbt von Wonn und Wesen", "tokens": ["Mag", "die", "Rei\u00b7me", ",", "durch\u00b7f\u00e4rbt", "von", "Wonn", "und", "We\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "$,", "VVFIN", "APPR", "NE", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Der Beschauer der Wunder Gottes lesen:", "tokens": ["Der", "Be\u00b7schau\u00b7er", "der", "Wun\u00b7der", "Got\u00b7tes", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Er kan inner sich Gott: in Gott die Sachen", "tokens": ["Er", "kan", "in\u00b7ner", "sich", "Gott", ":", "in", "Gott", "die", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "PRF", "NN", "$.", "APPR", "NN", "ART", "NN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.8": {"text": "Ihm bekannter als Galil\u00e6us machen.", "tokens": ["Ihm", "be\u00b7kann\u00b7ter", "als", "Ga\u00b7lil\u00e6us", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KOKOM", "NE", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Er: wann er mit dem Bley und Winckel-Eysen", "tokens": ["Er", ":", "wann", "er", "mit", "dem", "Bley", "und", "Win\u00b7ckel\u00b7Ey\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$.", "PWAV", "PPER", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wil vom Nordstern an bis zum Creutze reisen,", "tokens": ["Wil", "vom", "Nords\u00b7tern", "an", "bis", "zum", "Creut\u00b7ze", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "APPR", "APPR", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Und die Ruhstatt der schriemen Nabe sehen,", "tokens": ["Und", "die", "Ruh\u00b7statt", "der", "schrie\u00b7men", "Na\u00b7be", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Mit dem Fusse da stehn: die Welt umdrehen:", "tokens": ["Mit", "dem", "Fus\u00b7se", "da", "stehn", ":", "die", "Welt", "um\u00b7dre\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF", "$.", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Welche ein Archimedes kont erfragen,", "tokens": ["Wel\u00b7che", "ein", "Ar\u00b7chi\u00b7me\u00b7des", "kont", "er\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+--+---+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Mag der Feld Me\u00dfer auch das Buch aufschlagen:", "tokens": ["Mag", "der", "Feld", "Me\u00b7\u00dfer", "auch", "das", "Buch", "auf\u00b7schla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Das Wort Gottes das h\u00e4lt die beyden Schrauben,", "tokens": ["Das", "Wort", "Got\u00b7tes", "das", "h\u00e4lt", "die", "bey\u00b7den", "Schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PDS", "VVFIN", "ART", "PIAT", "NN", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Das ergr\u00fcndet kein Dreyeck, sondern Glauben.", "tokens": ["Das", "er\u00b7gr\u00fcn\u00b7det", "kein", "Drey\u00b7eck", ",", "son\u00b7dern", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "$,", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.30": {"line.1": {"text": "Er: wann er wil die Zahl auf Bl\u00e4tter schreiben,", "tokens": ["Er", ":", "wann", "er", "wil", "die", "Zahl", "auf", "Bl\u00e4t\u00b7ter", "schrei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und bezifferte Zaubereyen treiben:", "tokens": ["Und", "be\u00b7zif\u00b7fer\u00b7te", "Zau\u00b7be\u00b7re\u00b7yen", "trei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wann er grossen Verstand daraus wird haben,", "tokens": ["Wann", "er", "gros\u00b7sen", "Ver\u00b7stand", "da\u00b7raus", "wird", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJA", "NN", "PAV", "VAFIN", "VAINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Weil das Ende der Welt Gott drein gegraben:", "tokens": ["Weil", "das", "En\u00b7de", "der", "Welt", "Gott", "drein", "ge\u00b7gra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "NN", "ADV", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Das Johannes und Daniel erwehlen:", "tokens": ["Das", "Jo\u00b7han\u00b7nes", "und", "Da\u00b7ni\u00b7el", "er\u00b7weh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NE", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Mag der Rechmeister auch die Schl\u00fcsse zehlen:", "tokens": ["Mag", "der", "Rech\u00b7meis\u00b7ter", "auch", "die", "Schl\u00fcs\u00b7se", "zeh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wer die Raitung der Welt, wie sie, wil schl\u00fcssen,", "tokens": ["Wer", "die", "Rai\u00b7tung", "der", "Welt", ",", "wie", "sie", ",", "wil", "schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "$,", "PWAV", "PPER", "$,", "VMFIN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Mu\u00df auch Ihr Einmal Eins im Geiste wissen.", "tokens": ["Mu\u00df", "auch", "Ihr", "Ein\u00b7mal", "Eins", "im", "Geis\u00b7te", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "ADV", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Er: wann er wird in Gottes Willen stehen,", "tokens": ["Er", ":", "wann", "er", "wird", "in", "Got\u00b7tes", "Wil\u00b7len", "ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VAFIN", "APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und des Glaubens Krafft in dem Geist erh\u00f6hen:", "tokens": ["Und", "des", "Glau\u00b7bens", "Krafft", "in", "dem", "Geist", "er\u00b7h\u00f6\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wann der Geist das Licht wird schaun in dem Lichte,", "tokens": ["Wann", "der", "Geist", "das", "Licht", "wird", "schaun", "in", "dem", "Lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VAFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und Gott selbst von Gesichte zu Gesichte:", "tokens": ["Und", "Gott", "selbst", "von", "Ge\u00b7sich\u00b7te", "zu", "Ge\u00b7sich\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wann in Gottes Bild ihn das Schaun wird setzen,", "tokens": ["Wann", "in", "Got\u00b7tes", "Bild", "ihn", "das", "Schaun", "wird", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "NN", "PPER", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hertz und Lehrstuhl erf\u00fclln mit reichen Sch\u00e4tzen:", "tokens": ["Hertz", "und", "Lehr\u00b7stuhl", "er\u00b7f\u00fclln", "mit", "rei\u00b7chen", "Sch\u00e4t\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Mag der Geistliche singen ohn Versehren", "tokens": ["Mag", "der", "Geist\u00b7li\u00b7che", "sin\u00b7gen", "ohn", "Ver\u00b7seh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Auch dem Sterbenden diese weise Lehren.", "tokens": ["Auch", "dem", "Ster\u00b7ben\u00b7den", "die\u00b7se", "wei\u00b7se", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PDAT", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Nicht sein, sondern das Wort sol er erheben,", "tokens": ["Nicht", "sein", ",", "son\u00b7dern", "das", "Wort", "sol", "er", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAINF", "$,", "KON", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Das im Buchstaben todt, im Geiste ist Leben.", "tokens": ["Das", "im", "Buch\u00b7sta\u00b7ben", "todt", ",", "im", "Geis\u00b7te", "ist", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "ADJD", "$,", "APPRART", "NN", "VAFIN", "NN", "$."], "meter": "---+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Er: wann er wird das Recht den Kl\u00e4gern sprechen,", "tokens": ["Er", ":", "wann", "er", "wird", "das", "Recht", "den", "Kl\u00e4\u00b7gern", "spre\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und den Stab \u00fcber \u00dcbelth\u00e4ter brechen:", "tokens": ["Und", "den", "Stab", "\u00fc\u00b7ber", "\u00dc\u00b7belt\u00b7h\u00e4\u00b7ter", "bre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "--++-+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Schwerd und Wage befreyt von Blut und Gaben", "tokens": ["Schwerd", "und", "Wa\u00b7ge", "be\u00b7freyt", "von", "Blut", "und", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVPP", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Dem Gecreutzigten eingeh\u00e4ndiget haben:", "tokens": ["Dem", "Ge\u00b7cr\u00b7eut\u00b7zig\u00b7ten", "ein\u00b7ge\u00b7h\u00e4n\u00b7di\u00b7get", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Und sein End Urtheil Christlich \u00fcberlegen,", "tokens": ["Und", "sein", "End", "Ur\u00b7theil", "Christ\u00b7lich", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mag der Richter die Zwey-Reim auch erwegen:", "tokens": ["Mag", "der", "Rich\u00b7ter", "die", "Zwey\u00b7Reim", "auch", "er\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Wie er Menschen, so wird Gott auch Ihn richten,", "tokens": ["Wie", "er", "Men\u00b7schen", ",", "so", "wird", "Gott", "auch", "Ihn", "rich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "$,", "ADV", "VAFIN", "NN", "ADV", "PPER", "VVINF", "$,"], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und so seine Sache, als er ihre schlichten.", "tokens": ["Und", "so", "sei\u00b7ne", "Sa\u00b7che", ",", "als", "er", "ih\u00b7re", "schlich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.33": {"line.1": {"text": "Er: wann er wird das Ertz-Saltz \u00fcberkochen,", "tokens": ["Er", ":", "wann", "er", "wird", "das", "Ertz\u00b7Saltz", "\u00fc\u00b7ber\u00b7ko\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und den ersten Zeug aller Dinge suchen,", "tokens": ["Und", "den", "ers\u00b7ten", "Zeug", "al\u00b7ler", "Din\u00b7ge", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PIAT", "NN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wird den felsichten Rauch im Glase sperren:", "tokens": ["Wird", "den", "fel\u00b7sich\u00b7ten", "Rauch", "im", "Gla\u00b7se", "sper\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und die f\u00e4rbende Krafft des Wassers d\u00f6rren:", "tokens": ["Und", "die", "f\u00e4r\u00b7ben\u00b7de", "Krafft", "des", "Was\u00b7sers", "d\u00f6r\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Wird den Raph\u00e4el an dem Theil erheben,", "tokens": ["Wird", "den", "Ra\u00b7ph\u00e4\u00b7el", "an", "dem", "Theil", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den mein Franckenberg an das Licht gegeben:", "tokens": ["Den", "mein", "Fran\u00b7cken\u00b7berg", "an", "das", "Licht", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Und die Gabe des H\u00f6chsten dr\u00fcber preisen,", "tokens": ["Und", "die", "Ga\u00b7be", "des", "H\u00f6chs\u00b7ten", "dr\u00fc\u00b7ber", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "PAV", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Mag der Artzt die Gedicht auch Krancken weisen:", "tokens": ["Mag", "der", "Artzt", "die", "Ge\u00b7dicht", "auch", "Kran\u00b7cken", "wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "ADV", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Er sol sich vor erforschen, drauff die Erde.", "tokens": ["Er", "sol", "sich", "vor", "er\u00b7for\u00b7schen", ",", "drauff", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "VVINF", "$,", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ihm vor selber genung thun, drauff dem Heerde.", "tokens": ["Ihm", "vor", "sel\u00b7ber", "ge\u00b7nung", "thun", ",", "drauff", "dem", "Heer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADV", "ADV", "VVINF", "$,", "PAV", "ART", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.34": {"line.1": {"text": "Auch, die \u00fcber des Nilus R\u00e4tzel rathen,", "tokens": ["Auch", ",", "die", "\u00fc\u00b7ber", "des", "Ni\u00b7lus", "R\u00e4t\u00b7zel", "ra\u00b7then", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "APPR", "ART", "NE", "NN", "VVFIN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und die Wunderschrifft dieser Welt erstatten,", "tokens": ["Und", "die", "Wun\u00b7der\u00b7schrifft", "die\u00b7ser", "Welt", "er\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PDAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die die Buchstaben vom Gew\u00fcrm und Thieren", "tokens": ["Die", "die", "Buch\u00b7sta\u00b7ben", "vom", "Ge\u00b7w\u00fcrm", "und", "Thie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Itzt aus der Pharaonschen Mund Art f\u00fchren.", "tokens": ["Itzt", "aus", "der", "Pha\u00b7raon\u00b7schen", "Mund", "Art", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und die Wissenschafft von geheimen Dingen", "tokens": ["Und", "die", "Wis\u00b7sen\u00b7schafft", "von", "ge\u00b7hei\u00b7men", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Durch den Oedipus aus Egypten bringen.", "tokens": ["Durch", "den", "O\u00b7e\u00b7di\u00b7pus", "aus", "E\u00b7gyp\u00b7ten", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.35": {"line.1": {"text": "Auch, die spannen auf Orpheus seine Saiten,", "tokens": ["Auch", ",", "die", "span\u00b7nen", "auf", "Or\u00b7pheus", "sei\u00b7ne", "Sai\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "VVFIN", "APPR", "NE", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und der Griechischen Argo Lauff begleiten,", "tokens": ["Und", "der", "Grie\u00b7chi\u00b7schen", "Ar\u00b7go", "Lauff", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die das goldene Fell beym Jason ehren,", "tokens": ["Die", "das", "gol\u00b7de\u00b7ne", "Fell", "beym", "Ja\u00b7son", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und das Meisterthum dieser Schiffarth lehren:", "tokens": ["Und", "das", "Meis\u00b7ter\u00b7thum", "die\u00b7ser", "Schiff\u00b7arth", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PDAT", "NN", "VVINF", "$."], "meter": "--+----+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Die den Hertzens Grund der Natur aufschrauben,", "tokens": ["Die", "den", "Hert\u00b7zens", "Grund", "der", "Na\u00b7tur", "auf\u00b7schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und uns heissen der Kunst nicht Glauben glauben:", "tokens": ["Und", "uns", "heis\u00b7sen", "der", "Kunst", "nicht", "Glau\u00b7ben", "glau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.36": {"line.1": {"text": "Auch die, weil sie Gott so inbr\u00fcnstig lieben,", "tokens": ["Auch", "die", ",", "weil", "sie", "Gott", "so", "in\u00b7br\u00fcns\u00b7tig", "lie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "KOUS", "PPER", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In der Engel Gesellschafft sind geschrieben:", "tokens": ["In", "der", "En\u00b7gel", "Ge\u00b7sell\u00b7schafft", "sind", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die Wahrheit, und voller Zuvertrauen", "tokens": ["Und", "die", "Wahr\u00b7heit", ",", "und", "vol\u00b7ler", "Zu\u00b7ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "KON", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Die Selbst\u00e4ndigkeit aller Dinge schauen:", "tokens": ["Die", "Selb\u00b7st\u00e4n\u00b7dig\u00b7keit", "al\u00b7ler", "Din\u00b7ge", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Und die Wei\u00dfheit, weit \u00fcber Welt und Sternen", "tokens": ["Und", "die", "Wei\u00df\u00b7heit", ",", "weit", "\u00fc\u00b7ber", "Welt", "und", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "APPR", "NN", "KON", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hier aus Mercava, dort aus Bresith lernen.", "tokens": ["Hier", "aus", "Mer\u00b7ca\u00b7va", ",", "dort", "aus", "Bre\u00b7sith", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Alle diese, wann sie die Spr\u00fcche mercken,", "tokens": ["Al\u00b7le", "die\u00b7se", ",", "wann", "sie", "die", "Spr\u00fc\u00b7che", "mer\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PDS", "$,", "PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Werden ihre Gewerbschafft etwas st\u00e4rcken.", "tokens": ["Wer\u00b7den", "ih\u00b7re", "Ge\u00b7werb\u00b7schafft", "et\u00b7was", "st\u00e4r\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Was ein Priester der Isis h\u00e4lt verborgen,", "tokens": ["Was", "ein", "Pries\u00b7ter", "der", "I\u00b7sis", "h\u00e4lt", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NE", "VVFIN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Was ein Argonaut eingeschifft voll Sorgen:", "tokens": ["Was", "ein", "Ar\u00b7go\u00b7naut", "ein\u00b7ge\u00b7schifft", "voll", "Sor\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was beschauen die wahren Cabalisten:", "tokens": ["Was", "be\u00b7schau\u00b7en", "die", "wah\u00b7ren", "Ca\u00b7ba\u00b7lis\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Was erglauben die Gotts gelehrte Christen.", "tokens": ["Was", "er\u00b7glau\u00b7ben", "die", "Gotts", "ge\u00b7lehr\u00b7te", "Chris\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.38": {"line.1": {"text": "Das ist sonder Berg in uns angeloffen,", "tokens": ["Das", "ist", "son\u00b7der", "Berg", "in", "uns", "an\u00b7ge\u00b7lof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das ist sonder Sorg in uns zu erhoffen:", "tokens": ["Das", "ist", "son\u00b7der", "Sorg", "in", "uns", "zu", "er\u00b7hof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das wird wol beschaut und zugleich umbschlossen:", "tokens": ["Das", "wird", "wol", "be\u00b7schaut", "und", "zu\u00b7gleich", "umbsc\u00b7hlos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KON", "ADV", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das wird wol erglaubt, und zugleich genossen:", "tokens": ["Das", "wird", "wol", "er\u00b7glaubt", ",", "und", "zu\u00b7gleich", "ge\u00b7nos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,", "KON", "ADV", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wo auf Worte nicht, sondern Acht auf Leben,", "tokens": ["Wo", "auf", "Wor\u00b7te", "nicht", ",", "son\u00b7dern", "Acht", "auf", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "PTKNEG", "$,", "KON", "CARD", "APPR", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Nicht auf Lehre wird, sondern Geist gegeben.", "tokens": ["Nicht", "auf", "Leh\u00b7re", "wird", ",", "son\u00b7dern", "Geist", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VAFIN", "$,", "KON", "NN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Geist und Leben kan Wort und Lehre f\u00e4rben,", "tokens": ["Geist", "und", "Le\u00b7ben", "kan", "Wort", "und", "Leh\u00b7re", "f\u00e4r\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Und die Farbe behalten, wann wir sterben:", "tokens": ["Und", "die", "Far\u00b7be", "be\u00b7hal\u00b7ten", ",", "wann", "wir", "ster\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Und dis such ich der Ritterschafft im Guten", "tokens": ["Und", "dis", "such", "ich", "der", "Rit\u00b7ter\u00b7schafft", "im", "Gu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des Fruchtbringenden Palmbaums zu zumuthen:", "tokens": ["Des", "Frucht\u00b7brin\u00b7gen\u00b7den", "Palm\u00b7baums", "zu", "zu\u00b7mut\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.39": {"line.1": {"text": "Aber: ist es erlaubet meinen Musen,", "tokens": ["A\u00b7ber", ":", "ist", "es", "er\u00b7lau\u00b7bet", "mei\u00b7nen", "Mu\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "VAFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die der Schreck-Schild besch\u00fctzet von Medusen:", "tokens": ["Die", "der", "Schreck\u00b7Schild", "be\u00b7sch\u00fct\u00b7zet", "von", "Me\u00b7du\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ich, darff ich vor das Gesichte treten,", "tokens": ["Und", "ich", ",", "darff", "ich", "vor", "das", "Ge\u00b7sich\u00b7te", "tre\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Welches Mavors und Pallas selbst anbeten:", "tokens": ["Wel\u00b7ches", "Ma\u00b7vors", "und", "Pal\u00b7las", "selbst", "an\u00b7be\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "KON", "NN", "ADV", "VVINF", "$."], "meter": "+--+-++-+--", "measure": "iambic.penta.invert"}, "line.5": {"text": "Hertzog: so sag ich /:aber gantz bescheiden:/", "tokens": ["Hert\u00b7zog", ":", "so", "sag", "ich", "/", ":", "a\u00b7ber", "gantz", "be\u00b7schei\u00b7den", ":/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "emoticon"], "pos": ["NE", "$.", "ADV", "VVFIN", "PPER", "$(", "$.", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fcrsten m\u00f6gen die Vers auch umb sich leiden.", "tokens": ["F\u00fcrs\u00b7ten", "m\u00f6\u00b7gen", "die", "Vers", "auch", "umb", "sich", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "ADV", "APPR", "PRF", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.40": {"line.1": {"text": "Ob sie setzen, so wol was ihr Geschlechte,", "tokens": ["Ob", "sie", "set\u00b7zen", ",", "so", "wol", "was", "ihr", "Ge\u00b7schlech\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$,", "ADV", "ADV", "PWS", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Als das R\u00f6mische Reich betrifft zu Rechte:", "tokens": ["Als", "das", "R\u00f6\u00b7mi\u00b7sche", "Reich", "be\u00b7tr\u00b7ifft", "zu", "Rech\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die Schwerdter vor beyder Freyheit schwingen,", "tokens": ["Und", "die", "Schwerd\u00b7ter", "vor", "bey\u00b7der", "Frey\u00b7heit", "schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Auf die Hand Pferd erhitzt in Harnschen springen:", "tokens": ["Auf", "die", "Hand", "Pferd", "er\u00b7hitzt", "in", "Harn\u00b7schen", "sprin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und den Adler, und auf des Adlers Br\u00fcsten", "tokens": ["Und", "den", "Ad\u00b7ler", ",", "und", "auf", "des", "Ad\u00b7lers", "Br\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Das Burgundische Creutz, als Deutsch und Christen:", "tokens": ["Das", "Bur\u00b7gun\u00b7di\u00b7sche", "Creutz", ",", "als", "Deutsch", "und", "Chris\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vor den T\u00fcrcken und Gottes Feinden sch\u00fctzen:", "tokens": ["Vor", "den", "T\u00fcr\u00b7cken", "und", "Got\u00b7tes", "Fein\u00b7den", "sch\u00fct\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Zu Gericht und zu Pferd in einem sitzen.", "tokens": ["Zu", "Ge\u00b7richt", "und", "zu", "Pferd", "in", "ei\u00b7nem", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Da\u00df das Kayserthum alle Welt erkenne,", "tokens": ["Da\u00df", "das", "Kay\u00b7ser\u00b7thum", "al\u00b7le", "Welt", "er\u00b7ken\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Und es beydes gerecht und sieghafft nenne.", "tokens": ["Und", "es", "bey\u00b7des", "ge\u00b7recht", "und", "sieg\u00b7hafft", "nen\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "ADJD", "KON", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.41": {"line.1": {"text": "Ob sie setzen die Krafft von ihrem Stande", "tokens": ["Ob", "sie", "set\u00b7zen", "die", "Krafft", "von", "ih\u00b7rem", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Deutscher Freyheit und ernster Zucht zu Pfande:", "tokens": ["Deut\u00b7scher", "Frey\u00b7heit", "und", "erns\u00b7ter", "Zucht", "zu", "Pfan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wann die starren Gerippe grauser Ahnen", "tokens": ["Wann", "die", "star\u00b7ren", "Ge\u00b7rip\u00b7pe", "grau\u00b7ser", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sie zur eysernen Tapfferkeit ermahnen:", "tokens": ["Sie", "zur", "ey\u00b7ser\u00b7nen", "Tapf\u00b7fer\u00b7keit", "er\u00b7mah\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "So auf Wallst\u00e4ten stehn, und aufrecht sterben,", "tokens": ["So", "auf", "Wall\u00b7st\u00e4\u00b7ten", "stehn", ",", "und", "auf\u00b7recht", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$,", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und im Tode Befehl thun. Folgt ihr Erben!", "tokens": ["Und", "im", "To\u00b7de", "Be\u00b7fehl", "thun", ".", "Folgt", "ihr", "Er\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "NN", "VVINF", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Wie den Wittikind: wie vor grauen Zeiten", "tokens": ["Wie", "den", "Wit\u00b7ti\u00b7kind", ":", "wie", "vor", "grau\u00b7en", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "$.", "KOKOM", "APPR", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Unsern Herrmann sein Westphaln sahn streiten;", "tokens": ["Un\u00b7sern", "Herr\u00b7mann", "sein", "West\u00b7phaln", "sahn", "strei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "VVFIN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Der den Varus schlug, da\u00df vor solchem Putzen", "tokens": ["Der", "den", "Va\u00b7rus", "schlug", ",", "da\u00df", "vor", "sol\u00b7chem", "Put\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NE", "VVFIN", "$,", "KOUS", "APPR", "PIAT", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.10": {"text": "Mit den Mauern der Kayser wolte stutzen.", "tokens": ["Mit", "den", "Mau\u00b7ern", "der", "Kay\u00b7ser", "wol\u00b7te", "stut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.42": {"line.1": {"text": "Ob sie setzen das Grundrecht der Gemeine", "tokens": ["Ob", "sie", "set\u00b7zen", "das", "Grund\u00b7recht", "der", "Ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und des Gottesdiensts zu dem Angelsteine:", "tokens": ["Und", "des", "Got\u00b7tes\u00b7diensts", "zu", "dem", "An\u00b7gel\u00b7stei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Drauf der M\u00fcnster- und Osnabr\u00fcgsche Frieden", "tokens": ["Drauf", "der", "M\u00fcns\u00b7ter", "und", "Os\u00b7na\u00b7br\u00fcg\u00b7sche", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Eingemauert steht: Von Gefahr geschieden:", "tokens": ["Ein\u00b7ge\u00b7mau\u00b7ert", "steht", ":", "Von", "Ge\u00b7fahr", "ge\u00b7schie\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$.", "APPR", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und mit B\u00fcndn\u00fcssen ihre Ruh verst\u00e4rcken,", "tokens": ["Und", "mit", "B\u00fcnd\u00b7n\u00fcs\u00b7sen", "ih\u00b7re", "Ruh", "ver\u00b7st\u00e4r\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Vor der Liebe des Volcks kein be\u00dfres mercken.", "tokens": ["Vor", "der", "Lie\u00b7be", "des", "Volcks", "kein", "be\u00df\u00b7res", "mer\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PIAT", "ADJA", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.43": {"line.1": {"text": "Ob sie d\u00e4mpffen die stoltzen Feder Kielen", "tokens": ["Ob", "sie", "d\u00e4mpf\u00b7fen", "die", "stolt\u00b7zen", "Fe\u00b7der", "Kie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Auf den Lehrst\u00e4ten, auf den Dreyfu\u00df St\u00fchlen,", "tokens": ["Auf", "den", "Lehr\u00b7st\u00e4\u00b7ten", ",", "auf", "den", "Drey\u00b7fu\u00df", "St\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die den Gottesdienst und die Freyheit st\u00f6ren,", "tokens": ["Die", "den", "Got\u00b7tes\u00b7dienst", "und", "die", "Frey\u00b7heit", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "KON", "ART", "NN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Durch ihr Dintenfa\u00df Blutstr\u00f6m in uns r\u00f6hren:", "tokens": ["Durch", "ihr", "Din\u00b7ten\u00b7fa\u00df", "Blut\u00b7str\u00f6m", "in", "uns", "r\u00f6h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+--++--+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und viel Seelen verwirrn: und doch zusammen", "tokens": ["Und", "viel", "See\u00b7len", "ver\u00b7wirrn", ":", "und", "doch", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVINF", "$.", "KON", "ADV", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ihre Zanck K\u00fcnst in Todes Noth verdammen.", "tokens": ["Ih\u00b7re", "Zanck", "K\u00fcnst", "in", "To\u00b7des", "Noth", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "APPR", "NN", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "Von dem Glauben Vernunfft und Ansehn scheiden,", "tokens": ["Von", "dem", "Glau\u00b7ben", "Ver\u00b7nunfft", "und", "An\u00b7sehn", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und sich tr\u00f6sten mit uns mit Gottes Leiden.", "tokens": ["Und", "sich", "tr\u00f6s\u00b7ten", "mit", "uns", "mit", "Got\u00b7tes", "Lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "PPER", "APPR", "NN", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.44": {"line.1": {"text": "Ob sie beydes durch trauen und nicht trauen", "tokens": ["Ob", "sie", "bey\u00b7des", "durch", "trau\u00b7en", "und", "nicht", "trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "APPR", "VVINF", "KON", "PTKNEG", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihre Sicherheit hier und auswerts bauen:", "tokens": ["Ih\u00b7re", "Si\u00b7cher\u00b7heit", "hier", "und", "aus\u00b7werts", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "KON", "ADV", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und den F\u00fcrsten des Friedens unter Vieren,", "tokens": ["Und", "den", "F\u00fcrs\u00b7ten", "des", "Frie\u00b7dens", "un\u00b7ter", "Vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Unsern Ferdinand mit der Krone zieren,", "tokens": ["Un\u00b7sern", "Fer\u00b7di\u00b7nand", "mit", "der", "Kro\u00b7ne", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Die der Adler bereit zum guten Zeichen", "tokens": ["Die", "der", "Ad\u00b7ler", "be\u00b7reit", "zum", "gu\u00b7ten", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJD", "APPRART", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Auf die Hungrisch und B\u00f6hmsche wolte reichen,", "tokens": ["Auf", "die", "Hun\u00b7grisch", "und", "B\u00f6hm\u00b7sche", "wol\u00b7te", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NE", "VMFIN", "VVINF", "$,"], "meter": "--++-+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Den um Schweidnitz wir bey der Huldung fiengen,", "tokens": ["Den", "um", "Schweid\u00b7nitz", "wir", "bey", "der", "Hul\u00b7dung", "fi\u00b7en\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Bi\u00df die Vierdte der Vierdte wird erschwingen.", "tokens": ["Bi\u00df", "die", "Vierd\u00b7te", "der", "Vierd\u00b7te", "wird", "er\u00b7schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Und wo Gottesfurcht, wo ihr eigne T\u00f6chter", "tokens": ["Und", "wo", "Got\u00b7tes\u00b7furcht", ",", "wo", "ihr", "eig\u00b7ne", "T\u00f6ch\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "NN", "$,", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Wei\u00dfheit und M\u00e4ssigkeit ziern die Geschlechter,", "tokens": ["Wei\u00df\u00b7heit", "und", "M\u00e4s\u00b7sig\u00b7keit", "zi\u00b7ern", "die", "Ge\u00b7schlech\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.11": {"text": "Und aus F\u00fcrsten vermenschte G\u00f6tter machen,", "tokens": ["Und", "aus", "F\u00fcrs\u00b7ten", "ver\u00b7menschte", "G\u00f6t\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.12": {"text": "Kan kein G\u00f6ttlicher F\u00fcrst in Deutschland wachen;", "tokens": ["Kan", "kein", "G\u00f6tt\u00b7li\u00b7cher", "F\u00fcrst", "in", "Deutschland", "wa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "NN", "APPR", "NE", "VVINF", "$."], "meter": "+-+--+-++-", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Ob die Engel ihn unter ihren Thr\u00f6nen", "tokens": ["Ob", "die", "En\u00b7gel", "ihn", "un\u00b7ter", "ih\u00b7ren", "Thr\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Solten selber erwehlen und bekr\u00f6nen.", "tokens": ["Sol\u00b7ten", "sel\u00b7ber", "er\u00b7weh\u00b7len", "und", "be\u00b7kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.45": {"line.1": {"text": "Ob sie, sag ich: Gedancken, und Gedancken,", "tokens": ["Ob", "sie", ",", "sag", "ich", ":", "Ge\u00b7dan\u00b7cken", ",", "und", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "VVFIN", "PPER", "$.", "NN", "$,", "KON", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Die recht F\u00fcrstlich sind, die niemals nicht wancken,", "tokens": ["Die", "recht", "F\u00fcrst\u00b7lich", "sind", ",", "die", "nie\u00b7mals", "nicht", "wan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "VAFIN", "$,", "PRELS", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ausser dienstbaren Mund und Hertzen f\u00fchren,", "tokens": ["Aus\u00b7ser", "dienst\u00b7ba\u00b7ren", "Mund", "und", "Hert\u00b7zen", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und die Adern vom Deutsche Blute r\u00fchren,", "tokens": ["Und", "die", "A\u00b7dern", "vom", "Deut\u00b7sche", "Blu\u00b7te", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Drinnen Geister der edlen Freyheit wallen,", "tokens": ["Drin\u00b7nen", "Geis\u00b7ter", "der", "ed\u00b7len", "Frey\u00b7heit", "wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Doch sol ihnen dis Buch, hoff ich, gefallen.", "tokens": ["Doch", "sol", "ih\u00b7nen", "dis", "Buch", ",", "hoff", "ich", ",", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PDS", "NN", "$,", "VVFIN", "PPER", "$,", "VVPP", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}}, "stanza.46": {"line.1": {"text": "Nicht umbsonsten. Es werden draus auf Erden", "tokens": ["Nicht", "um\u00b7bsons\u00b7ten", ".", "Es", "wer\u00b7den", "draus", "auf", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "$.", "PPER", "VAFIN", "PAV", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Menschen, unter den Menschen, Menschen werden.", "tokens": ["Men\u00b7schen", ",", "un\u00b7ter", "den", "Men\u00b7schen", ",", "Men\u00b7schen", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "NN", "$,", "NN", "VAINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.47": {"line.1": {"text": "Wir: das Ebenbild: das nach Gott entsprossen,", "tokens": ["Wir", ":", "das", "E\u00b7ben\u00b7bild", ":", "das", "nach", "Gott", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "NN", "$.", "ART", "APPR", "NN", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir: das Wunderwerck: das aus Gott geflossen:", "tokens": ["Wir", ":", "das", "Wun\u00b7der\u00b7werck", ":", "das", "aus", "Gott", "ge\u00b7flos\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "NN", "$.", "PDS", "APPR", "NN", "VVPP", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir: das Meisterst\u00fcck, das von Gott erkohren,", "tokens": ["Wir", ":", "das", "Meis\u00b7ter\u00b7st\u00fcck", ",", "das", "von", "Gott", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "NN", "$,", "PRELS", "APPR", "NN", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hatten unter uns Gott und uns verlohren.", "tokens": ["Hat\u00b7ten", "un\u00b7ter", "uns", "Gott", "und", "uns", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "NN", "KON", "PPER", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Gott: wir liessen uns seinen Geist nicht f\u00fchren:", "tokens": ["Gott", ":", "wir", "lies\u00b7sen", "uns", "sei\u00b7nen", "Geist", "nicht", "f\u00fch\u00b7ren", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und wir giengen von Engeln zu den Thieren.", "tokens": ["Und", "wir", "gien\u00b7gen", "von", "En\u00b7geln", "zu", "den", "Thie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Draus kam, da\u00df wir worden, wie zu schauen,", "tokens": ["Draus", "kam", ",", "da\u00df", "wir", "wor\u00b7den", ",", "wie", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "KOUS", "PPER", "VAPP", "$,", "PWAV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Aus dem Ebenbild ein Thier voller Grauen:", "tokens": ["Aus", "dem", "E\u00b7ben\u00b7bild", "ein", "Thier", "vol\u00b7ler", "Grau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Aus dem Wunderwerck ein Ziel aller St\u00fcrme:", "tokens": ["Aus", "dem", "Wun\u00b7der\u00b7werck", "ein", "Ziel", "al\u00b7ler", "St\u00fcr\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PIAT", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Aus dem Meisterst\u00fcck ein Aas grauser W\u00fcrme.", "tokens": ["Aus", "dem", "Meis\u00b7ter\u00b7st\u00fcck", "ein", "Aas", "grau\u00b7ser", "W\u00fcr\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.48": {"line.1": {"text": "Doch es k\u00f6nt' in dem Abgrund unsrer Seelen", "tokens": ["Doch", "es", "k\u00f6nt'", "in", "dem", "Ab\u00b7grund", "uns\u00b7rer", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sich ein F\u00fcncklein der G\u00f6ttlichkeit verheelen:", "tokens": ["Sich", "ein", "F\u00fcnc\u00b7klein", "der", "G\u00f6tt\u00b7lich\u00b7keit", "ver\u00b7hee\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Welches, wollt es gleich H\u00f6ll und Tod vorschweiffen,", "tokens": ["Wel\u00b7ches", ",", "wollt", "es", "gleich", "H\u00f6ll", "und", "Tod", "vor\u00b7schwei\u00b7ffen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VMFIN", "PPER", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Doch den Trost der Errettung k\u00f6nt' ergreiffen.", "tokens": ["Doch", "den", "Trost", "der", "Er\u00b7ret\u00b7tung", "k\u00f6nt'", "er\u00b7greif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.49": {"line.1": {"text": "Unterm Grauen ward uns' das Wolbehagen", "tokens": ["Un\u00b7term", "Grau\u00b7en", "ward", "un\u00b7s'", "das", "Wol\u00b7be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Untern St\u00fcrmen die Ruhstatt angetragen:", "tokens": ["Un\u00b7tern", "St\u00fcr\u00b7men", "die", "Ruh\u00b7statt", "an\u00b7ge\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Untern W\u00fcrmen des Lebens Glantz und Frieden:", "tokens": ["Un\u00b7tern", "W\u00fcr\u00b7men", "des", "Le\u00b7bens", "Glantz", "und", "Frie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Doch mit ewigen Kl\u00fcfften unterschieden.", "tokens": ["Doch", "mit", "e\u00b7wi\u00b7gen", "Kl\u00fcff\u00b7ten", "un\u00b7ter\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.50": {"line.1": {"text": "Als das Zitternde F\u00fcncklein untern Banden", "tokens": ["Als", "das", "Zit\u00b7tern\u00b7de", "F\u00fcnc\u00b7klein", "un\u00b7tern", "Ban\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "In geb\u00e4hrender Angst und Zeit gestanden:", "tokens": ["In", "ge\u00b7b\u00e4h\u00b7ren\u00b7der", "Angst", "und", "Zeit", "ge\u00b7stan\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Schleust das Tieffste das H\u00f6chst in sein Begehren,", "tokens": ["Schleust", "das", "Tieffs\u00b7te", "das", "H\u00f6chst", "in", "sein", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Uns den Trost der Errettung zu gew\u00e4hren.", "tokens": ["Uns", "den", "Trost", "der", "Er\u00b7ret\u00b7tung", "zu", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.51": {"line.1": {"text": "Das gew\u00e4hrn, das Erretten, das Vertr\u00f6sten", "tokens": ["Das", "ge\u00b7w\u00e4hrn", ",", "das", "Er\u00b7ret\u00b7ten", ",", "das", "Ver\u00b7tr\u00f6s\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Machte zwischen Verdammten und Erl\u00f6sten", "tokens": ["Mach\u00b7te", "zwi\u00b7schen", "Ver\u00b7damm\u00b7ten", "und", "Er\u00b7l\u00f6s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ein Heil-wirckendes Creutz: aus den Verdammten", "tokens": ["Ein", "Heil\u00b7wir\u00b7cken\u00b7des", "Creutz", ":", "aus", "den", "Ver\u00b7damm\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Gehn Erl\u00f6ste vor: Christen aus gesammten.", "tokens": ["Gehn", "Er\u00b7l\u00f6s\u00b7te", "vor", ":", "Chris\u00b7ten", "aus", "ge\u00b7samm\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$.", "NN", "APPR", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.52": {"line.1": {"text": "Als die Cabala kam vom Weibes Saamen,", "tokens": ["Als", "die", "Ca\u00b7ba\u00b7la", "kam", "vom", "Wei\u00b7bes", "Saa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NE", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ward das F\u00fcncklein durchgl\u00e4ntzt von Gottes Nahmen,", "tokens": ["Ward", "das", "F\u00fcnc\u00b7klein", "durch\u00b7gl\u00e4ntzt", "von", "Got\u00b7tes", "Nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "APPR", "NN", "NN", "$,"], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Drauf sich steiffet des Glaubens gantzer Orden", "tokens": ["Drauf", "sich", "steif\u00b7fet", "des", "Glau\u00b7bens", "gant\u00b7zer", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PRF", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Weil das Wort Fleisch, und Gott Mensch dr\u00fcber worden.", "tokens": ["Weil", "das", "Wort", "Fleisch", ",", "und", "Gott", "Mensch", "dr\u00fc\u00b7ber", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,", "KON", "NN", "NN", "PAV", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Das selbst\u00e4ndige Wesen alles Wesen,", "tokens": ["Das", "selb\u00b7st\u00e4n\u00b7di\u00b7ge", "We\u00b7sen", "al\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ohn das nichts, durch das alles mu\u00df genesen,", "tokens": ["Ohn", "das", "nichts", ",", "durch", "das", "al\u00b7les", "mu\u00df", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "$,", "APPR", "ART", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wolt aus innerster Grund- Erb\u00e4rmbd uns zeigen,", "tokens": ["Wolt", "aus", "in\u00b7ners\u00b7ter", "Grun\u00b7d", "Er\u00b7b\u00e4rmbd", "uns", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ADJA", "TRUNC", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wie wir Himmel an wieder solten steigen.", "tokens": ["Wie", "wir", "Him\u00b7mel", "an", "wie\u00b7der", "sol\u00b7ten", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "APPR", "ADV", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.54": {"line.1": {"text": "Er l\u00e4st uns durch zwey Weg' in zweyen B\u00fcchern", "tokens": ["Er", "l\u00e4st", "uns", "durch", "zwey", "Weg'", "in", "zwe\u00b7yen", "B\u00fc\u00b7chern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "CARD", "NN", "APPR", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dessen aus der Natur und Schrifft versichern:", "tokens": ["Des\u00b7sen", "aus", "der", "Na\u00b7tur", "und", "Schrifft", "ver\u00b7si\u00b7chern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Der Natur Weg ist heimlich, der Schrifft offen,", "tokens": ["Der", "Na\u00b7tur", "Weg", "ist", "heim\u00b7lich", ",", "der", "Schrifft", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Beyde zeigen uns, was wir sollen hoffen.", "tokens": ["Bey\u00b7de", "zei\u00b7gen", "uns", ",", "was", "wir", "sol\u00b7len", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.55": {"line.1": {"text": "Die Natur ist ein Licht, das vorgebrochen,", "tokens": ["Die", "Na\u00b7tur", "ist", "ein", "Licht", ",", "das", "vor\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,", "PRELS", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als das ewige Fiat ward gesprochen:", "tokens": ["Als", "das", "e\u00b7wi\u00b7ge", "Fiat", "ward", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Das im I seinen Ausflu\u00df hat gefunden,", "tokens": ["Das", "im", "I", "sei\u00b7nen", "Aus\u00b7flu\u00df", "hat", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "CARD", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der ohn Ende sich an das A gebunden:", "tokens": ["Der", "ohn", "En\u00b7de", "sich", "an", "das", "A", "ge\u00b7bun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PRF", "APPR", "ART", "NE", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und so allen Gesch\u00f6pffen eingegeben", "tokens": ["Und", "so", "al\u00b7len", "Ge\u00b7sch\u00f6pf\u00b7fen", "ein\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "NN", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Geist und Wesen, Gestalt, und Licht und Leben.", "tokens": ["Geist", "und", "We\u00b7sen", ",", "Ge\u00b7stalt", ",", "und", "Licht", "und", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "NN", "$,", "KON", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Dieses FIAT, das ist das Wort und Wesen,", "tokens": ["Die\u00b7ses", "FiAT", ",", "das", "ist", "das", "Wort", "und", "We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Das Gott selbsten war, und Gott hat erlesen:", "tokens": ["Das", "Gott", "selbs\u00b7ten", "war", ",", "und", "Gott", "hat", "er\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "$,", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ist der Athem und Hauch, davon wir leben", "tokens": ["Ist", "der", "A\u00b7them", "und", "Hauch", ",", "da\u00b7von", "wir", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$,", "PAV", "PPER", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Draus die G\u00f6ttliche Lufft die Parcen weben,", "tokens": ["Draus", "die", "G\u00f6tt\u00b7li\u00b7che", "Lufft", "die", "Par\u00b7cen", "we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Ist das F\u00fcncklein, das Weise sonder Gr\u00e4ntzen", "tokens": ["Ist", "das", "F\u00fcnc\u00b7klein", ",", "das", "Wei\u00b7se", "son\u00b7der", "Gr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "In der reinen Vernunfft sehn wieder gl\u00e4ntzen:", "tokens": ["In", "der", "rei\u00b7nen", "Ver\u00b7nunfft", "sehn", "wie\u00b7der", "gl\u00e4nt\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ADV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Ist des heiligen Gottes grosser Nahmen,", "tokens": ["Ist", "des", "hei\u00b7li\u00b7gen", "Got\u00b7tes", "gros\u00b7ser", "Nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "Das erleuchtende Licht des Weibes Saamen:", "tokens": ["Das", "er\u00b7leuch\u00b7ten\u00b7de", "Licht", "des", "Wei\u00b7bes", "Saa\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.15": {"text": "Ist die Wahrheit, die alles ausgesprochen,", "tokens": ["Ist", "die", "Wahr\u00b7heit", ",", "die", "al\u00b7les", "aus\u00b7ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PIS", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Die in allen ist, ob man sie wil suchen.", "tokens": ["Die", "in", "al\u00b7len", "ist", ",", "ob", "man", "sie", "wil", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIS", "VAFIN", "$,", "KOUS", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "In uns ist ja was g\u00f6ttliches zu sp\u00fchren,", "tokens": ["In", "uns", "ist", "ja", "was", "g\u00f6tt\u00b7li\u00b7ches", "zu", "sp\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "PWS", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Das zu Gott und der Wahrheit uns kan f\u00fchren,", "tokens": ["Das", "zu", "Gott", "und", "der", "Wahr\u00b7heit", "uns", "kan", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "KON", "ART", "NN", "PPER", "VMFIN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.19": {"text": "Wann ein ziehender Schrack es angeglommen,", "tokens": ["Wann", "ein", "zie\u00b7hen\u00b7der", "Schrack", "es", "an\u00b7ge\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "Zeigt das Creutze die Bahn, und du solt kommen.", "tokens": ["Zeigt", "das", "Creut\u00b7ze", "die", "Bahn", ",", "und", "du", "solt", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,", "KON", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.21": {"text": "Das Buch in der Natur, das kan uns weisen", "tokens": ["Das", "Buch", "in", "der", "Na\u00b7tur", ",", "das", "kan", "uns", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PDS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Den geheimen Weg, den die Alten preisen.", "tokens": ["Den", "ge\u00b7hei\u00b7men", "Weg", ",", "den", "die", "Al\u00b7ten", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.23": {"text": "Den hat Hermes am Leben und an Worten", "tokens": ["Den", "hat", "Her\u00b7mes", "am", "Le\u00b7ben", "und", "an", "Wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NE", "APPRART", "NN", "KON", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.24": {"text": "L\u00e4ngst vor Mosen dort umb des Nilus Pforten", "tokens": ["L\u00e4ngst", "vor", "Mo\u00b7sen", "dort", "umb", "des", "Ni\u00b7lus", "Pfor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "ADV", "APPR", "ART", "NE", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.25": {"text": "Nach der S\u00fcndfluth gelehrt voll Kunst und G\u00fcte", "tokens": ["Nach", "der", "S\u00fcnd\u00b7fluth", "ge\u00b7lehrt", "voll", "Kunst", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP", "ADJD", "NN", "KON", "NN"], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.26": {"text": "Im Pimander gelehrt vom himmlischen Gem\u00fcthe.", "tokens": ["Im", "Pi\u00b7man\u00b7der", "ge\u00b7lehrt", "vom", "himm\u00b7li\u00b7schen", "Ge\u00b7m\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Diesen hat Zoroaster wollen lernen,", "tokens": ["Die\u00b7sen", "hat", "Zo\u00b7roas\u00b7ter", "wol\u00b7len", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.28": {"text": "Der die Gr\u00fcnde der Welt, den Lauff der Sternen,", "tokens": ["Der", "die", "Gr\u00fcn\u00b7de", "der", "Welt", ",", "den", "Lauff", "der", "Ster\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.29": {"text": "Und der Dinge Gestalt und Krafft erfahren,", "tokens": ["Und", "der", "Din\u00b7ge", "Ge\u00b7stalt", "und", "Krafft", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.30": {"text": "Und ein K\u00f6nig war erster Weisen Schaaren.", "tokens": ["Und", "ein", "K\u00f6\u00b7nig", "war", "ers\u00b7ter", "Wei\u00b7sen", "Schaa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJA", "NN", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.56": {"line.1": {"text": "Den hat Pythagoras durch Stilleschweigen", "tokens": ["Den", "hat", "Py\u00b7tha\u00b7go\u00b7ras", "durch", "Stil\u00b7le\u00b7schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NE", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Seinen J\u00fcngern mit Fingern wollen zeigen,", "tokens": ["Sei\u00b7nen", "J\u00fcn\u00b7gern", "mit", "Fin\u00b7gern", "wol\u00b7len", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Der die Wissenschafft von dem Obern Wesen", "tokens": ["Der", "die", "Wis\u00b7sen\u00b7schafft", "von", "dem", "O\u00b7bern", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "In den weisen Tetractys gab zu lesen.", "tokens": ["In", "den", "wei\u00b7sen", "Tet\u00b7rac\u00b7tys", "gab", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.57": {"line.1": {"text": "Diesen hat die Idea auch gewiesen,", "tokens": ["Die\u00b7sen", "hat", "die", "I\u00b7dea", "auch", "ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NE", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Welche Plato in seiner Art gepriesen,", "tokens": ["Wel\u00b7che", "Pla\u00b7to", "in", "sei\u00b7ner", "Art", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Der kein andere Seeligkeit kan finden,", "tokens": ["Der", "kein", "an\u00b7de\u00b7re", "See\u00b7lig\u00b7keit", "kan", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Als das Hertze Grundaus mit Gott verbinden.", "tokens": ["Als", "das", "Hert\u00b7ze", "Grun\u00b7daus", "mit", "Gott", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Da\u00df nu Gottes Geheimn\u00fc\u00dfe vor allen", "tokens": ["Da\u00df", "nu", "Got\u00b7tes", "Ge\u00b7heim\u00b7n\u00fc\u00b7\u00dfe", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "NN", "APPR", "PIAT"], "meter": "+-+--++--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Durch das Heydenthum man euch h\u00f6rte schallen,", "tokens": ["Durch", "das", "Hey\u00b7den\u00b7thum", "man", "euch", "h\u00f6r\u00b7te", "schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIS", "PPER", "VVFIN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.7": {"text": "Bi\u00df durch K\u00f6nig und Priester Er gantz eigen", "tokens": ["Bi\u00df", "durch", "K\u00f6\u00b7nig", "und", "Pries\u00b7ter", "Er", "gantz", "ei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "NN", "KON", "NN", "PPER", "ADV", "ADJD"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Den Chald\u00e6rn und Indien sie bezeigen:", "tokens": ["Den", "Chald\u00e6rn", "und", "In\u00b7di\u00b7en", "sie", "be\u00b7zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "So die Wahrheit, der Seelen edle Speise,", "tokens": ["So", "die", "Wahr\u00b7heit", ",", "der", "See\u00b7len", "ed\u00b7le", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Ausgebreitet, verdeckter Art und Weise:", "tokens": ["Aus\u00b7ge\u00b7brei\u00b7tet", ",", "ver\u00b7deck\u00b7ter", "Art", "und", "Wei\u00b7se", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Und der V\u00f6lcker, bey denen sie gelesen,", "tokens": ["Und", "der", "V\u00f6l\u00b7cker", ",", "bey", "de\u00b7nen", "sie", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "\u00dcbersinnliche Meister sind gewesen:", "tokens": ["\u00dc\u00b7ber\u00b7sinn\u00b7li\u00b7che", "Meis\u00b7ter", "sind", "ge\u00b7we\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "VAPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Weil sie vom Abraham drob lehrten herrschen,", "tokens": ["Weil", "sie", "vom", "Ab\u00b7ra\u00b7ham", "drob", "lehr\u00b7ten", "herr\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NE", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "In Egypten, vom Daniel in Perschen.", "tokens": ["In", "E\u00b7gyp\u00b7ten", ",", "vom", "Da\u00b7ni\u00b7el", "in", "Per\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPRART", "NN", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.58": {"line.1": {"text": "Wie von Ursach auf Ursach in den Dingen", "tokens": ["Wie", "von", "Ur\u00b7sach", "auf", "Ur\u00b7sach", "in", "den", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sie zur Ursach ohn Ursach endlich giengen:", "tokens": ["Sie", "zur", "Ur\u00b7sach", "ohn", "Ur\u00b7sach", "end\u00b7lich", "gien\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Vor sich Menschen und Erd und Himmel nahmen,", "tokens": ["Vor", "sich", "Men\u00b7schen", "und", "Erd", "und", "Him\u00b7mel", "nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Von der a\u00fcsren Gestalt zur innren kamen:", "tokens": ["Von", "der", "a\u00b7\u00fcs\u00b7ren", "Ge\u00b7stalt", "zur", "inn\u00b7ren", "ka\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Bi\u00df die Sache sie, daraus alle gehen,", "tokens": ["Bi\u00df", "die", "Sa\u00b7che", "sie", ",", "da\u00b7raus", "al\u00b7le", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "$,", "PAV", "PIS", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Unter einer iedwedern Sache sehen:", "tokens": ["Un\u00b7ter", "ei\u00b7ner", "ied\u00b7we\u00b7dern", "Sa\u00b7che", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Und, wann drinnen ihr Hertz und Geist zuflossen,", "tokens": ["Und", ",", "wann", "drin\u00b7nen", "ihr", "Hertz", "und", "Geist", "zu\u00b7flos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADV", "PPOSAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Unaussprechliche S\u00fcssigkeit geno\u00dfen;", "tokens": ["Un\u00b7aus\u00b7sprech\u00b7li\u00b7che", "S\u00fcs\u00b7sig\u00b7keit", "ge\u00b7no\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.59": {"line.1": {"text": "Also machen die Menschen diese Reime", "tokens": ["Al\u00b7so", "ma\u00b7chen", "die", "Men\u00b7schen", "die\u00b7se", "Rei\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PDAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Durch den Weg der Natur mit Gott geheime:", "tokens": ["Durch", "den", "Weg", "der", "Na\u00b7tur", "mit", "Gott", "ge\u00b7hei\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Der von Staffel zu Staffel voll Behagen", "tokens": ["Der", "von", "Staf\u00b7fel", "zu", "Staf\u00b7fel", "voll", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "NN", "ADJD", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sein erbarmende Liebe uns angetragen:", "tokens": ["Sein", "er\u00b7bar\u00b7men\u00b7de", "Lie\u00b7be", "uns", "an\u00b7ge\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Unser F\u00fcncklein geht an: wir sehn und f\u00fchlen", "tokens": ["Un\u00b7ser", "F\u00fcnc\u00b7klein", "geht", "an", ":", "wir", "sehn", "und", "f\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VVINF", "KON", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "In ihm gr\u00fcndlich die Wahrheit wieder spielen.", "tokens": ["In", "ihm", "gr\u00fcnd\u00b7lich", "die", "Wahr\u00b7heit", "wie\u00b7der", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.60": {"line.1": {"text": "Aber der Weg der Schrifft: Das Buch der Gnaden,", "tokens": ["A\u00b7ber", "der", "Weg", "der", "Schrifft", ":", "Das", "Buch", "der", "Gna\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Das uns offenbahret unser Heil und Schaden:", "tokens": ["Das", "uns", "of\u00b7fen\u00b7bah\u00b7ret", "un\u00b7ser", "Heil", "und", "Scha\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "In zwey B\u00fcnde, von dem Gesetz und Frieden,", "tokens": ["In", "zwey", "B\u00fcn\u00b7de", ",", "von", "dem", "Ge\u00b7setz", "und", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Durch Verheissen und durch Gew\u00e4hrn geschieden:", "tokens": ["Durch", "Ver\u00b7heis\u00b7sen", "und", "durch", "Ge\u00b7w\u00e4hrn", "ge\u00b7schie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Wei\u00df die Cabala reiner auszugr\u00fcnden,", "tokens": ["Wei\u00df", "die", "Ca\u00b7ba\u00b7la", "rei\u00b7ner", "aus\u00b7zu\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ADJA", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Die wir in Gott und seinem Worte finden.", "tokens": ["Die", "wir", "in", "Gott", "und", "sei\u00b7nem", "Wor\u00b7te", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.61": {"line.1": {"text": "Denn die Schrifft ist ein Licht, das gantz vollkommen", "tokens": ["Denn", "die", "Schrifft", "ist", "ein", "Licht", ",", "das", "gantz", "voll\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "In dem Hertzen der Gottheit angeglommen,", "tokens": ["In", "dem", "Hert\u00b7zen", "der", "Got\u00b7theit", "an\u00b7ge\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ist die Krafft, durch die Gottes Geist zusammen", "tokens": ["Ist", "die", "Krafft", ",", "durch", "die", "Got\u00b7tes", "Geist", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "APPR", "ART", "NN", "NN", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die Propheten erf\u00fcllt mit heilgen Flammen:", "tokens": ["Die", "Pro\u00b7phe\u00b7ten", "er\u00b7f\u00fcllt", "mit", "heil\u00b7gen", "Flam\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ist das Wort, drauf den Grund der Ewigkeiten", "tokens": ["Ist", "das", "Wort", ",", "drauf", "den", "Grund", "der", "E\u00b7wig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PAV", "ART", "NN", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Gott gebaut, den kein Teufel kan bestreiten:", "tokens": ["Gott", "ge\u00b7baut", ",", "den", "kein", "Teu\u00b7fel", "kan", "be\u00b7strei\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Ist das Pfand, ist die Richtschnur, ist der Bronnen,", "tokens": ["Ist", "das", "Pfand", ",", "ist", "die", "Richt\u00b7schnur", ",", "ist", "der", "Bron\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Draus die Seeligkeit in uns k\u00f6mmt geronnen:", "tokens": ["Draus", "die", "See\u00b7lig\u00b7keit", "in", "uns", "k\u00f6mmt", "ge\u00b7ron\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "PPER", "VVFIN", "VVPP", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.9": {"text": "Hie wird, welches vor alle Ding erkohren,", "tokens": ["Hie", "wird", ",", "wel\u00b7ches", "vor", "al\u00b7le", "Ding", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "PRELS", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Das unendliche FIAT selbst gebohren:", "tokens": ["Das", "un\u00b7end\u00b7li\u00b7che", "FiAT", "selbst", "ge\u00b7boh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.62": {"line.1": {"text": "Hier ist, h\u00e4tt es die Welt doch wahrgenommen,", "tokens": ["Hier", "ist", ",", "h\u00e4tt", "es", "die", "Welt", "doch", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "VAFIN", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der versprochene Weibes Saamen kommen:", "tokens": ["Der", "ver\u00b7spro\u00b7che\u00b7ne", "Wei\u00b7bes", "Saa\u00b7men", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Was kein Weiser im Himmel ie erstiegen,", "tokens": ["Was", "kein", "Wei\u00b7ser", "im", "Him\u00b7mel", "ie", "er\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sehn wir zu Bethlehem im Stalle liegen:", "tokens": ["Sehn", "wir", "zu", "Beth\u00b7le\u00b7hem", "im", "Stal\u00b7le", "lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dessen Cabala heist vor andern Lehren.", "tokens": ["Des\u00b7sen", "Ca\u00b7ba\u00b7la", "heist", "vor", "an\u00b7dern", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Dis ist mein lieber Sohn, den solt ihr h\u00f6ren.", "tokens": ["Dis", "ist", "mein", "lie\u00b7ber", "Sohn", ",", "den", "solt", "ihr", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "ART", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.63": {"line.1": {"text": "Dieses haben, als sie in Geist gegangen,", "tokens": ["Die\u00b7ses", "ha\u00b7ben", ",", "als", "sie", "in", "Geist", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Adam und Abraham von Gott empfangen:", "tokens": ["A\u00b7dam", "und", "Ab\u00b7ra\u00b7ham", "von", "Gott", "emp\u00b7fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "APPR", "NN", "VVPP", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Der ein Vater vom Fleisch, und der vom Glauben,", "tokens": ["Der", "ein", "Va\u00b7ter", "vom", "Fleisch", ",", "und", "der", "vom", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPRART", "NN", "$,", "KON", "ART", "APPRART", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Beyden konte noch Noth, noch Tod es rauben.", "tokens": ["Bey\u00b7den", "kon\u00b7te", "noch", "Noth", ",", "noch", "Tod", "es", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "NN", "$,", "ADV", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.64": {"line.1": {"text": "Die hat Moses und Christus voller Gaben,", "tokens": ["Die", "hat", "Mo\u00b7ses", "und", "Chris\u00b7tus", "vol\u00b7ler", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "KON", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der auf Sina, auf Sion der erhaben:", "tokens": ["Der", "auf", "Si\u00b7na", ",", "auf", "Si\u00b7on", "der", "er\u00b7ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "$,", "APPR", "NE", "ART", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Durch Gesetz geben und Gesetz erf\u00fcllen,", "tokens": ["Durch", "Ge\u00b7setz", "ge\u00b7ben", "und", "Ge\u00b7setz", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Uns zu offenbahrn unsers Gottes Willen.", "tokens": ["Uns", "zu", "of\u00b7fen\u00b7bahrn", "un\u00b7sers", "Got\u00b7tes", "Wil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKA", "ADJD", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Diese haben durch Gottes Geist getrieben,", "tokens": ["Die\u00b7se", "ha\u00b7ben", "durch", "Got\u00b7tes", "Geist", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Beydes M\u00e4nner und Boten Gotts beschrieben:", "tokens": ["Bey\u00b7des", "M\u00e4n\u00b7ner", "und", "Bo\u00b7ten", "Gotts", "be\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "NE", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Es bezeugt es der heilgen M\u00e4rtrer Orden,", "tokens": ["Es", "be\u00b7zeugt", "es", "der", "heil\u00b7gen", "M\u00e4r\u00b7trer", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da\u00df durch Gottes Blut sie best\u00e4tigt worden.", "tokens": ["Da\u00df", "durch", "Got\u00b7tes", "Blut", "sie", "be\u00b7st\u00e4\u00b7tigt", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "NN", "PPER", "VVPP", "VAPP", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die hat Gott in der Christlichen Gemeine", "tokens": ["Die", "hat", "Gott", "in", "der", "Christ\u00b7li\u00b7chen", "Ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Von dem ersten zu diesem Sonnenscheine", "tokens": ["Von", "dem", "ers\u00b7ten", "zu", "die\u00b7sem", "Son\u00b7nen\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "APPR", "PDAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Vor des Teufels Gewalt und Trotz erhalten:", "tokens": ["Vor", "des", "Teu\u00b7fels", "Ge\u00b7walt", "und", "Trotz", "er\u00b7hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "Die Sein Wort, nicht der Menschen l\u00e4sset walten.", "tokens": ["Die", "Sein", "Wort", ",", "nicht", "der", "Men\u00b7schen", "l\u00e4s\u00b7set", "wal\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$,", "PTKNEG", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.13": {"text": "Vor der Kirchen, die bleibt bey diesen Worten,", "tokens": ["Vor", "der", "Kir\u00b7chen", ",", "die", "bleibt", "bey", "die\u00b7sen", "Wor\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "Gehn zu St\u00fccke der H\u00f6llen d\u00fcstre Pforten.", "tokens": ["Gehn", "zu", "St\u00fc\u00b7cke", "der", "H\u00f6l\u00b7len", "d\u00fcst\u00b7re", "Pfor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ART", "NN", "VVFIN", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Ja die Kirch, ob sie solt in eines Hertzen", "tokens": ["Ja", "die", "Kirch", ",", "ob", "sie", "solt", "in", "ei\u00b7nes", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ART", "NN", "$,", "KOUS", "PPER", "VMFIN", "APPR", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Blo\u00df bestehn, wir den Ha\u00df der Pforten schertzen,", "tokens": ["Blo\u00df", "be\u00b7stehn", ",", "wir", "den", "Ha\u00df", "der", "Pfor\u00b7ten", "schert\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "Wann den Weg der Schrifft Sie nur nicht verlassen,", "tokens": ["Wann", "den", "Weg", "der", "Schrifft", "Sie", "nur", "nicht", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Ohn die Irrth\u00fcmer Predigstuhl umbfassen:", "tokens": ["Ohn", "die", "I\u00b7rrth\u00fc\u00b7mer", "Pre\u00b7digs\u00b7tuhl", "umb\u00b7fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Menschen Zeugn\u00fcsse fehlen: Gottes stehen:", "tokens": ["Men\u00b7schen", "Zeug\u00b7n\u00fcs\u00b7se", "feh\u00b7len", ":", "Got\u00b7tes", "ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$.", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.20": {"text": "Auf die mu\u00df man in Glaubens Sachen gehen.", "tokens": ["Auf", "die", "mu\u00df", "man", "in", "Glau\u00b7bens", "Sa\u00b7chen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "PIS", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.21": {"text": "Denn der Gottesdienst der besteht auf Erden", "tokens": ["Denn", "der", "Got\u00b7tes\u00b7dienst", "der", "be\u00b7steht", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "VVFIN", "APPR", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Blo\u00df in dem, wie der Mensch sol seelig werden:", "tokens": ["Blo\u00df", "in", "dem", ",", "wie", "der", "Mensch", "sol", "see\u00b7lig", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "$,", "PWAV", "ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Den Weg zeiget die Schrifft, der sol er trauen,", "tokens": ["Den", "Weg", "zei\u00b7get", "die", "Schrifft", ",", "der", "sol", "er", "trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "PRELS", "KOUS", "PPER", "VVINF", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "So auf Gott durch sein Wort den Glauben bauen:", "tokens": ["So", "auf", "Gott", "durch", "sein", "Wort", "den", "Glau\u00b7ben", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Und da\u00df wir nicht gef\u00e4hret sollen werden:", "tokens": ["Und", "da\u00df", "wir", "nicht", "ge\u00b7f\u00e4h\u00b7ret", "sol\u00b7len", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "VVPP", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Wird Gott Mensch, und das Wort selbst Fleisch auf Erden.", "tokens": ["Wird", "Gott", "Mensch", ",", "und", "das", "Wort", "selbst", "Fleisch", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "$,", "KON", "ART", "NN", "ADV", "NN", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.27": {"text": "Was der V\u00e4ter Schaar aus den vier Buchstaben", "tokens": ["Was", "der", "V\u00e4\u00b7ter", "Schaar", "aus", "den", "vier", "Buch\u00b7sta\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NN", "APPR", "ART", "CARD", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Mit dem SIN vermischt, hochgew\u00fcnscht zu haben,", "tokens": ["Mit", "dem", "SiN", "ver\u00b7mischt", ",", "hoch\u00b7ge\u00b7w\u00fcnscht", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.29": {"text": "Zeigt die Schrifft blo\u00df vor uns; vor uns vorhanden,", "tokens": ["Zeigt", "die", "Schrifft", "blo\u00df", "vor", "uns", ";", "vor", "uns", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "PPER", "$.", "APPR", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Uns gebohren, uns gecreutziget, Uns erstanden.", "tokens": ["Uns", "ge\u00b7boh\u00b7ren", ",", "uns", "ge\u00b7cr\u00b7eut\u00b7zi\u00b7get", ",", "Uns", "er\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PPER", "VVPP", "$,", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.31": {"text": "Die sind, so nach der Schrifft durch IHN im Wesen", "tokens": ["Die", "sind", ",", "so", "nach", "der", "Schrifft", "durch", "IhN", "im", "We\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "ADV", "APPR", "ART", "NN", "APPR", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Die Barmhertzigkeit Gottes erglaubt, gewesen.", "tokens": ["Die", "Barm\u00b7hert\u00b7zig\u00b7keit", "Got\u00b7tes", "er\u00b7glaubt", ",", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,", "VAPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.33": {"text": "Wie sie alle Gewalt aus Gottes G\u00fcte", "tokens": ["Wie", "sie", "al\u00b7le", "Ge\u00b7walt", "aus", "Got\u00b7tes", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PIAT", "NN", "APPR", "NN", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.34": {"text": "Durch ihr Hertze, durch Seel und durch Gem\u00fcthe", "tokens": ["Durch", "ihr", "Hert\u00b7ze", ",", "durch", "Seel", "und", "durch", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.35": {"text": "In die h\u00f6chste ziehn, und sich drinnen leiden,", "tokens": ["In", "die", "h\u00f6chs\u00b7te", "ziehn", ",", "und", "sich", "drin\u00b7nen", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVINF", "$,", "KON", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.36": {"text": "Bi\u00df in sein Verdienst sie der Herr wil kleiden:", "tokens": ["Bi\u00df", "in", "sein", "Ver\u00b7dienst", "sie", "der", "Herr", "wil", "klei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPOSAT", "NN", "PPER", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Und drauf voller Trost mit erwecktem Muthe,", "tokens": ["Und", "drauf", "vol\u00b7ler", "Trost", "mit", "er\u00b7weck\u00b7tem", "Mu\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Rein und heilig von Christus Lehr und Blute.", "tokens": ["Rein", "und", "hei\u00b7lig", "von", "Chris\u00b7tus", "Lehr", "und", "Blu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "NE", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.39": {"text": "Sich durch Schrifft und durch Geist, /:zwey starcke Schrauben: /", "tokens": ["Sich", "durch", "Schrifft", "und", "durch", "Geist", ",", "/", ":", "zwey", "star\u00b7cke", "Schrau\u00b7ben", ":", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "APPR", "NN", "$,", "$(", "$.", "CARD", "ADJA", "NN", "$.", "$("], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "In das Hertze der tieffren Gottheit glauben:", "tokens": ["In", "das", "Hert\u00b7ze", "der", "tief\u00b7fren", "Got\u00b7theit", "glau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.41": {"text": "Das am Creutze der Heyland aufgerissen,", "tokens": ["Das", "am", "Creut\u00b7ze", "der", "Hey\u00b7land", "auf\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.42": {"text": "Sie durch seine f\u00fcnff Wunden drein zu schliessen:", "tokens": ["Sie", "durch", "sei\u00b7ne", "f\u00fcnff", "Wun\u00b7den", "drein", "zu", "schlies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "CARD", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.43": {"text": "/:Wol verwahrt. Dann in Gottes Hertz und Gnaden", "tokens": ["/", ":", "Wol", "ver\u00b7wahrt", ".", "Dann", "in", "Got\u00b7tes", "Hertz", "und", "Gna\u00b7den"], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "$.", "ADV", "VVPP", "$.", "ADV", "APPR", "NN", "NN", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.44": {"text": "Kan noch H\u00f6lle, noch Teufel ihnen schaden:/", "tokens": ["Kan", "noch", "H\u00f6l\u00b7le", ",", "noch", "Teu\u00b7fel", "ih\u00b7nen", "scha\u00b7den", ":/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "emoticon"], "pos": ["VMFIN", "ADV", "NN", "$,", "ADV", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.45": {"text": "Also werden, wie Stahl mit Kieselsteinen", "tokens": ["Al\u00b7so", "wer\u00b7den", ",", "wie", "Stahl", "mit", "Kie\u00b7sel\u00b7stei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAINF", "$,", "PWAV", "NN", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.46": {"text": "Den Verstand, die Vernunfft, den Glauben reinen:", "tokens": ["Den", "Ver\u00b7stand", ",", "die", "Ver\u00b7nunfft", ",", "den", "Glau\u00b7ben", "rei\u00b7nen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.47": {"text": "Und durch Christus Verdienst das Hertz anfeuchten,", "tokens": ["Und", "durch", "Chris\u00b7tus", "Ver\u00b7dienst", "das", "Hertz", "an\u00b7feuch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.48": {"text": "Draus wir werden sehn Gottes Gnade leuchten:", "tokens": ["Draus", "wir", "wer\u00b7den", "sehn", "Got\u00b7tes", "Gna\u00b7de", "leuch\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VAFIN", "CARD", "NN", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.49": {"text": "/:Wie sie, als ich sie von der Hand geschrieben,", "tokens": ["/", ":", "Wie", "sie", ",", "als", "ich", "sie", "von", "der", "Hand", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$.", "PWAV", "PPER", "$,", "KOUS", "PPER", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Meinen edlen von Donat angetrieben,", "tokens": ["Mei\u00b7nen", "ed\u00b7len", "von", "Do\u00b7nat", "an\u00b7ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "APPR", "NE", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.51": {"text": "Da\u00df in einer Nacht er /:O theurer Orden:/", "tokens": ["Da\u00df", "in", "ei\u00b7ner", "Nacht", "er", "/", ":o", "theu\u00b7rer", "Or\u00b7den", ":/"], "token_info": ["word", "word", "word", "word", "word", "punct", "emoticon", "word", "word", "emoticon"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "$(", "NE", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.52": {"text": "Ein Mensch, ein Christ, ein Gottesfreund ist worden.", "tokens": ["Ein", "Mensch", ",", "ein", "Christ", ",", "ein", "Got\u00b7tes\u00b7freund", "ist", "wor\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.53": {"text": "Dessen eilender Tod ihm bald das Leben,", "tokens": ["Des\u00b7sen", "ei\u00b7len\u00b7der", "Tod", "ihm", "bald", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.54": {"text": "Das er drunter erblickt, in Gott gegeben:", "tokens": ["Das", "er", "drun\u00b7ter", "er\u00b7blickt", ",", "in", "Gott", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PAV", "VVPP", "$,", "APPR", "NN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.55": {"text": "Ja es werden, wilst du sie Grundrecht h\u00f6ren,", "tokens": ["Ja", "es", "wer\u00b7den", ",", "wilst", "du", "sie", "Grund\u00b7recht", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VAINF", "$,", "VMFIN", "PPER", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.56": {"text": "Also dich zu Gott ziehn die Weisen Lehren.", "tokens": ["Al\u00b7so", "dich", "zu", "Gott", "ziehn", "die", "Wei\u00b7sen", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.57": {"text": "Hertzog: Vor Euch, wo es ihm wird gel\u00fccken,", "tokens": ["Hert\u00b7zog", ":", "Vor", "Euch", ",", "wo", "es", "ihm", "wird", "ge\u00b7l\u00fc\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "PPER", "$,", "PWAV", "PPER", "PPER", "VAFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.58": {"text": "Wird der deutsche Phaleucus sich nu b\u00fccken:", "tokens": ["Wird", "der", "deut\u00b7sche", "Pha\u00b7leu\u00b7cus", "sich", "nu", "b\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.59": {"text": "Als ein Wegweiser zweyer hohen Strassen,", "tokens": ["Als", "ein", "Weg\u00b7wei\u00b7ser", "zwey\u00b7er", "ho\u00b7hen", "Stras\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.60": {"text": "Derer sich nach der Ordnung anzumassen:", "tokens": ["De\u00b7rer", "sich", "nach", "der", "Ord\u00b7nung", "an\u00b7zu\u00b7mas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Die im Tichten des Geists Entz\u00fcckung f\u00fchlen,", "tokens": ["Die", "im", "Tich\u00b7ten", "des", "Geists", "Ent\u00b7z\u00fc\u00b7ckung", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.62": {"text": "Die der Sterne Gestalt und Lauff erzielen:", "tokens": ["Die", "der", "Ster\u00b7ne", "Ge\u00b7stalt", "und", "Lauff", "er\u00b7zie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.63": {"text": "Die im Monden uns alle Sterne zeigen,", "tokens": ["Die", "im", "Mon\u00b7den", "uns", "al\u00b7le", "Ster\u00b7ne", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.64": {"text": "Seine Kugel durch Gl\u00e4ser zu uns neigen:", "tokens": ["Sei\u00b7ne", "Ku\u00b7gel", "durch", "Gl\u00e4\u00b7ser", "zu", "uns", "nei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.65": {"text": "Die im Messen der Erden Wendung finden:", "tokens": ["Die", "im", "Mes\u00b7sen", "der", "Er\u00b7den", "Wen\u00b7dung", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.66": {"text": "Die im Rechnen in Einem Alles gr\u00fcnden:", "tokens": ["Die", "im", "Rech\u00b7nen", "in", "Ei\u00b7nem", "Al\u00b7les", "gr\u00fcn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "APPR", "ART", "PIS", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.67": {"text": "Die im Lehren Gem\u00fcth und Gott vereinen:", "tokens": ["Die", "im", "Leh\u00b7ren", "Ge\u00b7m\u00fcth", "und", "Gott", "ver\u00b7ei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.68": {"text": "Die im Richten das Recht, nicht Menschen meinen:", "tokens": ["Die", "im", "Rich\u00b7ten", "das", "Recht", ",", "nicht", "Men\u00b7schen", "mei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "$,", "PTKNEG", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.69": {"text": "Die im Heilen sich ziehn auf Gottes Seegen,", "tokens": ["Die", "im", "Hei\u00b7len", "sich", "ziehn", "auf", "Got\u00b7tes", "See\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PRF", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.70": {"text": "Der das Mittel kan in die Mittel legen.", "tokens": ["Der", "das", "Mit\u00b7tel", "kan", "in", "die", "Mit\u00b7tel", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.71": {"text": "Auch die: Wesen und Nahmen auszuf\u00fchren,", "tokens": ["Auch", "die", ":", "We\u00b7sen", "und", "Nah\u00b7men", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$.", "NN", "KON", "NN", "VVIZU", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.72": {"text": "Der Natur A. B. C. nach buchstabieren.", "tokens": ["Der", "Na\u00b7tur", "A.", "B.", "C.", "nach", "buch\u00b7sta\u00b7bie\u00b7ren", "."], "token_info": ["word", "word", "abbreviation", "abbreviation", "abbreviation", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "NE", "APPR", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.73": {"text": "Auch die, welche den Grund der Erde suchen,", "tokens": ["Auch", "die", ",", "wel\u00b7che", "den", "Grund", "der", "Er\u00b7de", "su\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.74": {"text": "Und ihr glastendes Hertz aus solchem kochen.", "tokens": ["Und", "ihr", "glas\u00b7ten\u00b7des", "Hertz", "aus", "sol\u00b7chem", "ko\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "PIAT", "ADJA", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.75": {"text": "Auch die voll Seeligkeit sabbathisiren,", "tokens": ["Auch", "die", "voll", "See\u00b7lig\u00b7keit", "sab\u00b7ba\u00b7thi\u00b7si\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "+--+--+-+--", "measure": "dactylic.di.plus"}, "line.76": {"text": "Untern Thronf\u00fcrsten Gottes Lob vollf\u00fchren.", "tokens": ["Un\u00b7tern", "Thron\u00b7f\u00fcrs\u00b7ten", "Got\u00b7tes", "Lob", "voll\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.77": {"text": "Auch die, welche nach Ehre pflegt zu d\u00fcrsten,", "tokens": ["Auch", "die", ",", "wel\u00b7che", "nach", "Eh\u00b7re", "pflegt", "zu", "d\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.78": {"text": "Wie vom Stande so vom Verstande F\u00fcrsten.", "tokens": ["Wie", "vom", "Stan\u00b7de", "so", "vom", "Ver\u00b7stan\u00b7de", "F\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.79": {"text": "Wann sie ihr und des Reiches Ruh erwegen:", "tokens": ["Wann", "sie", "ihr", "und", "des", "Rei\u00b7ches", "Ruh", "er\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.80": {"text": "Wann die Freyheit sie sch\u00fctzen mit dem Degen:", "tokens": ["Wann", "die", "Frey\u00b7heit", "sie", "sch\u00fct\u00b7zen", "mit", "dem", "De\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.81": {"text": "Wann zu Gott sie durch sein Wort gehn und treten,", "tokens": ["Wann", "zu", "Gott", "sie", "durch", "sein", "Wort", "gehn", "und", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "KON", "VVFIN", "$,"], "meter": "--+----+-+-", "measure": "anapaest.init"}, "line.82": {"text": "Wann sie Prediger heissen lehrn und beten.", "tokens": ["Wann", "sie", "Pre\u00b7di\u00b7ger", "heis\u00b7sen", "lehrn", "und", "be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "VVINF", "KON", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.83": {"text": "Wann sie Reichst\u00e4g schliessen und drob halten,", "tokens": ["Wann", "sie", "Reichs\u00b7t\u00e4g", "schlies\u00b7sen", "und", "drob", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "KON", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.84": {"text": "Wann sie Ehrsucht und Feindschafft nicht kan spalten.", "tokens": ["Wann", "sie", "Ehr\u00b7sucht", "und", "Feind\u00b7schafft", "nicht", "kan", "spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.85": {"text": "Kurtz: wer unter den Menschen sich im Leben", "tokens": ["Kurtz", ":", "wer", "un\u00b7ter", "den", "Men\u00b7schen", "sich", "im", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PWS", "APPR", "ART", "NN", "PRF", "APPRART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.86": {"text": "\u00dcber Menschliche Dinge wil erheben,", "tokens": ["\u00dc\u00b7ber", "Menschli\u00b7che", "Din\u00b7ge", "wil", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.87": {"text": "Und, da\u00df er sey ein rechter Mensch, erweisen,", "tokens": ["Und", ",", "da\u00df", "er", "sey", "ein", "rech\u00b7ter", "Mensch", ",", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.88": {"text": "Mu\u00df die Strasse, sonst ist er kein Mensch, reisen.", "tokens": ["Mu\u00df", "die", "Stras\u00b7se", ",", "sonst", "ist", "er", "kein", "Mensch", ",", "rei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "PIAT", "NN", "$,", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.89": {"text": "Beyde haben im Hertzen und im Munde", "tokens": ["Bey\u00b7de", "ha\u00b7ben", "im", "Hert\u00b7zen", "und", "im", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.90": {"text": "Jene Schrifft, die Natur die zu dem Grunde.", "tokens": ["Je\u00b7ne", "Schrifft", ",", "die", "Na\u00b7tur", "die", "zu", "dem", "Grun\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "ART", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.91": {"text": "Es geht beyder Grund, drauf kanst du dich schrauben:", "tokens": ["Es", "geht", "bey\u00b7der", "Grund", ",", "drauf", "kanst", "du", "dich", "schrau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "PAV", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.92": {"text": "Der Natur auf Verstehn, der Schrifft auf Glauben.", "tokens": ["Der", "Na\u00b7tur", "auf", "Ver\u00b7stehn", ",", "der", "Schrifft", "auf", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.93": {"text": "Ey nu /:wem auch wol solten sie sonst feyern:/", "tokens": ["Ey", "nu", "/", ":", "wem", "auch", "wol", "sol\u00b7ten", "sie", "sonst", "fey\u00b7ern", ":/"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["NN", "ADV", "$(", "$.", "PWS", "ADV", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.94": {"text": "Wie die Tichter, was sie voll Gottheit leyern:", "tokens": ["Wie", "die", "Tich\u00b7ter", ",", "was", "sie", "voll", "Got\u00b7theit", "ley\u00b7ern", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "--+---+--+-", "measure": "iambic.tri.relaxed"}, "line.95": {"text": "Wie die Sternfreunde, was sie sehn durch Scheiben:", "tokens": ["Wie", "die", "Stern\u00b7freun\u00b7de", ",", "was", "sie", "sehn", "durch", "Schei\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.96": {"text": "Wie die Schauer, was sie erfahrn und schreiben:", "tokens": ["Wie", "die", "Schau\u00b7er", ",", "was", "sie", "er\u00b7fahrn", "und", "schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.97": {"text": "Wie die FeldMesser, was die St\u00e4be tragen:", "tokens": ["Wie", "die", "Feld", "Mes\u00b7ser", ",", "was", "die", "St\u00e4\u00b7be", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.98": {"text": "Wie die RechMeister, was sie \u00fcberschlagen:", "tokens": ["Wie", "die", "Rech", "Meis\u00b7ter", ",", "was", "sie", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.99": {"text": "Wie die Priester, was sie im Geiste schauen:", "tokens": ["Wie", "die", "Pries\u00b7ter", ",", "was", "sie", "im", "Geis\u00b7te", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.100": {"text": "Wie die Richter, was sie vor Urtheil bauen:", "tokens": ["Wie", "die", "Rich\u00b7ter", ",", "was", "sie", "vor", "Ur\u00b7theil", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.101": {"text": "Wie die Aertzte, was sie bedachtsam suchen,", "tokens": ["Wie", "die", "A\u00b7ertz\u00b7te", ",", "was", "sie", "be\u00b7dacht\u00b7sam", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$,"], "meter": "---+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.102": {"text": "Und aus Kra\u00fctern, aus Ertzt, aus Thieren kochen:", "tokens": ["Und", "aus", "Kr\u00b7a\u00fc\u00b7tern", ",", "aus", "Ertzt", ",", "aus", "Thie\u00b7ren", "ko\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.103": {"text": "Euch dem OberHaupt und nach dem Wort Zeichen", "tokens": ["Euch", "dem", "O\u00b7ber", "Haupt", "und", "nach", "dem", "Wort", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "NN", "KON", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.104": {"text": "Dem Schmackhafften in der Gesellschafft reichen:", "tokens": ["Dem", "Schmack\u00b7haff\u00b7ten", "in", "der", "Ge\u00b7sell\u00b7schafft", "rei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-++-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.105": {"text": "Hertzog: Also nehmt nach den Reichs Gesch\u00e4fften,", "tokens": ["Hert\u00b7zog", ":", "Al\u00b7so", "nehmt", "nach", "den", "Reichs", "Ge\u00b7sch\u00e4ff\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "++--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.106": {"text": "Nach des Weinmarschen Hauses Zier und Kr\u00e4fften:", "tokens": ["Nach", "des", "Wein\u00b7mar\u00b7schen", "Hau\u00b7ses", "Zier", "und", "Kr\u00e4ff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.107": {"text": "Nach dem Gottesdienst und den heilgen Stunden.", "tokens": ["Nach", "dem", "Got\u00b7tes\u00b7dienst", "und", "den", "heil\u00b7gen", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.108": {"text": "Etwa: wie auf der Bahn das Wild von Hunden,", "tokens": ["Et\u00b7wa", ":", "wie", "auf", "der", "Bahn", "das", "Wild", "von", "Hun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PWAV", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.109": {"text": "Wie die Blumen im Garten von den Reisen:", "tokens": ["Wie", "die", "Blu\u00b7men", "im", "Gar\u00b7ten", "von", "den", "Rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.110": {"text": "Wie die Fr\u00fccht auf der Taffel nach den Speisen:", "tokens": ["Wie", "die", "Fr\u00fccht", "auf", "der", "Taf\u00b7fel", "nach", "den", "Spei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.111": {"text": "Das ist: wie es beliebt: die weisen Lehren.", "tokens": ["Das", "ist", ":", "wie", "es", "be\u00b7liebt", ":", "die", "wei\u00b7sen", "Leh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$.", "PWAV", "PPER", "ADJD", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.112": {"text": "Nehmt, und g\u00f6nnt mir die Ehr, Euch so zu ehren.", "tokens": ["Nehmt", ",", "und", "g\u00f6nnt", "mir", "die", "Ehr", ",", "Euch", "so", "zu", "eh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.113": {"text": "Es sol Euer Land drum wie Raute stehen,", "tokens": ["Es", "sol", "Eu\u00b7er", "Land", "drum", "wie", "Rau\u00b7te", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PAV", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.114": {"text": "Euer Haus wie der Palmbaum sich erh\u00f6hen,", "tokens": ["Eu\u00b7er", "Haus", "wie", "der", "Palm\u00b7baum", "sich", "er\u00b7h\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.115": {"text": "Euer Hoff von gelehrten Leuten gl\u00e4ntzen,", "tokens": ["Eu\u00b7er", "Hoff", "von", "ge\u00b7lehr\u00b7ten", "Leu\u00b7ten", "gl\u00e4nt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.116": {"text": "Euer Ruhm mit der Welt die Wette gr\u00e4ntzen.", "tokens": ["Eu\u00b7er", "Ruhm", "mit", "der", "Welt", "die", "Wet\u00b7te", "gr\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.117": {"text": "Ja es wird der Geburtstamm Eurer Printzen", "tokens": ["Ja", "es", "wird", "der", "Ge\u00b7burt\u00b7stamm", "Eu\u00b7rer", "Print\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.118": {"text": "Vor der Sonnen Gewalt am minsten blintzen:", "tokens": ["Vor", "der", "Son\u00b7nen", "Ge\u00b7walt", "am", "mins\u00b7ten", "blint\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.119": {"text": "Er wird mitten in Sie die Augen werffen,", "tokens": ["Er", "wird", "mit\u00b7ten", "in", "Sie", "die", "Au\u00b7gen", "werf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.120": {"text": "Und nach Adlers Art sein in Euren sch\u00e4rffen.", "tokens": ["Und", "nach", "Ad\u00b7lers", "Art", "sein", "in", "Eu\u00b7ren", "sch\u00e4rf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "PPOSAT", "APPR", "PPOSAT", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.121": {"text": "Wol: Ich sehe wie sie voll Gottheit brennen:", "tokens": ["Wol", ":", "Ich", "se\u00b7he", "wie", "sie", "voll", "Got\u00b7theit", "bren\u00b7nen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "KOKOM", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.122": {"text": "Beyde Strassen mit freyen Z\u00fcgeln rennen:", "tokens": ["Bey\u00b7de", "Stras\u00b7sen", "mit", "frey\u00b7en", "Z\u00fc\u00b7geln", "ren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.123": {"text": "So die Schrifft und dann die Natur gebrochen,", "tokens": ["So", "die", "Schrifft", "und", "dann", "die", "Na\u00b7tur", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.124": {"text": "Jen in Gott, in der Welt ist die zu suchen:", "tokens": ["Jen", "in", "Gott", ",", "in", "der", "Welt", "ist", "die", "zu", "su\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$,", "APPR", "ART", "NN", "VAFIN", "ART", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.125": {"text": "Jene Seeligkeit, die kan Wei\u00dfheit geben,", "tokens": ["Je\u00b7ne", "See\u00b7lig\u00b7keit", ",", "die", "kan", "Wei\u00df\u00b7heit", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PRELS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.126": {"text": "\u00dcber F\u00fcrsten ein iedre F\u00fcrsten heben.", "tokens": ["\u00dc\u00b7ber", "F\u00fcrs\u00b7ten", "ein", "ie\u00b7dre", "F\u00fcrs\u00b7ten", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.127": {"text": "Gut: der Wei\u00dfheit in der Natur nachschlagen:", "tokens": ["Gut", ":", "der", "Wei\u00df\u00b7heit", "in", "der", "Na\u00b7tur", "nach\u00b7schla\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.128": {"text": "Besser: Seeligkeit in der Schrifft erfragen:", "tokens": ["Bes\u00b7ser", ":", "See\u00b7lig\u00b7keit", "in", "der", "Schrifft", "er\u00b7fra\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.129": {"text": "An dem besten: Natur und Schrifft vergleichen,", "tokens": ["An", "dem", "bes\u00b7ten", ":", "Na\u00b7tur", "und", "Schrifft", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.130": {"text": "Als der g\u00f6ttlichen Wahrheit feste Zeichen.", "tokens": ["Als", "der", "g\u00f6tt\u00b7li\u00b7chen", "Wahr\u00b7heit", "fes\u00b7te", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.131": {"text": "Und nichts weis', als was seelig ist, erkennen,", "tokens": ["Und", "nichts", "weis'", ",", "als", "was", "see\u00b7lig", "ist", ",", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "PTKVZ", "$,", "KOUS", "PIS", "ADJD", "VAFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.132": {"text": "Und nichts seelig, als was da weis' ist, nennen:", "tokens": ["Und", "nichts", "see\u00b7lig", ",", "als", "was", "da", "weis'", "ist", ",", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "$,", "KOUS", "PIS", "ADV", "VVFIN", "VAFIN", "$,", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.133": {"text": "Beyder Grund ist Gott f\u00fcrchten und Gott ehren:", "tokens": ["Bey\u00b7der", "Grund", "ist", "Gott", "f\u00fcrch\u00b7ten", "und", "Gott", "eh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "NN", "VVINF", "KON", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.134": {"text": "Den zeig ich der Gesellschaft in den LEHREN.", "tokens": ["Den", "zeig", "ich", "der", "Ge\u00b7sell\u00b7schaft", "in", "den", "LeH\u00b7REN", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.65": {"line.1": {"text": "Nicht blo\u00df \u00fcber viel Festen, St\u00e4dt und Flecken,", "tokens": ["Nicht", "blo\u00df", "\u00fc\u00b7ber", "viel", "Fes\u00b7ten", ",", "St\u00e4dt", "und", "Fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PIAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Was vor Leute die Stern auch drunter decken:", "tokens": ["Was", "vor", "Leu\u00b7te", "die", "Stern", "auch", "drun\u00b7ter", "de\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ART", "NN", "ADV", "PAV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Sondern \u00fcber viel K\u00fcnst' und weise Schrifften,", "tokens": ["Son\u00b7dern", "\u00fc\u00b7ber", "viel", "K\u00fcnst'", "und", "wei\u00b7se", "Schriff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "So die Deutsche Gesellschafft wei\u00df zu stifften:", "tokens": ["So", "die", "Deut\u00b7sche", "Ge\u00b7sell\u00b7schafft", "wei\u00df", "zu", "stiff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "/: O ein \u00fcberaus herrliches Gebiete!:/", "tokens": ["/", ":", "O", "ein", "\u00fc\u00b7be\u00b7raus", "herr\u00b7li\u00b7ches", "Ge\u00b7bie\u00b7te", "!", ":/"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "punct", "emoticon"], "pos": ["$(", "$.", "NE", "ART", "ADV", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Hertzog vom Wittikindischen Gebl\u00fcte!", "tokens": ["Hert\u00b7zog", "vom", "Wit\u00b7ti\u00b7kin\u00b7di\u00b7schen", "Ge\u00b7bl\u00fc\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.66": {"line.1": {"text": "Da\u00df die Fackel vom Ober Sachsen Creisse", "tokens": ["Da\u00df", "die", "Fa\u00b7ckel", "vom", "O\u00b7ber", "Sach\u00b7sen", "Creis\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPRART", "NN", "NE", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Euer Weinmar mich also weichen heisse,", "tokens": ["Eu\u00b7er", "Wein\u00b7mar", "mich", "al\u00b7so", "wei\u00b7chen", "heis\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADV", "VVINF", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Als vermessen durch eures Schlosses Bogen", "tokens": ["Als", "ver\u00b7mes\u00b7sen", "durch", "eu\u00b7res", "Schlos\u00b7ses", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VVPP", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Dieser deutsche Phaleucus kommt gezogen.", "tokens": ["Die\u00b7ser", "deut\u00b7sche", "Pha\u00b7leu\u00b7cus", "kommt", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "VVFIN", "VVPP", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}}, "stanza.67": {"line.1": {"text": "Jedoch, unter so hocherlauchten Helden,", "tokens": ["Je\u00b7doch", ",", "un\u00b7ter", "so", "ho\u00b7cher\u00b7lauch\u00b7ten", "Hel\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "So von Alpen bi\u00df an Codan zu melden,", "tokens": ["So", "von", "Al\u00b7pen", "bi\u00df", "an", "Co\u00b7dan", "zu", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lasset Eure Trabanten, Euch zu gr\u00fcssen,", "tokens": ["Las\u00b7set", "Eu\u00b7re", "Tra\u00b7ban\u00b7ten", ",", "Euch", "zu", "gr\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Mir die unterste Staffel nicht verschliessen.", "tokens": ["Mir", "die", "un\u00b7ters\u00b7te", "Staf\u00b7fel", "nicht", "ver\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.68": {"line.1": {"text": "Von dem Zobten Berg und der Oder Rande", "tokens": ["Von", "dem", "Zob\u00b7ten", "Berg", "und", "der", "O\u00b7der", "Ran\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "ART", "NE", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Komm an Ettersberg ich zur Sala Strande:", "tokens": ["Komm", "an", "Et\u00b7ters\u00b7berg", "ich", "zur", "Sa\u00b7la", "Stran\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PPER", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Von der Stadt, die genannt wird von dem Schweine:", "tokens": ["Von", "der", "Stadt", ",", "die", "ge\u00b7nannt", "wird", "von", "dem", "Schwei\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVPP", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Zu der Stadt, die genannt wird von dem Weine.", "tokens": ["Zu", "der", "Stadt", ",", "die", "ge\u00b7nannt", "wird", "von", "dem", "Wei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVPP", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.69": {"line.1": {"text": "Derowegen, o Haupt der kl\u00fcgsten Sinnen,", "tokens": ["De\u00b7ro\u00b7we\u00b7gen", ",", "o", "Haupt", "der", "kl\u00fcgs\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So die Crone der Wissenschafft beginnen:", "tokens": ["So", "die", "Cro\u00b7ne", "der", "Wis\u00b7sen\u00b7schafft", "be\u00b7gin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und den Weinmarischen Hof weit vor Iberen,", "tokens": ["Und", "den", "Wein\u00b7ma\u00b7ri\u00b7schen", "Hof", "weit", "vor", "I\u00b7be\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJD", "APPR", "NE", "$,"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Weit vor Gallien, weit vor Rom verehren.", "tokens": ["Weit", "vor", "Gal\u00b7li\u00b7en", ",", "weit", "vor", "Rom", "ver\u00b7eh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NE", "$,", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.70": {"line.1": {"text": "Untern B\u00fcchern und Schrifften, so zu preisen,", "tokens": ["Un\u00b7tern", "B\u00fc\u00b7chern", "und", "Schriff\u00b7ten", ",", "so", "zu", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Unter K\u00fcnsten und Sachen alter Weisen:", "tokens": ["Un\u00b7ter", "K\u00fcns\u00b7ten", "und", "Sa\u00b7chen", "al\u00b7ter", "Wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Unter Sprachen und Lehren, so zu mercken,", "tokens": ["Un\u00b7ter", "Spra\u00b7chen", "und", "Leh\u00b7ren", ",", "so", "zu", "mer\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Unter Meistern von Deutscher Art und Wercken.", "tokens": ["Un\u00b7ter", "Meis\u00b7tern", "von", "Deut\u00b7scher", "Art", "und", "Wer\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.71": {"line.1": {"text": "Es sey: da\u00df sie den Geist der Tichter f\u00fchlen,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "den", "Geist", "der", "Tich\u00b7ter", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie sie an der gelehrten Pegnitz spielen:", "tokens": ["Wie", "sie", "an", "der", "ge\u00b7lehr\u00b7ten", "Peg\u00b7nitz", "spie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und in der Hecatombe recht betrachten,", "tokens": ["Und", "in", "der", "He\u00b7ca\u00b7tom\u00b7be", "recht", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wo die Eitelkeit Balde bald wil schlachten.", "tokens": ["Wo", "die", "Ei\u00b7tel\u00b7keit", "Bal\u00b7de", "bald", "wil", "schlach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "ADV", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.72": {"line.1": {"text": "Es sey: da\u00df sie die Sonn an Himmel zwecken,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "die", "Sonn", "an", "Him\u00b7mel", "zwe\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihren Thier Circkel umb das Mittel stecken,", "tokens": ["Ih\u00b7ren", "Thier", "Cir\u00b7ckel", "umb", "das", "Mit\u00b7tel", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und die Irrstern in ihre Bogen schliessen,", "tokens": ["Und", "die", "Irrs\u00b7tern", "in", "ih\u00b7re", "Bo\u00b7gen", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Was nach hundert Jahrn sol geschehn, draus wissen:", "tokens": ["Was", "nach", "hun\u00b7dert", "Jahrn", "sol", "ge\u00b7schehn", ",", "draus", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "CARD", "NN", "VMFIN", "VVINF", "$,", "PAV", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Wie es Cunitia die Zier der Frauen", "tokens": ["Wie", "es", "Cu\u00b7ni\u00b7tia", "die", "Zier", "der", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "NE", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "In unsterbliche Taffeln hat gehauen:", "tokens": ["In", "uns\u00b7terb\u00b7li\u00b7che", "Taf\u00b7feln", "hat", "ge\u00b7hau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.73": {"line.1": {"text": "Es sey: da\u00df sie durch Stern und Fern Gesichte", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "durch", "Stern", "und", "Fern", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "APPR", "NN", "KON", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Uns die Ewigkeit machen hell und lichte:", "tokens": ["Uns", "die", "E\u00b7wig\u00b7keit", "ma\u00b7chen", "hell", "und", "lich\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und im Monden eine andre Welt beweisen,", "tokens": ["Und", "im", "Mon\u00b7den", "ei\u00b7ne", "and\u00b7re", "Welt", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "In die wir mit Gem\u00fcth und Augen reisen:", "tokens": ["In", "die", "wir", "mit", "Ge\u00b7m\u00fcth", "und", "Au\u00b7gen", "rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Drinnen Landschafften, Meer und Berge mercken,", "tokens": ["Drin\u00b7nen", "Land\u00b7schaff\u00b7ten", ",", "Meer", "und", "Ber\u00b7ge", "mer\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und den Sch\u00f6pffer verehrn in seinen Wercken:", "tokens": ["Und", "den", "Sch\u00f6pf\u00b7fer", "ver\u00b7ehrn", "in", "sei\u00b7nen", "Wer\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Wie es Hewelcke vor den Mund gerissen,", "tokens": ["Wie", "es", "He\u00b7wel\u00b7cke", "vor", "den", "Mund", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und vorf\u00fchret mit Grundgerechten Schl\u00fcssen:", "tokens": ["Und", "vor\u00b7f\u00fch\u00b7ret", "mit", "Grund\u00b7ge\u00b7rech\u00b7ten", "Schl\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.74": {"line.1": {"text": "Es sey: da\u00df der verborgene Grund der Erden", "tokens": ["Es", "sey", ":", "da\u00df", "der", "ver\u00b7bor\u00b7ge\u00b7ne", "Grund", "der", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch den Me\u00df Stab erkundiget sol werden:", "tokens": ["Durch", "den", "Me\u00df", "Stab", "er\u00b7kun\u00b7di\u00b7get", "sol", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "VMFIN", "VAINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Und die Welt, die im Mittel noch sol stecken:", "tokens": ["Und", "die", "Welt", ",", "die", "im", "Mit\u00b7tel", "noch", "sol", "ste\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPRART", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Die der Fuldische Kircher wil erwecken,", "tokens": ["Die", "der", "Ful\u00b7di\u00b7sche", "Kir\u00b7cher", "wil", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Der die Ursachen kan vom Licht und Schatten,", "tokens": ["Der", "die", "Ur\u00b7sa\u00b7chen", "kan", "vom", "Licht", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VMFIN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und vom Z\u00fcgstein und Einklang uns erstatten.", "tokens": ["Und", "vom", "Z\u00fcgs\u00b7tein", "und", "Ein\u00b7klang", "uns", "er\u00b7stat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "KON", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.75": {"line.1": {"text": "Es sey: da\u00df das Geheimn\u00fcs in den Zahlen", "tokens": ["Es", "sey", ":", "da\u00df", "das", "Ge\u00b7heim\u00b7n\u00fcs", "in", "den", "Zah\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aus der Algebra uns sol \u00fcberstrahlen:", "tokens": ["Aus", "der", "Al\u00b7ge\u00b7bra", "uns", "sol", "\u00fc\u00b7bers\u00b7trah\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "PPER", "VMFIN", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und der Staub aus des Epicurus B\u00fcchern,", "tokens": ["Und", "der", "Staub", "aus", "des", "E\u00b7pi\u00b7cu\u00b7rus", "B\u00fc\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Den Gassendus so k\u00fcnstlich wei\u00df zu sichern.", "tokens": ["Den", "Gas\u00b7sen\u00b7dus", "so", "k\u00fcnst\u00b7lich", "wei\u00df", "zu", "si\u00b7chern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.76": {"line.1": {"text": "Es sey: da\u00df sie die Gottheit angeglommen,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "die", "Got\u00b7theit", "an\u00b7ge\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wie Paulus vom dritten Himmel kommen:", "tokens": ["Und", "wie", "Pau\u00b7lus", "vom", "drit\u00b7ten", "Him\u00b7mel", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und den Schl\u00fcssel zu den geheimen Gr\u00fcnden", "tokens": ["Und", "den", "Schl\u00fcs\u00b7sel", "zu", "den", "ge\u00b7hei\u00b7men", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--++-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "In dem Pathmoschen Offenbahrer finden:", "tokens": ["In", "dem", "Path\u00b7mo\u00b7schen", "Of\u00b7fen\u00b7bah\u00b7rer", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Welchen unter den vier und zwantzig Alten", "tokens": ["Wel\u00b7chen", "un\u00b7ter", "den", "vier", "und", "zwant\u00b7zig", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAT", "APPR", "ART", "CARD", "KON", "CARD", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Unser Mach\u00e6ropoeus wil erhalten.", "tokens": ["Un\u00b7ser", "Mach\u00e6ro\u00b7poeus", "wil", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.77": {"line.1": {"text": "Es sey: da\u00df sie Gericht und Recht verstehen,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "Ge\u00b7richt", "und", "Recht", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und nach Wissen und nach Gewissen gehen:", "tokens": ["Und", "nach", "Wis\u00b7sen", "und", "nach", "Ge\u00b7wis\u00b7sen", "ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Weder Schulen noch Kirchen in nichts trennen:", "tokens": ["We\u00b7der", "Schu\u00b7len", "noch", "Kir\u00b7chen", "in", "nichts", "tren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "NN", "APPR", "PIS", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Jedem seines /: Der Welt und Gott :/ zu nennen.", "tokens": ["Je\u00b7dem", "sei\u00b7nes", "/", ":", "Der", "Welt", "und", "Gott", ":/", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "emoticon", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "$(", "$.", "ART", "NN", "KON", "NN", "$(", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.78": {"line.1": {"text": "Es sey: da\u00df sie die Hand auf Artzney richten,", "tokens": ["Es", "sey", ":", "da\u00df", "sie", "die", "Hand", "auf", "Artz\u00b7ney", "rich\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und das Meisterthum in dem Glase schlichten:", "tokens": ["Und", "das", "Meis\u00b7ter\u00b7thum", "in", "dem", "Gla\u00b7se", "schlich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Und vom Ertzte, von Kra\u00fctern und von Thieren,", "tokens": ["Und", "vom", "Ertz\u00b7te", ",", "von", "Kr\u00b7a\u00fc\u00b7tern", "und", "von", "Thie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+-+--++-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Durch ihr Alkahest Geist und Wesen f\u00fchren,", "tokens": ["Durch", "ihr", "Al\u00b7ka\u00b7hest", "Geist", "und", "We\u00b7sen", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie Montanus das f\u00fcnffte von den Dingen", "tokens": ["Wie", "Mon\u00b7ta\u00b7nus", "das", "f\u00fcnff\u00b7te", "von", "den", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "ART", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Konte machen, und sich damit verj\u00fcngen.", "tokens": ["Kon\u00b7te", "ma\u00b7chen", ",", "und", "sich", "da\u00b7mit", "ver\u00b7j\u00fcn\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "KON", "PRF", "PAV", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.79": {"line.1": {"text": "Und was Hellas, was vor der Zeit zum minsten;", "tokens": ["Und", "was", "Hel\u00b7las", ",", "was", "vor", "der", "Zeit", "zum", "mins\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "$,", "PRELS", "APPR", "ART", "NN", "APPRART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Egyptier wust an weisen K\u00fcnsten:", "tokens": ["Der", "E\u00b7gyp\u00b7tier", "wust", "an", "wei\u00b7sen", "K\u00fcns\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und die Cabala uns bisher verhalten,", "tokens": ["Und", "die", "Ca\u00b7ba\u00b7la", "uns", "bis\u00b7her", "ver\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "ADV", "VVINF", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So von Engeln empfiengen unsre Alten:", "tokens": ["So", "von", "En\u00b7geln", "emp\u00b7fi\u00b7en\u00b7gen", "uns\u00b7re", "Al\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Es sey, da\u00df an des Deutschen Palmbaums Rinden", "tokens": ["Es", "sey", ",", "da\u00df", "an", "des", "Deut\u00b7schen", "Palm\u00b7baums", "Rin\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es gepr\u00e4get steht, oder sich wird finden.", "tokens": ["Es", "ge\u00b7pr\u00e4\u00b7get", "steht", ",", "o\u00b7der", "sich", "wird", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VVFIN", "$,", "KON", "PRF", "VAFIN", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.80": {"line.1": {"text": "Herr, nu unter so hochgepreisten Sachen,", "tokens": ["Herr", ",", "nu", "un\u00b7ter", "so", "hoch\u00b7ge\u00b7preis\u00b7ten", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die zum Deutschlande Deutschland ersten machen:", "tokens": ["Die", "zum", "Deutschlan\u00b7de", "Deutschland", "ers\u00b7ten", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "ADJA", "NN", "VVFIN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Unter kunstreichen Wercken, die dem Orden", "tokens": ["Un\u00b7ter", "kuns\u00b7trei\u00b7chen", "Wer\u00b7cken", ",", "die", "dem", "Or\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Der fruchtbringenden Ritterschafft sind worden:", "tokens": ["Der", "frucht\u00b7brin\u00b7gen\u00b7den", "Rit\u00b7ter\u00b7schafft", "sind", "wor\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VAPP", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.81": {"line.1": {"text": "Nehmet: weit von den wichtigen Gesch\u00e4fften,", "tokens": ["Neh\u00b7met", ":", "weit", "von", "den", "wich\u00b7ti\u00b7gen", "Ge\u00b7sch\u00e4ff\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die das F\u00fcrstliche Hertz an Sorgen hefften:", "tokens": ["Die", "das", "F\u00fcrst\u00b7li\u00b7che", "Hertz", "an", "Sor\u00b7gen", "heff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wie die Wolfarth der Deutschen zu versichern,", "tokens": ["Wie", "die", "Wolf\u00b7arth", "der", "Deut\u00b7schen", "zu", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Auf dem Reichstag an Waffen und an B\u00fcchern:", "tokens": ["Auf", "dem", "Reichs\u00b7tag", "an", "Waf\u00b7fen", "und", "an", "B\u00fc\u00b7chern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Auf dem Reichstag: auf dem das Wolvertrauen", "tokens": ["Auf", "dem", "Reichs\u00b7tag", ":", "auf", "dem", "das", "Wol\u00b7ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "APPR", "PRELS", "ART", "NN"], "meter": "--+-++-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "\u00dcber Deutschland wird von dem Himmel schauen.", "tokens": ["\u00dc\u00b7ber", "Deutschland", "wird", "von", "dem", "Him\u00b7mel", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.82": {"line.1": {"text": "Nehmet: Draus wir noch sehn das Feuer schrauben,", "tokens": ["Neh\u00b7met", ":", "Draus", "wir", "noch", "sehn", "das", "Feu\u00b7er", "schrau\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PAV", "PPER", "ADV", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Weit von Schlacht Schwerdtern, weit von Pickelhauben,", "tokens": ["Weit", "von", "Schlacht", "Schwerd\u00b7tern", ",", "weit", "von", "Pi\u00b7ckel\u00b7hau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Die der Deutsche Carl und dann, als sie schlugen,", "tokens": ["Die", "der", "Deut\u00b7sche", "Carl", "und", "dann", ",", "als", "sie", "schlu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NE", "KON", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wittikindus an Haubt und Fa\u00fcsten trugen,", "tokens": ["Wit\u00b7ti\u00b7kin\u00b7dus", "an", "Haubt", "und", "Fa\u00fcs\u00b7ten", "tru\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und zur Erbschafft verliessen, wie sie lauten,", "tokens": ["Und", "zur", "Erb\u00b7schafft", "ver\u00b7lies\u00b7sen", ",", "wie", "sie", "lau\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Dessen Enckeln gekr\u00f6nt mir gr\u00fcner Rauten.", "tokens": ["Des\u00b7sen", "En\u00b7ckeln", "ge\u00b7kr\u00f6nt", "mir", "gr\u00fc\u00b7ner", "Rau\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVPP", "PPER", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.83": {"line.1": {"text": "Nehmet: weit sag ich von dem frommen Sorgen,", "tokens": ["Neh\u00b7met", ":", "weit", "sag", "ich", "von", "dem", "from\u00b7men", "Sor\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ADJD", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+----+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "So die Sonne zu Abend und zu Morgen", "tokens": ["So", "die", "Son\u00b7ne", "zu", "A\u00b7bend", "und", "zu", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Vor die Kirche, vor euer Land und Leute,", "tokens": ["Vor", "die", "Kir\u00b7che", ",", "vor", "eu\u00b7er", "Land", "und", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Euch zutheilet als eures Standes Beute.", "tokens": ["Euch", "zu\u00b7thei\u00b7let", "als", "eu\u00b7res", "Stan\u00b7des", "Beu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.84": {"line.1": {"text": "Wann ein Lang \u00d6rchen unterm raschen Hetzen", "tokens": ["Wann", "ein", "Lang", "\u00d6r\u00b7chen", "un\u00b7term", "ra\u00b7schen", "Het\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das erlauchte Gem\u00fcthe wird erg\u00f6tzen:", "tokens": ["Das", "er\u00b7lauch\u00b7te", "Ge\u00b7m\u00fc\u00b7the", "wird", "er\u00b7g\u00f6t\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wann ein Schwartz- oder Roth-Wild unterm Sterben", "tokens": ["Wann", "ein", "Schwartz", "o\u00b7der", "Ro\u00b7th\u00b7Wild", "un\u00b7term", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "TRUNC", "KON", "NN", "APPRART", "NN"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wird das theilende Weide Messer f\u00e4rben:", "tokens": ["Wird", "das", "thei\u00b7len\u00b7de", "Wei\u00b7de", "Mes\u00b7ser", "f\u00e4r\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.85": {"line.1": {"text": "Wann die Zwiebeln von so viel bunten Arten", "tokens": ["Wann", "die", "Zwie\u00b7beln", "von", "so", "viel", "bun\u00b7ten", "Ar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ADV", "PIAT", "ADJA", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie die Tulipen mahlen in dem Garten,", "tokens": ["Sie", "die", "Tu\u00b7li\u00b7pen", "mah\u00b7len", "in", "dem", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und Carnarische Zei\u00dfgen untern Zweigen", "tokens": ["Und", "Car\u00b7na\u00b7ri\u00b7sche", "Zei\u00df\u00b7gen", "un\u00b7tern", "Zwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das Gesicht und Geh\u00f6r werden neigen:", "tokens": ["Das", "Ge\u00b7sicht", "und", "Ge\u00b7h\u00f6r", "wer\u00b7den", "nei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAINF", "VVFIN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.86": {"line.1": {"text": "Hertzog, wann die gelehrten Eitelkeiten", "tokens": ["Hert\u00b7zog", ",", "wann", "die", "ge\u00b7lehr\u00b7ten", "Ei\u00b7tel\u00b7kei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach der Taffel euch eine Lust bereiten,", "tokens": ["Nach", "der", "Taf\u00b7fel", "euch", "ei\u00b7ne", "Lust", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und der Traurigkeit suchen zu entladen:", "tokens": ["Und", "der", "Trau\u00b7rig\u00b7keit", "su\u00b7chen", "zu", "ent\u00b7la\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Alsdenn Nehmet die Schlu\u00df-Reim an in Gnaden.", "tokens": ["Als\u00b7denn", "Neh\u00b7met", "die", "Schlu\u00df\u00b7Reim", "an", "in", "Gna\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.87": {"line.1": {"text": "Sie sind: Alle setz ich daf\u00fcr zu Pfande:", "tokens": ["Sie", "sind", ":", "Al\u00b7le", "setz", "ich", "da\u00b7f\u00fcr", "zu", "Pfan\u00b7de", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "PIS", "VVFIN", "PPER", "PAV", "APPR", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Kurtz an Worten, lang aber am Verstande,", "tokens": ["Kurtz", "an", "Wor\u00b7ten", ",", "lang", "a\u00b7ber", "am", "Ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "ADJD", "ADV", "APPRART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Herb an Wurtzeln, s\u00fc\u00df aber an den Keimen,", "tokens": ["Herb", "an", "Wurt\u00b7zeln", ",", "s\u00fc\u00df", "a\u00b7ber", "an", "den", "Kei\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Schwer an Lehren, leicht aber an den Reimen.", "tokens": ["Schwer", "an", "Leh\u00b7ren", ",", "leicht", "a\u00b7ber", "an", "den", "Rei\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.88": {"line.1": {"text": "Kurtz: man kan sie bald nehmen, bald hinlegen:", "tokens": ["Kurtz", ":", "man", "kan", "sie", "bald", "neh\u00b7men", ",", "bald", "hin\u00b7le\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$.", "PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lang: man sol sie stets lesen, stets erwegen:", "tokens": ["Lang", ":", "man", "sol", "sie", "stets", "le\u00b7sen", ",", "stets", "er\u00b7we\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VMFIN", "PPER", "ADV", "VVINF", "$,", "ADV", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Herbe: wer sie wil nach den Worten setzen:", "tokens": ["Her\u00b7be", ":", "wer", "sie", "wil", "nach", "den", "Wor\u00b7ten", "set\u00b7zen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "S\u00fcsse: wer sie kan nach dem Geiste sch\u00e4tzen:", "tokens": ["S\u00fcs\u00b7se", ":", "wer", "sie", "kan", "nach", "dem", "Geis\u00b7te", "sch\u00e4t\u00b7zen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "PPER", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Schwer: ein ieder sol nach den Lehren leben:", "tokens": ["Schwer", ":", "ein", "ie\u00b7der", "sol", "nach", "den", "Leh\u00b7ren", "le\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ART", "PIS", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Leicht: ein ieder darff sich blo\u00df Gott ergeben.", "tokens": ["Leicht", ":", "ein", "ie\u00b7der", "darff", "sich", "blo\u00df", "Gott", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "PIS", "VMFIN", "PRF", "ADV", "NN", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.89": {"line.1": {"text": "Statt der leutseeligen Erg\u00f6tzlichkeiten:", "tokens": ["Statt", "der", "leut\u00b7see\u00b7li\u00b7gen", "Er\u00b7g\u00f6tz\u00b7lich\u00b7kei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Statt der kargen Vergessenheit der Zeiten:", "tokens": ["Statt", "der", "kar\u00b7gen", "Ver\u00b7ges\u00b7sen\u00b7heit", "der", "Zei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Statt der fleissigen M\u00fcssigg\u00e4ng und Wesen:", "tokens": ["Statt", "der", "fleis\u00b7si\u00b7gen", "M\u00fcs\u00b7sig\u00b7g\u00e4ng", "und", "We\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sind die Reime zwar aufgesetzt zu lesen.", "tokens": ["Sind", "die", "Rei\u00b7me", "zwar", "auf\u00b7ge\u00b7setzt", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.90": {"line.1": {"text": "Aber: Er: wann er gl\u00fcht von Abendtheuern,", "tokens": ["A\u00b7ber", ":", "Er", ":", "wann", "er", "gl\u00fcht", "von", "A\u00b7bendt\u00b7heu\u00b7ern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "PPER", "$.", "PWAV", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Die sein hitziges Hertz und Haubt durchfeuern:", "tokens": ["Die", "sein", "hit\u00b7zi\u00b7ges", "Hertz", "und", "Haubt", "durch\u00b7feu\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wann die G\u00f6ttliche Regung reitzt die Sinnen,", "tokens": ["Wann", "die", "G\u00f6tt\u00b7li\u00b7che", "Re\u00b7gung", "reitzt", "die", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Mag der Tichter die Schlu\u00df Reim auch beginnen:", "tokens": ["Mag", "der", "Tich\u00b7ter", "die", "Schlu\u00df", "Reim", "auch", "be\u00b7gin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Er sol leben viel eh, als Reimen lernen,", "tokens": ["Er", "sol", "le\u00b7ben", "viel", "eh", ",", "als", "Rei\u00b7men", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "ADV", "KOUS", "$,", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Nicht nach Schaalen sich sehnen, sondern Kernen.", "tokens": ["Nicht", "nach", "Schaa\u00b7len", "sich", "seh\u00b7nen", ",", "son\u00b7dern", "Ker\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "PRF", "VVINF", "$,", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.91": {"line.1": {"text": "Er: wann Er: und was Er? wann sie vor Andern", "tokens": ["Er", ":", "wann", "Er", ":", "und", "was", "Er", "?", "wann", "sie", "vor", "An\u00b7dern"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$.", "PWAV", "PPER", "$.", "KON", "PWS", "PPER", "$.", "PWAV", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Cunitia wird auf Sternen wandern,", "tokens": ["Die", "Cu\u00b7ni\u00b7tia", "wird", "auf", "Ster\u00b7nen", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und den Ticho de Brahe \u00fcbersteigen,", "tokens": ["Und", "den", "Ti\u00b7cho", "de", "Bra\u00b7he", "\u00fc\u00b7bers\u00b7tei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "NE", "NE", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Mag ihr Antlitz sie auf die Staffel neigen.", "tokens": ["Mag", "ihr", "Ant\u00b7litz", "sie", "auf", "die", "Staf\u00b7fel", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Was sol jene thun? Es zeigt andre Wonne", "tokens": ["Was", "sol", "je\u00b7ne", "thun", "?", "Es", "zeigt", "and\u00b7re", "Won\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PDS", "VVINF", "$.", "PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Die am Creutzes Stamm angezweckte Sonne.", "tokens": ["Die", "am", "Creut\u00b7zes", "Stamm", "an\u00b7ge\u00b7zweck\u00b7te", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.92": {"line.1": {"text": "Er: wann er durch das Fern Glas auf den H\u00f6hen", "tokens": ["Er", ":", "wann", "er", "durch", "das", "Fern", "Glas", "auf", "den", "H\u00f6\u00b7hen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$.", "PWAV", "PPER", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In die Sterne des Himmels sucht zu gehen,", "tokens": ["In", "die", "Ster\u00b7ne", "des", "Him\u00b7mels", "sucht", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die Raumstadt, ein Reich von keinen Gr\u00e4ntzen", "tokens": ["Und", "die", "Raum\u00b7stadt", ",", "ein", "Reich", "von", "kei\u00b7nen", "Gr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "In Gesicht und Gem\u00fcthe siehet gl\u00e4ntzen;", "tokens": ["In", "Ge\u00b7sicht", "und", "Ge\u00b7m\u00fc\u00b7the", "sie\u00b7het", "gl\u00e4nt\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Mag die Reime, durchf\u00e4rbt von Wonn und Wesen", "tokens": ["Mag", "die", "Rei\u00b7me", ",", "durch\u00b7f\u00e4rbt", "von", "Wonn", "und", "We\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "$,", "VVFIN", "APPR", "NE", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Der Beschauer der Wunder Gottes lesen:", "tokens": ["Der", "Be\u00b7schau\u00b7er", "der", "Wun\u00b7der", "Got\u00b7tes", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Er kan inner sich Gott: in Gott die Sachen", "tokens": ["Er", "kan", "in\u00b7ner", "sich", "Gott", ":", "in", "Gott", "die", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "PRF", "NN", "$.", "APPR", "NN", "ART", "NN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.8": {"text": "Ihm bekannter als Galil\u00e6us machen.", "tokens": ["Ihm", "be\u00b7kann\u00b7ter", "als", "Ga\u00b7lil\u00e6us", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KOKOM", "NE", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.93": {"line.1": {"text": "Er: wann er mit dem Bley und Winckel-Eysen", "tokens": ["Er", ":", "wann", "er", "mit", "dem", "Bley", "und", "Win\u00b7ckel\u00b7Ey\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$.", "PWAV", "PPER", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wil vom Nordstern an bis zum Creutze reisen,", "tokens": ["Wil", "vom", "Nords\u00b7tern", "an", "bis", "zum", "Creut\u00b7ze", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "APPR", "APPR", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Und die Ruhstatt der schriemen Nabe sehen,", "tokens": ["Und", "die", "Ruh\u00b7statt", "der", "schrie\u00b7men", "Na\u00b7be", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Mit dem Fusse da stehn: die Welt umdrehen:", "tokens": ["Mit", "dem", "Fus\u00b7se", "da", "stehn", ":", "die", "Welt", "um\u00b7dre\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF", "$.", "ART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Welche ein Archimedes kont erfragen,", "tokens": ["Wel\u00b7che", "ein", "Ar\u00b7chi\u00b7me\u00b7des", "kont", "er\u00b7fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+--+---+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Mag der Feld Me\u00dfer auch das Buch aufschlagen:", "tokens": ["Mag", "der", "Feld", "Me\u00b7\u00dfer", "auch", "das", "Buch", "auf\u00b7schla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Das Wort Gottes das h\u00e4lt die beyden Schrauben,", "tokens": ["Das", "Wort", "Got\u00b7tes", "das", "h\u00e4lt", "die", "bey\u00b7den", "Schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PDS", "VVFIN", "ART", "PIAT", "NN", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Das ergr\u00fcndet kein Dreyeck, sondern Glauben.", "tokens": ["Das", "er\u00b7gr\u00fcn\u00b7det", "kein", "Drey\u00b7eck", ",", "son\u00b7dern", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIAT", "NN", "$,", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.94": {"line.1": {"text": "Er: wann er wil die Zahl auf Bl\u00e4tter schreiben,", "tokens": ["Er", ":", "wann", "er", "wil", "die", "Zahl", "auf", "Bl\u00e4t\u00b7ter", "schrei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und bezifferte Zaubereyen treiben:", "tokens": ["Und", "be\u00b7zif\u00b7fer\u00b7te", "Zau\u00b7be\u00b7re\u00b7yen", "trei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wann er grossen Verstand daraus wird haben,", "tokens": ["Wann", "er", "gros\u00b7sen", "Ver\u00b7stand", "da\u00b7raus", "wird", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJA", "NN", "PAV", "VAFIN", "VAINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Weil das Ende der Welt Gott drein gegraben:", "tokens": ["Weil", "das", "En\u00b7de", "der", "Welt", "Gott", "drein", "ge\u00b7gra\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "NN", "ADV", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Das Johannes und Daniel erwehlen:", "tokens": ["Das", "Jo\u00b7han\u00b7nes", "und", "Da\u00b7ni\u00b7el", "er\u00b7weh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "NE", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Mag der Rechmeister auch die Schl\u00fcsse zehlen:", "tokens": ["Mag", "der", "Rech\u00b7meis\u00b7ter", "auch", "die", "Schl\u00fcs\u00b7se", "zeh\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wer die Raitung der Welt, wie sie, wil schl\u00fcssen,", "tokens": ["Wer", "die", "Rai\u00b7tung", "der", "Welt", ",", "wie", "sie", ",", "wil", "schl\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NN", "$,", "PWAV", "PPER", "$,", "VMFIN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Mu\u00df auch Ihr Einmal Eins im Geiste wissen.", "tokens": ["Mu\u00df", "auch", "Ihr", "Ein\u00b7mal", "Eins", "im", "Geis\u00b7te", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "ADV", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.95": {"line.1": {"text": "Er: wann er wird in Gottes Willen stehen,", "tokens": ["Er", ":", "wann", "er", "wird", "in", "Got\u00b7tes", "Wil\u00b7len", "ste\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VAFIN", "APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und des Glaubens Krafft in dem Geist erh\u00f6hen:", "tokens": ["Und", "des", "Glau\u00b7bens", "Krafft", "in", "dem", "Geist", "er\u00b7h\u00f6\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wann der Geist das Licht wird schaun in dem Lichte,", "tokens": ["Wann", "der", "Geist", "das", "Licht", "wird", "schaun", "in", "dem", "Lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VAFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und Gott selbst von Gesichte zu Gesichte:", "tokens": ["Und", "Gott", "selbst", "von", "Ge\u00b7sich\u00b7te", "zu", "Ge\u00b7sich\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wann in Gottes Bild ihn das Schaun wird setzen,", "tokens": ["Wann", "in", "Got\u00b7tes", "Bild", "ihn", "das", "Schaun", "wird", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "NN", "PPER", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hertz und Lehrstuhl erf\u00fclln mit reichen Sch\u00e4tzen:", "tokens": ["Hertz", "und", "Lehr\u00b7stuhl", "er\u00b7f\u00fclln", "mit", "rei\u00b7chen", "Sch\u00e4t\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Mag der Geistliche singen ohn Versehren", "tokens": ["Mag", "der", "Geist\u00b7li\u00b7che", "sin\u00b7gen", "ohn", "Ver\u00b7seh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "VVFIN", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Auch dem Sterbenden diese weise Lehren.", "tokens": ["Auch", "dem", "Ster\u00b7ben\u00b7den", "die\u00b7se", "wei\u00b7se", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PDAT", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Nicht sein, sondern das Wort sol er erheben,", "tokens": ["Nicht", "sein", ",", "son\u00b7dern", "das", "Wort", "sol", "er", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAINF", "$,", "KON", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Das im Buchstaben todt, im Geiste ist Leben.", "tokens": ["Das", "im", "Buch\u00b7sta\u00b7ben", "todt", ",", "im", "Geis\u00b7te", "ist", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "ADJD", "$,", "APPRART", "NN", "VAFIN", "NN", "$."], "meter": "---+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.96": {"line.1": {"text": "Er: wann er wird das Recht den Kl\u00e4gern sprechen,", "tokens": ["Er", ":", "wann", "er", "wird", "das", "Recht", "den", "Kl\u00e4\u00b7gern", "spre\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und den Stab \u00fcber \u00dcbelth\u00e4ter brechen:", "tokens": ["Und", "den", "Stab", "\u00fc\u00b7ber", "\u00dc\u00b7belt\u00b7h\u00e4\u00b7ter", "bre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "--++-+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Schwerd und Wage befreyt von Blut und Gaben", "tokens": ["Schwerd", "und", "Wa\u00b7ge", "be\u00b7freyt", "von", "Blut", "und", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVPP", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Dem Gecreutzigten eingeh\u00e4ndiget haben:", "tokens": ["Dem", "Ge\u00b7cr\u00b7eut\u00b7zig\u00b7ten", "ein\u00b7ge\u00b7h\u00e4n\u00b7di\u00b7get", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Und sein End Urtheil Christlich \u00fcberlegen,", "tokens": ["Und", "sein", "End", "Ur\u00b7theil", "Christ\u00b7lich", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mag der Richter die Zwey-Reim auch erwegen:", "tokens": ["Mag", "der", "Rich\u00b7ter", "die", "Zwey\u00b7Reim", "auch", "er\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Wie er Menschen, so wird Gott auch Ihn richten,", "tokens": ["Wie", "er", "Men\u00b7schen", ",", "so", "wird", "Gott", "auch", "Ihn", "rich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "$,", "ADV", "VAFIN", "NN", "ADV", "PPER", "VVINF", "$,"], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und so seine Sache, als er ihre schlichten.", "tokens": ["Und", "so", "sei\u00b7ne", "Sa\u00b7che", ",", "als", "er", "ih\u00b7re", "schlich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.97": {"line.1": {"text": "Er: wann er wird das Ertz-Saltz \u00fcberkochen,", "tokens": ["Er", ":", "wann", "er", "wird", "das", "Ertz\u00b7Saltz", "\u00fc\u00b7ber\u00b7ko\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PWAV", "PPER", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und den ersten Zeug aller Dinge suchen,", "tokens": ["Und", "den", "ers\u00b7ten", "Zeug", "al\u00b7ler", "Din\u00b7ge", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PIAT", "NN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wird den felsichten Rauch im Glase sperren:", "tokens": ["Wird", "den", "fel\u00b7sich\u00b7ten", "Rauch", "im", "Gla\u00b7se", "sper\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und die f\u00e4rbende Krafft des Wassers d\u00f6rren:", "tokens": ["Und", "die", "f\u00e4r\u00b7ben\u00b7de", "Krafft", "des", "Was\u00b7sers", "d\u00f6r\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Wird den Raph\u00e4el an dem Theil erheben,", "tokens": ["Wird", "den", "Ra\u00b7ph\u00e4\u00b7el", "an", "dem", "Theil", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den mein Franckenberg an das Licht gegeben:", "tokens": ["Den", "mein", "Fran\u00b7cken\u00b7berg", "an", "das", "Licht", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Und die Gabe des H\u00f6chsten dr\u00fcber preisen,", "tokens": ["Und", "die", "Ga\u00b7be", "des", "H\u00f6chs\u00b7ten", "dr\u00fc\u00b7ber", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "PAV", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Mag der Artzt die Gedicht auch Krancken weisen:", "tokens": ["Mag", "der", "Artzt", "die", "Ge\u00b7dicht", "auch", "Kran\u00b7cken", "wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "ADV", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Er sol sich vor erforschen, drauff die Erde.", "tokens": ["Er", "sol", "sich", "vor", "er\u00b7for\u00b7schen", ",", "drauff", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "VVINF", "$,", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ihm vor selber genung thun, drauff dem Heerde.", "tokens": ["Ihm", "vor", "sel\u00b7ber", "ge\u00b7nung", "thun", ",", "drauff", "dem", "Heer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADV", "ADV", "VVINF", "$,", "PAV", "ART", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.98": {"line.1": {"text": "Auch, die \u00fcber des Nilus R\u00e4tzel rathen,", "tokens": ["Auch", ",", "die", "\u00fc\u00b7ber", "des", "Ni\u00b7lus", "R\u00e4t\u00b7zel", "ra\u00b7then", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "APPR", "ART", "NE", "NN", "VVFIN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und die Wunderschrifft dieser Welt erstatten,", "tokens": ["Und", "die", "Wun\u00b7der\u00b7schrifft", "die\u00b7ser", "Welt", "er\u00b7stat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PDAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die die Buchstaben vom Gew\u00fcrm und Thieren", "tokens": ["Die", "die", "Buch\u00b7sta\u00b7ben", "vom", "Ge\u00b7w\u00fcrm", "und", "Thie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Itzt aus der Pharaonschen Mund Art f\u00fchren.", "tokens": ["Itzt", "aus", "der", "Pha\u00b7raon\u00b7schen", "Mund", "Art", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und die Wissenschafft von geheimen Dingen", "tokens": ["Und", "die", "Wis\u00b7sen\u00b7schafft", "von", "ge\u00b7hei\u00b7men", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Durch den Oedipus aus Egypten bringen.", "tokens": ["Durch", "den", "O\u00b7e\u00b7di\u00b7pus", "aus", "E\u00b7gyp\u00b7ten", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.99": {"line.1": {"text": "Auch, die spannen auf Orpheus seine Saiten,", "tokens": ["Auch", ",", "die", "span\u00b7nen", "auf", "Or\u00b7pheus", "sei\u00b7ne", "Sai\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "VVFIN", "APPR", "NE", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und der Griechischen Argo Lauff begleiten,", "tokens": ["Und", "der", "Grie\u00b7chi\u00b7schen", "Ar\u00b7go", "Lauff", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Die das goldene Fell beym Jason ehren,", "tokens": ["Die", "das", "gol\u00b7de\u00b7ne", "Fell", "beym", "Ja\u00b7son", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und das Meisterthum dieser Schiffarth lehren:", "tokens": ["Und", "das", "Meis\u00b7ter\u00b7thum", "die\u00b7ser", "Schiff\u00b7arth", "leh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PDAT", "NN", "VVINF", "$."], "meter": "--+----+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Die den Hertzens Grund der Natur aufschrauben,", "tokens": ["Die", "den", "Hert\u00b7zens", "Grund", "der", "Na\u00b7tur", "auf\u00b7schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "ART", "NN", "VVIZU", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und uns heissen der Kunst nicht Glauben glauben:", "tokens": ["Und", "uns", "heis\u00b7sen", "der", "Kunst", "nicht", "Glau\u00b7ben", "glau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PTKNEG", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.100": {"line.1": {"text": "Auch die, weil sie Gott so inbr\u00fcnstig lieben,", "tokens": ["Auch", "die", ",", "weil", "sie", "Gott", "so", "in\u00b7br\u00fcns\u00b7tig", "lie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "KOUS", "PPER", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In der Engel Gesellschafft sind geschrieben:", "tokens": ["In", "der", "En\u00b7gel", "Ge\u00b7sell\u00b7schafft", "sind", "ge\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die Wahrheit, und voller Zuvertrauen", "tokens": ["Und", "die", "Wahr\u00b7heit", ",", "und", "vol\u00b7ler", "Zu\u00b7ver\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "KON", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Die Selbst\u00e4ndigkeit aller Dinge schauen:", "tokens": ["Die", "Selb\u00b7st\u00e4n\u00b7dig\u00b7keit", "al\u00b7ler", "Din\u00b7ge", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Und die Wei\u00dfheit, weit \u00fcber Welt und Sternen", "tokens": ["Und", "die", "Wei\u00df\u00b7heit", ",", "weit", "\u00fc\u00b7ber", "Welt", "und", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "APPR", "NN", "KON", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Hier aus Mercava, dort aus Bresith lernen.", "tokens": ["Hier", "aus", "Mer\u00b7ca\u00b7va", ",", "dort", "aus", "Bre\u00b7sith", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.101": {"line.1": {"text": "Alle diese, wann sie die Spr\u00fcche mercken,", "tokens": ["Al\u00b7le", "die\u00b7se", ",", "wann", "sie", "die", "Spr\u00fc\u00b7che", "mer\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PDS", "$,", "PWAV", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Werden ihre Gewerbschafft etwas st\u00e4rcken.", "tokens": ["Wer\u00b7den", "ih\u00b7re", "Ge\u00b7werb\u00b7schafft", "et\u00b7was", "st\u00e4r\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Was ein Priester der Isis h\u00e4lt verborgen,", "tokens": ["Was", "ein", "Pries\u00b7ter", "der", "I\u00b7sis", "h\u00e4lt", "ver\u00b7bor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ART", "NE", "VVFIN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Was ein Argonaut eingeschifft voll Sorgen:", "tokens": ["Was", "ein", "Ar\u00b7go\u00b7naut", "ein\u00b7ge\u00b7schifft", "voll", "Sor\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was beschauen die wahren Cabalisten:", "tokens": ["Was", "be\u00b7schau\u00b7en", "die", "wah\u00b7ren", "Ca\u00b7ba\u00b7lis\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Was erglauben die Gotts gelehrte Christen.", "tokens": ["Was", "er\u00b7glau\u00b7ben", "die", "Gotts", "ge\u00b7lehr\u00b7te", "Chris\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.102": {"line.1": {"text": "Das ist sonder Berg in uns angeloffen,", "tokens": ["Das", "ist", "son\u00b7der", "Berg", "in", "uns", "an\u00b7ge\u00b7lof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das ist sonder Sorg in uns zu erhoffen:", "tokens": ["Das", "ist", "son\u00b7der", "Sorg", "in", "uns", "zu", "er\u00b7hof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das wird wol beschaut und zugleich umbschlossen:", "tokens": ["Das", "wird", "wol", "be\u00b7schaut", "und", "zu\u00b7gleich", "umbsc\u00b7hlos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KON", "ADV", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das wird wol erglaubt, und zugleich genossen:", "tokens": ["Das", "wird", "wol", "er\u00b7glaubt", ",", "und", "zu\u00b7gleich", "ge\u00b7nos\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,", "KON", "ADV", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wo auf Worte nicht, sondern Acht auf Leben,", "tokens": ["Wo", "auf", "Wor\u00b7te", "nicht", ",", "son\u00b7dern", "Acht", "auf", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "PTKNEG", "$,", "KON", "CARD", "APPR", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Nicht auf Lehre wird, sondern Geist gegeben.", "tokens": ["Nicht", "auf", "Leh\u00b7re", "wird", ",", "son\u00b7dern", "Geist", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "VAFIN", "$,", "KON", "NN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Geist und Leben kan Wort und Lehre f\u00e4rben,", "tokens": ["Geist", "und", "Le\u00b7ben", "kan", "Wort", "und", "Leh\u00b7re", "f\u00e4r\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Und die Farbe behalten, wann wir sterben:", "tokens": ["Und", "die", "Far\u00b7be", "be\u00b7hal\u00b7ten", ",", "wann", "wir", "ster\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Und dis such ich der Ritterschafft im Guten", "tokens": ["Und", "dis", "such", "ich", "der", "Rit\u00b7ter\u00b7schafft", "im", "Gu\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Des Fruchtbringenden Palmbaums zu zumuthen:", "tokens": ["Des", "Frucht\u00b7brin\u00b7gen\u00b7den", "Palm\u00b7baums", "zu", "zu\u00b7mut\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}}, "stanza.103": {"line.1": {"text": "Aber: ist es erlaubet meinen Musen,", "tokens": ["A\u00b7ber", ":", "ist", "es", "er\u00b7lau\u00b7bet", "mei\u00b7nen", "Mu\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "VAFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die der Schreck-Schild besch\u00fctzet von Medusen:", "tokens": ["Die", "der", "Schreck\u00b7Schild", "be\u00b7sch\u00fct\u00b7zet", "von", "Me\u00b7du\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und ich, darff ich vor das Gesichte treten,", "tokens": ["Und", "ich", ",", "darff", "ich", "vor", "das", "Ge\u00b7sich\u00b7te", "tre\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Welches Mavors und Pallas selbst anbeten:", "tokens": ["Wel\u00b7ches", "Ma\u00b7vors", "und", "Pal\u00b7las", "selbst", "an\u00b7be\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "KON", "NN", "ADV", "VVINF", "$."], "meter": "+--+-++-+--", "measure": "iambic.penta.invert"}, "line.5": {"text": "Hertzog: so sag ich /:aber gantz bescheiden:/", "tokens": ["Hert\u00b7zog", ":", "so", "sag", "ich", "/", ":", "a\u00b7ber", "gantz", "be\u00b7schei\u00b7den", ":/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "emoticon"], "pos": ["NE", "$.", "ADV", "VVFIN", "PPER", "$(", "$.", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "F\u00fcrsten m\u00f6gen die Vers auch umb sich leiden.", "tokens": ["F\u00fcrs\u00b7ten", "m\u00f6\u00b7gen", "die", "Vers", "auch", "umb", "sich", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "NN", "ADV", "APPR", "PRF", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.104": {"line.1": {"text": "Ob sie setzen, so wol was ihr Geschlechte,", "tokens": ["Ob", "sie", "set\u00b7zen", ",", "so", "wol", "was", "ihr", "Ge\u00b7schlech\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$,", "ADV", "ADV", "PWS", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Als das R\u00f6mische Reich betrifft zu Rechte:", "tokens": ["Als", "das", "R\u00f6\u00b7mi\u00b7sche", "Reich", "be\u00b7tr\u00b7ifft", "zu", "Rech\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die Schwerdter vor beyder Freyheit schwingen,", "tokens": ["Und", "die", "Schwerd\u00b7ter", "vor", "bey\u00b7der", "Frey\u00b7heit", "schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Auf die Hand Pferd erhitzt in Harnschen springen:", "tokens": ["Auf", "die", "Hand", "Pferd", "er\u00b7hitzt", "in", "Harn\u00b7schen", "sprin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und den Adler, und auf des Adlers Br\u00fcsten", "tokens": ["Und", "den", "Ad\u00b7ler", ",", "und", "auf", "des", "Ad\u00b7lers", "Br\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Das Burgundische Creutz, als Deutsch und Christen:", "tokens": ["Das", "Bur\u00b7gun\u00b7di\u00b7sche", "Creutz", ",", "als", "Deutsch", "und", "Chris\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vor den T\u00fcrcken und Gottes Feinden sch\u00fctzen:", "tokens": ["Vor", "den", "T\u00fcr\u00b7cken", "und", "Got\u00b7tes", "Fein\u00b7den", "sch\u00fct\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Zu Gericht und zu Pferd in einem sitzen.", "tokens": ["Zu", "Ge\u00b7richt", "und", "zu", "Pferd", "in", "ei\u00b7nem", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Da\u00df das Kayserthum alle Welt erkenne,", "tokens": ["Da\u00df", "das", "Kay\u00b7ser\u00b7thum", "al\u00b7le", "Welt", "er\u00b7ken\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Und es beydes gerecht und sieghafft nenne.", "tokens": ["Und", "es", "bey\u00b7des", "ge\u00b7recht", "und", "sieg\u00b7hafft", "nen\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PIS", "ADJD", "KON", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.105": {"line.1": {"text": "Ob sie setzen die Krafft von ihrem Stande", "tokens": ["Ob", "sie", "set\u00b7zen", "die", "Krafft", "von", "ih\u00b7rem", "Stan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Deutscher Freyheit und ernster Zucht zu Pfande:", "tokens": ["Deut\u00b7scher", "Frey\u00b7heit", "und", "erns\u00b7ter", "Zucht", "zu", "Pfan\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "APPR", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Wann die starren Gerippe grauser Ahnen", "tokens": ["Wann", "die", "star\u00b7ren", "Ge\u00b7rip\u00b7pe", "grau\u00b7ser", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Sie zur eysernen Tapfferkeit ermahnen:", "tokens": ["Sie", "zur", "ey\u00b7ser\u00b7nen", "Tapf\u00b7fer\u00b7keit", "er\u00b7mah\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "So auf Wallst\u00e4ten stehn, und aufrecht sterben,", "tokens": ["So", "auf", "Wall\u00b7st\u00e4\u00b7ten", "stehn", ",", "und", "auf\u00b7recht", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "$,", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und im Tode Befehl thun. Folgt ihr Erben!", "tokens": ["Und", "im", "To\u00b7de", "Be\u00b7fehl", "thun", ".", "Folgt", "ihr", "Er\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "NN", "VVINF", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Wie den Wittikind: wie vor grauen Zeiten", "tokens": ["Wie", "den", "Wit\u00b7ti\u00b7kind", ":", "wie", "vor", "grau\u00b7en", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "$.", "KOKOM", "APPR", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Unsern Herrmann sein Westphaln sahn streiten;", "tokens": ["Un\u00b7sern", "Herr\u00b7mann", "sein", "West\u00b7phaln", "sahn", "strei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN", "VVFIN", "VVFIN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Der den Varus schlug, da\u00df vor solchem Putzen", "tokens": ["Der", "den", "Va\u00b7rus", "schlug", ",", "da\u00df", "vor", "sol\u00b7chem", "Put\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NE", "VVFIN", "$,", "KOUS", "APPR", "PIAT", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.10": {"text": "Mit den Mauern der Kayser wolte stutzen.", "tokens": ["Mit", "den", "Mau\u00b7ern", "der", "Kay\u00b7ser", "wol\u00b7te", "stut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.106": {"line.1": {"text": "Ob sie setzen das Grundrecht der Gemeine", "tokens": ["Ob", "sie", "set\u00b7zen", "das", "Grund\u00b7recht", "der", "Ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und des Gottesdiensts zu dem Angelsteine:", "tokens": ["Und", "des", "Got\u00b7tes\u00b7diensts", "zu", "dem", "An\u00b7gel\u00b7stei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Drauf der M\u00fcnster- und Osnabr\u00fcgsche Frieden", "tokens": ["Drauf", "der", "M\u00fcns\u00b7ter", "und", "Os\u00b7na\u00b7br\u00fcg\u00b7sche", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Eingemauert steht: Von Gefahr geschieden:", "tokens": ["Ein\u00b7ge\u00b7mau\u00b7ert", "steht", ":", "Von", "Ge\u00b7fahr", "ge\u00b7schie\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$.", "APPR", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und mit B\u00fcndn\u00fcssen ihre Ruh verst\u00e4rcken,", "tokens": ["Und", "mit", "B\u00fcnd\u00b7n\u00fcs\u00b7sen", "ih\u00b7re", "Ruh", "ver\u00b7st\u00e4r\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Vor der Liebe des Volcks kein be\u00dfres mercken.", "tokens": ["Vor", "der", "Lie\u00b7be", "des", "Volcks", "kein", "be\u00df\u00b7res", "mer\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PIAT", "ADJA", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.107": {"line.1": {"text": "Ob sie d\u00e4mpffen die stoltzen Feder Kielen", "tokens": ["Ob", "sie", "d\u00e4mpf\u00b7fen", "die", "stolt\u00b7zen", "Fe\u00b7der", "Kie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Auf den Lehrst\u00e4ten, auf den Dreyfu\u00df St\u00fchlen,", "tokens": ["Auf", "den", "Lehr\u00b7st\u00e4\u00b7ten", ",", "auf", "den", "Drey\u00b7fu\u00df", "St\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die den Gottesdienst und die Freyheit st\u00f6ren,", "tokens": ["Die", "den", "Got\u00b7tes\u00b7dienst", "und", "die", "Frey\u00b7heit", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "KON", "ART", "NN", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Durch ihr Dintenfa\u00df Blutstr\u00f6m in uns r\u00f6hren:", "tokens": ["Durch", "ihr", "Din\u00b7ten\u00b7fa\u00df", "Blut\u00b7str\u00f6m", "in", "uns", "r\u00f6h\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+--++--+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und viel Seelen verwirrn: und doch zusammen", "tokens": ["Und", "viel", "See\u00b7len", "ver\u00b7wirrn", ":", "und", "doch", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVINF", "$.", "KON", "ADV", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Ihre Zanck K\u00fcnst in Todes Noth verdammen.", "tokens": ["Ih\u00b7re", "Zanck", "K\u00fcnst", "in", "To\u00b7des", "Noth", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "APPR", "NN", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "Von dem Glauben Vernunfft und Ansehn scheiden,", "tokens": ["Von", "dem", "Glau\u00b7ben", "Ver\u00b7nunfft", "und", "An\u00b7sehn", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und sich tr\u00f6sten mit uns mit Gottes Leiden.", "tokens": ["Und", "sich", "tr\u00f6s\u00b7ten", "mit", "uns", "mit", "Got\u00b7tes", "Lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "PPER", "APPR", "NN", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.108": {"line.1": {"text": "Ob sie beydes durch trauen und nicht trauen", "tokens": ["Ob", "sie", "bey\u00b7des", "durch", "trau\u00b7en", "und", "nicht", "trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "APPR", "VVINF", "KON", "PTKNEG", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihre Sicherheit hier und auswerts bauen:", "tokens": ["Ih\u00b7re", "Si\u00b7cher\u00b7heit", "hier", "und", "aus\u00b7werts", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "KON", "ADV", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und den F\u00fcrsten des Friedens unter Vieren,", "tokens": ["Und", "den", "F\u00fcrs\u00b7ten", "des", "Frie\u00b7dens", "un\u00b7ter", "Vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Unsern Ferdinand mit der Krone zieren,", "tokens": ["Un\u00b7sern", "Fer\u00b7di\u00b7nand", "mit", "der", "Kro\u00b7ne", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Die der Adler bereit zum guten Zeichen", "tokens": ["Die", "der", "Ad\u00b7ler", "be\u00b7reit", "zum", "gu\u00b7ten", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJD", "APPRART", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Auf die Hungrisch und B\u00f6hmsche wolte reichen,", "tokens": ["Auf", "die", "Hun\u00b7grisch", "und", "B\u00f6hm\u00b7sche", "wol\u00b7te", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NE", "VMFIN", "VVINF", "$,"], "meter": "--++-+-+-+-", "measure": "anapaest.init"}, "line.7": {"text": "Den um Schweidnitz wir bey der Huldung fiengen,", "tokens": ["Den", "um", "Schweid\u00b7nitz", "wir", "bey", "der", "Hul\u00b7dung", "fi\u00b7en\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Bi\u00df die Vierdte der Vierdte wird erschwingen.", "tokens": ["Bi\u00df", "die", "Vierd\u00b7te", "der", "Vierd\u00b7te", "wird", "er\u00b7schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Und wo Gottesfurcht, wo ihr eigne T\u00f6chter", "tokens": ["Und", "wo", "Got\u00b7tes\u00b7furcht", ",", "wo", "ihr", "eig\u00b7ne", "T\u00f6ch\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "NN", "$,", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Wei\u00dfheit und M\u00e4ssigkeit ziern die Geschlechter,", "tokens": ["Wei\u00df\u00b7heit", "und", "M\u00e4s\u00b7sig\u00b7keit", "zi\u00b7ern", "die", "Ge\u00b7schlech\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.11": {"text": "Und aus F\u00fcrsten vermenschte G\u00f6tter machen,", "tokens": ["Und", "aus", "F\u00fcrs\u00b7ten", "ver\u00b7menschte", "G\u00f6t\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.12": {"text": "Kan kein G\u00f6ttlicher F\u00fcrst in Deutschland wachen;", "tokens": ["Kan", "kein", "G\u00f6tt\u00b7li\u00b7cher", "F\u00fcrst", "in", "Deutschland", "wa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "NN", "APPR", "NE", "VVINF", "$."], "meter": "+-+--+-++-", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Ob die Engel ihn unter ihren Thr\u00f6nen", "tokens": ["Ob", "die", "En\u00b7gel", "ihn", "un\u00b7ter", "ih\u00b7ren", "Thr\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Solten selber erwehlen und bekr\u00f6nen.", "tokens": ["Sol\u00b7ten", "sel\u00b7ber", "er\u00b7weh\u00b7len", "und", "be\u00b7kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.109": {"line.1": {"text": "Ob sie, sag ich: Gedancken, und Gedancken,", "tokens": ["Ob", "sie", ",", "sag", "ich", ":", "Ge\u00b7dan\u00b7cken", ",", "und", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "VVFIN", "PPER", "$.", "NN", "$,", "KON", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Die recht F\u00fcrstlich sind, die niemals nicht wancken,", "tokens": ["Die", "recht", "F\u00fcrst\u00b7lich", "sind", ",", "die", "nie\u00b7mals", "nicht", "wan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "VAFIN", "$,", "PRELS", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ausser dienstbaren Mund und Hertzen f\u00fchren,", "tokens": ["Aus\u00b7ser", "dienst\u00b7ba\u00b7ren", "Mund", "und", "Hert\u00b7zen", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und die Adern vom Deutsche Blute r\u00fchren,", "tokens": ["Und", "die", "A\u00b7dern", "vom", "Deut\u00b7sche", "Blu\u00b7te", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Drinnen Geister der edlen Freyheit wallen,", "tokens": ["Drin\u00b7nen", "Geis\u00b7ter", "der", "ed\u00b7len", "Frey\u00b7heit", "wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Doch sol ihnen dis Buch, hoff ich, gefallen.", "tokens": ["Doch", "sol", "ih\u00b7nen", "dis", "Buch", ",", "hoff", "ich", ",", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PDS", "NN", "$,", "VVFIN", "PPER", "$,", "VVPP", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}}, "stanza.110": {"line.1": {"text": "Nicht umbsonsten. Es werden draus auf Erden", "tokens": ["Nicht", "um\u00b7bsons\u00b7ten", ".", "Es", "wer\u00b7den", "draus", "auf", "Er\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "$.", "PPER", "VAFIN", "PAV", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Menschen, unter den Menschen, Menschen werden.", "tokens": ["Men\u00b7schen", ",", "un\u00b7ter", "den", "Men\u00b7schen", ",", "Men\u00b7schen", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "NN", "$,", "NN", "VAINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.111": {"line.1": {"text": "Wir: das Ebenbild: das nach Gott entsprossen,", "tokens": ["Wir", ":", "das", "E\u00b7ben\u00b7bild", ":", "das", "nach", "Gott", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "NN", "$.", "ART", "APPR", "NN", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir: das Wunderwerck: das aus Gott geflossen:", "tokens": ["Wir", ":", "das", "Wun\u00b7der\u00b7werck", ":", "das", "aus", "Gott", "ge\u00b7flos\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "NN", "$.", "PDS", "APPR", "NN", "VVPP", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir: das Meisterst\u00fcck, das von Gott erkohren,", "tokens": ["Wir", ":", "das", "Meis\u00b7ter\u00b7st\u00fcck", ",", "das", "von", "Gott", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "ART", "NN", "$,", "PRELS", "APPR", "NN", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hatten unter uns Gott und uns verlohren.", "tokens": ["Hat\u00b7ten", "un\u00b7ter", "uns", "Gott", "und", "uns", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "NN", "KON", "PPER", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Gott: wir liessen uns seinen Geist nicht f\u00fchren:", "tokens": ["Gott", ":", "wir", "lies\u00b7sen", "uns", "sei\u00b7nen", "Geist", "nicht", "f\u00fch\u00b7ren", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und wir giengen von Engeln zu den Thieren.", "tokens": ["Und", "wir", "gien\u00b7gen", "von", "En\u00b7geln", "zu", "den", "Thie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Draus kam, da\u00df wir worden, wie zu schauen,", "tokens": ["Draus", "kam", ",", "da\u00df", "wir", "wor\u00b7den", ",", "wie", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "KOUS", "PPER", "VAPP", "$,", "PWAV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Aus dem Ebenbild ein Thier voller Grauen:", "tokens": ["Aus", "dem", "E\u00b7ben\u00b7bild", "ein", "Thier", "vol\u00b7ler", "Grau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Aus dem Wunderwerck ein Ziel aller St\u00fcrme:", "tokens": ["Aus", "dem", "Wun\u00b7der\u00b7werck", "ein", "Ziel", "al\u00b7ler", "St\u00fcr\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PIAT", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Aus dem Meisterst\u00fcck ein Aas grauser W\u00fcrme.", "tokens": ["Aus", "dem", "Meis\u00b7ter\u00b7st\u00fcck", "ein", "Aas", "grau\u00b7ser", "W\u00fcr\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.112": {"line.1": {"text": "Doch es k\u00f6nt' in dem Abgrund unsrer Seelen", "tokens": ["Doch", "es", "k\u00f6nt'", "in", "dem", "Ab\u00b7grund", "uns\u00b7rer", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sich ein F\u00fcncklein der G\u00f6ttlichkeit verheelen:", "tokens": ["Sich", "ein", "F\u00fcnc\u00b7klein", "der", "G\u00f6tt\u00b7lich\u00b7keit", "ver\u00b7hee\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Welches, wollt es gleich H\u00f6ll und Tod vorschweiffen,", "tokens": ["Wel\u00b7ches", ",", "wollt", "es", "gleich", "H\u00f6ll", "und", "Tod", "vor\u00b7schwei\u00b7ffen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "VMFIN", "PPER", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Doch den Trost der Errettung k\u00f6nt' ergreiffen.", "tokens": ["Doch", "den", "Trost", "der", "Er\u00b7ret\u00b7tung", "k\u00f6nt'", "er\u00b7greif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.113": {"line.1": {"text": "Unterm Grauen ward uns' das Wolbehagen", "tokens": ["Un\u00b7term", "Grau\u00b7en", "ward", "un\u00b7s'", "das", "Wol\u00b7be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Untern St\u00fcrmen die Ruhstatt angetragen:", "tokens": ["Un\u00b7tern", "St\u00fcr\u00b7men", "die", "Ruh\u00b7statt", "an\u00b7ge\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Untern W\u00fcrmen des Lebens Glantz und Frieden:", "tokens": ["Un\u00b7tern", "W\u00fcr\u00b7men", "des", "Le\u00b7bens", "Glantz", "und", "Frie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Doch mit ewigen Kl\u00fcfften unterschieden.", "tokens": ["Doch", "mit", "e\u00b7wi\u00b7gen", "Kl\u00fcff\u00b7ten", "un\u00b7ter\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.114": {"line.1": {"text": "Als das Zitternde F\u00fcncklein untern Banden", "tokens": ["Als", "das", "Zit\u00b7tern\u00b7de", "F\u00fcnc\u00b7klein", "un\u00b7tern", "Ban\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "In geb\u00e4hrender Angst und Zeit gestanden:", "tokens": ["In", "ge\u00b7b\u00e4h\u00b7ren\u00b7der", "Angst", "und", "Zeit", "ge\u00b7stan\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Schleust das Tieffste das H\u00f6chst in sein Begehren,", "tokens": ["Schleust", "das", "Tieffs\u00b7te", "das", "H\u00f6chst", "in", "sein", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Uns den Trost der Errettung zu gew\u00e4hren.", "tokens": ["Uns", "den", "Trost", "der", "Er\u00b7ret\u00b7tung", "zu", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.115": {"line.1": {"text": "Das gew\u00e4hrn, das Erretten, das Vertr\u00f6sten", "tokens": ["Das", "ge\u00b7w\u00e4hrn", ",", "das", "Er\u00b7ret\u00b7ten", ",", "das", "Ver\u00b7tr\u00f6s\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Machte zwischen Verdammten und Erl\u00f6sten", "tokens": ["Mach\u00b7te", "zwi\u00b7schen", "Ver\u00b7damm\u00b7ten", "und", "Er\u00b7l\u00f6s\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ein Heil-wirckendes Creutz: aus den Verdammten", "tokens": ["Ein", "Heil\u00b7wir\u00b7cken\u00b7des", "Creutz", ":", "aus", "den", "Ver\u00b7damm\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Gehn Erl\u00f6ste vor: Christen aus gesammten.", "tokens": ["Gehn", "Er\u00b7l\u00f6s\u00b7te", "vor", ":", "Chris\u00b7ten", "aus", "ge\u00b7samm\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$.", "NN", "APPR", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.116": {"line.1": {"text": "Als die Cabala kam vom Weibes Saamen,", "tokens": ["Als", "die", "Ca\u00b7ba\u00b7la", "kam", "vom", "Wei\u00b7bes", "Saa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NE", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ward das F\u00fcncklein durchgl\u00e4ntzt von Gottes Nahmen,", "tokens": ["Ward", "das", "F\u00fcnc\u00b7klein", "durch\u00b7gl\u00e4ntzt", "von", "Got\u00b7tes", "Nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "APPR", "NN", "NN", "$,"], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Drauf sich steiffet des Glaubens gantzer Orden", "tokens": ["Drauf", "sich", "steif\u00b7fet", "des", "Glau\u00b7bens", "gant\u00b7zer", "Or\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PRF", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Weil das Wort Fleisch, und Gott Mensch dr\u00fcber worden.", "tokens": ["Weil", "das", "Wort", "Fleisch", ",", "und", "Gott", "Mensch", "dr\u00fc\u00b7ber", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$,", "KON", "NN", "NN", "PAV", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.117": {"line.1": {"text": "Das selbst\u00e4ndige Wesen alles Wesen,", "tokens": ["Das", "selb\u00b7st\u00e4n\u00b7di\u00b7ge", "We\u00b7sen", "al\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ohn das nichts, durch das alles mu\u00df genesen,", "tokens": ["Ohn", "das", "nichts", ",", "durch", "das", "al\u00b7les", "mu\u00df", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "$,", "APPR", "ART", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wolt aus innerster Grund- Erb\u00e4rmbd uns zeigen,", "tokens": ["Wolt", "aus", "in\u00b7ners\u00b7ter", "Grun\u00b7d", "Er\u00b7b\u00e4rmbd", "uns", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ADJA", "TRUNC", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wie wir Himmel an wieder solten steigen.", "tokens": ["Wie", "wir", "Him\u00b7mel", "an", "wie\u00b7der", "sol\u00b7ten", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "APPR", "ADV", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.118": {"line.1": {"text": "Er l\u00e4st uns durch zwey Weg' in zweyen B\u00fcchern", "tokens": ["Er", "l\u00e4st", "uns", "durch", "zwey", "Weg'", "in", "zwe\u00b7yen", "B\u00fc\u00b7chern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "CARD", "NN", "APPR", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dessen aus der Natur und Schrifft versichern:", "tokens": ["Des\u00b7sen", "aus", "der", "Na\u00b7tur", "und", "Schrifft", "ver\u00b7si\u00b7chern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Der Natur Weg ist heimlich, der Schrifft offen,", "tokens": ["Der", "Na\u00b7tur", "Weg", "ist", "heim\u00b7lich", ",", "der", "Schrifft", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Beyde zeigen uns, was wir sollen hoffen.", "tokens": ["Bey\u00b7de", "zei\u00b7gen", "uns", ",", "was", "wir", "sol\u00b7len", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.119": {"line.1": {"text": "Die Natur ist ein Licht, das vorgebrochen,", "tokens": ["Die", "Na\u00b7tur", "ist", "ein", "Licht", ",", "das", "vor\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,", "PRELS", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als das ewige Fiat ward gesprochen:", "tokens": ["Als", "das", "e\u00b7wi\u00b7ge", "Fiat", "ward", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Das im I seinen Ausflu\u00df hat gefunden,", "tokens": ["Das", "im", "I", "sei\u00b7nen", "Aus\u00b7flu\u00df", "hat", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "CARD", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der ohn Ende sich an das A gebunden:", "tokens": ["Der", "ohn", "En\u00b7de", "sich", "an", "das", "A", "ge\u00b7bun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PRF", "APPR", "ART", "NE", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Und so allen Gesch\u00f6pffen eingegeben", "tokens": ["Und", "so", "al\u00b7len", "Ge\u00b7sch\u00f6pf\u00b7fen", "ein\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "NN", "VVINF"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Geist und Wesen, Gestalt, und Licht und Leben.", "tokens": ["Geist", "und", "We\u00b7sen", ",", "Ge\u00b7stalt", ",", "und", "Licht", "und", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "NN", "$,", "KON", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Dieses FIAT, das ist das Wort und Wesen,", "tokens": ["Die\u00b7ses", "FiAT", ",", "das", "ist", "das", "Wort", "und", "We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Das Gott selbsten war, und Gott hat erlesen:", "tokens": ["Das", "Gott", "selbs\u00b7ten", "war", ",", "und", "Gott", "hat", "er\u00b7le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "$,", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ist der Athem und Hauch, davon wir leben", "tokens": ["Ist", "der", "A\u00b7them", "und", "Hauch", ",", "da\u00b7von", "wir", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$,", "PAV", "PPER", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Draus die G\u00f6ttliche Lufft die Parcen weben,", "tokens": ["Draus", "die", "G\u00f6tt\u00b7li\u00b7che", "Lufft", "die", "Par\u00b7cen", "we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Ist das F\u00fcncklein, das Weise sonder Gr\u00e4ntzen", "tokens": ["Ist", "das", "F\u00fcnc\u00b7klein", ",", "das", "Wei\u00b7se", "son\u00b7der", "Gr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "In der reinen Vernunfft sehn wieder gl\u00e4ntzen:", "tokens": ["In", "der", "rei\u00b7nen", "Ver\u00b7nunfft", "sehn", "wie\u00b7der", "gl\u00e4nt\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ADV", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.13": {"text": "Ist des heiligen Gottes grosser Nahmen,", "tokens": ["Ist", "des", "hei\u00b7li\u00b7gen", "Got\u00b7tes", "gros\u00b7ser", "Nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "Das erleuchtende Licht des Weibes Saamen:", "tokens": ["Das", "er\u00b7leuch\u00b7ten\u00b7de", "Licht", "des", "Wei\u00b7bes", "Saa\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.15": {"text": "Ist die Wahrheit, die alles ausgesprochen,", "tokens": ["Ist", "die", "Wahr\u00b7heit", ",", "die", "al\u00b7les", "aus\u00b7ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PIS", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "Die in allen ist, ob man sie wil suchen.", "tokens": ["Die", "in", "al\u00b7len", "ist", ",", "ob", "man", "sie", "wil", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIS", "VAFIN", "$,", "KOUS", "PIS", "PPER", "VMFIN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "In uns ist ja was g\u00f6ttliches zu sp\u00fchren,", "tokens": ["In", "uns", "ist", "ja", "was", "g\u00f6tt\u00b7li\u00b7ches", "zu", "sp\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "PWS", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Das zu Gott und der Wahrheit uns kan f\u00fchren,", "tokens": ["Das", "zu", "Gott", "und", "der", "Wahr\u00b7heit", "uns", "kan", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "KON", "ART", "NN", "PPER", "VMFIN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.19": {"text": "Wann ein ziehender Schrack es angeglommen,", "tokens": ["Wann", "ein", "zie\u00b7hen\u00b7der", "Schrack", "es", "an\u00b7ge\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "Zeigt das Creutze die Bahn, und du solt kommen.", "tokens": ["Zeigt", "das", "Creut\u00b7ze", "die", "Bahn", ",", "und", "du", "solt", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,", "KON", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.21": {"text": "Das Buch in der Natur, das kan uns weisen", "tokens": ["Das", "Buch", "in", "der", "Na\u00b7tur", ",", "das", "kan", "uns", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PDS", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Den geheimen Weg, den die Alten preisen.", "tokens": ["Den", "ge\u00b7hei\u00b7men", "Weg", ",", "den", "die", "Al\u00b7ten", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.23": {"text": "Den hat Hermes am Leben und an Worten", "tokens": ["Den", "hat", "Her\u00b7mes", "am", "Le\u00b7ben", "und", "an", "Wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NE", "APPRART", "NN", "KON", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.24": {"text": "L\u00e4ngst vor Mosen dort umb des Nilus Pforten", "tokens": ["L\u00e4ngst", "vor", "Mo\u00b7sen", "dort", "umb", "des", "Ni\u00b7lus", "Pfor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "ADV", "APPR", "ART", "NE", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.25": {"text": "Nach der S\u00fcndfluth gelehrt voll Kunst und G\u00fcte", "tokens": ["Nach", "der", "S\u00fcnd\u00b7fluth", "ge\u00b7lehrt", "voll", "Kunst", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP", "ADJD", "NN", "KON", "NN"], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.26": {"text": "Im Pimander gelehrt vom himmlischen Gem\u00fcthe.", "tokens": ["Im", "Pi\u00b7man\u00b7der", "ge\u00b7lehrt", "vom", "himm\u00b7li\u00b7schen", "Ge\u00b7m\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Diesen hat Zoroaster wollen lernen,", "tokens": ["Die\u00b7sen", "hat", "Zo\u00b7roas\u00b7ter", "wol\u00b7len", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.28": {"text": "Der die Gr\u00fcnde der Welt, den Lauff der Sternen,", "tokens": ["Der", "die", "Gr\u00fcn\u00b7de", "der", "Welt", ",", "den", "Lauff", "der", "Ster\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.29": {"text": "Und der Dinge Gestalt und Krafft erfahren,", "tokens": ["Und", "der", "Din\u00b7ge", "Ge\u00b7stalt", "und", "Krafft", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.30": {"text": "Und ein K\u00f6nig war erster Weisen Schaaren.", "tokens": ["Und", "ein", "K\u00f6\u00b7nig", "war", "ers\u00b7ter", "Wei\u00b7sen", "Schaa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJA", "NN", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.120": {"line.1": {"text": "Den hat Pythagoras durch Stilleschweigen", "tokens": ["Den", "hat", "Py\u00b7tha\u00b7go\u00b7ras", "durch", "Stil\u00b7le\u00b7schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NE", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Seinen J\u00fcngern mit Fingern wollen zeigen,", "tokens": ["Sei\u00b7nen", "J\u00fcn\u00b7gern", "mit", "Fin\u00b7gern", "wol\u00b7len", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Der die Wissenschafft von dem Obern Wesen", "tokens": ["Der", "die", "Wis\u00b7sen\u00b7schafft", "von", "dem", "O\u00b7bern", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "In den weisen Tetractys gab zu lesen.", "tokens": ["In", "den", "wei\u00b7sen", "Tet\u00b7rac\u00b7tys", "gab", "zu", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.121": {"line.1": {"text": "Diesen hat die Idea auch gewiesen,", "tokens": ["Die\u00b7sen", "hat", "die", "I\u00b7dea", "auch", "ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NE", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Welche Plato in seiner Art gepriesen,", "tokens": ["Wel\u00b7che", "Pla\u00b7to", "in", "sei\u00b7ner", "Art", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NE", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Der kein andere Seeligkeit kan finden,", "tokens": ["Der", "kein", "an\u00b7de\u00b7re", "See\u00b7lig\u00b7keit", "kan", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Als das Hertze Grundaus mit Gott verbinden.", "tokens": ["Als", "das", "Hert\u00b7ze", "Grun\u00b7daus", "mit", "Gott", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Da\u00df nu Gottes Geheimn\u00fc\u00dfe vor allen", "tokens": ["Da\u00df", "nu", "Got\u00b7tes", "Ge\u00b7heim\u00b7n\u00fc\u00b7\u00dfe", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "NN", "APPR", "PIAT"], "meter": "+-+--++--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Durch das Heydenthum man euch h\u00f6rte schallen,", "tokens": ["Durch", "das", "Hey\u00b7den\u00b7thum", "man", "euch", "h\u00f6r\u00b7te", "schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIS", "PPER", "VVFIN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.7": {"text": "Bi\u00df durch K\u00f6nig und Priester Er gantz eigen", "tokens": ["Bi\u00df", "durch", "K\u00f6\u00b7nig", "und", "Pries\u00b7ter", "Er", "gantz", "ei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "NN", "KON", "NN", "PPER", "ADV", "ADJD"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Den Chald\u00e6rn und Indien sie bezeigen:", "tokens": ["Den", "Chald\u00e6rn", "und", "In\u00b7di\u00b7en", "sie", "be\u00b7zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NE", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "So die Wahrheit, der Seelen edle Speise,", "tokens": ["So", "die", "Wahr\u00b7heit", ",", "der", "See\u00b7len", "ed\u00b7le", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Ausgebreitet, verdeckter Art und Weise:", "tokens": ["Aus\u00b7ge\u00b7brei\u00b7tet", ",", "ver\u00b7deck\u00b7ter", "Art", "und", "Wei\u00b7se", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Und der V\u00f6lcker, bey denen sie gelesen,", "tokens": ["Und", "der", "V\u00f6l\u00b7cker", ",", "bey", "de\u00b7nen", "sie", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "\u00dcbersinnliche Meister sind gewesen:", "tokens": ["\u00dc\u00b7ber\u00b7sinn\u00b7li\u00b7che", "Meis\u00b7ter", "sind", "ge\u00b7we\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "VAPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Weil sie vom Abraham drob lehrten herrschen,", "tokens": ["Weil", "sie", "vom", "Ab\u00b7ra\u00b7ham", "drob", "lehr\u00b7ten", "herr\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NE", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "In Egypten, vom Daniel in Perschen.", "tokens": ["In", "E\u00b7gyp\u00b7ten", ",", "vom", "Da\u00b7ni\u00b7el", "in", "Per\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPRART", "NN", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.122": {"line.1": {"text": "Wie von Ursach auf Ursach in den Dingen", "tokens": ["Wie", "von", "Ur\u00b7sach", "auf", "Ur\u00b7sach", "in", "den", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "NN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sie zur Ursach ohn Ursach endlich giengen:", "tokens": ["Sie", "zur", "Ur\u00b7sach", "ohn", "Ur\u00b7sach", "end\u00b7lich", "gien\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "APPR", "NN", "ADV", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Vor sich Menschen und Erd und Himmel nahmen,", "tokens": ["Vor", "sich", "Men\u00b7schen", "und", "Erd", "und", "Him\u00b7mel", "nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Von der a\u00fcsren Gestalt zur innren kamen:", "tokens": ["Von", "der", "a\u00b7\u00fcs\u00b7ren", "Ge\u00b7stalt", "zur", "inn\u00b7ren", "ka\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Bi\u00df die Sache sie, daraus alle gehen,", "tokens": ["Bi\u00df", "die", "Sa\u00b7che", "sie", ",", "da\u00b7raus", "al\u00b7le", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "$,", "PAV", "PIS", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Unter einer iedwedern Sache sehen:", "tokens": ["Un\u00b7ter", "ei\u00b7ner", "ied\u00b7we\u00b7dern", "Sa\u00b7che", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Und, wann drinnen ihr Hertz und Geist zuflossen,", "tokens": ["Und", ",", "wann", "drin\u00b7nen", "ihr", "Hertz", "und", "Geist", "zu\u00b7flos\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADV", "PPOSAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Unaussprechliche S\u00fcssigkeit geno\u00dfen;", "tokens": ["Un\u00b7aus\u00b7sprech\u00b7li\u00b7che", "S\u00fcs\u00b7sig\u00b7keit", "ge\u00b7no\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.123": {"line.1": {"text": "Also machen die Menschen diese Reime", "tokens": ["Al\u00b7so", "ma\u00b7chen", "die", "Men\u00b7schen", "die\u00b7se", "Rei\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PDAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Durch den Weg der Natur mit Gott geheime:", "tokens": ["Durch", "den", "Weg", "der", "Na\u00b7tur", "mit", "Gott", "ge\u00b7hei\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Der von Staffel zu Staffel voll Behagen", "tokens": ["Der", "von", "Staf\u00b7fel", "zu", "Staf\u00b7fel", "voll", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "NN", "ADJD", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sein erbarmende Liebe uns angetragen:", "tokens": ["Sein", "er\u00b7bar\u00b7men\u00b7de", "Lie\u00b7be", "uns", "an\u00b7ge\u00b7tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "VVPP", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Unser F\u00fcncklein geht an: wir sehn und f\u00fchlen", "tokens": ["Un\u00b7ser", "F\u00fcnc\u00b7klein", "geht", "an", ":", "wir", "sehn", "und", "f\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$.", "PPER", "VVINF", "KON", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "In ihm gr\u00fcndlich die Wahrheit wieder spielen.", "tokens": ["In", "ihm", "gr\u00fcnd\u00b7lich", "die", "Wahr\u00b7heit", "wie\u00b7der", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.124": {"line.1": {"text": "Aber der Weg der Schrifft: Das Buch der Gnaden,", "tokens": ["A\u00b7ber", "der", "Weg", "der", "Schrifft", ":", "Das", "Buch", "der", "Gna\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$.", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Das uns offenbahret unser Heil und Schaden:", "tokens": ["Das", "uns", "of\u00b7fen\u00b7bah\u00b7ret", "un\u00b7ser", "Heil", "und", "Scha\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "In zwey B\u00fcnde, von dem Gesetz und Frieden,", "tokens": ["In", "zwey", "B\u00fcn\u00b7de", ",", "von", "dem", "Ge\u00b7setz", "und", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Durch Verheissen und durch Gew\u00e4hrn geschieden:", "tokens": ["Durch", "Ver\u00b7heis\u00b7sen", "und", "durch", "Ge\u00b7w\u00e4hrn", "ge\u00b7schie\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Wei\u00df die Cabala reiner auszugr\u00fcnden,", "tokens": ["Wei\u00df", "die", "Ca\u00b7ba\u00b7la", "rei\u00b7ner", "aus\u00b7zu\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "ADJA", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Die wir in Gott und seinem Worte finden.", "tokens": ["Die", "wir", "in", "Gott", "und", "sei\u00b7nem", "Wor\u00b7te", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.125": {"line.1": {"text": "Denn die Schrifft ist ein Licht, das gantz vollkommen", "tokens": ["Denn", "die", "Schrifft", "ist", "ein", "Licht", ",", "das", "gantz", "voll\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "ADJD"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "In dem Hertzen der Gottheit angeglommen,", "tokens": ["In", "dem", "Hert\u00b7zen", "der", "Got\u00b7theit", "an\u00b7ge\u00b7glom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ist die Krafft, durch die Gottes Geist zusammen", "tokens": ["Ist", "die", "Krafft", ",", "durch", "die", "Got\u00b7tes", "Geist", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "APPR", "ART", "NN", "NN", "VVINF"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die Propheten erf\u00fcllt mit heilgen Flammen:", "tokens": ["Die", "Pro\u00b7phe\u00b7ten", "er\u00b7f\u00fcllt", "mit", "heil\u00b7gen", "Flam\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ist das Wort, drauf den Grund der Ewigkeiten", "tokens": ["Ist", "das", "Wort", ",", "drauf", "den", "Grund", "der", "E\u00b7wig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$,", "PAV", "ART", "NN", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Gott gebaut, den kein Teufel kan bestreiten:", "tokens": ["Gott", "ge\u00b7baut", ",", "den", "kein", "Teu\u00b7fel", "kan", "be\u00b7strei\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Ist das Pfand, ist die Richtschnur, ist der Bronnen,", "tokens": ["Ist", "das", "Pfand", ",", "ist", "die", "Richt\u00b7schnur", ",", "ist", "der", "Bron\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Draus die Seeligkeit in uns k\u00f6mmt geronnen:", "tokens": ["Draus", "die", "See\u00b7lig\u00b7keit", "in", "uns", "k\u00f6mmt", "ge\u00b7ron\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "PPER", "VVFIN", "VVPP", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.9": {"text": "Hie wird, welches vor alle Ding erkohren,", "tokens": ["Hie", "wird", ",", "wel\u00b7ches", "vor", "al\u00b7le", "Ding", "er\u00b7koh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "PRELS", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Das unendliche FIAT selbst gebohren:", "tokens": ["Das", "un\u00b7end\u00b7li\u00b7che", "FiAT", "selbst", "ge\u00b7boh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.126": {"line.1": {"text": "Hier ist, h\u00e4tt es die Welt doch wahrgenommen,", "tokens": ["Hier", "ist", ",", "h\u00e4tt", "es", "die", "Welt", "doch", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "VAFIN", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der versprochene Weibes Saamen kommen:", "tokens": ["Der", "ver\u00b7spro\u00b7che\u00b7ne", "Wei\u00b7bes", "Saa\u00b7men", "kom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Was kein Weiser im Himmel ie erstiegen,", "tokens": ["Was", "kein", "Wei\u00b7ser", "im", "Him\u00b7mel", "ie", "er\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sehn wir zu Bethlehem im Stalle liegen:", "tokens": ["Sehn", "wir", "zu", "Beth\u00b7le\u00b7hem", "im", "Stal\u00b7le", "lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dessen Cabala heist vor andern Lehren.", "tokens": ["Des\u00b7sen", "Ca\u00b7ba\u00b7la", "heist", "vor", "an\u00b7dern", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Dis ist mein lieber Sohn, den solt ihr h\u00f6ren.", "tokens": ["Dis", "ist", "mein", "lie\u00b7ber", "Sohn", ",", "den", "solt", "ihr", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,", "ART", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.127": {"line.1": {"text": "Dieses haben, als sie in Geist gegangen,", "tokens": ["Die\u00b7ses", "ha\u00b7ben", ",", "als", "sie", "in", "Geist", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Adam und Abraham von Gott empfangen:", "tokens": ["A\u00b7dam", "und", "Ab\u00b7ra\u00b7ham", "von", "Gott", "emp\u00b7fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "APPR", "NN", "VVPP", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Der ein Vater vom Fleisch, und der vom Glauben,", "tokens": ["Der", "ein", "Va\u00b7ter", "vom", "Fleisch", ",", "und", "der", "vom", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPRART", "NN", "$,", "KON", "ART", "APPRART", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Beyden konte noch Noth, noch Tod es rauben.", "tokens": ["Bey\u00b7den", "kon\u00b7te", "noch", "Noth", ",", "noch", "Tod", "es", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "NN", "$,", "ADV", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.128": {"line.1": {"text": "Die hat Moses und Christus voller Gaben,", "tokens": ["Die", "hat", "Mo\u00b7ses", "und", "Chris\u00b7tus", "vol\u00b7ler", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "KON", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der auf Sina, auf Sion der erhaben:", "tokens": ["Der", "auf", "Si\u00b7na", ",", "auf", "Si\u00b7on", "der", "er\u00b7ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "$,", "APPR", "NE", "ART", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Durch Gesetz geben und Gesetz erf\u00fcllen,", "tokens": ["Durch", "Ge\u00b7setz", "ge\u00b7ben", "und", "Ge\u00b7setz", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Uns zu offenbahrn unsers Gottes Willen.", "tokens": ["Uns", "zu", "of\u00b7fen\u00b7bahrn", "un\u00b7sers", "Got\u00b7tes", "Wil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKA", "ADJD", "PPOSAT", "NN", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Diese haben durch Gottes Geist getrieben,", "tokens": ["Die\u00b7se", "ha\u00b7ben", "durch", "Got\u00b7tes", "Geist", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "NN", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Beydes M\u00e4nner und Boten Gotts beschrieben:", "tokens": ["Bey\u00b7des", "M\u00e4n\u00b7ner", "und", "Bo\u00b7ten", "Gotts", "be\u00b7schrie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "NE", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Es bezeugt es der heilgen M\u00e4rtrer Orden,", "tokens": ["Es", "be\u00b7zeugt", "es", "der", "heil\u00b7gen", "M\u00e4r\u00b7trer", "Or\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da\u00df durch Gottes Blut sie best\u00e4tigt worden.", "tokens": ["Da\u00df", "durch", "Got\u00b7tes", "Blut", "sie", "be\u00b7st\u00e4\u00b7tigt", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "NN", "PPER", "VVPP", "VAPP", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Die hat Gott in der Christlichen Gemeine", "tokens": ["Die", "hat", "Gott", "in", "der", "Christ\u00b7li\u00b7chen", "Ge\u00b7mei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.10": {"text": "Von dem ersten zu diesem Sonnenscheine", "tokens": ["Von", "dem", "ers\u00b7ten", "zu", "die\u00b7sem", "Son\u00b7nen\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "APPR", "PDAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Vor des Teufels Gewalt und Trotz erhalten:", "tokens": ["Vor", "des", "Teu\u00b7fels", "Ge\u00b7walt", "und", "Trotz", "er\u00b7hal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "Die Sein Wort, nicht der Menschen l\u00e4sset walten.", "tokens": ["Die", "Sein", "Wort", ",", "nicht", "der", "Men\u00b7schen", "l\u00e4s\u00b7set", "wal\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$,", "PTKNEG", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.13": {"text": "Vor der Kirchen, die bleibt bey diesen Worten,", "tokens": ["Vor", "der", "Kir\u00b7chen", ",", "die", "bleibt", "bey", "die\u00b7sen", "Wor\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "Gehn zu St\u00fccke der H\u00f6llen d\u00fcstre Pforten.", "tokens": ["Gehn", "zu", "St\u00fc\u00b7cke", "der", "H\u00f6l\u00b7len", "d\u00fcst\u00b7re", "Pfor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ART", "NN", "VVFIN", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Ja die Kirch, ob sie solt in eines Hertzen", "tokens": ["Ja", "die", "Kirch", ",", "ob", "sie", "solt", "in", "ei\u00b7nes", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ART", "NN", "$,", "KOUS", "PPER", "VMFIN", "APPR", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.16": {"text": "Blo\u00df bestehn, wir den Ha\u00df der Pforten schertzen,", "tokens": ["Blo\u00df", "be\u00b7stehn", ",", "wir", "den", "Ha\u00df", "der", "Pfor\u00b7ten", "schert\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "Wann den Weg der Schrifft Sie nur nicht verlassen,", "tokens": ["Wann", "den", "Weg", "der", "Schrifft", "Sie", "nur", "nicht", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Ohn die Irrth\u00fcmer Predigstuhl umbfassen:", "tokens": ["Ohn", "die", "I\u00b7rrth\u00fc\u00b7mer", "Pre\u00b7digs\u00b7tuhl", "umb\u00b7fas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Menschen Zeugn\u00fcsse fehlen: Gottes stehen:", "tokens": ["Men\u00b7schen", "Zeug\u00b7n\u00fcs\u00b7se", "feh\u00b7len", ":", "Got\u00b7tes", "ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "VVINF", "$.", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.20": {"text": "Auf die mu\u00df man in Glaubens Sachen gehen.", "tokens": ["Auf", "die", "mu\u00df", "man", "in", "Glau\u00b7bens", "Sa\u00b7chen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "PIS", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.21": {"text": "Denn der Gottesdienst der besteht auf Erden", "tokens": ["Denn", "der", "Got\u00b7tes\u00b7dienst", "der", "be\u00b7steht", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "VVFIN", "APPR", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Blo\u00df in dem, wie der Mensch sol seelig werden:", "tokens": ["Blo\u00df", "in", "dem", ",", "wie", "der", "Mensch", "sol", "see\u00b7lig", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "$,", "PWAV", "ART", "NN", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Den Weg zeiget die Schrifft, der sol er trauen,", "tokens": ["Den", "Weg", "zei\u00b7get", "die", "Schrifft", ",", "der", "sol", "er", "trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "PRELS", "KOUS", "PPER", "VVINF", "$,"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "So auf Gott durch sein Wort den Glauben bauen:", "tokens": ["So", "auf", "Gott", "durch", "sein", "Wort", "den", "Glau\u00b7ben", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Und da\u00df wir nicht gef\u00e4hret sollen werden:", "tokens": ["Und", "da\u00df", "wir", "nicht", "ge\u00b7f\u00e4h\u00b7ret", "sol\u00b7len", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "VVPP", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Wird Gott Mensch, und das Wort selbst Fleisch auf Erden.", "tokens": ["Wird", "Gott", "Mensch", ",", "und", "das", "Wort", "selbst", "Fleisch", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "$,", "KON", "ART", "NN", "ADV", "NN", "APPR", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.27": {"text": "Was der V\u00e4ter Schaar aus den vier Buchstaben", "tokens": ["Was", "der", "V\u00e4\u00b7ter", "Schaar", "aus", "den", "vier", "Buch\u00b7sta\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NN", "APPR", "ART", "CARD", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Mit dem SIN vermischt, hochgew\u00fcnscht zu haben,", "tokens": ["Mit", "dem", "SiN", "ver\u00b7mischt", ",", "hoch\u00b7ge\u00b7w\u00fcnscht", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.29": {"text": "Zeigt die Schrifft blo\u00df vor uns; vor uns vorhanden,", "tokens": ["Zeigt", "die", "Schrifft", "blo\u00df", "vor", "uns", ";", "vor", "uns", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "PPER", "$.", "APPR", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Uns gebohren, uns gecreutziget, Uns erstanden.", "tokens": ["Uns", "ge\u00b7boh\u00b7ren", ",", "uns", "ge\u00b7cr\u00b7eut\u00b7zi\u00b7get", ",", "Uns", "er\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "PPER", "VVPP", "$,", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.31": {"text": "Die sind, so nach der Schrifft durch IHN im Wesen", "tokens": ["Die", "sind", ",", "so", "nach", "der", "Schrifft", "durch", "IhN", "im", "We\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "$,", "ADV", "APPR", "ART", "NN", "APPR", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Die Barmhertzigkeit Gottes erglaubt, gewesen.", "tokens": ["Die", "Barm\u00b7hert\u00b7zig\u00b7keit", "Got\u00b7tes", "er\u00b7glaubt", ",", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$,", "VAPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.33": {"text": "Wie sie alle Gewalt aus Gottes G\u00fcte", "tokens": ["Wie", "sie", "al\u00b7le", "Ge\u00b7walt", "aus", "Got\u00b7tes", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PIAT", "NN", "APPR", "NN", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.34": {"text": "Durch ihr Hertze, durch Seel und durch Gem\u00fcthe", "tokens": ["Durch", "ihr", "Hert\u00b7ze", ",", "durch", "Seel", "und", "durch", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "APPR", "NN", "KON", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.35": {"text": "In die h\u00f6chste ziehn, und sich drinnen leiden,", "tokens": ["In", "die", "h\u00f6chs\u00b7te", "ziehn", ",", "und", "sich", "drin\u00b7nen", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVINF", "$,", "KON", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.36": {"text": "Bi\u00df in sein Verdienst sie der Herr wil kleiden:", "tokens": ["Bi\u00df", "in", "sein", "Ver\u00b7dienst", "sie", "der", "Herr", "wil", "klei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPOSAT", "NN", "PPER", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Und drauf voller Trost mit erwecktem Muthe,", "tokens": ["Und", "drauf", "vol\u00b7ler", "Trost", "mit", "er\u00b7weck\u00b7tem", "Mu\u00b7the", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Rein und heilig von Christus Lehr und Blute.", "tokens": ["Rein", "und", "hei\u00b7lig", "von", "Chris\u00b7tus", "Lehr", "und", "Blu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "NE", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.39": {"text": "Sich durch Schrifft und durch Geist, /:zwey starcke Schrauben: /", "tokens": ["Sich", "durch", "Schrifft", "und", "durch", "Geist", ",", "/", ":", "zwey", "star\u00b7cke", "Schrau\u00b7ben", ":", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "APPR", "NN", "KON", "APPR", "NN", "$,", "$(", "$.", "CARD", "ADJA", "NN", "$.", "$("], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.40": {"text": "In das Hertze der tieffren Gottheit glauben:", "tokens": ["In", "das", "Hert\u00b7ze", "der", "tief\u00b7fren", "Got\u00b7theit", "glau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.41": {"text": "Das am Creutze der Heyland aufgerissen,", "tokens": ["Das", "am", "Creut\u00b7ze", "der", "Hey\u00b7land", "auf\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.42": {"text": "Sie durch seine f\u00fcnff Wunden drein zu schliessen:", "tokens": ["Sie", "durch", "sei\u00b7ne", "f\u00fcnff", "Wun\u00b7den", "drein", "zu", "schlies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "CARD", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.43": {"text": "/:Wol verwahrt. Dann in Gottes Hertz und Gnaden", "tokens": ["/", ":", "Wol", "ver\u00b7wahrt", ".", "Dann", "in", "Got\u00b7tes", "Hertz", "und", "Gna\u00b7den"], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "$.", "ADV", "VVPP", "$.", "ADV", "APPR", "NN", "NN", "KON", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.44": {"text": "Kan noch H\u00f6lle, noch Teufel ihnen schaden:/", "tokens": ["Kan", "noch", "H\u00f6l\u00b7le", ",", "noch", "Teu\u00b7fel", "ih\u00b7nen", "scha\u00b7den", ":/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "emoticon"], "pos": ["VMFIN", "ADV", "NN", "$,", "ADV", "NN", "PPER", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.45": {"text": "Also werden, wie Stahl mit Kieselsteinen", "tokens": ["Al\u00b7so", "wer\u00b7den", ",", "wie", "Stahl", "mit", "Kie\u00b7sel\u00b7stei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAINF", "$,", "PWAV", "NN", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.46": {"text": "Den Verstand, die Vernunfft, den Glauben reinen:", "tokens": ["Den", "Ver\u00b7stand", ",", "die", "Ver\u00b7nunfft", ",", "den", "Glau\u00b7ben", "rei\u00b7nen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.47": {"text": "Und durch Christus Verdienst das Hertz anfeuchten,", "tokens": ["Und", "durch", "Chris\u00b7tus", "Ver\u00b7dienst", "das", "Hertz", "an\u00b7feuch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.48": {"text": "Draus wir werden sehn Gottes Gnade leuchten:", "tokens": ["Draus", "wir", "wer\u00b7den", "sehn", "Got\u00b7tes", "Gna\u00b7de", "leuch\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VAFIN", "CARD", "NN", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.49": {"text": "/:Wie sie, als ich sie von der Hand geschrieben,", "tokens": ["/", ":", "Wie", "sie", ",", "als", "ich", "sie", "von", "der", "Hand", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$.", "PWAV", "PPER", "$,", "KOUS", "PPER", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Meinen edlen von Donat angetrieben,", "tokens": ["Mei\u00b7nen", "ed\u00b7len", "von", "Do\u00b7nat", "an\u00b7ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "APPR", "NE", "VVPP", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.51": {"text": "Da\u00df in einer Nacht er /:O theurer Orden:/", "tokens": ["Da\u00df", "in", "ei\u00b7ner", "Nacht", "er", "/", ":o", "theu\u00b7rer", "Or\u00b7den", ":/"], "token_info": ["word", "word", "word", "word", "word", "punct", "emoticon", "word", "word", "emoticon"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "$(", "NE", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.52": {"text": "Ein Mensch, ein Christ, ein Gottesfreund ist worden.", "tokens": ["Ein", "Mensch", ",", "ein", "Christ", ",", "ein", "Got\u00b7tes\u00b7freund", "ist", "wor\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VAFIN", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.53": {"text": "Dessen eilender Tod ihm bald das Leben,", "tokens": ["Des\u00b7sen", "ei\u00b7len\u00b7der", "Tod", "ihm", "bald", "das", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.54": {"text": "Das er drunter erblickt, in Gott gegeben:", "tokens": ["Das", "er", "drun\u00b7ter", "er\u00b7blickt", ",", "in", "Gott", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PAV", "VVPP", "$,", "APPR", "NN", "VVPP", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.55": {"text": "Ja es werden, wilst du sie Grundrecht h\u00f6ren,", "tokens": ["Ja", "es", "wer\u00b7den", ",", "wilst", "du", "sie", "Grund\u00b7recht", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VAINF", "$,", "VMFIN", "PPER", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.56": {"text": "Also dich zu Gott ziehn die Weisen Lehren.", "tokens": ["Al\u00b7so", "dich", "zu", "Gott", "ziehn", "die", "Wei\u00b7sen", "Leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.57": {"text": "Hertzog: Vor Euch, wo es ihm wird gel\u00fccken,", "tokens": ["Hert\u00b7zog", ":", "Vor", "Euch", ",", "wo", "es", "ihm", "wird", "ge\u00b7l\u00fc\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "PPER", "$,", "PWAV", "PPER", "PPER", "VAFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.58": {"text": "Wird der deutsche Phaleucus sich nu b\u00fccken:", "tokens": ["Wird", "der", "deut\u00b7sche", "Pha\u00b7leu\u00b7cus", "sich", "nu", "b\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.59": {"text": "Als ein Wegweiser zweyer hohen Strassen,", "tokens": ["Als", "ein", "Weg\u00b7wei\u00b7ser", "zwey\u00b7er", "ho\u00b7hen", "Stras\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.60": {"text": "Derer sich nach der Ordnung anzumassen:", "tokens": ["De\u00b7rer", "sich", "nach", "der", "Ord\u00b7nung", "an\u00b7zu\u00b7mas\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "Die im Tichten des Geists Entz\u00fcckung f\u00fchlen,", "tokens": ["Die", "im", "Tich\u00b7ten", "des", "Geists", "Ent\u00b7z\u00fc\u00b7ckung", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.62": {"text": "Die der Sterne Gestalt und Lauff erzielen:", "tokens": ["Die", "der", "Ster\u00b7ne", "Ge\u00b7stalt", "und", "Lauff", "er\u00b7zie\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.63": {"text": "Die im Monden uns alle Sterne zeigen,", "tokens": ["Die", "im", "Mon\u00b7den", "uns", "al\u00b7le", "Ster\u00b7ne", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.64": {"text": "Seine Kugel durch Gl\u00e4ser zu uns neigen:", "tokens": ["Sei\u00b7ne", "Ku\u00b7gel", "durch", "Gl\u00e4\u00b7ser", "zu", "uns", "nei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.65": {"text": "Die im Messen der Erden Wendung finden:", "tokens": ["Die", "im", "Mes\u00b7sen", "der", "Er\u00b7den", "Wen\u00b7dung", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.66": {"text": "Die im Rechnen in Einem Alles gr\u00fcnden:", "tokens": ["Die", "im", "Rech\u00b7nen", "in", "Ei\u00b7nem", "Al\u00b7les", "gr\u00fcn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "APPR", "ART", "PIS", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.67": {"text": "Die im Lehren Gem\u00fcth und Gott vereinen:", "tokens": ["Die", "im", "Leh\u00b7ren", "Ge\u00b7m\u00fcth", "und", "Gott", "ver\u00b7ei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.68": {"text": "Die im Richten das Recht, nicht Menschen meinen:", "tokens": ["Die", "im", "Rich\u00b7ten", "das", "Recht", ",", "nicht", "Men\u00b7schen", "mei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "$,", "PTKNEG", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.69": {"text": "Die im Heilen sich ziehn auf Gottes Seegen,", "tokens": ["Die", "im", "Hei\u00b7len", "sich", "ziehn", "auf", "Got\u00b7tes", "See\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PRF", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.70": {"text": "Der das Mittel kan in die Mittel legen.", "tokens": ["Der", "das", "Mit\u00b7tel", "kan", "in", "die", "Mit\u00b7tel", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.71": {"text": "Auch die: Wesen und Nahmen auszuf\u00fchren,", "tokens": ["Auch", "die", ":", "We\u00b7sen", "und", "Nah\u00b7men", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$.", "NN", "KON", "NN", "VVIZU", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.72": {"text": "Der Natur A. B. C. nach buchstabieren.", "tokens": ["Der", "Na\u00b7tur", "A.", "B.", "C.", "nach", "buch\u00b7sta\u00b7bie\u00b7ren", "."], "token_info": ["word", "word", "abbreviation", "abbreviation", "abbreviation", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "NE", "APPR", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.73": {"text": "Auch die, welche den Grund der Erde suchen,", "tokens": ["Auch", "die", ",", "wel\u00b7che", "den", "Grund", "der", "Er\u00b7de", "su\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.74": {"text": "Und ihr glastendes Hertz aus solchem kochen.", "tokens": ["Und", "ihr", "glas\u00b7ten\u00b7des", "Hertz", "aus", "sol\u00b7chem", "ko\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "PIAT", "ADJA", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.75": {"text": "Auch die voll Seeligkeit sabbathisiren,", "tokens": ["Auch", "die", "voll", "See\u00b7lig\u00b7keit", "sab\u00b7ba\u00b7thi\u00b7si\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "+--+--+-+--", "measure": "dactylic.di.plus"}, "line.76": {"text": "Untern Thronf\u00fcrsten Gottes Lob vollf\u00fchren.", "tokens": ["Un\u00b7tern", "Thron\u00b7f\u00fcrs\u00b7ten", "Got\u00b7tes", "Lob", "voll\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.77": {"text": "Auch die, welche nach Ehre pflegt zu d\u00fcrsten,", "tokens": ["Auch", "die", ",", "wel\u00b7che", "nach", "Eh\u00b7re", "pflegt", "zu", "d\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.78": {"text": "Wie vom Stande so vom Verstande F\u00fcrsten.", "tokens": ["Wie", "vom", "Stan\u00b7de", "so", "vom", "Ver\u00b7stan\u00b7de", "F\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.79": {"text": "Wann sie ihr und des Reiches Ruh erwegen:", "tokens": ["Wann", "sie", "ihr", "und", "des", "Rei\u00b7ches", "Ruh", "er\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.80": {"text": "Wann die Freyheit sie sch\u00fctzen mit dem Degen:", "tokens": ["Wann", "die", "Frey\u00b7heit", "sie", "sch\u00fct\u00b7zen", "mit", "dem", "De\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.81": {"text": "Wann zu Gott sie durch sein Wort gehn und treten,", "tokens": ["Wann", "zu", "Gott", "sie", "durch", "sein", "Wort", "gehn", "und", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "KON", "VVFIN", "$,"], "meter": "--+----+-+-", "measure": "anapaest.init"}, "line.82": {"text": "Wann sie Prediger heissen lehrn und beten.", "tokens": ["Wann", "sie", "Pre\u00b7di\u00b7ger", "heis\u00b7sen", "lehrn", "und", "be\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "VVINF", "KON", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.83": {"text": "Wann sie Reichst\u00e4g schliessen und drob halten,", "tokens": ["Wann", "sie", "Reichs\u00b7t\u00e4g", "schlies\u00b7sen", "und", "drob", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVINF", "KON", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.84": {"text": "Wann sie Ehrsucht und Feindschafft nicht kan spalten.", "tokens": ["Wann", "sie", "Ehr\u00b7sucht", "und", "Feind\u00b7schafft", "nicht", "kan", "spal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.85": {"text": "Kurtz: wer unter den Menschen sich im Leben", "tokens": ["Kurtz", ":", "wer", "un\u00b7ter", "den", "Men\u00b7schen", "sich", "im", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$.", "PWS", "APPR", "ART", "NN", "PRF", "APPRART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.86": {"text": "\u00dcber Menschliche Dinge wil erheben,", "tokens": ["\u00dc\u00b7ber", "Menschli\u00b7che", "Din\u00b7ge", "wil", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.87": {"text": "Und, da\u00df er sey ein rechter Mensch, erweisen,", "tokens": ["Und", ",", "da\u00df", "er", "sey", "ein", "rech\u00b7ter", "Mensch", ",", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.88": {"text": "Mu\u00df die Strasse, sonst ist er kein Mensch, reisen.", "tokens": ["Mu\u00df", "die", "Stras\u00b7se", ",", "sonst", "ist", "er", "kein", "Mensch", ",", "rei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "$,", "ADV", "VAFIN", "PPER", "PIAT", "NN", "$,", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.89": {"text": "Beyde haben im Hertzen und im Munde", "tokens": ["Bey\u00b7de", "ha\u00b7ben", "im", "Hert\u00b7zen", "und", "im", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPRART", "NN", "KON", "APPRART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.90": {"text": "Jene Schrifft, die Natur die zu dem Grunde.", "tokens": ["Je\u00b7ne", "Schrifft", ",", "die", "Na\u00b7tur", "die", "zu", "dem", "Grun\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "ART", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.91": {"text": "Es geht beyder Grund, drauf kanst du dich schrauben:", "tokens": ["Es", "geht", "bey\u00b7der", "Grund", ",", "drauf", "kanst", "du", "dich", "schrau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "PAV", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.92": {"text": "Der Natur auf Verstehn, der Schrifft auf Glauben.", "tokens": ["Der", "Na\u00b7tur", "auf", "Ver\u00b7stehn", ",", "der", "Schrifft", "auf", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.93": {"text": "Ey nu /:wem auch wol solten sie sonst feyern:/", "tokens": ["Ey", "nu", "/", ":", "wem", "auch", "wol", "sol\u00b7ten", "sie", "sonst", "fey\u00b7ern", ":/"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["NN", "ADV", "$(", "$.", "PWS", "ADV", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.94": {"text": "Wie die Tichter, was sie voll Gottheit leyern:", "tokens": ["Wie", "die", "Tich\u00b7ter", ",", "was", "sie", "voll", "Got\u00b7theit", "ley\u00b7ern", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "--+---+--+-", "measure": "iambic.tri.relaxed"}, "line.95": {"text": "Wie die Sternfreunde, was sie sehn durch Scheiben:", "tokens": ["Wie", "die", "Stern\u00b7freun\u00b7de", ",", "was", "sie", "sehn", "durch", "Schei\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.96": {"text": "Wie die Schauer, was sie erfahrn und schreiben:", "tokens": ["Wie", "die", "Schau\u00b7er", ",", "was", "sie", "er\u00b7fahrn", "und", "schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.97": {"text": "Wie die FeldMesser, was die St\u00e4be tragen:", "tokens": ["Wie", "die", "Feld", "Mes\u00b7ser", ",", "was", "die", "St\u00e4\u00b7be", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.98": {"text": "Wie die RechMeister, was sie \u00fcberschlagen:", "tokens": ["Wie", "die", "Rech", "Meis\u00b7ter", ",", "was", "sie", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NE", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.99": {"text": "Wie die Priester, was sie im Geiste schauen:", "tokens": ["Wie", "die", "Pries\u00b7ter", ",", "was", "sie", "im", "Geis\u00b7te", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.100": {"text": "Wie die Richter, was sie vor Urtheil bauen:", "tokens": ["Wie", "die", "Rich\u00b7ter", ",", "was", "sie", "vor", "Ur\u00b7theil", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.101": {"text": "Wie die Aertzte, was sie bedachtsam suchen,", "tokens": ["Wie", "die", "A\u00b7ertz\u00b7te", ",", "was", "sie", "be\u00b7dacht\u00b7sam", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$,"], "meter": "---+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.102": {"text": "Und aus Kra\u00fctern, aus Ertzt, aus Thieren kochen:", "tokens": ["Und", "aus", "Kr\u00b7a\u00fc\u00b7tern", ",", "aus", "Ertzt", ",", "aus", "Thie\u00b7ren", "ko\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.103": {"text": "Euch dem OberHaupt und nach dem Wort Zeichen", "tokens": ["Euch", "dem", "O\u00b7ber", "Haupt", "und", "nach", "dem", "Wort", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "NN", "KON", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.104": {"text": "Dem Schmackhafften in der Gesellschafft reichen:", "tokens": ["Dem", "Schmack\u00b7haff\u00b7ten", "in", "der", "Ge\u00b7sell\u00b7schafft", "rei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-++-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.105": {"text": "Hertzog: Also nehmt nach den Reichs Gesch\u00e4fften,", "tokens": ["Hert\u00b7zog", ":", "Al\u00b7so", "nehmt", "nach", "den", "Reichs", "Ge\u00b7sch\u00e4ff\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "++--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.106": {"text": "Nach des Weinmarschen Hauses Zier und Kr\u00e4fften:", "tokens": ["Nach", "des", "Wein\u00b7mar\u00b7schen", "Hau\u00b7ses", "Zier", "und", "Kr\u00e4ff\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.107": {"text": "Nach dem Gottesdienst und den heilgen Stunden.", "tokens": ["Nach", "dem", "Got\u00b7tes\u00b7dienst", "und", "den", "heil\u00b7gen", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.108": {"text": "Etwa: wie auf der Bahn das Wild von Hunden,", "tokens": ["Et\u00b7wa", ":", "wie", "auf", "der", "Bahn", "das", "Wild", "von", "Hun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PWAV", "APPR", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.109": {"text": "Wie die Blumen im Garten von den Reisen:", "tokens": ["Wie", "die", "Blu\u00b7men", "im", "Gar\u00b7ten", "von", "den", "Rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.110": {"text": "Wie die Fr\u00fccht auf der Taffel nach den Speisen:", "tokens": ["Wie", "die", "Fr\u00fccht", "auf", "der", "Taf\u00b7fel", "nach", "den", "Spei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.111": {"text": "Das ist: wie es beliebt: die weisen Lehren.", "tokens": ["Das", "ist", ":", "wie", "es", "be\u00b7liebt", ":", "die", "wei\u00b7sen", "Leh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$.", "PWAV", "PPER", "ADJD", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.112": {"text": "Nehmt, und g\u00f6nnt mir die Ehr, Euch so zu ehren.", "tokens": ["Nehmt", ",", "und", "g\u00f6nnt", "mir", "die", "Ehr", ",", "Euch", "so", "zu", "eh\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.113": {"text": "Es sol Euer Land drum wie Raute stehen,", "tokens": ["Es", "sol", "Eu\u00b7er", "Land", "drum", "wie", "Rau\u00b7te", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PAV", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.114": {"text": "Euer Haus wie der Palmbaum sich erh\u00f6hen,", "tokens": ["Eu\u00b7er", "Haus", "wie", "der", "Palm\u00b7baum", "sich", "er\u00b7h\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.115": {"text": "Euer Hoff von gelehrten Leuten gl\u00e4ntzen,", "tokens": ["Eu\u00b7er", "Hoff", "von", "ge\u00b7lehr\u00b7ten", "Leu\u00b7ten", "gl\u00e4nt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.116": {"text": "Euer Ruhm mit der Welt die Wette gr\u00e4ntzen.", "tokens": ["Eu\u00b7er", "Ruhm", "mit", "der", "Welt", "die", "Wet\u00b7te", "gr\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.117": {"text": "Ja es wird der Geburtstamm Eurer Printzen", "tokens": ["Ja", "es", "wird", "der", "Ge\u00b7burt\u00b7stamm", "Eu\u00b7rer", "Print\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.118": {"text": "Vor der Sonnen Gewalt am minsten blintzen:", "tokens": ["Vor", "der", "Son\u00b7nen", "Ge\u00b7walt", "am", "mins\u00b7ten", "blint\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.119": {"text": "Er wird mitten in Sie die Augen werffen,", "tokens": ["Er", "wird", "mit\u00b7ten", "in", "Sie", "die", "Au\u00b7gen", "werf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.120": {"text": "Und nach Adlers Art sein in Euren sch\u00e4rffen.", "tokens": ["Und", "nach", "Ad\u00b7lers", "Art", "sein", "in", "Eu\u00b7ren", "sch\u00e4rf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "PPOSAT", "APPR", "PPOSAT", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.121": {"text": "Wol: Ich sehe wie sie voll Gottheit brennen:", "tokens": ["Wol", ":", "Ich", "se\u00b7he", "wie", "sie", "voll", "Got\u00b7theit", "bren\u00b7nen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VVFIN", "KOKOM", "PPER", "ADJD", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.122": {"text": "Beyde Strassen mit freyen Z\u00fcgeln rennen:", "tokens": ["Bey\u00b7de", "Stras\u00b7sen", "mit", "frey\u00b7en", "Z\u00fc\u00b7geln", "ren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.123": {"text": "So die Schrifft und dann die Natur gebrochen,", "tokens": ["So", "die", "Schrifft", "und", "dann", "die", "Na\u00b7tur", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.124": {"text": "Jen in Gott, in der Welt ist die zu suchen:", "tokens": ["Jen", "in", "Gott", ",", "in", "der", "Welt", "ist", "die", "zu", "su\u00b7chen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$,", "APPR", "ART", "NN", "VAFIN", "ART", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.125": {"text": "Jene Seeligkeit, die kan Wei\u00dfheit geben,", "tokens": ["Je\u00b7ne", "See\u00b7lig\u00b7keit", ",", "die", "kan", "Wei\u00df\u00b7heit", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PRELS", "VMFIN", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.126": {"text": "\u00dcber F\u00fcrsten ein iedre F\u00fcrsten heben.", "tokens": ["\u00dc\u00b7ber", "F\u00fcrs\u00b7ten", "ein", "ie\u00b7dre", "F\u00fcrs\u00b7ten", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.127": {"text": "Gut: der Wei\u00dfheit in der Natur nachschlagen:", "tokens": ["Gut", ":", "der", "Wei\u00df\u00b7heit", "in", "der", "Na\u00b7tur", "nach\u00b7schla\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.128": {"text": "Besser: Seeligkeit in der Schrifft erfragen:", "tokens": ["Bes\u00b7ser", ":", "See\u00b7lig\u00b7keit", "in", "der", "Schrifft", "er\u00b7fra\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.129": {"text": "An dem besten: Natur und Schrifft vergleichen,", "tokens": ["An", "dem", "bes\u00b7ten", ":", "Na\u00b7tur", "und", "Schrifft", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "NN", "KON", "NN", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.130": {"text": "Als der g\u00f6ttlichen Wahrheit feste Zeichen.", "tokens": ["Als", "der", "g\u00f6tt\u00b7li\u00b7chen", "Wahr\u00b7heit", "fes\u00b7te", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.131": {"text": "Und nichts weis', als was seelig ist, erkennen,", "tokens": ["Und", "nichts", "weis'", ",", "als", "was", "see\u00b7lig", "ist", ",", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "PTKVZ", "$,", "KOUS", "PIS", "ADJD", "VAFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.132": {"text": "Und nichts seelig, als was da weis' ist, nennen:", "tokens": ["Und", "nichts", "see\u00b7lig", ",", "als", "was", "da", "weis'", "ist", ",", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "$,", "KOUS", "PIS", "ADV", "VVFIN", "VAFIN", "$,", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.133": {"text": "Beyder Grund ist Gott f\u00fcrchten und Gott ehren:", "tokens": ["Bey\u00b7der", "Grund", "ist", "Gott", "f\u00fcrch\u00b7ten", "und", "Gott", "eh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "NN", "VVINF", "KON", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.134": {"text": "Den zeig ich der Gesellschaft in den LEHREN.", "tokens": ["Den", "zeig", "ich", "der", "Ge\u00b7sell\u00b7schaft", "in", "den", "LeH\u00b7REN", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}