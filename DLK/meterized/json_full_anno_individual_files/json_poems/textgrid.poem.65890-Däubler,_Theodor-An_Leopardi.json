{"textgrid.poem.65890": {"metadata": {"author": {"name": "D\u00e4ubler, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "An Leopardi", "genre": "verse", "period": "N.A.", "pub_year": 1905, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Mittelmeeres Schwermut war dein Sagen,", "tokens": ["Des", "Mit\u00b7tel\u00b7mee\u00b7res", "Schwer\u00b7mut", "war", "dein", "Sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach der Versunkenheit verlorner Ruf;", "tokens": ["Nach", "der", "Ver\u00b7sun\u00b7ken\u00b7heit", "ver\u00b7lor\u00b7ner", "Ruf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Was Hellas wagte und Italien schuf,", "tokens": ["Was", "Hel\u00b7las", "wag\u00b7te", "und", "I\u00b7ta\u00b7li\u00b7en", "schuf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "KON", "NE", "VVFIN", "$,"], "meter": "-+-+--++--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Verwunderte das Herz durch altes Fragen:", "tokens": ["Ver\u00b7wun\u00b7der\u00b7te", "das", "Herz", "durch", "al\u00b7tes", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So dumpfe Sch\u00f6pfung, sprich, warum wir zagen?", "tokens": ["So", "dump\u00b7fe", "Sch\u00f6p\u00b7fung", ",", "sprich", ",", "wa\u00b7rum", "wir", "za\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADJD", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "O wo erweckt uns Helios' Rossehuf:", "tokens": ["O", "wo", "er\u00b7weckt", "uns", "He\u00b7lios'", "Ros\u00b7se\u00b7huf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "VVFIN", "PPER", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ersch\u00fctterte sind wir, ohne Beruf \u2013", "tokens": ["Er\u00b7sch\u00fct\u00b7ter\u00b7te", "sind", "wir", ",", "oh\u00b7ne", "Be\u00b7ruf", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "KOUI", "NN", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vielleicht die Wachsamen durch hartes Jagen?", "tokens": ["Viel\u00b7leicht", "die", "Wach\u00b7sa\u00b7men", "durch", "har\u00b7tes", "Ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Vollbrachtheit blieb mir S\u00fc\u00dfe unsrer Sprache,", "tokens": ["Voll\u00b7bracht\u00b7heit", "blieb", "mir", "S\u00fc\u00b7\u00dfe", "uns\u00b7rer", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die attische Vollendung in Florenz:", "tokens": ["Die", "at\u00b7ti\u00b7sche", "Vol\u00b7len\u00b7dung", "in", "Flo\u00b7renz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ilisos, durch des Dichters Mund, als Ache,", "tokens": ["I\u00b7li\u00b7sos", ",", "durch", "des", "Dich\u00b7ters", "Mund", ",", "als", "A\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "NN", "NN", "$,", "KOUS", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Voll \u00dcbersch\u00e4umungsmut zu j\u00fcngstem Lenz;", "tokens": ["Voll", "\u00dc\u00b7bersc\u00b7h\u00e4u\u00b7mungs\u00b7mut", "zu", "j\u00fcngs\u00b7tem", "Lenz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch Blut, mein Blut, wie weit ist uns die Brache", "tokens": ["Doch", "Blut", ",", "mein", "Blut", ",", "wie", "weit", "ist", "uns", "die", "Bra\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PPOSAT", "NN", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 Ein Schweigen naht \u2013 gesungne Ahnung kennts.", "tokens": ["\u2013", "Ein", "Schwei\u00b7gen", "naht", "\u2013", "ge\u00b7sung\u00b7ne", "Ah\u00b7nung", "kennts", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "$(", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Des Mittelmeeres Schwermut war dein Sagen,", "tokens": ["Des", "Mit\u00b7tel\u00b7mee\u00b7res", "Schwer\u00b7mut", "war", "dein", "Sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach der Versunkenheit verlorner Ruf;", "tokens": ["Nach", "der", "Ver\u00b7sun\u00b7ken\u00b7heit", "ver\u00b7lor\u00b7ner", "Ruf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Was Hellas wagte und Italien schuf,", "tokens": ["Was", "Hel\u00b7las", "wag\u00b7te", "und", "I\u00b7ta\u00b7li\u00b7en", "schuf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "KON", "NE", "VVFIN", "$,"], "meter": "-+-+--++--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Verwunderte das Herz durch altes Fragen:", "tokens": ["Ver\u00b7wun\u00b7der\u00b7te", "das", "Herz", "durch", "al\u00b7tes", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "So dumpfe Sch\u00f6pfung, sprich, warum wir zagen?", "tokens": ["So", "dump\u00b7fe", "Sch\u00f6p\u00b7fung", ",", "sprich", ",", "wa\u00b7rum", "wir", "za\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "ADJD", "$,", "PWAV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "O wo erweckt uns Helios' Rossehuf:", "tokens": ["O", "wo", "er\u00b7weckt", "uns", "He\u00b7lios'", "Ros\u00b7se\u00b7huf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "VVFIN", "PPER", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ersch\u00fctterte sind wir, ohne Beruf \u2013", "tokens": ["Er\u00b7sch\u00fct\u00b7ter\u00b7te", "sind", "wir", ",", "oh\u00b7ne", "Be\u00b7ruf", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "KOUI", "NN", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vielleicht die Wachsamen durch hartes Jagen?", "tokens": ["Viel\u00b7leicht", "die", "Wach\u00b7sa\u00b7men", "durch", "har\u00b7tes", "Ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Vollbrachtheit blieb mir S\u00fc\u00dfe unsrer Sprache,", "tokens": ["Voll\u00b7bracht\u00b7heit", "blieb", "mir", "S\u00fc\u00b7\u00dfe", "uns\u00b7rer", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die attische Vollendung in Florenz:", "tokens": ["Die", "at\u00b7ti\u00b7sche", "Vol\u00b7len\u00b7dung", "in", "Flo\u00b7renz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$."], "meter": "-+--+---+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ilisos, durch des Dichters Mund, als Ache,", "tokens": ["I\u00b7li\u00b7sos", ",", "durch", "des", "Dich\u00b7ters", "Mund", ",", "als", "A\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ART", "NN", "NN", "$,", "KOUS", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Voll \u00dcbersch\u00e4umungsmut zu j\u00fcngstem Lenz;", "tokens": ["Voll", "\u00dc\u00b7bersc\u00b7h\u00e4u\u00b7mungs\u00b7mut", "zu", "j\u00fcngs\u00b7tem", "Lenz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch Blut, mein Blut, wie weit ist uns die Brache", "tokens": ["Doch", "Blut", ",", "mein", "Blut", ",", "wie", "weit", "ist", "uns", "die", "Bra\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "PPOSAT", "NN", "$,", "PWAV", "ADJD", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u2013 Ein Schweigen naht \u2013 gesungne Ahnung kennts.", "tokens": ["\u2013", "Ein", "Schwei\u00b7gen", "naht", "\u2013", "ge\u00b7sung\u00b7ne", "Ah\u00b7nung", "kennts", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "$(", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}