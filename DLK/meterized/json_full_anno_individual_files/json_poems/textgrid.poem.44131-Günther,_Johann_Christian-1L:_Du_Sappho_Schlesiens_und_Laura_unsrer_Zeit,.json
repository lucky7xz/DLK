{"textgrid.poem.44131": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du Sappho Schlesiens und Laura unsrer Zeit,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du Sappho Schlesiens und Laura unsrer Zeit,", "tokens": ["Du", "Sap\u00b7pho", "Schle\u00b7si\u00b7ens", "und", "Lau\u00b7ra", "uns\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "NE", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Frau, deren seltner Trieb Geschlechtern Glanz verleiht", "tokens": ["Frau", ",", "de\u00b7ren", "selt\u00b7ner", "Trieb", "Ge\u00b7schlech\u00b7tern", "Glanz", "ver\u00b7leiht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELAT", "ADJA", "NN", "NN", "NN", "VVFIN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und deren am Parna\u00df geh\u00e4ufte Vorzugsgaben", "tokens": ["Und", "de\u00b7ren", "am", "Par\u00b7na\u00df", "ge\u00b7h\u00e4uf\u00b7te", "Vor\u00b7zugs\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "APPRART", "NE", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der Nachwelt Eifersucht mit Ruhm zu hofen haben,", "tokens": ["Der", "Nach\u00b7welt", "Ei\u00b7fer\u00b7sucht", "mit", "Ruhm", "zu", "ho\u00b7fen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NN", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gelehrte Bre\u00dflerin, ach biethe mir ein Theil", "tokens": ["Ge\u00b7lehr\u00b7te", "Bre\u00df\u00b7le\u00b7rin", ",", "ach", "bie\u00b7the", "mir", "ein", "Theil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "ITJ", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von deinem \u00dcberflu\u00df in netten Reimen feil", "tokens": ["Von", "dei\u00b7nem", "\u00dc\u00b7berf\u00b7lu\u00df", "in", "net\u00b7ten", "Rei\u00b7men", "feil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und lehre mich anjezt mit holden Gnadenblicken", "tokens": ["Und", "leh\u00b7re", "mich", "an\u00b7jezt", "mit", "hol\u00b7den", "Gna\u00b7den\u00b7bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Die Kunst, das, was man denckt, nat\u00fcrlich auszudr\u00fccken.", "tokens": ["Die", "Kunst", ",", "das", ",", "was", "man", "denckt", ",", "na\u00b7t\u00fcr\u00b7lich", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "$,", "PRELS", "PIS", "VVFIN", "$,", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich bitt es nicht vor mich, es geht dein Lob mit an,", "tokens": ["Ich", "bitt", "es", "nicht", "vor", "mich", ",", "es", "geht", "dein", "Lob", "mit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPER", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Damit ich nehmlich nur geschickt erkl\u00e4ren kan,", "tokens": ["Da\u00b7mit", "ich", "nehm\u00b7lich", "nur", "ge\u00b7schickt", "er\u00b7kl\u00e4\u00b7ren", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Welch ehrfurchtsvolle Lust mich jenen Tag entz\u00fcckte,", "tokens": ["Welch", "ehr\u00b7furchts\u00b7vol\u00b7le", "Lust", "mich", "je\u00b7nen", "Tag", "ent\u00b7z\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "An dem dein guldner Mund mein truncknes Ohr erquickte.", "tokens": ["An", "dem", "dein", "guld\u00b7ner", "Mund", "mein", "trunck\u00b7nes", "Ohr", "er\u00b7quick\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Man lud mich unverdient zu deiner Tafel ein,", "tokens": ["Man", "lud", "mich", "un\u00b7ver\u00b7di\u00b7ent", "zu", "dei\u00b7ner", "Ta\u00b7fel", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Dein Wiz vers\u00fc\u00dfte mir den aufgedrungnen Wein,", "tokens": ["Dein", "Wiz", "ver\u00b7s\u00fc\u00df\u00b7te", "mir", "den", "auf\u00b7ge\u00b7drung\u00b7nen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der an und vor sich selbst das Blut zu fl\u00fcgeln wuste", "tokens": ["Der", "an", "und", "vor", "sich", "selbst", "das", "Blut", "zu", "fl\u00fc\u00b7geln", "wus\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKVZ", "KON", "APPR", "PRF", "ADV", "ART", "NN", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und deinem Feuer doch an Adel weichen muste.", "tokens": ["Und", "dei\u00b7nem", "Feu\u00b7er", "doch", "an", "A\u00b7del", "wei\u00b7chen", "mus\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der G\u00fcrthel, den Homer der Venus angedicht,", "tokens": ["Der", "G\u00fcr\u00b7thel", ",", "den", "Ho\u00b7mer", "der", "Ve\u00b7nus", "an\u00b7ge\u00b7dicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "War blos von Z\u00e4rtligkeit und Anmuth zugericht;", "tokens": ["War", "blos", "von", "Z\u00e4rt\u00b7lig\u00b7keit", "und", "An\u00b7muth", "zu\u00b7ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Mich deucht, du habest ihn in unsrer Zeit gefunden", "tokens": ["Mich", "deucht", ",", "du", "ha\u00b7best", "ihn", "in", "uns\u00b7rer", "Zeit", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und jeden Reim damit der Ewigkeit verbunden.", "tokens": ["Und", "je\u00b7den", "Reim", "da\u00b7mit", "der", "E\u00b7wig\u00b7keit", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Vermehrte Socrates durch Lehr und Wi\u00dfenschaft", "tokens": ["Ver\u00b7mehr\u00b7te", "So\u00b7cra\u00b7tes", "durch", "Lehr", "und", "Wi\u00b7\u00dfen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "Bey G\u00e4sten manche Nacht der Speisen Werth und Kraft,", "tokens": ["Bey", "G\u00e4s\u00b7ten", "man\u00b7che", "Nacht", "der", "Spei\u00b7sen", "Werth", "und", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So war . . . dein Geschmack und Urtheil von dem Dichten", "tokens": ["So", "war", ".", ".", ".", "dein", "Ge\u00b7schmack", "und", "Ur\u00b7theil", "von", "dem", "Dich\u00b7ten"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$.", "$.", "$.", "PPOSAT", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Das allerherrlichste von allen Schaugerichten.", "tokens": ["Das", "al\u00b7ler\u00b7herr\u00b7lichs\u00b7te", "von", "al\u00b7len", "Schau\u00b7ge\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Liebe, wie man sagt, kam zwischen Salz und Meer", "tokens": ["Die", "Lie\u00b7be", ",", "wie", "man", "sagt", ",", "kam", "zwi\u00b7schen", "Salz", "und", "Meer"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Von Saamen aus der H\u00f6h aus Thau und Muschel her;", "tokens": ["Von", "Saa\u00b7men", "aus", "der", "H\u00f6h", "aus", "Thau", "und", "Mu\u00b7schel", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Nun scheint die Fabel wahr, da Wei\u00dfheit und Vergn\u00fcgen", "tokens": ["Nun", "scheint", "die", "Fa\u00b7bel", "wahr", ",", "da", "Wei\u00df\u00b7heit", "und", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Sich als ein Himmelskind in deinem Wappen wiegen.", "tokens": ["Sich", "als", "ein", "Him\u00b7mel\u00b7skind", "in", "dei\u00b7nem", "Wap\u00b7pen", "wie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So wie kein Reisender, der blos nach Wundern zieht,", "tokens": ["So", "wie", "kein", "Rei\u00b7sen\u00b7der", ",", "der", "blos", "nach", "Wun\u00b7dern", "zieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIAT", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "In manchem Cabinet viel Kostbarkeiten sieht,", "tokens": ["In", "man\u00b7chem", "Ca\u00b7bi\u00b7net", "viel", "Kost\u00b7bar\u00b7kei\u00b7ten", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NE", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wo Meng und Pracht und Werth den m\u00fcden Blick erg\u00f6zen,", "tokens": ["Wo", "Meng", "und", "Pracht", "und", "Werth", "den", "m\u00fc\u00b7den", "Blick", "er\u00b7g\u00f6\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Auf einmal f\u00e4hig ist, sie ordentlich zu sch\u00e4zen,", "tokens": ["Auf", "ein\u00b7mal", "f\u00e4\u00b7hig", "ist", ",", "sie", "or\u00b7dent\u00b7lich", "zu", "sch\u00e4\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "VAFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Doch nachmahls, wenn die Nacht sein Haupt zu Bette legt,", "tokens": ["Doch", "nach\u00b7mahls", ",", "wenn", "die", "Nacht", "sein", "Haupt", "zu", "Bet\u00b7te", "legt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Im Finstern bey sich selbst des Tages Lust erwegt", "tokens": ["Im", "Fins\u00b7tern", "bey", "sich", "selbst", "des", "Ta\u00b7ges", "Lust", "er\u00b7wegt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "PRF", "ADV", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und dann, soviel auch nur Schlaf und Ged\u00e4chtn\u00fc\u00df leidet,", "tokens": ["Und", "dann", ",", "so\u00b7viel", "auch", "nur", "Schlaf", "und", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "lei\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "ADV", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "Die Bilder wiederholt und be\u00dfer unterscheidet", "tokens": ["Die", "Bil\u00b7der", "wie\u00b7der\u00b7holt", "und", "be\u00b7\u00dfer", "un\u00b7ter\u00b7schei\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "KON", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.38": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.2": {"line.1": {"text": "Du Sappho Schlesiens und Laura unsrer Zeit,", "tokens": ["Du", "Sap\u00b7pho", "Schle\u00b7si\u00b7ens", "und", "Lau\u00b7ra", "uns\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "NE", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Frau, deren seltner Trieb Geschlechtern Glanz verleiht", "tokens": ["Frau", ",", "de\u00b7ren", "selt\u00b7ner", "Trieb", "Ge\u00b7schlech\u00b7tern", "Glanz", "ver\u00b7leiht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELAT", "ADJA", "NN", "NN", "NN", "VVFIN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und deren am Parna\u00df geh\u00e4ufte Vorzugsgaben", "tokens": ["Und", "de\u00b7ren", "am", "Par\u00b7na\u00df", "ge\u00b7h\u00e4uf\u00b7te", "Vor\u00b7zugs\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "APPRART", "NE", "ADJA", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der Nachwelt Eifersucht mit Ruhm zu hofen haben,", "tokens": ["Der", "Nach\u00b7welt", "Ei\u00b7fer\u00b7sucht", "mit", "Ruhm", "zu", "ho\u00b7fen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NN", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gelehrte Bre\u00dflerin, ach biethe mir ein Theil", "tokens": ["Ge\u00b7lehr\u00b7te", "Bre\u00df\u00b7le\u00b7rin", ",", "ach", "bie\u00b7the", "mir", "ein", "Theil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "ITJ", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von deinem \u00dcberflu\u00df in netten Reimen feil", "tokens": ["Von", "dei\u00b7nem", "\u00dc\u00b7berf\u00b7lu\u00df", "in", "net\u00b7ten", "Rei\u00b7men", "feil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und lehre mich anjezt mit holden Gnadenblicken", "tokens": ["Und", "leh\u00b7re", "mich", "an\u00b7jezt", "mit", "hol\u00b7den", "Gna\u00b7den\u00b7bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Die Kunst, das, was man denckt, nat\u00fcrlich auszudr\u00fccken.", "tokens": ["Die", "Kunst", ",", "das", ",", "was", "man", "denckt", ",", "na\u00b7t\u00fcr\u00b7lich", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "$,", "PRELS", "PIS", "VVFIN", "$,", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich bitt es nicht vor mich, es geht dein Lob mit an,", "tokens": ["Ich", "bitt", "es", "nicht", "vor", "mich", ",", "es", "geht", "dein", "Lob", "mit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPER", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Damit ich nehmlich nur geschickt erkl\u00e4ren kan,", "tokens": ["Da\u00b7mit", "ich", "nehm\u00b7lich", "nur", "ge\u00b7schickt", "er\u00b7kl\u00e4\u00b7ren", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Welch ehrfurchtsvolle Lust mich jenen Tag entz\u00fcckte,", "tokens": ["Welch", "ehr\u00b7furchts\u00b7vol\u00b7le", "Lust", "mich", "je\u00b7nen", "Tag", "ent\u00b7z\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "An dem dein guldner Mund mein truncknes Ohr erquickte.", "tokens": ["An", "dem", "dein", "guld\u00b7ner", "Mund", "mein", "trunck\u00b7nes", "Ohr", "er\u00b7quick\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Man lud mich unverdient zu deiner Tafel ein,", "tokens": ["Man", "lud", "mich", "un\u00b7ver\u00b7di\u00b7ent", "zu", "dei\u00b7ner", "Ta\u00b7fel", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Dein Wiz vers\u00fc\u00dfte mir den aufgedrungnen Wein,", "tokens": ["Dein", "Wiz", "ver\u00b7s\u00fc\u00df\u00b7te", "mir", "den", "auf\u00b7ge\u00b7drung\u00b7nen", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der an und vor sich selbst das Blut zu fl\u00fcgeln wuste", "tokens": ["Der", "an", "und", "vor", "sich", "selbst", "das", "Blut", "zu", "fl\u00fc\u00b7geln", "wus\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PTKVZ", "KON", "APPR", "PRF", "ADV", "ART", "NN", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und deinem Feuer doch an Adel weichen muste.", "tokens": ["Und", "dei\u00b7nem", "Feu\u00b7er", "doch", "an", "A\u00b7del", "wei\u00b7chen", "mus\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der G\u00fcrthel, den Homer der Venus angedicht,", "tokens": ["Der", "G\u00fcr\u00b7thel", ",", "den", "Ho\u00b7mer", "der", "Ve\u00b7nus", "an\u00b7ge\u00b7dicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "War blos von Z\u00e4rtligkeit und Anmuth zugericht;", "tokens": ["War", "blos", "von", "Z\u00e4rt\u00b7lig\u00b7keit", "und", "An\u00b7muth", "zu\u00b7ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Mich deucht, du habest ihn in unsrer Zeit gefunden", "tokens": ["Mich", "deucht", ",", "du", "ha\u00b7best", "ihn", "in", "uns\u00b7rer", "Zeit", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und jeden Reim damit der Ewigkeit verbunden.", "tokens": ["Und", "je\u00b7den", "Reim", "da\u00b7mit", "der", "E\u00b7wig\u00b7keit", "ver\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Vermehrte Socrates durch Lehr und Wi\u00dfenschaft", "tokens": ["Ver\u00b7mehr\u00b7te", "So\u00b7cra\u00b7tes", "durch", "Lehr", "und", "Wi\u00b7\u00dfen\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "Bey G\u00e4sten manche Nacht der Speisen Werth und Kraft,", "tokens": ["Bey", "G\u00e4s\u00b7ten", "man\u00b7che", "Nacht", "der", "Spei\u00b7sen", "Werth", "und", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "So war . . . dein Geschmack und Urtheil von dem Dichten", "tokens": ["So", "war", ".", ".", ".", "dein", "Ge\u00b7schmack", "und", "Ur\u00b7theil", "von", "dem", "Dich\u00b7ten"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$.", "$.", "$.", "PPOSAT", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Das allerherrlichste von allen Schaugerichten.", "tokens": ["Das", "al\u00b7ler\u00b7herr\u00b7lichs\u00b7te", "von", "al\u00b7len", "Schau\u00b7ge\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Liebe, wie man sagt, kam zwischen Salz und Meer", "tokens": ["Die", "Lie\u00b7be", ",", "wie", "man", "sagt", ",", "kam", "zwi\u00b7schen", "Salz", "und", "Meer"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Von Saamen aus der H\u00f6h aus Thau und Muschel her;", "tokens": ["Von", "Saa\u00b7men", "aus", "der", "H\u00f6h", "aus", "Thau", "und", "Mu\u00b7schel", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Nun scheint die Fabel wahr, da Wei\u00dfheit und Vergn\u00fcgen", "tokens": ["Nun", "scheint", "die", "Fa\u00b7bel", "wahr", ",", "da", "Wei\u00df\u00b7heit", "und", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Sich als ein Himmelskind in deinem Wappen wiegen.", "tokens": ["Sich", "als", "ein", "Him\u00b7mel\u00b7skind", "in", "dei\u00b7nem", "Wap\u00b7pen", "wie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So wie kein Reisender, der blos nach Wundern zieht,", "tokens": ["So", "wie", "kein", "Rei\u00b7sen\u00b7der", ",", "der", "blos", "nach", "Wun\u00b7dern", "zieht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIAT", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "In manchem Cabinet viel Kostbarkeiten sieht,", "tokens": ["In", "man\u00b7chem", "Ca\u00b7bi\u00b7net", "viel", "Kost\u00b7bar\u00b7kei\u00b7ten", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NE", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Wo Meng und Pracht und Werth den m\u00fcden Blick erg\u00f6zen,", "tokens": ["Wo", "Meng", "und", "Pracht", "und", "Werth", "den", "m\u00fc\u00b7den", "Blick", "er\u00b7g\u00f6\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "KON", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Auf einmal f\u00e4hig ist, sie ordentlich zu sch\u00e4zen,", "tokens": ["Auf", "ein\u00b7mal", "f\u00e4\u00b7hig", "ist", ",", "sie", "or\u00b7dent\u00b7lich", "zu", "sch\u00e4\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "VAFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Doch nachmahls, wenn die Nacht sein Haupt zu Bette legt,", "tokens": ["Doch", "nach\u00b7mahls", ",", "wenn", "die", "Nacht", "sein", "Haupt", "zu", "Bet\u00b7te", "legt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Im Finstern bey sich selbst des Tages Lust erwegt", "tokens": ["Im", "Fins\u00b7tern", "bey", "sich", "selbst", "des", "Ta\u00b7ges", "Lust", "er\u00b7wegt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "PRF", "ADV", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und dann, soviel auch nur Schlaf und Ged\u00e4chtn\u00fc\u00df leidet,", "tokens": ["Und", "dann", ",", "so\u00b7viel", "auch", "nur", "Schlaf", "und", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "lei\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "ADV", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "Die Bilder wiederholt und be\u00dfer unterscheidet", "tokens": ["Die", "Bil\u00b7der", "wie\u00b7der\u00b7holt", "und", "be\u00b7\u00dfer", "un\u00b7ter\u00b7schei\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "KON", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.38": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}}}}