{"dta.poem.21784": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "Ix.  \n  Die gr\u00f6ste Beschwerligkeit/ die  \n Liebe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Mjt Lieben ist es so beschaffen:", "tokens": ["Mjt", "Lie\u00b7ben", "ist", "es", "so", "be\u00b7schaf\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "du must dich offters lassen straffen/", "tokens": ["du", "must", "dich", "off\u00b7ters", "las\u00b7sen", "straf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "dein Ernst mu\u00df Spott und Tohrheit sein.", "tokens": ["dein", "Ernst", "mu\u00df", "Spott", "und", "Tohr\u00b7heit", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du must dich so/ bald anders stellen.", "tokens": ["Du", "must", "dich", "so", "/", "bald", "an\u00b7ders", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "$(", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Redtstu vom Himmel/ sie spricht: Nein/", "tokens": ["Redt\u00b7stu", "vom", "Him\u00b7mel", "/", "sie", "spricht", ":", "Nein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$(", "PPER", "VVFIN", "$.", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kein ruhig Leben kanstu f\u00fchren/", "tokens": ["Kein", "ru\u00b7hig", "Le\u00b7ben", "kans\u00b7tu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "du must dich selbst in dir verlieren/", "tokens": ["du", "must", "dich", "selbst", "in", "dir", "ver\u00b7lie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "must lebend-todt/ todt-lebend sein.", "tokens": ["must", "le\u00b7ben\u00b7dtodt", "/", "todt\u00b7le\u00b7bend", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "$(", "ADJD", "VAINF", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "du darffst nicht/ was dir gut d\u00fcnkt/ sagen", "tokens": ["du", "darffst", "nicht", "/", "was", "dir", "gut", "d\u00fcnkt", "/", "sa\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "PPER", "ADJD", "VVFIN", "$(", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "bew\u00e4hrstu da\u00df und sie spricht Nein/", "tokens": ["be\u00b7w\u00e4hrs\u00b7tu", "da\u00df", "und", "sie", "spricht", "Nein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "KON", "PPER", "VVFIN", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dein Tag vergeht in Noth und Plagen/", "tokens": ["Dein", "Tag", "ver\u00b7geht", "in", "Noth", "und", "Pla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die Nacht verschwindet dir mit Klagen/", "tokens": ["die", "Nacht", "ver\u00b7schwin\u00b7det", "dir", "mit", "Kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du kanst nicht schlaff-nicht wacheno sein", "tokens": ["du", "kanst", "nicht", "schlaff\u00b7nicht", "wa\u00b7che\u00b7no", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADJD", "NE", "PPOSAT"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "hast du dich eins der Lieb\u2019 ergeben", "tokens": ["hast", "du", "dich", "eins", "der", "Lieb'", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "PIS", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und meinest froh zu sein. Ach nein!", "tokens": ["und", "mei\u00b7nest", "froh", "zu", "sein", ".", "Ach", "nein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PTKZU", "VAINF", "$.", "NN", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die Lieb ist mir ein Marterleben.", "tokens": ["die", "Lieb", "ist", "mir", "ein", "Mar\u00b7ter\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Offt mustu vor die Pforten nachten/", "tokens": ["Offt", "mus\u00b7tu", "vor", "die", "Pfor\u00b7ten", "nach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "must Regen/ Frost und Schnee verachten/", "tokens": ["must", "Re\u00b7gen", "/", "Frost", "und", "Schnee", "ver\u00b7ach\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "$(", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "must leiden und geduldig sein.", "tokens": ["must", "lei\u00b7den", "und", "ge\u00b7dul\u00b7dig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00f6rt sie dich an mit tauben Ohren;", "tokens": ["H\u00f6rt", "sie", "dich", "an", "mit", "tau\u00b7ben", "Oh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PRF", "APPR", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verdru\u00df hat manchen Raub verlohren.", "tokens": ["Ver\u00b7dru\u00df", "hat", "man\u00b7chen", "Raub", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Neider Zungen mustu lachen/", "tokens": ["Der", "Nei\u00b7der", "Zun\u00b7gen", "mus\u00b7tu", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "must allzeit dich Politisch machen/", "tokens": ["must", "all\u00b7zeit", "dich", "Po\u00b7li\u00b7tisch", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "NN", "VVINF", "$("], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.3": {"text": "in alle S\u00e4ttel eben sein.", "tokens": ["in", "al\u00b7le", "S\u00e4t\u00b7tel", "e\u00b7ben", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fragt iemand/ ob du diese liebest/", "tokens": ["Fragt", "ie\u00b7mand", "/", "ob", "du", "die\u00b7se", "lie\u00b7best", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$(", "KOUS", "PPER", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df du dich nicht mit ihr betr\u00fcbest.", "tokens": ["da\u00df", "du", "dich", "nicht", "mit", "ihr", "be\u00b7tr\u00fc\u00b7best", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was ihr gef\u00e4llet/ mustu preisen", "tokens": ["Was", "ihr", "ge\u00b7f\u00e4l\u00b7let", "/", "mus\u00b7tu", "prei\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "PPER", "VVPP", "$(", "VMFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und iederzeit dich so erweisen/", "tokens": ["und", "ie\u00b7der\u00b7zeit", "dich", "so", "er\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df du nicht ihr m\u00f6gst widrig sein.", "tokens": ["da\u00df", "du", "nicht", "ihr", "m\u00f6gst", "wid\u00b7rig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hastu von ihr was fliegen lassen/", "tokens": ["Has\u00b7tu", "von", "ihr", "was", "flie\u00b7gen", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "PIS", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sie befragt dich. Antwort: Nein", "tokens": ["und", "sie", "be\u00b7fragt", "dich", ".", "Ant\u00b7wort", ":", "Nein"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$.", "NN", "$.", "PTKANT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "damit sie dich nicht m\u00f6ge hassen.", "tokens": ["da\u00b7mit", "sie", "dich", "nicht", "m\u00f6\u00b7ge", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Spielt sie: so la\u00df sie nicht verlieren/", "tokens": ["Spielt", "sie", ":", "so", "la\u00df", "sie", "nicht", "ver\u00b7lie\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "VVIMP", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "nur dir wil der Verlust geb\u00fchren.", "tokens": ["nur", "dir", "wil", "der", "Ver\u00b7lust", "ge\u00b7b\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Dein Beutel mu\u00df stets offen sein/", "tokens": ["Dein", "Beu\u00b7tel", "mu\u00df", "stets", "of\u00b7fen", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "durch Lieben kan man wenig haben:", "tokens": ["durch", "Lie\u00b7ben", "kan", "man", "we\u00b7nig", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VMFIN", "PIS", "PIS", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "kein Kr\u00f6sus wirstu werden. Nein", "tokens": ["kein", "Kr\u00f6\u00b7sus", "wirs\u00b7tu", "wer\u00b7den", ".", "Nein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "NN", "VAFIN", "VAINF", "$.", "PTKANT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die Jungfern lieben Gold und Gaben.", "tokens": ["die", "Jung\u00b7fern", "lie\u00b7ben", "Gold", "und", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Heist sie dich sp\u00f6ttlich von sich gehen", "tokens": ["Heist", "sie", "dich", "sp\u00f6tt\u00b7lich", "von", "sich", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "ADJD", "APPR", "PRF", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "must dumm und unempfindlich sein.", "tokens": ["must", "dumm", "und", "un\u00b7emp\u00b7find\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auff ihr Verachten/ Schimpff und schelten", "tokens": ["Auff", "ihr", "Ver\u00b7ach\u00b7ten", "/", "Schimpff", "und", "schel\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$(", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mustu nicht z\u00fcrnen. Nein ach nein!", "tokens": ["mus\u00b7tu", "nicht", "z\u00fcr\u00b7nen", ".", "Nein", "ach", "nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVINF", "$.", "PTKANT", "ADV", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die Lieb\u2019 ist sonder St\u00fcrme selten.", "tokens": ["die", "Lieb'", "ist", "son\u00b7der", "St\u00fcr\u00b7me", "sel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der Hoffnung/ Sorge/ Furcht und Sehnen", "tokens": ["Der", "Hoff\u00b7nung", "/", "Sor\u00b7ge", "/", "Furcht", "und", "Seh\u00b7nen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "d\u00fcrffstu dich nimmer abgewehnen/", "tokens": ["d\u00fcrffs\u00b7tu", "dich", "nim\u00b7mer", "ab\u00b7ge\u00b7weh\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "must nimmer frey und deine sein.", "tokens": ["must", "nim\u00b7mer", "frey", "und", "dei\u00b7ne", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "KON", "PPOSAT", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Drumb wil ich nun vom Lieben lassen.", "tokens": ["Drumb", "wil", "ich", "nun", "vom", "Lie\u00b7ben", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wer kan die lieben Jungfern hassen?", "tokens": ["Wer", "kan", "die", "lie\u00b7ben", "Jung\u00b7fern", "has\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}