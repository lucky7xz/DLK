{"textgrid.poem.42797": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach, lieber Gott, gib, da\u00df sie nicht", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach, lieber Gott, gib, da\u00df sie nicht", "tokens": ["Ach", ",", "lie\u00b7ber", "Gott", ",", "gib", ",", "da\u00df", "sie", "nicht"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "NN", "$,", "VVIMP", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns aus der Wohnung jagen.", "tokens": ["Uns", "aus", "der", "Woh\u00b7nung", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was soll ich ihr denn noch sagen \u2013", "tokens": ["Was", "soll", "ich", "ihr", "denn", "noch", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Meiner Frau \u2013 in ihr verheultes Gesicht!?", "tokens": ["Mei\u00b7ner", "Frau", "\u2013", "in", "ihr", "ver\u00b7heul\u00b7tes", "Ge\u00b7sicht", "!?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "Ich ringe meine H\u00e4nde.", "tokens": ["Ich", "rin\u00b7ge", "mei\u00b7ne", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weil ich keinen Ausweg f\u00e4nde,", "tokens": ["Weil", "ich", "kei\u00b7nen", "Aus\u00b7weg", "f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn's eines Tags so wirklich w\u00e4r:", "tokens": ["Wenn's", "ei\u00b7nes", "Tags", "so", "wirk\u00b7lich", "w\u00e4r", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bett, Kleider, B\u00fccher, mein Sekret\u00e4r, \u2013", "tokens": ["Bett", ",", "Klei\u00b7der", ",", "B\u00fc\u00b7cher", ",", "mein", "Se\u00b7kre\u00b7t\u00e4r", ",", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "$,", "$("], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Da\u00df das auf der Stra\u00dfe st\u00e4nde.", "tokens": ["Da\u00df", "das", "auf", "der", "Stra\u00b7\u00dfe", "st\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Sollt ich's versetzen, verkaufen?", "tokens": ["Sollt", "ich's", "ver\u00b7set\u00b7zen", ",", "ver\u00b7kau\u00b7fen", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "$,", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Ist all doch n\u00f6tigstes Ger\u00e4t.", "tokens": ["Ist", "all", "doch", "n\u00f6\u00b7tigs\u00b7tes", "Ge\u00b7r\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir w\u00fcrden, einmal, die Not versaufen,", "tokens": ["Wir", "w\u00fcr\u00b7den", ",", "ein\u00b7mal", ",", "die", "Not", "ver\u00b7sau\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ADV", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und dann: Wer wei\u00df, was ich t\u00e4t.", "tokens": ["Und", "dann", ":", "Wer", "wei\u00df", ",", "was", "ich", "t\u00e4t", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PWS", "VVFIN", "$,", "PWS", "PPER", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Ich h\u00e4nge so an dem Bilde,", "tokens": ["Ich", "h\u00e4n\u00b7ge", "so", "an", "dem", "Bil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das noch von meiner Gro\u00dfmama stammt.", "tokens": ["Das", "noch", "von", "mei\u00b7ner", "Gro\u00df\u00b7ma\u00b7ma", "stammt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gott, gie\u00dfe doch etwas Milde", "tokens": ["Gott", ",", "gie\u00b7\u00dfe", "doch", "et\u00b7was", "Mil\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "ADV", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u00dcber das steinerne Wohnungsamt.", "tokens": ["\u00dc\u00b7ber", "das", "stei\u00b7ner\u00b7ne", "Woh\u00b7nungs\u00b7amt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Wie meine Frau die Nacht durchweint,", "tokens": ["Wie", "mei\u00b7ne", "Frau", "die", "Nacht", "durch\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das barmt durch all meine Tr\u00e4ume.", "tokens": ["Das", "barmt", "durch", "all", "mei\u00b7ne", "Tr\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Gott, la\u00df uns die lieben zwei R\u00e4ume", "tokens": ["Gott", ",", "la\u00df", "uns", "die", "lie\u00b7ben", "zwei", "R\u00e4u\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVIMP", "PPER", "ART", "ADJA", "CARD", "NN"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Mit der Sonne, die vormittags hinein scheint.", "tokens": ["Mit", "der", "Son\u00b7ne", ",", "die", "vor\u00b7mit\u00b7tags", "hin\u00b7ein", "scheint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$."], "meter": "--+----+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Ach, lieber Gott, gib, da\u00df sie nicht", "tokens": ["Ach", ",", "lie\u00b7ber", "Gott", ",", "gib", ",", "da\u00df", "sie", "nicht"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "NN", "$,", "VVIMP", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns aus der Wohnung jagen.", "tokens": ["Uns", "aus", "der", "Woh\u00b7nung", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was soll ich ihr denn noch sagen \u2013", "tokens": ["Was", "soll", "ich", "ihr", "denn", "noch", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Meiner Frau \u2013 in ihr verheultes Gesicht!?", "tokens": ["Mei\u00b7ner", "Frau", "\u2013", "in", "ihr", "ver\u00b7heul\u00b7tes", "Ge\u00b7sicht", "!?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.7": {"line.1": {"text": "Ich ringe meine H\u00e4nde.", "tokens": ["Ich", "rin\u00b7ge", "mei\u00b7ne", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weil ich keinen Ausweg f\u00e4nde,", "tokens": ["Weil", "ich", "kei\u00b7nen", "Aus\u00b7weg", "f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn's eines Tags so wirklich w\u00e4r:", "tokens": ["Wenn's", "ei\u00b7nes", "Tags", "so", "wirk\u00b7lich", "w\u00e4r", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bett, Kleider, B\u00fccher, mein Sekret\u00e4r, \u2013", "tokens": ["Bett", ",", "Klei\u00b7der", ",", "B\u00fc\u00b7cher", ",", "mein", "Se\u00b7kre\u00b7t\u00e4r", ",", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "$,", "$("], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Da\u00df das auf der Stra\u00dfe st\u00e4nde.", "tokens": ["Da\u00df", "das", "auf", "der", "Stra\u00b7\u00dfe", "st\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sollt ich's versetzen, verkaufen?", "tokens": ["Sollt", "ich's", "ver\u00b7set\u00b7zen", ",", "ver\u00b7kau\u00b7fen", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "$,", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Ist all doch n\u00f6tigstes Ger\u00e4t.", "tokens": ["Ist", "all", "doch", "n\u00f6\u00b7tigs\u00b7tes", "Ge\u00b7r\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir w\u00fcrden, einmal, die Not versaufen,", "tokens": ["Wir", "w\u00fcr\u00b7den", ",", "ein\u00b7mal", ",", "die", "Not", "ver\u00b7sau\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ADV", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und dann: Wer wei\u00df, was ich t\u00e4t.", "tokens": ["Und", "dann", ":", "Wer", "wei\u00df", ",", "was", "ich", "t\u00e4t", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PWS", "VVFIN", "$,", "PWS", "PPER", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Ich h\u00e4nge so an dem Bilde,", "tokens": ["Ich", "h\u00e4n\u00b7ge", "so", "an", "dem", "Bil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das noch von meiner Gro\u00dfmama stammt.", "tokens": ["Das", "noch", "von", "mei\u00b7ner", "Gro\u00df\u00b7ma\u00b7ma", "stammt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gott, gie\u00dfe doch etwas Milde", "tokens": ["Gott", ",", "gie\u00b7\u00dfe", "doch", "et\u00b7was", "Mil\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "ADV", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u00dcber das steinerne Wohnungsamt.", "tokens": ["\u00dc\u00b7ber", "das", "stei\u00b7ner\u00b7ne", "Woh\u00b7nungs\u00b7amt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.10": {"line.1": {"text": "Wie meine Frau die Nacht durchweint,", "tokens": ["Wie", "mei\u00b7ne", "Frau", "die", "Nacht", "durch\u00b7weint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das barmt durch all meine Tr\u00e4ume.", "tokens": ["Das", "barmt", "durch", "all", "mei\u00b7ne", "Tr\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Gott, la\u00df uns die lieben zwei R\u00e4ume", "tokens": ["Gott", ",", "la\u00df", "uns", "die", "lie\u00b7ben", "zwei", "R\u00e4u\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVIMP", "PPER", "ART", "ADJA", "CARD", "NN"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Mit der Sonne, die vormittags hinein scheint.", "tokens": ["Mit", "der", "Son\u00b7ne", ",", "die", "vor\u00b7mit\u00b7tags", "hin\u00b7ein", "scheint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$."], "meter": "--+----+--+", "measure": "iambic.tri.chol"}}}}}