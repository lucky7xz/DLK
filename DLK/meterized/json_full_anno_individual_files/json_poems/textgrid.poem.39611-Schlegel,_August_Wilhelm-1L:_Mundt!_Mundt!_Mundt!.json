{"textgrid.poem.39611": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mundt! Mundt! Mundt!", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mundt! Mundt! Mundt!", "tokens": ["Mundt", "!", "Mundt", "!", "Mundt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Halte k\u00fcnftig reinen Mund!", "tokens": ["Hal\u00b7te", "k\u00fcnf\u00b7tig", "rei\u00b7nen", "Mund", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hattest freches Zeug gesprochen:", "tokens": ["Hat\u00b7test", "fre\u00b7ches", "Zeug", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und was half dir da dein Pochen?", "tokens": ["Und", "was", "half", "dir", "da", "dein", "Po\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Nun bist du zu Kreuz gekrochen", "tokens": ["Nun", "bist", "du", "zu", "Kreuz", "ge\u00b7kro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und thust aller Welt es kund,", "tokens": ["Und", "thust", "al\u00b7ler", "Welt", "es", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PPER", "PTKVZ", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.7": {"text": "Kund, kund, kund.", "tokens": ["Kund", ",", "kund", ",", "kund", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Mundt! Mundt! Mundt!", "tokens": ["Mundt", "!", "Mundt", "!", "Mundt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Jenes Vorleg-Schlo\u00df am Mund", "tokens": ["Je\u00b7nes", "Vor\u00b7leg\u00b7Schlo\u00df", "am", "Mund"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist in Gnaden abgenommen.", "tokens": ["Ist", "in", "Gna\u00b7den", "ab\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Halte nun dich zu den Frommen;", "tokens": ["Hal\u00b7te", "nun", "dich", "zu", "den", "From\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sonst wird dir es schlecht bekommen,", "tokens": ["Sonst", "wird", "dir", "es", "schlecht", "be\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wie das frische Gras dem Hund,", "tokens": ["Wie", "das", "fri\u00b7sche", "Gras", "dem", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Hund, Hund, Hund.", "tokens": ["Hund", ",", "Hund", ",", "Hund", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Mundt! Mundt! Mundt!", "tokens": ["Mundt", "!", "Mundt", "!", "Mundt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Halte k\u00fcnftig reinen Mund!", "tokens": ["Hal\u00b7te", "k\u00fcnf\u00b7tig", "rei\u00b7nen", "Mund", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hattest freches Zeug gesprochen:", "tokens": ["Hat\u00b7test", "fre\u00b7ches", "Zeug", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und was half dir da dein Pochen?", "tokens": ["Und", "was", "half", "dir", "da", "dein", "Po\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Nun bist du zu Kreuz gekrochen", "tokens": ["Nun", "bist", "du", "zu", "Kreuz", "ge\u00b7kro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und thust aller Welt es kund,", "tokens": ["Und", "thust", "al\u00b7ler", "Welt", "es", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PPER", "PTKVZ", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.7": {"text": "Kund, kund, kund.", "tokens": ["Kund", ",", "kund", ",", "kund", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Mundt! Mundt! Mundt!", "tokens": ["Mundt", "!", "Mundt", "!", "Mundt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Jenes Vorleg-Schlo\u00df am Mund", "tokens": ["Je\u00b7nes", "Vor\u00b7leg\u00b7Schlo\u00df", "am", "Mund"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist in Gnaden abgenommen.", "tokens": ["Ist", "in", "Gna\u00b7den", "ab\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Halte nun dich zu den Frommen;", "tokens": ["Hal\u00b7te", "nun", "dich", "zu", "den", "From\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sonst wird dir es schlecht bekommen,", "tokens": ["Sonst", "wird", "dir", "es", "schlecht", "be\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wie das frische Gras dem Hund,", "tokens": ["Wie", "das", "fri\u00b7sche", "Gras", "dem", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Hund, Hund, Hund.", "tokens": ["Hund", ",", "Hund", ",", "Hund", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}