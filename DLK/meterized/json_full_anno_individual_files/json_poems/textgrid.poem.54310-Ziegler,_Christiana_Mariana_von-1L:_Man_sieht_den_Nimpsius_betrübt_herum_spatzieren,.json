{"textgrid.poem.54310": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Man sieht den Nimpsius betr\u00fcbt herum spatzieren,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man sieht den Nimpsius betr\u00fcbt herum spatzieren,", "tokens": ["Man", "sieht", "den", "Nim\u00b7psius", "be\u00b7tr\u00fcbt", "he\u00b7rum", "spat\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NE", "VVPP", "APZR", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er tritt pathetisch her und sieht doch sch\u00fcchtern aus.", "tokens": ["Er", "tritt", "pa\u00b7the\u00b7tisch", "her", "und", "sieht", "doch", "sch\u00fcch\u00b7tern", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein! was gedenckt er wohl vor Arglist auszuf\u00fchren?", "tokens": ["Mein", "!", "was", "ge\u00b7denckt", "er", "wohl", "vor", "Arg\u00b7list", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und doch kommt wohl zuletzt ein plumper Streich heraus.", "tokens": ["Und", "doch", "kommt", "wohl", "zu\u00b7letzt", "ein", "plum\u00b7per", "Streich", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ach freylich mu\u00df man ihn und sein Gehirn beklagen;", "tokens": ["Ach", "frey\u00b7lich", "mu\u00df", "man", "ihn", "und", "sein", "Ge\u00b7hirn", "be\u00b7kla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "VMFIN", "PIS", "PPER", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der letzt fatale Streich vergist sich sicher nicht.", "tokens": ["Der", "letzt", "fa\u00b7ta\u00b7le", "Streich", "ver\u00b7gist", "sich", "si\u00b7cher", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man darff das Pflaster nur hier auf der Strassen fragen,", "tokens": ["Man", "darff", "das", "Pflas\u00b7ter", "nur", "hier", "auf", "der", "Stras\u00b7sen", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Warum es ihm an Witz und an Verstand gebricht?", "tokens": ["Wa\u00b7rum", "es", "ihm", "an", "Witz", "und", "an", "Ver\u00b7stand", "ge\u00b7bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "APPR", "NN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn als er letztens sich mit gravit\u00e4tschen Schritten,", "tokens": ["Denn", "als", "er", "letz\u00b7tens", "sich", "mit", "gra\u00b7vi\u00b7t\u00e4t\u00b7schen", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Recht tollk\u00fchn und erboo\u00dft lie\u00df auf der Gassen sehn,", "tokens": ["Recht", "toll\u00b7k\u00fchn", "und", "er\u00b7boo\u00dft", "lie\u00df", "auf", "der", "Gas\u00b7sen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVFIN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So war, indem sein Fu\u00df vielleicht ihm ausgeglitten,", "tokens": ["So", "war", ",", "in\u00b7dem", "sein", "Fu\u00df", "viel\u00b7leicht", "ihm", "aus\u00b7ge\u00b7glit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein l\u00e4cherlicher Fall von ungefehr geschehn,", "tokens": ["Ein", "l\u00e4\u00b7cher\u00b7li\u00b7cher", "Fall", "von", "un\u00b7ge\u00b7fehr", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Bey welchem ihm sein Kopff empfindlich aufgeschlagen,", "tokens": ["Bey", "wel\u00b7chem", "ihm", "sein", "Kopff", "emp\u00b7find\u00b7lich", "auf\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Denn das Ingenium scheint j\u00e4mmerlich l\u00e4dirt,", "tokens": ["Denn", "das", "In\u00b7ge\u00b7ni\u00b7um", "scheint", "j\u00e4m\u00b7mer\u00b7lich", "l\u00e4\u00b7dirt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "VVPP", "$,"], "meter": "--+-+-++-+-+", "measure": "anapaest.init"}, "line.15": {"text": "So da\u00df man Splitter nur davon hervor sieht ragen,", "tokens": ["So", "da\u00df", "man", "Split\u00b7ter", "nur", "da\u00b7von", "her\u00b7vor", "sieht", "ra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "NN", "ADV", "PAV", "PTKVZ", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wie man an der Figur und seiner Forme sp\u00fchrt.", "tokens": ["Wie", "man", "an", "der", "Fi\u00b7gur", "und", "sei\u00b7ner", "For\u00b7me", "sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "Es ist ein kleiner Rest ihm leider! \u00fcbrig blieben,", "tokens": ["Es", "ist", "ein", "klei\u00b7ner", "Rest", "ihm", "lei\u00b7der", "!", "\u00fcb\u00b7rig", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PPER", "ADV", "$.", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und sein Verstand sieht sich nach H\u00fclff und Aertzten um;", "tokens": ["Und", "sein", "Ver\u00b7stand", "sieht", "sich", "nach", "H\u00fclff", "und", "A\u00b7ertz\u00b7ten", "um", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Und doch soll alle Welt ihn, wie er dencket, lieben.", "tokens": ["Und", "doch", "soll", "al\u00b7le", "Welt", "ihn", ",", "wie", "er", "den\u00b7cket", ",", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PIAT", "NN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Betrogner Nimpsius, ubi Judicium?", "tokens": ["Be\u00b7trog\u00b7ner", "Nim\u00b7psius", ",", "u\u00b7bi", "Ju\u00b7di\u00b7ci\u00b7um", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "FM", "FM", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Ein affectirter Gang, ein freches Augen-Wincken", "tokens": ["Ein", "af\u00b7fec\u00b7tir\u00b7ter", "Gang", ",", "ein", "fre\u00b7ches", "Au\u00b7gen\u00b7Win\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und l\u00e4ppisch Lachen soll gantz was besonders seyn.", "tokens": ["Und", "l\u00e4p\u00b7pisch", "La\u00b7chen", "soll", "gantz", "was", "be\u00b7son\u00b7ders", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "VMFIN", "ADV", "PWS", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Coffee, Bier, Wein, Toback, in einer Stunde trincken,", "tokens": ["Cof\u00b7fee", ",", "Bier", ",", "Wein", ",", "To\u00b7back", ",", "in", "ei\u00b7ner", "Stun\u00b7de", "trin\u00b7cken", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.24": {"text": "Heist, wie er selbsten spricht, galant und ungemein.", "tokens": ["Heist", ",", "wie", "er", "selbs\u00b7ten", "spricht", ",", "ga\u00b7lant", "und", "un\u00b7ge\u00b7mein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Von W\u00fcrden und Verdienst ist gar kein Gran zu finden,", "tokens": ["Von", "W\u00fcr\u00b7den", "und", "Ver\u00b7dienst", "ist", "gar", "kein", "Gran", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Sein niedertr\u00e4chtig Thun, das sich sattsam erweist", "tokens": ["Sein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Thun", ",", "das", "sich", "satt\u00b7sam", "er\u00b7weist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Und seine Mine soll gleich Weiber-Hertzen binden.", "tokens": ["Und", "sei\u00b7ne", "Mi\u00b7ne", "soll", "gleich", "Wei\u00b7ber\u00b7Hert\u00b7zen", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "O! Ja da\u00df man sich nicht um solche Gecken reist.", "tokens": ["O", "!", "Ja", "da\u00df", "man", "sich", "nicht", "um", "sol\u00b7che", "Ge\u00b7cken", "reist", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PTKANT", "KOUS", "PIS", "PRF", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Er k\u00fcst vor Wunder offt sein eigen Bild und Schatten,", "tokens": ["Er", "k\u00fcst", "vor", "Wun\u00b7der", "offt", "sein", "ei\u00b7gen", "Bild", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV", "PPOSAT", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Eh sich der Mund bewegt, so h\u00f6rt er schon voraus,", "tokens": ["Eh", "sich", "der", "Mund", "be\u00b7wegt", ",", "so", "h\u00f6rt", "er", "schon", "vo\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.31": {"text": "Wie sich die Wei\u00dfheit wird mit seinen Worten gatten,", "tokens": ["Wie", "sich", "die", "Wei\u00df\u00b7heit", "wird", "mit", "sei\u00b7nen", "Wor\u00b7ten", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und dennoch kommt zuletzt ein toller Mischmasch raus.", "tokens": ["Und", "den\u00b7noch", "kommt", "zu\u00b7letzt", "ein", "tol\u00b7ler", "Mischmasch", "raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Der, wie der Thore meynt, soll sch\u00f6nen Aepfeln gleichen", "tokens": ["Der", ",", "wie", "der", "Tho\u00b7re", "meynt", ",", "soll", "sch\u00f6\u00b7nen", "A\u00b7e\u00b7pfeln", "glei\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "PWAV", "ART", "NN", "VVFIN", "$,", "VMFIN", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Die man noch \u00fcberdi\u00df in g\u00f6ldne Schalen legt.", "tokens": ["Die", "man", "noch", "\u00fc\u00b7ber\u00b7di\u00df", "in", "g\u00f6ld\u00b7ne", "Scha\u00b7len", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ja Schellen kan er uns statt g\u00f6ldner Schalen reichen,", "tokens": ["Ja", "Schel\u00b7len", "kan", "er", "uns", "statt", "g\u00f6ld\u00b7ner", "Scha\u00b7len", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "VMFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Dergleichen Zierath er auf seiner Haube tr\u00e4gt.", "tokens": ["Derg\u00b7lei\u00b7chen", "Zie\u00b7rath", "er", "auf", "sei\u00b7ner", "Hau\u00b7be", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nein! solchen Haasen-Safft mu\u00df keine nicht benaschen,", "tokens": ["Nein", "!", "sol\u00b7chen", "Haa\u00b7sen\u00b7\u00b7S\u00b7afft", "mu\u00df", "kei\u00b7ne", "nicht", "be\u00b7na\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PIAT", "NN", "VMFIN", "PIAT", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Sie tritt sonst selbsten mit in dessen Fett hinein;", "tokens": ["Sie", "tritt", "sonst", "selbs\u00b7ten", "mit", "in", "des\u00b7sen", "Fett", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "APPR", "PRELAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und liesse sich von ihm auch eine Nympff erhaschen,", "tokens": ["Und", "lies\u00b7se", "sich", "von", "ihm", "auch", "ei\u00b7ne", "Nympff", "er\u00b7ha\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "So m\u00fcste sie gewi\u00df recht dumm gewieget seyn.", "tokens": ["So", "m\u00fcs\u00b7te", "sie", "ge\u00b7wi\u00df", "recht", "dumm", "ge\u00b7wie\u00b7get", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Was klug ist, wird sich nicht so leicht in ihm vergaffen,", "tokens": ["Was", "klug", "ist", ",", "wird", "sich", "nicht", "so", "leicht", "in", "ihm", "ver\u00b7gaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VAFIN", "PRF", "PTKNEG", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Er daucht am besten wohl vor einen Charletan.", "tokens": ["Er", "daucht", "am", "bes\u00b7ten", "wohl", "vor", "ei\u00b7nen", "Char\u00b7le\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Dergleichen in sich selbst verliebt und tollen Affen", "tokens": ["Derg\u00b7lei\u00b7chen", "in", "sich", "selbst", "ver\u00b7liebt", "und", "tol\u00b7len", "Af\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "APPR", "PRF", "ADV", "VVPP", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Zieht man, mein Nimpsius, ein Narren Kleidgen an.", "tokens": ["Zieht", "man", ",", "mein", "Nim\u00b7psius", ",", "ein", "Nar\u00b7ren", "Kleid\u00b7gen", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PPOSAT", "NE", "$,", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Man sieht den Nimpsius betr\u00fcbt herum spatzieren,", "tokens": ["Man", "sieht", "den", "Nim\u00b7psius", "be\u00b7tr\u00fcbt", "he\u00b7rum", "spat\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NE", "VVPP", "APZR", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er tritt pathetisch her und sieht doch sch\u00fcchtern aus.", "tokens": ["Er", "tritt", "pa\u00b7the\u00b7tisch", "her", "und", "sieht", "doch", "sch\u00fcch\u00b7tern", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein! was gedenckt er wohl vor Arglist auszuf\u00fchren?", "tokens": ["Mein", "!", "was", "ge\u00b7denckt", "er", "wohl", "vor", "Arg\u00b7list", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VVFIN", "PPER", "ADV", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und doch kommt wohl zuletzt ein plumper Streich heraus.", "tokens": ["Und", "doch", "kommt", "wohl", "zu\u00b7letzt", "ein", "plum\u00b7per", "Streich", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ach freylich mu\u00df man ihn und sein Gehirn beklagen;", "tokens": ["Ach", "frey\u00b7lich", "mu\u00df", "man", "ihn", "und", "sein", "Ge\u00b7hirn", "be\u00b7kla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "VMFIN", "PIS", "PPER", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der letzt fatale Streich vergist sich sicher nicht.", "tokens": ["Der", "letzt", "fa\u00b7ta\u00b7le", "Streich", "ver\u00b7gist", "sich", "si\u00b7cher", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man darff das Pflaster nur hier auf der Strassen fragen,", "tokens": ["Man", "darff", "das", "Pflas\u00b7ter", "nur", "hier", "auf", "der", "Stras\u00b7sen", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Warum es ihm an Witz und an Verstand gebricht?", "tokens": ["Wa\u00b7rum", "es", "ihm", "an", "Witz", "und", "an", "Ver\u00b7stand", "ge\u00b7bricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "APPR", "NN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn als er letztens sich mit gravit\u00e4tschen Schritten,", "tokens": ["Denn", "als", "er", "letz\u00b7tens", "sich", "mit", "gra\u00b7vi\u00b7t\u00e4t\u00b7schen", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Recht tollk\u00fchn und erboo\u00dft lie\u00df auf der Gassen sehn,", "tokens": ["Recht", "toll\u00b7k\u00fchn", "und", "er\u00b7boo\u00dft", "lie\u00df", "auf", "der", "Gas\u00b7sen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVFIN", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So war, indem sein Fu\u00df vielleicht ihm ausgeglitten,", "tokens": ["So", "war", ",", "in\u00b7dem", "sein", "Fu\u00df", "viel\u00b7leicht", "ihm", "aus\u00b7ge\u00b7glit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "PPOSAT", "NN", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein l\u00e4cherlicher Fall von ungefehr geschehn,", "tokens": ["Ein", "l\u00e4\u00b7cher\u00b7li\u00b7cher", "Fall", "von", "un\u00b7ge\u00b7fehr", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Bey welchem ihm sein Kopff empfindlich aufgeschlagen,", "tokens": ["Bey", "wel\u00b7chem", "ihm", "sein", "Kopff", "emp\u00b7find\u00b7lich", "auf\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPOSAT", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Denn das Ingenium scheint j\u00e4mmerlich l\u00e4dirt,", "tokens": ["Denn", "das", "In\u00b7ge\u00b7ni\u00b7um", "scheint", "j\u00e4m\u00b7mer\u00b7lich", "l\u00e4\u00b7dirt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "VVPP", "$,"], "meter": "--+-+-++-+-+", "measure": "anapaest.init"}, "line.15": {"text": "So da\u00df man Splitter nur davon hervor sieht ragen,", "tokens": ["So", "da\u00df", "man", "Split\u00b7ter", "nur", "da\u00b7von", "her\u00b7vor", "sieht", "ra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "NN", "ADV", "PAV", "PTKVZ", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wie man an der Figur und seiner Forme sp\u00fchrt.", "tokens": ["Wie", "man", "an", "der", "Fi\u00b7gur", "und", "sei\u00b7ner", "For\u00b7me", "sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "Es ist ein kleiner Rest ihm leider! \u00fcbrig blieben,", "tokens": ["Es", "ist", "ein", "klei\u00b7ner", "Rest", "ihm", "lei\u00b7der", "!", "\u00fcb\u00b7rig", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PPER", "ADV", "$.", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und sein Verstand sieht sich nach H\u00fclff und Aertzten um;", "tokens": ["Und", "sein", "Ver\u00b7stand", "sieht", "sich", "nach", "H\u00fclff", "und", "A\u00b7ertz\u00b7ten", "um", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Und doch soll alle Welt ihn, wie er dencket, lieben.", "tokens": ["Und", "doch", "soll", "al\u00b7le", "Welt", "ihn", ",", "wie", "er", "den\u00b7cket", ",", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PIAT", "NN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Betrogner Nimpsius, ubi Judicium?", "tokens": ["Be\u00b7trog\u00b7ner", "Nim\u00b7psius", ",", "u\u00b7bi", "Ju\u00b7di\u00b7ci\u00b7um", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "FM", "FM", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Ein affectirter Gang, ein freches Augen-Wincken", "tokens": ["Ein", "af\u00b7fec\u00b7tir\u00b7ter", "Gang", ",", "ein", "fre\u00b7ches", "Au\u00b7gen\u00b7Win\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und l\u00e4ppisch Lachen soll gantz was besonders seyn.", "tokens": ["Und", "l\u00e4p\u00b7pisch", "La\u00b7chen", "soll", "gantz", "was", "be\u00b7son\u00b7ders", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "VMFIN", "ADV", "PWS", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Coffee, Bier, Wein, Toback, in einer Stunde trincken,", "tokens": ["Cof\u00b7fee", ",", "Bier", ",", "Wein", ",", "To\u00b7back", ",", "in", "ei\u00b7ner", "Stun\u00b7de", "trin\u00b7cken", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.24": {"text": "Heist, wie er selbsten spricht, galant und ungemein.", "tokens": ["Heist", ",", "wie", "er", "selbs\u00b7ten", "spricht", ",", "ga\u00b7lant", "und", "un\u00b7ge\u00b7mein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Von W\u00fcrden und Verdienst ist gar kein Gran zu finden,", "tokens": ["Von", "W\u00fcr\u00b7den", "und", "Ver\u00b7dienst", "ist", "gar", "kein", "Gran", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Sein niedertr\u00e4chtig Thun, das sich sattsam erweist", "tokens": ["Sein", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "Thun", ",", "das", "sich", "satt\u00b7sam", "er\u00b7weist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Und seine Mine soll gleich Weiber-Hertzen binden.", "tokens": ["Und", "sei\u00b7ne", "Mi\u00b7ne", "soll", "gleich", "Wei\u00b7ber\u00b7Hert\u00b7zen", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "O! Ja da\u00df man sich nicht um solche Gecken reist.", "tokens": ["O", "!", "Ja", "da\u00df", "man", "sich", "nicht", "um", "sol\u00b7che", "Ge\u00b7cken", "reist", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PTKANT", "KOUS", "PIS", "PRF", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Er k\u00fcst vor Wunder offt sein eigen Bild und Schatten,", "tokens": ["Er", "k\u00fcst", "vor", "Wun\u00b7der", "offt", "sein", "ei\u00b7gen", "Bild", "und", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV", "PPOSAT", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Eh sich der Mund bewegt, so h\u00f6rt er schon voraus,", "tokens": ["Eh", "sich", "der", "Mund", "be\u00b7wegt", ",", "so", "h\u00f6rt", "er", "schon", "vo\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.31": {"text": "Wie sich die Wei\u00dfheit wird mit seinen Worten gatten,", "tokens": ["Wie", "sich", "die", "Wei\u00df\u00b7heit", "wird", "mit", "sei\u00b7nen", "Wor\u00b7ten", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und dennoch kommt zuletzt ein toller Mischmasch raus.", "tokens": ["Und", "den\u00b7noch", "kommt", "zu\u00b7letzt", "ein", "tol\u00b7ler", "Mischmasch", "raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.33": {"text": "Der, wie der Thore meynt, soll sch\u00f6nen Aepfeln gleichen", "tokens": ["Der", ",", "wie", "der", "Tho\u00b7re", "meynt", ",", "soll", "sch\u00f6\u00b7nen", "A\u00b7e\u00b7pfeln", "glei\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "PWAV", "ART", "NN", "VVFIN", "$,", "VMFIN", "ADJA", "NN", "ADJA"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Die man noch \u00fcberdi\u00df in g\u00f6ldne Schalen legt.", "tokens": ["Die", "man", "noch", "\u00fc\u00b7ber\u00b7di\u00df", "in", "g\u00f6ld\u00b7ne", "Scha\u00b7len", "legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ja Schellen kan er uns statt g\u00f6ldner Schalen reichen,", "tokens": ["Ja", "Schel\u00b7len", "kan", "er", "uns", "statt", "g\u00f6ld\u00b7ner", "Scha\u00b7len", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "VMFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Dergleichen Zierath er auf seiner Haube tr\u00e4gt.", "tokens": ["Derg\u00b7lei\u00b7chen", "Zie\u00b7rath", "er", "auf", "sei\u00b7ner", "Hau\u00b7be", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Nein! solchen Haasen-Safft mu\u00df keine nicht benaschen,", "tokens": ["Nein", "!", "sol\u00b7chen", "Haa\u00b7sen\u00b7\u00b7S\u00b7afft", "mu\u00df", "kei\u00b7ne", "nicht", "be\u00b7na\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PIAT", "NN", "VMFIN", "PIAT", "PTKNEG", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Sie tritt sonst selbsten mit in dessen Fett hinein;", "tokens": ["Sie", "tritt", "sonst", "selbs\u00b7ten", "mit", "in", "des\u00b7sen", "Fett", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "APPR", "PRELAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und liesse sich von ihm auch eine Nympff erhaschen,", "tokens": ["Und", "lies\u00b7se", "sich", "von", "ihm", "auch", "ei\u00b7ne", "Nympff", "er\u00b7ha\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "So m\u00fcste sie gewi\u00df recht dumm gewieget seyn.", "tokens": ["So", "m\u00fcs\u00b7te", "sie", "ge\u00b7wi\u00df", "recht", "dumm", "ge\u00b7wie\u00b7get", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Was klug ist, wird sich nicht so leicht in ihm vergaffen,", "tokens": ["Was", "klug", "ist", ",", "wird", "sich", "nicht", "so", "leicht", "in", "ihm", "ver\u00b7gaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VAFIN", "PRF", "PTKNEG", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Er daucht am besten wohl vor einen Charletan.", "tokens": ["Er", "daucht", "am", "bes\u00b7ten", "wohl", "vor", "ei\u00b7nen", "Char\u00b7le\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Dergleichen in sich selbst verliebt und tollen Affen", "tokens": ["Derg\u00b7lei\u00b7chen", "in", "sich", "selbst", "ver\u00b7liebt", "und", "tol\u00b7len", "Af\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "APPR", "PRF", "ADV", "VVPP", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Zieht man, mein Nimpsius, ein Narren Kleidgen an.", "tokens": ["Zieht", "man", ",", "mein", "Nim\u00b7psius", ",", "ein", "Nar\u00b7ren", "Kleid\u00b7gen", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PPOSAT", "NE", "$,", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}}}}