{"textgrid.poem.43098": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ei, wie sch\u00f6n du warst, als Laune,", "tokens": ["Ei", ",", "wie", "sch\u00f6n", "du", "warst", ",", "als", "Lau\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$,", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wein und Lust im Aug' dir gl\u00fchte!", "tokens": ["Wein", "und", "Lust", "im", "Aug'", "dir", "gl\u00fch\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wof\u00fcr h\u00e4ltst du mich denn pl\u00f6tzlich,", "tokens": ["Wo\u00b7f\u00fcr", "h\u00e4ltst", "du", "mich", "denn", "pl\u00f6tz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df du schw\u00e4rmst jetzt von Gem\u00fcthe?", "tokens": ["Da\u00df", "du", "schw\u00e4rmst", "jetzt", "von", "Ge\u00b7m\u00fc\u00b7the", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Lasse, Freund, doch die Kom\u00f6die \u2013", "tokens": ["Las\u00b7se", ",", "Freund", ",", "doch", "die", "Ko\u00b7m\u00f6\u00b7die", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir sind viel zu klug zum schw\u00e4rmen,", "tokens": ["Wir", "sind", "viel", "zu", "klug", "zum", "schw\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKA", "ADJD", "APPRART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heut' sich k\u00fcssen, morgen scheiden,", "tokens": ["Heut'", "sich", "k\u00fcs\u00b7sen", ",", "mor\u00b7gen", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gibt uns keinen Grund zum h\u00e4rmen.", "tokens": ["Gibt", "uns", "kei\u00b7nen", "Grund", "zum", "h\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "APPRART", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Dort die kurzgesch\u00fcrzten Weiber", "tokens": ["Dort", "die", "kurz\u00b7ge\u00b7sch\u00fcrz\u00b7ten", "Wei\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den kecken Schellenm\u00fctzen", "tokens": ["Mit", "den", "ke\u00b7cken", "Schel\u00b7len\u00b7m\u00fct\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden vor Gem\u00fcthsbewegung", "tokens": ["Wer\u00b7den", "vor", "Ge\u00b7m\u00fcths\u00b7be\u00b7we\u00b7gung"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vor Trennungsschmerz dich sch\u00fctzen.", "tokens": ["Und", "vor", "Tren\u00b7nungs\u00b7schmerz", "dich", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Diese flinken Ballerinen,", "tokens": ["Die\u00b7se", "flin\u00b7ken", "Bal\u00b7le\u00b7ri\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese sch\u00f6nen nackten S\u00fcnden", "tokens": ["Die\u00b7se", "sch\u00f6\u00b7nen", "nack\u00b7ten", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden schwatzhaft, freundlich-boshaft", "tokens": ["Wer\u00b7den", "schwatz\u00b7haft", ",", "freund\u00b7lich\u00b7bos\u00b7haft"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich ", "tokens": ["Was", "ich"], "token_info": ["word", "word"], "pos": ["PWS", "PPER"], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Sieh', ich sch\u00fctz' dich vor Entt\u00e4uschung;", "tokens": ["Sieh'", ",", "ich", "sch\u00fctz'", "dich", "vor", "Ent\u00b7t\u00e4u\u00b7schung", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Um uns wogt und rauscht das Leben:", "tokens": ["Um", "uns", "wogt", "und", "rauscht", "das", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was das ", "tokens": ["Was", "das"], "token_info": ["word", "word"], "pos": ["PWS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Mag das ", "tokens": ["Mag", "das"], "token_info": ["word", "word"], "pos": ["VMFIN", "ART"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.6": {"line.1": {"text": "Ei, wie sch\u00f6n du warst, als Laune,", "tokens": ["Ei", ",", "wie", "sch\u00f6n", "du", "warst", ",", "als", "Lau\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADJD", "PPER", "VAFIN", "$,", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wein und Lust im Aug' dir gl\u00fchte!", "tokens": ["Wein", "und", "Lust", "im", "Aug'", "dir", "gl\u00fch\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wof\u00fcr h\u00e4ltst du mich denn pl\u00f6tzlich,", "tokens": ["Wo\u00b7f\u00fcr", "h\u00e4ltst", "du", "mich", "denn", "pl\u00f6tz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df du schw\u00e4rmst jetzt von Gem\u00fcthe?", "tokens": ["Da\u00df", "du", "schw\u00e4rmst", "jetzt", "von", "Ge\u00b7m\u00fc\u00b7the", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Lasse, Freund, doch die Kom\u00f6die \u2013", "tokens": ["Las\u00b7se", ",", "Freund", ",", "doch", "die", "Ko\u00b7m\u00f6\u00b7die", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir sind viel zu klug zum schw\u00e4rmen,", "tokens": ["Wir", "sind", "viel", "zu", "klug", "zum", "schw\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKA", "ADJD", "APPRART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Heut' sich k\u00fcssen, morgen scheiden,", "tokens": ["Heut'", "sich", "k\u00fcs\u00b7sen", ",", "mor\u00b7gen", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVINF", "$,", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gibt uns keinen Grund zum h\u00e4rmen.", "tokens": ["Gibt", "uns", "kei\u00b7nen", "Grund", "zum", "h\u00e4r\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "APPRART", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Dort die kurzgesch\u00fcrzten Weiber", "tokens": ["Dort", "die", "kurz\u00b7ge\u00b7sch\u00fcrz\u00b7ten", "Wei\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den kecken Schellenm\u00fctzen", "tokens": ["Mit", "den", "ke\u00b7cken", "Schel\u00b7len\u00b7m\u00fct\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden vor Gem\u00fcthsbewegung", "tokens": ["Wer\u00b7den", "vor", "Ge\u00b7m\u00fcths\u00b7be\u00b7we\u00b7gung"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vor Trennungsschmerz dich sch\u00fctzen.", "tokens": ["Und", "vor", "Tren\u00b7nungs\u00b7schmerz", "dich", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Diese flinken Ballerinen,", "tokens": ["Die\u00b7se", "flin\u00b7ken", "Bal\u00b7le\u00b7ri\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese sch\u00f6nen nackten S\u00fcnden", "tokens": ["Die\u00b7se", "sch\u00f6\u00b7nen", "nack\u00b7ten", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden schwatzhaft, freundlich-boshaft", "tokens": ["Wer\u00b7den", "schwatz\u00b7haft", ",", "freund\u00b7lich\u00b7bos\u00b7haft"], "token_info": ["word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich ", "tokens": ["Was", "ich"], "token_info": ["word", "word"], "pos": ["PWS", "PPER"], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "Sieh', ich sch\u00fctz' dich vor Entt\u00e4uschung;", "tokens": ["Sieh'", ",", "ich", "sch\u00fctz'", "dich", "vor", "Ent\u00b7t\u00e4u\u00b7schung", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Um uns wogt und rauscht das Leben:", "tokens": ["Um", "uns", "wogt", "und", "rauscht", "das", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was das ", "tokens": ["Was", "das"], "token_info": ["word", "word"], "pos": ["PWS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Mag das ", "tokens": ["Mag", "das"], "token_info": ["word", "word"], "pos": ["VMFIN", "ART"], "meter": "+-", "measure": "trochaic.single"}}}}}