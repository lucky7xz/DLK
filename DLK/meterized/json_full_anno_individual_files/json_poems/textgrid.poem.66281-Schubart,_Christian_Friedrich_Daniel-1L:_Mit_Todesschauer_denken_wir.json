{"textgrid.poem.66281": {"metadata": {"author": {"name": "Schubart, Christian Friedrich Daniel", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mit Todesschauer denken wir", "genre": "verse", "period": "N.A.", "pub_year": 1767, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mit Todesschauer denken wir", "tokens": ["Mit", "To\u00b7des\u00b7schau\u00b7er", "den\u00b7ken", "wir"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Jahre schnellen Lauf", "tokens": ["Der", "Jah\u00b7re", "schnel\u00b7len", "Lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und singen in dem Tempel hier", "tokens": ["Und", "sin\u00b7gen", "in", "dem", "Tem\u00b7pel", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Lied zu Gott hinauf.", "tokens": ["Ein", "Lied", "zu", "Gott", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Schnell, wie Gedanken, Schall und Licht,", "tokens": ["Schnell", ",", "wie", "Ge\u00b7dan\u00b7ken", ",", "Schall", "und", "Licht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Flieht hinter uns die Zeit,", "tokens": ["Flieht", "hin\u00b7ter", "uns", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und vor uns drohet ein Gericht", "tokens": ["Und", "vor", "uns", "dro\u00b7het", "ein", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und eine Ewigkeit.", "tokens": ["Und", "ei\u00b7ne", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und dennoch morden wir die Zeit", "tokens": ["Und", "den\u00b7noch", "mor\u00b7den", "wir", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fcrchten nicht den Tod?", "tokens": ["Und", "f\u00fcrch\u00b7ten", "nicht", "den", "Tod", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und f\u00fcrchten nicht die Ewigkeit,", "tokens": ["Und", "f\u00fcrch\u00b7ten", "nicht", "die", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns, den M\u00f6rdern, droht?", "tokens": ["Die", "uns", ",", "den", "M\u00f6r\u00b7dern", ",", "droht", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "$,", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wer nicht an Jesum Christum glaubt,", "tokens": ["Wer", "nicht", "an", "Je\u00b7sum", "Chris\u00b7tum", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "APPR", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihn nicht br\u00fcnstig liebt,", "tokens": ["Und", "ihn", "nicht", "br\u00fcns\u00b7tig", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dem Sch\u00f6pfer seine Ehre raubt", "tokens": ["Dem", "Sch\u00f6p\u00b7fer", "sei\u00b7ne", "Eh\u00b7re", "raubt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sie Gesch\u00f6pfen gibt;", "tokens": ["Und", "sie", "Ge\u00b7sch\u00f6p\u00b7fen", "gibt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wer wie ein Vieh aus Pf\u00fctzen s\u00e4uft,", "tokens": ["Wer", "wie", "ein", "Vieh", "aus", "Pf\u00fct\u00b7zen", "s\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "KOKOM", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Lasterkothe w\u00fchlt;", "tokens": ["Im", "Las\u00b7ter\u00b7ko\u00b7the", "w\u00fchlt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wer S\u00fcnden wie Gebirge h\u00e4uft,", "tokens": ["Wer", "S\u00fcn\u00b7den", "wie", "Ge\u00b7bir\u00b7ge", "h\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und doch den Berg nicht f\u00fchlt;", "tokens": ["Und", "doch", "den", "Berg", "nicht", "f\u00fchlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und wer mit h\u00fcndischer Begier", "tokens": ["Und", "wer", "mit", "h\u00fcn\u00b7di\u00b7scher", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An seinen G\u00fctern zerrt,", "tokens": ["An", "sei\u00b7nen", "G\u00fc\u00b7tern", "zerrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vor einem Lazarus die Th\u00fcr'", "tokens": ["Vor", "ei\u00b7nem", "La\u00b7za\u00b7rus", "die", "Th\u00fcr'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit gro\u00dfen Riegeln sperrt;", "tokens": ["Mit", "gro\u00b7\u00dfen", "Rie\u00b7geln", "sperrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wer eine blut'ge Thr\u00e4nenfluth", "tokens": ["Wer", "ei\u00b7ne", "blut'\u00b7ge", "Thr\u00e4\u00b7nen\u00b7fluth"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Wittwenaugen pre\u00dft,", "tokens": ["Aus", "Witt\u00b7wen\u00b7au\u00b7gen", "pre\u00dft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und seinen fetten Wanst vom Blut", "tokens": ["Und", "sei\u00b7nen", "fet\u00b7ten", "Wanst", "vom", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zertretner Waisen m\u00e4st't;", "tokens": ["Zer\u00b7tret\u00b7ner", "Wai\u00b7sen", "m\u00e4st't", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wer au\u00dfen wie ein Schaf gekleidt,", "tokens": ["Wer", "au\u00b7\u00dfen", "wie", "ein", "Schaf", "ge\u00b7kleidt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "KOKOM", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von innen w\u00f6lfisch denkt,", "tokens": ["Von", "in\u00b7nen", "w\u00f6l\u00b7fisch", "denkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wer das Gl\u00fcck der Ewigkeit", "tokens": ["Und", "wer", "das", "Gl\u00fcck", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Erdengl\u00fcck verschenkt;", "tokens": ["F\u00fcr", "Er\u00b7den\u00b7gl\u00fcck", "ver\u00b7schenkt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wer Br\u00fcdern nach dem Leben greift,", "tokens": ["Wer", "Br\u00fc\u00b7dern", "nach", "dem", "Le\u00b7ben", "greift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Rache angethan;", "tokens": ["Mit", "Ra\u00b7che", "an\u00b7ge\u00b7than", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wer nur Beleidigungen h\u00e4uft", "tokens": ["Wer", "nur", "Be\u00b7lei\u00b7di\u00b7gun\u00b7gen", "h\u00e4uft"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nicht verzeihen kann;", "tokens": ["Und", "nicht", "ver\u00b7zei\u00b7hen", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wer g\u00e4hnend seine Pflicht vergi\u00dft", "tokens": ["Wer", "g\u00e4h\u00b7nend", "sei\u00b7ne", "Pflicht", "ver\u00b7gi\u00dft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Zeitvertreibe sucht,", "tokens": ["Und", "Zeit\u00b7ver\u00b7trei\u00b7be", "sucht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wenn die Zeit verflogen ist,", "tokens": ["Und", "wenn", "die", "Zeit", "ver\u00b7flo\u00b7gen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf ihre Schwingen flucht;", "tokens": ["Auf", "ih\u00b7re", "Schwin\u00b7gen", "flucht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wer unreif zu der Ewigkeit", "tokens": ["Wer", "un\u00b7reif", "zu", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Tode sich nicht schickt:", "tokens": ["Zum", "To\u00b7de", "sich", "nicht", "schickt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das ist der M\u00f6rder, der die Zeit", "tokens": ["Das", "ist", "der", "M\u00f6r\u00b7der", ",", "der", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit eigner Hand erdr\u00fcckt.", "tokens": ["Mit", "eig\u00b7ner", "Hand", "er\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Sind solche Ungeheuer hier,", "tokens": ["Sind", "sol\u00b7che", "Un\u00b7ge\u00b7heu\u00b7er", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr, so bekehre sie!", "tokens": ["Herr", ",", "so", "be\u00b7keh\u00b7re", "sie", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Der ganze Tempel seufzt wie wir:", "tokens": ["Der", "gan\u00b7ze", "Tem\u00b7pel", "seufzt", "wie", "wir", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach Herr! bekehre sie.", "tokens": ["Ach", "Herr", "!", "be\u00b7keh\u00b7re", "sie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wie viele singen heute auf,", "tokens": ["Wie", "vie\u00b7le", "sin\u00b7gen", "heu\u00b7te", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch unbekehrt und blind,", "tokens": ["Noch", "un\u00b7be\u00b7kehrt", "und", "blind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die nach vollbrachtem Jahreslauf", "tokens": ["Die", "nach", "voll\u00b7brach\u00b7tem", "Jah\u00b7res\u00b7lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schon Staub und Moder sind.", "tokens": ["Schon", "Staub", "und", "Mo\u00b7der", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wie dunkle Schatten fahren sie", "tokens": ["Wie", "dunk\u00b7le", "Schat\u00b7ten", "fah\u00b7ren", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur H\u00f6lle dann hinab;", "tokens": ["Zur", "H\u00f6l\u00b7le", "dann", "hin\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu der Tyrannin, die noch nie", "tokens": ["Zu", "der", "Ty\u00b7ran\u00b7nin", ",", "die", "noch", "nie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Todten wieder gab.", "tokens": ["Die", "Tod\u00b7ten", "wie\u00b7der", "gab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Drum arme Seele denke heut", "tokens": ["Drum", "ar\u00b7me", "See\u00b7le", "den\u00b7ke", "heut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADJA", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Ernst an deinen Tod;", "tokens": ["Mit", "Ernst", "an", "dei\u00b7nen", "Tod", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn jedes unsrer Jahre schreit:", "tokens": ["Denn", "je\u00b7des", "uns\u00b7rer", "Jah\u00b7re", "schreit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gedenk an deinen Tod!", "tokens": ["Ge\u00b7denk", "an", "dei\u00b7nen", "Tod", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Zu dir, der sein wird, ist, und war,", "tokens": ["Zu", "dir", ",", "der", "sein", "wird", ",", "ist", ",", "und", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PRELS", "VAINF", "VAFIN", "$,", "VAFIN", "$,", "KON", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steig' unser Lied hinauf:", "tokens": ["Steig'", "un\u00b7ser", "Lied", "hin\u00b7auf", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach Gott, nimm doch in diesem Jahr", "tokens": ["Ach", "Gott", ",", "nimm", "doch", "in", "die\u00b7sem", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "$,", "VVIMP", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Todten zu dir auf.", "tokens": ["Die", "Tod\u00b7ten", "zu", "dir", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Und du, Vertreter, rede laut,", "tokens": ["Und", "du", ",", "Ver\u00b7tre\u00b7ter", ",", "re\u00b7de", "laut", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn uns der Richter droht;", "tokens": ["Wenn", "uns", "der", "Rich\u00b7ter", "droht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Zorn aus seinem Auge schaut", "tokens": ["Wenn", "Zorn", "aus", "sei\u00b7nem", "Au\u00b7ge", "schaut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und aus der Stirne Tod.", "tokens": ["Und", "aus", "der", "Stir\u00b7ne", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Geist Gottes, zeige deine Macht,", "tokens": ["Geist", "Got\u00b7tes", ",", "zei\u00b7ge", "dei\u00b7ne", "Macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn uns das Auge bricht.", "tokens": ["Wenn", "uns", "das", "Au\u00b7ge", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In einer solchen Mitternacht,", "tokens": ["In", "ei\u00b7ner", "sol\u00b7chen", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da brauchen wir ja Licht.", "tokens": ["Da", "brau\u00b7chen", "wir", "ja", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Wie kann der frommen Christenschaar", "tokens": ["Wie", "kann", "der", "from\u00b7men", "Chris\u00b7ten\u00b7schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tod nun schrecklich sein?", "tokens": ["Der", "Tod", "nun", "schreck\u00b7lich", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie weihen ja das neue Jahr", "tokens": ["Sie", "wei\u00b7hen", "ja", "das", "neu\u00b7e", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit ihren Thr\u00e4nen ein.", "tokens": ["Mit", "ih\u00b7ren", "Thr\u00e4\u00b7nen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Mit Todesschauer denken wir", "tokens": ["Mit", "To\u00b7des\u00b7schau\u00b7er", "den\u00b7ken", "wir"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Jahre schnellen Lauf", "tokens": ["Der", "Jah\u00b7re", "schnel\u00b7len", "Lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und singen in dem Tempel hier", "tokens": ["Und", "sin\u00b7gen", "in", "dem", "Tem\u00b7pel", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Lied zu Gott hinauf.", "tokens": ["Ein", "Lied", "zu", "Gott", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Schnell, wie Gedanken, Schall und Licht,", "tokens": ["Schnell", ",", "wie", "Ge\u00b7dan\u00b7ken", ",", "Schall", "und", "Licht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Flieht hinter uns die Zeit,", "tokens": ["Flieht", "hin\u00b7ter", "uns", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und vor uns drohet ein Gericht", "tokens": ["Und", "vor", "uns", "dro\u00b7het", "ein", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und eine Ewigkeit.", "tokens": ["Und", "ei\u00b7ne", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und dennoch morden wir die Zeit", "tokens": ["Und", "den\u00b7noch", "mor\u00b7den", "wir", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fcrchten nicht den Tod?", "tokens": ["Und", "f\u00fcrch\u00b7ten", "nicht", "den", "Tod", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und f\u00fcrchten nicht die Ewigkeit,", "tokens": ["Und", "f\u00fcrch\u00b7ten", "nicht", "die", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns, den M\u00f6rdern, droht?", "tokens": ["Die", "uns", ",", "den", "M\u00f6r\u00b7dern", ",", "droht", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "$,", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Wer nicht an Jesum Christum glaubt,", "tokens": ["Wer", "nicht", "an", "Je\u00b7sum", "Chris\u00b7tum", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "APPR", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihn nicht br\u00fcnstig liebt,", "tokens": ["Und", "ihn", "nicht", "br\u00fcns\u00b7tig", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dem Sch\u00f6pfer seine Ehre raubt", "tokens": ["Dem", "Sch\u00f6p\u00b7fer", "sei\u00b7ne", "Eh\u00b7re", "raubt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sie Gesch\u00f6pfen gibt;", "tokens": ["Und", "sie", "Ge\u00b7sch\u00f6p\u00b7fen", "gibt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Wer wie ein Vieh aus Pf\u00fctzen s\u00e4uft,", "tokens": ["Wer", "wie", "ein", "Vieh", "aus", "Pf\u00fct\u00b7zen", "s\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "KOKOM", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Lasterkothe w\u00fchlt;", "tokens": ["Im", "Las\u00b7ter\u00b7ko\u00b7the", "w\u00fchlt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wer S\u00fcnden wie Gebirge h\u00e4uft,", "tokens": ["Wer", "S\u00fcn\u00b7den", "wie", "Ge\u00b7bir\u00b7ge", "h\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und doch den Berg nicht f\u00fchlt;", "tokens": ["Und", "doch", "den", "Berg", "nicht", "f\u00fchlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Und wer mit h\u00fcndischer Begier", "tokens": ["Und", "wer", "mit", "h\u00fcn\u00b7di\u00b7scher", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An seinen G\u00fctern zerrt,", "tokens": ["An", "sei\u00b7nen", "G\u00fc\u00b7tern", "zerrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vor einem Lazarus die Th\u00fcr'", "tokens": ["Vor", "ei\u00b7nem", "La\u00b7za\u00b7rus", "die", "Th\u00fcr'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit gro\u00dfen Riegeln sperrt;", "tokens": ["Mit", "gro\u00b7\u00dfen", "Rie\u00b7geln", "sperrt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Wer eine blut'ge Thr\u00e4nenfluth", "tokens": ["Wer", "ei\u00b7ne", "blut'\u00b7ge", "Thr\u00e4\u00b7nen\u00b7fluth"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Wittwenaugen pre\u00dft,", "tokens": ["Aus", "Witt\u00b7wen\u00b7au\u00b7gen", "pre\u00dft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und seinen fetten Wanst vom Blut", "tokens": ["Und", "sei\u00b7nen", "fet\u00b7ten", "Wanst", "vom", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zertretner Waisen m\u00e4st't;", "tokens": ["Zer\u00b7tret\u00b7ner", "Wai\u00b7sen", "m\u00e4st't", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wer au\u00dfen wie ein Schaf gekleidt,", "tokens": ["Wer", "au\u00b7\u00dfen", "wie", "ein", "Schaf", "ge\u00b7kleidt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "KOKOM", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von innen w\u00f6lfisch denkt,", "tokens": ["Von", "in\u00b7nen", "w\u00f6l\u00b7fisch", "denkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wer das Gl\u00fcck der Ewigkeit", "tokens": ["Und", "wer", "das", "Gl\u00fcck", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Erdengl\u00fcck verschenkt;", "tokens": ["F\u00fcr", "Er\u00b7den\u00b7gl\u00fcck", "ver\u00b7schenkt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Wer Br\u00fcdern nach dem Leben greift,", "tokens": ["Wer", "Br\u00fc\u00b7dern", "nach", "dem", "Le\u00b7ben", "greift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Rache angethan;", "tokens": ["Mit", "Ra\u00b7che", "an\u00b7ge\u00b7than", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wer nur Beleidigungen h\u00e4uft", "tokens": ["Wer", "nur", "Be\u00b7lei\u00b7di\u00b7gun\u00b7gen", "h\u00e4uft"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nicht verzeihen kann;", "tokens": ["Und", "nicht", "ver\u00b7zei\u00b7hen", "kann", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Wer g\u00e4hnend seine Pflicht vergi\u00dft", "tokens": ["Wer", "g\u00e4h\u00b7nend", "sei\u00b7ne", "Pflicht", "ver\u00b7gi\u00dft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Zeitvertreibe sucht,", "tokens": ["Und", "Zeit\u00b7ver\u00b7trei\u00b7be", "sucht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wenn die Zeit verflogen ist,", "tokens": ["Und", "wenn", "die", "Zeit", "ver\u00b7flo\u00b7gen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf ihre Schwingen flucht;", "tokens": ["Auf", "ih\u00b7re", "Schwin\u00b7gen", "flucht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Wer unreif zu der Ewigkeit", "tokens": ["Wer", "un\u00b7reif", "zu", "der", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Tode sich nicht schickt:", "tokens": ["Zum", "To\u00b7de", "sich", "nicht", "schickt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das ist der M\u00f6rder, der die Zeit", "tokens": ["Das", "ist", "der", "M\u00f6r\u00b7der", ",", "der", "die", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit eigner Hand erdr\u00fcckt.", "tokens": ["Mit", "eig\u00b7ner", "Hand", "er\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Sind solche Ungeheuer hier,", "tokens": ["Sind", "sol\u00b7che", "Un\u00b7ge\u00b7heu\u00b7er", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Herr, so bekehre sie!", "tokens": ["Herr", ",", "so", "be\u00b7keh\u00b7re", "sie", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Der ganze Tempel seufzt wie wir:", "tokens": ["Der", "gan\u00b7ze", "Tem\u00b7pel", "seufzt", "wie", "wir", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach Herr! bekehre sie.", "tokens": ["Ach", "Herr", "!", "be\u00b7keh\u00b7re", "sie", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Wie viele singen heute auf,", "tokens": ["Wie", "vie\u00b7le", "sin\u00b7gen", "heu\u00b7te", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch unbekehrt und blind,", "tokens": ["Noch", "un\u00b7be\u00b7kehrt", "und", "blind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die nach vollbrachtem Jahreslauf", "tokens": ["Die", "nach", "voll\u00b7brach\u00b7tem", "Jah\u00b7res\u00b7lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schon Staub und Moder sind.", "tokens": ["Schon", "Staub", "und", "Mo\u00b7der", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Wie dunkle Schatten fahren sie", "tokens": ["Wie", "dunk\u00b7le", "Schat\u00b7ten", "fah\u00b7ren", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur H\u00f6lle dann hinab;", "tokens": ["Zur", "H\u00f6l\u00b7le", "dann", "hin\u00b7ab", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu der Tyrannin, die noch nie", "tokens": ["Zu", "der", "Ty\u00b7ran\u00b7nin", ",", "die", "noch", "nie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Todten wieder gab.", "tokens": ["Die", "Tod\u00b7ten", "wie\u00b7der", "gab", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Drum arme Seele denke heut", "tokens": ["Drum", "ar\u00b7me", "See\u00b7le", "den\u00b7ke", "heut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADJA", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Ernst an deinen Tod;", "tokens": ["Mit", "Ernst", "an", "dei\u00b7nen", "Tod", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn jedes unsrer Jahre schreit:", "tokens": ["Denn", "je\u00b7des", "uns\u00b7rer", "Jah\u00b7re", "schreit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gedenk an deinen Tod!", "tokens": ["Ge\u00b7denk", "an", "dei\u00b7nen", "Tod", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Zu dir, der sein wird, ist, und war,", "tokens": ["Zu", "dir", ",", "der", "sein", "wird", ",", "ist", ",", "und", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PRELS", "VAINF", "VAFIN", "$,", "VAFIN", "$,", "KON", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steig' unser Lied hinauf:", "tokens": ["Steig'", "un\u00b7ser", "Lied", "hin\u00b7auf", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach Gott, nimm doch in diesem Jahr", "tokens": ["Ach", "Gott", ",", "nimm", "doch", "in", "die\u00b7sem", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "$,", "VVIMP", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Todten zu dir auf.", "tokens": ["Die", "Tod\u00b7ten", "zu", "dir", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Und du, Vertreter, rede laut,", "tokens": ["Und", "du", ",", "Ver\u00b7tre\u00b7ter", ",", "re\u00b7de", "laut", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn uns der Richter droht;", "tokens": ["Wenn", "uns", "der", "Rich\u00b7ter", "droht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Zorn aus seinem Auge schaut", "tokens": ["Wenn", "Zorn", "aus", "sei\u00b7nem", "Au\u00b7ge", "schaut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und aus der Stirne Tod.", "tokens": ["Und", "aus", "der", "Stir\u00b7ne", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Geist Gottes, zeige deine Macht,", "tokens": ["Geist", "Got\u00b7tes", ",", "zei\u00b7ge", "dei\u00b7ne", "Macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn uns das Auge bricht.", "tokens": ["Wenn", "uns", "das", "Au\u00b7ge", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In einer solchen Mitternacht,", "tokens": ["In", "ei\u00b7ner", "sol\u00b7chen", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da brauchen wir ja Licht.", "tokens": ["Da", "brau\u00b7chen", "wir", "ja", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Wie kann der frommen Christenschaar", "tokens": ["Wie", "kann", "der", "from\u00b7men", "Chris\u00b7ten\u00b7schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tod nun schrecklich sein?", "tokens": ["Der", "Tod", "nun", "schreck\u00b7lich", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie weihen ja das neue Jahr", "tokens": ["Sie", "wei\u00b7hen", "ja", "das", "neu\u00b7e", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit ihren Thr\u00e4nen ein.", "tokens": ["Mit", "ih\u00b7ren", "Thr\u00e4\u00b7nen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}