{"textgrid.poem.54135": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Also wat nu \u2013 ja oder ja?", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie ick noch 'n kleena Junge wah,", "tokens": ["Wie", "ick", "noch", "'n", "klee\u00b7na", "Jun\u00b7ge", "wah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "da hattn wa auffe Schule", "tokens": ["da", "hattn", "wa", "auf\u00b7fe", "Schu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "XY", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "een Lehra, den nannten wa blo\u00df: Papa \u2013", "tokens": ["e\u00b7en", "Leh\u00b7ra", ",", "den", "nann\u00b7ten", "wa", "blo\u00df", ":", "Pa\u00b7pa", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "ADV", "$.", "NN", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "een jewissen Doktor Kuhle.", "tokens": ["e\u00b7en", "je\u00b7wis\u00b7sen", "Dok\u00b7tor", "Kuh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Un frachte der wat, un der Schieler war dumm,", "tokens": ["Un", "frach\u00b7te", "der", "wat", ",", "un", "der", "Schie\u00b7ler", "war", "dumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "FM", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "un der quatschte und kl\u00f6nte blo\u00df so rum,", "tokens": ["un", "der", "quatschte", "und", "kl\u00f6n\u00b7te", "blo\u00df", "so", "rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "ART", "ADJA", "KON", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "denn sachte Kuhle feierlich:", "tokens": ["denn", "sach\u00b7te", "Kuh\u00b7le", "fei\u00b7er\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbalso \u2013 du wee\u00dft et nich!\u00ab", "tokens": ["\u00bb", "al\u00b7so", "\u2013", "du", "wee\u00dft", "et", "nich", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$(", "PPER", "VVFIN", "NE", "PTKNEG", "$.", "$("], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.2": {"line.1": {"text": "So nachn Essen, da rooch ick jern", "tokens": ["So", "nachn", "Es\u00b7sen", ",", "da", "rooch", "ick", "jern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "$,", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "in stillen meine S\u00dfijarre.", "tokens": ["in", "stil\u00b7len", "mei\u00b7ne", "S\u00dfi\u00b7jar\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da denk ick so, inwieso un wiefern", "tokens": ["Da", "denk", "ick", "so", ",", "in\u00b7wi\u00b7e\u00b7so", "un", "wie\u00b7fern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "FM", "FM", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "un wie se so looft, die Karre.", "tokens": ["un", "wie", "se", "so", "looft", ",", "die", "Kar\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADV", "ADV", "VVFIN", "$,", "ART", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Wer wee\u00df det . . . Heute w\u00e4hln wa noch rot,", "tokens": ["Wer", "wee\u00df", "det", ".", ".", ".", "Heu\u00b7te", "w\u00e4hln", "wa", "noch", "rot", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDS", "$.", "$.", "$.", "ADV", "APPR", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "un morjen sind wa valleicht alle tot.", "tokens": ["un", "mor\u00b7jen", "sind", "wa", "val\u00b7leicht", "al\u00b7le", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "PIS", "ADJD", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Also ick ja nich, denkt jeda. Immahin . . .", "tokens": ["Al\u00b7so", "ick", "ja", "nich", ",", "denkt", "je\u00b7da", ".", "Im\u00b7ma\u00b7hin", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["ADV", "PPER", "ADV", "PTKNEG", "$,", "VVFIN", "PIS", "$.", "ADV", "$.", "$.", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "man denkt sich so manchet in seinen Sinn.", "tokens": ["man", "denkt", "sich", "so", "man\u00b7chet", "in", "sei\u00b7nen", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Ick bin, ick werde, ich wah jewesen . . .", "tokens": ["Ick", "bin", ",", "ick", "wer\u00b7de", ",", "ich", "wah", "je\u00b7we\u00b7sen", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VAFIN", "$,", "PPER", "ADV", "VVINF", "$.", "$.", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Da haak nu so ville Bicher jelesen.", "tokens": ["Da", "haak", "nu", "so", "vil\u00b7le", "Bi\u00b7cher", "je\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und da steht die Wissenschaft uff de Kommode.", "tokens": ["Und", "da", "steht", "die", "Wis\u00b7sen\u00b7schaft", "uff", "de", "Kom\u00b7mo\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "NE", "NN", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Wie wird det mit uns so nachn Tode?", "tokens": ["Wie", "wird", "det", "mit", "uns", "so", "nachn", "To\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "APPR", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die K\u00fcrche kommt jleich eilich jeloofn,", "tokens": ["Die", "K\u00fcr\u00b7che", "kommt", "jleich", "ei\u00b7lich", "je\u00b7loofn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "da jibt et 'n Waschkorb voll Phillesophen . . .", "tokens": ["da", "jibt", "et", "'n", "Waschkorb", "voll", "Phil\u00b7le\u00b7so\u00b7phen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "NN", "ADJD", "NN", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Det lies man. Un haste det hinta dir,", "tokens": ["Det", "lies", "man", ".", "Un", "has\u00b7te", "det", "hin\u00b7ta", "dir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "dreihundert Pfund bedrucktet Papier,", "tokens": ["drei\u00b7hun\u00b7dert", "Pfund", "be\u00b7druck\u00b7tet", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.17": {"text": "denn leechste die Weisen", "tokens": ["denn", "leechs\u00b7te", "die", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.18": {"text": "beit alte Eisen", "tokens": ["beit", "al\u00b7te", "Ei\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "un sachst dir, wie Kuhle, innalich:", "tokens": ["un", "sachst", "dir", ",", "wie", "Kuh\u00b7le", ",", "in\u00b7na\u00b7lich", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["FM", "VVFIN", "PPER", "$,", "PWAV", "NN", "$,", "ADJD", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.20": {"text": "Sie wissen et nich. Sie wissen et nich.", "tokens": ["Sie", "wis\u00b7sen", "et", "nich", ".", "Sie", "wis\u00b7sen", "et", "nich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PTKNEG", "$.", "PPER", "VVFIN", "NE", "PTKNEG", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Wie ick noch 'n kleena Junge wah,", "tokens": ["Wie", "ick", "noch", "'n", "klee\u00b7na", "Jun\u00b7ge", "wah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "da hattn wa auffe Schule", "tokens": ["da", "hattn", "wa", "auf\u00b7fe", "Schu\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "XY", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "een Lehra, den nannten wa blo\u00df: Papa \u2013", "tokens": ["e\u00b7en", "Leh\u00b7ra", ",", "den", "nann\u00b7ten", "wa", "blo\u00df", ":", "Pa\u00b7pa", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "ADV", "$.", "NN", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "een jewissen Doktor Kuhle.", "tokens": ["e\u00b7en", "je\u00b7wis\u00b7sen", "Dok\u00b7tor", "Kuh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Un frachte der wat, un der Schieler war dumm,", "tokens": ["Un", "frach\u00b7te", "der", "wat", ",", "un", "der", "Schie\u00b7ler", "war", "dumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "FM", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "un der quatschte und kl\u00f6nte blo\u00df so rum,", "tokens": ["un", "der", "quatschte", "und", "kl\u00f6n\u00b7te", "blo\u00df", "so", "rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "ART", "ADJA", "KON", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "denn sachte Kuhle feierlich:", "tokens": ["denn", "sach\u00b7te", "Kuh\u00b7le", "fei\u00b7er\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbalso \u2013 du wee\u00dft et nich!\u00ab", "tokens": ["\u00bb", "al\u00b7so", "\u2013", "du", "wee\u00dft", "et", "nich", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$(", "PPER", "VVFIN", "NE", "PTKNEG", "$.", "$("], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.4": {"line.1": {"text": "So nachn Essen, da rooch ick jern", "tokens": ["So", "nachn", "Es\u00b7sen", ",", "da", "rooch", "ick", "jern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "$,", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "in stillen meine S\u00dfijarre.", "tokens": ["in", "stil\u00b7len", "mei\u00b7ne", "S\u00dfi\u00b7jar\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da denk ick so, inwieso un wiefern", "tokens": ["Da", "denk", "ick", "so", ",", "in\u00b7wi\u00b7e\u00b7so", "un", "wie\u00b7fern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "FM", "FM", "VVINF"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "un wie se so looft, die Karre.", "tokens": ["un", "wie", "se", "so", "looft", ",", "die", "Kar\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADV", "ADV", "VVFIN", "$,", "ART", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Wer wee\u00df det . . . Heute w\u00e4hln wa noch rot,", "tokens": ["Wer", "wee\u00df", "det", ".", ".", ".", "Heu\u00b7te", "w\u00e4hln", "wa", "noch", "rot", ","], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDS", "$.", "$.", "$.", "ADV", "APPR", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "un morjen sind wa valleicht alle tot.", "tokens": ["un", "mor\u00b7jen", "sind", "wa", "val\u00b7leicht", "al\u00b7le", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "PIS", "ADJD", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Also ick ja nich, denkt jeda. Immahin . . .", "tokens": ["Al\u00b7so", "ick", "ja", "nich", ",", "denkt", "je\u00b7da", ".", "Im\u00b7ma\u00b7hin", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["ADV", "PPER", "ADV", "PTKNEG", "$,", "VVFIN", "PIS", "$.", "ADV", "$.", "$.", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "man denkt sich so manchet in seinen Sinn.", "tokens": ["man", "denkt", "sich", "so", "man\u00b7chet", "in", "sei\u00b7nen", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Ick bin, ick werde, ich wah jewesen . . .", "tokens": ["Ick", "bin", ",", "ick", "wer\u00b7de", ",", "ich", "wah", "je\u00b7we\u00b7sen", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VAFIN", "$,", "PPER", "ADV", "VVINF", "$.", "$.", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Da haak nu so ville Bicher jelesen.", "tokens": ["Da", "haak", "nu", "so", "vil\u00b7le", "Bi\u00b7cher", "je\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und da steht die Wissenschaft uff de Kommode.", "tokens": ["Und", "da", "steht", "die", "Wis\u00b7sen\u00b7schaft", "uff", "de", "Kom\u00b7mo\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "NE", "NN", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Wie wird det mit uns so nachn Tode?", "tokens": ["Wie", "wird", "det", "mit", "uns", "so", "nachn", "To\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "APPR", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die K\u00fcrche kommt jleich eilich jeloofn,", "tokens": ["Die", "K\u00fcr\u00b7che", "kommt", "jleich", "ei\u00b7lich", "je\u00b7loofn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "da jibt et 'n Waschkorb voll Phillesophen . . .", "tokens": ["da", "jibt", "et", "'n", "Waschkorb", "voll", "Phil\u00b7le\u00b7so\u00b7phen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "NN", "ADJD", "NN", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Det lies man. Un haste det hinta dir,", "tokens": ["Det", "lies", "man", ".", "Un", "has\u00b7te", "det", "hin\u00b7ta", "dir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "$.", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "dreihundert Pfund bedrucktet Papier,", "tokens": ["drei\u00b7hun\u00b7dert", "Pfund", "be\u00b7druck\u00b7tet", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.17": {"text": "denn leechste die Weisen", "tokens": ["denn", "leechs\u00b7te", "die", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.18": {"text": "beit alte Eisen", "tokens": ["beit", "al\u00b7te", "Ei\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "un sachst dir, wie Kuhle, innalich:", "tokens": ["un", "sachst", "dir", ",", "wie", "Kuh\u00b7le", ",", "in\u00b7na\u00b7lich", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["FM", "VVFIN", "PPER", "$,", "PWAV", "NN", "$,", "ADJD", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.20": {"text": "Sie wissen et nich. Sie wissen et nich.", "tokens": ["Sie", "wis\u00b7sen", "et", "nich", ".", "Sie", "wis\u00b7sen", "et", "nich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PTKNEG", "$.", "PPER", "VVFIN", "NE", "PTKNEG", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}}}}