{"textgrid.poem.39056": {"metadata": {"author": {"name": "Neuber, Friederike Caroline", "birth": "N.A.", "death": "N.A."}, "title": "Antritts-Rede,", "genre": "verse", "period": "N.A.", "pub_year": 1728, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Schauplatz wird diesmal was sp\u00e4ter aufgemacht,", "tokens": ["Der", "Schau\u00b7platz", "wird", "dies\u00b7mal", "was", "sp\u00e4\u00b7ter", "auf\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PWS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als sonst geschehen ist. Warum? Mit Vorbedacht.", "tokens": ["Als", "sonst", "ge\u00b7sche\u00b7hen", "ist", ".", "Wa\u00b7rum", "?", "Mit", "Vor\u00b7be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVPP", "VAFIN", "$.", "PWAV", "$.", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gnug, da\u00df er offen steht. Wir danken Euch indessen,", "tokens": ["Gnug", ",", "da\u00df", "er", "of\u00b7fen", "steht", ".", "Wir", "dan\u00b7ken", "Euch", "in\u00b7des\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Ihr uns allerseits die Tage nicht vergessen,", "tokens": ["Da\u00df", "Ihr", "uns", "al\u00b7ler\u00b7seits", "die", "Ta\u00b7ge", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da er verschlossen war. Im Gl\u00fcck Behutsamkeit;", "tokens": ["Da", "er", "ver\u00b7schlos\u00b7sen", "war", ".", "Im", "Gl\u00fcck", "Be\u00b7hut\u00b7sam\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$.", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Unfall rechter Muth und wahre Redlichkeit,", "tokens": ["Im", "Un\u00b7fall", "rech\u00b7ter", "Muth", "und", "wah\u00b7re", "Red\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist schon genug f\u00fcr mich. Gehorsam seyn und weichen,", "tokens": ["Ist", "schon", "ge\u00b7nug", "f\u00fcr", "mich", ".", "Ge\u00b7hor\u00b7sam", "seyn", "und", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "PPER", "$.", "NN", "VAINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Geh\u00f6rt der klugen Welt. Wie ein vern\u00fcnftig schweigen", "tokens": ["Ge\u00b7h\u00f6rt", "der", "klu\u00b7gen", "Welt", ".", "Wie", "ein", "ver\u00b7n\u00fcnf\u00b7tig", "schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "PWAV", "ART", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mehr spricht und reden kann, als wenn ein Plaudrer schreyt,", "tokens": ["Mehr", "spricht", "und", "re\u00b7den", "kann", ",", "als", "wenn", "ein", "Plaud\u00b7rer", "schreyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVINF", "VMFIN", "$,", "KOKOM", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So heilt den gr\u00f6ssten Schmerz, Geduld, Vernunft und Zeit.", "tokens": ["So", "heilt", "den", "gr\u00f6ss\u00b7ten", "Schmerz", ",", "Ge\u00b7duld", ",", "Ver\u00b7nunft", "und", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Das Gl\u00fccksrad ist ein Ding von unsichtbarer Gr\u00f6sse", "tokens": ["Das", "Gl\u00fccks\u00b7rad", "ist", "ein", "Ding", "von", "un\u00b7sicht\u00b7ba\u00b7rer", "Gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dem einen hilft es fort, dem andern giebt es St\u00f6\u00dfe.", "tokens": ["Dem", "ei\u00b7nen", "hilft", "es", "fort", ",", "dem", "an\u00b7dern", "giebt", "es", "St\u00f6\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PRELS", "PIS", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und der sie unverdient zu einer Zeit erh\u00e4lt", "tokens": ["Und", "der", "sie", "un\u00b7ver\u00b7di\u00b7ent", "zu", "ei\u00b7ner", "Zeit", "er\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.14": {"text": "Bek\u00f6mmt zu andrer Zeit, das, was ihm wohlgef\u00e4llt", "tokens": ["Be\u00b7k\u00f6mmt", "zu", "an\u00b7drer", "Zeit", ",", "das", ",", "was", "ihm", "wohl\u00b7ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,", "PDS", "$,", "PWS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Trost dient Sp\u00f6ttern zwar zu einem frohen Lachen", "tokens": ["Der", "Trost", "dient", "Sp\u00f6t\u00b7tern", "zwar", "zu", "ei\u00b7nem", "fro\u00b7hen", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Alleine die Natur der gut und b\u00f6sen Sachen", "tokens": ["Al\u00b7lei\u00b7ne", "die", "Na\u00b7tur", "der", "gut", "und", "b\u00f6\u00b7sen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ist nur am Ende rein und deutlich anzusehn.", "tokens": ["Ist", "nur", "am", "En\u00b7de", "rein", "und", "deut\u00b7lich", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ADJD", "KON", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Viel ist bereits vorbey, und viel noch nicht geschehn.", "tokens": ["Viel", "ist", "be\u00b7reits", "vor\u00b7bey", ",", "und", "viel", "noch", "nicht", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKVZ", "$,", "KON", "ADV", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das, was verflossen ist, das sind ja nur Geschichte", "tokens": ["Das", ",", "was", "ver\u00b7flos\u00b7sen", "ist", ",", "das", "sind", "ja", "nur", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "VVPP", "VAFIN", "$,", "PDS", "VAFIN", "ADV", "ADV", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und was noch kommen soll, das leidet sein Gewichte.", "tokens": ["Und", "was", "noch", "kom\u00b7men", "soll", ",", "das", "lei\u00b7det", "sein", "Ge\u00b7wich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVINF", "VMFIN", "$,", "PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Zeit, die Wahrheit macht die Sachen offenbahr,", "tokens": ["Die", "Zeit", ",", "die", "Wahr\u00b7heit", "macht", "die", "Sa\u00b7chen", "of\u00b7fen\u00b7bahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und das, was b\u00f6se scheint, ist \u00f6fters gar nicht wahr.", "tokens": ["Und", "das", ",", "was", "b\u00f6\u00b7se", "scheint", ",", "ist", "\u00f6f\u00b7ters", "gar", "nicht", "wahr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man mu\u00df das B\u00f6se nur zu seiner Bessrung brauchen", "tokens": ["Man", "mu\u00df", "das", "B\u00f6\u00b7se", "nur", "zu", "sei\u00b7ner", "Bess\u00b7rung", "brau\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da lieget der Gewinn im Herzen vor den Augen.", "tokens": ["Da", "lie\u00b7get", "der", "Ge\u00b7winn", "im", "Her\u00b7zen", "vor", "den", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wenn die Ruthe sich vom streichen abgenutzt;", "tokens": ["Und", "wenn", "die", "Ru\u00b7the", "sich", "vom", "strei\u00b7chen", "ab\u00b7ge\u00b7nutzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hat sie ein frommes Kind vollkommen ausgeputzt", "tokens": ["Hat", "sie", "ein", "from\u00b7mes", "Kind", "voll\u00b7kom\u00b7men", "aus\u00b7ge\u00b7putzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und zur Vernunft gest\u00e4rkt, ja redlich wohlgezogen", "tokens": ["Und", "zur", "Ver\u00b7nunft", "ge\u00b7st\u00e4rkt", ",", "ja", "red\u00b7lich", "wohl\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Deswegen bleibt man auch der Ruthe so gewogen.", "tokens": ["Des\u00b7we\u00b7gen", "bleibt", "man", "auch", "der", "Ru\u00b7the", "so", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nicht, weil sie Ruthe ist, Nein! in der klugen Hand", "tokens": ["Nicht", ",", "weil", "sie", "Ru\u00b7the", "ist", ",", "Nein", "!", "in", "der", "klu\u00b7gen", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,", "PTKANT", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Verehrt man ihre Kraft; da wird sie erst bekannt", "tokens": ["Ver\u00b7ehrt", "man", "ih\u00b7re", "Kraft", ";", "da", "wird", "sie", "erst", "be\u00b7kannt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df sie sich von sich selbst nicht von der Stelle r\u00fchren", "tokens": ["Da\u00df", "sie", "sich", "von", "sich", "selbst", "nicht", "von", "der", "Stel\u00b7le", "r\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PRF", "ADV", "PTKNEG", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und niemand treffen kann. Sie mu\u00df sich lassen f\u00fchren", "tokens": ["Und", "nie\u00b7mand", "tref\u00b7fen", "kann", ".", "Sie", "mu\u00df", "sich", "las\u00b7sen", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVINF", "VMFIN", "$.", "PPER", "VMFIN", "PRF", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und thut sich selbst mit Weh. Ist der Gebrauch vorbey", "tokens": ["Und", "thut", "sich", "selbst", "mit", "Weh", ".", "Ist", "der", "Ge\u00b7brauch", "vor\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "$.", "VAFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So wird sie selber d\u00fcrr und geht von selbst entzwey.", "tokens": ["So", "wird", "sie", "sel\u00b7ber", "d\u00fcrr", "und", "geht", "von", "selbst", "ent\u00b7zwey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "VVFIN", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Nutzen ist gemacht: Sie aber wird vergessen.", "tokens": ["Der", "Nut\u00b7zen", "ist", "ge\u00b7macht", ":", "Sie", "a\u00b7ber", "wird", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nun ist ein Umstand noch recht n\u00f6thig zu ermessen.", "tokens": ["Nun", "ist", "ein", "Um\u00b7stand", "noch", "recht", "n\u00f6\u00b7thig", "zu", "er\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kommt, seht uns flei\u00dfig an; Erg\u00f6tzt Euch unsre Pflicht:", "tokens": ["Kommt", ",", "seht", "uns", "flei\u00b7\u00dfig", "an", ";", "Er\u00b7g\u00f6tzt", "Euch", "uns\u00b7re", "Pflicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und macht sie Euch noch Ruhm; O! so verge\u00dft uns nicht", "tokens": ["Und", "macht", "sie", "Euch", "noch", "Ruhm", ";", "O", "!", "so", "ver\u00b7ge\u00dft", "uns", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "NN", "$.", "NE", "$.", "ADV", "VVFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erfreut Euch \u00fcber mich. Mein Dank soll Euch zu Ehren", "tokens": ["Er\u00b7freut", "Euch", "\u00fc\u00b7ber", "mich", ".", "Mein", "Dank", "soll", "Euch", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$.", "PPOSAT", "NN", "VMFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sich an kein Ungemach und an kein Leiden kehren.", "tokens": ["Sich", "an", "kein", "Un\u00b7ge\u00b7mach", "und", "an", "kein", "Lei\u00b7den", "keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIAT", "NN", "KON", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mein erster Auftritt ist in meinem Trauerspiel", "tokens": ["Mein", "ers\u00b7ter", "Auf\u00b7tritt", "ist", "in", "mei\u00b7nem", "Trau\u00b7er\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vielleicht der letzte Schmerz. Jetzt aber brauch ich viel.", "tokens": ["Viel\u00b7leicht", "der", "letz\u00b7te", "Schmerz", ".", "Jetzt", "a\u00b7ber", "brauch", "ich", "viel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$.", "ADV", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Schaden ist geschehn. Ihr k\u00f6nnt ihn leichter machen,", "tokens": ["Der", "Scha\u00b7den", "ist", "ge\u00b7schehn", ".", "Ihr", "k\u00f6nnt", "ihn", "leich\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn Ihr uns nicht verlasst. Und kriegt Ihr nichts zu lachen:", "tokens": ["Wenn", "Ihr", "uns", "nicht", "ver\u00b7lasst", ".", "Und", "kriegt", "Ihr", "nichts", "zu", "la\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$.", "KON", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So wartet! Doch Ihr sucht nichts, als vern\u00fcnftgen Scherz,", "tokens": ["So", "war\u00b7tet", "!", "Doch", "Ihr", "sucht", "nichts", ",", "als", "ver\u00b7n\u00fcnft\u00b7gen", "Scherz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "KON", "PPER", "VVFIN", "PIS", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wo er zu suchen ist, und ehrt ein redlich Herz.", "tokens": ["Wo", "er", "zu", "su\u00b7chen", "ist", ",", "und", "ehrt", "ein", "red\u00b7lich", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKZU", "VVINF", "VAFIN", "$,", "KON", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ihr kennet Kunst und Flei\u00df. Was hab ich denn zu klagen?", "tokens": ["Ihr", "ken\u00b7net", "Kunst", "und", "Flei\u00df", ".", "Was", "hab", "ich", "denn", "zu", "kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich will an dessen statt Euch das zu Ehren sagen:", "tokens": ["Ich", "will", "an", "des\u00b7sen", "statt", "Euch", "das", "zu", "Eh\u00b7ren", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDS", "VVFIN", "PPER", "PDS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df nur ein Leipzig ist an Klugheit und Verstand.", "tokens": ["Da\u00df", "nur", "ein", "Leip\u00b7zig", "ist", "an", "Klug\u00b7heit", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "VAFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Habt Dank! Ihr seyd der Welt, und ich bin Euch bekannt.", "tokens": ["Habt", "Dank", "!", "Ihr", "seyd", "der", "Welt", ",", "und", "ich", "bin", "Euch", "be\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "$,", "KON", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der Schauplatz wird diesmal was sp\u00e4ter aufgemacht,", "tokens": ["Der", "Schau\u00b7platz", "wird", "dies\u00b7mal", "was", "sp\u00e4\u00b7ter", "auf\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PWS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als sonst geschehen ist. Warum? Mit Vorbedacht.", "tokens": ["Als", "sonst", "ge\u00b7sche\u00b7hen", "ist", ".", "Wa\u00b7rum", "?", "Mit", "Vor\u00b7be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVPP", "VAFIN", "$.", "PWAV", "$.", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gnug, da\u00df er offen steht. Wir danken Euch indessen,", "tokens": ["Gnug", ",", "da\u00df", "er", "of\u00b7fen", "steht", ".", "Wir", "dan\u00b7ken", "Euch", "in\u00b7des\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Ihr uns allerseits die Tage nicht vergessen,", "tokens": ["Da\u00df", "Ihr", "uns", "al\u00b7ler\u00b7seits", "die", "Ta\u00b7ge", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da er verschlossen war. Im Gl\u00fcck Behutsamkeit;", "tokens": ["Da", "er", "ver\u00b7schlos\u00b7sen", "war", ".", "Im", "Gl\u00fcck", "Be\u00b7hut\u00b7sam\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$.", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im Unfall rechter Muth und wahre Redlichkeit,", "tokens": ["Im", "Un\u00b7fall", "rech\u00b7ter", "Muth", "und", "wah\u00b7re", "Red\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist schon genug f\u00fcr mich. Gehorsam seyn und weichen,", "tokens": ["Ist", "schon", "ge\u00b7nug", "f\u00fcr", "mich", ".", "Ge\u00b7hor\u00b7sam", "seyn", "und", "wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPR", "PPER", "$.", "NN", "VAINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Geh\u00f6rt der klugen Welt. Wie ein vern\u00fcnftig schweigen", "tokens": ["Ge\u00b7h\u00f6rt", "der", "klu\u00b7gen", "Welt", ".", "Wie", "ein", "ver\u00b7n\u00fcnf\u00b7tig", "schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "PWAV", "ART", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mehr spricht und reden kann, als wenn ein Plaudrer schreyt,", "tokens": ["Mehr", "spricht", "und", "re\u00b7den", "kann", ",", "als", "wenn", "ein", "Plaud\u00b7rer", "schreyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVINF", "VMFIN", "$,", "KOKOM", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So heilt den gr\u00f6ssten Schmerz, Geduld, Vernunft und Zeit.", "tokens": ["So", "heilt", "den", "gr\u00f6ss\u00b7ten", "Schmerz", ",", "Ge\u00b7duld", ",", "Ver\u00b7nunft", "und", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Das Gl\u00fccksrad ist ein Ding von unsichtbarer Gr\u00f6sse", "tokens": ["Das", "Gl\u00fccks\u00b7rad", "ist", "ein", "Ding", "von", "un\u00b7sicht\u00b7ba\u00b7rer", "Gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dem einen hilft es fort, dem andern giebt es St\u00f6\u00dfe.", "tokens": ["Dem", "ei\u00b7nen", "hilft", "es", "fort", ",", "dem", "an\u00b7dern", "giebt", "es", "St\u00f6\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PRELS", "PIS", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und der sie unverdient zu einer Zeit erh\u00e4lt", "tokens": ["Und", "der", "sie", "un\u00b7ver\u00b7di\u00b7ent", "zu", "ei\u00b7ner", "Zeit", "er\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.14": {"text": "Bek\u00f6mmt zu andrer Zeit, das, was ihm wohlgef\u00e4llt", "tokens": ["Be\u00b7k\u00f6mmt", "zu", "an\u00b7drer", "Zeit", ",", "das", ",", "was", "ihm", "wohl\u00b7ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,", "PDS", "$,", "PWS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Trost dient Sp\u00f6ttern zwar zu einem frohen Lachen", "tokens": ["Der", "Trost", "dient", "Sp\u00f6t\u00b7tern", "zwar", "zu", "ei\u00b7nem", "fro\u00b7hen", "La\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Alleine die Natur der gut und b\u00f6sen Sachen", "tokens": ["Al\u00b7lei\u00b7ne", "die", "Na\u00b7tur", "der", "gut", "und", "b\u00f6\u00b7sen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ist nur am Ende rein und deutlich anzusehn.", "tokens": ["Ist", "nur", "am", "En\u00b7de", "rein", "und", "deut\u00b7lich", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ADJD", "KON", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Viel ist bereits vorbey, und viel noch nicht geschehn.", "tokens": ["Viel", "ist", "be\u00b7reits", "vor\u00b7bey", ",", "und", "viel", "noch", "nicht", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKVZ", "$,", "KON", "ADV", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das, was verflossen ist, das sind ja nur Geschichte", "tokens": ["Das", ",", "was", "ver\u00b7flos\u00b7sen", "ist", ",", "das", "sind", "ja", "nur", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PRELS", "VVPP", "VAFIN", "$,", "PDS", "VAFIN", "ADV", "ADV", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und was noch kommen soll, das leidet sein Gewichte.", "tokens": ["Und", "was", "noch", "kom\u00b7men", "soll", ",", "das", "lei\u00b7det", "sein", "Ge\u00b7wich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVINF", "VMFIN", "$,", "PDS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Zeit, die Wahrheit macht die Sachen offenbahr,", "tokens": ["Die", "Zeit", ",", "die", "Wahr\u00b7heit", "macht", "die", "Sa\u00b7chen", "of\u00b7fen\u00b7bahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und das, was b\u00f6se scheint, ist \u00f6fters gar nicht wahr.", "tokens": ["Und", "das", ",", "was", "b\u00f6\u00b7se", "scheint", ",", "ist", "\u00f6f\u00b7ters", "gar", "nicht", "wahr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Man mu\u00df das B\u00f6se nur zu seiner Bessrung brauchen", "tokens": ["Man", "mu\u00df", "das", "B\u00f6\u00b7se", "nur", "zu", "sei\u00b7ner", "Bess\u00b7rung", "brau\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da lieget der Gewinn im Herzen vor den Augen.", "tokens": ["Da", "lie\u00b7get", "der", "Ge\u00b7winn", "im", "Her\u00b7zen", "vor", "den", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wenn die Ruthe sich vom streichen abgenutzt;", "tokens": ["Und", "wenn", "die", "Ru\u00b7the", "sich", "vom", "strei\u00b7chen", "ab\u00b7ge\u00b7nutzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hat sie ein frommes Kind vollkommen ausgeputzt", "tokens": ["Hat", "sie", "ein", "from\u00b7mes", "Kind", "voll\u00b7kom\u00b7men", "aus\u00b7ge\u00b7putzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und zur Vernunft gest\u00e4rkt, ja redlich wohlgezogen", "tokens": ["Und", "zur", "Ver\u00b7nunft", "ge\u00b7st\u00e4rkt", ",", "ja", "red\u00b7lich", "wohl\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVPP", "$,", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Deswegen bleibt man auch der Ruthe so gewogen.", "tokens": ["Des\u00b7we\u00b7gen", "bleibt", "man", "auch", "der", "Ru\u00b7the", "so", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nicht, weil sie Ruthe ist, Nein! in der klugen Hand", "tokens": ["Nicht", ",", "weil", "sie", "Ru\u00b7the", "ist", ",", "Nein", "!", "in", "der", "klu\u00b7gen", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,", "PTKANT", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Verehrt man ihre Kraft; da wird sie erst bekannt", "tokens": ["Ver\u00b7ehrt", "man", "ih\u00b7re", "Kraft", ";", "da", "wird", "sie", "erst", "be\u00b7kannt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPOSAT", "NN", "$.", "ADV", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df sie sich von sich selbst nicht von der Stelle r\u00fchren", "tokens": ["Da\u00df", "sie", "sich", "von", "sich", "selbst", "nicht", "von", "der", "Stel\u00b7le", "r\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PRF", "ADV", "PTKNEG", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und niemand treffen kann. Sie mu\u00df sich lassen f\u00fchren", "tokens": ["Und", "nie\u00b7mand", "tref\u00b7fen", "kann", ".", "Sie", "mu\u00df", "sich", "las\u00b7sen", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVINF", "VMFIN", "$.", "PPER", "VMFIN", "PRF", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und thut sich selbst mit Weh. Ist der Gebrauch vorbey", "tokens": ["Und", "thut", "sich", "selbst", "mit", "Weh", ".", "Ist", "der", "Ge\u00b7brauch", "vor\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "$.", "VAFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So wird sie selber d\u00fcrr und geht von selbst entzwey.", "tokens": ["So", "wird", "sie", "sel\u00b7ber", "d\u00fcrr", "und", "geht", "von", "selbst", "ent\u00b7zwey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "VVFIN", "APPR", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Nutzen ist gemacht: Sie aber wird vergessen.", "tokens": ["Der", "Nut\u00b7zen", "ist", "ge\u00b7macht", ":", "Sie", "a\u00b7ber", "wird", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "PPER", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nun ist ein Umstand noch recht n\u00f6thig zu ermessen.", "tokens": ["Nun", "ist", "ein", "Um\u00b7stand", "noch", "recht", "n\u00f6\u00b7thig", "zu", "er\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kommt, seht uns flei\u00dfig an; Erg\u00f6tzt Euch unsre Pflicht:", "tokens": ["Kommt", ",", "seht", "uns", "flei\u00b7\u00dfig", "an", ";", "Er\u00b7g\u00f6tzt", "Euch", "uns\u00b7re", "Pflicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADJD", "PTKVZ", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und macht sie Euch noch Ruhm; O! so verge\u00dft uns nicht", "tokens": ["Und", "macht", "sie", "Euch", "noch", "Ruhm", ";", "O", "!", "so", "ver\u00b7ge\u00dft", "uns", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "NN", "$.", "NE", "$.", "ADV", "VVFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erfreut Euch \u00fcber mich. Mein Dank soll Euch zu Ehren", "tokens": ["Er\u00b7freut", "Euch", "\u00fc\u00b7ber", "mich", ".", "Mein", "Dank", "soll", "Euch", "zu", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$.", "PPOSAT", "NN", "VMFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sich an kein Ungemach und an kein Leiden kehren.", "tokens": ["Sich", "an", "kein", "Un\u00b7ge\u00b7mach", "und", "an", "kein", "Lei\u00b7den", "keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIAT", "NN", "KON", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mein erster Auftritt ist in meinem Trauerspiel", "tokens": ["Mein", "ers\u00b7ter", "Auf\u00b7tritt", "ist", "in", "mei\u00b7nem", "Trau\u00b7er\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vielleicht der letzte Schmerz. Jetzt aber brauch ich viel.", "tokens": ["Viel\u00b7leicht", "der", "letz\u00b7te", "Schmerz", ".", "Jetzt", "a\u00b7ber", "brauch", "ich", "viel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$.", "ADV", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Schaden ist geschehn. Ihr k\u00f6nnt ihn leichter machen,", "tokens": ["Der", "Scha\u00b7den", "ist", "ge\u00b7schehn", ".", "Ihr", "k\u00f6nnt", "ihn", "leich\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn Ihr uns nicht verlasst. Und kriegt Ihr nichts zu lachen:", "tokens": ["Wenn", "Ihr", "uns", "nicht", "ver\u00b7lasst", ".", "Und", "kriegt", "Ihr", "nichts", "zu", "la\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$.", "KON", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So wartet! Doch Ihr sucht nichts, als vern\u00fcnftgen Scherz,", "tokens": ["So", "war\u00b7tet", "!", "Doch", "Ihr", "sucht", "nichts", ",", "als", "ver\u00b7n\u00fcnft\u00b7gen", "Scherz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "KON", "PPER", "VVFIN", "PIS", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wo er zu suchen ist, und ehrt ein redlich Herz.", "tokens": ["Wo", "er", "zu", "su\u00b7chen", "ist", ",", "und", "ehrt", "ein", "red\u00b7lich", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKZU", "VVINF", "VAFIN", "$,", "KON", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ihr kennet Kunst und Flei\u00df. Was hab ich denn zu klagen?", "tokens": ["Ihr", "ken\u00b7net", "Kunst", "und", "Flei\u00df", ".", "Was", "hab", "ich", "denn", "zu", "kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich will an dessen statt Euch das zu Ehren sagen:", "tokens": ["Ich", "will", "an", "des\u00b7sen", "statt", "Euch", "das", "zu", "Eh\u00b7ren", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PDS", "VVFIN", "PPER", "PDS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df nur ein Leipzig ist an Klugheit und Verstand.", "tokens": ["Da\u00df", "nur", "ein", "Leip\u00b7zig", "ist", "an", "Klug\u00b7heit", "und", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NE", "VAFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Habt Dank! Ihr seyd der Welt, und ich bin Euch bekannt.", "tokens": ["Habt", "Dank", "!", "Ihr", "seyd", "der", "Welt", ",", "und", "ich", "bin", "Euch", "be\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$.", "PPER", "VAFIN", "ART", "NN", "$,", "KON", "PPER", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}