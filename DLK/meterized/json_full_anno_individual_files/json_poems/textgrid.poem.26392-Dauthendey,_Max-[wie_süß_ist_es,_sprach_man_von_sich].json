{"textgrid.poem.26392": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[wie s\u00fc\u00df ist es, sprach man von sich]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie s\u00fc\u00df ist es, sprach man von sich.", "tokens": ["Wie", "s\u00fc\u00df", "ist", "es", ",", "sprach", "man", "von", "sich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "VVFIN", "PIS", "APPR", "PRF", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Man ist nicht mehr ein stummes Ich,", "tokens": ["Man", "ist", "nicht", "mehr", "ein", "stum\u00b7mes", "Ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKNEG", "ADV", "ART", "ADJA", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man kann sich fast mit sich vers\u00f6hnen", "tokens": ["Man", "kann", "sich", "fast", "mit", "sich", "ver\u00b7s\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sich das Leben abgew\u00f6hnen.", "tokens": ["Und", "sich", "das", "Le\u00b7ben", "ab\u00b7ge\u00b7w\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man wird zum zarten Spiegelbild", "tokens": ["Man", "wird", "zum", "zar\u00b7ten", "Spie\u00b7gel\u00b7bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sieht und denkt und grinst so mild,", "tokens": ["Und", "sieht", "und", "denkt", "und", "grinst", "so", "mild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn was gewesen, ist geschehn,", "tokens": ["Denn", "was", "ge\u00b7we\u00b7sen", ",", "ist", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "VAPP", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und jeder hat's ja nicht gesehn;", "tokens": ["Und", "je\u00b7der", "hat's", "ja", "nicht", "ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und was gewesen, kommt nie wieder,", "tokens": ["Und", "was", "ge\u00b7we\u00b7sen", ",", "kommt", "nie", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAPP", "$,", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und darum schreibt man es wohl nieder.", "tokens": ["Und", "da\u00b7rum", "schreibt", "man", "es", "wohl", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Man mu\u00df es sich nur eingestehn:", "tokens": ["Man", "mu\u00df", "es", "sich", "nur", "ein\u00b7ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das Leben will vor\u00fcbergehn.", "tokens": ["Das", "Le\u00b7ben", "will", "vor\u00b7\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Denn seht, im Alter kommt ein Jahr", "tokens": ["Denn", "seht", ",", "im", "Al\u00b7ter", "kommt", "ein", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPRART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wo, was gewesen, nie ganz war,", "tokens": ["Wo", ",", "was", "ge\u00b7we\u00b7sen", ",", "nie", "ganz", "war", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PRELS", "VAPP", "$,", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dummheit von dazumal und S\u00fcnden", "tokens": ["Dumm\u00b7heit", "von", "da\u00b7zu\u00b7mal", "und", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADV", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Die werden dann zu reichen Pfr\u00fcnden,", "tokens": ["Die", "wer\u00b7den", "dann", "zu", "rei\u00b7chen", "Pfr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Erinnerung wird Kapital", "tokens": ["E\u00b7rin\u00b7ne\u00b7rung", "wird", "Ka\u00b7pi\u00b7tal"], "token_info": ["word", "word", "word"], "pos": ["NN", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Datiert auf Annodazumal.", "tokens": ["Da\u00b7tiert", "auf", "An\u00b7no\u00b7da\u00b7zu\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Denn wenn man es bei Licht besieht,", "tokens": ["Denn", "wenn", "man", "es", "bei", "Licht", "be\u00b7sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wenn was Geheimes wo geschieht,", "tokens": ["Wenn", "was", "Ge\u00b7hei\u00b7mes", "wo", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PWAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Das Heimlichste, das wird ein Fest,", "tokens": ["Das", "Heim\u00b7lichs\u00b7te", ",", "das", "wird", "ein", "Fest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wenn's sp\u00e4ter sich erz\u00e4hlen l\u00e4\u00dft.", "tokens": ["Wenn's", "sp\u00e4\u00b7ter", "sich", "er\u00b7z\u00e4h\u00b7len", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie s\u00fc\u00df ist es, sprach man von sich.", "tokens": ["Wie", "s\u00fc\u00df", "ist", "es", ",", "sprach", "man", "von", "sich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "$,", "VVFIN", "PIS", "APPR", "PRF", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Man ist nicht mehr ein stummes Ich,", "tokens": ["Man", "ist", "nicht", "mehr", "ein", "stum\u00b7mes", "Ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKNEG", "ADV", "ART", "ADJA", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man kann sich fast mit sich vers\u00f6hnen", "tokens": ["Man", "kann", "sich", "fast", "mit", "sich", "ver\u00b7s\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sich das Leben abgew\u00f6hnen.", "tokens": ["Und", "sich", "das", "Le\u00b7ben", "ab\u00b7ge\u00b7w\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man wird zum zarten Spiegelbild", "tokens": ["Man", "wird", "zum", "zar\u00b7ten", "Spie\u00b7gel\u00b7bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sieht und denkt und grinst so mild,", "tokens": ["Und", "sieht", "und", "denkt", "und", "grinst", "so", "mild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn was gewesen, ist geschehn,", "tokens": ["Denn", "was", "ge\u00b7we\u00b7sen", ",", "ist", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "VAPP", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und jeder hat's ja nicht gesehn;", "tokens": ["Und", "je\u00b7der", "hat's", "ja", "nicht", "ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und was gewesen, kommt nie wieder,", "tokens": ["Und", "was", "ge\u00b7we\u00b7sen", ",", "kommt", "nie", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAPP", "$,", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und darum schreibt man es wohl nieder.", "tokens": ["Und", "da\u00b7rum", "schreibt", "man", "es", "wohl", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Man mu\u00df es sich nur eingestehn:", "tokens": ["Man", "mu\u00df", "es", "sich", "nur", "ein\u00b7ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das Leben will vor\u00fcbergehn.", "tokens": ["Das", "Le\u00b7ben", "will", "vor\u00b7\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Denn seht, im Alter kommt ein Jahr", "tokens": ["Denn", "seht", ",", "im", "Al\u00b7ter", "kommt", "ein", "Jahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPRART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wo, was gewesen, nie ganz war,", "tokens": ["Wo", ",", "was", "ge\u00b7we\u00b7sen", ",", "nie", "ganz", "war", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PRELS", "VAPP", "$,", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dummheit von dazumal und S\u00fcnden", "tokens": ["Dumm\u00b7heit", "von", "da\u00b7zu\u00b7mal", "und", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADV", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Die werden dann zu reichen Pfr\u00fcnden,", "tokens": ["Die", "wer\u00b7den", "dann", "zu", "rei\u00b7chen", "Pfr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Erinnerung wird Kapital", "tokens": ["E\u00b7rin\u00b7ne\u00b7rung", "wird", "Ka\u00b7pi\u00b7tal"], "token_info": ["word", "word", "word"], "pos": ["NN", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Datiert auf Annodazumal.", "tokens": ["Da\u00b7tiert", "auf", "An\u00b7no\u00b7da\u00b7zu\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Denn wenn man es bei Licht besieht,", "tokens": ["Denn", "wenn", "man", "es", "bei", "Licht", "be\u00b7sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wenn was Geheimes wo geschieht,", "tokens": ["Wenn", "was", "Ge\u00b7hei\u00b7mes", "wo", "ge\u00b7schieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "PWAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Das Heimlichste, das wird ein Fest,", "tokens": ["Das", "Heim\u00b7lichs\u00b7te", ",", "das", "wird", "ein", "Fest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wenn's sp\u00e4ter sich erz\u00e4hlen l\u00e4\u00dft.", "tokens": ["Wenn's", "sp\u00e4\u00b7ter", "sich", "er\u00b7z\u00e4h\u00b7len", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}