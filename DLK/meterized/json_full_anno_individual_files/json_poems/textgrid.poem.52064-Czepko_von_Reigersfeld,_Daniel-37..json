{"textgrid.poem.52064": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "37.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tag sey gegr\u00fc\u00dft, du gieb, Apollo, Verse her,", "tokens": ["Tag", "sey", "ge\u00b7gr\u00fc\u00dft", ",", "du", "gieb", ",", "A\u00b7pol\u00b7lo", ",", "Ver\u00b7se", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "$,", "NE", "$,", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ihm sey ja kein Gew\u00fclck und dir kein Strahl zu schwer:", "tokens": ["Ihm", "sey", "ja", "kein", "Ge\u00b7w\u00fclck", "und", "dir", "kein", "Strahl", "zu", "schwer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "KON", "PPER", "PIAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Heut (und wer wolte nicht die Freud in ihm vermehrn)", "tokens": ["Heut", "(", "und", "wer", "wol\u00b7te", "nicht", "die", "Freud", "in", "ihm", "ver\u00b7mehrn", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KON", "PWS", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seh ich drey K\u00f6nige das gro\u00dfe Kind verehrn:", "tokens": ["Seh", "ich", "drey", "K\u00f6\u00b7ni\u00b7ge", "das", "gro\u00b7\u00dfe", "Kind", "ver\u00b7ehrn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Heut! ach der G\u00fcttigkeit! verehret nach Begier", "tokens": ["Heut", "!", "ach", "der", "G\u00fct\u00b7tig\u00b7keit", "!", "ver\u00b7eh\u00b7ret", "nach", "Be\u00b7gier"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "XY", "ART", "NN", "$.", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sich selbst das grosse Kind den Eltern und dann mir.", "tokens": ["Sich", "selbst", "das", "gros\u00b7se", "Kind", "den", "El\u00b7tern", "und", "dann", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "ADJA", "NN", "ART", "NN", "KON", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verzeiht es mir, so weit ein Mensch vor Sch\u00e4tze geht,", "tokens": ["Ver\u00b7zeiht", "es", "mir", ",", "so", "weit", "ein", "Mensch", "vor", "Sch\u00e4t\u00b7ze", "geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "ADJD", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nach selbigen die Welt mit ihren Kindern steht,", "tokens": ["Nach", "sel\u00b7bi\u00b7gen", "die", "Welt", "mit", "ih\u00b7ren", "Kin\u00b7dern", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "So weit geht dis Verehrn den K\u00f6niglichen bey:", "tokens": ["So", "weit", "geht", "dis", "Ver\u00b7ehrn", "den", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PDS", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dann denckt, da\u00df dis von Gott, von Menschen jenes sey.", "tokens": ["Dann", "denckt", ",", "da\u00df", "dis", "von", "Gott", ",", "von", "Men\u00b7schen", "je\u00b7nes", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PDS", "APPR", "NN", "$,", "APPR", "NN", "PDS", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Tag sey gegr\u00fc\u00dft, du gieb, Apollo, Verse her,", "tokens": ["Tag", "sey", "ge\u00b7gr\u00fc\u00dft", ",", "du", "gieb", ",", "A\u00b7pol\u00b7lo", ",", "Ver\u00b7se", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,", "PPER", "VVFIN", "$,", "NE", "$,", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ihm sey ja kein Gew\u00fclck und dir kein Strahl zu schwer:", "tokens": ["Ihm", "sey", "ja", "kein", "Ge\u00b7w\u00fclck", "und", "dir", "kein", "Strahl", "zu", "schwer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "KON", "PPER", "PIAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Heut (und wer wolte nicht die Freud in ihm vermehrn)", "tokens": ["Heut", "(", "und", "wer", "wol\u00b7te", "nicht", "die", "Freud", "in", "ihm", "ver\u00b7mehrn", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KON", "PWS", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seh ich drey K\u00f6nige das gro\u00dfe Kind verehrn:", "tokens": ["Seh", "ich", "drey", "K\u00f6\u00b7ni\u00b7ge", "das", "gro\u00b7\u00dfe", "Kind", "ver\u00b7ehrn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "CARD", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Heut! ach der G\u00fcttigkeit! verehret nach Begier", "tokens": ["Heut", "!", "ach", "der", "G\u00fct\u00b7tig\u00b7keit", "!", "ver\u00b7eh\u00b7ret", "nach", "Be\u00b7gier"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "XY", "ART", "NN", "$.", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sich selbst das grosse Kind den Eltern und dann mir.", "tokens": ["Sich", "selbst", "das", "gros\u00b7se", "Kind", "den", "El\u00b7tern", "und", "dann", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "ADJA", "NN", "ART", "NN", "KON", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verzeiht es mir, so weit ein Mensch vor Sch\u00e4tze geht,", "tokens": ["Ver\u00b7zeiht", "es", "mir", ",", "so", "weit", "ein", "Mensch", "vor", "Sch\u00e4t\u00b7ze", "geht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "ADJD", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nach selbigen die Welt mit ihren Kindern steht,", "tokens": ["Nach", "sel\u00b7bi\u00b7gen", "die", "Welt", "mit", "ih\u00b7ren", "Kin\u00b7dern", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "So weit geht dis Verehrn den K\u00f6niglichen bey:", "tokens": ["So", "weit", "geht", "dis", "Ver\u00b7ehrn", "den", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PDS", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dann denckt, da\u00df dis von Gott, von Menschen jenes sey.", "tokens": ["Dann", "denckt", ",", "da\u00df", "dis", "von", "Gott", ",", "von", "Men\u00b7schen", "je\u00b7nes", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PDS", "APPR", "NN", "$,", "APPR", "NN", "PDS", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}