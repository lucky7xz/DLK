{"textgrid.poem.34274": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ach meine Freundin todt? \u2013 den Z\u00e4hren", "genre": "verse", "period": "N.A.", "pub_year": 1771, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ach meine Freundin todt? \u2013 den Z\u00e4hren", "tokens": ["Ach", "mei\u00b7ne", "Freun\u00b7din", "todt", "?", "\u2013", "den", "Z\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ITJ", "PPOSAT", "NN", "ADJD", "$.", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um Sie darf keine Wei\u00dfheit wehren,", "tokens": ["Um", "Sie", "darf", "kei\u00b7ne", "Wei\u00df\u00b7heit", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Empfindung ehrt die gr\u00f6\u00dfte Brust:", "tokens": ["Emp\u00b7fin\u00b7dung", "ehrt", "die", "gr\u00f6\u00df\u00b7te", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch lasset uns den Tod betrachten;", "tokens": ["Doch", "las\u00b7set", "uns", "den", "Tod", "be\u00b7trach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So werden wir sie gl\u00fccklich achten,", "tokens": ["So", "wer\u00b7den", "wir", "sie", "gl\u00fcck\u00b7lich", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und unser blinder Schmerz wird Lust.", "tokens": ["Und", "un\u00b7ser", "blin\u00b7der", "Schmerz", "wird", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "O Tod! Der P\u00f6bel nur mag zittern,", "tokens": ["O", "Tod", "!", "Der", "P\u00f6\u00b7bel", "nur", "mag", "zit\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du werdest ihm sein Gl\u00fcck verbittern,", "tokens": ["Du", "wer\u00b7dest", "ihm", "sein", "Gl\u00fcck", "ver\u00b7bit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da doch das Gl\u00fcck stets mit dir zieht:", "tokens": ["Da", "doch", "das", "Gl\u00fcck", "stets", "mit", "dir", "zieht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit sch\u00f6ner Streng, um uns zu retten,", "tokens": ["Mit", "sch\u00f6\u00b7ner", "Streng", ",", "um", "uns", "zu", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zerrei\u00dfest du die tausend Ketten", "tokens": ["Zer\u00b7rei\u00b7\u00dfest", "du", "die", "tau\u00b7send", "Ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die uns ans Elend angeschmiedt.", "tokens": ["Die", "uns", "ans", "E\u00b7lend", "an\u00b7ge\u00b7schmiedt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Mit jedem Tage lernt man kl\u00e4rer,", "tokens": ["Mit", "je\u00b7dem", "Ta\u00b7ge", "lernt", "man", "kl\u00e4\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df nur der Tod der gro\u00dfe Lehrer", "tokens": ["Da\u00df", "nur", "der", "Tod", "der", "gro\u00b7\u00dfe", "Leh\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tugend und des Gl\u00fcckes sei.", "tokens": ["Der", "Tu\u00b7gend", "und", "des", "Gl\u00fc\u00b7ckes", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um gl\u00fccklich ", "tokens": ["Um", "gl\u00fcck\u00b7lich"], "token_info": ["word", "word"], "pos": ["KOUI", "ADJD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Dazu geh\u00f6ret viel Bestreben", "tokens": ["Da\u00b7zu", "ge\u00b7h\u00f6\u00b7ret", "viel", "Be\u00b7stre\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Bo\u00dfheit und der Heuchelei.", "tokens": ["Der", "Bo\u00df\u00b7heit", "und", "der", "Heu\u00b7che\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein Eigennutz der nichts verschonet", "tokens": ["Ein", "Ei\u00b7gen\u00b7nutz", "der", "nichts", "ver\u00b7scho\u00b7net"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PIS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Redlichkeit mit T\u00fccke lohnet,", "tokens": ["Und", "Red\u00b7lich\u00b7keit", "mit", "T\u00fc\u00b7cke", "loh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Bo\u00dfheit, die als Tugend glei\u00dft,", "tokens": ["Die", "Bo\u00df\u00b7heit", ",", "die", "als", "Tu\u00b7gend", "glei\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Wege findt zu den Gem\u00fcthern:", "tokens": ["Und", "We\u00b7ge", "findt", "zu", "den", "Ge\u00b7m\u00fc\u00b7thern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das sind die Mittel zu den G\u00fctern", "tokens": ["Das", "sind", "die", "Mit\u00b7tel", "zu", "den", "G\u00fc\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch die der Thor hier gl\u00fccklich hei\u00dft.", "tokens": ["Durch", "die", "der", "Thor", "hier", "gl\u00fcck\u00b7lich", "hei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Hier werden unverf\u00e4lschte Frommen", "tokens": ["Hier", "wer\u00b7den", "un\u00b7ver\u00b7f\u00e4lschte", "From\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aufs h\u00f6chste nicht in Acht genommen,", "tokens": ["Aufs", "h\u00f6chs\u00b7te", "nicht", "in", "Acht", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PTKNEG", "APPR", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo nicht verl\u00e4stert und gedr\u00fcckt.", "tokens": ["Wo", "nicht", "ver\u00b7l\u00e4s\u00b7tert", "und", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier m\u00fc\u00dfen oft die sch\u00f6nsten Seelen", "tokens": ["Hier", "m\u00fc\u00b7\u00dfen", "oft", "die", "sch\u00f6ns\u00b7ten", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sich unbemerkt im Elend qu\u00e4len", "tokens": ["Sich", "un\u00b7be\u00b7merkt", "im", "E\u00b7lend", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Thorheit ist mit Glanz geschm\u00fcckt.", "tokens": ["Und", "Thor\u00b7heit", "ist", "mit", "Glanz", "ge\u00b7schm\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mein Damon! w\u00fcnsche nicht ins Leben", "tokens": ["Mein", "Da\u00b7mon", "!", "w\u00fcn\u00b7sche", "nicht", "ins", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PTKNEG", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Gattin, die mit Glanz umgeben", "tokens": ["Die", "Gat\u00b7tin", ",", "die", "mit", "Glanz", "um\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dir z\u00e4rtlich aus dem Himmel winkt.", "tokens": ["Dir", "z\u00e4rt\u00b7lich", "aus", "dem", "Him\u00b7mel", "winkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer, kaum der wilden Fluth entschwommen,", "tokens": ["Wer", ",", "kaum", "der", "wil\u00b7den", "Fluth", "ent\u00b7schwom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "An sch\u00f6nen Ufern angekommen,", "tokens": ["An", "sch\u00f6\u00b7nen", "U\u00b7fern", "an\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Willt du da\u00df der zur\u00fccke springt?", "tokens": ["Willt", "du", "da\u00df", "der", "zu\u00b7r\u00fc\u00b7cke", "springt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.7": {"line.1": {"text": "La\u00df ab, la\u00df ab um sie zu weinen.", "tokens": ["La\u00df", "ab", ",", "la\u00df", "ab", "um", "sie", "zu", "wei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVIMP", "PTKVZ", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tod wird euch gewi\u00df vereinen:", "tokens": ["Der", "Tod", "wird", "euch", "ge\u00b7wi\u00df", "ver\u00b7ei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Leben ist ein Augenblick,", "tokens": ["Das", "Le\u00b7ben", "ist", "ein", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein tr\u00fcber Traum, ein Mittagsschlummer,", "tokens": ["Ein", "tr\u00fc\u00b7ber", "Traum", ",", "ein", "Mit\u00b7tags\u00b7schlum\u00b7mer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein unbetr\u00e4chtlich kleiner Kummer, \u2013", "tokens": ["Ein", "un\u00b7be\u00b7tr\u00e4cht\u00b7lich", "klei\u00b7ner", "Kum\u00b7mer", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Tod ist unaussprechlich Gl\u00fcck.", "tokens": ["Und", "Tod", "ist", "un\u00b7aus\u00b7sprech\u00b7lich", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ja s\u00fc\u00dfer Tod! auch mit den Meinen", "tokens": ["Ja", "s\u00fc\u00b7\u00dfer", "Tod", "!", "auch", "mit", "den", "Mei\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADJA", "NN", "$.", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wirst du mich einst gewi\u00df vereinen,", "tokens": ["Wirst", "du", "mich", "einst", "ge\u00b7wi\u00df", "ver\u00b7ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn du gebietest jedermann.", "tokens": ["Denn", "du", "ge\u00b7bie\u00b7test", "je\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du willst die Schwester mir entziehen \u2013", "tokens": ["Du", "willst", "die", "Schwes\u00b7ter", "mir", "ent\u00b7zie\u00b7hen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O warte, bis ich mit ihr fliehen", "tokens": ["O", "war\u00b7te", ",", "bis", "ich", "mit", "ihr", "flie\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu bessern Welten fliehen kann.", "tokens": ["Zu", "bes\u00b7sern", "Wel\u00b7ten", "flie\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Was sch\u00f6n ist, mu\u00df zuletzt verderben.", "tokens": ["Was", "sch\u00f6n", "ist", ",", "mu\u00df", "zu\u00b7letzt", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VMFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was liebensw\u00fcrdig ist, (das) mu\u00df sterben.", "tokens": ["Was", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "ist", ",", "(", "das", ")", "mu\u00df", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "$(", "ART", "$(", "VMFIN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Welt beh\u00e4lt kein seltnes Gut.", "tokens": ["Die", "Welt", "be\u00b7h\u00e4lt", "kein", "selt\u00b7nes", "Gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da wir hier nichts besitzen k\u00f6nnen,", "tokens": ["Da", "wir", "hier", "nichts", "be\u00b7sit\u00b7zen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So la\u00dft uns nach dem Himmel brennen \u2013", "tokens": ["So", "la\u00dft", "uns", "nach", "dem", "Him\u00b7mel", "bren\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vielleicht verzehrt uns diese Gluth.", "tokens": ["Viel\u00b7leicht", "ver\u00b7zehrt", "uns", "die\u00b7se", "Gluth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach meine Freundin todt? \u2013 den Z\u00e4hren", "tokens": ["Ach", "mei\u00b7ne", "Freun\u00b7din", "todt", "?", "\u2013", "den", "Z\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ITJ", "PPOSAT", "NN", "ADJD", "$.", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um Sie darf keine Wei\u00dfheit wehren,", "tokens": ["Um", "Sie", "darf", "kei\u00b7ne", "Wei\u00df\u00b7heit", "weh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Empfindung ehrt die gr\u00f6\u00dfte Brust:", "tokens": ["Emp\u00b7fin\u00b7dung", "ehrt", "die", "gr\u00f6\u00df\u00b7te", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch lasset uns den Tod betrachten;", "tokens": ["Doch", "las\u00b7set", "uns", "den", "Tod", "be\u00b7trach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So werden wir sie gl\u00fccklich achten,", "tokens": ["So", "wer\u00b7den", "wir", "sie", "gl\u00fcck\u00b7lich", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und unser blinder Schmerz wird Lust.", "tokens": ["Und", "un\u00b7ser", "blin\u00b7der", "Schmerz", "wird", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "O Tod! Der P\u00f6bel nur mag zittern,", "tokens": ["O", "Tod", "!", "Der", "P\u00f6\u00b7bel", "nur", "mag", "zit\u00b7tern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du werdest ihm sein Gl\u00fcck verbittern,", "tokens": ["Du", "wer\u00b7dest", "ihm", "sein", "Gl\u00fcck", "ver\u00b7bit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da doch das Gl\u00fcck stets mit dir zieht:", "tokens": ["Da", "doch", "das", "Gl\u00fcck", "stets", "mit", "dir", "zieht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit sch\u00f6ner Streng, um uns zu retten,", "tokens": ["Mit", "sch\u00f6\u00b7ner", "Streng", ",", "um", "uns", "zu", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zerrei\u00dfest du die tausend Ketten", "tokens": ["Zer\u00b7rei\u00b7\u00dfest", "du", "die", "tau\u00b7send", "Ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die uns ans Elend angeschmiedt.", "tokens": ["Die", "uns", "ans", "E\u00b7lend", "an\u00b7ge\u00b7schmiedt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Mit jedem Tage lernt man kl\u00e4rer,", "tokens": ["Mit", "je\u00b7dem", "Ta\u00b7ge", "lernt", "man", "kl\u00e4\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df nur der Tod der gro\u00dfe Lehrer", "tokens": ["Da\u00df", "nur", "der", "Tod", "der", "gro\u00b7\u00dfe", "Leh\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tugend und des Gl\u00fcckes sei.", "tokens": ["Der", "Tu\u00b7gend", "und", "des", "Gl\u00fc\u00b7ckes", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um gl\u00fccklich ", "tokens": ["Um", "gl\u00fcck\u00b7lich"], "token_info": ["word", "word"], "pos": ["KOUI", "ADJD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Dazu geh\u00f6ret viel Bestreben", "tokens": ["Da\u00b7zu", "ge\u00b7h\u00f6\u00b7ret", "viel", "Be\u00b7stre\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Bo\u00dfheit und der Heuchelei.", "tokens": ["Der", "Bo\u00df\u00b7heit", "und", "der", "Heu\u00b7che\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ein Eigennutz der nichts verschonet", "tokens": ["Ein", "Ei\u00b7gen\u00b7nutz", "der", "nichts", "ver\u00b7scho\u00b7net"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PIS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Redlichkeit mit T\u00fccke lohnet,", "tokens": ["Und", "Red\u00b7lich\u00b7keit", "mit", "T\u00fc\u00b7cke", "loh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Bo\u00dfheit, die als Tugend glei\u00dft,", "tokens": ["Die", "Bo\u00df\u00b7heit", ",", "die", "als", "Tu\u00b7gend", "glei\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Wege findt zu den Gem\u00fcthern:", "tokens": ["Und", "We\u00b7ge", "findt", "zu", "den", "Ge\u00b7m\u00fc\u00b7thern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das sind die Mittel zu den G\u00fctern", "tokens": ["Das", "sind", "die", "Mit\u00b7tel", "zu", "den", "G\u00fc\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch die der Thor hier gl\u00fccklich hei\u00dft.", "tokens": ["Durch", "die", "der", "Thor", "hier", "gl\u00fcck\u00b7lich", "hei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Hier werden unverf\u00e4lschte Frommen", "tokens": ["Hier", "wer\u00b7den", "un\u00b7ver\u00b7f\u00e4lschte", "From\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Aufs h\u00f6chste nicht in Acht genommen,", "tokens": ["Aufs", "h\u00f6chs\u00b7te", "nicht", "in", "Acht", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PTKNEG", "APPR", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo nicht verl\u00e4stert und gedr\u00fcckt.", "tokens": ["Wo", "nicht", "ver\u00b7l\u00e4s\u00b7tert", "und", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier m\u00fc\u00dfen oft die sch\u00f6nsten Seelen", "tokens": ["Hier", "m\u00fc\u00b7\u00dfen", "oft", "die", "sch\u00f6ns\u00b7ten", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sich unbemerkt im Elend qu\u00e4len", "tokens": ["Sich", "un\u00b7be\u00b7merkt", "im", "E\u00b7lend", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Thorheit ist mit Glanz geschm\u00fcckt.", "tokens": ["Und", "Thor\u00b7heit", "ist", "mit", "Glanz", "ge\u00b7schm\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Mein Damon! w\u00fcnsche nicht ins Leben", "tokens": ["Mein", "Da\u00b7mon", "!", "w\u00fcn\u00b7sche", "nicht", "ins", "Le\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PTKNEG", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Gattin, die mit Glanz umgeben", "tokens": ["Die", "Gat\u00b7tin", ",", "die", "mit", "Glanz", "um\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dir z\u00e4rtlich aus dem Himmel winkt.", "tokens": ["Dir", "z\u00e4rt\u00b7lich", "aus", "dem", "Him\u00b7mel", "winkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wer, kaum der wilden Fluth entschwommen,", "tokens": ["Wer", ",", "kaum", "der", "wil\u00b7den", "Fluth", "ent\u00b7schwom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "An sch\u00f6nen Ufern angekommen,", "tokens": ["An", "sch\u00f6\u00b7nen", "U\u00b7fern", "an\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Willt du da\u00df der zur\u00fccke springt?", "tokens": ["Willt", "du", "da\u00df", "der", "zu\u00b7r\u00fc\u00b7cke", "springt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.16": {"line.1": {"text": "La\u00df ab, la\u00df ab um sie zu weinen.", "tokens": ["La\u00df", "ab", ",", "la\u00df", "ab", "um", "sie", "zu", "wei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVIMP", "PTKVZ", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tod wird euch gewi\u00df vereinen:", "tokens": ["Der", "Tod", "wird", "euch", "ge\u00b7wi\u00df", "ver\u00b7ei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Leben ist ein Augenblick,", "tokens": ["Das", "Le\u00b7ben", "ist", "ein", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein tr\u00fcber Traum, ein Mittagsschlummer,", "tokens": ["Ein", "tr\u00fc\u00b7ber", "Traum", ",", "ein", "Mit\u00b7tags\u00b7schlum\u00b7mer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein unbetr\u00e4chtlich kleiner Kummer, \u2013", "tokens": ["Ein", "un\u00b7be\u00b7tr\u00e4cht\u00b7lich", "klei\u00b7ner", "Kum\u00b7mer", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Tod ist unaussprechlich Gl\u00fcck.", "tokens": ["Und", "Tod", "ist", "un\u00b7aus\u00b7sprech\u00b7lich", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ja s\u00fc\u00dfer Tod! auch mit den Meinen", "tokens": ["Ja", "s\u00fc\u00b7\u00dfer", "Tod", "!", "auch", "mit", "den", "Mei\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADJA", "NN", "$.", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wirst du mich einst gewi\u00df vereinen,", "tokens": ["Wirst", "du", "mich", "einst", "ge\u00b7wi\u00df", "ver\u00b7ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn du gebietest jedermann.", "tokens": ["Denn", "du", "ge\u00b7bie\u00b7test", "je\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du willst die Schwester mir entziehen \u2013", "tokens": ["Du", "willst", "die", "Schwes\u00b7ter", "mir", "ent\u00b7zie\u00b7hen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "O warte, bis ich mit ihr fliehen", "tokens": ["O", "war\u00b7te", ",", "bis", "ich", "mit", "ihr", "flie\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu bessern Welten fliehen kann.", "tokens": ["Zu", "bes\u00b7sern", "Wel\u00b7ten", "flie\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Was sch\u00f6n ist, mu\u00df zuletzt verderben.", "tokens": ["Was", "sch\u00f6n", "ist", ",", "mu\u00df", "zu\u00b7letzt", "ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VMFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was liebensw\u00fcrdig ist, (das) mu\u00df sterben.", "tokens": ["Was", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "ist", ",", "(", "das", ")", "mu\u00df", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "$(", "ART", "$(", "VMFIN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Welt beh\u00e4lt kein seltnes Gut.", "tokens": ["Die", "Welt", "be\u00b7h\u00e4lt", "kein", "selt\u00b7nes", "Gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da wir hier nichts besitzen k\u00f6nnen,", "tokens": ["Da", "wir", "hier", "nichts", "be\u00b7sit\u00b7zen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So la\u00dft uns nach dem Himmel brennen \u2013", "tokens": ["So", "la\u00dft", "uns", "nach", "dem", "Him\u00b7mel", "bren\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vielleicht verzehrt uns diese Gluth.", "tokens": ["Viel\u00b7leicht", "ver\u00b7zehrt", "uns", "die\u00b7se", "Gluth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}