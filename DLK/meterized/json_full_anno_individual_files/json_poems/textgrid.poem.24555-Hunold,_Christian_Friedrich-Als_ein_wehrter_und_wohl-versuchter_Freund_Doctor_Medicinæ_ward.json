{"textgrid.poem.24555": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Als ein wehrter und wohl-versuchter Freund Doctor Medicin\u00e6 ward", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn/ Hochgesch\u00e4tzter Freund/ dich nun die W\u00fcrde schm\u00fcckt/", "tokens": ["Wenn", "/", "Hoch\u00b7ge\u00b7sch\u00e4tz\u00b7ter", "Freund", "/", "dich", "nun", "die", "W\u00fcr\u00b7de", "schm\u00fcckt", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ADJA", "NN", "$(", "PPER", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die muntre Musen kr\u00f6nt/ gelehrte K\u00f6pfe zieret/", "tokens": ["Die", "mun\u00b7tre", "Mu\u00b7sen", "kr\u00f6nt", "/", "ge\u00b7lehr\u00b7te", "K\u00f6p\u00b7fe", "zie\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn man den ", "tokens": ["Wenn", "man", "den"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Und dein verdienter Prei\u00df der Freunde Hertzen r\u00fchret:", "tokens": ["Und", "dein", "ver\u00b7dien\u00b7ter", "Prei\u00df", "der", "Freun\u00b7de", "Hert\u00b7zen", "r\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "So glaube da\u00df ich auch mit Wahrheit freudig sey/", "tokens": ["So", "glau\u00b7be", "da\u00df", "ich", "auch", "mit", "Wahr\u00b7heit", "freu\u00b7dig", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOUS", "PPER", "ADV", "APPR", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So redlich/ wenn ich dir zu deinem Ruhm was schreibe/", "tokens": ["So", "red\u00b7lich", "/", "wenn", "ich", "dir", "zu", "dei\u00b7nem", "Ruhm", "was", "schrei\u00b7be", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KOUS", "PPER", "PPER", "APPR", "PPOSAT", "NN", "PWS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als wie du selber bist/ und da\u00df die Schmeicheley/", "tokens": ["Als", "wie", "du", "sel\u00b7ber", "bist", "/", "und", "da\u00df", "die", "Schmei\u00b7che\u00b7ley", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "ADV", "VAFIN", "$(", "KON", "KOUS", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die sonst hierbey gemein/ mich keines weges treibe.", "tokens": ["Die", "sonst", "hier\u00b7bey", "ge\u00b7mein", "/", "mich", "kei\u00b7nes", "we\u00b7ges", "trei\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "$(", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dein Wesen/ welches mir wie andern wohlgef\u00e4llt/", "tokens": ["Dein", "We\u00b7sen", "/", "wel\u00b7ches", "mir", "wie", "an\u00b7dern", "wohl\u00b7ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PWS", "PPER", "KOKOM", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die kluge H\u00f6flichkeit/ dein unverf\u00e4lscht Gem\u00fcthe/", "tokens": ["Die", "klu\u00b7ge", "H\u00f6f\u00b7lich\u00b7keit", "/", "dein", "un\u00b7ver\u00b7f\u00e4lscht", "Ge\u00b7m\u00fc\u00b7the", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das aus der Stirne spielt/ empfehlen dich der Welt/", "tokens": ["Das", "aus", "der", "Stir\u00b7ne", "spielt", "/", "emp\u00b7feh\u00b7len", "dich", "der", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$(", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die Gelehrsamkeit ist auch von gleicher G\u00fcte.", "tokens": ["Und", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit", "ist", "auch", "von", "glei\u00b7cher", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Von diesem Saal-", "tokens": ["Von", "die\u00b7sem", "Saa\u00b7l"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "TRUNC"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Da du den Grund gelegt/ drauf Gl\u00fcck und Ehre bauen/", "tokens": ["Da", "du", "den", "Grund", "ge\u00b7legt", "/", "drauf", "Gl\u00fcck", "und", "Eh\u00b7re", "bau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$(", "PAV", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Begabst du dich ins Feld/ alwo die Tapferkeit", "tokens": ["Be\u00b7gabst", "du", "dich", "ins", "Feld", "/", "al\u00b7wo", "die", "Tap\u00b7fer\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey ihren Thaten dir lie\u00df viel Erfahrung schauen.", "tokens": ["Bey", "ih\u00b7ren", "Tha\u00b7ten", "dir", "lie\u00df", "viel", "Er\u00b7fah\u00b7rung", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Helden unsers Reichs bezeigten ihren Muth/", "tokens": ["Die", "Hel\u00b7den", "un\u00b7sers", "Reichs", "be\u00b7zeig\u00b7ten", "ih\u00b7ren", "Muth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du aber deine Kunst/ wenn sie den Feind geschlagen.", "tokens": ["Du", "a\u00b7ber", "dei\u00b7ne", "Kunst", "/", "wenn", "sie", "den", "Feind", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn billig sorget man vor so h\u00f6chst sch\u00e4tzbar Blut/", "tokens": ["Denn", "bil\u00b7lig", "sor\u00b7get", "man", "vor", "so", "h\u00f6chst", "sch\u00e4tz\u00b7bar", "Blut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "APPR", "ADV", "ADV", "ADJD", "NN", "$("], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und solche Musen kan ", "tokens": ["Und", "sol\u00b7che", "Mu\u00b7sen", "kan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VMFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und reicht der Ehre Lohn/ der dir vorl\u00e4ngst gegr\u00fcnet/", "tokens": ["Und", "reicht", "der", "Eh\u00b7re", "Lohn", "/", "der", "dir", "vor\u00b7l\u00e4ngst", "ge\u00b7gr\u00fc\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "$(", "PRELS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn deine Wissenschafft/ dein wohl erfahrner Lauf/", "tokens": ["Denn", "dei\u00b7ne", "Wis\u00b7sen\u00b7schafft", "/", "dein", "wohl", "er\u00b7fahr\u00b7ner", "Lauf", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$(", "PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat einen ", "tokens": ["Hat", "ei\u00b7nen"], "token_info": ["word", "word"], "pos": ["VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.7": {"line.1": {"text": "Ich w\u00fcnsche Gl\u00fcck darzu; und dieses noch dabey/", "tokens": ["Ich", "w\u00fcn\u00b7sche", "Gl\u00fcck", "dar\u00b7zu", ";", "und", "die\u00b7ses", "noch", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PAV", "$.", "KON", "PDS", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df/ wirst du dich ins Feld nun wiederum begeben/", "tokens": ["Da\u00df", "/", "wirst", "du", "dich", "ins", "Feld", "nun", "wie\u00b7de\u00b7rum", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "VAFIN", "PPER", "PRF", "APPRART", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df deine Cur sein Heil/ sein Heil dir sey das Leben.", "tokens": ["Da\u00df", "dei\u00b7ne", "Cur", "sein", "Heil", "/", "sein", "Heil", "dir", "sey", "das", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Wenn/ Hochgesch\u00e4tzter Freund/ dich nun die W\u00fcrde schm\u00fcckt/", "tokens": ["Wenn", "/", "Hoch\u00b7ge\u00b7sch\u00e4tz\u00b7ter", "Freund", "/", "dich", "nun", "die", "W\u00fcr\u00b7de", "schm\u00fcckt", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ADJA", "NN", "$(", "PPER", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die muntre Musen kr\u00f6nt/ gelehrte K\u00f6pfe zieret/", "tokens": ["Die", "mun\u00b7tre", "Mu\u00b7sen", "kr\u00f6nt", "/", "ge\u00b7lehr\u00b7te", "K\u00f6p\u00b7fe", "zie\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn man den ", "tokens": ["Wenn", "man", "den"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Und dein verdienter Prei\u00df der Freunde Hertzen r\u00fchret:", "tokens": ["Und", "dein", "ver\u00b7dien\u00b7ter", "Prei\u00df", "der", "Freun\u00b7de", "Hert\u00b7zen", "r\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "So glaube da\u00df ich auch mit Wahrheit freudig sey/", "tokens": ["So", "glau\u00b7be", "da\u00df", "ich", "auch", "mit", "Wahr\u00b7heit", "freu\u00b7dig", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOUS", "PPER", "ADV", "APPR", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So redlich/ wenn ich dir zu deinem Ruhm was schreibe/", "tokens": ["So", "red\u00b7lich", "/", "wenn", "ich", "dir", "zu", "dei\u00b7nem", "Ruhm", "was", "schrei\u00b7be", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KOUS", "PPER", "PPER", "APPR", "PPOSAT", "NN", "PWS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als wie du selber bist/ und da\u00df die Schmeicheley/", "tokens": ["Als", "wie", "du", "sel\u00b7ber", "bist", "/", "und", "da\u00df", "die", "Schmei\u00b7che\u00b7ley", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "ADV", "VAFIN", "$(", "KON", "KOUS", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die sonst hierbey gemein/ mich keines weges treibe.", "tokens": ["Die", "sonst", "hier\u00b7bey", "ge\u00b7mein", "/", "mich", "kei\u00b7nes", "we\u00b7ges", "trei\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "$(", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Dein Wesen/ welches mir wie andern wohlgef\u00e4llt/", "tokens": ["Dein", "We\u00b7sen", "/", "wel\u00b7ches", "mir", "wie", "an\u00b7dern", "wohl\u00b7ge\u00b7f\u00e4llt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PWS", "PPER", "KOKOM", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die kluge H\u00f6flichkeit/ dein unverf\u00e4lscht Gem\u00fcthe/", "tokens": ["Die", "klu\u00b7ge", "H\u00f6f\u00b7lich\u00b7keit", "/", "dein", "un\u00b7ver\u00b7f\u00e4lscht", "Ge\u00b7m\u00fc\u00b7the", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das aus der Stirne spielt/ empfehlen dich der Welt/", "tokens": ["Das", "aus", "der", "Stir\u00b7ne", "spielt", "/", "emp\u00b7feh\u00b7len", "dich", "der", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$(", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und die Gelehrsamkeit ist auch von gleicher G\u00fcte.", "tokens": ["Und", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit", "ist", "auch", "von", "glei\u00b7cher", "G\u00fc\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Von diesem Saal-", "tokens": ["Von", "die\u00b7sem", "Saa\u00b7l"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "TRUNC"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Da du den Grund gelegt/ drauf Gl\u00fcck und Ehre bauen/", "tokens": ["Da", "du", "den", "Grund", "ge\u00b7legt", "/", "drauf", "Gl\u00fcck", "und", "Eh\u00b7re", "bau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$(", "PAV", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Begabst du dich ins Feld/ alwo die Tapferkeit", "tokens": ["Be\u00b7gabst", "du", "dich", "ins", "Feld", "/", "al\u00b7wo", "die", "Tap\u00b7fer\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "APPRART", "NN", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey ihren Thaten dir lie\u00df viel Erfahrung schauen.", "tokens": ["Bey", "ih\u00b7ren", "Tha\u00b7ten", "dir", "lie\u00df", "viel", "Er\u00b7fah\u00b7rung", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Die Helden unsers Reichs bezeigten ihren Muth/", "tokens": ["Die", "Hel\u00b7den", "un\u00b7sers", "Reichs", "be\u00b7zeig\u00b7ten", "ih\u00b7ren", "Muth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du aber deine Kunst/ wenn sie den Feind geschlagen.", "tokens": ["Du", "a\u00b7ber", "dei\u00b7ne", "Kunst", "/", "wenn", "sie", "den", "Feind", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn billig sorget man vor so h\u00f6chst sch\u00e4tzbar Blut/", "tokens": ["Denn", "bil\u00b7lig", "sor\u00b7get", "man", "vor", "so", "h\u00f6chst", "sch\u00e4tz\u00b7bar", "Blut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "APPR", "ADV", "ADV", "ADJD", "NN", "$("], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und solche Musen kan ", "tokens": ["Und", "sol\u00b7che", "Mu\u00b7sen", "kan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VMFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Und reicht der Ehre Lohn/ der dir vorl\u00e4ngst gegr\u00fcnet/", "tokens": ["Und", "reicht", "der", "Eh\u00b7re", "Lohn", "/", "der", "dir", "vor\u00b7l\u00e4ngst", "ge\u00b7gr\u00fc\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "$(", "PRELS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn deine Wissenschafft/ dein wohl erfahrner Lauf/", "tokens": ["Denn", "dei\u00b7ne", "Wis\u00b7sen\u00b7schafft", "/", "dein", "wohl", "er\u00b7fahr\u00b7ner", "Lauf", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$(", "PPOSAT", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat einen ", "tokens": ["Hat", "ei\u00b7nen"], "token_info": ["word", "word"], "pos": ["VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.14": {"line.1": {"text": "Ich w\u00fcnsche Gl\u00fcck darzu; und dieses noch dabey/", "tokens": ["Ich", "w\u00fcn\u00b7sche", "Gl\u00fcck", "dar\u00b7zu", ";", "und", "die\u00b7ses", "noch", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PAV", "$.", "KON", "PDS", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df/ wirst du dich ins Feld nun wiederum begeben/", "tokens": ["Da\u00df", "/", "wirst", "du", "dich", "ins", "Feld", "nun", "wie\u00b7de\u00b7rum", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "VAFIN", "PPER", "PRF", "APPRART", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df deine Cur sein Heil/ sein Heil dir sey das Leben.", "tokens": ["Da\u00df", "dei\u00b7ne", "Cur", "sein", "Heil", "/", "sein", "Heil", "dir", "sey", "das", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}