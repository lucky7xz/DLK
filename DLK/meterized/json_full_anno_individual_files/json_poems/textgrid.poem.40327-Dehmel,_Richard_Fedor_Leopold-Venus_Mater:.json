{"textgrid.poem.40327": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Venus Mater:", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tr\u00e4ume, tr\u00e4ume, du mein s\u00fc\u00dfes Leben,", "tokens": ["Tr\u00e4u\u00b7me", ",", "tr\u00e4u\u00b7me", ",", "du", "mein", "s\u00fc\u00b7\u00dfes", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "von dem Himmel, der die Blumen bringt;", "tokens": ["von", "dem", "Him\u00b7mel", ",", "der", "die", "Blu\u00b7men", "bringt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Bl\u00fcten schimmern da, die beben", "tokens": ["Bl\u00fc\u00b7ten", "schim\u00b7mern", "da", ",", "die", "be\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "$,", "PRELS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "von dem Lied, das deine Mutter singt.", "tokens": ["von", "dem", "Lied", ",", "das", "dei\u00b7ne", "Mut\u00b7ter", "singt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Tr\u00e4ume, tr\u00e4ume, Knospe meiner Sorgen,", "tokens": ["Tr\u00e4u\u00b7me", ",", "tr\u00e4u\u00b7me", ",", "Knos\u00b7pe", "mei\u00b7ner", "Sor\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "von dem Tage, da die Blume spro\u00df;", "tokens": ["von", "dem", "Ta\u00b7ge", ",", "da", "die", "Blu\u00b7me", "spro\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "von dem hellen Bl\u00fctenmorgen,", "tokens": ["von", "dem", "hel\u00b7len", "Bl\u00fc\u00b7ten\u00b7mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da dein Seelchen sich der Welt erschlo\u00df.", "tokens": ["da", "dein", "Seel\u00b7chen", "sich", "der", "Welt", "er\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Tr\u00e4ume, tr\u00e4ume, Bl\u00fcte meiner Liebe,", "tokens": ["Tr\u00e4u\u00b7me", ",", "tr\u00e4u\u00b7me", ",", "Bl\u00fc\u00b7te", "mei\u00b7ner", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "von der stillen, von der heiligen Nacht,", "tokens": ["von", "der", "stil\u00b7len", ",", "von", "der", "hei\u00b7li\u00b7gen", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "da die Blume Seiner Liebe", "tokens": ["da", "die", "Blu\u00b7me", "Sei\u00b7ner", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "diese Welt zum Himmel mir gemacht.", "tokens": ["die\u00b7se", "Welt", "zum", "Him\u00b7mel", "mir", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPRART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.5": {"line.1": {"text": "Und gleich ihr in Demut hingegeben", "tokens": ["Und", "gleich", "ihr", "in", "De\u00b7mut", "hin\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "sollt ich stolz mich Vater nennen.", "tokens": ["sollt", "ich", "stolz", "mich", "Va\u00b7ter", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor mir lag dies Kl\u00fcmpchen Leben,", "tokens": ["Vor", "mir", "lag", "dies", "Kl\u00fcmp\u00b7chen", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDS", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kaum als Menschlein zu erkennen:", "tokens": ["kaum", "als", "Mensc\u00b7hlein", "zu", "er\u00b7ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "eine Laune meiner Lenden \u2013", "tokens": ["ei\u00b7ne", "Lau\u00b7ne", "mei\u00b7ner", "Len\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Daran sollt ich Gottgeist mich ergetzen?", "tokens": ["Da\u00b7ran", "sollt", "ich", "Gott\u00b7geist", "mich", "er\u00b7get\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "NN", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Damit sollt ich Weltumw\u00e4lzender enden?", "tokens": ["Da\u00b7mit", "sollt", "ich", "Wel\u00b7tum\u00b7w\u00e4l\u00b7zen\u00b7der", "en\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich erkannte mit Entsetzen", "tokens": ["Ich", "er\u00b7kann\u00b7te", "mit", "Ent\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Tr\u00e4ume, tr\u00e4ume, du mein s\u00fc\u00dfes Leben,", "tokens": ["Tr\u00e4u\u00b7me", ",", "tr\u00e4u\u00b7me", ",", "du", "mein", "s\u00fc\u00b7\u00dfes", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "von dem Himmel, der die Blumen bringt;", "tokens": ["von", "dem", "Him\u00b7mel", ",", "der", "die", "Blu\u00b7men", "bringt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Bl\u00fcten schimmern da, die beben", "tokens": ["Bl\u00fc\u00b7ten", "schim\u00b7mern", "da", ",", "die", "be\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "$,", "PRELS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "von dem Lied, das deine Mutter singt.", "tokens": ["von", "dem", "Lied", ",", "das", "dei\u00b7ne", "Mut\u00b7ter", "singt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Tr\u00e4ume, tr\u00e4ume, Knospe meiner Sorgen,", "tokens": ["Tr\u00e4u\u00b7me", ",", "tr\u00e4u\u00b7me", ",", "Knos\u00b7pe", "mei\u00b7ner", "Sor\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "von dem Tage, da die Blume spro\u00df;", "tokens": ["von", "dem", "Ta\u00b7ge", ",", "da", "die", "Blu\u00b7me", "spro\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "von dem hellen Bl\u00fctenmorgen,", "tokens": ["von", "dem", "hel\u00b7len", "Bl\u00fc\u00b7ten\u00b7mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da dein Seelchen sich der Welt erschlo\u00df.", "tokens": ["da", "dein", "Seel\u00b7chen", "sich", "der", "Welt", "er\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Tr\u00e4ume, tr\u00e4ume, Bl\u00fcte meiner Liebe,", "tokens": ["Tr\u00e4u\u00b7me", ",", "tr\u00e4u\u00b7me", ",", "Bl\u00fc\u00b7te", "mei\u00b7ner", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "von der stillen, von der heiligen Nacht,", "tokens": ["von", "der", "stil\u00b7len", ",", "von", "der", "hei\u00b7li\u00b7gen", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "da die Blume Seiner Liebe", "tokens": ["da", "die", "Blu\u00b7me", "Sei\u00b7ner", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "diese Welt zum Himmel mir gemacht.", "tokens": ["die\u00b7se", "Welt", "zum", "Him\u00b7mel", "mir", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPRART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.11": {"line.1": {"text": "Und gleich ihr in Demut hingegeben", "tokens": ["Und", "gleich", "ihr", "in", "De\u00b7mut", "hin\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPOSAT", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "sollt ich stolz mich Vater nennen.", "tokens": ["sollt", "ich", "stolz", "mich", "Va\u00b7ter", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor mir lag dies Kl\u00fcmpchen Leben,", "tokens": ["Vor", "mir", "lag", "dies", "Kl\u00fcmp\u00b7chen", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDS", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kaum als Menschlein zu erkennen:", "tokens": ["kaum", "als", "Mensc\u00b7hlein", "zu", "er\u00b7ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "eine Laune meiner Lenden \u2013", "tokens": ["ei\u00b7ne", "Lau\u00b7ne", "mei\u00b7ner", "Len\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Daran sollt ich Gottgeist mich ergetzen?", "tokens": ["Da\u00b7ran", "sollt", "ich", "Gott\u00b7geist", "mich", "er\u00b7get\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "NN", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Damit sollt ich Weltumw\u00e4lzender enden?", "tokens": ["Da\u00b7mit", "sollt", "ich", "Wel\u00b7tum\u00b7w\u00e4l\u00b7zen\u00b7der", "en\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich erkannte mit Entsetzen", "tokens": ["Ich", "er\u00b7kann\u00b7te", "mit", "Ent\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}