{"dta.poem.1335": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Himmel-Schl\u00fcssel  \n oder  \n Geistliche Gedichte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Auff ihr edlen Zioninnen/", "tokens": ["Auff", "ihr", "ed\u00b7len", "Zi\u00b7o\u00b7nin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Salems T\u00f6chter/ macht euch auff!", "tokens": ["Sa\u00b7lems", "T\u00f6ch\u00b7ter", "/", "macht", "euch", "auff", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$(", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auff! ermuntert Geist und Sinnen/", "tokens": ["Auff", "!", "er\u00b7mun\u00b7tert", "Geist", "und", "Sin\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Last der Freude freyen Lauff/", "tokens": ["Last", "der", "Freu\u00b7de", "frey\u00b7en", "Lauff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Singt und spielt ein Lied zu Ruhme", "tokens": ["Singt", "und", "spielt", "ein", "Lied", "zu", "Ruh\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Aller Jungfern Cron und Blume!", "tokens": ["Al\u00b7ler", "Jung\u00b7fern", "Cron", "und", "Blu\u00b7me", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NE", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Unter allen Welt-Geschlechtern", "tokens": ["Un\u00b7ter", "al\u00b7len", "Welt\u00b7Ge\u00b7schlech\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4llt das Lo\u00df auff Jud\u00e4 Rei\u00df/", "tokens": ["F\u00e4llt", "das", "Lo\u00df", "auff", "Ju\u00b7d\u00e4", "Rei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NE", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und von tausend Davids-T\u00f6chtern/", "tokens": ["Und", "von", "tau\u00b7send", "Da\u00b7vids\u00b7T\u00f6ch\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die das Land zu z\u00e4hlen wei\u00df/", "tokens": ["Die", "das", "Land", "zu", "z\u00e4h\u00b7len", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hat Marien GOtt erlesen/", "tokens": ["Hat", "Ma\u00b7ri\u00b7en", "Gott", "er\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seines Sohnes zu genesen.", "tokens": ["Sei\u00b7nes", "Soh\u00b7nes", "zu", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Eva hat den Tod gebohren", "tokens": ["E\u00b7va", "hat", "den", "Tod", "ge\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch verbotne Kost und Lust:", "tokens": ["Durch", "ver\u00b7bot\u00b7ne", "Kost", "und", "Lust", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Diese hat GOtt auserkohren/", "tokens": ["Die\u00b7se", "hat", "Gott", "au\u00b7ser\u00b7koh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der kein fremder Trieb bewust/", "tokens": ["Der", "kein", "frem\u00b7der", "Trieb", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aller Welt durch ihr geb\u00e4hren", "tokens": ["Al\u00b7ler", "Welt", "durch", "ihr", "ge\u00b7b\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Heyl und Leben zu Gewehren.", "tokens": ["Heyl", "und", "Le\u00b7ben", "zu", "Ge\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Macht die List der falschen Schlange/", "tokens": ["Macht", "die", "List", "der", "fal\u00b7schen", "Schlan\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die uns bracht ums Paradi\u00df/", "tokens": ["Die", "uns", "bracht", "ums", "Pa\u00b7ra\u00b7di\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPRART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unsern ersten Eltern bange", "tokens": ["Un\u00b7sern", "ers\u00b7ten", "El\u00b7tern", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcr den k\u00fchnen Apffel-Bi\u00df;", "tokens": ["F\u00fcr", "den", "k\u00fch\u00b7nen", "Apf\u00b7fel\u00b7Bi\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Den Zertreter dieser Schlangen", "tokens": ["Den", "Zer\u00b7tre\u00b7ter", "die\u00b7ser", "Schlan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat Maria heut empfangen.", "tokens": ["Hat", "Ma\u00b7ria", "heut", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Aus der H\u00f6he k\u00f6mmt hernieder", "tokens": ["Aus", "der", "H\u00f6\u00b7he", "k\u00f6mmt", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Selbst der reine Wunder-Geist/", "tokens": ["Selbst", "der", "rei\u00b7ne", "Wun\u00b7der\u00b7Geist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uberschattet ihre Glieder/", "tokens": ["U\u00b7ber\u00b7schat\u00b7tet", "ih\u00b7re", "Glie\u00b7der", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie JEsus Mutter heist/", "tokens": ["Da\u00df", "sie", "Je\u00b7sus", "Mut\u00b7ter", "heist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gott hat sie zur Braut erw\u00e4hlet/", "tokens": ["Gott", "hat", "sie", "zur", "Braut", "er\u00b7w\u00e4h\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und sich selbst mit ihr verm\u00e4hlet.", "tokens": ["Und", "sich", "selbst", "mit", "ihr", "ver\u00b7m\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Reine Mutter/ keusch von Hertzen/", "tokens": ["Rei\u00b7ne", "Mut\u00b7ter", "/", "keusch", "von", "Hert\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Voll von heisser Andachts-Glutt/", "tokens": ["Voll", "von", "heis\u00b7ser", "An\u00b7dachts\u00b7Glutt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die ohn Jungfrauschaffts Verschertzen", "tokens": ["Die", "ohn", "Jung\u00b7frausc\u00b7haffts", "Ver\u00b7schert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bracht zur Welt das h\u00f6chste Gutt/", "tokens": ["Bracht", "zur", "Welt", "das", "h\u00f6chs\u00b7te", "Gutt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Billich wird von allen Zungen", "tokens": ["Bil\u00b7lich", "wird", "von", "al\u00b7len", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Deine Seligkeit besungen.", "tokens": ["Dei\u00b7ne", "Se\u00b7lig\u00b7keit", "be\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Idum\u00e4a komm mit Kr\u00e4ntzen", "tokens": ["I\u00b7du\u00b7m\u00e4a", "komm", "mit", "Kr\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NN"], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Binde tausend Blumen ein/", "tokens": ["Bin\u00b7de", "tau\u00b7send", "Blu\u00b7men", "ein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "ART", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Veyeln von dem fr\u00fchen Lentzen", "tokens": ["Vey\u00b7eln", "von", "dem", "fr\u00fc\u00b7hen", "Lent\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Solln der Demutt Bildnis seyn/", "tokens": ["Solln", "der", "De\u00b7mutt", "Bild\u00b7nis", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "NN", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Rosen/ Liljen/ die sich weisen/", "tokens": ["Ro\u00b7sen", "/", "Lil\u00b7jen", "/", "die", "sich", "wei\u00b7sen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "PRELS", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihre Scham und Keuschheit preisen?", "tokens": ["Ih\u00b7re", "Scham", "und", "Keuschheit", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-++-", "measure": "unknown.measure.tetra"}}, "stanza.8": {"line.1": {"text": "Augen Trost/ der Heyden Wonne", "tokens": ["Au\u00b7gen", "Trost", "/", "der", "Hey\u00b7den", "Won\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$(", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zeigt sich selbst auff ihrer Scho\u00df/", "tokens": ["Zeigt", "sich", "selbst", "auff", "ih\u00b7rer", "Scho\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Himmel-Schl\u00fcssel/ Thau der Sonne/", "tokens": ["Him\u00b7mel\u00b7Sch\u00b7l\u00fcs\u00b7sel", "/", "Thau", "der", "Son\u00b7ne", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "ART", "NN", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Gottes Gnade giebt sich blo\u00df/", "tokens": ["Got\u00b7tes", "Gna\u00b7de", "giebt", "sich", "blo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PRF", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ehren-Prei\u00df und Liebes-Flammen", "tokens": ["Eh\u00b7ren\u00b7Prei\u00df", "und", "Lie\u00b7bes\u00b7Flam\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Schliessen diesen Krantz zusammen.", "tokens": ["Schlies\u00b7sen", "die\u00b7sen", "Krantz", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}