{"textgrid.poem.32614": {"metadata": {"author": {"name": "Pet\u00f6fi, S\u00e1ndor", "birth": "N.A.", "death": "N.A."}, "title": "1L: M\u00e4uler und Ohren auf!", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "M\u00e4uler und Ohren auf!", "tokens": ["M\u00e4u\u00b7ler", "und", "Oh\u00b7ren", "auf", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Pa\u00dft auf, fein still,", "tokens": ["Pa\u00dft", "auf", ",", "fein", "still", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Weil ein gewichtig Wort", "tokens": ["Weil", "ein", "ge\u00b7wich\u00b7tig", "Wort"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich reden will!", "tokens": ["Ich", "re\u00b7den", "will", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Vernehmt, was jetzt mein Mund", "tokens": ["Ver\u00b7nehmt", ",", "was", "jetzt", "mein", "Mund"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PRELS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Verk\u00fcndet euch,", "tokens": ["Ver\u00b7k\u00fcn\u00b7det", "euch", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und auch der Himmel h\u00f6r'", "tokens": ["Und", "auch", "der", "Him\u00b7mel", "h\u00f6r'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Es gnadenreich!", "tokens": ["Es", "gna\u00b7den\u00b7reich", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Lang spinne sich \u2013 lang, wie", "tokens": ["Lang", "spin\u00b7ne", "sich", "\u2013", "lang", ",", "wie"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NN", "VVFIN", "PRF", "$(", "ADJD", "$,", "PWAV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die W\u00fcrste dort \u2013", "tokens": ["Die", "W\u00fcrs\u00b7te", "dort", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "An unsrem Lebensrad", "tokens": ["An", "uns\u00b7rem", "Le\u00b7bens\u00b7rad"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der Faden fort!", "tokens": ["Der", "Fa\u00b7den", "fort", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Wie wir jetzt schmunzeln nach", "tokens": ["Wie", "wir", "jetzt", "schmun\u00b7zeln", "nach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Dem Braten hier,", "tokens": ["Dem", "Bra\u00b7ten", "hier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "So l\u00e4chle das Geschick", "tokens": ["So", "l\u00e4ch\u00b7le", "das", "Ge\u00b7schick"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Uns f\u00fcr und f\u00fcr!", "tokens": ["Uns", "f\u00fcr", "und", "f\u00fcr", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "KON", "APPR", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Es \u00fcbersch\u00fctte uns", "tokens": ["Es", "\u00fc\u00b7ber\u00b7sch\u00fct\u00b7te", "uns"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Mit seiner Gnad',", "tokens": ["Mit", "sei\u00b7ner", "Gnad'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wie's hier den Brei mit Schmalz", "tokens": ["Wie's", "hier", "den", "Brei", "mit", "Schmalz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Beflutet hat!", "tokens": ["Be\u00b7flu\u00b7tet", "hat", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Und h\u00e4lt sein grimmes Mahl", "tokens": ["Und", "h\u00e4lt", "sein", "grim\u00b7mes", "Mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der Tod zuletzt,", "tokens": ["Der", "Tod", "zu\u00b7letzt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Der, zu verspeisen uns,", "tokens": ["Der", ",", "zu", "ver\u00b7spei\u00b7sen", "uns", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PTKZU", "VVINF", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sich niedersetzt:", "tokens": ["Sich", "nie\u00b7der\u00b7setzt", ":"], "token_info": ["word", "word", "punct"], "pos": ["PRF", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Dann m\u00f6g' ein Riesenklo\u00df", "tokens": ["Dann", "m\u00f6g'", "ein", "Rie\u00b7sen\u00b7klo\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der Himmel sein,", "tokens": ["Der", "Him\u00b7mel", "sein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wir aber seien blo\u00df", "tokens": ["Wir", "a\u00b7ber", "sei\u00b7en", "blo\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das F\u00fcllsel drein!", "tokens": ["Das", "F\u00fcll\u00b7sel", "drein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}