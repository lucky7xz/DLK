{"dta.poem.7167": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Betrachtung des Schlafs,  \n als  \n eine G\u00f6ttliche Wohlthat,  \n bey dem 1728sten Jahres-Wechsel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1730", "urn": "urn:nbn:de:kobv:b4-20087-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Denn diese hadern unter mir,", "tokens": ["Denn", "die\u00b7se", "ha\u00b7dern", "un\u00b7ter", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich aber richte unter Dir.", "tokens": ["Ich", "a\u00b7ber", "rich\u00b7te", "un\u00b7ter", "Dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df, wenn der Sachen Eigenschafft;", "tokens": ["La\u00df", ",", "wenn", "der", "Sa\u00b7chen", "Ei\u00b7gen\u00b7schafft", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ihre F\u00e4lle zweifelhafft,", "tokens": ["Und", "ih\u00b7re", "F\u00e4l\u00b7le", "zwei\u00b7fel\u00b7hafft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mich mehr geneigt seyn, lo\u00dfzuz\u00e4hlen,", "tokens": ["Mich", "mehr", "ge\u00b7neigt", "seyn", ",", "lo\u00df\u00b7zu\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAINF", "$,", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als strenge Straffen zu erw\u00e4hlen.", "tokens": ["Als", "stren\u00b7ge", "Straf\u00b7fen", "zu", "er\u00b7w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Es sey mein Ansehn nie durch schelten, schnarchen, pochen,", "tokens": ["Es", "sey", "mein", "An\u00b7sehn", "nie", "durch", "schel\u00b7ten", ",", "schnar\u00b7chen", ",", "po\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und n\u00e4rrschen Amts-Trutz unterbrochen!", "tokens": ["Und", "n\u00e4rr\u00b7schen", "Amts\u00b7Trutz", "un\u00b7ter\u00b7bro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Gieb, da\u00df mit aufgekl\u00e4rt- und heiterem Gesichte,", "tokens": ["Gieb", ",", "da\u00df", "mit", "auf\u00b7ge\u00b7kl\u00e4r\u00b7t", "und", "hei\u00b7te\u00b7rem", "Ge\u00b7sich\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "APPR", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Ich nicht als ein Tyrann, nein, als ein Vater richte!", "tokens": ["Ich", "nicht", "als", "ein", "Ty\u00b7rann", ",", "nein", ",", "als", "ein", "Va\u00b7ter", "rich\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "KOUS", "ART", "NN", "$,", "PTKANT", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und da\u00df ich voller Lieb\u2019 und Sanff tmuth jedem zeige", "tokens": ["Und", "da\u00df", "ich", "vol\u00b7ler", "Lieb'", "und", "Sanff", "tmuth", "je\u00b7dem", "zei\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJA", "NN", "KON", "NN", "VVFIN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df ich ihm Gutes g\u00f6nn\u2019 und doch das Recht nicht beuge!", "tokens": ["Da\u00df", "ich", "ihm", "Gu\u00b7tes", "g\u00f6nn'", "und", "doch", "das", "Recht", "nicht", "beu\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "NN", "ADJD", "KON", "ADV", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Gieb, da\u00df die Sanfftmuth auch so weit sich nicht er-", "tokens": ["Gieb", ",", "da\u00df", "die", "Sanfft\u00b7muth", "auch", "so", "weit", "sich", "nicht", "er"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "KOUS", "ART", "NN", "ADV", "ADV", "ADJD", "PRF", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "strecke,", "tokens": ["stre\u00b7cke", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.15": {"text": "Da\u00df ein Gewaltiger mich schrecke,", "tokens": ["Da\u00df", "ein", "Ge\u00b7wal\u00b7ti\u00b7ger", "mich", "schre\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und mich, auch in dem kleinsten Dinge,", "tokens": ["Und", "mich", ",", "auch", "in", "dem", "kleins\u00b7ten", "Din\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Den Niedrigen zu unterdr\u00fccken zwinge!", "tokens": ["Den", "Nied\u00b7ri\u00b7gen", "zu", "un\u00b7ter\u00b7dr\u00fc\u00b7cken", "zwin\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Gieb, da\u00df ich dergestalt gelassen,", "tokens": ["Gieb", ",", "da\u00df", "ich", "der\u00b7ge\u00b7stalt", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Bem\u00fcht sey, so das Urtheil abzufassen,", "tokens": ["Be\u00b7m\u00fcht", "sey", ",", "so", "das", "Ur\u00b7theil", "ab\u00b7zu\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "ADV", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Da\u00df niemand Ursach haben m\u00f6ge,", "tokens": ["Da\u00df", "nie\u00b7mand", "Ur\u00b7sach", "ha\u00b7ben", "m\u00f6\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "NN", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Wenn Leidenschafften mich verf\u00fchren,", "tokens": ["Wenn", "Lei\u00b7den\u00b7schaff\u00b7ten", "mich", "ver\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Von mir an mich zu appelliren.", "tokens": ["Von", "mir", "an", "mich", "zu", "ap\u00b7pel\u00b7li\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.23": {"text": "La\u00df mich mit Niedertr\u00e4chtigkeit", "tokens": ["La\u00df", "mich", "mit", "Nie\u00b7der\u00b7tr\u00e4ch\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Mein wichtig Amt niemahls beflecken,", "tokens": ["Mein", "wich\u00b7tig", "Amt", "nie\u00b7mahls", "be\u00b7fle\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VVINF", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Doch aber auch zu keiner Zeit", "tokens": ["Doch", "a\u00b7ber", "auch", "zu", "kei\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Mich h\u00f6her, als mein Amt geht, strecken!", "tokens": ["Mich", "h\u00f6\u00b7her", ",", "als", "mein", "Amt", "geht", ",", "stre\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Gieb, da\u00df im Strudel-reichen Meer,", "tokens": ["Gieb", ",", "da\u00df", "im", "Stru\u00b7del\u00b7rei\u00b7chen", "Meer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Der offt nur gar zu sehr gedehneten Gesetze,", "tokens": ["Der", "offt", "nur", "gar", "zu", "sehr", "ge\u00b7deh\u00b7ne\u00b7ten", "Ge\u00b7set\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADV", "PTKA", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Mit Vorbedacht nicht nur, auch nicht von ungefehr,", "tokens": ["Mit", "Vor\u00b7be\u00b7dacht", "nicht", "nur", ",", "auch", "nicht", "von", "un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "ADV", "$,", "ADV", "PTKNEG", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ich andre nicht, auch nicht mich selbst verletze!", "tokens": ["Ich", "and\u00b7re", "nicht", ",", "auch", "nicht", "mich", "selbst", "ver\u00b7let\u00b7ze", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "PTKNEG", "$,", "ADV", "PTKNEG", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Ach la\u00df mich nicht der mancherley Beschwerden,", "tokens": ["Ach", "la\u00df", "mich", "nicht", "der", "man\u00b7cher\u00b7ley", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "PPER", "PTKNEG", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Noch der Gerichts-Zeit, m\u00fcde werden!", "tokens": ["Noch", "der", "Ge\u00b7richts\u00b7Zeit", ",", "m\u00fc\u00b7de", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Gieb, da\u00df absonderlich in diesen zweyen Jahren,", "tokens": ["Gieb", ",", "da\u00df", "ab\u00b7son\u00b7der\u00b7lich", "in", "die\u00b7sen", "zwe\u00b7yen", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "ADJD", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ich sonsten nichts zum Lohn zu haben sey beflissen,", "tokens": ["Ich", "sons\u00b7ten", "nichts", "zum", "Lohn", "zu", "ha\u00b7ben", "sey", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPRART", "NN", "PTKZU", "VAINF", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Von meinem redlichen Verfahren,", "tokens": ["Von", "mei\u00b7nem", "red\u00b7li\u00b7chen", "Ver\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Als blo\u00df allein ein gut Gewissen.", "tokens": ["Als", "blo\u00df", "al\u00b7lein", "ein", "gut", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.37": {"text": "Gieb, da\u00df ich, Dir allein zum Preise,", "tokens": ["Gieb", ",", "da\u00df", "ich", ",", "Dir", "al\u00b7lein", "zum", "Prei\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "KOUS", "PPER", "$,", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Der Du, aus vielen, mich zu diesem Stand erhoben,", "tokens": ["Der", "Du", ",", "aus", "vie\u00b7len", ",", "mich", "zu", "die\u00b7sem", "Stand", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "APPR", "PIAT", "$,", "PRF", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Mich immer dergestalt erweise;", "tokens": ["Mich", "im\u00b7mer", "der\u00b7ge\u00b7stalt", "er\u00b7wei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Da\u00df Dich auch meine Thaten loben!", "tokens": ["Da\u00df", "Dich", "auch", "mei\u00b7ne", "Tha\u00b7ten", "lo\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Sollt\u2019 ich denn etwan nicht des Amtes End\u2019 erleben,", "tokens": ["Sollt'", "ich", "denn", "et\u00b7wan", "nicht", "des", "Am\u00b7tes", "End'", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So wollest du mir, HERR, ein selig\u2019s Ende geben!", "tokens": ["So", "wol\u00b7lest", "du", "mir", ",", "HeRR", ",", "ein", "se\u00b7lig's", "En\u00b7de", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "$,", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wird es mir aber, HERR, durch deine Huld gelingen;", "tokens": ["Wird", "es", "mir", "a\u00b7ber", ",", "HeRR", ",", "durch", "dei\u00b7ne", "Huld", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "$,", "NN", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Werd\u2019 ich die Zeit gesund und gl\u00fccklich \u00fcberbringen;", "tokens": ["Werd'", "ich", "die", "Zeit", "ge\u00b7sund", "und", "gl\u00fcck\u00b7lich", "\u00fc\u00b7berb\u00b7rin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "So gieb, da\u00df ich nicht m\u00f6ge nur allein", "tokens": ["So", "gieb", ",", "da\u00df", "ich", "nicht", "m\u00f6\u00b7ge", "nur", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "$,", "KOUS", "PPER", "PTKNEG", "VMFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Dar\u00fcber hertzlich mich erfreuen,", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "hertz\u00b7lich", "mich", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Und Dir in Ehrfurcht danckbar seyn;", "tokens": ["Und", "Dir", "in", "Ehr\u00b7furcht", "dan\u00b7ck\u00b7bar", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.48": {"text": "Ach la\u00df mein Saiten Spiel sodann, wie vor, erklingen!", "tokens": ["Ach", "la\u00df", "mein", "Sai\u00b7ten", "Spiel", "so\u00b7dann", ",", "wie", "vor", ",", "er\u00b7klin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "VVIMP", "PPOSAT", "NN", "NN", "ADV", "$,", "PWAV", "PTKVZ", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ach la\u00df mich voller Brunst, sodann von neuen,", "tokens": ["Ach", "la\u00df", "mich", "vol\u00b7ler", "Brunst", ",", "so\u00b7dann", "von", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "VVIMP", "PPER", "ADJA", "NN", "$,", "ADV", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "In Deinen herrlichen Gesch\u00f6pffen, Dich besingen!", "tokens": ["In", "Dei\u00b7nen", "herr\u00b7li\u00b7chen", "Ge\u00b7sch\u00f6pf\u00b7fen", ",", "Dich", "be\u00b7sin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}