{"textgrid.poem.34572": {"metadata": {"author": {"name": "Hoffmannswaldau, Christian Hoffmann von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich singe tauben Ohren,", "genre": "verse", "period": "N.A.", "pub_year": 1647, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich singe tauben Ohren,", "tokens": ["Ich", "sin\u00b7ge", "tau\u00b7ben", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein sch\u00f6nes Antlitz kennt mich nicht.", "tokens": ["Dein", "sch\u00f6\u00b7nes", "Ant\u00b7litz", "kennt", "mich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hab' ich der Freundschaft s\u00fc\u00dfes Licht,", "tokens": ["Hab'", "ich", "der", "Freund\u00b7schaft", "s\u00fc\u00b7\u00dfes", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein bestes Kleinod, ganz verloren?", "tokens": ["Mein", "bes\u00b7tes", "Klei\u00b7nod", ",", "ganz", "ver\u00b7lo\u00b7ren", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wird denn mein Tag zu d\u00fcstrer Nacht?", "tokens": ["Wird", "denn", "mein", "Tag", "zu", "d\u00fcst\u00b7rer", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Soll ich lebendig mich begraben", "tokens": ["Soll", "ich", "le\u00b7ben\u00b7dig", "mich", "be\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADJD", "PPER", "VVPP"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Und deiner Augen sch\u00f6ne Pracht,", "tokens": ["Und", "dei\u00b7ner", "Au\u00b7gen", "sch\u00f6\u00b7ne", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wo vormals Sonne war, jetzt zu Kometen haben?", "tokens": ["Wo", "vor\u00b7mals", "Son\u00b7ne", "war", ",", "jetzt", "zu", "Ko\u00b7me\u00b7ten", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "VAFIN", "$,", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was sind es doch f\u00fcr S\u00fcnden,", "tokens": ["Was", "sind", "es", "doch", "f\u00fcr", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Daf\u00fcr ich peinlich b\u00fc\u00dfen mu\u00df", "tokens": ["Da\u00b7f\u00fcr", "ich", "pein\u00b7lich", "b\u00fc\u00b7\u00dfen", "mu\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und aller Schmerzen Ueberflu\u00df,", "tokens": ["Und", "al\u00b7ler", "Schmer\u00b7zen", "Ue\u00b7berf\u00b7lu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Uebelth\u00e4ter, itzt empfinden?", "tokens": ["Als", "Ue\u00b7belt\u00b7h\u00e4\u00b7ter", ",", "itzt", "emp\u00b7fin\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch la\u00df der Uebelth\u00e4ter Recht", "tokens": ["Doch", "la\u00df", "der", "Ue\u00b7belt\u00b7h\u00e4\u00b7ter", "Recht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mich, eh' ich sterbe, nur genie\u00dfen,", "tokens": ["Mich", ",", "eh'", "ich", "ster\u00b7be", ",", "nur", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mache, da\u00df dein armer Knecht,", "tokens": ["Und", "ma\u00b7che", ",", "da\u00df", "dein", "ar\u00b7mer", "Knecht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was er verbrochen hat, mag vor dem Tode wissen.", "tokens": ["Was", "er", "ver\u00b7bro\u00b7chen", "hat", ",", "mag", "vor", "dem", "To\u00b7de", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$,", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wof\u00fcr hab' ich zu b\u00fc\u00dfen?", "tokens": ["Wo\u00b7f\u00fcr", "hab'", "ich", "zu", "b\u00fc\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als G\u00f6ttinn hab' ich dich erkannt,", "tokens": ["Als", "G\u00f6t\u00b7tinn", "hab'", "ich", "dich", "er\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Herz als Weihrauch dir gebrannt", "tokens": ["Mein", "Herz", "als", "Weih\u00b7rauch", "dir", "ge\u00b7brannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOUS", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mich gelegt zu deinen F\u00fc\u00dfen.", "tokens": ["Und", "mich", "ge\u00b7legt", "zu", "dei\u00b7nen", "F\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Straft mich der Himmel oder du?", "tokens": ["Straft", "mich", "der", "Him\u00b7mel", "o\u00b7der", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "KON", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir hab' ich mich in mir verzehret;", "tokens": ["Dir", "hab'", "ich", "mich", "in", "mir", "ver\u00b7zeh\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Der Himmel st\u00fcrmet auf mich zu,", "tokens": ["Der", "Him\u00b7mel", "st\u00fcr\u00b7met", "auf", "mich", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil ich dir allzuviel und ihm fast nichts gew\u00e4hret.", "tokens": ["Weil", "ich", "dir", "all\u00b7zu\u00b7viel", "und", "ihm", "fast", "nichts", "ge\u00b7w\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PIAT", "KON", "PPER", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ach, z\u00fcrne nicht, Melinde,", "tokens": ["Ach", ",", "z\u00fcr\u00b7ne", "nicht", ",", "Me\u00b7lin\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PTKNEG", "$,", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df mir dies freche Wort entf\u00e4hrt!", "tokens": ["Da\u00df", "mir", "dies", "fre\u00b7che", "Wort", "ent\u00b7f\u00e4hrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein S\u00fcnder ist erbarmenswerth.", "tokens": ["Ein", "S\u00fcn\u00b7der", "ist", "er\u00b7bar\u00b7mens\u00b7werth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du f\u00fchlest nicht, was ich empfinde!", "tokens": ["Du", "f\u00fch\u00b7lest", "nicht", ",", "was", "ich", "emp\u00b7fin\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nicht lache, wenn dein Sklave f\u00e4llt;", "tokens": ["Nicht", "la\u00b7che", ",", "wenn", "dein", "Skla\u00b7ve", "f\u00e4llt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du wei\u00dft, Verwirretsein und Lieben", "tokens": ["Du", "wei\u00dft", ",", "Ver\u00b7wir\u00b7ret\u00b7sein", "und", "Lie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "NN", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hat allbereits die erste Welt", "tokens": ["Hat", "all\u00b7be\u00b7reits", "die", "ers\u00b7te", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit Schrift, die nicht verl\u00f6scht, zusammen eingeschrieben.", "tokens": ["Mit", "Schrift", ",", "die", "nicht", "ver\u00b7l\u00f6scht", ",", "zu\u00b7sam\u00b7men", "ein\u00b7ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "VVPP", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Doch willst du G\u00f6ttinn hei\u00dfen,", "tokens": ["Doch", "willst", "du", "G\u00f6t\u00b7tinn", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu der dich deine Tugend macht,", "tokens": ["Zu", "der", "dich", "dei\u00b7ne", "Tu\u00b7gend", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So mu\u00dft du auch bei solcher Pracht", "tokens": ["So", "mu\u00dft", "du", "auch", "bei", "sol\u00b7cher", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich der Erbarmung stets beflei\u00dfen.", "tokens": ["Dich", "der", "Er\u00b7bar\u00b7mung", "stets", "be\u00b7flei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Rei\u00df deinen kalten Vorsatz ein;", "tokens": ["Rei\u00df", "dei\u00b7nen", "kal\u00b7ten", "Vor\u00b7satz", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht mache meine Noth zum Scherze!", "tokens": ["Nicht", "ma\u00b7che", "mei\u00b7ne", "Noth", "zum", "Scher\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die H\u00f6lle lehret grausam sein;", "tokens": ["Die", "H\u00f6l\u00b7le", "leh\u00b7ret", "grau\u00b7sam", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Himmel, dem du gleichst, vertr\u00e4gt kein steinern Herze.", "tokens": ["Der", "Him\u00b7mel", ",", "dem", "du", "gleichst", ",", "ver\u00b7tr\u00e4gt", "kein", "stei\u00b7nern", "Her\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "PIAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}