{"dta.poem.5448": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Sonnen-Finsterni\u00df 1733.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Sonnen strahlend Licht brach durch die reine Luft,", "tokens": ["Der", "Son\u00b7nen", "strah\u00b7lend", "Licht", "brach", "durch", "die", "rei\u00b7ne", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein schwebendes Gew\u00f6lck, kein Nebel, Dunst,", "tokens": ["Kein", "schwe\u00b7ben\u00b7des", "Ge\u00b7w\u00f6lck", ",", "kein", "Ne\u00b7bel", ",", "Dunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verh\u00fcllte die Sapphirne Tieffe;", "tokens": ["Ver\u00b7h\u00fcll\u00b7te", "die", "Sap\u00b7phir\u00b7ne", "Tief\u00b7fe", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Als eine l\u00e4ngst vorher beschriebne Finsterni\u00df", "tokens": ["Als", "ei\u00b7ne", "l\u00e4ngst", "vor\u00b7her", "be\u00b7schrieb\u00b7ne", "Fins\u00b7ter\u00b7ni\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Den sonst gew\u00f6hnlichen Gesch\u00e4ften mich entri\u00df,", "tokens": ["Den", "sonst", "ge\u00b7w\u00f6hn\u00b7li\u00b7chen", "Ge\u00b7sch\u00e4f\u00b7ten", "mich", "ent\u00b7ri\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nebst noch andern mich auf eine H\u00f6he rieffe,", "tokens": ["Und", "nebst", "noch", "an\u00b7dern", "mich", "auf", "ei\u00b7ne", "H\u00f6\u00b7he", "rief\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Bayer, dem davor kein schlechter Danck geb\u00fchrt,", "tokens": ["Die", "Ba\u00b7yer", ",", "dem", "da\u00b7vor", "kein", "schlech\u00b7ter", "Danck", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "PAV", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.8": {"text": "So n\u00fctz-als k\u00fcnstlich aufgef\u00fchrt,", "tokens": ["So", "n\u00fctz\u00b7als", "k\u00fcnst\u00b7lich", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Woselbst bald durch ein Glas, so durch den Dampf vom", "tokens": ["Wo\u00b7selbst", "bald", "durch", "ein", "Glas", ",", "so", "durch", "den", "Dampf", "vom"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "APPRART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Geschw\u00e4rtzet; bald durch eins, so blau war, mein Gesicht", "tokens": ["Ge\u00b7schw\u00e4rt\u00b7zet", ";", "bald", "durch", "eins", ",", "so", "blau", "war", ",", "mein", "Ge\u00b7sicht"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$.", "ADV", "APPR", "PIS", "$,", "ADV", "ADJD", "VAFIN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Gest\u00e4rckt, und ich dadurch im Stande war,", "tokens": ["Ge\u00b7st\u00e4rckt", ",", "und", "ich", "da\u00b7durch", "im", "Stan\u00b7de", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "PPER", "PAV", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die Glut der Sonnen ungeblendet,", "tokens": ["Die", "Glut", "der", "Son\u00b7nen", "un\u00b7ge\u00b7blen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Mit scharfen Blicken, anzusehn.", "tokens": ["Mit", "schar\u00b7fen", "Bli\u00b7cken", ",", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Kaum hatte die Minute sich geendet,", "tokens": ["Kaum", "hat\u00b7te", "die", "Mi\u00b7nu\u00b7te", "sich", "ge\u00b7en\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die ausgerechnet war, als wir,", "tokens": ["Die", "aus\u00b7ge\u00b7rech\u00b7net", "war", ",", "als", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "VVPP", "VAFIN", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Bewundrungs-voll, auf dem Papier,", "tokens": ["Be\u00b7wun\u00b7drungs\u00b7voll", ",", "auf", "dem", "Pa\u00b7pier", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Worauf der Sonnen Bild durch k\u00fcnstliche Christallen", "tokens": ["Wo\u00b7rauf", "der", "Son\u00b7nen", "Bild", "durch", "k\u00fcnst\u00b7li\u00b7che", "Chris\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Jm dunckeln Zimmer man bewundernd sahe fallen,", "tokens": ["Jm", "dun\u00b7ckeln", "Zim\u00b7mer", "man", "be\u00b7wun\u00b7dernd", "sa\u00b7he", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PIS", "ADJD", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Schon von der Finsterni\u00df die erste Spur entstehn,", "tokens": ["Schon", "von", "der", "Fins\u00b7ter\u00b7ni\u00df", "die", "ers\u00b7te", "Spur", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den Rand sich schw\u00e4rtzen sah\u2019n; worauf der Schatten sich", "tokens": ["Den", "Rand", "sich", "schw\u00e4rt\u00b7zen", "sah'n", ";", "wo\u00b7rauf", "der", "Schat\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "VVINF", "VVFIN", "$.", "PWAV", "ART", "NN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Vermehrt\u2019 und mercklich wuchs, bi\u00df da\u00df wir die Figur", "tokens": ["Ver\u00b7mehrt'", "und", "merck\u00b7lich", "wuchs", ",", "bi\u00df", "da\u00df", "wir", "die", "Fi\u00b7gur"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "ADJD", "VVFIN", "$,", "KON", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Des runden Mondes sah\u2019n, der, da er schwartz und dicht,", "tokens": ["Des", "run\u00b7den", "Mon\u00b7des", "sah'n", ",", "der", ",", "da", "er", "schwartz", "und", "dicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Der Sonnen strahlend Licht,", "tokens": ["Der", "Son\u00b7nen", "strah\u00b7lend", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Doch nur auf kurtze Zeit, entzog;", "tokens": ["Doch", "nur", "auf", "kurt\u00b7ze", "Zeit", ",", "ent\u00b7zog", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Das denn auf zweyerley zu dencken mich bewog.", "tokens": ["Das", "denn", "auf", "zwey\u00b7er\u00b7ley", "zu", "den\u00b7cken", "mich", "be\u00b7wog", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PIS", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Zuerst entstand in meiner Seelen", "tokens": ["Zu\u00b7erst", "ent\u00b7stand", "in", "mei\u00b7ner", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein br\u00fcnstigs Andacht-Feur, ein Ehrfurcht volles Dencken:", "tokens": ["Ein", "br\u00fcns\u00b7tigs", "An\u00b7dacht\u00b7Feur", ",", "ein", "Ehr\u00b7furcht", "vol\u00b7les", "Den\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Da so viel tausend Jahr so grosse C\u00f6rper sich,", "tokens": ["Da", "so", "viel", "tau\u00b7send", "Jahr", "so", "gros\u00b7se", "C\u00f6r\u00b7per", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "CARD", "NN", "ADV", "ADJA", "NN", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ohn im geringsten je zu fehlen,", "tokens": ["Ohn", "im", "ge\u00b7rings\u00b7ten", "je", "zu", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In solcher steten Ordnung lencken;", "tokens": ["In", "sol\u00b7cher", "ste\u00b7ten", "Ord\u00b7nung", "len\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie m\u00e4chtig, weise, gro\u00df und unver\u00e4nderlich", "tokens": ["Wie", "m\u00e4ch\u00b7tig", ",", "wei\u00b7se", ",", "gro\u00df", "und", "un\u00b7ver\u00b7\u00e4n\u00b7der\u00b7lich"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mu\u00df der, durch dessen weisen Willen,", "tokens": ["Mu\u00df", "der", ",", "durch", "des\u00b7sen", "wei\u00b7sen", "Wil\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "$,", "APPR", "PRELAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie ihren festen Lauf so ungehemmt erf\u00fcllen,", "tokens": ["Sie", "ih\u00b7ren", "fes\u00b7ten", "Lauf", "so", "un\u00b7ge\u00b7hemmt", "er\u00b7f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der sie aus Nichts allein erschuf, der sie allein", "tokens": ["Der", "sie", "aus", "Nichts", "al\u00b7lein", "er\u00b7schuf", ",", "der", "sie", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PIS", "ADV", "VVFIN", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Blos durch sein Wort erh\u00e4lt, der ew\u2019ge Sch\u00f6pfer, seyn!", "tokens": ["Blos", "durch", "sein", "Wort", "er\u00b7h\u00e4lt", ",", "der", "ew'\u00b7ge", "Sch\u00f6p\u00b7fer", ",", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es fiel zugleich mir dieses ein:", "tokens": ["Es", "fiel", "zu\u00b7gleich", "mir", "die\u00b7ses", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ist etwas auf der Welt, so uns von unserm Geist", "tokens": ["Ist", "et\u00b7was", "auf", "der", "Welt", ",", "so", "uns", "von", "un\u00b7serm", "Geist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "ART", "NN", "$,", "ADV", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Was gr\u00f6ssers, und was GOtt f\u00fcr F\u00e4higkeit ihm schencket,", "tokens": ["Was", "gr\u00f6s\u00b7sers", ",", "und", "was", "Gott", "f\u00fcr", "F\u00e4\u00b7hig\u00b7keit", "ihm", "schen\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "$,", "KON", "PWS", "NN", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Als eine Finsterni\u00df uns weis\u2019t?", "tokens": ["Als", "ei\u00b7ne", "Fins\u00b7ter\u00b7ni\u00df", "uns", "weis't", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Da er, fast auf ein Haar, wie ein Gestirn sich lencket,", "tokens": ["Da", "er", ",", "fast", "auf", "ein", "Haar", ",", "wie", "ein", "Ge\u00b7stirn", "sich", "len\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADV", "APPR", "ART", "NN", "$,", "PWAV", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auf hundert Jahre schon vorher sieht und gedencket.", "tokens": ["Auf", "hun\u00b7dert", "Jah\u00b7re", "schon", "vor\u00b7her", "sieht", "und", "ge\u00b7den\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Hei\u00dft alles dieses nichts, von solchen Finsternissen,", "tokens": ["Hei\u00dft", "al\u00b7les", "die\u00b7ses", "nichts", ",", "von", "sol\u00b7chen", "Fins\u00b7ter\u00b7nis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PDAT", "PIS", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Von der Planeten Lauf, Bewegungen und Drehn", "tokens": ["Von", "der", "Pla\u00b7ne\u00b7ten", "Lauf", ",", "Be\u00b7we\u00b7gun\u00b7gen", "und", "Drehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "$,", "NN", "KON", "CARD"], "meter": "--+--+-++--+", "measure": "anapaest.di.plus"}, "line.17": {"text": "Die stete Richtigkeit so gar genau zu wissen,", "tokens": ["Die", "ste\u00b7te", "Rich\u00b7tig\u00b7keit", "so", "gar", "ge\u00b7nau", "zu", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Auf einen Augenblick vorher zu sehn?", "tokens": ["Auf", "ei\u00b7nen", "Au\u00b7gen\u00b7blick", "vor\u00b7her", "zu", "sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Und zwar", "tokens": ["Und", "zwar"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.20": {"text": "Auf so viel hundert Jahr,", "tokens": ["Auf", "so", "viel", "hun\u00b7dert", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.21": {"text": "Ja noch auf l\u00e4ngere Zeit,", "tokens": ["Ja", "noch", "auf", "l\u00e4n\u00b7ge\u00b7re", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.22": {"text": "Ohn da\u00df wir im geringsten fehlen?", "tokens": ["Ohn", "da\u00df", "wir", "im", "ge\u00b7rings\u00b7ten", "feh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Wo hierinn keine Treflichkeit,", "tokens": ["Wo", "hie\u00b7rinn", "kei\u00b7ne", "Tref\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Kraft, Feur, und Vorzug unsrer Seelen", "tokens": ["Kraft", ",", "Feur", ",", "und", "Vor\u00b7zug", "uns\u00b7rer", "See\u00b7len"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "KON", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Vor allen andern Thieren", "tokens": ["Vor", "al\u00b7len", "an\u00b7dern", "Thie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.26": {"text": "Unwiedersprechlich zu versp\u00fchren;", "tokens": ["Un\u00b7wie\u00b7der\u00b7sprech\u00b7lich", "zu", "ver\u00b7sp\u00fch\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "So wei\u00df ich nicht auf welche Weise man", "tokens": ["So", "wei\u00df", "ich", "nicht", "auf", "wel\u00b7che", "Wei\u00b7se", "man"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "PWAT", "NN", "PIS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Sich einigen Begrif von Wahrheit machen kann?", "tokens": ["Sich", "ei\u00b7ni\u00b7gen", "Be\u00b7grif", "von", "Wahr\u00b7heit", "ma\u00b7chen", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Durch die Betrachtung froh, und recht aufs neu gest\u00e4rckt,", "tokens": ["Durch", "die", "Be\u00b7trach\u00b7tung", "froh", ",", "und", "recht", "aufs", "neu", "ge\u00b7st\u00e4rckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,", "KON", "ADJD", "APPRART", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verjag ich nicht allein", "tokens": ["Ver\u00b7jag", "ich", "nicht", "al\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PTKNEG", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die eitele Furcht, wodurch bey Finsternissen,", "tokens": ["Die", "ei\u00b7te\u00b7le", "Furcht", ",", "wo\u00b7durch", "bey", "Fins\u00b7ter\u00b7nis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "APPR", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Durch Aberglauben tumm, sich viele qv\u00e4len m\u00fcssen,", "tokens": ["Durch", "A\u00b7berg\u00b7lau\u00b7ben", "tumm", ",", "sich", "vie\u00b7le", "qv\u00e4\u00b7len", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "PRF", "PIS", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und blos aus Einfalt bange seyn:", "tokens": ["Und", "blos", "aus", "Ein\u00b7falt", "ban\u00b7ge", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Es steckt zu gleich solch\u2019 eine Dunckelheit", "tokens": ["Es", "steckt", "zu", "gleich", "solch'", "ei\u00b7ne", "Dun\u00b7ckel\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "PIAT", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein helles Licht in meiner Seelen an,", "tokens": ["Ein", "hel\u00b7les", "Licht", "in", "mei\u00b7ner", "See\u00b7len", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df ich nicht nur von meinem eignen Wesen", "tokens": ["Da\u00df", "ich", "nicht", "nur", "von", "mei\u00b7nem", "eig\u00b7nen", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was grosses mehr, als sonst, kann lesen;", "tokens": ["Was", "gros\u00b7ses", "mehr", ",", "als", "sonst", ",", "kann", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJA", "ADV", "$,", "KOUS", "ADV", "$,", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie zeiget mir zugleich noch eine grosse Lehre,", "tokens": ["Sie", "zei\u00b7get", "mir", "zu\u00b7gleich", "noch", "ei\u00b7ne", "gros\u00b7se", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu aller Ding\u2019 und meines Sch\u00f6pfers Ehre,", "tokens": ["Zu", "al\u00b7ler", "Ding'", "und", "mei\u00b7nes", "Sch\u00f6p\u00b7fers", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und mach\u2019 ich mir hieraus die ewig-wahren Schl\u00fcsse,", "tokens": ["Und", "mach'", "ich", "mir", "hier\u00b7aus", "die", "e\u00b7wig\u00b7wah\u00b7ren", "Schl\u00fcs\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df GOtt der Sonnen, Mond und Welt regirt und", "tokens": ["Da\u00df", "Gott", "der", "Son\u00b7nen", ",", "Mond", "und", "Welt", "re\u00b7girt", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ART", "NN", "$,", "NN", "KON", "NN", "VVPP", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und der zugleich auch uns solch einen Geist geschenckt,", "tokens": ["Und", "der", "zu\u00b7gleich", "auch", "uns", "solch", "ei\u00b7nen", "Geist", "ge\u00b7schenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "PPER", "PIAT", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Worin nur er allein der Weisheit Schatz gesenckt,", "tokens": ["Wo\u00b7rin", "nur", "er", "al\u00b7lein", "der", "Weis\u00b7heit", "Schatz", "ge\u00b7senckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ADV", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Allein gelobt, geliebt, verehret werden m\u00fcsse.", "tokens": ["Al\u00b7lein", "ge\u00b7lobt", ",", "ge\u00b7liebt", ",", "ver\u00b7eh\u00b7ret", "wer\u00b7den", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "VVPP", "$,", "VVFIN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}