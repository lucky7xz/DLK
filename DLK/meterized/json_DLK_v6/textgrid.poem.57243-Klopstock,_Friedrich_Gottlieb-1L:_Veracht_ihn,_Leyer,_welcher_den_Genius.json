{"textgrid.poem.57243": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Veracht ihn, Leyer, welcher den Genius", "genre": "verse", "period": "N.A.", "pub_year": 1752, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Veracht ihn, Leyer, welcher den Genius", "tokens": ["Ver\u00b7acht", "ihn", ",", "Le\u00b7yer", ",", "wel\u00b7cher", "den", "Ge\u00b7nius"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "NE", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In sich verkennet! und zu des Albion,", "tokens": ["In", "sich", "ver\u00b7ken\u00b7net", "!", "und", "zu", "des", "Al\u00b7bi\u00b7on", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVFIN", "$.", "KON", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Zu jedem edlern Stolz unf\u00e4hig,", "tokens": ["Zu", "je\u00b7dem", "ed\u00b7lern", "Stolz", "un\u00b7f\u00e4\u00b7hig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fern, es zu werden, noch immer nachahmt!", "tokens": ["Fern", ",", "es", "zu", "wer\u00b7den", ",", "noch", "im\u00b7mer", "nac\u00b7hahmt", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "PTKZU", "VAINF", "$,", "ADV", "ADV", "ADJD", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.2": {"line.1": {"text": "Soll Hermanns Sohn, und, Leibniz, dein Zeitgenoss,", "tokens": ["Soll", "Her\u00b7manns", "Sohn", ",", "und", ",", "Leib\u00b7niz", ",", "dein", "Zeit\u00b7ge\u00b7noss", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "NE", "NN", "$,", "KON", "$,", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "(des Denkers Leben lebet noch unter uns!)", "tokens": ["(", "des", "Den\u00b7kers", "Le\u00b7ben", "le\u00b7bet", "noch", "un\u00b7ter", "uns", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ART", "NN", "VVFIN", "ADV", "APPR", "PPER", "$.", "$("], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Soll der in Ketten denen nachgehn,", "tokens": ["Soll", "der", "in", "Ket\u00b7ten", "de\u00b7nen", "nach\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "APPR", "NN", "PDS", "VVINF", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Welchen er, k\u00fchner, vor\u00fcber fl\u00f6ge?", "tokens": ["Wel\u00b7chen", "er", ",", "k\u00fch\u00b7ner", ",", "vor\u00b7\u00fc\u00b7ber", "fl\u00f6\u00b7ge", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "$,", "ADJA", "$,", "ADV", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Und doch die Wange niemals mit gl\u00fchender", "tokens": ["Und", "doch", "die", "Wan\u00b7ge", "nie\u00b7mals", "mit", "gl\u00fc\u00b7hen\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "APPR", "ADJA"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Schamvoller R\u00f6the f\u00e4rben? nie feuriger,", "tokens": ["Scham\u00b7vol\u00b7ler", "R\u00f6\u00b7the", "f\u00e4r\u00b7ben", "?", "nie", "feu\u00b7ri\u00b7ger", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$.", "ADV", "ADJD", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Sieht er des Griechen Flug, ausrufen:", "tokens": ["Sieht", "er", "des", "Grie\u00b7chen", "Flug", ",", "aus\u00b7ru\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wurde zum Dichter nur er geboren?", "tokens": ["Wur\u00b7de", "zum", "Dich\u00b7ter", "nur", "er", "ge\u00b7bo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ADV", "PPER", "VVPP", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Nicht z\u00fcrnend weinen, weinen vor Ehrbegier,", "tokens": ["Nicht", "z\u00fcr\u00b7nend", "wei\u00b7nen", ",", "wei\u00b7nen", "vor", "Ehr\u00b7be\u00b7gier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVINF", "$,", "VVINF", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wenn ers nicht ausrief? gehen, um Mitternacht", "tokens": ["Wenn", "ers", "nicht", "aus\u00b7rief", "?", "ge\u00b7hen", ",", "um", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "PIS", "PTKNEG", "VVFIN", "$.", "VVINF", "$,", "KOUI", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Auffahren? nicht, an seiner Kleinmuth,", "tokens": ["Auf\u00b7fah\u00b7ren", "?", "nicht", ",", "an", "sei\u00b7ner", "Klein\u00b7muth", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PTKNEG", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich, durch unsterbliche Werke, r\u00e4chen?", "tokens": ["Sich", ",", "durch", "uns\u00b7terb\u00b7li\u00b7che", "Wer\u00b7ke", ",", "r\u00e4\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "$,", "APPR", "ADJA", "NN", "$,", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Zwar, werther Hermanns, hat die best\u00e4ubte Schlacht", "tokens": ["Zwar", ",", "wert\u00b7her", "Her\u00b7manns", ",", "hat", "die", "be\u00b7st\u00e4ub\u00b7te", "Schlacht"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Uns oft gekr\u00f6net! hat sich des J\u00fcnglings Blick", "tokens": ["Uns", "oft", "ge\u00b7kr\u00f6\u00b7net", "!", "hat", "sich", "des", "J\u00fcng\u00b7lings", "Blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVPP", "$.", "VAFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Entflamt! hat laut sein Herz geschlagen,", "tokens": ["Ent\u00b7flamt", "!", "hat", "laut", "sein", "Herz", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Brennend nach k\u00fchnerer That gedurstet!", "tokens": ["Bren\u00b7nend", "nach", "k\u00fch\u00b7ne\u00b7rer", "That", "ge\u00b7durs\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "Dess Zeug' ist H\u00f6chsted, dort, wo die dunkle Schlacht", "tokens": ["Dess", "Zeug'", "ist", "H\u00f6chs\u00b7ted", ",", "dort", ",", "wo", "die", "dunk\u00b7le", "Schlacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NE", "$,", "ADV", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch donnert, wo, mit edlen Britanniern,", "tokens": ["Noch", "don\u00b7nert", ",", "wo", ",", "mit", "ed\u00b7len", "Bri\u00b7tan\u00b7ni\u00b7ern", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gleich w\u00fcrdig ihrer grossen V\u00e4ter,", "tokens": ["Gleich", "w\u00fcr\u00b7dig", "ih\u00b7rer", "gros\u00b7sen", "V\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Deutsche dem Gallier Flucht geboten!", "tokens": ["Deut\u00b7sche", "dem", "Gal\u00b7lier", "Flucht", "ge\u00b7bo\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Das Werk des Meisters, welches von hohem Geist", "tokens": ["Das", "Werk", "des", "Meis\u00b7ters", ",", "wel\u00b7ches", "von", "ho\u00b7hem", "Geist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Gefl\u00fcgelt hinschwebt, ist, wie des Helden That,", "tokens": ["Ge\u00b7fl\u00fc\u00b7gelt", "hin\u00b7schwebt", ",", "ist", ",", "wie", "des", "Hel\u00b7den", "That", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "VAFIN", "$,", "PWAV", "ART", "NN", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Unsterblich! wird, gleich ihr, den Lorber", "tokens": ["U\u00b7nsterb\u00b7lich", "!", "wird", ",", "gleich", "ihr", ",", "den", "Lor\u00b7ber"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "$.", "VAFIN", "$,", "ADV", "PPER", "$,", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "M\u00e4nnlich verdienen, und niedersehen!", "tokens": ["M\u00e4nn\u00b7lich", "ver\u00b7die\u00b7nen", ",", "und", "nie\u00b7der\u00b7se\u00b7hen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "KON", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}