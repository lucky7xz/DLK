{"dta.poem.3592": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Kurzweil .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519172", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich hab mir ein Maidlein auserw\u00e4hlt,               ", "tokens": ["Ich", "hab", "mir", "ein", "Maid\u00b7lein", "au\u00b7ser\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dasselbig mir im Herzen wohlgef\u00e4llt;", "tokens": ["Das\u00b7sel\u00b7big", "mir", "im", "Her\u00b7zen", "wohl\u00b7ge\u00b7f\u00e4llt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Von Ehren ist sie hoch zu loben,", "tokens": ["Von", "Eh\u00b7ren", "ist", "sie", "hoch", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mein junges Herz", "tokens": ["Mein", "jun\u00b7ges", "Herz"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "In Schimpf und Scherz", "tokens": ["In", "Schimpf", "und", "Scherz"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mu\u00df gar bei ihr vertoben.", "tokens": ["Mu\u00df", "gar", "bei", "ihr", "ver\u00b7to\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Dasselbig Maidlein, das ist mein,", "tokens": ["Das\u00b7sel\u00b7big", "Maid\u00b7lein", ",", "das", "ist", "mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soll mir also gesinnet seyn;", "tokens": ["Soll", "mir", "al\u00b7so", "ge\u00b7sin\u00b7net", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Mein Herz ist traurig volle", "tokens": ["Mein", "Herz", "ist", "trau\u00b7rig", "vol\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wieder hinum,", "tokens": ["Wie\u00b7der", "hi\u00b7num", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Das Maidlein frum,", "tokens": ["Das", "Maid\u00b7lein", "frum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mich herzlich tr\u00f6sten solle.", "tokens": ["Mich", "herz\u00b7lich", "tr\u00f6s\u00b7ten", "sol\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Am Abend, wenn ich soll schlafen gehn,", "tokens": ["Am", "A\u00b7bend", ",", "wenn", "ich", "soll", "schla\u00b7fen", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "VMFIN", "VVINF", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nachdem so wird sie's wohl verstehn,", "tokens": ["Nach\u00b7dem", "so", "wird", "sie's", "wohl", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VAFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nehm ich sie freundlich an meinen Arm,", "tokens": ["Nehm", "ich", "sie", "freund\u00b7lich", "an", "mei\u00b7nen", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "An meinen Leib", "tokens": ["An", "mei\u00b7nen", "Leib"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Sie als mein Weib,", "tokens": ["Sie", "als", "mein", "Weib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ich als ihr lieber Mann.", "tokens": ["Ich", "als", "ihr", "lie\u00b7ber", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und wenn denn solches als geschicht,", "tokens": ["Und", "wenn", "denn", "sol\u00b7ches", "als", "ge\u00b7schicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIAT", "KOKOM", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So zweifelt mir mit nichten nicht,", "tokens": ["So", "zwei\u00b7felt", "mir", "mit", "nich\u00b7ten", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PIS", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gott wird sein Segen dazu geben;", "tokens": ["Gott", "wird", "sein", "Se\u00b7gen", "da\u00b7zu", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Drauf da\u00df uns komm", "tokens": ["Drauf", "da\u00df", "uns", "komm"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "KOUS", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Ein Kindlein fromm,", "tokens": ["Ein", "Kin\u00b7dlein", "fromm", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "In solchem ehlichen Leben.", "tokens": ["In", "sol\u00b7chem", "eh\u00b7li\u00b7chen", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Wird solches Kind ein Maidelein,", "tokens": ["Wird", "sol\u00b7ches", "Kind", "ein", "Mai\u00b7de\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So soll El\u00df sein Nahme seyn;", "tokens": ["So", "soll", "El\u00df", "sein", "Nah\u00b7me", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "PPOSAT", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleich wie man mein liebes Weib thut nennen,", "tokens": ["Gleich", "wie", "man", "mein", "lie\u00b7bes", "Weib", "thut", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIS", "PPOSAT", "ADJA", "NN", "VVFIN", "VVINF", "$,"], "meter": "----+-+-+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Da\u00df durch die Tauf", "tokens": ["Da\u00df", "durch", "die", "Tauf"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Sein S\u00fcnd ersauf,", "tokens": ["Sein", "S\u00fcnd", "er\u00b7sauf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Drauf da\u00df es Gott erkenne.", "tokens": ["Drauf", "da\u00df", "es", "Gott", "er\u00b7ken\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Beschehrt mir Gott ein werthen Sohn,", "tokens": ["Be\u00b7schehrt", "mir", "Gott", "ein", "wert\u00b7hen", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bin ich mehr erfreuet von;", "tokens": ["Bin", "ich", "mehr", "er\u00b7freu\u00b7et", "von", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVFIN", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Also in solcher Gestalte,", "tokens": ["Al\u00b7so", "in", "sol\u00b7cher", "Ge\u00b7stal\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Sein Nahm christlich,", "tokens": ["Sein", "Nahm", "christ\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Heissen wie ich,", "tokens": ["Heis\u00b7sen", "wie", "ich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "PPER", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Mit Nahmen Jorg Gr\u00fcnenwalde.", "tokens": ["Mit", "Nah\u00b7men", "Jorg", "Gr\u00fc\u00b7nen\u00b7wal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}