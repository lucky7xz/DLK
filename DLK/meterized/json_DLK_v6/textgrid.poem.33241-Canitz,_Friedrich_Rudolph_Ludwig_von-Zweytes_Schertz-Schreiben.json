{"textgrid.poem.33241": {"metadata": {"author": {"name": "Canitz, Friedrich Rudolph Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "Zweytes Schertz-Schreiben", "genre": "verse", "period": "N.A.", "pub_year": 1676, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ohn Zweiffel, lieber Bruder mein,", "tokens": ["Ohn", "Zweif\u00b7fel", ",", "lie\u00b7ber", "Bru\u00b7der", "mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wirst du von mir ein Schreiben fein", "tokens": ["Wirst", "du", "von", "mir", "ein", "Schrei\u00b7ben", "fein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu H\u00e4nden han empfangen,", "tokens": ["Zu", "H\u00e4n\u00b7den", "han", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und daraus wohl ersehen satt,", "tokens": ["Und", "da\u00b7raus", "wohl", "er\u00b7se\u00b7hen", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADV", "VVINF", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie es allhier in dieser Stadt", "tokens": ["Wie", "es", "all\u00b7hier", "in", "die\u00b7ser", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und auch bey Hof ergangen.", "tokens": ["Und", "auch", "bey", "Hof", "er\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Nunmehr ich auch berichten thu,", "tokens": ["Nun\u00b7mehr", "ich", "auch", "be\u00b7rich\u00b7ten", "thu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was sich seit dem getragen zu", "tokens": ["Was", "sich", "seit", "dem", "ge\u00b7tra\u00b7gen", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "ART", "VVPP", "PTKZU"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Gar sch\u00f6n nach alter Weise.", "tokens": ["Gar", "sch\u00f6n", "nach", "al\u00b7ter", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der junge Printz I*** gut,", "tokens": ["Der", "jun\u00b7ge", "Printz", "I", "*", "*", "*", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "XY", "XY", "XY", "XY", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sich hier nicht mehr aufhalten thut,", "tokens": ["Sich", "hier", "nicht", "mehr", "auf\u00b7hal\u00b7ten", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PTKNEG", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er nahm von hier die Reise.", "tokens": ["Er", "nahm", "von", "hier", "die", "Rei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Gleichwie, er nun incognito", "tokens": ["Gleich\u00b7wie", ",", "er", "nun", "in\u00b7co\u00b7gni\u00b7to"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gelebet, hat er auch also", "tokens": ["Ge\u00b7le\u00b7bet", ",", "hat", "er", "auch", "al\u00b7so"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich weggemacht zur Stunde.", "tokens": ["Sich", "weg\u00b7ge\u00b7macht", "zur", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Warum? Es kam ein andrer F\u00fcrst", "tokens": ["Wa\u00b7rum", "?", "Es", "kam", "ein", "an\u00b7drer", "F\u00fcrst"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und nahm ihm, wie du h\u00f6ren wirst,", "tokens": ["Und", "nahm", "ihm", ",", "wie", "du", "h\u00f6\u00b7ren", "wirst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Braten aus dem Munde.", "tokens": ["Den", "Bra\u00b7ten", "aus", "dem", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der Br\u00e4utigam, die gute Haut,", "tokens": ["Der", "Br\u00e4u\u00b7ti\u00b7gam", ",", "die", "gu\u00b7te", "Haut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verlohr dar\u00fcber seine Braut,", "tokens": ["Ver\u00b7lohr", "da\u00b7r\u00fc\u00b7ber", "sei\u00b7ne", "Braut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denckt Christen, welcher Jammer!", "tokens": ["Denckt", "Chris\u00b7ten", ",", "wel\u00b7cher", "Jam\u00b7mer", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "PWAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Printz von Neuburg Tugendsam,", "tokens": ["Der", "Printz", "von", "Neu\u00b7burg", "Tu\u00b7gend\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des K\u00e4ysers Schwager kam und nahm", "tokens": ["Des", "K\u00e4y\u00b7sers", "Schwa\u00b7ger", "kam", "und", "nahm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Besitz in Bett und Kammer.", "tokens": ["Be\u00b7sitz", "in", "Bett", "und", "Kam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er kam hieher ohn allen Spott,", "tokens": ["Er", "kam", "hie\u00b7her", "ohn", "al\u00b7len", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hatte seiner Diener Rott", "tokens": ["Und", "hat\u00b7te", "sei\u00b7ner", "Die\u00b7ner", "Rott"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey sich ohn alle Scheue.", "tokens": ["Bey", "sich", "ohn", "al\u00b7le", "Scheu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "APPR", "PIAT", "NN", "$."], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Der Churf\u00fcrst ihn ins Schlo\u00df nahm ein,", "tokens": ["Der", "Chur\u00b7f\u00fcrst", "ihn", "ins", "Schlo\u00df", "nahm", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPRART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat ihn auch selbst zur Tafel sein", "tokens": ["Hat", "ihn", "auch", "selbst", "zur", "Ta\u00b7fel", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geladen ein mit Treue.", "tokens": ["Ge\u00b7la\u00b7den", "ein", "mit", "Treu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "So bald er sich hier einlogirt,", "tokens": ["So", "bald", "er", "sich", "hier", "ein\u00b7lo\u00b7girt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward gleich sein tapffres Hertz ger\u00fchrt", "tokens": ["Ward", "gleich", "sein", "tapf\u00b7fres", "Hertz", "ge\u00b7r\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit des Cupido Pfeilen.", "tokens": ["Mit", "des", "Cu\u00b7pi\u00b7do", "Pfei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Er dachte, wie er sich bey ihr", "tokens": ["Er", "dach\u00b7te", ",", "wie", "er", "sich", "bey", "ihr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "PRF", "APPR", "PPOSAT"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Der Wittwen, m\u00f6chte mit Manir", "tokens": ["Der", "Witt\u00b7wen", ",", "m\u00f6ch\u00b7te", "mit", "Ma\u00b7nir"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VMFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Einspielen ohn verweilen.", "tokens": ["Ein\u00b7spie\u00b7len", "ohn", "ver\u00b7wei\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die junge reiche Wittwe frisch", "tokens": ["Die", "jun\u00b7ge", "rei\u00b7che", "Witt\u00b7we", "frisch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df stets bey ihm an einem Tisch", "tokens": ["Sa\u00df", "stets", "bey", "ihm", "an", "ei\u00b7nem", "Tisch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "APPR", "ART", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Wohl recht zu seiner Seiten,", "tokens": ["Wohl", "recht", "zu", "sei\u00b7ner", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und lie\u00df sich drauf, in kurtzer Frist,", "tokens": ["Und", "lie\u00df", "sich", "drauf", ",", "in", "kurt\u00b7zer", "Frist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vernimm von mir ohn arge List,", "tokens": ["Ver\u00b7nimm", "von", "mir", "ohn", "ar\u00b7ge", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu seiner Liebe leiten.", "tokens": ["Zu", "sei\u00b7ner", "Lie\u00b7be", "lei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Vergessen war der Br\u00e4utigam,", "tokens": ["Ver\u00b7ges\u00b7sen", "war", "der", "Br\u00e4u\u00b7ti\u00b7gam", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der in Gedancken sie schon nahm", "tokens": ["Der", "in", "Ge\u00b7dan\u00b7cken", "sie", "schon", "nahm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vor diesem jungen Helden.", "tokens": ["Vor", "die\u00b7sem", "jun\u00b7gen", "Hel\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie lie\u00df sich eilends mit ihm traun,", "tokens": ["Sie", "lie\u00df", "sich", "ei\u00b7lends", "mit", "ihm", "traun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "B*** durffte nicht zuschaun,", "tokens": ["B", "*", "*", "*", "durff\u00b7te", "nicht", "zu\u00b7schaun", ","], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["XY", "XY", "XY", "XY", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Glaub mir, was ich thu melden.", "tokens": ["Glaub", "mir", ",", "was", "ich", "thu", "mel\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWS", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Den Herrn Gravel di\u00df Ding verdro\u00df,", "tokens": ["Den", "Herrn", "Gra\u00b7vel", "di\u00df", "Ding", "ver\u00b7dro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "PDS", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Vor Unmuth fuhr er bald aufs Schlo\u00df,", "tokens": ["Vor", "Un\u00b7muth", "fuhr", "er", "bald", "aufs", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bald wieder auf die Strassen.", "tokens": ["Bald", "wie\u00b7der", "auf", "die", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch dieses halff nichts mehr dazu,", "tokens": ["Doch", "die\u00b7ses", "halff", "nichts", "mehr", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PIS", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Teuffel selber mu\u00df sie nu", "tokens": ["Der", "Teuf\u00b7fel", "sel\u00b7ber", "mu\u00df", "sie", "nu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wohl bey einander lassen.", "tokens": ["Wohl", "bey", "ein\u00b7an\u00b7der", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Das ist so in der Still geschehn,", "tokens": ["Das", "ist", "so", "in", "der", "Still", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sich es niemand hat versehn,", "tokens": ["Da", "sich", "es", "nie\u00b7mand", "hat", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPER", "PIS", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So geht es auf der Erden:", "tokens": ["So", "geht", "es", "auf", "der", "Er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der eine sticht den andern aus,", "tokens": ["Der", "ei\u00b7ne", "sticht", "den", "an\u00b7dern", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie in der Karte kan das Tau\u00df", "tokens": ["Wie", "in", "der", "Kar\u00b7te", "kan", "das", "Tau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vom Trumpff gestochen werden.", "tokens": ["Vom", "Trumpff", "ge\u00b7sto\u00b7chen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Hiermit, mein Bruder, gute Nacht!", "tokens": ["Hier\u00b7mit", ",", "mein", "Bru\u00b7der", ",", "gu\u00b7te", "Nacht", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tausend sechshundert achzig acht,", "tokens": ["Tau\u00b7send", "sechs\u00b7hun\u00b7dert", "ach\u00b7zig", "acht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "CARD", "CARD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Zu Berlin nicht zu Halle,", "tokens": ["Zu", "Ber\u00b7lin", "nicht", "zu", "Hal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKNEG", "APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hab ichs den ersten Tag datirt,", "tokens": ["Hab", "ichs", "den", "ers\u00b7ten", "Tag", "da\u00b7tirt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der von August den Nahmen f\u00fchrt,", "tokens": ["Der", "von", "Au\u00b7gust", "den", "Nah\u00b7men", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Nun ist mein Neues alle.", "tokens": ["Nun", "ist", "mein", "Neu\u00b7es", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Das Brieflein liegen blieben ist,", "tokens": ["Das", "Brie\u00b7flein", "lie\u00b7gen", "blie\u00b7ben", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df ich dir noch di\u00df schreiben,", "tokens": ["Mu\u00df", "ich", "dir", "noch", "di\u00df", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "PDS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df heut, den anderen August,", "tokens": ["Da\u00df", "heut", ",", "den", "an\u00b7de\u00b7ren", "Au\u00b7gust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Thore dieser Stadt mit Lust", "tokens": ["Die", "Tho\u00b7re", "die\u00b7ser", "Stadt", "mit", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Geschlossen m\u00fcssen bleiben.", "tokens": ["Ge\u00b7schlos\u00b7sen", "m\u00fcs\u00b7sen", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Man war bem\u00fcht denselben gar,", "tokens": ["Man", "war", "be\u00b7m\u00fcht", "den\u00b7sel\u00b7ben", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "VVPP", "PDS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der heimlich hat getraut di\u00df Paar,", "tokens": ["Der", "heim\u00b7lich", "hat", "ge\u00b7traut", "di\u00df", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "VVPP", "PDS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu greiffen und zu fangen;", "tokens": ["Zu", "greif\u00b7fen", "und", "zu", "fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein, der Fuchs hat sich bey Zeit", "tokens": ["Al\u00b7lein", ",", "der", "Fuchs", "hat", "sich", "bey", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ART", "NE", "VAFIN", "PRF", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als wie ein Hofmann ausgekleidt,", "tokens": ["Als", "wie", "ein", "Hof\u00b7mann", "aus\u00b7ge\u00b7kleidt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ist davon gegangen.", "tokens": ["Und", "ist", "da\u00b7von", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}