{"textgrid.poem.53587": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Persisch", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Omar Chab, der Hoffl\u00f6tiste,", "tokens": ["O\u00b7mar", "Chab", ",", "der", "Hof\u00b7fl\u00f6\u00b7tis\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf dem Markt zu Teheran,", "tokens": ["auf", "dem", "Markt", "zu", "Te\u00b7he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "steht auf einer Eierkiste,", "tokens": ["steht", "auf", "ei\u00b7ner", "Ei\u00b7er\u00b7kis\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "stimmt die neue Sure an:", "tokens": ["stimmt", "die", "neu\u00b7e", "Su\u00b7re", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oh kaleika, leika, leika \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka", ",", "lei\u00b7ka", ",", "lei\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["XY", "XY", "$,", "NE", "$,", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oh kaleikal\u00e9 \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka\u00b7l\u00e9", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["XY", "XY", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Oh kaleika, leika, leika \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka", ",", "lei\u00b7ka", ",", "lei\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["XY", "XY", "$,", "NE", "$,", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "piddlju\u00e9-\u00e9eeeeh! \u2013", "tokens": ["piddl\u00b7ju\u00e9\u00b7\u00e9ee\u00b7e\u00b7eh", "!", "\u2013"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Und das Volk tanzt ganz begeistert", "tokens": ["Und", "das", "Volk", "tanzt", "ganz", "be\u00b7geis\u00b7tert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "(wie es Brauch) auf einem Bein;", "tokens": ["(", "wie", "es", "Brauch", ")", "auf", "ei\u00b7nem", "Bein", ";"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "NN", "$(", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Forscher, die gef\u00fchlsbekleistert,", "tokens": ["For\u00b7scher", ",", "die", "ge\u00b7f\u00fchls\u00b7be\u00b7kleis\u00b7tert", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schreiben es in B\u00fccher ein:", "tokens": ["schrei\u00b7ben", "es", "in", "B\u00fc\u00b7cher", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oh kaleika, leika, leika \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka", ",", "lei\u00b7ka", ",", "lei\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["XY", "XY", "$,", "NE", "$,", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oh kaleikal\u00e9 \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka\u00b7l\u00e9", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["XY", "XY", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Oh kaleika, leika, leika \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka", ",", "lei\u00b7ka", ",", "lei\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["XY", "XY", "$,", "NE", "$,", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "piddlju\u00e9-\u00e9eeeeh!", "tokens": ["piddl\u00b7ju\u00e9\u00b7\u00e9ee\u00b7e\u00b7eh", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Theobald, der dies gelesen,", "tokens": ["Theo\u00b7bald", ",", "der", "dies", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "kriecht bei Clairen tief herein \u2013", "tokens": ["kriecht", "bei", "Clai\u00b7ren", "tief", "her\u00b7ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "ADJD", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo er einst entz\u00fcckt gewesen,", "tokens": ["wo", "er", "einst", "ent\u00b7z\u00fcckt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVPP", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bl\u00e4st er nunmehr tief und fein:", "tokens": ["bl\u00e4st", "er", "nun\u00b7mehr", "tief", "und", "fein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oh kaleika, leika, leika \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka", ",", "lei\u00b7ka", ",", "lei\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["XY", "XY", "$,", "NE", "$,", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Oh kaleikal\u00e9 \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka\u00b7l\u00e9", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["XY", "XY", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Oh kaleika, leika, leika \u2013", "tokens": ["Oh", "ka\u00b7lei\u00b7ka", ",", "lei\u00b7ka", ",", "lei\u00b7ka", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["XY", "XY", "$,", "NE", "$,", "FM.la", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "piddlju\u00e9 \u2013 \u00e9eeeeehh! \u2013", "tokens": ["piddl\u00b7ju\u00e9", "\u2013", "\u00e9ee\u00b7e\u00b7e\u00b7ehh", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct"], "pos": ["NE", "$(", "ADJD", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Tje . . .", "tokens": ["Tje", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["NE", "$.", "$.", "$."], "meter": "+", "measure": "single.up"}}}}}