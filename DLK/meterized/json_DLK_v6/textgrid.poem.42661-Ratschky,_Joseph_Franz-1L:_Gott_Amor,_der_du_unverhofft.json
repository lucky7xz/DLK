{"textgrid.poem.42661": {"metadata": {"author": {"name": "Ratschky, Joseph Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gott Amor, der du unverhofft", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gott Amor, der du unverhofft", "tokens": ["Gott", "A\u00b7mor", ",", "der", "du", "un\u00b7ver\u00b7hofft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PRELS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Schw\u00e4rmer Treue lehrest,", "tokens": ["Den", "Schw\u00e4r\u00b7mer", "Treu\u00b7e", "leh\u00b7rest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und einen weisen Graubart oft", "tokens": ["Und", "ei\u00b7nen", "wei\u00b7sen", "Grau\u00b7bart", "oft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In einen Faun verkehrest!", "tokens": ["In", "ei\u00b7nen", "Faun", "ver\u00b7keh\u00b7rest", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Dich ehret man, o Cypripor!", "tokens": ["Dich", "eh\u00b7ret", "man", ",", "o", "Cyp\u00b7ri\u00b7por", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In H\u00fctten und in Hallen,", "tokens": ["In", "H\u00fct\u00b7ten", "und", "in", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sieh! der Weise wie der Thor", "tokens": ["Und", "sieh", "!", "der", "Wei\u00b7se", "wie", "der", "Thor"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind deiner Macht Vasallen.", "tokens": ["Sind", "dei\u00b7ner", "Macht", "Va\u00b7sal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Es k\u00fcssen deinen Zepterstab", "tokens": ["Es", "k\u00fcs\u00b7sen", "dei\u00b7nen", "Zep\u00b7ter\u00b7stab"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wildsten V\u00f6lker Rotten", "tokens": ["Der", "wilds\u00b7ten", "V\u00f6l\u00b7ker", "Rot\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vom kalten Lappen bis hinab", "tokens": ["Vom", "kal\u00b7ten", "Lap\u00b7pen", "bis", "hin\u00b7ab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum braunen Hottentotten.", "tokens": ["Zum", "brau\u00b7nen", "Hot\u00b7ten\u00b7tot\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Dir huldigen in Hindostan", "tokens": ["Dir", "hul\u00b7di\u00b7gen", "in", "Hin\u00b7dos\u00b7tan"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die finsteren Braminen,", "tokens": ["Die", "fins\u00b7te\u00b7ren", "Bra\u00b7mi\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dir muss der ernste Grosssultan,", "tokens": ["Dir", "muss", "der", "erns\u00b7te", "Gross\u00b7sul\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wie sein Sklave, dienen.", "tokens": ["So", "wie", "sein", "Skla\u00b7ve", ",", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "KOKOM", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Man kennet deine Macht nicht nur", "tokens": ["Man", "ken\u00b7net", "dei\u00b7ne", "Macht", "nicht", "nur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey ungeweihten Layen:", "tokens": ["Bey", "un\u00b7ge\u00b7weih\u00b7ten", "La\u00b7yen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Man ehrt dich auch, trotz Eid und Schwur,", "tokens": ["Man", "ehrt", "dich", "auch", ",", "trotz", "Eid", "und", "Schwur", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "$,", "APPR", "NN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Kl\u00f6stern und Abteyen.", "tokens": ["In", "Kl\u00f6s\u00b7tern", "und", "Ab\u00b7te\u00b7yen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Zwar w\u00e4hnen, durch Kasteyn gest\u00e4rkt,", "tokens": ["Zwar", "w\u00e4h\u00b7nen", ",", "durch", "Kas\u00b7teyn", "ge\u00b7st\u00e4rkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Bonzen dich zu zwingen,", "tokens": ["Die", "Bon\u00b7zen", "dich", "zu", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch weiss man, dass sie unbemerkt", "tokens": ["Doch", "weiss", "man", ",", "dass", "sie", "un\u00b7be\u00b7merkt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "$,", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dir manches Opfer bringen.", "tokens": ["Dir", "man\u00b7ches", "Op\u00b7fer", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Du darfst nur winken, so bef\u00e4llt", "tokens": ["Du", "darfst", "nur", "win\u00b7ken", ",", "so", "be\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den kl\u00fcgsten Kopf der Schwindel,", "tokens": ["Den", "kl\u00fcgs\u00b7ten", "Kopf", "der", "Schwin\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Herkules, der stolze Held,", "tokens": ["Und", "Her\u00b7ku\u00b7les", ",", "der", "stol\u00b7ze", "Held", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Erniedrigt sich zur Spindel.", "tokens": ["Er\u00b7nied\u00b7rigt", "sich", "zur", "Spin\u00b7del", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Doch, Gott der Liebe! deine Macht", "tokens": ["Doch", ",", "Gott", "der", "Lie\u00b7be", "!", "dei\u00b7ne", "Macht"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "NN", "ART", "NN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mag auch noch weiter reichen,", "tokens": ["Mag", "auch", "noch", "wei\u00b7ter", "rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich bin es m\u00fcde, Tag und Nacht", "tokens": ["Ich", "bin", "es", "m\u00fc\u00b7de", ",", "Tag", "und", "Nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An deinem Joch zu keichen.", "tokens": ["An", "dei\u00b7nem", "Joch", "zu", "kei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Unz\u00e4hlbar, wie der Sand am Meer,", "tokens": ["Un\u00b7z\u00e4hl\u00b7bar", ",", "wie", "der", "Sand", "am", "Meer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Unz\u00e4hlbar sind die Plagen,", "tokens": ["Un\u00b7z\u00e4hl\u00b7bar", "sind", "die", "Pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die ich in deinem Dienst bisher", "tokens": ["Die", "ich", "in", "dei\u00b7nem", "Dienst", "bis\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bey Tag und Nacht ertragen.", "tokens": ["Bey", "Tag", "und", "Nacht", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Zwangst du nicht nachts, wenn alles ruht,", "tokens": ["Zwangst", "du", "nicht", "nachts", ",", "wenn", "al\u00b7les", "ruht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKNEG", "ADV", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich stundenweit zu laufen,", "tokens": ["Mich", "stun\u00b7den\u00b7weit", "zu", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und in des Mittags strenger Glut", "tokens": ["Und", "in", "des", "Mit\u00b7tags", "stren\u00b7ger", "Glut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach Athem oft zu schnaufen?", "tokens": ["Nach", "A\u00b7them", "oft", "zu", "schnau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Und triebst du mich nicht hundertmal", "tokens": ["Und", "triebst", "du", "mich", "nicht", "hun\u00b7dert\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PRF", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des losen M\u00e4dchens wegen,", "tokens": ["Des", "lo\u00b7sen", "M\u00e4d\u00b7chens", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das mir Vernunft und Freyheit stahl,", "tokens": ["Das", "mir", "Ver\u00b7nunft", "und", "Frey\u00b7heit", "stahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Sturmwind, Frost und Regen?", "tokens": ["Durch", "Sturm\u00b7wind", ",", "Frost", "und", "Re\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Sonst pries man als ein Muster mich:", "tokens": ["Sonst", "pries", "man", "als", "ein", "Mus\u00b7ter", "mich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "KOKOM", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Ruf war ohne Makel,", "tokens": ["Mein", "Ruf", "war", "oh\u00b7ne", "Ma\u00b7kel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ach! nun dien' ich rings durch dich", "tokens": ["Und", "ach", "!", "nun", "dien'", "ich", "rings", "durch", "dich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Volke zum Spektakel.", "tokens": ["Dem", "Vol\u00b7ke", "zum", "Spek\u00b7ta\u00b7kel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ich bin es satt, ein Thor zu seyn.", "tokens": ["Ich", "bin", "es", "satt", ",", "ein", "Thor", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$,", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du magst mit deinen Pfeilen", "tokens": ["Du", "magst", "mit", "dei\u00b7nen", "Pfei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und deinem bunten K\u00f6cherlein", "tokens": ["Und", "dei\u00b7nem", "bun\u00b7ten", "K\u00f6\u00b7cher\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun in das R\u00fcsthaus eilen.", "tokens": ["Nun", "in", "das", "R\u00fcst\u00b7haus", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "So rief ich auf. Da kam, o weh!", "tokens": ["So", "rief", "ich", "auf", ".", "Da", "kam", ",", "o", "weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "VVFIN", "$,", "FM", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit frischen Rosenwangen", "tokens": ["Mit", "fri\u00b7schen", "Ro\u00b7sen\u00b7wan\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und einem Busen, weiss wie Schnee,", "tokens": ["Und", "ei\u00b7nem", "Bu\u00b7sen", ",", "weiss", "wie", "Schnee", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "VVFIN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein sch\u00f6nes Kind gegangen.", "tokens": ["Ein", "sch\u00f6\u00b7nes", "Kind", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Dionen glich es an Gestalt.", "tokens": ["Di\u00b7o\u00b7nen", "glich", "es", "an", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sollt' ich widerstehen?", "tokens": ["Wie", "sollt'", "ich", "wi\u00b7der\u00b7ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie konnt' ich unger\u00fchrt und kalt", "tokens": ["Wie", "konnt'", "ich", "un\u00b7ge\u00b7r\u00fchrt", "und", "kalt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So viele Reitze sehen?", "tokens": ["So", "vie\u00b7le", "Reit\u00b7ze", "se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Es schlang den weichen sammtnen Arm", "tokens": ["Es", "schlang", "den", "wei\u00b7chen", "sammt\u00b7nen", "Arm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir l\u00e4chelnd um den Nacken,", "tokens": ["Mir", "l\u00e4\u00b7chelnd", "um", "den", "Na\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und sieh! mein Blut ward brennendwarm,", "tokens": ["Und", "sieh", "!", "mein", "Blut", "ward", "bren\u00b7nend\u00b7warm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es gl\u00fchten meine Backen.", "tokens": ["Es", "gl\u00fch\u00b7ten", "mei\u00b7ne", "Ba\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Ich \u00fcberliess mich taumelblind", "tokens": ["Ich", "\u00fc\u00b7berl\u00b7iess", "mich", "tau\u00b7mel\u00b7blind"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem m\u00e4chtigsten der Triebe,", "tokens": ["Dem", "m\u00e4ch\u00b7tigs\u00b7ten", "der", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Und fand, dass Ketten s\u00fcsser sind,", "tokens": ["Und", "fand", ",", "dass", "Ket\u00b7ten", "s\u00fcs\u00b7ser", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Freyheit ohne Liebe.", "tokens": ["Als", "Frey\u00b7heit", "oh\u00b7ne", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Mag jeder, den diess Schwachheit d\u00e4ucht,", "tokens": ["Mag", "je\u00b7der", ",", "den", "diess", "Schwach\u00b7heit", "d\u00e4ucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich auch der Thorheit zeihen;", "tokens": ["Mich", "auch", "der", "Thor\u00b7heit", "zei\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn jede Schwachheit dieser gleicht,", "tokens": ["Wenn", "je\u00b7de", "Schwach\u00b7heit", "die\u00b7ser", "gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So soll mich keine reuen.", "tokens": ["So", "soll", "mich", "kei\u00b7ne", "reu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}