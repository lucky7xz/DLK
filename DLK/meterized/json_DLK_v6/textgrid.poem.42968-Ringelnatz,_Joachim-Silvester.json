{"textgrid.poem.42968": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Silvester", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es gibt bei Armen und Reichen", "tokens": ["Es", "gibt", "bei", "Ar\u00b7men", "und", "Rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "So manche Herzen bang und still;", "tokens": ["So", "man\u00b7che", "Her\u00b7zen", "bang", "und", "still", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus manchem dieser Herzen will", "tokens": ["Aus", "man\u00b7chem", "die\u00b7ser", "Her\u00b7zen", "will"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "PDAT", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sorge nimmer weichen.", "tokens": ["Die", "Sor\u00b7ge", "nim\u00b7mer", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich bin einer neuen Idee auf der Spur", "tokens": ["Ich", "bin", "ei\u00b7ner", "neu\u00b7en", "I\u00b7dee", "auf", "der", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und \u00fcberlege sie sehr:", "tokens": ["Und", "\u00fc\u00b7berl\u00b7e\u00b7ge", "sie", "sehr", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Man sollte armen Leuten nur", "tokens": ["Man", "soll\u00b7te", "ar\u00b7men", "Leu\u00b7ten", "nur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gutes tun oder sagen,", "tokens": ["Gu\u00b7tes", "tun", "o\u00b7der", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Ohne vorher oder hinterher", "tokens": ["Oh\u00b7ne", "vor\u00b7her", "o\u00b7der", "hin\u00b7ter\u00b7her"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADV", "KON", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Nach ihnen zu fragen.", "tokens": ["Nach", "ih\u00b7nen", "zu", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Wer hat das wohl zuerst bestellt,", "tokens": ["Wer", "hat", "das", "wohl", "zu\u00b7erst", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was nun so glatt sich leiert:", "tokens": ["Was", "nun", "so", "glatt", "sich", "lei\u00b7ert", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ADJD", "PRF", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df jeder Stand und alle Welt", "tokens": ["Da\u00df", "je\u00b7der", "Stand", "und", "al\u00b7le", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Terminlich trauert und feiert.", "tokens": ["Ter\u00b7min\u00b7lich", "trau\u00b7ert", "und", "fei\u00b7ert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "So w\u00fcnschlein-p\u00fcnschlein den andern gleich", "tokens": ["So", "w\u00fcn\u00b7schlein\u00b7p\u00fcn\u00b7schlein", "den", "an\u00b7dern", "gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "ADJA", "ADV"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Will ich mich n\u00fcchtern betrinken,", "tokens": ["Will", "ich", "mich", "n\u00fcch\u00b7tern", "be\u00b7trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADJD", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Um gegen Morgen durchs Federweich", "tokens": ["Um", "ge\u00b7gen", "Mor\u00b7gen", "durchs", "Fe\u00b7der\u00b7weich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "NN", "APPRART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In Kaktustr\u00e4ume zu sinken.", "tokens": ["In", "Kak\u00b7tust\u00b7r\u00e4u\u00b7me", "zu", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Etwa: Da\u00df eine Mutschekuh,", "tokens": ["Et\u00b7wa", ":", "Da\u00df", "ei\u00b7ne", "Mut\u00b7sche\u00b7kuh", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die vollgefressen mit Heu war,", "tokens": ["Die", "voll\u00b7ge\u00b7fres\u00b7sen", "mit", "Heu", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mein Zimmer betrat und rief mir zu:", "tokens": ["Mein", "Zim\u00b7mer", "be\u00b7trat", "und", "rief", "mir", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u00bbprost Neujahr, Herr Doktor, prost Neujahr!\u00ab", "tokens": ["\u00bb", "prost", "Neu\u00b7jahr", ",", "Herr", "Dok\u00b7tor", ",", "prost", "Neu\u00b7jahr", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "NN", "$,", "NN", "NN", "$,", "VVFIN", "NN", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}