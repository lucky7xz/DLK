{"dta.poem.722": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  Es ist alles eitel.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Dv sihst/ wohin du sihst nur Eitelkeit auff Erden. ", "tokens": ["Dv", "sihst", "/", "wo\u00b7hin", "du", "sihst", "nur", "Ei\u00b7tel\u00b7keit", "auff", "Er\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$(", "PWAV", "PPER", "VVFIN", "ADV", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was dieser heute bawt/ reist jener morgen eyn: ", "tokens": ["Was", "die\u00b7ser", "heu\u00b7te", "bawt", "/", "reist", "je\u00b7ner", "mor\u00b7gen", "eyn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADV", "VVFIN", "$(", "VVFIN", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo jtzund St\u00e4dte stehn/ wird eine Wiesen seyn ", "tokens": ["Wo", "jt\u00b7zund", "St\u00e4d\u00b7te", "stehn", "/", "wird", "ei\u00b7ne", "Wie\u00b7sen", "seyn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "VVINF", "$(", "VAFIN", "ART", "NN", "VAINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auff der ein sch\u00e4fers Kind wird spilen mit den herden.", "tokens": ["Auff", "der", "ein", "sch\u00e4\u00b7fers", "Kind", "wird", "spi\u00b7len", "mit", "den", "her\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "VAFIN", "VVFIN", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was jtzund pr\u00e4chtig bl\u00fcht sol bald zutretten werden. ", "tokens": ["Was", "jt\u00b7zund", "pr\u00e4ch\u00b7tig", "bl\u00fcht", "sol", "bald", "zu\u00b7tret\u00b7ten", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VVFIN", "VMFIN", "ADV", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Was jtzt so pocht vnd trotzt ist morgen Asch vnd Bein. ", "tokens": ["Was", "jtzt", "so", "pocht", "vnd", "trotzt", "ist", "mor\u00b7gen", "Asch", "vnd", "Bein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VVFIN", "KON", "VVPP", "VAFIN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nichts ist das ewig sey/ kein Ertz kein ", "tokens": ["Nichts", "ist", "das", "e\u00b7wig", "sey", "/", "kein", "Ertz", "kein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "ADJD", "VAFIN", "$(", "PIAT", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Jtzt lacht das gl\u00fcck vns an/ bald donnern die Beschwerden.", "tokens": ["Jtzt", "lacht", "das", "gl\u00fcck", "vns", "an", "/", "bald", "don\u00b7nern", "die", "Be\u00b7schwer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$(", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der hohen thaten ruhm mu\u00df wie ein Traum vergehn. ", "tokens": ["Der", "ho\u00b7hen", "tha\u00b7ten", "ruhm", "mu\u00df", "wie", "ein", "Traum", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VMFIN", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll denn das spiel der zeit/ der leichte Mensch bestehn.", "tokens": ["Soll", "denn", "das", "spiel", "der", "zeit", "/", "der", "leich\u00b7te", "Mensch", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "PDS", "VVFIN", "ART", "NN", "$(", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach/ was ist alles di\u00df was wir k\u00f6stlich a", "tokens": ["Ach", "/", "was", "ist", "al\u00b7les", "di\u00df", "was", "wir", "k\u00f6st\u00b7lich", "a"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$(", "PWS", "VAFIN", "PIS", "PDS", "PRELS", "PPER", "ADJD", "NE"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Als schlechte nichtigkeit/ als ", "tokens": ["Als", "schlech\u00b7te", "nich\u00b7tig\u00b7keit", "/", "als"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KOUS", "ADJA", "NN", "$(", "KOKOM"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als eine wiesen Blum/ die man nicht wider findt.", "tokens": ["Als", "ei\u00b7ne", "wie\u00b7sen", "Blum", "/", "die", "man", "nicht", "wi\u00b7der", "findt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NE", "$(", "PRELS", "PIS", "PTKNEG", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Noch wil was ewig ist kein einig Mensch betrachten.", "tokens": ["Noch", "wil", "was", "e\u00b7wig", "ist", "kein", "ei\u00b7nig", "Mensch", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADJD", "VAFIN", "PIAT", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}