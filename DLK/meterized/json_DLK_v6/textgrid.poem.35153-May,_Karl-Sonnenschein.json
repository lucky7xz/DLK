{"textgrid.poem.35153": {"metadata": {"author": {"name": "May, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Sonnenschein", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sei lieb; sei gut, und z\u00fcrne nicht!", "tokens": ["Sei", "lieb", ";", "sei", "gut", ",", "und", "z\u00fcr\u00b7ne", "nicht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$.", "VAFIN", "ADJD", "$,", "KON", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum willst du nicht g\u00fctig sein?", "tokens": ["Wa\u00b7rum", "willst", "du", "nicht", "g\u00fc\u00b7tig", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein Leben sei wie ein Gedicht,", "tokens": ["Dein", "Le\u00b7ben", "sei", "wie", "ein", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Titelwort \u00bbNur Sonnenschein\u00ab.", "tokens": ["Das", "Ti\u00b7tel\u00b7wort", "\u00bb", "Nur", "Son\u00b7nen\u00b7schein", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$(", "ADV", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Schau dir die liebe Sonne an!", "tokens": ["Schau", "dir", "die", "lie\u00b7be", "Son\u00b7ne", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Ihr Segen reicht so weit, so weit.", "tokens": ["Ihr", "Se\u00b7gen", "reicht", "so", "weit", ",", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie leuchtet nicht blos dann und wann;", "tokens": ["Sie", "leuch\u00b7tet", "nicht", "blos", "dann", "und", "wann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "KON", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie thut es stets, zu aller Zeit.", "tokens": ["Sie", "thut", "es", "stets", ",", "zu", "al\u00b7ler", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Sie k\u00fc\u00dft die Sterne ohne Wahl;", "tokens": ["Sie", "k\u00fc\u00dft", "die", "Ster\u00b7ne", "oh\u00b7ne", "Wahl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie wei\u00df von Gunst und Vorzug nichts.", "tokens": ["Sie", "wei\u00df", "von", "Gunst", "und", "Vor\u00b7zug", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es trifft den Berg wie auch das Thal", "tokens": ["Es", "trifft", "den", "Berg", "wie", "auch", "das", "Thal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KOKOM", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ganze F\u00fclle ihres Lichts.", "tokens": ["Die", "gan\u00b7ze", "F\u00fcl\u00b7le", "ih\u00b7res", "Lichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und da\u00df sie keinen Dank begehrt,", "tokens": ["Und", "da\u00df", "sie", "kei\u00b7nen", "Dank", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das wei\u00dft du wohl schon l\u00e4ngst von ihr.", "tokens": ["Das", "wei\u00dft", "du", "wohl", "schon", "l\u00e4ngst", "von", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie denkt ja, was sie dir bescheert,", "tokens": ["Sie", "denkt", "ja", ",", "was", "sie", "dir", "be\u00b7scheert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PRELS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geh\u00f6re Alles, Alles dir.", "tokens": ["Ge\u00b7h\u00f6\u00b7re", "Al\u00b7les", ",", "Al\u00b7les", "dir", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PIS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was man auf Erden von ihr meint,", "tokens": ["Was", "man", "auf", "Er\u00b7den", "von", "ihr", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das st\u00f6rt sie nicht in ihrem Lauf.", "tokens": ["Das", "st\u00f6rt", "sie", "nicht", "in", "ih\u00b7rem", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie hat geschienen, und sie scheint;", "tokens": ["Sie", "hat", "ge\u00b7schie\u00b7nen", ",", "und", "sie", "scheint", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie h\u00f6rt auch nicht zu scheinen auf.", "tokens": ["Sie", "h\u00f6rt", "auch", "nicht", "zu", "schei\u00b7nen", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PTKZU", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sei lieb; sei gut, und z\u00fcrne nicht;", "tokens": ["Sei", "lieb", ";", "sei", "gut", ",", "und", "z\u00fcr\u00b7ne", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$.", "VAFIN", "ADJD", "$,", "KON", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denk immer an den Sonnenschein;", "tokens": ["Denk", "im\u00b7mer", "an", "den", "Son\u00b7nen\u00b7schein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann wird dein Leben ein Gedicht", "tokens": ["Dann", "wird", "dein", "Le\u00b7ben", "ein", "Ge\u00b7dicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Himmels f\u00fcr die Erde sein!", "tokens": ["Des", "Him\u00b7mels", "f\u00fcr", "die", "Er\u00b7de", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}