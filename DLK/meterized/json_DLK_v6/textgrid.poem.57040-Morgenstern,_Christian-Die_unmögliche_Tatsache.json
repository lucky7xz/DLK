{"textgrid.poem.57040": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Die unm\u00f6gliche Tatsache", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Palmstr\u00f6m, etwas schon an Jahren,", "tokens": ["Palm\u00b7str\u00f6m", ",", "et\u00b7was", "schon", "an", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wird an einer Stra\u00dfenbeuge", "tokens": ["wird", "an", "ei\u00b7ner", "Stra\u00b7\u00dfen\u00b7beu\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und von einem Kraftfahrzeuge", "tokens": ["und", "von", "ei\u00b7nem", "Kraft\u00b7fahr\u00b7zeu\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00fcberfahren.", "tokens": ["\u00fc\u00b7berf\u00b7ah\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Wie war (spricht er, sich erhebend", "tokens": ["Wie", "war", "(", "spricht", "er", ",", "sich", "er\u00b7he\u00b7bend"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "VAFIN", "$(", "VVFIN", "PPER", "$,", "PRF", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und entschlossen weiterlebend)", "tokens": ["und", "ent\u00b7schlos\u00b7sen", "wei\u00b7ter\u00b7le\u00b7bend", ")"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "m\u00f6glich, wie dies Ungl\u00fcck, ja \u2013:", "tokens": ["m\u00f6g\u00b7lich", ",", "wie", "dies", "Un\u00b7gl\u00fcck", ",", "ja", "\u2013", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJD", "$,", "PWAV", "PDS", "NN", "$,", "ADV", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df es \u00fcberhaupt geschah?", "tokens": ["da\u00df", "es", "\u00fc\u00b7ber\u00b7haupt", "ge\u00b7schah", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ist die Staatskunst anzuklagen", "tokens": ["Ist", "die", "Staats\u00b7kunst", "an\u00b7zu\u00b7kla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVIZU"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in Bezug auf Kraftfahrwagen?", "tokens": ["in", "Be\u00b7zug", "auf", "Kraft\u00b7fahr\u00b7wa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gab die Polizeivorschrift", "tokens": ["Gab", "die", "Po\u00b7li\u00b7zei\u00b7vor\u00b7schrift"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "hier dem Fahrer freie Trift?", "tokens": ["hier", "dem", "Fah\u00b7rer", "frei\u00b7e", "Trift", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Oder war vielmehr verboten", "tokens": ["O\u00b7der", "war", "viel\u00b7mehr", "ver\u00b7bo\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hier Lebendige zu Toten", "tokens": ["hier", "Le\u00b7ben\u00b7di\u00b7ge", "zu", "To\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "umzuwandeln \u2013 kurz und schlicht:", "tokens": ["um\u00b7zu\u00b7wan\u00b7deln", "\u2013", "kurz", "und", "schlicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVIZU", "$(", "ADJD", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Eingeh\u00fcllt in feuchte T\u00fccher,", "tokens": ["Ein\u00b7ge\u00b7h\u00fcllt", "in", "feuch\u00b7te", "T\u00fc\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "pr\u00fcft er die Gesetzesb\u00fccher", "tokens": ["pr\u00fcft", "er", "die", "Ge\u00b7set\u00b7zes\u00b7b\u00fc\u00b7cher"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und ist alsobald im klaren:", "tokens": ["und", "ist", "al\u00b7so\u00b7bald", "im", "kla\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPRART", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wagen durften dort nicht fahren!", "tokens": ["Wa\u00b7gen", "durf\u00b7ten", "dort", "nicht", "fah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und er kommt zu dem Ergebnis:", "tokens": ["Und", "er", "kommt", "zu", "dem", "Er\u00b7geb\u00b7nis", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur ein Traum war das Erlebnis.", "tokens": ["Nur", "ein", "Traum", "war", "das", "Er\u00b7leb\u00b7nis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Weil, so schlie\u00dft er messerscharf,", "tokens": ["Weil", ",", "so", "schlie\u00dft", "er", "mes\u00b7ser\u00b7scharf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht sein ", "tokens": ["nicht", "sein"], "token_info": ["word", "word"], "pos": ["PTKNEG", "VAINF"], "meter": "-+", "measure": "iambic.single"}}}}}