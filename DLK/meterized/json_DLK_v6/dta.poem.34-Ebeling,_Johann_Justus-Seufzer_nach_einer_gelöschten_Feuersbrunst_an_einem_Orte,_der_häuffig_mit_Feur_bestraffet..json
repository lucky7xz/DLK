{"dta.poem.34": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Seufzer  \n nach einer gel\u00f6schten Feuersbrunst an  \n einem Orte, der h\u00e4uffig mit Feur  \n bestraffet.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198797", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Gerechter GOtt! die Feuer-Stimme,", "tokens": ["Ge\u00b7rech\u00b7ter", "Gott", "!", "die", "Feu\u00b7er\u00b7Stim\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat uns gezeigt mit ihren Grimme,", "tokens": ["Hat", "uns", "ge\u00b7zeigt", "mit", "ih\u00b7ren", "Grim\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie schreklich sey dein strenger Zorn:", "tokens": ["Wie", "schrek\u00b7lich", "sey", "dein", "stren\u00b7ger", "Zorn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch deine Gnade hat den Born,", "tokens": ["Doch", "dei\u00b7ne", "Gna\u00b7de", "hat", "den", "Born", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zur Stillung wiederum geschaffen,", "tokens": ["Zur", "Stil\u00b7lung", "wie\u00b7de\u00b7rum", "ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Uns nicht mit Untergang zu straffen.", "tokens": ["Uns", "nicht", "mit", "Un\u00b7ter\u00b7gang", "zu", "straf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Dein Feur das w\u00fctend um sich brennet,", "tokens": ["Dein", "Feur", "das", "w\u00fc\u00b7tend", "um", "sich", "bren\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von einem Haus zum andern rennet,", "tokens": ["Von", "ei\u00b7nem", "Haus", "zum", "an\u00b7dern", "ren\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Frist alles, was sein Brand ber\u00fchrt:", "tokens": ["Frist", "al\u00b7les", ",", "was", "sein", "Brand", "be\u00b7r\u00fchrt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dies haben wir auch oft versp\u00fcrt;", "tokens": ["Dies", "ha\u00b7ben", "wir", "auch", "oft", "ver\u00b7sp\u00fcrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da wir uns doch nicht gebessert;", "tokens": ["Und", "da", "wir", "uns", "doch", "nicht", "ge\u00b7bes\u00b7sert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "So hast du es mit Recht vergr\u00f6ssert.", "tokens": ["So", "hast", "du", "es", "mit", "Recht", "ver\u00b7gr\u00f6s\u00b7sert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du st\u00e4upest die mit deiner Ruthen,", "tokens": ["Du", "st\u00e4u\u00b7pest", "die", "mit", "dei\u00b7ner", "Ru\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die noch von alten Wunden bluten;", "tokens": ["Die", "noch", "von", "al\u00b7ten", "Wun\u00b7den", "blu\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo es noch raucht, entsteht dein Brand", "tokens": ["Wo", "es", "noch", "raucht", ",", "ent\u00b7steht", "dein", "Brand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach! zieh zur\u00fck die schwere Hand!", "tokens": ["Ach", "!", "zieh", "zu\u00b7r\u00fck", "die", "schwe\u00b7re", "Hand", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du h\u00f6rest Vater unser Weinen,", "tokens": ["Du", "h\u00f6\u00b7rest", "Va\u00b7ter", "un\u00b7ser", "Wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und l\u00e4st stat Feuer, Gnade scheinen.", "tokens": ["Und", "l\u00e4st", "stat", "Feu\u00b7er", ",", "Gna\u00b7de", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}