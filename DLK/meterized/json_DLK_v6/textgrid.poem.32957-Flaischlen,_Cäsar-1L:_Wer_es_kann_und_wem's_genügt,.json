{"textgrid.poem.32957": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer es kann und wem's gen\u00fcgt,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer es kann und wem's gen\u00fcgt,", "tokens": ["Wer", "es", "kann", "und", "wem's", "ge\u00b7n\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "KON", "PWS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df er sich mit dem bescheidet,", "tokens": ["da\u00df", "er", "sich", "mit", "dem", "be\u00b7schei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "ehrsam, biedermannvergn\u00fcgt,", "tokens": ["ehr\u00b7sam", ",", "bie\u00b7der\u00b7mann\u00b7ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "drauf der Alltag ihn vereidet ...", "tokens": ["drauf", "der", "All\u00b7tag", "ihn", "ver\u00b7ei\u00b7det", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wem gen\u00fcgt, was er so kann,", "tokens": ["Wem", "ge\u00b7n\u00fcgt", ",", "was", "er", "so", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PWS", "PPER", "ADV", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "schlecht und recht, wie eben jeder", "tokens": ["schlecht", "und", "recht", ",", "wie", "e\u00b7ben", "je\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "$,", "PWAV", "ADV", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "mit der Zeit sich an\u00fcbt, sei's ...", "tokens": ["mit", "der", "Zeit", "sich", "an\u00b7\u00fcbt", ",", "sei's", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$,", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "sei's mit Pinsel oder Feder ...", "tokens": ["sei's", "mit", "Pin\u00b7sel", "o\u00b7der", "Fe\u00b7der", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Der vertr\u00e4gt sich freilich stets", "tokens": ["Der", "ver\u00b7tr\u00e4gt", "sich", "frei\u00b7lich", "stets"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "musterhaft mit allen Tanten,", "tokens": ["mus\u00b7ter\u00b7haft", "mit", "al\u00b7len", "Tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wei\u00df von guten Leuten nur,", "tokens": ["wei\u00df", "von", "gu\u00b7ten", "Leu\u00b7ten", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "nur von guten Musikanten.", "tokens": ["nur", "von", "gu\u00b7ten", "Mu\u00b7si\u00b7kan\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbruhe!\u00ab r\u00e4t er \u00bbRuhe, Freund!", "tokens": ["\u00bb", "ru\u00b7he", "!", "\u00ab", "r\u00e4t", "er", "\u00bb", "Ru\u00b7he", ",", "Freund", "!"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "NN", "$.", "$(", "VVFIN", "PPER", "$(", "NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vorsicht, soll das Boot nicht kentern!", "tokens": ["Vor\u00b7sicht", ",", "soll", "das", "Boot", "nicht", "ken\u00b7tern", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "unser Kurs war gut bis jetzt,", "tokens": ["un\u00b7ser", "Kurs", "war", "gut", "bis", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "APPR", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und wozu, was gut ist, \u00e4ndern!?", "tokens": ["und", "wo\u00b7zu", ",", "was", "gut", "ist", ",", "\u00e4n\u00b7dern", "!?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWAV", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was auch soll dein trotzig-toll", "tokens": ["Was", "auch", "soll", "dein", "trot\u00b7zig\u00b7toll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VMFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Strom- und Sturm-entgegen-Segeln?!", "tokens": ["Strom", "und", "Stur\u00b7ment\u00b7ge\u00b7gen\u00b7Se\u00b7geln", "?!"], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "lerne lieber endlich Skat", "tokens": ["ler\u00b7ne", "lie\u00b7ber", "end\u00b7lich", "Skat"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "oder komm, eins mit zu kegeln!\u00ab", "tokens": ["o\u00b7der", "komm", ",", "eins", "mit", "zu", "ke\u00b7geln", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$,", "PIS", "APPR", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und der Mann hat ja so recht:", "tokens": ["Und", "der", "Mann", "hat", "ja", "so", "recht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "la\u00df dein Mehr-als-andre-Wollen", "tokens": ["la\u00df", "dein", "Mehr\u00b7als\u00b7an\u00b7dre\u00b7Wol\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und begn\u00fcge dich damit,", "tokens": ["und", "be\u00b7gn\u00fc\u00b7ge", "dich", "da\u00b7mit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "den gebahnten Weg zu trollen.", "tokens": ["den", "ge\u00b7bahn\u00b7ten", "Weg", "zu", "trol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Dichte, was die Leute freut,", "tokens": ["Dich\u00b7te", ",", "was", "die", "Leu\u00b7te", "freut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "la\u00df dein In-die-Tiefe-Graben!", "tokens": ["la\u00df", "dein", "In\u00b7die\u00b7Tie\u00b7fe\u00b7Gra\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "male, wie du, brauchst du Geld,", "tokens": ["ma\u00b7le", ",", "wie", "du", ",", "brauchst", "du", "Geld", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "$,", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "w\u00fcnschen wirst, gemalt zu haben!", "tokens": ["w\u00fcn\u00b7schen", "wirst", ",", "ge\u00b7malt", "zu", "ha\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVINF", "VAFIN", "$,", "VVPP", "PTKZU", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Weise denkt, wer also denkt:", "tokens": ["Wei\u00b7se", "denkt", ",", "wer", "al\u00b7so", "denkt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWS", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "voll stets hat er seine Kiepe!", "tokens": ["voll", "stets", "hat", "er", "sei\u00b7ne", "Kie\u00b7pe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und das ist ja doch der Zweck ...", "tokens": ["und", "das", "ist", "ja", "doch", "der", "Zweck", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "was die Nachwelt meint, ist \u2013 piepe!", "tokens": ["was", "die", "Nach\u00b7welt", "meint", ",", "ist", "\u2013", "pie\u00b7pe", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VAFIN", "$(", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}