{"dta.poem.607": {"metadata": {"author": {"name": "Gressel, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "Als die hohe   Vice-Rectorats- W\u00fcrde einen  \n  Professori Metaphys.  aufgetragen wurde.  \n Jm Thon:  \n  Nichts ist so   galant   gebohren/ als die sch\u00f6ne   Galathee.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1716", "urn": "urn:nbn:de:kobv:b4-200905199041", "language": ["de:0.85", "nl:0.14"], "booktitle": "Celander [i. e. Gressel, Johann Georg]: Verliebte-Galante/ Sinn-Vermischte und Grab-Gedichte. Hamburg u. a., 1716."}, "poem": {"stanza.1": {"line.1": {"text": "Nichts ist so verha\u00dft geworden", "tokens": ["Nichts", "ist", "so", "ver\u00b7ha\u00dft", "ge\u00b7wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "VAPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als die ", "tokens": ["Als", "die"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Denn der dummen Sp\u00f6tter-Orden", "tokens": ["Denn", "der", "dum\u00b7men", "Sp\u00f6t\u00b7ter\u00b7Or\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schimpffet und verl\u00e4stert ja/", "tokens": ["Schimpf\u00b7fet", "und", "ver\u00b7l\u00e4s\u00b7tert", "ja", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ein ", "tokens": ["Da\u00df", "ein"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Ein Gelehrter heissen mu\u00df.", "tokens": ["Ein", "Ge\u00b7lehr\u00b7ter", "heis\u00b7sen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ens und non ens sollen Sachen", "tokens": ["Ens", "und", "non", "ens", "sol\u00b7len", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "ADV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gar von keinen Werthe seyn/", "tokens": ["Gar", "von", "kei\u00b7nen", "Wert\u00b7he", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch ich mu\u00df der Thorheit lachen/", "tokens": ["Doch", "ich", "mu\u00df", "der", "Thor\u00b7heit", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn mir f\u00e4llt das Sprich-wort ein:", "tokens": ["Denn", "mir", "f\u00e4llt", "das", "Sprich\u00b7wort", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df die K\u00fcnste keiner ha\u00dft/", "tokens": ["Da\u00df", "die", "K\u00fcns\u00b7te", "kei\u00b7ner", "ha\u00dft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als der selber nichts gefa\u00dft.", "tokens": ["Als", "der", "sel\u00b7ber", "nichts", "ge\u00b7fa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Blinde Welt/ du bist geschossen/", "tokens": ["Blin\u00b7de", "Welt", "/", "du", "bist", "ge\u00b7schos\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PPER", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unverstand/ du bist verblendt/", "tokens": ["Un\u00b7ver\u00b7stand", "/", "du", "bist", "ver\u00b7blendt", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weisheit nennst du Kinder Possen/", "tokens": ["Weis\u00b7heit", "nennst", "du", "Kin\u00b7der", "Pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil dein dummer Kopff nicht kennt/", "tokens": ["Weil", "dein", "dum\u00b7mer", "Kopff", "nicht", "kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PTKNEG", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie der Weisheit falscher Dunst/", "tokens": ["Wie", "der", "Weis\u00b7heit", "fal\u00b7scher", "Dunst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird verjagt durch diese Kunst.", "tokens": ["Wird", "ver\u00b7jagt", "durch", "die\u00b7se", "Kunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Stahl/ der alle Welt ergetzet/", "tokens": ["Stahl", "/", "der", "al\u00b7le", "Welt", "er\u00b7get\u00b7zet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4tte den gest\u00e4hlten Muht", "tokens": ["H\u00e4t\u00b7te", "den", "ge\u00b7st\u00e4hl\u00b7ten", "Muht"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nie an diese Kunst gesetzet/", "tokens": ["Nie", "an", "die\u00b7se", "Kunst", "ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn er nicht das h\u00f6chste Gut", "tokens": ["Wenn", "er", "nicht", "das", "h\u00f6chs\u00b7te", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Diese Lehre zu verstehn", "tokens": ["Die\u00b7se", "Leh\u00b7re", "zu", "ver\u00b7stehn"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Jhm vor andern ausersehn.", "tokens": ["Jhm", "vor", "an\u00b7dern", "au\u00b7ser\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "VVIZU", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hebenstreit das Licht der Erden/", "tokens": ["He\u00b7ben\u00b7streit", "das", "Licht", "der", "Er\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der viel Streite beygelegt/", "tokens": ["Der", "viel", "Strei\u00b7te", "bey\u00b7ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "D\u00fcrffte wol vergessen werden/", "tokens": ["D\u00fcrff\u00b7te", "wol", "ver\u00b7ges\u00b7sen", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVPP", "VAINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn er nicht den Geist gepr\u00e4gt", "tokens": ["Wenn", "er", "nicht", "den", "Geist", "ge\u00b7pr\u00e4gt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "In die B\u00fccher die der Safft", "tokens": ["In", "die", "B\u00fc\u00b7cher", "die", "der", "Safft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind von aller Wissenschafft.", "tokens": ["Sind", "von", "al\u00b7ler", "Wis\u00b7sen\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "L&#339;bers und Martini Schrifften", "tokens": ["L", "&#339;", "bers", "und", "Mar\u00b7ti\u00b7ni", "Schriff\u00b7ten"], "token_info": ["word", "XML_entity", "word", "word", "word", "word"], "pos": ["NE", "$(", "ADV", "KON", "NE", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "So der Welt viel Licht gebracht/", "tokens": ["So", "der", "Welt", "viel", "Licht", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PIAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nnen uns ein Denck-Mahl stifften/", "tokens": ["K\u00f6n\u00b7nen", "uns", "ein", "Den\u00b7ck\u00b7Mahl", "stiff\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "So der Zeiten Rost verlacht/", "tokens": ["So", "der", "Zei\u00b7ten", "Rost", "ver\u00b7lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VVPP", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Bis der Eltz und Elm vergeht.", "tokens": ["Bis", "der", "Eltz", "und", "Elm", "ver\u00b7geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Antenor du hast erfahren/", "tokens": ["An\u00b7te\u00b7nor", "du", "hast", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VAFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie der unverdro\u00dfne Flei\u00df", "tokens": ["Wie", "der", "un\u00b7ver\u00b7dro\u00df\u00b7ne", "Flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich kan mit der Weisheit paaren/", "tokens": ["Sich", "kan", "mit", "der", "Weis\u00b7heit", "paa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VMFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wenn der Jugend warmer Schwei\u00df", "tokens": ["Wenn", "der", "Ju\u00b7gend", "war\u00b7mer", "Schwei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich durch alle Adern dringt/", "tokens": ["Dich", "durch", "al\u00b7le", "A\u00b7dern", "dringt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und den Ruhm zum Lohne bringt.", "tokens": ["Und", "den", "Ruhm", "zum", "Loh\u00b7ne", "bringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Es ist dein erhitzt Bem\u00fchen", "tokens": ["Es", "ist", "dein", "er\u00b7hitzt", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "VVFIN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keine Grillen-F\u00e4ngerey/", "tokens": ["Kei\u00b7ne", "Gril\u00b7len\u00b7F\u00e4n\u00b7ge\u00b7rey", "/"], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn du weist heraus zu ziehen/", "tokens": ["Denn", "du", "weist", "he\u00b7raus", "zu", "zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was zur Sache dienlich sey:", "tokens": ["Was", "zur", "Sa\u00b7che", "dien\u00b7lich", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kein Wort/ so du je gelehrt/", "tokens": ["Kein", "Wort", "/", "so", "du", "je", "ge\u00b7lehrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "ADV", "PPER", "ADV", "VVPP", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Ist vergeblich angeh\u00f6rt.", "tokens": ["Ist", "ver\u00b7geb\u00b7lich", "an\u00b7ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Unsre Stadt r\u00fchmt deine Gaben/", "tokens": ["Uns\u00b7re", "Stadt", "r\u00fchmt", "dei\u00b7ne", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Womit dich der Himmel ziert/", "tokens": ["Wo\u00b7mit", "dich", "der", "Him\u00b7mel", "ziert", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wird noch mehr Nutzen haben/", "tokens": ["Und", "wird", "noch", "mehr", "Nut\u00b7zen", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "VAFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wenn der nun den Scepter f\u00fchrt/", "tokens": ["Wenn", "der", "nun", "den", "Scep\u00b7ter", "f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher ist zu unsrer Zeit", "tokens": ["Wel\u00b7cher", "ist", "zu", "uns\u00b7rer", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mehr als Stahl und Hebenstreit.", "tokens": ["Mehr", "als", "Stahl", "und", "He\u00b7ben\u00b7streit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Brauche denn was dir gegeben", "tokens": ["Brau\u00b7che", "denn", "was", "dir", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PWS", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00fcnfftig zur Gerechtigkeit:", "tokens": ["K\u00fcnff\u00b7tig", "zur", "Ge\u00b7rech\u00b7tig\u00b7keit", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df den Purpur Geist und Leben", "tokens": ["La\u00df", "den", "Pur\u00b7pur", "Geist", "und", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns zum besten seyn geweyht:", "tokens": ["Uns", "zum", "bes\u00b7ten", "seyn", "ge\u00b7weyht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "B\u00f6s\u2019 und gute ", "tokens": ["B\u00f6s'", "und", "gu\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Hei\u00dft den Scepter wohlgef\u00fchrt.", "tokens": ["Hei\u00dft", "den", "Scep\u00b7ter", "wohl\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}