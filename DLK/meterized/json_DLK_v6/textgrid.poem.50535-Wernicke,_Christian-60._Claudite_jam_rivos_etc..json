{"textgrid.poem.50535": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "60. Claudite jam rivos etc.", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schlisst eure ", "tokens": ["Schlisst", "eu\u00b7re"], "token_info": ["word", "word"], "pos": ["VVFIN", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "H\u00e4tt' ich gelernt, wie man ", "tokens": ["H\u00e4tt'", "ich", "ge\u00b7lernt", ",", "wie", "man"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "VVPP", "$,", "PWAV", "PIS"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So h\u00e4tt' ich schon vielleicht ", "tokens": ["So", "h\u00e4tt'", "ich", "schon", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und h\u00e4tt' ich ", "tokens": ["Und", "h\u00e4tt'", "ich"], "token_info": ["word", "word", "word"], "pos": ["KON", "VAFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "So ging mir auch vielleicht anitzt kein ", "tokens": ["So", "ging", "mir", "auch", "viel\u00b7leicht", "a\u00b7nitzt", "kein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PIAT"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "H\u00e4tt' ich durch ", "tokens": ["H\u00e4tt'", "ich", "durch"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "So tr\u00fcg' ich auch vielleicht schon einen ", "tokens": ["So", "tr\u00fcg'", "ich", "auch", "viel\u00b7leicht", "schon", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und w\u00fcst' ich ", "tokens": ["Und", "w\u00fcst'", "ich"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "So h\u00e4tt' ich ", "tokens": ["So", "h\u00e4tt'", "ich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Es muss, wer etwas hier gedencket zu erwischen,", "tokens": ["Es", "muss", ",", "wer", "et\u00b7was", "hier", "ge\u00b7den\u00b7cket", "zu", "er\u00b7wi\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PWS", "PIS", "ADV", "VVPP", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Stat eurem ", "tokens": ["Stat", "eu\u00b7rem"], "token_info": ["word", "word"], "pos": ["FM.la", "FM.la"], "meter": "-+-", "measure": "amphibrach.single"}}}}}