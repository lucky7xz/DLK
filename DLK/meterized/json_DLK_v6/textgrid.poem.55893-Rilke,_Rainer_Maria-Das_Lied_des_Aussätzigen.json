{"textgrid.poem.55893": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Das Lied des Auss\u00e4tzigen", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sieh ich bin einer, den alles verlassen hat.", "tokens": ["Sieh", "ich", "bin", "ei\u00b7ner", ",", "den", "al\u00b7les", "ver\u00b7las\u00b7sen", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VAFIN", "ART", "$,", "PRELS", "PIS", "VVPP", "VAFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Keiner wei\u00df in der Stadt von mir,", "tokens": ["Kei\u00b7ner", "wei\u00df", "in", "der", "Stadt", "von", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "APPR", "PPER", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Aussatz hat mich befallen.", "tokens": ["Aus\u00b7satz", "hat", "mich", "be\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ich schlage mein Klapperwerk,", "tokens": ["Und", "ich", "schla\u00b7ge", "mein", "Klap\u00b7per\u00b7werk", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "klopfe mein trauriges Augenmerk", "tokens": ["klop\u00b7fe", "mein", "trau\u00b7ri\u00b7ges", "Au\u00b7gen\u00b7merk"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "in die Ohren allen", "tokens": ["in", "die", "Oh\u00b7ren", "al\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "die nahe vor\u00fcbergehn.", "tokens": ["die", "na\u00b7he", "vor\u00b7\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und die es h\u00f6lzern h\u00f6ren, sehn", "tokens": ["Und", "die", "es", "h\u00f6l\u00b7zern", "h\u00f6\u00b7ren", ",", "sehn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "PPER", "VVINF", "VVINF", "$,", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "erst gar nicht her, und was hier geschehn", "tokens": ["erst", "gar", "nicht", "her", ",", "und", "was", "hier", "ge\u00b7schehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PTKNEG", "PTKVZ", "$,", "KON", "PWS", "ADV", "VVINF"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "wollen sie nicht erfahren.", "tokens": ["wol\u00b7len", "sie", "nicht", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Soweit der Klang meiner Klapper reicht", "tokens": ["So\u00b7weit", "der", "Klang", "mei\u00b7ner", "Klap\u00b7per", "reicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "bin ich zuhause; aber vielleicht", "tokens": ["bin", "ich", "zu\u00b7hau\u00b7se", ";", "a\u00b7ber", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "$.", "ADV", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "machst Du meine Klapper so laut,", "tokens": ["machst", "Du", "mei\u00b7ne", "Klap\u00b7per", "so", "laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "da\u00df sich keiner in meine Ferne traut", "tokens": ["da\u00df", "sich", "kei\u00b7ner", "in", "mei\u00b7ne", "Fer\u00b7ne", "traut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PIS", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "der mir jetzt aus der N\u00e4he weicht.", "tokens": ["der", "mir", "jetzt", "aus", "der", "N\u00e4\u00b7he", "weicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "So da\u00df ich sehr lange gehen kann", "tokens": ["So", "da\u00df", "ich", "sehr", "lan\u00b7ge", "ge\u00b7hen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "ohne M\u00e4dchen, Frau oder Mann", "tokens": ["oh\u00b7ne", "M\u00e4d\u00b7chen", ",", "Frau", "o\u00b7der", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "oder Kind zu entdecken.", "tokens": ["o\u00b7der", "Kind", "zu", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.3": {"line.1": {"text": "Tiere will ich nicht schrecken.", "tokens": ["Tie\u00b7re", "will", "ich", "nicht", "schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}