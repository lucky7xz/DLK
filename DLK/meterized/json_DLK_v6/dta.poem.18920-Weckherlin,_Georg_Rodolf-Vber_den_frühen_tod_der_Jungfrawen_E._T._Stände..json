{"dta.poem.18920": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Vber den fr\u00fchen tod der Jungfrawen  \n E. T. St\u00e4nde.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Der wahren Tugent glantz/ der klar in dem auff-", "tokens": ["Der", "wah\u00b7ren", "Tu\u00b7gent", "glantz", "/", "der", "klar", "in", "dem", "auf\u00b7f"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "ART", "ADJD", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "gang", "tokens": ["gang"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Dich mehr dan der Mittag in andern wolte zieren/", "tokens": ["Dich", "mehr", "dan", "der", "Mit\u00b7tag", "in", "an\u00b7dern", "wol\u00b7te", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ART", "NN", "APPR", "PIS", "VMFIN", "VVINF", "$("], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Bezeugte/ da\u00df dein lauff gantz l\u00f6blich vn\u0303 nit lang", "tokens": ["Be\u00b7zeug\u00b7te", "/", "da\u00df", "dein", "lauff", "gantz", "l\u00f6b\u00b7lich", "v\u00f1", "nit", "lang"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "KOUS", "PPOSAT", "NN", "ADV", "ADJD", "NE", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Solt/ wie ein sch\u00f6ner tag/ schnellfl\u00fcchtig fort pas-", "tokens": ["Solt", "/", "wie", "ein", "sch\u00f6\u00b7ner", "tag", "/", "schnell\u00b7fl\u00fcch\u00b7tig", "fort", "pas"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "$(", "KOKOM", "ART", "ADJA", "NN", "$(", "ADJD", "PTKVZ", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "sieren.", "tokens": ["sie\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.2": {"line.1": {"text": "Die blumen/ welche sich erzaigen reiff zu fr\u00fch/", "tokens": ["Die", "blu\u00b7men", "/", "wel\u00b7che", "sich", "er\u00b7zai\u00b7gen", "reiff", "zu", "fr\u00fch", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PRF", "VVINF", "VVFIN", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die werden von dem frost bald welck/ vnd weg-", "tokens": ["Die", "wer\u00b7den", "von", "dem", "frost", "bald", "welck", "/", "vnd", "weg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "ART", "NN", "ADV", "ADJD", "$(", "KON", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "genommen:", "tokens": ["ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Vn\u0303 kein zufr\u00fche frucht ka\u0303/ wa\u0303 man sch\u00f5 mit m\u00fch", "tokens": ["V\u00f1", "kein", "zu\u00b7fr\u00fc\u00b7he", "frucht", "k\u00e3", "/", "w\u00e3", "man", "sch\u00f5", "mit", "m\u00fch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PIAT", "ADJA", "NN", "VVFIN", "$(", "PWAV", "PIS", "VVFIN", "APPR", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie lang behalten wolt/ den Winter vberkommen.", "tokens": ["Sie", "lang", "be\u00b7hal\u00b7ten", "wolt", "/", "den", "Win\u00b7ter", "vber\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "VMFIN", "$(", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Dan der Natur gesatz/ das der mensch halten mu\u00df/", "tokens": ["Dan", "der", "Na\u00b7tur", "ge\u00b7satz", "/", "das", "der", "mensch", "hal\u00b7ten", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "$(", "PRELS", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gebeut/ dz nichts alhie gl\u00fcck seelig lang soll wehre\u0304;", "tokens": ["Ge\u00b7beut", "/", "dz", "nichts", "al\u00b7hie", "gl\u00fcck", "see\u00b7lig", "lang", "soll", "wehr\u0113", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PIS", "ADV", "ADJD", "ADJD", "ADJD", "VMFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd das was herrlich ist/ gleichsam zu einer bu\u00df", "tokens": ["Vnd", "das", "was", "herr\u00b7lich", "ist", "/", "gleich\u00b7sam", "zu", "ei\u00b7ner", "bu\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PDS", "PRELS", "ADJD", "VAFIN", "$(", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Soll (die welt nicht zu lang zuehren) bald auff-", "tokens": ["Soll", "(", "die", "welt", "nicht", "zu", "lang", "zu\u00b7eh\u00b7ren", ")", "bald", "auf\u00b7f"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "$(", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "VVINF", "$(", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "h\u00f6ren.", "tokens": ["h\u00f6\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.4": {"line.1": {"text": "So deine Jugent zart mit arbeit/ ehr vnd zucht/", "tokens": ["So", "dei\u00b7ne", "Ju\u00b7gent", "zart", "mit", "ar\u00b7beit", "/", "ehr", "vnd", "zucht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJD", "APPR", "NN", "$(", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Wei\u00dfheit vnd Gotsforcht/ wissenschafft viler", "tokens": ["Mit", "Wei\u00df\u00b7heit", "vnd", "Gots\u00b7forcht", "/", "wis\u00b7sen\u00b7schafft", "vi\u00b7ler"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$(", "VVFIN", "PIAT"], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "zungen/", "tokens": ["zun\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["ADV", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Mit deiner Sch\u00f6nheit blust/ mit deines verstands", "tokens": ["Mit", "dei\u00b7ner", "Sch\u00f6n\u00b7heit", "blust", "/", "mit", "dei\u00b7nes", "ver\u00b7stands"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$(", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "frucht/", "tokens": ["frucht", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Zog dich bill ich herf\u00fcr bey alten vnd bey jungen.", "tokens": ["Zog", "dich", "bill", "ich", "her\u00b7f\u00fcr", "bey", "al\u00b7ten", "vnd", "bey", "jun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "KON", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Daher der freche tod/ sehend wie deine sehl", "tokens": ["Da\u00b7her", "der", "fre\u00b7che", "tod", "/", "se\u00b7hend", "wie", "dei\u00b7ne", "sehl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "$(", "ADJD", "KOKOM", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "War mit vernunfft vnd kunst des alters selbs ge-", "tokens": ["War", "mit", "ver\u00b7nunfft", "vnd", "kunst", "des", "al\u00b7ters", "selbs", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NN", "KON", "NN", "ART", "ADJA", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "schm\u00fccket/", "tokens": ["schm\u00fc\u00b7cket", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Hat als ein reiffe frucht dich (frey von allem fehl)", "tokens": ["Hat", "als", "ein", "reif\u00b7fe", "frucht", "dich", "(", "frey", "von", "al\u00b7lem", "fehl", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "NN", "PPER", "$(", "ADJD", "APPR", "PIS", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit ga\u0303tz gnadloser ha\u0303d/ noch bl\u00fchend/ abgezwicket.", "tokens": ["Mit", "g\u00e3tz", "gnad\u00b7lo\u00b7ser", "h\u00e3d", "/", "noch", "bl\u00fc\u00b7hend", "/", "ab\u00b7ge\u00b7zwi\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$(", "ADV", "VVPP", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ob aber wol der Tod dir/ vnbefl\u00f6ckte blum/", "tokens": ["Ob", "a\u00b7ber", "wol", "der", "Tod", "dir", "/", "vn\u00b7be\u00b7fl\u00f6ck\u00b7te", "blum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "PPER", "$(", "ADJA", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch seiner sichel straich den fall zu fr\u00fch gegeb\u1ebd;", "tokens": ["Durch", "sei\u00b7ner", "si\u00b7chel", "straich", "den", "fall", "zu", "fr\u00fch", "ge\u00b7ge\u00b7b\u1ebd", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "ART", "NN", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "So bl\u00fchet allzeit doch frisch deiner tugent ruhm/", "tokens": ["So", "bl\u00fc\u00b7het", "all\u00b7zeit", "doch", "frisch", "dei\u00b7ner", "tu\u00b7gent", "ruhm", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADJD", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil die lang leben gnug/ die recht vnd wol gnug", "tokens": ["Weil", "die", "lang", "le\u00b7ben", "gnug", "/", "die", "recht", "vnd", "wol", "gnug"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "VVFIN", "ADV", "$(", "ART", "ADJD", "KON", "ADV", "ADV"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "leben.", "tokens": ["le\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "Wan dan/ O s\u00fcsse seehl/ dein leben vnd dein Tod", "tokens": ["Wan", "dan", "/", "O", "s\u00fcs\u00b7se", "seehl", "/", "dein", "le\u00b7ben", "vnd", "dein", "Tod"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "$(", "NE", "ADJA", "NN", "$(", "PPOSAT", "VVINF", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vns deines hayls gewin/ vnnd vnsern verlust", "tokens": ["Vns", "dei\u00b7nes", "hayls", "ge\u00b7win", "/", "vnnd", "vn\u00b7sern", "ver\u00b7lust"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "NE", "$(", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "weysen/", "tokens": ["wey\u00b7sen", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "So m\u00f6gen billich wir Got klagen vnser noht", "tokens": ["So", "m\u00f6\u00b7gen", "bil\u00b7lich", "wir", "Got", "kla\u00b7gen", "vn\u00b7ser", "noht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADJD", "PPER", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch also/ dz wir jhn auch f\u00fcr dein leben preysen.", "tokens": ["Doch", "al\u00b7so", "/", "dz", "wir", "jhn", "auch", "f\u00fcr", "dein", "le\u00b7ben", "prey\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "KOUS", "PPER", "PPER", "ADV", "APPR", "PPOSAT", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}