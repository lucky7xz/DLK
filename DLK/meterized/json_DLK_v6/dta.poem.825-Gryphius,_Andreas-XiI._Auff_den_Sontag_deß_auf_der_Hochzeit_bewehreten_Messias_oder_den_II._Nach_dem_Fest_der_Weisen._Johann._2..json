{"dta.poem.825": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XiI.  Auff den Sontag de\u00df auf der Hochzeit  \n bewehreten Messias/ oder den  II.  Nach dem  \n Fest der Weisen. Johann. 2.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Jsts so mein Seelentrost/ da\u00df die gew\u00fcndschte Stunde ", "tokens": ["Ists", "so", "mein", "See\u00b7lent\u00b7rost", "/", "da\u00df", "die", "ge\u00b7w\u00fcnd\u00b7schte", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADV", "PPOSAT", "NN", "$(", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der h\u00fclffe noch nicht dar? Ists m\u00f6glich da\u00df ich mu\u00df", "tokens": ["Der", "h\u00fclf\u00b7fe", "noch", "nicht", "dar", "?", "Ists", "m\u00f6g\u00b7lich", "da\u00df", "ich", "mu\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PTKNEG", "PTKVZ", "$.", "NE", "ADJD", "KOUS", "PPER", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Noch weiter trostlo\u00df seyn? vnd folgt auf meinen gru\u00df/", "tokens": ["Noch", "wei\u00b7ter", "trost\u00b7lo\u00df", "seyn", "?", "vnd", "folgt", "auf", "mei\u00b7nen", "gru\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VAINF", "$.", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nichts al\u00df ein rawes wortt? Ogrimme Seelen wunde!", "tokens": ["Nichts", "al\u00df", "ein", "ra\u00b7wes", "wortt", "?", "O\u00b7grim\u00b7me", "See\u00b7len", "wun\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "ADJA", "NN", "$.", "NN", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was hab ich Mensch mit dir! kom\u2019t di\u00df aus dein\u1ebd Munde?", "tokens": ["Was", "hab", "ich", "Mensch", "mit", "dir", "!", "kom't", "di\u00df", "aus", "dein\u1ebd", "Mun\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "NN", "APPR", "PPER", "$.", "VVFIN", "PDS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich lasse doch nicht ab/ mich kr\u00e4ncket kein verdru\u00df", "tokens": ["Ich", "las\u00b7se", "doch", "nicht", "ab", "/", "mich", "kr\u00e4n\u00b7cket", "kein", "ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PTKVZ", "$(", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich wartt\u2019 o Br\u00e4\u00fctigam auf deinen frewden ku\u00df/", "tokens": ["Ich", "wartt'", "o", "Br\u00e4\u00fc\u00b7ti\u00b7gam", "auf", "dei\u00b7nen", "frew\u00b7den", "ku\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "FM", "NE", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du kennest rechte zeit/ vnd wirst nach deinem Bunde", "tokens": ["Du", "ken\u00b7nest", "rech\u00b7te", "zeit", "/", "vnd", "wirst", "nach", "dei\u00b7nem", "Bun\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$(", "KON", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Hertzen die bi\u00dfher mit Gallen sind getr\u00e4nckt", "tokens": ["Die", "Hert\u00b7zen", "die", "bi\u00df\u00b7her", "mit", "Gal\u00b7len", "sind", "ge\u00b7tr\u00e4nckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADV", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Den du den Creutzkelch hast gantz thr\u00e4nen voll geschenckt", "tokens": ["Den", "du", "den", "Creutz\u00b7kelch", "hast", "gantz", "thr\u00e4\u00b7nen", "voll", "ge\u00b7schenckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "VAFIN", "ADV", "VVFIN", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mit reiner wollust Wein in ewigkeit ergetzen?", "tokens": ["Mit", "rei\u00b7ner", "wol\u00b7lust", "Wein", "in", "e\u00b7wig\u00b7keit", "er\u00b7get\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wen man de\u00df Teuffels Braut/ der rohen tollen Welt", "tokens": ["Wen", "man", "de\u00df", "Teuf\u00b7fels", "Braut", "/", "der", "ro\u00b7hen", "tol\u00b7len", "Welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die truncken von dem gl\u00fcck an itzt jhr Fra\u00dffest h\u00e4lt/", "tokens": ["Die", "trun\u00b7cken", "von", "dem", "gl\u00fcck", "an", "itzt", "jhr", "Fra\u00df\u00b7fest", "h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "APPR", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das \u00e4rg\u2019ste wird zu letzt mit Gall vnd Pech vorsetzen.", "tokens": ["Das", "\u00e4r\u00b7g'\u00b7ste", "wird", "zu", "letzt", "mit", "Gall", "vnd", "Pech", "vor\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "APPR", "ADV", "APPR", "NE", "KON", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}}}}