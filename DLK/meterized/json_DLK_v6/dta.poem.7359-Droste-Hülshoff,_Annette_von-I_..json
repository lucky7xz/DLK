{"dta.poem.7359": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "I .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-20090519994", "language": ["de:0.99"], "booktitle": "Droste-H\u00fclshoff, Annette von: Gedichte. Stuttgart u. a., 1844."}, "poem": {"stanza.1": {"line.1": {"text": "Das war der Graf von Thal,", "tokens": ["Das", "war", "der", "Graf", "von", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "So ritt an der Felsenwand;", "tokens": ["So", "ritt", "an", "der", "Fel\u00b7sen\u00b7wand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das war sein ehlich Gemahl,", "tokens": ["Das", "war", "sein", "eh\u00b7lich", "Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die hinter dem Steine stand.", "tokens": ["Die", "hin\u00b7ter", "dem", "Stei\u00b7ne", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie schaut' im Sonnenstral", "tokens": ["Sie", "schaut'", "im", "Son\u00b7nen\u00b7stral"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Hinunter den linden Hang,", "tokens": ["Hin\u00b7un\u00b7ter", "den", "lin\u00b7den", "Hang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u201ewo bleibt der Graf von Thal?", "tokens": ["\u201e", "wo", "bleibt", "der", "Graf", "von", "Thal", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u201eich h\u00f6rt' ihn doch reiten entlang!\u201c", "tokens": ["\u201e", "ich", "h\u00f6rt'", "ihn", "doch", "rei\u00b7ten", "ent\u00b7lang", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "\u201eob das ein Hufschlag ist?", "tokens": ["\u201e", "ob", "das", "ein", "Huf\u00b7schlag", "ist", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PDS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u201evielleicht ein Hufschlag fern?", "tokens": ["\u201e", "viel\u00b7leicht", "ein", "Huf\u00b7schlag", "fern", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eich wei\u00df doch wohl ohne List,", "tokens": ["\u201e", "ich", "wei\u00df", "doch", "wohl", "oh\u00b7ne", "List", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201eich hab' geh\u00f6rt meinen Herrn!\u201c", "tokens": ["\u201e", "ich", "hab'", "ge\u00b7h\u00f6rt", "mei\u00b7nen", "Herrn", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Sie bog zur\u00fcck den Zweig.", "tokens": ["Sie", "bog", "zu\u00b7r\u00fcck", "den", "Zweig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u201ebin blind ich oder auch taub?\u201c", "tokens": ["\u201e", "bin", "blind", "ich", "o\u00b7der", "auch", "taub", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "ADJD", "PPER", "KON", "ADV", "ADJD", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Sie blinzelt' in das Gestr\u00e4uch,", "tokens": ["Sie", "blin\u00b7zelt'", "in", "das", "Ge\u00b7str\u00e4uch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Und horcht' auf das rauschende Laub.", "tokens": ["Und", "horcht'", "auf", "das", "rau\u00b7schen\u00b7de", "Laub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Oed' war's, im Hohlweg leer,", "tokens": ["O\u00b7ed'", "wa\u00b7r's", ",", "im", "Hohl\u00b7weg", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Einsam im rispelnden Wald;", "tokens": ["Ein\u00b7sam", "im", "ris\u00b7peln\u00b7den", "Wald", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Doch \u00fcber'm Weiher, am Wehr,", "tokens": ["Doch", "\u00fc\u00b7ber'm", "Wei\u00b7her", ",", "am", "Wehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Da fand sie den Grafen bald.", "tokens": ["Da", "fand", "sie", "den", "Gra\u00b7fen", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "In seinen Schatten sie trat.", "tokens": ["In", "sei\u00b7nen", "Schat\u00b7ten", "sie", "trat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Er und seine Gesellen,", "tokens": ["Er", "und", "sei\u00b7ne", "Ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die fl\u00fcstern und halten Rath,", "tokens": ["Die", "fl\u00fcs\u00b7tern", "und", "hal\u00b7ten", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Viel lauter rieseln die Wellen.", "tokens": ["Viel", "lau\u00b7ter", "rie\u00b7seln", "die", "Wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie starrten \u00fcber das Land,", "tokens": ["Sie", "starr\u00b7ten", "\u00fc\u00b7ber", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Genau sie sp\u00e4hten, genau,", "tokens": ["Ge\u00b7nau", "sie", "sp\u00e4h\u00b7ten", ",", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sahn jedes Zweiglein am Strand,", "tokens": ["Sahn", "je\u00b7des", "Zwei\u00b7glein", "am", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Doch nicht am Wehre die Frau.", "tokens": ["Doch", "nicht", "am", "Weh\u00b7re", "die", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Zur Erde blickte der Graf,", "tokens": ["Zur", "Er\u00b7de", "blick\u00b7te", "der", "Graf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "So sprach der Graf von Thal:", "tokens": ["So", "sprach", "der", "Graf", "von", "Thal", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eseit dreizehn Jahren den Schlaf", "tokens": ["\u201e", "seit", "drei\u00b7zehn", "Jah\u00b7ren", "den", "Schlaf"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "CARD", "NN", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "\u201erachlose Schmach mir stahl.\u201c", "tokens": ["\u201e", "rach\u00b7lo\u00b7se", "Schmach", "mir", "stahl", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.9": {"line.1": {"text": "\u201ewar das ein Seufzer lind?", "tokens": ["\u201e", "war", "das", "ein", "Seuf\u00b7zer", "lind", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PDS", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u201egesellen, wer hat's geh\u00f6rt?\u201c", "tokens": ["\u201e", "ge\u00b7sel\u00b7len", ",", "wer", "hat's", "ge\u00b7h\u00f6rt", "?", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "$,", "PWS", "VAFIN", "VVPP", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sprach Kurt: \u201eEs ist nur der Wind,", "tokens": ["Sprach", "Kurt", ":", "\u201e", "Es", "ist", "nur", "der", "Wind", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "\u201eder \u00fcber das Schilfblatt f\u00e4hrt.\u201c \u2014", "tokens": ["\u201e", "der", "\u00fc\u00b7ber", "das", "Schilf\u00b7blatt", "f\u00e4hrt", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "APPR", "ART", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "\u201eso schw\u00f6r' ich bei'm h\u00f6chsten Gut,", "tokens": ["\u201e", "so", "schw\u00f6r'", "ich", "bei'm", "h\u00f6chs\u00b7ten", "Gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u201eund w\u00e4r's mein ehlich Weib,", "tokens": ["\u201e", "und", "w\u00e4r's", "mein", "eh\u00b7lich", "Weib", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201eund w\u00e4r's meines Bruders Blut,", "tokens": ["\u201e", "und", "w\u00e4r's", "mei\u00b7nes", "Bru\u00b7ders", "Blut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "\u201eviel minder mein eigner Leib:\u201c", "tokens": ["\u201e", "viel", "min\u00b7der", "mein", "eig\u00b7ner", "Leib", ":", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "\u201enichts soll mir wenden den Sinn,", "tokens": ["\u201e", "nichts", "soll", "mir", "wen\u00b7den", "den", "Sinn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "\u201eda\u00df ich die Rache ihm spar';", "tokens": ["\u201e", "da\u00df", "ich", "die", "Ra\u00b7che", "ihm", "spa\u00b7r'", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eder Freche soll werden inn',", "tokens": ["\u201e", "der", "Fre\u00b7che", "soll", "wer\u00b7den", "inn'", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VMFIN", "VAINF", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201ezins tragen auch dreizehn Jahr'.\u201c", "tokens": ["\u201e", "zins", "tra\u00b7gen", "auch", "drei\u00b7zehn", "Jahr'", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "VVFIN", "ADV", "CARD", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}