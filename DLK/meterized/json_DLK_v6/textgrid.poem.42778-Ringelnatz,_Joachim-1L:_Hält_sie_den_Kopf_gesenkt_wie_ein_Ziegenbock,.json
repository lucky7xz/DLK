{"textgrid.poem.42778": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: H\u00e4lt sie den Kopf gesenkt wie ein Ziegenbock,", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00e4lt sie den Kopf gesenkt wie ein Ziegenbock,", "tokens": ["H\u00e4lt", "sie", "den", "Kopf", "ge\u00b7senkt", "wie", "ein", "Zie\u00b7gen\u00b7bock", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ihre Gem\u00fcsenase,", "tokens": ["Ih\u00b7re", "Ge\u00b7m\u00fc\u00b7se\u00b7na\u00b7se", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ihr spitzer H\u00f6cker, ihr gest\u00fcckelter Rock", "tokens": ["Ihr", "spit\u00b7zer", "H\u00f6\u00b7cker", ",", "ihr", "ge\u00b7st\u00fc\u00b7ckel\u00b7ter", "Rock"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Haben die gleiche farblose Drecksymphonie", "tokens": ["Ha\u00b7ben", "die", "glei\u00b7che", "farb\u00b7lo\u00b7se", "Dreck\u00b7symp\u00b7ho\u00b7nie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Der Stra\u00dfe.", "tokens": ["Der", "Stra\u00b7\u00dfe", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Mimikry.", "tokens": ["Mi\u00b7mik\u00b7ry", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "---", "measure": "unknown.measure.zero"}}, "stanza.2": {"line.1": {"text": "Selbst\u00e4ndig krabbeln ihre kn\u00f6chernen H\u00e4nde", "tokens": ["Selb\u00b7st\u00e4n\u00b7dig", "krab\u00b7beln", "ih\u00b7re", "kn\u00f6\u00b7cher\u00b7nen", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Die Gosse entlang zwischen Kehricht und Schlamm,", "tokens": ["Die", "Gos\u00b7se", "ent\u00b7lang", "zwi\u00b7schen", "Keh\u00b7richt", "und", "Schlamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPO", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Finden Billette, Nadeln und Horngegenst\u00e4nde,", "tokens": ["Fin\u00b7den", "Bil\u00b7let\u00b7te", ",", "Na\u00b7deln", "und", "Horn\u00b7ge\u00b7gen\u00b7st\u00e4n\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Noch einen Knopf und auch einen Kamm.", "tokens": ["Noch", "ei\u00b7nen", "Knopf", "und", "auch", "ei\u00b7nen", "Kamm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.3": {"line.1": {"text": "\u00dcber Speichel und Rotz zittern die Finger;", "tokens": ["\u00dc\u00b7ber", "Spei\u00b7chel", "und", "Rotz", "zit\u00b7tern", "die", "Fin\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "VVFIN", "ART", "NN", "$."], "meter": "--+--++--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Hundek\u00f6tel werden wie Pferded\u00fcnger", "tokens": ["Hun\u00b7de\u00b7k\u00f6\u00b7tel", "wer\u00b7den", "wie", "Pfer\u00b7de\u00b7d\u00fcn\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAINF", "KOKOM", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Sachlich beiseite geschoben.", "tokens": ["Sach\u00b7lich", "bei\u00b7sei\u00b7te", "ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Lumpen, Kork, Papier und Metall werden aufgehoben,", "tokens": ["Lum\u00b7pen", ",", "Kork", ",", "Pa\u00b7pier", "und", "Me\u00b7tall", "wer\u00b7den", "auf\u00b7ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.5": {"text": "Stetig \u2013 stopf \u2013 in den Sack geschoben.", "tokens": ["Ste\u00b7tig", "\u2013", "stopf", "\u2013", "in", "den", "Sack", "ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "XY", "$(", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Der Sack stinkt aus seinem verbuchteten Leib.", "tokens": ["Der", "Sack", "stinkt", "aus", "sei\u00b7nem", "ver\u00b7buch\u00b7te\u00b7ten", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Er hat viel spitzere H\u00f6cker.", "tokens": ["Er", "hat", "viel", "spit\u00b7ze\u00b7re", "H\u00f6\u00b7cker", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er ist noch ziegenb\u00f6cker", "tokens": ["Er", "ist", "noch", "zie\u00b7gen\u00b7b\u00f6\u00b7cker"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als jenes arg m\u00fcrbe Weib.", "tokens": ["Als", "je\u00b7nes", "arg", "m\u00fcr\u00b7be", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Schl\u00fcrfend, schweigsam schleppt sie, schleift sie die B\u00fcrde.", "tokens": ["Schl\u00fcr\u00b7fend", ",", "schweig\u00b7sam", "schleppt", "sie", ",", "schleift", "sie", "die", "B\u00fcr\u00b7de", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Wenn sie jemals niesen w\u00fcrde,", "tokens": ["Wenn", "sie", "je\u00b7mals", "nie\u00b7sen", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was wegen Verstopfung bisher nie geschah,", "tokens": ["Was", "we\u00b7gen", "Ver\u00b7stop\u00b7fung", "bis\u00b7her", "nie", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "W\u00fcrde die gute Alte zerst\u00e4uben", "tokens": ["W\u00fcr\u00b7de", "die", "gu\u00b7te", "Al\u00b7te", "zer\u00b7st\u00e4u\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wie gepusteter Paprika. \u2013", "tokens": ["Wie", "ge\u00b7pus\u00b7te\u00b7ter", "Pa\u00b7pri\u00b7ka", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und was w\u00fcrde \u00fcbrig bleiben?", "tokens": ["Und", "was", "w\u00fcr\u00b7de", "\u00fcb\u00b7rig", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Schnalle von ihrem Rock,", "tokens": ["Ei\u00b7ne", "Schnal\u00b7le", "von", "ih\u00b7rem", "Rock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Sieben Stecknadeln, ein Berlock,", "tokens": ["Sie\u00b7ben", "Steck\u00b7na\u00b7deln", ",", "ein", "Ber\u00b7lock", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Vergoldet oder vernickelt.", "tokens": ["Ver\u00b7gol\u00b7det", "o\u00b7der", "ver\u00b7ni\u00b7ckelt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Vielleicht auch: vielmals eingewickelt", "tokens": ["Viel\u00b7leicht", "auch", ":", "viel\u00b7mals", "ein\u00b7ge\u00b7wi\u00b7ckelt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "$.", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und zwischen zwei fettigen Pappen:", "tokens": ["Und", "zwi\u00b7schen", "zwei", "fet\u00b7ti\u00b7gen", "Pap\u00b7pen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "CARD", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "F\u00fcnfzig g\u00fcltige, saubere blaue Lappen.", "tokens": ["F\u00fcnf\u00b7zig", "g\u00fcl\u00b7ti\u00b7ge", ",", "sau\u00b7be\u00b7re", "blau\u00b7e", "Lap\u00b7pen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "$,", "ADJA", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Irgendwo w\u00fcrde ein Stall erbrochen,", "tokens": ["Ir\u00b7gend\u00b7wo", "w\u00fcr\u00b7de", "ein", "Stall", "er\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "F\u00e4nde man sortiert, gestapelt, geb\u00fcndelt, umschn\u00fcrt", "tokens": ["F\u00e4n\u00b7de", "man", "sor\u00b7tiert", ",", "ge\u00b7sta\u00b7pelt", ",", "ge\u00b7b\u00fcn\u00b7delt", ",", "um\u00b7schn\u00fcrt"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "PIS", "VVFIN", "$,", "VVPP", "$,", "VVPP", "$,", "VVFIN"], "meter": "+-+-+-+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Lumpen, Stanniol, Strumpfenb\u00e4nder und Knochen.", "tokens": ["Lum\u00b7pen", ",", "Stan\u00b7ni\u00b7ol", ",", "Strump\u00b7fen\u00b7b\u00e4n\u00b7der", "und", "Kno\u00b7chen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Was hat die Hexe f\u00fcr ein Leben gef\u00fchrt?", "tokens": ["Was", "hat", "die", "He\u00b7xe", "f\u00fcr", "ein", "Le\u00b7ben", "ge\u00b7f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-----+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Vielleicht hat sie Lateinisch gesprochen.", "tokens": ["Viel\u00b7leicht", "hat", "sie", "La\u00b7tei\u00b7nisch", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Vielleicht hat einst eine Zofe sie manik\u00fcrt.", "tokens": ["Viel\u00b7leicht", "hat", "einst", "ei\u00b7ne", "Zo\u00b7fe", "sie", "ma\u00b7ni\u00b7k\u00fcrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Vielleicht ist sie vor tausend Jahren als Spulwurm", "tokens": ["Viel\u00b7leicht", "ist", "sie", "vor", "tau\u00b7send", "Jah\u00b7ren", "als", "Spul\u00b7wurm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "CARD", "NN", "KOUS", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Durch das Ged\u00e4rm eines Marsbewohners gekrochen.", "tokens": ["Durch", "das", "Ge\u00b7d\u00e4rm", "ei\u00b7nes", "Mars\u00b7be\u00b7woh\u00b7ners", "ge\u00b7kro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}}}}}