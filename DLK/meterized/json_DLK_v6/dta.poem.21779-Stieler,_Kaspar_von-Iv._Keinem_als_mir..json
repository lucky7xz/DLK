{"dta.poem.21779": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n  Keinem/ als mir.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Legere l\u00e4st sich offters gr\u00fcssen/", "tokens": ["Le\u00b7ge\u00b7re", "l\u00e4st", "sich", "off\u00b7ters", "gr\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADV", "VVINF", "$("], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Legere l\u00e4st sich offters k\u00fcssen", "tokens": ["Le\u00b7ge\u00b7re", "l\u00e4st", "sich", "off\u00b7ters", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PRF", "ADV", "VVINF"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "und/ komm ich ungefehr darzu/", "tokens": ["und", "/", "komm", "ich", "un\u00b7ge\u00b7fehr", "dar\u00b7zu", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "PPER", "ADJD", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Legere/ la\u00df die Possen bleiben/", "tokens": ["Le\u00b7ge\u00b7re", "/", "la\u00df", "die", "Pos\u00b7sen", "blei\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVIMP", "ART", "NN", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "la\u00df dir den Mund nicht so bereiben/", "tokens": ["la\u00df", "dir", "den", "Mund", "nicht", "so", "be\u00b7rei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "ich achte hier nicht Fug noch Recht.", "tokens": ["ich", "ach\u00b7te", "hier", "nicht", "Fug", "noch", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir sind verdacht/ die Mutter/ Br\u00fcder", "tokens": ["Mir", "sind", "ver\u00b7dacht", "/", "die", "Mut\u00b7ter", "/", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "ART", "NN", "$(", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die Schwester/ Freunde; ja ein ieder", "tokens": ["die", "Schwes\u00b7ter", "/", "Freun\u00b7de", ";", "ja", "ein", "ie\u00b7der"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "$.", "ADV", "ART", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und w\u00e4r\u2019 es meines Dieners Knecht.", "tokens": ["und", "w\u00e4r'", "es", "mei\u00b7nes", "Die\u00b7ners", "Knecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Vergib mir meine Furcht Legere.", "tokens": ["Ver\u00b7gib", "mir", "mei\u00b7ne", "Furcht", "Le\u00b7ge\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Jungfer Lust wehrt keine Wehre/", "tokens": ["Der", "Jung\u00b7fer", "Lust", "wehrt", "kei\u00b7ne", "Weh\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wil sie/ so hilfft kein halten nicht.", "tokens": ["wil", "sie", "/", "so", "hilfft", "kein", "hal\u00b7ten", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$(", "ADV", "VVFIN", "PIAT", "VVFIN", "PTKNEG", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Der ihr verwahrtes Schlo\u00df entgliedet/", "tokens": ["Der", "ihr", "ver\u00b7wahr\u00b7tes", "Schlo\u00df", "ent\u00b7glie\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der Schl\u00fcssel/ ist bereit geschmiedet", "tokens": ["der", "Schl\u00fcs\u00b7sel", "/", "ist", "be\u00b7reit", "ge\u00b7schmie\u00b7det"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$(", "VAFIN", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und niemand lebt/ dehm er gebricht.", "tokens": ["und", "nie\u00b7mand", "lebt", "/", "dehm", "er", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$(", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Es kan sich bald ein Schmeichler finden", "tokens": ["Es", "kan", "sich", "bald", "ein", "Schmeich\u00b7ler", "fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der dein Gem\u00fchte kan entz\u00fcnden", "tokens": ["der", "dein", "Ge\u00b7m\u00fch\u00b7te", "kan", "ent\u00b7z\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und wer\u2019 es auch so kalt als Ey\u00df.", "tokens": ["und", "wer'", "es", "auch", "so", "kalt", "als", "Ey\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich kenne zarter Weiber Sinnen", "tokens": ["Ich", "ken\u00b7ne", "zar\u00b7ter", "Wei\u00b7ber", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wie schleunig der sie kan gewinnen/", "tokens": ["wie", "schleu\u00b7nig", "der", "sie", "kan", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der nur die rechten Griffchen wei\u00df.", "tokens": ["der", "nur", "die", "rech\u00b7ten", "Griff\u00b7chen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Biel Weiber sind au\u00df Griechen r\u00fcchtig", "tokens": ["Biel", "Wei\u00b7ber", "sind", "au\u00df", "Grie\u00b7chen", "r\u00fcch\u00b7tig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "NN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "doch war nicht mehr als eine z\u00fcchtig", "tokens": ["doch", "war", "nicht", "mehr", "als", "ei\u00b7ne", "z\u00fcch\u00b7tig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "ADV", "KOKOM", "ART", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die listige Penelope.", "tokens": ["die", "lis\u00b7ti\u00b7ge", "Pe\u00b7ne\u00b7lo\u00b7pe", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Rom hat nur eine treu beschrieben/", "tokens": ["Rom", "hat", "nur", "ei\u00b7ne", "treu", "be\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ART", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die ihren Ehmann konte lieben", "tokens": ["die", "ih\u00b7ren", "Eh\u00b7mann", "kon\u00b7te", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "die blutige Lukrezie.", "tokens": ["die", "blu\u00b7ti\u00b7ge", "Luk\u00b7re\u00b7zie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Ehr wird man schwarze Schwanen schauen/", "tokens": ["Ehr", "wird", "man", "schwar\u00b7ze", "Schwa\u00b7nen", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIS", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die Raben wei\u00dflich sehen grauen/", "tokens": ["die", "Ra\u00b7ben", "wei\u00df\u00b7lich", "se\u00b7hen", "grau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "den Schnee abschiessen Kohlen gleich:", "tokens": ["den", "Schnee", "ab\u00b7schies\u00b7sen", "Koh\u00b7len", "gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "als eine Jungfer sonder Wanken.", "tokens": ["als", "ei\u00b7ne", "Jung\u00b7fer", "son\u00b7der", "Wan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jhr Tuhn/ ihr Reden und Gedanken", "tokens": ["Ihr", "Tuhn", "/", "ihr", "Re\u00b7den", "und", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wird auff das leichtste Windchen weich.", "tokens": ["wird", "auff", "das", "leichts\u00b7te", "Wind\u00b7chen", "weich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Drum/ wiltu fromm und Erbar heissen/", "tokens": ["Drum", "/", "wil\u00b7tu", "fromm", "und", "Er\u00b7bar", "heis\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "VMFIN", "ADJD", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "mustu/ Leger\u2019 auch dich befleissen", "tokens": ["mus\u00b7tu", "/", "Le\u00b7ger'", "auch", "dich", "be\u00b7fleis\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "$(", "NN", "ADV", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "zu meiden allen argen Wahn.", "tokens": ["zu", "mei\u00b7den", "al\u00b7len", "ar\u00b7gen", "Wahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verdacht w\u00e4chst leichtlich au\u00df den Tahten", "tokens": ["Ver\u00b7dacht", "w\u00e4chst", "leicht\u00b7lich", "au\u00df", "den", "Tah\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kind willstu meinem Eyffer rahten", "tokens": ["Kind", "will\u00b7stu", "mei\u00b7nem", "Eyf\u00b7fer", "rah\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}