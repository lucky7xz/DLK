{"textgrid.poem.55027": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Mit einem goldnen Halskettchen", "genre": "verse", "period": "N.A.", "pub_year": 1770, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dir darf dies Blatt ein Kettchen bringen,", "tokens": ["Dir", "darf", "dies", "Blatt", "ein", "Kett\u00b7chen", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PDS", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das, ganz zur Biegsamkeit gew\u00f6hnt,", "tokens": ["Das", ",", "ganz", "zur", "Biegs\u00b7am\u00b7keit", "ge\u00b7w\u00f6hnt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich mit viel hundert kleinen Schlingen", "tokens": ["Sich", "mit", "viel", "hun\u00b7dert", "klei\u00b7nen", "Schlin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "PIAT", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Um deinen Hals zu schmiegen sehnt.", "tokens": ["Um", "dei\u00b7nen", "Hals", "zu", "schmie\u00b7gen", "sehnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gew\u00e4hr dem N\u00e4rrchen die Begierde,", "tokens": ["Ge\u00b7w\u00e4hr", "dem", "N\u00e4rr\u00b7chen", "die", "Be\u00b7gier\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ist voll Unschuld, ist nicht k\u00fchn;", "tokens": ["Sie", "ist", "voll", "Un\u00b7schuld", ",", "ist", "nicht", "k\u00fchn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "$,", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Am Tag ist's eine kleine Zierde,", "tokens": ["Am", "Tag", "ist's", "ei\u00b7ne", "klei\u00b7ne", "Zier\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Am Abend wirfst du's wieder hin.", "tokens": ["Am", "A\u00b7bend", "wirfst", "du's", "wie\u00b7der", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch bringt dir einer jene Kette,", "tokens": ["Doch", "bringt", "dir", "ei\u00b7ner", "je\u00b7ne", "Ket\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die schwerer dr\u00fcckt und ernster fa\u00dft,", "tokens": ["Die", "schwe\u00b7rer", "dr\u00fcckt", "und", "erns\u00b7ter", "fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verdenk ich dir es nicht, Lisette,", "tokens": ["Ver\u00b7denk", "ich", "dir", "es", "nicht", ",", "Li\u00b7set\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PPER", "PTKNEG", "$,", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn du ein klein Bedenken hast.", "tokens": ["Wenn", "du", "ein", "klein", "Be\u00b7den\u00b7ken", "hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}