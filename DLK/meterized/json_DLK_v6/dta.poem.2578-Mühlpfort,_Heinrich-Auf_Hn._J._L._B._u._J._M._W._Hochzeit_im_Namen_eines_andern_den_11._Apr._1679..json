{"dta.poem.2578": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Auf Hn. J. L. B. u. J. M. W. Hochzeit im  \n Namen eines andern den 11. Apr. 1679.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Theures Blut/ der Edlen Schwaben/", "tokens": ["Theu\u00b7res", "Blut", "/", "der", "Ed\u00b7len", "Schwa\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die durch ihre Tapfferkeit/", "tokens": ["Die", "durch", "ih\u00b7re", "Tapf\u00b7fer\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tugend/ Wei\u00dfheit/ Witz und Gaben/", "tokens": ["Tu\u00b7gend", "/", "Wei\u00df\u00b7heit", "/", "Witz", "und", "Ga\u00b7ben", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00f6wen-Muth in Kampff und Streit/", "tokens": ["L\u00f6\u00b7wen\u00b7Muth", "in", "Kampff", "und", "Streit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sich vor andern hoch geschwungen/", "tokens": ["Sich", "vor", "an\u00b7dern", "hoch", "ge\u00b7schwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIS", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df bi\u00df an den Sternen-Krei\u00df", "tokens": ["Da\u00df", "bi\u00df", "an", "den", "Ster\u00b7nen\u00b7Krei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Jhres Namens Ruhm erklungen.", "tokens": ["Ih\u00b7res", "Na\u00b7mens", "Ruhm", "er\u00b7klun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und gegr\u00fcnt ihr Ehren Prei\u00df.", "tokens": ["Und", "ge\u00b7gr\u00fcnt", "ihr", "Eh\u00b7ren", "Prei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Die nicht Rom/ der Zwang der Erden", "tokens": ["Die", "nicht", "Rom", "/", "der", "Zwang", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "NE", "$(", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Zaum der gantzen Welt/", "tokens": ["Und", "der", "Zaum", "der", "gant\u00b7zen", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jemals sehen dienstbahr werden/", "tokens": ["Je\u00b7mals", "se\u00b7hen", "dienst\u00b7bahr", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDS", "VAFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die entgegen sich gestelt", "tokens": ["Die", "ent\u00b7ge\u00b7gen", "sich", "ge\u00b7stelt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PRF", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und bi\u00df an die Apenninen", "tokens": ["Und", "bi\u00df", "an", "die", "A\u00b7pen\u00b7ni\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Jhren Feind zur\u00fcck gejagt/", "tokens": ["Ih\u00b7ren", "Feind", "zu\u00b7r\u00fcck", "ge\u00b7jagt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df wie trotzig er erschienen", "tokens": ["Da\u00df", "wie", "trot\u00b7zig", "er", "er\u00b7schie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ADJD", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Endlich worden doch verzagt.", "tokens": ["End\u00b7lich", "wor\u00b7den", "doch", "ver\u00b7zagt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAPP", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Theures Blut/ der Edlen Schwaben", "tokens": ["Theu\u00b7res", "Blut", "/", "der", "Ed\u00b7len", "Schwa\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$(", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die nicht nach der Mode-Welt/", "tokens": ["Die", "nicht", "nach", "der", "Mo\u00b7de\u00b7Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jhre Tracht ver\u00e4ndert haben", "tokens": ["Ih\u00b7re", "Tracht", "ver\u00b7\u00e4n\u00b7dert", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sich frembden gleich gestelt.", "tokens": ["Und", "sich", "fremb\u00b7den", "gleich", "ge\u00b7stelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die ihr deutsches Hertz und Sitten/", "tokens": ["Die", "ihr", "deut\u00b7sches", "Hertz", "und", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sambt der alten Redligkeit", "tokens": ["Sambt", "der", "al\u00b7ten", "Red\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Noch in iedem Tritt und Schritten", "tokens": ["Noch", "in", "ie\u00b7dem", "Tritt", "und", "Schrit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Weisen bey so langer Zeit.", "tokens": ["Wei\u00b7sen", "bey", "so", "lan\u00b7ger", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Werther Landsmann bi\u00df erfreuet", "tokens": ["Wert\u00b7her", "Lands\u00b7mann", "bi\u00df", "er\u00b7freu\u00b7et"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nun dir so das Gl\u00fccke lacht/", "tokens": ["Nun", "dir", "so", "das", "Gl\u00fc\u00b7cke", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nun der Himmel es verleihet", "tokens": ["Nun", "der", "Him\u00b7mel", "es", "ver\u00b7lei\u00b7het"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df dir von der Myrten Pracht", "tokens": ["Da\u00df", "dir", "von", "der", "Myr\u00b7ten", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Venus eine Krone windet/", "tokens": ["Ve\u00b7nus", "ei\u00b7ne", "Kro\u00b7ne", "win\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und mit einem solchen Bild", "tokens": ["Und", "mit", "ei\u00b7nem", "sol\u00b7chen", "Bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Voller Tugend dich verbindet/", "tokens": ["Vol\u00b7ler", "Tu\u00b7gend", "dich", "ver\u00b7bin\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df dein wunschen ist erf\u00fcllt.", "tokens": ["Da\u00df", "dein", "wun\u00b7schen", "ist", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Frost und Winter ist vergangen?", "tokens": ["Frost", "und", "Win\u00b7ter", "ist", "ver\u00b7gan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen Blumen-reichen M\u00e4y", "tokens": ["Ei\u00b7nen", "Blu\u00b7men\u00b7rei\u00b7chen", "M\u00e4y"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeiget dir auff Mund und Wangen/", "tokens": ["Zei\u00b7get", "dir", "auff", "Mund", "und", "Wan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deiner Liebsten Conterfei.", "tokens": ["Dei\u00b7ner", "Liebs\u00b7ten", "Con\u00b7ter\u00b7fei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du darffst dich nicht nach Violen", "tokens": ["Du", "darffst", "dich", "nicht", "nach", "Vi\u00b7o\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und den Hyacinth umbschaun/", "tokens": ["Und", "den", "Hya\u00b7cin\u00b7th", "umbsc\u00b7haun", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Weil denselben unverholen/", "tokens": ["Weil", "den\u00b7sel\u00b7ben", "un\u00b7ver\u00b7ho\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Deiner Nympfe Augen Baun.", "tokens": ["Dei\u00b7ner", "Nymp\u00b7fe", "Au\u00b7gen", "Baun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Sih\u2019 wie alles im Gew\u00e4sser", "tokens": ["Sih'", "wie", "al\u00b7les", "im", "Ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "PIS", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich von neuem wieder regt/", "tokens": ["Sich", "von", "neu\u00b7em", "wie\u00b7der", "regt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ADJA", "ADV", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch der Mensch macht es nicht besser", "tokens": ["Auch", "der", "Mensch", "macht", "es", "nicht", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "ADJD"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Dem das Blut in Adern schl\u00e4gt.", "tokens": ["Dem", "das", "Blut", "in", "A\u00b7dern", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie sich ietzt die Tauben paaren/", "tokens": ["Wie", "sich", "ietzt", "die", "Tau\u00b7ben", "paa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie der Hahn betritt das Huhn/", "tokens": ["Wie", "der", "Hahn", "be\u00b7tritt", "das", "Huhn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "So mustu bey gr\u00fcnen Jahren", "tokens": ["So", "mus\u00b7tu", "bey", "gr\u00fc\u00b7nen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Gleich es Huhn und Tauben thun.", "tokens": ["Gleich", "es", "Huhn", "und", "Tau\u00b7ben", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wirstu aber auch wohl geben", "tokens": ["Wirs\u00b7tu", "a\u00b7ber", "auch", "wohl", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinem Reim ein g\u00fcttig Ohr?", "tokens": ["Mei\u00b7nem", "Reim", "ein", "g\u00fct\u00b7tig", "Ohr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein ich h\u00f6re du wilst weben/", "tokens": ["Nein", "ich", "h\u00f6\u00b7re", "du", "wilst", "we\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "PPER", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und hast andre Arbeit vor.", "tokens": ["Und", "hast", "and\u00b7re", "Ar\u00b7beit", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ulm kan nicht so kleine spinnen", "tokens": ["Ulm", "kan", "nicht", "so", "klei\u00b7ne", "spin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PTKNEG", "ADV", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Dein geliebtes Vaterland/", "tokens": ["Dein", "ge\u00b7lieb\u00b7tes", "Va\u00b7ter\u00b7land", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Als was du ietzt wirst beginnen", "tokens": ["Als", "was", "du", "ietzt", "wirst", "be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PWS", "PPER", "ADV", "VAFIN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und bald nehmen vor die Hand.", "tokens": ["Und", "bald", "neh\u00b7men", "vor", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Indem ich wil weiter tichten/", "tokens": ["In\u00b7dem", "ich", "wil", "wei\u00b7ter", "tich\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "ADV", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tritt Cupido bey mir ein/", "tokens": ["Tritt", "Cu\u00b7pi\u00b7do", "bey", "mir", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "PPER", "ART", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Spricht; last doch dein Thun und richten", "tokens": ["Spricht", ";", "last", "doch", "dein", "Thun", "und", "rich\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Jetzt gantz abgestellet seyn.", "tokens": ["Jetzt", "gantz", "ab\u00b7ge\u00b7stel\u00b7let", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieser Br\u00e4utgam wird heut backen/", "tokens": ["Die\u00b7ser", "Br\u00e4ut\u00b7gam", "wird", "heut", "ba\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und weil ich ihm helffen mu\u00df", "tokens": ["Und", "weil", "ich", "ihm", "helf\u00b7fen", "mu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVINF", "VMFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Sauber alles Mehl aussacken/", "tokens": ["Sau\u00b7ber", "al\u00b7les", "Mehl", "aus\u00b7sa\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "So n\u00fctzt nicht der Reime Schlu\u00df.", "tokens": ["So", "n\u00fctzt", "nicht", "der", "Rei\u00b7me", "Schlu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Er wird in den Ofen schieben/", "tokens": ["Er", "wird", "in", "den", "O\u00b7fen", "schie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Manche Sorten mancher Art.", "tokens": ["Man\u00b7che", "Sor\u00b7ten", "man\u00b7cher", "Art", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Leckerle die sehr belieben/", "tokens": ["Le\u00b7cker\u00b7le", "die", "sehr", "be\u00b7lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kuchen von sehr guter Schwart.", "tokens": ["Ku\u00b7chen", "von", "sehr", "gu\u00b7ter", "Schwart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kugel-Dorten/ Schlangen-Schw\u00e4ntze/", "tokens": ["Ku\u00b7gel\u00b7Dor\u00b7ten", "/", "Schlan\u00b7gen\u00b7Schw\u00e4nt\u00b7ze", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "L\u00e4mmer/ M\u00e4u\u00dfle die gantz rauch/", "tokens": ["L\u00e4m\u00b7mer", "/", "M\u00e4u\u00df\u00b7le", "die", "gantz", "rauch", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "ART", "ADV", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Eyer-Baben/ Butter-Kr\u00e4ntze", "tokens": ["E\u00b7yer\u00b7Baben", "/", "But\u00b7ter\u00b7Kr\u00e4nt\u00b7ze"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$(", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und Spritz-Kuchen wie ein Schlauch.", "tokens": ["Und", "Spritz\u00b7Ku\u00b7chen", "wie", "ein", "Schlauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KOKOM", "ART", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.10": {"line.1": {"text": "Ich wil so den Ofen hitzen", "tokens": ["Ich", "wil", "so", "den", "O\u00b7fen", "hit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df bey recht bestelter Gluth/", "tokens": ["Da\u00df", "bey", "recht", "be\u00b7stel\u00b7ter", "Gluth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Jhm der Teig nicht bleibe sitzen", "tokens": ["Jhm", "der", "Teig", "nicht", "blei\u00b7be", "sit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "PTKNEG", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern sich wie Schw\u00e4m auffthut.", "tokens": ["Son\u00b7dern", "sich", "wie", "Schw\u00e4m", "aufft\u00b7hut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "KOKOM", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df sich Schlesier und Schwaben", "tokens": ["Da\u00df", "sich", "Schle\u00b7sier", "und", "Schwa\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "NN", "KON", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Uber dem Geb\u00e4ck erfreun;", "tokens": ["U\u00b7ber", "dem", "Ge\u00b7b\u00e4ck", "er\u00b7freun", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und da\u00df sie dergleichen haben", "tokens": ["Und", "da\u00df", "sie", "derg\u00b7lei\u00b7chen", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PIS", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Nie gesehn mit Wahrheit schreyn.", "tokens": ["Nie", "ge\u00b7sehn", "mit", "Wahr\u00b7heit", "schreyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Was soll ich bey solchen Sachen/", "tokens": ["Was", "soll", "ich", "bey", "sol\u00b7chen", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "PIAT", "NN", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Werther Landsmann stimmen an/", "tokens": ["Wert\u00b7her", "Lands\u00b7mann", "stim\u00b7men", "an", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wem die G\u00f6tter Hochzeit machen", "tokens": ["Wem", "die", "G\u00f6t\u00b7ter", "Hoch\u00b7zeit", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Umb den ist es wohl gethan.", "tokens": ["Umb", "den", "ist", "es", "wohl", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wem die Parcen seinen Faden", "tokens": ["Wem", "die", "Par\u00b7cen", "sei\u00b7nen", "Fa\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Weben nur von lauter Gold/", "tokens": ["We\u00b7ben", "nur", "von", "lau\u00b7ter", "Gold", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PIAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Diesem kan kein Ungl\u00fcck schaden", "tokens": ["Die\u00b7sem", "kan", "kein", "Un\u00b7gl\u00fcck", "scha\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PIAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und der Himmel ist ihm hold.", "tokens": ["Und", "der", "Him\u00b7mel", "ist", "ihm", "hold", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.12": {"line.1": {"text": "Nun er backe/ nun er webe/", "tokens": ["Nun", "er", "ba\u00b7cke", "/", "nun", "er", "we\u00b7be", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "$(", "ADV", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schw\u00e4bsche Kuchen/ Schlesisch Gut/", "tokens": ["Schw\u00e4b\u00b7sche", "Ku\u00b7chen", "/", "Schle\u00b7sisch", "Gut", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "NN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df die Welt ihm Zeugn\u00fc\u00df gebe", "tokens": ["Da\u00df", "die", "Welt", "ihm", "Zeug\u00b7n\u00fc\u00df", "ge\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie der Schwaben Edles Blut", "tokens": ["Wie", "der", "Schwa\u00b7ben", "Ed\u00b7les", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "In Nachkommen wachs\u2019/ und bl\u00fche", "tokens": ["In", "Nach\u00b7kom\u00b7men", "wachs'", "/", "und", "bl\u00fc\u00b7he"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "PTKVZ", "$(", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hurtig/ frisch/ und munter sey/", "tokens": ["Hur\u00b7tig", "/", "frisch", "/", "und", "mun\u00b7ter", "sey", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADJD", "$(", "KON", "ADJD", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und der Ehstand nach sich ziehe", "tokens": ["Und", "der", "Eh\u00b7stand", "nach", "sich", "zie\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PRF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Nichts/ als einen Seegen-M\u00e4y.", "tokens": ["Nichts", "/", "als", "ei\u00b7nen", "See\u00b7gen\u00b7M\u00e4y", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$(", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}