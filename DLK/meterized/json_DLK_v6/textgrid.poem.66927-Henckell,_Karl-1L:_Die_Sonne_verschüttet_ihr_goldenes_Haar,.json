{"textgrid.poem.66927": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Sonne versch\u00fcttet ihr goldenes Haar,", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Sonne versch\u00fcttet ihr goldenes Haar,", "tokens": ["Die", "Son\u00b7ne", "ver\u00b7sch\u00fct\u00b7tet", "ihr", "gol\u00b7de\u00b7nes", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Auge des Himmels leuchtet so klar.", "tokens": ["Das", "Au\u00b7ge", "des", "Him\u00b7mels", "leuch\u00b7tet", "so", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Nur hier auf der Erde noch raucht es von Blut,", "tokens": ["Nur", "hier", "auf", "der", "Er\u00b7de", "noch", "raucht", "es", "von", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "ADV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Da rollen die Schwaden von Gift und von Wut.", "tokens": ["Da", "rol\u00b7len", "die", "Schwa\u00b7den", "von", "Gift", "und", "von", "Wut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Da brodeln die D\u00e4mpfe von Ha\u00df und von Gier,", "tokens": ["Da", "bro\u00b7deln", "die", "D\u00e4mp\u00b7fe", "von", "Ha\u00df", "und", "von", "Gier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Als w\u00e4re der Mensch das verworfenste Tier.", "tokens": ["Als", "w\u00e4\u00b7re", "der", "Mensch", "das", "ver\u00b7wor\u00b7fens\u00b7te", "Tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Die Tiere sind schuldlos nach ewigem Wort,", "tokens": ["Die", "Tie\u00b7re", "sind", "schuld\u00b7los", "nach", "e\u00b7wi\u00b7gem", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Die Menschen, sie ", "tokens": ["Die", "Men\u00b7schen", ",", "sie"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "PPER"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "O ruchloser Weltkrieg! Du Wirbel und Meer", "tokens": ["O", "ruch\u00b7lo\u00b7ser", "Welt\u00b7krieg", "!", "Du", "Wir\u00b7bel", "und", "Meer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "PPER", "NN", "KON", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Von wilder Verzweiflung, dein Zorn traf uns schwer.", "tokens": ["Von", "wil\u00b7der", "Ver\u00b7zwei\u00b7flung", ",", "dein", "Zorn", "traf", "uns", "schwer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.6": {"line.1": {"text": "Wir triefen von Not, sind in Elend ers\u00e4uft,", "tokens": ["Wir", "trie\u00b7fen", "von", "Not", ",", "sind", "in", "E\u00b7lend", "er\u00b7s\u00e4uft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "VAFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Ma\u00df unsrer S\u00fcnden ist voll und geh\u00e4uft.", "tokens": ["Das", "Ma\u00df", "uns\u00b7rer", "S\u00fcn\u00b7den", "ist", "voll", "und", "ge\u00b7h\u00e4uft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Wes Volk und wes Art, wes Sprache, wes Land \u2013", "tokens": ["Wes", "Volk", "und", "wes", "Art", ",", "wes", "Spra\u00b7che", ",", "wes", "Land", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$,", "ADJA", "NN", "$,", "ADJA", "NN", "$("], "meter": "-+-++-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Gehorcht dem Gewissen und l\u00f6schet den Brand!", "tokens": ["Ge\u00b7horcht", "dem", "Ge\u00b7wis\u00b7sen", "und", "l\u00f6\u00b7schet", "den", "Brand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.8": {"line.1": {"text": "Vom Auge die Binde, herab vom Gesicht", "tokens": ["Vom", "Au\u00b7ge", "die", "Bin\u00b7de", ",", "her\u00b7ab", "vom", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Die Maske der L\u00fcge, die Wahrheit ans Licht!", "tokens": ["Die", "Mas\u00b7ke", "der", "L\u00fc\u00b7ge", ",", "die", "Wahr\u00b7heit", "ans", "Licht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.9": {"line.1": {"text": "Mitschuldig wir alle! Wer w\u00e4hnte sich rein!", "tokens": ["Mit\u00b7schul\u00b7dig", "wir", "al\u00b7le", "!", "Wer", "w\u00e4hn\u00b7te", "sich", "rein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PIS", "$.", "PWS", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Wir m\u00fcssen erwachen und \u00bbWeh der Welt!\u00ab schrein.", "tokens": ["Wir", "m\u00fcs\u00b7sen", "er\u00b7wa\u00b7chen", "und", "\u00bb", "Weh", "der", "Welt", "!", "\u00ab", "schrein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "KON", "$(", "NN", "ART", "NN", "$.", "$(", "PTKVZ", "$."], "meter": "-+--+--+-++", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Weh, wehe dem Krieg! Was ihn m\u00e4stet und n\u00e4hrt!", "tokens": ["Weh", ",", "we\u00b7he", "dem", "Krieg", "!", "Was", "ihn", "m\u00e4s\u00b7tet", "und", "n\u00e4hrt", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$.", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Schon hat er zum dritten sich grausig gej\u00e4hrt.", "tokens": ["Schon", "hat", "er", "zum", "drit\u00b7ten", "sich", "grau\u00b7sig", "ge\u00b7j\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "ADJA", "PRF", "ADJD", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.11": {"line.1": {"text": "Schon hat er gej\u00e4hrt sich zum drittenmal", "tokens": ["Schon", "hat", "er", "ge\u00b7j\u00e4hrt", "sich", "zum", "drit\u00b7ten\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "PRF", "APPRART", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mit Marter und Schande, mit Frevel und Qual.", "tokens": ["Mit", "Mar\u00b7ter", "und", "Schan\u00b7de", ",", "mit", "Fre\u00b7vel", "und", "Qual", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.12": {"line.1": {"text": "Was edel und weise, wird roh und verdummt,", "tokens": ["Was", "e\u00b7del", "und", "wei\u00b7se", ",", "wird", "roh", "und", "ver\u00b7dummt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "VVFIN", "$,", "VAFIN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Gl\u00fcck geht zugrunde, die Gr\u00f6\u00dfe verstummt.", "tokens": ["Das", "Gl\u00fcck", "geht", "zu\u00b7grun\u00b7de", ",", "die", "Gr\u00f6\u00b7\u00dfe", "ver\u00b7stummt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.13": {"line.1": {"text": "Es hungern und d\u00fcrsten die V\u00f6lker nach Brot", "tokens": ["Es", "hun\u00b7gern", "und", "d\u00fcrs\u00b7ten", "die", "V\u00f6l\u00b7ker", "nach", "Brot"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VMFIN", "ART", "NN", "APPR", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und Wein der Erl\u00f6sung vom geistigen Tod.", "tokens": ["Und", "Wein", "der", "Er\u00b7l\u00f6\u00b7sung", "vom", "geis\u00b7ti\u00b7gen", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.14": {"line.1": {"text": "Die Seele der Menschheit, sie zuckt und sie st\u00f6hnt,", "tokens": ["Die", "See\u00b7le", "der", "Menschheit", ",", "sie", "zuckt", "und", "sie", "st\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "KON", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und sie zittert nach Frieden, der heilt und vers\u00f6hnt.", "tokens": ["Und", "sie", "zit\u00b7tert", "nach", "Frie\u00b7den", ",", "der", "heilt", "und", "ver\u00b7s\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,", "PRELS", "VVFIN", "KON", "VVPP", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.15": {"line.1": {"text": "Rings strecken sich H\u00e4nde. Zur Sonne dringt klar:", "tokens": ["Rings", "stre\u00b7cken", "sich", "H\u00e4n\u00b7de", ".", "Zur", "Son\u00b7ne", "dringt", "klar", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "NN", "$.", "APPRART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Nun werde der Teig der Gerechtigkeit gar!", "tokens": ["Nun", "wer\u00b7de", "der", "Teig", "der", "Ge\u00b7rech\u00b7tig\u00b7keit", "gar", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ADV", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}}}}