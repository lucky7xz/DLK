{"textgrid.poem.34995": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Menge tut es", "genre": "verse", "period": "N.A.", "pub_year": 1852, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nie l\u00f6scht, als w\u00e4r sie gegossen in Bronze,", "tokens": ["Nie", "l\u00f6scht", ",", "als", "w\u00e4r", "sie", "ge\u00b7gos\u00b7sen", "in", "Bron\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOKOM", "VAFIN", "PPER", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mir im Ged\u00e4chtnis jene Annonce,", "tokens": ["Mir", "im", "Ge\u00b7d\u00e4cht\u00b7nis", "je\u00b7ne", "An\u00b7non\u00b7ce", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die einst ich las im Intelligenzblatt", "tokens": ["Die", "einst", "ich", "las", "im", "In\u00b7tel\u00b7li\u00b7genz\u00b7blatt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der intelligenten Borussenhauptstadt.", "tokens": ["Der", "in\u00b7tel\u00b7li\u00b7gen\u00b7ten", "Bo\u00b7rus\u00b7sen\u00b7haupt\u00b7stadt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+--+---", "measure": "amphibrach.tri.plus"}}, "stanza.2": {"line.1": {"text": "Borussenhauptstadt, mein liebes Berlin,", "tokens": ["Bo\u00b7rus\u00b7sen\u00b7haupt\u00b7stadt", ",", "mein", "lie\u00b7bes", "Ber\u00b7lin", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NE", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Dein Ruhm wird bl\u00fchen ewig ", "tokens": ["Dein", "Ruhm", "wird", "bl\u00fc\u00b7hen", "e\u00b7wig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVFIN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als wie die ", "tokens": ["Als", "wie", "die"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Leiden sie immer noch an Winden?", "tokens": ["Lei\u00b7den", "sie", "im\u00b7mer", "noch", "an", "Win\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wie geht's dem Tiergarten? Gibt's dort noch ein Tier,", "tokens": ["Wie", "geht's", "dem", "Tier\u00b7gar\u00b7ten", "?", "Gibt's", "dort", "noch", "ein", "Tier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$.", "NE", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Das ruhig trinkt sein blondes Bier,", "tokens": ["Das", "ru\u00b7hig", "trinkt", "sein", "blon\u00b7des", "Bier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit der blonden Gattin, in den H\u00fctten,", "tokens": ["Mit", "der", "blon\u00b7den", "Gat\u00b7tin", ",", "in", "den", "H\u00fct\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Wo kalte Schale und fromme Sitten?", "tokens": ["Wo", "kal\u00b7te", "Scha\u00b7le", "und", "from\u00b7me", "Sit\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Borussenhauptstadt, Berlin, was machst du?", "tokens": ["Bo\u00b7rus\u00b7sen\u00b7haupt\u00b7stadt", ",", "Ber\u00b7lin", ",", "was", "machst", "du", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ob welchem Eckensteher lachst du?", "tokens": ["Ob", "wel\u00b7chem", "E\u00b7cken\u00b7ste\u00b7her", "lachst", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu meiner Zeit gab's noch keinen Nante:", "tokens": ["Zu", "mei\u00b7ner", "Zeit", "gab's", "noch", "kei\u00b7nen", "Nan\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es haben damals nur gewitzelt", "tokens": ["Es", "ha\u00b7ben", "da\u00b7mals", "nur", "ge\u00b7wit\u00b7zelt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Herr Wisotzki und der bekannte", "tokens": ["Der", "Herr", "Wi\u00b7sotz\u00b7ki", "und", "der", "be\u00b7kann\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "KON", "ART", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Kronprinz, der jetzt auf dem Throne sitzelt.", "tokens": ["Kron\u00b7prinz", ",", "der", "jetzt", "auf", "dem", "Thro\u00b7ne", "sit\u00b7zelt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--++-+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Es ist ihm seitdem der Spa\u00df vergangen,", "tokens": ["Es", "ist", "ihm", "seit\u00b7dem", "der", "Spa\u00df", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PAV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und den Kopf mit der Krone l\u00e4\u00dft er hangen.", "tokens": ["Und", "den", "Kopf", "mit", "der", "Kro\u00b7ne", "l\u00e4\u00dft", "er", "han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Ich habe ein Faible f\u00fcr diesen K\u00f6nig;", "tokens": ["Ich", "ha\u00b7be", "ein", "Faib\u00b7le", "f\u00fcr", "die\u00b7sen", "K\u00f6\u00b7nig", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Ich glaube, wir sind uns \u00e4hnlich ein wenig.", "tokens": ["Ich", "glau\u00b7be", ",", "wir", "sind", "uns", "\u00e4hn\u00b7lich", "ein", "we\u00b7nig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "ADJD", "ART", "PIS", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ein vornehmer Geist, hat viel Talent \u2013", "tokens": ["Ein", "vor\u00b7neh\u00b7mer", "Geist", ",", "hat", "viel", "Ta\u00b7lent", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "PIAT", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Auch ich, ich w\u00e4re ein schlechter Regent.", "tokens": ["Auch", "ich", ",", "ich", "w\u00e4\u00b7re", "ein", "schlech\u00b7ter", "Re\u00b7gent", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Wie mir, ist auch zuwider ihm", "tokens": ["Wie", "mir", ",", "ist", "auch", "zu\u00b7wi\u00b7der", "ihm"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "$,", "VAFIN", "ADV", "ADJD", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die Musik, das edle Unget\u00fcm;", "tokens": ["Die", "Mu\u00b7sik", ",", "das", "ed\u00b7le", "Un\u00b7ge\u00b7t\u00fcm", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.15": {"text": "Aus diesem Grund protegiert auch er", "tokens": ["Aus", "die\u00b7sem", "Grund", "pro\u00b7te\u00b7giert", "auch", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ADV", "PPER"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Den Musikverderber, den Meyerbeer.", "tokens": ["Den", "Mu\u00b7sik\u00b7ver\u00b7der\u00b7ber", ",", "den", "Me\u00b7yer\u00b7beer", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Der K\u00f6nig bekam von ihm kein Geld,", "tokens": ["Der", "K\u00f6\u00b7nig", "be\u00b7kam", "von", "ihm", "kein", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Wie f\u00e4lschlich behauptet die b\u00f6se Welt.", "tokens": ["Wie", "f\u00e4lschlich", "be\u00b7haup\u00b7tet", "die", "b\u00f6\u00b7se", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Man l\u00fcgt soviel! Auch keinen Dreier", "tokens": ["Man", "l\u00fcgt", "so\u00b7viel", "!", "Auch", "kei\u00b7nen", "Drei\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PIS", "$.", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Kostet der K\u00f6nig dem Beerenmeyer.", "tokens": ["Kos\u00b7tet", "der", "K\u00f6\u00b7nig", "dem", "Bee\u00b7ren\u00b7me\u00b7yer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.21": {"text": "Derselbe dirigiert f\u00fcr ihn", "tokens": ["Der\u00b7sel\u00b7be", "di\u00b7ri\u00b7giert", "f\u00fcr", "ihn"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJD", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Die gro\u00dfe Oper zu Berlin,", "tokens": ["Die", "gro\u00b7\u00dfe", "O\u00b7per", "zu", "Ber\u00b7lin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Und doch auch er, der edle Mensch,", "tokens": ["Und", "doch", "auch", "er", ",", "der", "ed\u00b7le", "Mensch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Wird nur bezahlt en monnaie de singe,", "tokens": ["Wird", "nur", "be\u00b7zahlt", "en", "mon\u00b7nai\u00b7e", "de", "sin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Mit Titel und W\u00fcrden \u2013 Das ist gewi\u00df,", "tokens": ["Mit", "Ti\u00b7tel", "und", "W\u00fcr\u00b7den", "\u2013", "Das", "ist", "ge\u00b7wi\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "PDS", "VAFIN", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.26": {"text": "Er arbeitet dort f\u00fcr den Roi de Prusse.", "tokens": ["Er", "ar\u00b7bei\u00b7tet", "dort", "f\u00fcr", "den", "Roi", "de", "Prus\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NE", "NE", "NE", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Denk ich an Berlin, auch vor mir steht", "tokens": ["Denk", "ich", "an", "Ber\u00b7lin", ",", "auch", "vor", "mir", "steht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "NE", "$,", "ADV", "APPR", "PPER", "VVFIN"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Sogleich die Universit\u00e4t.", "tokens": ["Sog\u00b7leich", "die", "U\u00b7niv\u00b7er\u00b7si\u00b7t\u00e4t", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Dort reiten vor\u00fcber die roten Husaren,", "tokens": ["Dort", "rei\u00b7ten", "vor\u00b7\u00fc\u00b7ber", "die", "ro\u00b7ten", "Hu\u00b7sa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Mit klingendem Spiel, Trompetenfanfaren \u2013", "tokens": ["Mit", "klin\u00b7gen\u00b7dem", "Spiel", ",", "Trom\u00b7pe\u00b7ten\u00b7fan\u00b7fa\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es dringen die soldatesken T\u00f6ne", "tokens": ["Es", "drin\u00b7gen", "die", "sol\u00b7da\u00b7tes\u00b7ken", "T\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Bis in die Aula der Musens\u00f6hne.", "tokens": ["Bis", "in", "die", "Au\u00b7la", "der", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Wie geht es dort den Professoren", "tokens": ["Wie", "geht", "es", "dort", "den", "Pro\u00b7fes\u00b7so\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit mehr oder minder langen Ohren?", "tokens": ["Mit", "mehr", "o\u00b7der", "min\u00b7der", "lan\u00b7gen", "Oh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KON", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Wie geht es dem elegant geleckten,", "tokens": ["Wie", "geht", "es", "dem", "e\u00b7le\u00b7gant", "ge\u00b7leck\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "ADJD", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "S\u00fc\u00dflichen Troubadour der Pandekten,", "tokens": ["S\u00fc\u00df\u00b7li\u00b7chen", "Trou\u00b7ba\u00b7dour", "der", "Pan\u00b7dek\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Dem Savigny? Die holde Person,", "tokens": ["Dem", "Sa\u00b7vig\u00b7ny", "?", "Die", "hol\u00b7de", "Per\u00b7son", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Vielleicht ist sie l\u00e4ngst gestorben schon \u2013", "tokens": ["Viel\u00b7leicht", "ist", "sie", "l\u00e4ngst", "ge\u00b7stor\u00b7ben", "schon", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "ADV", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Ich wei\u00df es nicht \u2013 ihr d\u00fcrft's mir entdecken,", "tokens": ["Ich", "wei\u00df", "es", "nicht", "\u2013", "ihr", "d\u00fcrft's", "mir", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Ich werde nicht zu sehr erschrecken.", "tokens": ["Ich", "wer\u00b7de", "nicht", "zu", "sehr", "er\u00b7schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PTKA", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Auch Lott' ist tot! Die Sterbestunde,", "tokens": ["Auch", "Lott'", "ist", "tot", "!", "Die", "Ster\u00b7be\u00b7stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "ADJD", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Sie schl\u00e4gt f\u00fcr Menschen wie f\u00fcr Hunde,", "tokens": ["Sie", "schl\u00e4gt", "f\u00fcr", "Men\u00b7schen", "wie", "f\u00fcr", "Hun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Zumal f\u00fcr Hunde jener Zunft,", "tokens": ["Zu\u00b7mal", "f\u00fcr", "Hun\u00b7de", "je\u00b7ner", "Zunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Die immer angebellt die Vernunft", "tokens": ["Die", "im\u00b7mer", "an\u00b7ge\u00b7bellt", "die", "Ver\u00b7nunft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVPP", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.19": {"text": "Und gern zu einem r\u00f6mischen Knechte", "tokens": ["Und", "gern", "zu", "ei\u00b7nem", "r\u00f6\u00b7mi\u00b7schen", "Knech\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Den deutschen Freiling machen m\u00f6chte.", "tokens": ["Den", "deut\u00b7schen", "Frei\u00b7ling", "ma\u00b7chen", "m\u00f6ch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Und der Ma\u00dfmann mit der platten Nas',", "tokens": ["Und", "der", "Ma\u00df\u00b7mann", "mit", "der", "plat\u00b7ten", "Nas'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.22": {"text": "Hat Ma\u00dfmann noch nicht gebissen ins Gras?", "tokens": ["Hat", "Ma\u00df\u00b7mann", "noch", "nicht", "ge\u00b7bis\u00b7sen", "ins", "Gras", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "PTKNEG", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Ich will es nicht wissen, o sagt es mir nicht,", "tokens": ["Ich", "will", "es", "nicht", "wis\u00b7sen", ",", "o", "sagt", "es", "mir", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "FM", "VVFIN", "PPER", "PPER", "PTKNEG", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.24": {"text": "Wenn er verreckt \u2013 ich w\u00fcrde weinen.", "tokens": ["Wenn", "er", "ver\u00b7reckt", "\u2013", "ich", "w\u00fcr\u00b7de", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "$(", "PPER", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "O mag er noch lange im Lebenslicht", "tokens": ["O", "mag", "er", "noch", "lan\u00b7ge", "im", "Le\u00b7bens\u00b7licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADV", "ADV", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.26": {"text": "Hintrippeln auf seinen kurzen Beinchen,", "tokens": ["Hin\u00b7trip\u00b7peln", "auf", "sei\u00b7nen", "kur\u00b7zen", "Be\u00b7in\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Das Wurzelm\u00e4nnchen, das Alr\u00e4unchen", "tokens": ["Das", "Wur\u00b7zel\u00b7m\u00e4nn\u00b7chen", ",", "das", "Al\u00b7r\u00e4un\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Mit dem H\u00e4ngewanst! O diese Figur", "tokens": ["Mit", "dem", "H\u00e4n\u00b7ge\u00b7wanst", "!", "O", "die\u00b7se", "Fi\u00b7gur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$.", "NE", "PDAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.29": {"text": "War meine Lieblingskreatur", "tokens": ["War", "mei\u00b7ne", "Lieb\u00b7lings\u00b7kre\u00b7a\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "So lange Zeit \u2013 ich sehe sie noch \u2013", "tokens": ["So", "lan\u00b7ge", "Zeit", "\u2013", "ich", "se\u00b7he", "sie", "noch", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.31": {"text": "So klein sie war, sie soff wie ein Loch,", "tokens": ["So", "klein", "sie", "war", ",", "sie", "soff", "wie", "ein", "Loch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.32": {"text": "Mit seinen Sch\u00fclern, die bierentz\u00fcgelt", "tokens": ["Mit", "sei\u00b7nen", "Sch\u00fc\u00b7lern", ",", "die", "bie\u00b7rent\u00b7z\u00fc\u00b7gelt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "VVFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Den armen Turnmeister am Ende gepr\u00fcgelt.", "tokens": ["Den", "ar\u00b7men", "Turn\u00b7meis\u00b7ter", "am", "En\u00b7de", "ge\u00b7pr\u00fc\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.34": {"text": "Und welche Pr\u00fcgel! Die jungen Helden,", "tokens": ["Und", "wel\u00b7che", "Pr\u00fc\u00b7gel", "!", "Die", "jun\u00b7gen", "Hel\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Sie wollten beweisen, da\u00df rohe Kraft", "tokens": ["Sie", "woll\u00b7ten", "be\u00b7wei\u00b7sen", ",", "da\u00df", "ro\u00b7he", "Kraft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KOUS", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.36": {"text": "Und Flegeltum noch nicht erschlafft", "tokens": ["Und", "Fle\u00b7gel\u00b7tum", "noch", "nicht", "er\u00b7schlafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Beim Enkel von Hermann und Thusnelden!", "tokens": ["Beim", "En\u00b7kel", "von", "Her\u00b7mann", "und", "Thus\u00b7nel\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "Die ungewaschnen germanischen H\u00e4nde,", "tokens": ["Die", "un\u00b7ge\u00b7waschnen", "ger\u00b7ma\u00b7ni\u00b7schen", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "Sie schlugen so gr\u00fcndlich, das nahm kein Ende,", "tokens": ["Sie", "schlu\u00b7gen", "so", "gr\u00fcnd\u00b7lich", ",", "das", "nahm", "kein", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.40": {"text": "Zumal in den Stei\u00df die vielen Fu\u00dftritte,", "tokens": ["Zu\u00b7mal", "in", "den", "Stei\u00df", "die", "vie\u00b7len", "Fu\u00df\u00b7trit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.41": {"text": "Die das arme Luder geduldig litte.", "tokens": ["Die", "das", "ar\u00b7me", "Lu\u00b7der", "ge\u00b7dul\u00b7dig", "lit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.42": {"text": "\u00bbich kann\u00ab, rief ich, \u00bbdir nicht versagen", "tokens": ["\u00bb", "ich", "kann", "\u00ab", ",", "rief", "ich", ",", "\u00bb", "dir", "nicht", "ver\u00b7sa\u00b7gen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "All meine Bewundrung; wie kannst du ertragen", "tokens": ["All", "mei\u00b7ne", "Be\u00b7wund\u00b7rung", ";", "wie", "kannst", "du", "er\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "$.", "PWAV", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-++--+-", "measure": "iambic.penta.relaxed"}, "line.44": {"text": "So viele Pr\u00fcgel? du bist ein Brutus!\u00ab", "tokens": ["So", "vie\u00b7le", "Pr\u00fc\u00b7gel", "?", "du", "bist", "ein", "Bru\u00b7tus", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PIAT", "NN", "$.", "PPER", "VAFIN", "ART", "NE", "$.", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.45": {"text": "Doch Ma\u00dfmann sprach: \u00bbDie Menge tut es.\u00ab", "tokens": ["Doch", "Ma\u00df\u00b7mann", "sprach", ":", "\u00bb", "Die", "Men\u00b7ge", "tut", "es", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "VVFIN", "$.", "$(", "ART", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und apropos: wie sind geraten", "tokens": ["Und", "a\u00b7pro\u00b7pos", ":", "wie", "sind", "ge\u00b7ra\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "$.", "PWAV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In diesem Jahr die Teltower R\u00fcben", "tokens": ["In", "die\u00b7sem", "Jahr", "die", "Tel\u00b7to\u00b7wer", "R\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und sauren Gurken in meiner lieben", "tokens": ["Und", "sau\u00b7ren", "Gur\u00b7ken", "in", "mei\u00b7ner", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "APPR", "PPOSAT", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Borussenstadt? Und die Literaten,", "tokens": ["Bo\u00b7rus\u00b7sen\u00b7stadt", "?", "Und", "die", "Li\u00b7te\u00b7ra\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KON", "ART", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.5": {"text": "Befinden sie sich noch frisch und munter?", "tokens": ["Be\u00b7fin\u00b7den", "sie", "sich", "noch", "frisch", "und", "mun\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und ist immer noch kein Genie darunter?", "tokens": ["Und", "ist", "im\u00b7mer", "noch", "kein", "Ge\u00b7nie", "da\u00b7run\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "PIAT", "NN", "PAV", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Jedoch, wozu ein Genie? wir laben", "tokens": ["Je\u00b7doch", ",", "wo\u00b7zu", "ein", "Ge\u00b7nie", "?", "wir", "la\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "$.", "PPER", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Uns besser an frommen, bescheidnen Gaben,", "tokens": ["Uns", "bes\u00b7ser", "an", "from\u00b7men", ",", "be\u00b7scheid\u00b7nen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Auch sittliche Menschen haben ihr Gutes \u2013", "tokens": ["Auch", "sitt\u00b7li\u00b7che", "Men\u00b7schen", "ha\u00b7ben", "ihr", "Gu\u00b7tes", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zw\u00f6lf machen ein Dutzend \u2013 die Menge tut es.", "tokens": ["Zw\u00f6lf", "ma\u00b7chen", "ein", "Dut\u00b7zend", "\u2013", "die", "Men\u00b7ge", "tut", "es", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VVFIN", "ART", "NN", "$(", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Und wie geht's in Berlin den Leutenants", "tokens": ["Und", "wie", "geht's", "in", "Ber\u00b7lin", "den", "Leu\u00b7ten\u00b7ants"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VVFIN", "APPR", "NE", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Garde? Haben sie noch ihre Arroganz", "tokens": ["Der", "Gar\u00b7de", "?", "Ha\u00b7ben", "sie", "noch", "ih\u00b7re", "Ar\u00b7ro\u00b7ganz"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "VAFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ihre enggeschn\u00fcrte Taille?", "tokens": ["Und", "ih\u00b7re", "eng\u00b7ge\u00b7schn\u00fcr\u00b7te", "Tail\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schwadronieren sie noch von Kanaille?", "tokens": ["Schwad\u00b7ro\u00b7nie\u00b7ren", "sie", "noch", "von", "Ka\u00b7nail\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Ich rate euch, nehmt euch in acht,", "tokens": ["Ich", "ra\u00b7te", "euch", ",", "nehmt", "euch", "in", "acht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "APPR", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es bricht noch nicht, jedoch es kracht;", "tokens": ["Es", "bricht", "noch", "nicht", ",", "je\u00b7doch", "es", "kracht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "ADV", "PPER", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Und es ist das Brandenburger Tor", "tokens": ["Und", "es", "ist", "das", "Bran\u00b7den\u00b7bur\u00b7ger", "Tor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Noch immer so gro\u00df und so weit wie zuvor,", "tokens": ["Noch", "im\u00b7mer", "so", "gro\u00df", "und", "so", "weit", "wie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "KON", "ADV", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.9": {"text": "Und man k\u00f6nnt euch auf einmal zum Tor hinausschmei\u00dfen,", "tokens": ["Und", "man", "k\u00f6nnt", "euch", "auf", "ein\u00b7mal", "zum", "Tor", "hin\u00b7aus\u00b7schmei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPR", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.10": {"text": "Euch alle, mitsamt dem Prinzen von Preu\u00dfen \u2013", "tokens": ["Euch", "al\u00b7le", ",", "mit\u00b7samt", "dem", "Prin\u00b7zen", "von", "Preu\u00b7\u00dfen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "APPR", "ART", "NN", "APPR", "NE", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Die Menge tut es.", "tokens": ["Die", "Men\u00b7ge", "tut", "es", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}