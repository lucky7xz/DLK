{"textgrid.poem.44028": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie kanstu doch so viel vergebens klagen", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie kanstu doch so viel vergebens klagen", "tokens": ["Wie", "kans\u00b7tu", "doch", "so", "viel", "ver\u00b7ge\u00b7bens", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "ADV", "ADV", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und unerh\u00f6rte Seufzer thun?", "tokens": ["Und", "un\u00b7er\u00b7h\u00f6r\u00b7te", "Seuf\u00b7zer", "thun", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach, las einmahl die Augen ruhn", "tokens": ["Ach", ",", "las", "ein\u00b7mahl", "die", "Au\u00b7gen", "ruhn"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "VVFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und thu dir selber weh, die Schl\u00e4ge stumm zu tragen.", "tokens": ["Und", "thu", "dir", "sel\u00b7ber", "weh", ",", "die", "Schl\u00e4\u00b7ge", "stumm", "zu", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du siehst ja wohl einmahl, verworfnes Menschenkind,", "tokens": ["Du", "siehst", "ja", "wohl", "ein\u00b7mahl", ",", "ver\u00b7worf\u00b7nes", "Men\u00b7schen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df Gl\u00fcck und Gott nicht mehr der Unschuld Freunde sind.", "tokens": ["Da\u00df", "Gl\u00fcck", "und", "Gott", "nicht", "mehr", "der", "Un\u00b7schuld", "Freun\u00b7de", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PTKNEG", "ADV", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Du wurdest ja mit Angst zur Angst gebohren,", "tokens": ["Du", "wur\u00b7dest", "ja", "mit", "Angst", "zur", "Angst", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die dir ein blutig Morgenroth", "tokens": ["Die", "dir", "ein", "blu\u00b7tig", "Mor\u00b7gen\u00b7roth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon in der Mutter Schoos gedroht,", "tokens": ["Schon", "in", "der", "Mut\u00b7ter", "Schoos", "ge\u00b7droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Mutter, die durch dich so Wuntsch als Kraft verloren.", "tokens": ["Der", "Mut\u00b7ter", ",", "die", "durch", "dich", "so", "Wunt\u00b7sch", "als", "Kraft", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "ADV", "ADJD", "KOKOM", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ach, w\u00e4re dort dein Geist im ersten Bad erstickt,", "tokens": ["Ach", ",", "w\u00e4\u00b7re", "dort", "dein", "Geist", "im", "ers\u00b7ten", "Bad", "er\u00b7stickt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "ADV", "PPOSAT", "NN", "APPRART", "ADJA", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So w\u00fcrd er jezt nicht erst durch Thr\u00e4nen hinger\u00fcckt.", "tokens": ["So", "w\u00fcrd", "er", "jezt", "nicht", "erst", "durch", "Thr\u00e4\u00b7nen", "hin\u00b7ge\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dich, bla\u00dfer Mond, und euch, erz\u00fcrnte Sterne,", "tokens": ["Dich", ",", "bla\u00b7\u00dfer", "Mond", ",", "und", "euch", ",", "er\u00b7z\u00fcrn\u00b7te", "Ster\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "KON", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Euch, deren Einflu\u00df, Trieb und Macht", "tokens": ["Euch", ",", "de\u00b7ren", "Ein\u00b7flu\u00df", ",", "Trieb", "und", "Macht"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "PRELAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mein Elend zeugt und auch belacht,", "tokens": ["Mein", "E\u00b7lend", "zeugt", "und", "auch", "be\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beschw\u00f6r ich bey der Noth, wodurch ich fluchen lerne:", "tokens": ["Be\u00b7schw\u00f6r", "ich", "bey", "der", "Noth", ",", "wo\u00b7durch", "ich", "flu\u00b7chen", "ler\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sagt, weil doch euer Licht in alle Winckel f\u00e4llt,", "tokens": ["Sagt", ",", "weil", "doch", "eu\u00b7er", "Licht", "in", "al\u00b7le", "Win\u00b7ckel", "f\u00e4llt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sagt, ob auch die Natur noch solch ein Stiefkind h\u00e4lt.", "tokens": ["Sagt", ",", "ob", "auch", "die", "Na\u00b7tur", "noch", "solch", "ein", "Stief\u00b7kind", "h\u00e4lt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "ART", "NN", "ADV", "PIAT", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Bin ich allein zum \u00c4rgern\u00fc\u00df erschafen,", "tokens": ["Bin", "ich", "al\u00b7lein", "zum", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "er\u00b7scha\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und steckt mein Wesen voller Schuld?", "tokens": ["Und", "steckt", "mein", "We\u00b7sen", "vol\u00b7ler", "Schuld", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hat der Himmel noch Gedult,", "tokens": ["Wie", "hat", "der", "Him\u00b7mel", "noch", "Ge\u00b7dult", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und warum s\u00e4umt sein Zorn, mich pl\u00f6zlich hinzurafen,", "tokens": ["Und", "wa\u00b7rum", "s\u00e4umt", "sein", "Zorn", ",", "mich", "pl\u00f6z\u00b7lich", "hin\u00b7zu\u00b7ra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nachdem die Erd an mir ein solch Gesch\u00f6pfe n\u00e4hrt,", "tokens": ["Nach\u00b7dem", "die", "Erd", "an", "mir", "ein", "solch", "Ge\u00b7sch\u00f6p\u00b7fe", "n\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPER", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.6": {"text": "Das ihm zur Schande lebt und sonder Nuzen zehrt?", "tokens": ["Das", "ihm", "zur", "Schan\u00b7de", "lebt", "und", "son\u00b7der", "Nu\u00b7zen", "zehrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVFIN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Jedoch ich weis, er kennt mein treu Gem\u00fcthe", "tokens": ["Je\u00b7doch", "ich", "weis", ",", "er", "kennt", "mein", "treu", "Ge\u00b7m\u00fc\u00b7the"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und sieht des Herzens Neigung an,", "tokens": ["Und", "sieht", "des", "Her\u00b7zens", "Nei\u00b7gung", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die keinem schlimm begegnen kan,", "tokens": ["Die", "kei\u00b7nem", "schlimm", "be\u00b7geg\u00b7nen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Obgleich sein \u00e4rgster Feind ihm in die Hand geriethe:", "tokens": ["Ob\u00b7gleich", "sein", "\u00e4rgs\u00b7ter", "Feind", "ihm", "in", "die", "Hand", "ge\u00b7rie\u00b7the", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es fehlet als ein Mensch und darum, weil es fehlt,", "tokens": ["Es", "feh\u00b7let", "als", "ein", "Mensch", "und", "da\u00b7rum", ",", "weil", "es", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "KON", "PAV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vergiebt es jedem gern, den gleiche Schwachheit qu\u00e4lt.", "tokens": ["Ver\u00b7giebt", "es", "je\u00b7dem", "gern", ",", "den", "glei\u00b7che", "Schwach\u00b7heit", "qu\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "So bistu denn auch da nicht mehr zu finden,", "tokens": ["So", "bis\u00b7tu", "denn", "auch", "da", "nicht", "mehr", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADV", "ADV", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Dir, dir, Erbarmung, ruf ich zu \u2013", "tokens": ["\u2013", "Dir", ",", "dir", ",", "Er\u00b7bar\u00b7mung", ",", "ruf", "ich", "zu", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "PPER", "$,", "NN", "$,", "VVFIN", "PPER", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da, wo der Armen Trost und Ruh", "tokens": ["Da", ",", "wo", "der", "Ar\u00b7men", "Trost", "und", "Ruh"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich sonst gemeiniglich mit fester Zuflucht gr\u00fcnden?", "tokens": ["Sich", "sonst", "ge\u00b7mei\u00b7nig\u00b7lich", "mit", "fes\u00b7ter", "Zu\u00b7flucht", "gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ach, hat dich irgend auch der Himmel, der mich plagt,", "tokens": ["Ach", ",", "hat", "dich", "ir\u00b7gend", "auch", "der", "Him\u00b7mel", ",", "der", "mich", "plagt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nur mir zur lezten Qual aus seiner Schoos gejagt?", "tokens": ["Nur", "mir", "zur", "lez\u00b7ten", "Qual", "aus", "sei\u00b7ner", "Schoos", "ge\u00b7jagt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Sey, wo du wilt, du must mein Leid erfahren,", "tokens": ["Sey", ",", "wo", "du", "wilt", ",", "du", "must", "mein", "Leid", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Das fast ein jedes Element", "tokens": ["Das", "fast", "ein", "je\u00b7des", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gut als mich das Ungl\u00fcck kennt.", "tokens": ["So", "gut", "als", "mich", "das", "Un\u00b7gl\u00fcck", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Seufzer m\u00fc\u00dfen sich mit Luft und Winden paaren,", "tokens": ["Die", "Seuf\u00b7zer", "m\u00fc\u00b7\u00dfen", "sich", "mit", "Luft", "und", "Win\u00b7den", "paa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Erde f\u00fchlt die Last, von Thr\u00e4nen w\u00e4chst die Fluth,", "tokens": ["Die", "Er\u00b7de", "f\u00fchlt", "die", "Last", ",", "von", "Thr\u00e4\u00b7nen", "w\u00e4chst", "die", "Fluth", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und meiner G\u00fcter Rest entf\u00fchrt die wilde Glut.", "tokens": ["Und", "mei\u00b7ner", "G\u00fc\u00b7ter", "Rest", "ent\u00b7f\u00fchrt", "die", "wil\u00b7de", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Und mag's doch seyn. Ich will es nicht mehr r\u00fchren,", "tokens": ["Und", "mag's", "doch", "seyn", ".", "Ich", "will", "es", "nicht", "mehr", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VAINF", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nachdem mich auch kein Freund mehr klagt.", "tokens": ["Nach\u00b7dem", "mich", "auch", "kein", "Freund", "mehr", "klagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Schall, so alles wieder sagt,", "tokens": ["Der", "Schall", ",", "so", "al\u00b7les", "wie\u00b7der", "sagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mag, was mich qu\u00e4lt und dr\u00fcckt, in Wald und W\u00fcste f\u00fchren.", "tokens": ["Mag", ",", "was", "mich", "qu\u00e4lt", "und", "dr\u00fcckt", ",", "in", "Wald", "und", "W\u00fcs\u00b7te", "f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich zieh vielleicht bald nach, um bey so langer Pein", "tokens": ["Ich", "zieh", "viel\u00b7leicht", "bald", "nach", ",", "um", "bey", "so", "lan\u00b7ger", "Pein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "KOUI", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nicht mehr ein \u00c4rgern\u00fc\u00df der tummen Welt zu seyn.", "tokens": ["Nicht", "mehr", "ein", "\u00c4r\u00b7ger\u00b7n\u00fc\u00df", "der", "tum\u00b7men", "Welt", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "NN", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}