{"textgrid.poem.43048": {"metadata": {"author": {"name": "Jacoby, Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie soll ich dich schildern, du Geliebte!", "genre": "verse", "period": "N.A.", "pub_year": 1867, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie soll ich dich schildern, du Geliebte!", "tokens": ["Wie", "soll", "ich", "dich", "schil\u00b7dern", ",", "du", "Ge\u00b7lieb\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$,", "PPER", "NN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Meine Seele sehnt sich, dir Dank zu sagen,", "tokens": ["Mei\u00b7ne", "See\u00b7le", "sehnt", "sich", ",", "dir", "Dank", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "$,", "PPER", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Und mein Herz quillt \u00fcber,", "tokens": ["Und", "mein", "Herz", "quillt", "\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "So m\u00fcssen meine Lippen reden.", "tokens": ["So", "m\u00fcs\u00b7sen", "mei\u00b7ne", "Lip\u00b7pen", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Aus gepre\u00dftem Innern mu\u00df ich dein Lob singen.", "tokens": ["Aus", "ge\u00b7pre\u00df\u00b7tem", "In\u00b7nern", "mu\u00df", "ich", "dein", "Lob", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Fr\u00fcher,", "tokens": ["Fr\u00fc\u00b7her", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Da mich Niemand gekannt,", "tokens": ["Da", "mich", "Nie\u00b7mand", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVPP", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Hast du allein mich aufgenommen,", "tokens": ["Hast", "du", "al\u00b7lein", "mich", "auf\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und nun, da mich Alles verlassen,", "tokens": ["Und", "nun", ",", "da", "mich", "Al\u00b7les", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PIS", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Bist du doch mir treu geblieben", "tokens": ["Bist", "du", "doch", "mir", "treu", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und bist meine einzige Liebe geworden.", "tokens": ["Und", "bist", "mei\u00b7ne", "ein\u00b7zi\u00b7ge", "Lie\u00b7be", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN", "VAPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Wie soll ich dich schildern, du Geliebte!", "tokens": ["Wie", "soll", "ich", "dich", "schil\u00b7dern", ",", "du", "Ge\u00b7lieb\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$,", "PPER", "NN", "$."], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Bist du mir hold gesinnt,", "tokens": ["Bist", "du", "mir", "hold", "ge\u00b7sinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was habe ich zu fragen nach Ehre von Menschen?", "tokens": ["Was", "ha\u00b7be", "ich", "zu", "fra\u00b7gen", "nach", "Eh\u00b7re", "von", "Men\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKZU", "VVINF", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Was habe ich zu fragen nach den Sch\u00e4tzen,", "tokens": ["Was", "ha\u00b7be", "ich", "zu", "fra\u00b7gen", "nach", "den", "Sch\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die voll Jammer und Thr\u00e4nen der Armen sind?", "tokens": ["Die", "voll", "Jam\u00b7mer", "und", "Thr\u00e4\u00b7nen", "der", "Ar\u00b7men", "sind", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "KON", "NN", "ART", "NN", "VAFIN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Du wendest dein Antlitz mir zu voll Liebe,", "tokens": ["Du", "wen\u00b7dest", "dein", "Ant\u00b7litz", "mir", "zu", "voll", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PPER", "PTKA", "ADJD", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Und in deinem Lachen spiegeln sich", "tokens": ["Und", "in", "dei\u00b7nem", "La\u00b7chen", "spie\u00b7geln", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN", "PRF"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Die Sonne, der Mond und alle die Sterne.", "tokens": ["Die", "Son\u00b7ne", ",", "der", "Mond", "und", "al\u00b7le", "die", "Ster\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "PIS", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wenn du muthwillig bist und spielest,", "tokens": ["Wenn", "du", "mut\u00b7hwil\u00b7lig", "bist", "und", "spie\u00b7lest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dann bist du wie ein junges Reh im Walde,", "tokens": ["Dann", "bist", "du", "wie", "ein", "jun\u00b7ges", "Reh", "im", "Wal\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "KOKOM", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Da es bei der Mutter spielet,", "tokens": ["Da", "es", "bei", "der", "Mut\u00b7ter", "spie\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und ich mu\u00df jauchzen unter Thr\u00e4nen.", "tokens": ["Und", "ich", "mu\u00df", "jauch\u00b7zen", "un\u00b7ter", "Thr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VVINF", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Z\u00fcrnst du, ach sie wissen es nicht,", "tokens": ["Z\u00fcrnst", "du", ",", "ach", "sie", "wis\u00b7sen", "es", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "XY", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "Welche Qual du bereitest.", "tokens": ["Wel\u00b7che", "Qual", "du", "be\u00b7rei\u00b7test", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.4": {"line.1": {"text": "Wie eine Jungfrau zaghaft ist und unbeholfen,", "tokens": ["Wie", "ei\u00b7ne", "Jung\u00b7frau", "zag\u00b7haft", "ist", "und", "un\u00b7be\u00b7hol\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VAFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und doch der s\u00fc\u00dfesten Geheimnisse voll,", "tokens": ["Und", "doch", "der", "s\u00fc\u00b7\u00dfes\u00b7ten", "Ge\u00b7heim\u00b7nis\u00b7se", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "So bist du ach wie oft so spr\u00f6d',", "tokens": ["So", "bist", "du", "ach", "wie", "oft", "so", "spr\u00f6d'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "KOKOM", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So starr und widerstrebend,", "tokens": ["So", "starr", "und", "wi\u00b7der\u00b7stre\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df man sich mu\u00df \u00e4rgern \u00fcber dich", "tokens": ["Da\u00df", "man", "sich", "mu\u00df", "\u00e4r\u00b7gern", "\u00fc\u00b7ber", "dich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "VMFIN", "VVINF", "APPR", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Und mu\u00df dich doch lieb haben.", "tokens": ["Und", "mu\u00df", "dich", "doch", "lieb", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wenn ich dich aber schelten will,", "tokens": ["Wenn", "ich", "dich", "a\u00b7ber", "schel\u00b7ten", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dann blickst du mich mit einmal an", "tokens": ["Dann", "blickst", "du", "mich", "mit", "ein\u00b7mal", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Klug mit frischen Kinderaugen,", "tokens": ["Klug", "mit", "fri\u00b7schen", "Kin\u00b7der\u00b7au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Wie eine Tanne unterm Schnee vorguckt,", "tokens": ["Wie", "ei\u00b7ne", "Tan\u00b7ne", "un\u00b7term", "Schnee", "vor\u00b7guckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und aller Unmuth ist mir gleich davongeflogen.", "tokens": ["Und", "al\u00b7ler", "Un\u00b7muth", "ist", "mir", "gleich", "da\u00b7von\u00b7ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wenn du ein Herzenslied anhebst zu singen,", "tokens": ["Wenn", "du", "ein", "Her\u00b7zens\u00b7lied", "an\u00b7hebst", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dann quillt es alles heraus voll innerlichem Wohllaut,", "tokens": ["Dann", "quillt", "es", "al\u00b7les", "he\u00b7raus", "voll", "in\u00b7ner\u00b7li\u00b7chem", "Wohl\u00b7laut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und du bist reich an Sch\u00f6nheit", "tokens": ["Und", "du", "bist", "reich", "an", "Sch\u00f6n\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und an Gedankentiefe wunderbar", "tokens": ["Und", "an", "Ge\u00b7dan\u00b7ken\u00b7tie\u00b7fe", "wun\u00b7der\u00b7bar"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wie Meerleuchten.", "tokens": ["Wie", "Meer\u00b7leuch\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["PWAV", "NN", "$."], "meter": "-+--", "measure": "dactylic.init"}}, "stanza.6": {"line.1": {"text": "Du bist kein Singsang", "tokens": ["Du", "bist", "kein", "Sings\u00b7ang"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Und bist keine Sprache, um nichts zu sagen. \u2013", "tokens": ["Und", "bist", "kei\u00b7ne", "Spra\u00b7che", ",", "um", "nichts", "zu", "sa\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "$,", "KOUI", "PIS", "PTKZU", "VVINF", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Und du willst mich nimmer verlassen,", "tokens": ["Und", "du", "willst", "mich", "nim\u00b7mer", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Darob mu\u00df mein Herz wohl fr\u00f6hlich sein.", "tokens": ["Da\u00b7rob", "mu\u00df", "mein", "Herz", "wohl", "fr\u00f6h\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ADJD", "VAINF", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Wenn ich voll Jammer war,", "tokens": ["Wenn", "ich", "voll", "Jam\u00b7mer", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "NN", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wer hat mich getr\u00f6stet als du?", "tokens": ["Wer", "hat", "mich", "ge\u00b7tr\u00f6s\u00b7tet", "als", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVPP", "KOUS", "PPER", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Wenn ich verschmachtet war,", "tokens": ["Wenn", "ich", "ver\u00b7schmach\u00b7tet", "war", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Wer hat mich erquickt als du?", "tokens": ["Wer", "hat", "mich", "er\u00b7quickt", "als", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVFIN", "KOUS", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Wann habe ich eine frohe Stunde im Leben gehabt?", "tokens": ["Wann", "ha\u00b7be", "ich", "ei\u00b7ne", "fro\u00b7he", "Stun\u00b7de", "im", "Le\u00b7ben", "ge\u00b7habt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ART", "ADJA", "NN", "APPRART", "NN", "VAPP", "$."], "meter": "-+--+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Nach der Kindheit bis auf den heutigen Tag,", "tokens": ["Nach", "der", "Kind\u00b7heit", "bis", "auf", "den", "heu\u00b7ti\u00b7gen", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "Wenn du sie mir nicht gegeben?", "tokens": ["Wenn", "du", "sie", "mir", "nicht", "ge\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Du hast mich durch dunkle Nacht gef\u00fchrt,", "tokens": ["Du", "hast", "mich", "durch", "dunk\u00b7le", "Nacht", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "Und ich habe ein Licht gesehen,", "tokens": ["Und", "ich", "ha\u00b7be", "ein", "Licht", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Das noch niemals auf Erden", "tokens": ["Das", "noch", "nie\u00b7mals", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADV", "APPR", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": "Und auf die Menschen gestrahlet.", "tokens": ["Und", "auf", "die", "Men\u00b7schen", "ge\u00b7strah\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "So soll auch dein Ruhm klingen m\u00e4rchenhaft,", "tokens": ["So", "soll", "auch", "dein", "Ruhm", "klin\u00b7gen", "m\u00e4r\u00b7chen\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Und du wirst gesegnet sein,", "tokens": ["Und", "du", "wirst", "ge\u00b7seg\u00b7net", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Und dein Lob soll nicht untergehen,", "tokens": ["Und", "dein", "Lob", "soll", "nicht", "un\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "So lange Menschen auf Erden wohnen.", "tokens": ["So", "lan\u00b7ge", "Men\u00b7schen", "auf", "Er\u00b7den", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Wie solltest du auch nicht tr\u00f6sten k\u00f6nnen", "tokens": ["Wie", "soll\u00b7test", "du", "auch", "nicht", "tr\u00f6s\u00b7ten", "k\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "VMINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bis in die Tiefe der Menschenseele,", "tokens": ["Bis", "in", "die", "Tie\u00b7fe", "der", "Men\u00b7schen\u00b7see\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Bist du doch selber auch elend und gequ\u00e4lt.", "tokens": ["Bist", "du", "doch", "sel\u00b7ber", "auch", "e\u00b7lend", "und", "ge\u00b7qu\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "KON", "VVPP", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Du bist wie das Volk.", "tokens": ["Du", "bist", "wie", "das", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Die Geschichtschreiber und Hofgelehrten", "tokens": ["Die", "Ge\u00b7schicht\u00b7schrei\u00b7ber", "und", "Hof\u00b7ge\u00b7lehr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Verrathen dich alle Tage.", "tokens": ["Ver\u00b7ra\u00b7then", "dich", "al\u00b7le", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie schreiben L\u00fcgen in ihre B\u00fccher", "tokens": ["Sie", "schrei\u00b7ben", "L\u00fc\u00b7gen", "in", "ih\u00b7re", "B\u00fc\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und lassen sie auswendig lernen.", "tokens": ["Und", "las\u00b7sen", "sie", "aus\u00b7wen\u00b7dig", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie k\u00fcssen den Fu\u00df, der dich tritt", "tokens": ["Sie", "k\u00fcs\u00b7sen", "den", "Fu\u00df", ",", "der", "dich", "tritt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Und der sie selber von sich st\u00f6\u00dft.", "tokens": ["Und", "der", "sie", "sel\u00b7ber", "von", "sich", "st\u00f6\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sie sind blind mit offenen Augen.", "tokens": ["Sie", "sind", "blind", "mit", "of\u00b7fe\u00b7nen", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.9": {"text": "Du bist wie das Volk.", "tokens": ["Du", "bist", "wie", "das", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "Von den F\u00fcrsten hast du dich mi\u00dfhandeln lassen,", "tokens": ["Von", "den", "F\u00fcrs\u00b7ten", "hast", "du", "dich", "mi\u00df\u00b7han\u00b7deln", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PRF", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Von den K\u00f6nigen hast du dich verachten lassen,", "tokens": ["Von", "den", "K\u00f6\u00b7ni\u00b7gen", "hast", "du", "dich", "ver\u00b7ach\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PRF", "VVFIN", "VVINF", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und die falschen Propheten", "tokens": ["Und", "die", "fal\u00b7schen", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Haben nun die geschwollene Phrase \u00fcber dich geworfen,", "tokens": ["Ha\u00b7ben", "nun", "die", "ge\u00b7schwol\u00b7le\u00b7ne", "Phra\u00b7se", "\u00fc\u00b7ber", "dich", "ge\u00b7wor\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+--+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Um deinen Aufschrei zu ersticken.", "tokens": ["Um", "dei\u00b7nen", "Auf\u00b7schrei", "zu", "er\u00b7sti\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Aber ihnen zum Trotz hast du gebl\u00fchet zweimal,", "tokens": ["A\u00b7ber", "ih\u00b7nen", "zum", "Trotz", "hast", "du", "ge\u00b7bl\u00fc\u00b7het", "zwei\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "NN", "VAFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Ihnen allen zum Trotz wirst du bl\u00fchen", "tokens": ["Ih\u00b7nen", "al\u00b7len", "zum", "Trotz", "wirst", "du", "bl\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PIS", "APPRART", "NN", "VAFIN", "PPER", "VVINF"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ein drittes Mal,", "tokens": ["Ein", "drit\u00b7tes", "Mal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sch\u00f6ner als jede von beiden Bl\u00fcthen,", "tokens": ["Sch\u00f6\u00b7ner", "als", "je\u00b7de", "von", "bei\u00b7den", "Bl\u00fc\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "PIAT", "APPR", "PIAT", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.5": {"text": "Sch\u00f6ner als beide zusammen.", "tokens": ["Sch\u00f6\u00b7ner", "als", "bei\u00b7de", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PIS", "PTKVZ", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Wie wenn im Junimond,", "tokens": ["Wie", "wenn", "im", "Ju\u00b7ni\u00b7mond", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "An den Ufern des Stromes, der golden rauscht", "tokens": ["An", "den", "U\u00b7fern", "des", "Stro\u00b7mes", ",", "der", "gol\u00b7den", "rauscht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und von Liebe und Freiheit murmelnd klingt,", "tokens": ["Und", "von", "Lie\u00b7be", "und", "Frei\u00b7heit", "mur\u00b7melnd", "klingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ADJD", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ein s\u00fc\u00dfer Duft aufsteiget", "tokens": ["Ein", "s\u00fc\u00b7\u00dfer", "Duft", "auf\u00b7stei\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und ein lieblicher Wohlgeruch,", "tokens": ["Und", "ein", "lieb\u00b7li\u00b7cher", "Wohl\u00b7ge\u00b7ruch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Das ist der Duft der Weinbl\u00fcthen,", "tokens": ["Das", "ist", "der", "Duft", "der", "Wein\u00b7bl\u00fc\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.7": {"text": "Der von den Bergen und H\u00fcgeln kommt, \u2013", "tokens": ["Der", "von", "den", "Ber\u00b7gen", "und", "H\u00fc\u00b7geln", "kommt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "ART", "NN", "KON", "NN", "VVFIN", "$,", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Aber ihrer sind wenige, die sich daran erfreuen", "tokens": ["A\u00b7ber", "ih\u00b7rer", "sind", "we\u00b7ni\u00b7ge", ",", "die", "sich", "da\u00b7ran", "er\u00b7freu\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "VAFIN", "PIS", "$,", "PRELS", "PRF", "PAV", "VVINF"], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.9": {"text": "Und ihre Augen weiden und ihr Herz erquicken,", "tokens": ["Und", "ih\u00b7re", "Au\u00b7gen", "wei\u00b7den", "und", "ihr", "Herz", "er\u00b7qui\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So hast du gebl\u00fchet das erste Mal.", "tokens": ["So", "hast", "du", "ge\u00b7bl\u00fc\u00b7het", "das", "ers\u00b7te", "Mal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.12": {"line.1": {"text": "Und wie wenn zur Herbsteszeit", "tokens": ["Und", "wie", "wenn", "zur", "Herbs\u00b7tes\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOKOM", "KOUS", "APPRART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Auf den H\u00fcgeln und Bergen die Weinlese beginnt,", "tokens": ["Auf", "den", "H\u00fc\u00b7geln", "und", "Ber\u00b7gen", "die", "Wein\u00b7le\u00b7se", "be\u00b7ginnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und der Wein in die Kelter wird getragen,", "tokens": ["Und", "der", "Wein", "in", "die", "Kel\u00b7ter", "wird", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und Abends das junge Volk eilet zum Tanz", "tokens": ["Und", "A\u00b7bends", "das", "jun\u00b7ge", "Volk", "ei\u00b7let", "zum", "Tanz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ART", "ADJA", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Und lauter Lust und Jubel erklinget ringsum, \u2013", "tokens": ["Und", "lau\u00b7ter", "Lust", "und", "Ju\u00b7bel", "er\u00b7klin\u00b7get", "ring\u00b7sum", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "VVFIN", "ADV", "$,", "$("], "meter": "-+-+-+--+---", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und ihrer sind viel mehr, die ihr Herz erfreuen,", "tokens": ["Und", "ih\u00b7rer", "sind", "viel", "mehr", ",", "die", "ihr", "Herz", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VAFIN", "ADV", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Und von Grund der Seele fr\u00f6hlich werden,", "tokens": ["Und", "von", "Grund", "der", "See\u00b7le", "fr\u00f6h\u00b7lich", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Und der Wein hat manch Lied geboren, stark und herrlich,", "tokens": ["Und", "der", "Wein", "hat", "manch", "Lied", "ge\u00b7bo\u00b7ren", ",", "stark", "und", "herr\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PIAT", "NN", "VVPP", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Das unvergessen ist und unverg\u00e4nglich auf Erden, \u2013", "tokens": ["Das", "un\u00b7ver\u00b7ges\u00b7sen", "ist", "und", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "auf", "Er\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "VAFIN", "KON", "ADJD", "APPR", "NN", "$,", "$("], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "So hast du gebl\u00fchet das zweite Mal.", "tokens": ["So", "hast", "du", "ge\u00b7bl\u00fc\u00b7het", "das", "zwei\u00b7te", "Mal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Aber wie wenn nach des Winters Qual", "tokens": ["A\u00b7ber", "wie", "wenn", "nach", "des", "Win\u00b7ters", "Qual"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOKOM", "KOUS", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Bei des jungen Fr\u00fchlings Einkehr", "tokens": ["Bei", "des", "jun\u00b7gen", "Fr\u00fch\u00b7lings", "Ein\u00b7kehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein Hausherr den Tisch deckt voll und reich,", "tokens": ["Ein", "Haus\u00b7herr", "den", "Tisch", "deckt", "voll", "und", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und \u00f6ffnet die Th\u00fcren weit", "tokens": ["Und", "\u00f6ff\u00b7net", "die", "Th\u00fc\u00b7ren", "weit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und hinausruft in das Land:", "tokens": ["Und", "hin\u00b7aus\u00b7ruft", "in", "das", "Land", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Kommet her, all ihr Armen und Elenden!", "tokens": ["Kom\u00b7met", "her", ",", "all", "ihr", "Ar\u00b7men", "und", "E\u00b7len\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PIAT", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+--+--+--", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Ihr sollt nicht mehr ausgeschlossen sein", "tokens": ["Ihr", "sollt", "nicht", "mehr", "aus\u00b7ge\u00b7schlos\u00b7sen", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "VVPP", "VAINF"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Von den Freuden dieser Erde,", "tokens": ["Von", "den", "Freu\u00b7den", "die\u00b7ser", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Ihr sollt vollen Antheil haben", "tokens": ["Ihr", "sollt", "vol\u00b7len", "An\u00b7theil", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "An allem Sch\u00f6nen auf Erden,", "tokens": ["An", "al\u00b7lem", "Sch\u00f6\u00b7nen", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "So kommet her und erquicket euch alle! \u2013", "tokens": ["So", "kom\u00b7met", "her", "und", "er\u00b7quic\u00b7ket", "euch", "al\u00b7le", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und siehe, sie kommen alle herbei", "tokens": ["Und", "sie\u00b7he", ",", "sie", "kom\u00b7men", "al\u00b7le", "her\u00b7bei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "PPER", "VVFIN", "PIAT", "NN"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.13": {"text": "Und genie\u00dfen von Allem und trinken von dem Wein,", "tokens": ["Und", "ge\u00b7nie\u00b7\u00dfen", "von", "Al\u00b7lem", "und", "trin\u00b7ken", "von", "dem", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIS", "KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.14": {"text": "Und werden froh und fr\u00f6hlich", "tokens": ["Und", "wer\u00b7den", "froh", "und", "fr\u00f6h\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Und vergessen der grausen Zeit, die hinter ihnen liegt,", "tokens": ["Und", "ver\u00b7ges\u00b7sen", "der", "grau\u00b7sen", "Zeit", ",", "die", "hin\u00b7ter", "ih\u00b7nen", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "--+--+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.16": {"text": "Und ist ihnen wie ein Traum,", "tokens": ["Und", "ist", "ih\u00b7nen", "wie", "ein", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Aber sie brauchen nicht Angst haben aufzuwachen,", "tokens": ["A\u00b7ber", "sie", "brau\u00b7chen", "nicht", "Angst", "ha\u00b7ben", "auf\u00b7zu\u00b7wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "NN", "VAFIN", "VVPP", "$,"], "meter": "+--+-+++-+-+-", "measure": "iambic.septa.invert"}, "line.18": {"text": "Denn es ist in Wahrheit ein neuer Fr\u00fchling worden", "tokens": ["Denn", "es", "ist", "in", "Wahr\u00b7heit", "ein", "neu\u00b7er", "Fr\u00fch\u00b7ling", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "NN", "ART", "ADJA", "NN", "VAPP"], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Rings um sie her, \u2013", "tokens": ["Rings", "um", "sie", "her", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "$,", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "So wirst du bl\u00fchen das dritte Mal.", "tokens": ["So", "wirst", "du", "bl\u00fc\u00b7hen", "das", "drit\u00b7te", "Mal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Unvergleichlich, wie du bist,", "tokens": ["Un\u00b7ver\u00b7gleich\u00b7lich", ",", "wie", "du", "bist", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Ist auch die Weise, wie du geworden bist,", "tokens": ["Ist", "auch", "die", "Wei\u00b7se", ",", "wie", "du", "ge\u00b7wor\u00b7den", "bist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "VAPP", "VAFIN", "$,"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.23": {"text": "Und dein hoher Ruhm ist, sie zu erz\u00e4hlen:", "tokens": ["Und", "dein", "ho\u00b7her", "Ruhm", "ist", ",", "sie", "zu", "er\u00b7z\u00e4h\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Vom Morgen her,", "tokens": ["Vom", "Mor\u00b7gen", "her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,"], "meter": "-+--", "measure": "dactylic.init"}, "line.2": {"text": "Wo das Licht aufgehet", "tokens": ["Wo", "das", "Licht", "auf\u00b7ge\u00b7het"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die Wiege der Menschen stand,", "tokens": ["Und", "die", "Wie\u00b7ge", "der", "Men\u00b7schen", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Bist du gekommen,", "tokens": ["Bist", "du", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Und durch Abend sollst du wandern", "tokens": ["Und", "durch", "A\u00b7bend", "sollst", "du", "wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder zum Morgen!", "tokens": ["Wie\u00b7der", "zum", "Mor\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "++-+-", "measure": "iambic.di"}, "line.7": {"text": "Wild und st\u00fcrmisch ist dein Anfang gewesen,", "tokens": ["Wild", "und", "st\u00fcr\u00b7misch", "ist", "dein", "An\u00b7fang", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "VAPP", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Und wild und st\u00fcrmisch", "tokens": ["Und", "wild", "und", "st\u00fcr\u00b7misch"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "M\u00fcssen die Wendepunkte deines Lebens sein.", "tokens": ["M\u00fcs\u00b7sen", "die", "Wen\u00b7de\u00b7punk\u00b7te", "dei\u00b7nes", "Le\u00b7bens", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "VAINF", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.15": {"line.1": {"text": "Als ein Zug voll Abenteuer-Sehnsucht", "tokens": ["Als", "ein", "Zug", "voll", "A\u00b7ben\u00b7teu\u00b7er\u00b7Sehn\u00b7sucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJD", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und voll Schw\u00e4rmerei die Menschen ergriff", "tokens": ["Und", "voll", "Schw\u00e4r\u00b7me\u00b7rei", "die", "Men\u00b7schen", "er\u00b7griff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "NN", "ART", "NN", "VVFIN"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und r\u00fcckw\u00e4rts nach Morgen f\u00fchrte,", "tokens": ["Und", "r\u00fcck\u00b7w\u00e4rts", "nach", "Mor\u00b7gen", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und sich daheim mit der Liebe verband,", "tokens": ["Und", "sich", "da\u00b7heim", "mit", "der", "Lie\u00b7be", "ver\u00b7band", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "---+--+--+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da bl\u00fchtest du im S\u00fcden auf", "tokens": ["Da", "bl\u00fch\u00b7test", "du", "im", "S\u00fc\u00b7den", "auf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Voll Anmuth,", "tokens": ["Voll", "An\u00b7muth", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "In unerreichtem Sprachwohllaut.", "tokens": ["In", "un\u00b7er\u00b7reich\u00b7tem", "Sprach\u00b7wohl\u00b7laut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Damals als ein edler S\u00e4nger sang:", "tokens": ["Da\u00b7mals", "als", "ein", "ed\u00b7ler", "S\u00e4n\u00b7ger", "sang", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Durchs\u00fc\u00dfet und gebl\u00fcmet sind die reinen Frauen,", "tokens": ["Durch\u00b7s\u00fc\u00b7\u00dfet", "und", "ge\u00b7bl\u00fc\u00b7met", "sind", "die", "rei\u00b7nen", "Frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es ist so wonnigliches nicht zu schauen", "tokens": ["Es", "ist", "so", "won\u00b7nig\u00b7li\u00b7ches", "nicht", "zu", "schau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In L\u00fcften noch auf Erden, noch in allen gr\u00fcnen Auen.", "tokens": ["In", "L\u00fcf\u00b7ten", "noch", "auf", "Er\u00b7den", ",", "noch", "in", "al\u00b7len", "gr\u00fc\u00b7nen", "Au\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "NN", "$,", "ADV", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Aber noch war Nacht um dich her,", "tokens": ["A\u00b7ber", "noch", "war", "Nacht", "um", "dich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Stokfinstere graunvolle Nacht.", "tokens": ["Stok\u00b7fins\u00b7te\u00b7re", "graun\u00b7vol\u00b7le", "Nacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Da kam eine Zeit, die war wie heute.", "tokens": ["Da", "kam", "ei\u00b7ne", "Zeit", ",", "die", "war", "wie", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "VAFIN", "KOKOM", "ADV", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "An allen Ecken und Enden g\u00e4hrte es.", "tokens": ["An", "al\u00b7len", "E\u00b7cken", "und", "En\u00b7den", "g\u00e4hr\u00b7te", "es", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und die Menschen erfa\u00dfte ein Sehnen", "tokens": ["Und", "die", "Men\u00b7schen", "er\u00b7fa\u00df\u00b7te", "ein", "Seh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Und ein Hunger nach Licht und geistiger Speise.", "tokens": ["Und", "ein", "Hun\u00b7ger", "nach", "Licht", "und", "geis\u00b7ti\u00b7ger", "Spei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Da trat ein Mann auf und verdeutschte ein Buch,", "tokens": ["Da", "trat", "ein", "Mann", "auf", "und", "ver\u00b7deutschte", "ein", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das hat schon genug Blut gekostet auf Erden.", "tokens": ["Das", "hat", "schon", "ge\u00b7nug", "Blut", "ge\u00b7kos\u00b7tet", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "NN", "VVPP", "APPR", "NN", "$."], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und seine Sprache in dem Buch war wunderbar,", "tokens": ["Und", "sei\u00b7ne", "Spra\u00b7che", "in", "dem", "Buch", "war", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Voll Kraft und M\u00e4nnlichkeit", "tokens": ["Voll", "Kraft", "und", "M\u00e4nn\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Und doch voll hoher Sch\u00f6nheit fast \u00fcberall:", "tokens": ["Und", "doch", "voll", "ho\u00b7her", "Sch\u00f6n\u00b7heit", "fast", "\u00fc\u00b7be\u00b7rall", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ADJA", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.18": {"line.1": {"text": "Sie weinet des Nachts,", "tokens": ["Sie", "wei\u00b7net", "des", "Nachts", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Da\u00df ihr die Thr\u00e4nen \u00fcber die Backen laufen,", "tokens": ["Da\u00df", "ihr", "die", "Thr\u00e4\u00b7nen", "\u00fc\u00b7ber", "die", "Ba\u00b7cken", "lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es ist Niemand unter allen ihren Freunden,", "tokens": ["Es", "ist", "Nie\u00b7mand", "un\u00b7ter", "al\u00b7len", "ih\u00b7ren", "Freun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Der sie tr\u00f6ste.", "tokens": ["Der", "sie", "tr\u00f6s\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.19": {"line.1": {"text": "Die Augen der Blinden", "tokens": ["Die", "Au\u00b7gen", "der", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Werden aus dem Dunkel und Finsterni\u00df sehen.", "tokens": ["Wer\u00b7den", "aus", "dem", "Dun\u00b7kel", "und", "Fins\u00b7ter\u00b7ni\u00df", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und die Elenden werden wieder Freude haben \u2013", "tokens": ["Und", "die", "E\u00b7len\u00b7den", "wer\u00b7den", "wie\u00b7der", "Freu\u00b7de", "ha\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "NN", "VAFIN", "$("], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und die Armen unter den Menschen werden fr\u00f6hlich sein. \u2013", "tokens": ["Und", "die", "Ar\u00b7men", "un\u00b7ter", "den", "Men\u00b7schen", "wer\u00b7den", "fr\u00f6h\u00b7lich", "sein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VAFIN", "ADJD", "VAINF", "$.", "$("], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.20": {"line.1": {"text": "Nun ruhet doch alle Welt und ist stille,", "tokens": ["Nun", "ru\u00b7het", "doch", "al\u00b7le", "Welt", "und", "ist", "stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "KON", "VAFIN", "ADJA", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und jauchzet fr\u00f6hlich.", "tokens": ["Und", "jauch\u00b7zet", "fr\u00f6h\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Wenn ich mit Menschen- und mit Engelzungen redete,", "tokens": ["Wenn", "ich", "mit", "Men\u00b7schen", "und", "mit", "En\u00b7gel\u00b7zun\u00b7gen", "re\u00b7de\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "TRUNC", "KON", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Und h\u00e4tte der Liebe nicht,", "tokens": ["Und", "h\u00e4t\u00b7te", "der", "Lie\u00b7be", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "So w\u00e4re ich ein t\u00f6nend Erz,", "tokens": ["So", "w\u00e4\u00b7re", "ich", "ein", "t\u00f6\u00b7nend", "Erz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Oder eine klingende Schelle.", "tokens": ["O\u00b7der", "ei\u00b7ne", "klin\u00b7gen\u00b7de", "Schel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "[die Liebe] freuet sich nicht der Ungerechtigkeit,", "tokens": ["die", "Lie\u00b7be", "freu\u00b7et", "sich", "nicht", "der", "Un\u00b7ge\u00b7rech\u00b7tig\u00b7keit", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "VVFIN", "PRF", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.2": {"text": "Sie freuet sich aber der Wahrheit!", "tokens": ["Sie", "freu\u00b7et", "sich", "a\u00b7ber", "der", "Wahr\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.22": {"line.1": {"text": "Es war ein streitbarer Held,", "tokens": ["Es", "war", "ein", "streit\u00b7ba\u00b7rer", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und manch sch\u00f6nen Sieg hat er dem Dunkel abgerungen.", "tokens": ["Und", "manch", "sch\u00f6\u00b7nen", "Sieg", "hat", "er", "dem", "Dun\u00b7kel", "ab\u00b7ge\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "--+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Aber auf halbem Wege blieb er stehen,", "tokens": ["A\u00b7ber", "auf", "hal\u00b7bem", "We\u00b7ge", "blieb", "er", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Und mit ihm ist es finster blieben,", "tokens": ["Und", "mit", "ihm", "ist", "es", "fins\u00b7ter", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VAFIN", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Finster vor ihm", "tokens": ["Fins\u00b7ter", "vor", "ihm"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "PPER"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Und finster nach ihm.", "tokens": ["Und", "fins\u00b7ter", "nach", "ihm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Denn h\u00f6re es wohl, du Welt!", "tokens": ["Denn", "h\u00f6\u00b7re", "es", "wohl", ",", "du", "Welt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PPER", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Solche, die sich J\u00fcnger dessen nennen,", "tokens": ["Sol\u00b7che", ",", "die", "sich", "J\u00fcn\u00b7ger", "des\u00b7sen", "nen\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "$,", "PRELS", "PRF", "NE", "PDS", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Der doch gesprochen: Liebet euch unter einander!", "tokens": ["Der", "doch", "ge\u00b7spro\u00b7chen", ":", "Lie\u00b7bet", "euch", "un\u00b7ter", "ein\u00b7an\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "$.", "VVFIN", "PPER", "APPR", "PRF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Die sind die \u00e4rgsten Hasser geworden", "tokens": ["Die", "sind", "die", "\u00e4rgs\u00b7ten", "Has\u00b7ser", "ge\u00b7wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VAPP"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und Feinde des Menschengeschlechts auf Erden.", "tokens": ["Und", "Fein\u00b7de", "des", "Men\u00b7schen\u00b7ge\u00b7schlechts", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.23": {"line.1": {"text": "Die M\u00e4rchen und Poesien eines Buches", "tokens": ["Die", "M\u00e4r\u00b7chen", "und", "Poe\u00b7si\u00b7en", "ei\u00b7nes", "Bu\u00b7ches"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Haben sie zu einem Verdummungshammer gemacht,", "tokens": ["Ha\u00b7ben", "sie", "zu", "ei\u00b7nem", "Ver\u00b7dum\u00b7mungs\u00b7ham\u00b7mer", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Damit sie den Kopf des Volkes stumpfsinnig schlagen", "tokens": ["Da\u00b7mit", "sie", "den", "Kopf", "des", "Vol\u00b7kes", "stumpf\u00b7sin\u00b7nig", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADJD", "VVINF"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Bis auf den heutigen Tag.", "tokens": ["Bis", "auf", "den", "heu\u00b7ti\u00b7gen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "O wie f\u00fcrchterlich haben sie gew\u00fcthet!", "tokens": ["O", "wie", "f\u00fcrch\u00b7ter\u00b7lich", "ha\u00b7ben", "sie", "ge\u00b7w\u00fct\u00b7het", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "ADJD", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Die Erde,", "tokens": ["Die", "Er\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Darauf alle Menschen sollen Freude haben,", "tokens": ["Da\u00b7rauf", "al\u00b7le", "Men\u00b7schen", "sol\u00b7len", "Freu\u00b7de", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Die haben sie zu einem Jammerthale gemacht.", "tokens": ["Die", "ha\u00b7ben", "sie", "zu", "ei\u00b7nem", "Jam\u00b7mer\u00b7tha\u00b7le", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.9": {"text": "Sie haben so lange geschrieen: die Erde ist ein Jammerthal!", "tokens": ["Sie", "ha\u00b7ben", "so", "lan\u00b7ge", "ge\u00b7schri\u00b7een", ":", "die", "Er\u00b7de", "ist", "ein", "Jam\u00b7mer\u00b7thal", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$.", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--+--+-+-+-+", "measure": "amphibrach.tetra.plus"}, "line.10": {"text": "Bis sie es wirklich schier ist geworden.", "tokens": ["Bis", "sie", "es", "wirk\u00b7lich", "schier", "ist", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADJD", "VAFIN", "VAPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Zum gemeinen Manne haben sie gesprochen:", "tokens": ["Zum", "ge\u00b7mei\u00b7nen", "Man\u00b7ne", "ha\u00b7ben", "sie", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Qu\u00e4l' dich nur hier f\u00fcr uns", "tokens": ["Qu\u00e4l'", "dich", "nur", "hier", "f\u00fcr", "uns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Und la\u00df dich schinden hier f\u00fcr uns", "tokens": ["Und", "la\u00df", "dich", "schin\u00b7den", "hier", "f\u00fcr", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "VVFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und sei ein getreuer Sklav'", "tokens": ["Und", "sei", "ein", "ge\u00b7treu\u00b7er", "Skla\u00b7v'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.15": {"text": "Und muckse und murre nicht;", "tokens": ["Und", "muck\u00b7se", "und", "mur\u00b7re", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PTKNEG", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Wenn du aber erst todt bist,", "tokens": ["Wenn", "du", "a\u00b7ber", "erst", "todt", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.17": {"text": "Nachher wird Alles gut werden.", "tokens": ["Nach\u00b7her", "wird", "Al\u00b7les", "gut", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Und es giebt deren,", "tokens": ["Und", "es", "giebt", "de\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PDS", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Die hassen den Menschen noch \u00fcber den Tod hinaus.", "tokens": ["Die", "has\u00b7sen", "den", "Men\u00b7schen", "noch", "\u00fc\u00b7ber", "den", "Tod", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.20": {"text": "Sie lassen ja die Leichen nicht in ihren Gr\u00e4bern ruhen.", "tokens": ["Sie", "las\u00b7sen", "ja", "die", "Lei\u00b7chen", "nicht", "in", "ih\u00b7ren", "Gr\u00e4\u00b7bern", "ru\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.24": {"line.1": {"text": "Wenn der Arme und Elende krank vor ihnen liegt", "tokens": ["Wenn", "der", "Ar\u00b7me", "und", "E\u00b7len\u00b7de", "krank", "vor", "ih\u00b7nen", "liegt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "NN", "ADJD", "APPR", "PPER", "VVFIN"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und hilflos ist vor Kummer und Gram,", "tokens": ["Und", "hil\u00b7flos", "ist", "vor", "Kum\u00b7mer", "und", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Dann schlagen sie ihm sein Herz noch mehr entzwei", "tokens": ["Dann", "schla\u00b7gen", "sie", "ihm", "sein", "Herz", "noch", "mehr", "ent\u00b7zwei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PPOSAT", "NN", "ADV", "ADV", "PTKVZ"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Mit H\u00f6lle und mit Teufel nach dem Tode,", "tokens": ["Mit", "H\u00f6l\u00b7le", "und", "mit", "Teu\u00b7fel", "nach", "dem", "To\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Bis er schier wahnsinnig wird vor Angst", "tokens": ["Bis", "er", "schier", "wahn\u00b7sin\u00b7nig", "wird", "vor", "Angst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "APPR", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Und zu Allem, was sie wollen, ja sagt,", "tokens": ["Und", "zu", "Al\u00b7lem", ",", "was", "sie", "wol\u00b7len", ",", "ja", "sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "$,", "PRELS", "PPER", "VMFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Da er noch lebt.", "tokens": ["Da", "er", "noch", "lebt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Und brauchte sie doch blo\u00df einer zu fragen:", "tokens": ["Und", "brauch\u00b7te", "sie", "doch", "blo\u00df", "ei\u00b7ner", "zu", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Wenn du mir so Angst machst", "tokens": ["Wenn", "du", "mir", "so", "Angst", "machst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Und es so greulich dort ist,", "tokens": ["Und", "es", "so", "greu\u00b7lich", "dort", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJD", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Wie bist du denn von dort herausgekommen?", "tokens": ["Wie", "bist", "du", "denn", "von", "dort", "her\u00b7aus\u00b7ge\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Denn du mu\u00dft doch dort gewesen sein,", "tokens": ["Denn", "du", "mu\u00dft", "doch", "dort", "ge\u00b7we\u00b7sen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ADV", "ADV", "VAPP", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "Da du es so Alles haarklein wei\u00dft.", "tokens": ["Da", "du", "es", "so", "Al\u00b7les", "haar\u00b7klein", "wei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "PIS", "ADJD", "VVFIN", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.14": {"text": "So m\u00fc\u00dften sie ja auf der Stelle verstummen.", "tokens": ["So", "m\u00fc\u00df\u00b7ten", "sie", "ja", "auf", "der", "Stel\u00b7le", "ver\u00b7stum\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.15": {"text": "Aber das fragt sie keiner,", "tokens": ["A\u00b7ber", "das", "fragt", "sie", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "PIS", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.16": {"text": "So brauchen sie auch nicht darauf zu antworten.", "tokens": ["So", "brau\u00b7chen", "sie", "auch", "nicht", "da\u00b7rauf", "zu", "ant\u00b7wor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.17": {"text": "Und sie machen mit den Menschen, was sie wollen.", "tokens": ["Und", "sie", "ma\u00b7chen", "mit", "den", "Men\u00b7schen", ",", "was", "sie", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.18": {"text": "Und das ist ein gr\u00e4\u00dfliches Elend", "tokens": ["Und", "das", "ist", "ein", "gr\u00e4\u00df\u00b7li\u00b7ches", "E\u00b7lend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Und das F\u00fcrchterlichste von Allem,", "tokens": ["Und", "das", "F\u00fcrch\u00b7ter\u00b7lichs\u00b7te", "von", "Al\u00b7lem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PIS", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.20": {"text": "Was menschenliebende Augen sehen m\u00fcssen auf Erden.", "tokens": ["Was", "men\u00b7schen\u00b7lie\u00b7ben\u00b7de", "Au\u00b7gen", "se\u00b7hen", "m\u00fcs\u00b7sen", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VVINF", "VMFIN", "APPR", "NN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}}, "stanza.25": {"line.1": {"text": "Und sollten doch den Armen lieber sagen:", "tokens": ["Und", "soll\u00b7ten", "doch", "den", "Ar\u00b7men", "lie\u00b7ber", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir wollen dich fr\u00f6hlich machen im Leben", "tokens": ["Wir", "wol\u00b7len", "dich", "fr\u00f6h\u00b7lich", "ma\u00b7chen", "im", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADJD", "VVINF", "APPRART", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und nicht traurig im Tode.", "tokens": ["Und", "nicht", "trau\u00b7rig", "im", "To\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Du sollst leben mit Freude,", "tokens": ["Du", "sollst", "le\u00b7ben", "mit", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "NN", "$,"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "So sollst du sterben ohne Angst", "tokens": ["So", "sollst", "du", "ster\u00b7ben", "oh\u00b7ne", "Angst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ohne Groll,", "tokens": ["Und", "oh\u00b7ne", "Groll", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Sondern mit Dank f\u00fcr die Freude auf Erden.", "tokens": ["Son\u00b7dern", "mit", "Dank", "f\u00fcr", "die", "Freu\u00b7de", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.8": {"text": "Denn die Freude ist g\u00f6ttlich,", "tokens": ["Denn", "die", "Freu\u00b7de", "ist", "g\u00f6tt\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Und die Liebe ist die k\u00f6stlichste der Freuden.", "tokens": ["Und", "die", "Lie\u00b7be", "ist", "die", "k\u00f6st\u00b7lichs\u00b7te", "der", "Freu\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "ADJA", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.10": {"text": "Wer aber fr\u00f6hlich wird, der wird auch gut. \u2013", "tokens": ["Wer", "a\u00b7ber", "fr\u00f6h\u00b7lich", "wird", ",", "der", "wird", "auch", "gut", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADV", "ADJD", "VAFIN", "$,", "PRELS", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Aber der Mann, der auf halbem Wege stehen blieb,", "tokens": ["A\u00b7ber", "der", "Mann", ",", "der", "auf", "hal\u00b7bem", "We\u00b7ge", "ste\u00b7hen", "blieb", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVINF", "VVFIN", "$,"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Eine Sprache hat er dem Volke geschaffen,", "tokens": ["Ei\u00b7ne", "Spra\u00b7che", "hat", "er", "dem", "Vol\u00b7ke", "ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ein gutes Schwert f\u00fcr kommende Zeiten.", "tokens": ["Ein", "gu\u00b7tes", "Schwert", "f\u00fcr", "kom\u00b7men\u00b7de", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.27": {"line.1": {"text": "Wenn ringsum Kriege und St\u00fcrme tobten,", "tokens": ["Wenn", "ring\u00b7sum", "Krie\u00b7ge", "und", "St\u00fcr\u00b7me", "tob\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Alles auf den Armen einhieb und schlug,", "tokens": ["Und", "Al\u00b7les", "auf", "den", "Ar\u00b7men", "ein\u00b7hieb", "und", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dann sa\u00df der Arme und weinte still f\u00fcr sich", "tokens": ["Dann", "sa\u00df", "der", "Ar\u00b7me", "und", "wein\u00b7te", "still", "f\u00fcr", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "ADJD", "APPR", "PRF"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und las in dem Buch, so lernte er die Sprache,", "tokens": ["Und", "las", "in", "dem", "Buch", ",", "so", "lern\u00b7te", "er", "die", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und die schlichte, sinnige Ausdrucksweise", "tokens": ["Und", "die", "schlich\u00b7te", ",", "sin\u00b7ni\u00b7ge", "Aus\u00b7drucks\u00b7wei\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wuchs ihm tief in's Herz hinein.", "tokens": ["Wuchs", "ihm", "tief", "in's", "Herz", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Auf diesem Boden bl\u00fchete ein Baum empor,", "tokens": ["Auf", "die\u00b7sem", "Bo\u00b7den", "bl\u00fc\u00b7he\u00b7te", "ein", "Baum", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der soll noch herrliche Fr\u00fcchte tragen.", "tokens": ["Der", "soll", "noch", "herr\u00b7li\u00b7che", "Fr\u00fcch\u00b7te", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "Aber es kamen Tage des Jammers und der Noth", "tokens": ["A\u00b7ber", "es", "ka\u00b7men", "Ta\u00b7ge", "des", "Jam\u00b7mers", "und", "der", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NN", "ART", "NN", "KON", "ART", "NN"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Und wurde schier finsterer um dich her,", "tokens": ["Und", "wur\u00b7de", "schier", "fins\u00b7te\u00b7rer", "um", "dich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADJD", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Als es vordem jemals gewesen.", "tokens": ["Als", "es", "vor\u00b7dem", "je\u00b7mals", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VAPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und die Menschen erholten sich allm\u00e4hlig", "tokens": ["Und", "die", "Men\u00b7schen", "er\u00b7hol\u00b7ten", "sich", "all\u00b7m\u00e4h\u00b7lig"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "ADJD"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und sahen dich in Nebel und Dunkel geh\u00fcllt.", "tokens": ["Und", "sa\u00b7hen", "dich", "in", "Ne\u00b7bel", "und", "Dun\u00b7kel", "ge\u00b7h\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Da kam ein Mann auf,", "tokens": ["Da", "kam", "ein", "Mann", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Der k\u00e4mpfte mit scharfem Schwert und scharfem Wort", "tokens": ["Der", "k\u00e4mpf\u00b7te", "mit", "schar\u00b7fem", "Schwert", "und", "schar\u00b7fem", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Und brachte Vernunft und Licht und Klarheit", "tokens": ["Und", "brach\u00b7te", "Ver\u00b7nunft", "und", "Licht", "und", "Klar\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "KON", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "In eine verkommene Welt.", "tokens": ["In", "ei\u00b7ne", "ver\u00b7kom\u00b7me\u00b7ne", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.10": {"text": "Die Gesetze des Sch\u00f6nen hat er den Menschen vorgezeichnet", "tokens": ["Die", "Ge\u00b7set\u00b7ze", "des", "Sch\u00f6\u00b7nen", "hat", "er", "den", "Men\u00b7schen", "vor\u00b7ge\u00b7zeich\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVFIN"], "meter": "+-+--+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.11": {"text": "Und lehrte: frei sein von Vorurtheil.", "tokens": ["Und", "lehr\u00b7te", ":", "frei", "sein", "von", "Vor\u00b7urt\u00b7heil", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ADJD", "VAINF", "APPR", "NN", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.12": {"text": "Und lehrte es in klarer, durchsichtiger Sprache:", "tokens": ["Und", "lehr\u00b7te", "es", "in", "kla\u00b7rer", ",", "durch\u00b7sich\u00b7ti\u00b7ger", "Spra\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.29": {"line.1": {"text": "Es ist nicht jedem Auge gegeben, die H\u00fclle zu durchschauen,", "tokens": ["Es", "ist", "nicht", "je\u00b7dem", "Au\u00b7ge", "ge\u00b7ge\u00b7ben", ",", "die", "H\u00fcl\u00b7le", "zu", "durch\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "In welche der Dichter eine Wahrheit kleidet. \u2013", "tokens": ["In", "wel\u00b7che", "der", "Dich\u00b7ter", "ei\u00b7ne", "Wahr\u00b7heit", "klei\u00b7det", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.30": {"line.1": {"text": "Was ist ein Held ohne Menschenliebe?", "tokens": ["Was", "ist", "ein", "Held", "oh\u00b7ne", "Men\u00b7schen\u00b7lie\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Nun, wen lieben zwei", "tokens": ["Nun", ",", "wen", "lie\u00b7ben", "zwei"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VVFIN", "CARD"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Von euch am meisten? Macht, sagt an, ihr schweigt?", "tokens": ["Von", "euch", "am", "meis\u00b7ten", "?", "Macht", ",", "sagt", "an", ",", "ihr", "schweigt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKA", "PIS", "$.", "NN", "$,", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Ringe wirken nur zur\u00fcck und nicht", "tokens": ["Die", "Rin\u00b7ge", "wir\u00b7ken", "nur", "zu\u00b7r\u00fcck", "und", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "KON", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nach au\u00dfen? Jeder liebt sich selber nur", "tokens": ["Nach", "au\u00b7\u00dfen", "?", "Je\u00b7der", "liebt", "sich", "sel\u00b7ber", "nur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "$.", "PIS", "VVFIN", "PRF", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Am meisten? \u2013 O so seid ihr alle drei", "tokens": ["Am", "meis\u00b7ten", "?", "\u2013", "O", "so", "seid", "ihr", "al\u00b7le", "drei"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "PIS", "$.", "$(", "NE", "ADV", "VAFIN", "PPER", "PIAT", "CARD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Betrogene Betr\u00fcger!", "tokens": ["Be\u00b7tro\u00b7ge\u00b7ne", "Be\u00b7tr\u00fc\u00b7ger", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+---+-", "measure": "dactylic.init"}}, "stanza.32": {"line.1": {"text": "Er blieb im Leben einsam und f\u00fchlte sich einsam.", "tokens": ["Er", "blieb", "im", "Le\u00b7ben", "ein\u00b7sam", "und", "f\u00fchl\u00b7te", "sich", "ein\u00b7sam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADJD", "KON", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Da leuchtete ein Doppelstern empor am Himmel,", "tokens": ["Da", "leuch\u00b7te\u00b7te", "ein", "Dop\u00b7pels\u00b7tern", "em\u00b7por", "am", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und zwei Cedern bl\u00fcheten zusammen auf der Erde,", "tokens": ["Und", "zwei", "Ce\u00b7dern", "bl\u00fc\u00b7he\u00b7ten", "zu\u00b7sam\u00b7men", "auf", "der", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "Herrliche Gestalten!", "tokens": ["Herr\u00b7li\u00b7che", "Ge\u00b7stal\u00b7ten", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Einer an dem andern rankten sie sich empor zu gleicher Zeit,", "tokens": ["Ei\u00b7ner", "an", "dem", "an\u00b7dern", "rank\u00b7ten", "sie", "sich", "em\u00b7por", "zu", "glei\u00b7cher", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "ADJA", "VVFIN", "PPER", "PRF", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": "Ein nie gesehenes Schauspiel unter allen Nationen,", "tokens": ["Ein", "nie", "ge\u00b7se\u00b7he\u00b7nes", "Schau\u00b7spiel", "un\u00b7ter", "al\u00b7len", "Na\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Und wurden vollkommener einer durch den andern,", "tokens": ["Und", "wur\u00b7den", "voll\u00b7kom\u00b7me\u00b7ner", "ei\u00b7ner", "durch", "den", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ART", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bis er dahin ging allzufr\u00fch,", "tokens": ["Bis", "er", "da\u00b7hin", "ging", "all\u00b7zu\u00b7fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der eine Sprache schuf,", "tokens": ["Der", "ei\u00b7ne", "Spra\u00b7che", "schuf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Darin jedes Wort, einer vollen Aehre gleich,", "tokens": ["Da\u00b7rin", "je\u00b7des", "Wort", ",", "ei\u00b7ner", "vol\u00b7len", "A\u00b7eh\u00b7re", "gleich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "$,", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "--+-+--+----+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Sich beugt unter der Wucht der Gedanken:", "tokens": ["Sich", "beugt", "un\u00b7ter", "der", "Wucht", "der", "Ge\u00b7dan\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.33": {"line.1": {"text": "Der Menschheit W\u00fcrde ist in eure Hand gegeben,", "tokens": ["Der", "Menschheit", "W\u00fcr\u00b7de", "ist", "in", "eu\u00b7re", "Hand", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Bewahret sie! \u2013 \u2013", "tokens": ["Be\u00b7wah\u00b7ret", "sie", "!", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Erhebet euch mit k\u00fchnem Fl\u00fcgel", "tokens": ["Er\u00b7he\u00b7bet", "euch", "mit", "k\u00fch\u00b7nem", "Fl\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hoch \u00fcber euren Zeitenlauf!", "tokens": ["Hoch", "\u00fc\u00b7ber", "eu\u00b7ren", "Zei\u00b7ten\u00b7lauf", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Fern d\u00e4mmre schon in eurem Spiegel", "tokens": ["Fern", "d\u00e4mm\u00b7re", "schon", "in", "eu\u00b7rem", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das kommende Jahrhundert auf. \u2013 \u2013", "tokens": ["Das", "kom\u00b7men\u00b7de", "Jahr\u00b7hun\u00b7dert", "auf", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.7": {"text": "Der fortgeschritt'ne Mensch tr\u00e4gt auf erhob'nen Schwingen", "tokens": ["Der", "fort\u00b7ge\u00b7schritt'\u00b7ne", "Mensch", "tr\u00e4gt", "auf", "er\u00b7hob'\u00b7nen", "Schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dankbar die Kunst mit sich empor,", "tokens": ["Dank\u00b7bar", "die", "Kunst", "mit", "sich", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "APPR", "PRF", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Und neue Sch\u00f6nheitswelten springen", "tokens": ["Und", "neu\u00b7e", "Sch\u00f6n\u00b7heits\u00b7wel\u00b7ten", "sprin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Aus der bereicherten Natur hervor. \u2013", "tokens": ["Aus", "der", "be\u00b7rei\u00b7cher\u00b7ten", "Na\u00b7tur", "her\u00b7vor", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Und der Erste blieb allein,", "tokens": ["Und", "der", "Ers\u00b7te", "blieb", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ADV", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "Einer unter den Erdenmenschen,", "tokens": ["Ei\u00b7ner", "un\u00b7ter", "den", "Er\u00b7den\u00b7men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "$,"], "meter": "+-+---+--", "measure": "unknown.measure.tri"}, "line.13": {"text": "Der das Gl\u00fcck ertragen konnte:", "tokens": ["Der", "das", "Gl\u00fcck", "er\u00b7tra\u00b7gen", "konn\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Bedecke deinen Himmel, Zeus,", "tokens": ["Be\u00b7de\u00b7cke", "dei\u00b7nen", "Him\u00b7mel", ",", "Zeus", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Wolkendunst", "tokens": ["Mit", "Wol\u00b7ken\u00b7dunst"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und \u00fcbe, dem Knaben gleich,", "tokens": ["Und", "\u00fc\u00b7be", ",", "dem", "Kna\u00b7ben", "gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der Disteln k\u00f6pft,", "tokens": ["Der", "Dis\u00b7teln", "k\u00f6pft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "An Eichen dich und Bergesh\u00f6h'n!", "tokens": ["An", "Ei\u00b7chen", "dich", "und", "Ber\u00b7ges\u00b7h\u00f6h'n", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mu\u00dft mir meine Erde", "tokens": ["Mu\u00dft", "mir", "mei\u00b7ne", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Doch lassen steh'n", "tokens": ["Doch", "las\u00b7sen", "steh'n"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVINF", "VVINF"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Und meine H\u00fctte, die du nicht gebaut,", "tokens": ["Und", "mei\u00b7ne", "H\u00fct\u00b7te", ",", "die", "du", "nicht", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und meinen Herd,", "tokens": ["Und", "mei\u00b7nen", "Herd", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Um dessen Gluth", "tokens": ["Um", "des\u00b7sen", "Gluth"], "token_info": ["word", "word", "word"], "pos": ["KOUI", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Du mich beneidest.", "tokens": ["Du", "mich", "be\u00b7nei\u00b7dest", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.35": {"line.1": {"text": "Ich dich ehren? wof\u00fcr?", "tokens": ["Ich", "dich", "eh\u00b7ren", "?", "wo\u00b7f\u00fcr", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "PRF", "VVINF", "$.", "PWAV", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Hast du die Schmerzen gelindert", "tokens": ["Hast", "du", "die", "Schmer\u00b7zen", "ge\u00b7lin\u00b7dert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Je des Beladenen?", "tokens": ["Je", "des", "Be\u00b7la\u00b7de\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.4": {"text": "Hast du die Thr\u00e4nen gestillet", "tokens": ["Hast", "du", "die", "Thr\u00e4\u00b7nen", "ge\u00b7stil\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Je des Ge\u00e4ngsteten?", "tokens": ["Je", "des", "Ge\u00b7\u00e4ngs\u00b7te\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.6": {"text": "Hat nicht mich zum Manne geschmiedet", "tokens": ["Hat", "nicht", "mich", "zum", "Man\u00b7ne", "ge\u00b7schmie\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "PPER", "APPRART", "NN", "VVPP"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Die allm\u00e4chtige Zeit", "tokens": ["Die", "all\u00b7m\u00e4ch\u00b7ti\u00b7ge", "Zeit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und das ewige Schicksal,", "tokens": ["Und", "das", "e\u00b7wi\u00b7ge", "Schick\u00b7sal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.9": {"text": "Meine Herren und deine?", "tokens": ["Mei\u00b7ne", "Her\u00b7ren", "und", "dei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.10": {"text": "Hier sitz' ich, forme Menschen", "tokens": ["Hier", "sitz'", "ich", ",", "for\u00b7me", "Men\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Nach meinem Bilde,", "tokens": ["Nach", "mei\u00b7nem", "Bil\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Ein Geschlecht, das mir gleich sei,", "tokens": ["Ein", "Ge\u00b7schlecht", ",", "das", "mir", "gleich", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "Zu leiden, zu weinen,", "tokens": ["Zu", "lei\u00b7den", ",", "zu", "wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.14": {"text": "Zu genie\u00dfen und zu freuen sich", "tokens": ["Zu", "ge\u00b7nie\u00b7\u00dfen", "und", "zu", "freu\u00b7en", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "PRF"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.15": {"text": "Und dein nicht zu achten", "tokens": ["Und", "dein", "nicht", "zu", "ach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "PTKNEG", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.16": {"text": "Wie ich.", "tokens": ["Wie", "ich", "."], "token_info": ["word", "word", "punct"], "pos": ["PWAV", "PPER", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.36": {"line.1": {"text": "Nie hat in Worten unmittelbarer ein Mensch", "tokens": ["Nie", "hat", "in", "Wor\u00b7ten", "un\u00b7mit\u00b7tel\u00b7ba\u00b7rer", "ein", "Mensch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NN", "ADJA", "ART", "NN"], "meter": "++-+-+---+-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "An das Herz des Menschen gegriffen:", "tokens": ["An", "das", "Herz", "des", "Men\u00b7schen", "ge\u00b7grif\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.37": {"line.1": {"text": "Der Menschheit ganzer Jammer packt mich an.", "tokens": ["Der", "Menschheit", "gan\u00b7zer", "Jam\u00b7mer", "packt", "mich", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.38": {"line.1": {"text": "Wer f\u00fchlet,", "tokens": ["Wer", "f\u00fch\u00b7let", ","], "token_info": ["word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Wie w\u00fchlet", "tokens": ["Wie", "w\u00fch\u00b7let"], "token_info": ["word", "word"], "pos": ["PWAV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Der Schmerz mir im Gebein?", "tokens": ["Der", "Schmerz", "mir", "im", "Ge\u00b7bein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Wohin ich immer gehe,", "tokens": ["Wo\u00b7hin", "ich", "im\u00b7mer", "ge\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie weh, wie weh, wie wehe", "tokens": ["Wie", "weh", ",", "wie", "weh", ",", "wie", "we\u00b7he"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wird mir im Busen hier!", "tokens": ["Wird", "mir", "im", "Bu\u00b7sen", "hier", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin, ach! kaum alleine,", "tokens": ["Ich", "bin", ",", "ach", "!", "kaum", "al\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ITJ", "$.", "ADV", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich wein', ich wein', ich weine,", "tokens": ["Ich", "wein'", ",", "ich", "wein'", ",", "ich", "wei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Das Herz zerbricht in mir!", "tokens": ["Das", "Herz", "zer\u00b7bricht", "in", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Das Alte ist vergangen,", "tokens": ["Das", "Al\u00b7te", "ist", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und es ist Alles neu geworden.", "tokens": ["Und", "es", "ist", "Al\u00b7les", "neu", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sch\u00f6nheit, auf Unrecht aufgebaut, ist keine Sch\u00f6nheit!", "tokens": ["Die", "Sch\u00f6n\u00b7heit", ",", "auf", "Un\u00b7recht", "auf\u00b7ge\u00b7baut", ",", "ist", "kei\u00b7ne", "Sch\u00f6n\u00b7heit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "VVPP", "$,", "VAFIN", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Es ist ein h\u00e4\u00dflicher Flecken an ihr,", "tokens": ["Es", "ist", "ein", "h\u00e4\u00df\u00b7li\u00b7cher", "Fle\u00b7cken", "an", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der sie zu Grunde richtet.", "tokens": ["Der", "sie", "zu", "Grun\u00b7de", "rich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Darum ist die Sch\u00f6nheit Griechenlands untergegangen,", "tokens": ["Da\u00b7rum", "ist", "die", "Sch\u00f6n\u00b7heit", "Grie\u00b7chen\u00b7lands", "un\u00b7ter\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "NE", "VVPP", "$,"], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Denn sie war gebaut auf Sklaverei.", "tokens": ["Denn", "sie", "war", "ge\u00b7baut", "auf", "Skla\u00b7ve\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Die Sch\u00f6nheit, die wir aufrichten wollen,", "tokens": ["Die", "Sch\u00f6n\u00b7heit", ",", "die", "wir", "auf\u00b7rich\u00b7ten", "wol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Soll gebaut sein auf Menschenliebe,", "tokens": ["Soll", "ge\u00b7baut", "sein", "auf", "Men\u00b7schen\u00b7lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVPP", "VAINF", "APPR", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "Und darum wird sie leben bleiben.", "tokens": ["Und", "da\u00b7rum", "wird", "sie", "le\u00b7ben", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Viele sollen nicht treu sein Einem,", "tokens": ["Vie\u00b7le", "sol\u00b7len", "nicht", "treu", "sein", "Ei\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "ADJD", "VAINF", "PIS", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Aber Einer soll treu sein Vielen.", "tokens": ["A\u00b7ber", "Ei\u00b7ner", "soll", "treu", "sein", "Vie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Viele sollen nicht dankbar sein Einem,", "tokens": ["Vie\u00b7le", "sol\u00b7len", "nicht", "dank\u00b7bar", "sein", "Ei\u00b7nem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "ADJD", "VAINF", "PIS", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Aber Einer soll dankbar sein Vielen.", "tokens": ["A\u00b7ber", "Ei\u00b7ner", "soll", "dank\u00b7bar", "sein", "Vie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.42": {"line.1": {"text": "Jeder, der gequ\u00e4lt ist,", "tokens": ["Je\u00b7der", ",", "der", "ge\u00b7qu\u00e4lt", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Soll auf seine gequ\u00e4lten Br\u00fcder sehen,", "tokens": ["Soll", "auf", "sei\u00b7ne", "ge\u00b7qu\u00e4l\u00b7ten", "Br\u00fc\u00b7der", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Da\u00df er ihnen helfe,", "tokens": ["Da\u00df", "er", "ih\u00b7nen", "hel\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "So wird Einer treu sein Vielen.", "tokens": ["So", "wird", "Ei\u00b7ner", "treu", "sein", "Vie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jeder, der minder gequ\u00e4lt ist,", "tokens": ["Je\u00b7der", ",", "der", "min\u00b7der", "ge\u00b7qu\u00e4lt", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.6": {"text": "Soll auf seine Br\u00fcder sehen, die mehr gequ\u00e4lt sind,", "tokens": ["Soll", "auf", "sei\u00b7ne", "Br\u00fc\u00b7der", "se\u00b7hen", ",", "die", "mehr", "ge\u00b7qu\u00e4lt", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Da\u00df er ihnen helfe,", "tokens": ["Da\u00df", "er", "ih\u00b7nen", "hel\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "So wird Einer dankbar sein Vielen.", "tokens": ["So", "wird", "Ei\u00b7ner", "dank\u00b7bar", "sein", "Vie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "PPOSAT", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.43": {"line.1": {"text": "Alles, was den Menschen niedrig macht,", "tokens": ["Al\u00b7les", ",", "was", "den", "Men\u00b7schen", "nied\u00b7rig", "macht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ist in der Treue gegen Einen;", "tokens": ["Ist", "in", "der", "Treu\u00b7e", "ge\u00b7gen", "Ei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "APPR", "ART", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Alles, was den Menschen hoch erhebt,", "tokens": ["Al\u00b7les", ",", "was", "den", "Men\u00b7schen", "hoch", "er\u00b7hebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ist in der Treue gegen Viele.", "tokens": ["Ist", "in", "der", "Treu\u00b7e", "ge\u00b7gen", "Vie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "APPR", "PIS", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wer Vielen treu ist,", "tokens": ["Wer", "Vie\u00b7len", "treu", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Der mu\u00df frei werden;", "tokens": ["Der", "mu\u00df", "frei", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Wer Einem treu ist, der mu\u00df ein Sklave sein", "tokens": ["Wer", "Ei\u00b7nem", "treu", "ist", ",", "der", "mu\u00df", "ein", "Skla\u00b7ve", "sein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "ADJD", "VAFIN", "$,", "ART", "VMFIN", "ART", "NN", "PPOSAT"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Und er wird es bleiben.", "tokens": ["Und", "er", "wird", "es", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "Jeder Erwachsene soll den Kindern dankbar sein.", "tokens": ["Je\u00b7der", "Er\u00b7wach\u00b7se\u00b7ne", "soll", "den", "Kin\u00b7dern", "dank\u00b7bar", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Der Lehrer soll den Sch\u00fclern dankbar sein.", "tokens": ["Der", "Leh\u00b7rer", "soll", "den", "Sch\u00fc\u00b7lern", "dank\u00b7bar", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Gegenw\u00e4rtige soll den Kommenden dankbar sein.", "tokens": ["Der", "Ge\u00b7gen\u00b7w\u00e4r\u00b7ti\u00b7ge", "soll", "den", "Kom\u00b7men\u00b7den", "dank\u00b7bar", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-++-+--+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Durch den Dank nach r\u00fcckw\u00e4rts ist die Knechtschaft gekommen,", "tokens": ["Durch", "den", "Dank", "nach", "r\u00fcck\u00b7w\u00e4rts", "ist", "die", "Knecht\u00b7schaft", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Durch den Dank nach vorw\u00e4rts", "tokens": ["Durch", "den", "Dank", "nach", "vor\u00b7w\u00e4rts"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "M\u00fcssen die Sklaven freie Menschen werden", "tokens": ["M\u00fcs\u00b7sen", "die", "Skla\u00b7ven", "frei\u00b7e", "Men\u00b7schen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ADJA", "NN", "VAINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "Und mu\u00df alles Elend ein Ende haben.", "tokens": ["Und", "mu\u00df", "al\u00b7les", "E\u00b7lend", "ein", "En\u00b7de", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIAT", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.45": {"line.1": {"text": "Ihr sollt nicht M\u00e4hrchen f\u00fcr Wahrheit halten.", "tokens": ["Ihr", "sollt", "nicht", "M\u00e4hr\u00b7chen", "f\u00fcr", "Wahr\u00b7heit", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn wenn ihr das thuet,", "tokens": ["Denn", "wenn", "ihr", "das", "thu\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "VVFIN", "$,"], "meter": "----+-", "measure": "unknown.measure.single"}, "line.3": {"text": "So mordet ihr euch selbst", "tokens": ["So", "mor\u00b7det", "ihr", "euch", "selbst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und mordet eure Kinder.", "tokens": ["Und", "mor\u00b7det", "eu\u00b7re", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Stehe auf, du Sprache, und gehe dorthin,", "tokens": ["Ste\u00b7he", "auf", ",", "du", "Spra\u00b7che", ",", "und", "ge\u00b7he", "dor\u00b7thin", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PPER", "NN", "$,", "KON", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+++-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Wo der Jammer wohnet,", "tokens": ["Wo", "der", "Jam\u00b7mer", "woh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wo das Elend zu Tische sitzt,", "tokens": ["Wo", "das", "E\u00b7lend", "zu", "Ti\u00b7sche", "sitzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und der Hunger in den Eingeweiden w\u00fchlet.", "tokens": ["Und", "der", "Hun\u00b7ger", "in", "den", "Ein\u00b7ge\u00b7wei\u00b7den", "w\u00fch\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Wen du dort finden wirst,", "tokens": ["Wen", "du", "dort", "fin\u00b7den", "wirst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Mache seinen zerschlagenen Arm stark", "tokens": ["Ma\u00b7che", "sei\u00b7nen", "zer\u00b7schla\u00b7ge\u00b7nen", "Arm", "stark"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "ADJD"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Und seinen stumpfen Blick helle.", "tokens": ["Und", "sei\u00b7nen", "stump\u00b7fen", "Blick", "hel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADJA", "$."], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "La\u00df nicht ab von ihm,", "tokens": ["La\u00df", "nicht", "ab", "von", "ihm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKNEG", "PTKVZ", "APPR", "PPER", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Wenn er sich hinlegt vom Elend", "tokens": ["Wenn", "er", "sich", "hin\u00b7legt", "vom", "E\u00b7lend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "Und wenn er aufsteht zum Elend.", "tokens": ["Und", "wenn", "er", "auf\u00b7steht", "zum", "E\u00b7lend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Trommle, zischle, raune ihm zu:", "tokens": ["Tromm\u00b7le", ",", "zischle", ",", "rau\u00b7ne", "ihm", "zu", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.12": {"text": "Du sollst dich nicht treten lassen.", "tokens": ["Du", "sollst", "dich", "nicht", "tre\u00b7ten", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.13": {"text": "Du sollst dich nicht unterdr\u00fccken lassen.", "tokens": ["Du", "sollst", "dich", "nicht", "un\u00b7ter\u00b7dr\u00fc\u00b7cken", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "Du sollst dich nicht aussaugen lassen.", "tokens": ["Du", "sollst", "dich", "nicht", "aus\u00b7sau\u00b7gen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Du sollst den Sklavensinn von dir thun.", "tokens": ["Du", "sollst", "den", "Skla\u00b7ven\u00b7sinn", "von", "dir", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.16": {"text": "Du sollst die Knechtseligkeit von dir thun.", "tokens": ["Du", "sollst", "die", "Knecht\u00b7se\u00b7lig\u00b7keit", "von", "dir", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Du sollst dich nicht b\u00fccken vor einem lebendigen Menschen,", "tokens": ["Du", "sollst", "dich", "nicht", "b\u00fc\u00b7cken", "vor", "ei\u00b7nem", "le\u00b7ben\u00b7di\u00b7gen", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.18": {"text": "Denn er ist nicht mehr als du.", "tokens": ["Denn", "er", "ist", "nicht", "mehr", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "ADV", "KOUS", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Wirst du dies befolgen,", "tokens": ["Wirst", "du", "dies", "be\u00b7fol\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "So wird das Elend abfallen von dir,", "tokens": ["So", "wird", "das", "E\u00b7lend", "ab\u00b7fal\u00b7len", "von", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Wie ein Reif von der Erde schwindet,", "tokens": ["Wie", "ein", "Reif", "von", "der", "Er\u00b7de", "schwin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wenn das Fr\u00fchlicht kommt", "tokens": ["Wenn", "das", "Fr\u00fch\u00b7licht", "kommt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Und die Sonne am Himmel pranget.", "tokens": ["Und", "die", "Son\u00b7ne", "am", "Him\u00b7mel", "pran\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.48": {"line.1": {"text": "Denn weil du dich treten l\u00e4\u00dft,", "tokens": ["Denn", "weil", "du", "dich", "tre\u00b7ten", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Darum heulest du.", "tokens": ["Da\u00b7rum", "heu\u00b7lest", "du", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Weil du dich unterdr\u00fccken l\u00e4\u00dft,", "tokens": ["Weil", "du", "dich", "un\u00b7ter\u00b7dr\u00fc\u00b7cken", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darum bist du elend.", "tokens": ["Da\u00b7rum", "bist", "du", "e\u00b7lend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADJD", "$."], "meter": "--+-+-", "measure": "anapaest.init"}, "line.5": {"text": "Und weil du dich aussaugen l\u00e4\u00dft,", "tokens": ["Und", "weil", "du", "dich", "aus\u00b7sau\u00b7gen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Darum mu\u00dft du Hunger leiden.", "tokens": ["Da\u00b7rum", "mu\u00dft", "du", "Hun\u00b7ger", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Wer aber seinen Nebenmenschen zwingt,", "tokens": ["Wer", "a\u00b7ber", "sei\u00b7nen", "Ne\u00b7ben\u00b7men\u00b7schen", "zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Weniger zu wissen als er selber wei\u00df,", "tokens": ["We\u00b7ni\u00b7ger", "zu", "wis\u00b7sen", "als", "er", "sel\u00b7ber", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Der unterdr\u00fcckt seinen Bruder,", "tokens": ["Der", "un\u00b7ter\u00b7dr\u00fcckt", "sei\u00b7nen", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der tritt auf ihn", "tokens": ["Der", "tritt", "auf", "ihn"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und der saugt ihn aus.", "tokens": ["Und", "der", "saugt", "ihn", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+-+", "measure": "anapaest.init"}}, "stanza.50": {"line.1": {"text": "Und wer seinen Nebenmenschen zwingt,", "tokens": ["Und", "wer", "sei\u00b7nen", "Ne\u00b7ben\u00b7men\u00b7schen", "zwingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Mehr zu arbeiten, als er selber arbeitet,", "tokens": ["Mehr", "zu", "ar\u00b7bei\u00b7ten", ",", "als", "er", "sel\u00b7ber", "ar\u00b7bei\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Der unterdr\u00fcckt seinen Bruder,", "tokens": ["Der", "un\u00b7ter\u00b7dr\u00fcckt", "sei\u00b7nen", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der tritt auf ihn", "tokens": ["Der", "tritt", "auf", "ihn"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und der saugt ihn aus.", "tokens": ["Und", "der", "saugt", "ihn", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+-+", "measure": "anapaest.init"}}, "stanza.51": {"line.1": {"text": "Und du Sprache,", "tokens": ["Und", "du", "Spra\u00b7che", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Nimm eine Leuchte in deine Hand", "tokens": ["Nimm", "ei\u00b7ne", "Leuch\u00b7te", "in", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und gehe dorthin, wo es finster ist,", "tokens": ["Und", "ge\u00b7he", "dor\u00b7thin", ",", "wo", "es", "fins\u00b7ter", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wo es ganz finster ist.", "tokens": ["Wo", "es", "ganz", "fins\u00b7ter", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und strecke die Leuchte \u00fcber die dort schlummern", "tokens": ["Und", "stre\u00b7cke", "die", "Leuch\u00b7te", "\u00fc\u00b7ber", "die", "dort", "schlum\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PRELS", "ADV", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und nichts wissen von sich,", "tokens": ["Und", "nichts", "wis\u00b7sen", "von", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PRF", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Bis ihre Wimpern zucken", "tokens": ["Bis", "ih\u00b7re", "Wim\u00b7pern", "zu\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Und sie sich hin und wieder w\u00e4lzen.", "tokens": ["Und", "sie", "sich", "hin", "und", "wie\u00b7der", "w\u00e4l\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "PTKVZ", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und rufe laut, da\u00df es halle", "tokens": ["Und", "ru\u00b7fe", "laut", ",", "da\u00df", "es", "hal\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "VVFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Von H\u00fcgel zu H\u00fcgel,", "tokens": ["Von", "H\u00fc\u00b7gel", "zu", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.11": {"text": "Von Thal zu Thal:", "tokens": ["Von", "Thal", "zu", "Thal", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Wacht auf! wacht auf!", "tokens": ["Wacht", "auf", "!", "wacht", "auf", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Ihr habt zweitausend Jahre geschlafen,", "tokens": ["Ihr", "habt", "zweit\u00b7au\u00b7send", "Jah\u00b7re", "ge\u00b7schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Das ist lange genug. Wacht auf! seht,", "tokens": ["Das", "ist", "lan\u00b7ge", "ge\u00b7nug", ".", "Wacht", "auf", "!", "seht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "$.", "NN", "PTKVZ", "$.", "VVFIN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.15": {"text": "Es will lichter Morgen werden!", "tokens": ["Es", "will", "lich\u00b7ter", "Mor\u00b7gen", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "NN", "VAINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.52": {"line.1": {"text": "Und es h\u00f6ren es die H\u00fcgel,", "tokens": ["Und", "es", "h\u00f6\u00b7ren", "es", "die", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es h\u00f6ren es die Th\u00e4ler,", "tokens": ["Und", "es", "h\u00f6\u00b7ren", "es", "die", "Th\u00e4\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es h\u00f6ren es die Ufer des Meeres alle.", "tokens": ["Und", "es", "h\u00f6\u00b7ren", "es", "die", "U\u00b7fer", "des", "Mee\u00b7res", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PIAT", "$."], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und die Wellen am Ufer h\u00f6ren es,", "tokens": ["Und", "die", "Wel\u00b7len", "am", "U\u00b7fer", "h\u00f6\u00b7ren", "es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und beginnen es gegen einander zu schlagen.", "tokens": ["Und", "be\u00b7gin\u00b7nen", "es", "ge\u00b7gen", "ein\u00b7an\u00b7der", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PRF", "PTKZU", "VVINF", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.6": {"text": "Und die Tiefen des Meeres h\u00f6ren es,", "tokens": ["Und", "die", "Tie\u00b7fen", "des", "Mee\u00b7res", "h\u00f6\u00b7ren", "es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Und steigen mit Freuden empor.", "tokens": ["Und", "stei\u00b7gen", "mit", "Freu\u00b7den", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Und die letzten Wellen h\u00f6ren es,", "tokens": ["Und", "die", "letz\u00b7ten", "Wel\u00b7len", "h\u00f6\u00b7ren", "es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Und schlagen es an die Felsen mit Jubel.", "tokens": ["Und", "schla\u00b7gen", "es", "an", "die", "Fel\u00b7sen", "mit", "Ju\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Da dr\u00f6hnt das Land.", "tokens": ["Da", "dr\u00f6hnt", "das", "Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "Ein neues Licht durchzuckt alle Menschen.", "tokens": ["Ein", "neu\u00b7es", "Licht", "durch\u00b7zuckt", "al\u00b7le", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Aufjauchzen die Nationen der Erde.", "tokens": ["Auf\u00b7jauch\u00b7zen", "die", "Na\u00b7ti\u00b7o\u00b7nen", "der", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Denn der Fluch ist von ihnen genommen,", "tokens": ["Denn", "der", "Fluch", "ist", "von", "ih\u00b7nen", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.14": {"text": "Und den Blinden sind die Augen aufgethan,", "tokens": ["Und", "den", "Blin\u00b7den", "sind", "die", "Au\u00b7gen", "auf\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.15": {"text": "Und wollen als freie Menschen auf Erden wohnen,", "tokens": ["Und", "wol\u00b7len", "als", "frei\u00b7e", "Men\u00b7schen", "auf", "Er\u00b7den", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOKOM", "ADJA", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Und ein Blutbad unter ihnen wird nicht mehr sein.", "tokens": ["Und", "ein", "Blut\u00b7bad", "un\u00b7ter", "ih\u00b7nen", "wird", "nicht", "mehr", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "VAFIN", "PTKNEG", "ADV", "VAINF", "$."], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}}}}}