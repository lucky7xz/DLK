{"dta.poem.19045": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "XxVI.  Auf Herrn Heinrich des Drey und  \n Zwantzigsten Entschlafen.   Gedruckt zu Dre\u00dfden.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Du fragst: Jm Schlu\u00df dero letzten Briefes vom 10. Novembr. 1723. Wie gut wird sichs doch nach der Arbeit\nruhn?", "tokens": ["Du", "fragst", ":", "Jm", "Schlu\u00df", "de\u00b7ro", "letz\u00b7ten", "Brie\u00b7fes", "vom", "10.", "No\u00b7vembr", ".", "1723", ".", "Wie", "gut", "wird", "sichs", "doch", "nach", "der", "Ar\u00b7beit", "ruhn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "ordinal", "word", "punct", "number", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "APPRART", "NN", "PRELAT", "ADJA", "NN", "APPRART", "ADJA", "NN", "$.", "CARD", "$.", "PWAV", "ADJD", "VAFIN", "PIS", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+--++-+---+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Du rechtes Wittwen-Hertz, Die Frau Gr\u00e4fin Reu\u00dfin, geb. Freye von S\u00f6hlenth. d. z. Jh-\nro K\u00f6nigl. Hoheit Prinze\u00dfin Louyse von D\u00e4nnemarck Hof-\nmeisterin. Du fragst: Wie wohl\nwirds thun?", "tokens": ["Du", "rech\u00b7tes", "Witt\u00b7wen\u00b7Hertz", ",", "Die", "Frau", "Gr\u00e4\u00b7fin", "Reu\u00b7\u00dfin", ",", "ge\u00b7b.", "Frey\u00b7e", "von", "S\u00f6h\u00b7lenth", ".", "d.", "z.", "Jh", "ro", "K\u00f6\u00b7nigl", ".", "Ho\u00b7heit", "Prin\u00b7ze\u00b7\u00dfin", "Lou\u00b7yse", "von", "D\u00e4n\u00b7ne\u00b7marck", "Hof", "meis\u00b7te\u00b7rin", ".", "Du", "fragst", ":", "Wie", "wohl", "wirds", "thun", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "abbreviation", "word", "word", "word", "punct", "abbreviation", "abbreviation", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "ART", "NN", "NN", "NE", "$,", "ADJA", "NN", "APPR", "NN", "$.", "PDS", "APPRART", "TRUNC", "NE", "NE", "$.", "NN", "NN", "NE", "APPR", "NE", "TRUNC", "PPOSAT", "$.", "PPER", "VVFIN", "$.", "PWAV", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+--+-+--+-+-+-+-+-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Ich sage vor dem HErrn: So wohl, da\u00df alle Wehen", "tokens": ["Ich", "sa\u00b7ge", "vor", "dem", "Herrn", ":", "So", "wohl", ",", "da\u00df", "al\u00b7le", "We\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "ADV", "ADV", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der kurtzen Leidens-Zeit nun ewiglich vergehen.", "tokens": ["Der", "kurt\u00b7zen", "Lei\u00b7dens\u00b7Zeit", "nun", "e\u00b7wig\u00b7lich", "ver\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "O Tage dieser Zeit, da unser Auge thr\u00e4nt,\nO Stunden, da der Geist sich nur nach Freyheit sehnt,\nMinuten, die den Sinn in tiefe Schwermuth st\u00fcrtzen,", "tokens": ["O", "Ta\u00b7ge", "die\u00b7ser", "Zeit", ",", "da", "un\u00b7ser", "Au\u00b7ge", "thr\u00e4nt", ",", "O", "Stun\u00b7den", ",", "da", "der", "Geist", "sich", "nur", "nach", "Frey\u00b7heit", "sehnt", ",", "Mi\u00b7nu\u00b7ten", ",", "die", "den", "Sinn", "in", "tie\u00b7fe", "Schwer\u00b7muth", "st\u00fcrt\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PDAT", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,", "NE", "NN", "$,", "KOUS", "ART", "NN", "PRF", "ADV", "APPR", "NN", "VVFIN", "$,", "NN", "$,", "PRELS", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Jhr ", "tokens": ["Ihr"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}}, "stanza.3": {"line.1": {"text": "Warum ist unser Aug auf euer ", "tokens": ["Wa\u00b7rum", "ist", "un\u00b7ser", "Aug", "auf", "eu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPOSAT", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Davon der meiste Theil bereits dahin gerannt?", "tokens": ["Da\u00b7von", "der", "meis\u00b7te", "Theil", "be\u00b7reits", "da\u00b7hin", "ge\u00b7rannt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie, blickt es nicht vielmehr ins Innerste der Seelen,", "tokens": ["Wie", ",", "blickt", "es", "nicht", "viel\u00b7mehr", "ins", "In\u00b7ners\u00b7te", "der", "See\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Wo mit der Ewigkeit die Blicke sich verm\u00e4hlen?", "tokens": ["Wo", "mit", "der", "E\u00b7wig\u00b7keit", "die", "Bli\u00b7cke", "sich", "ver\u00b7m\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Es ist wol eines Theils des tr\u00e4gen Fleisches Schuld,", "tokens": ["Es", "ist", "wol", "ei\u00b7nes", "Theils", "des", "tr\u00e4\u00b7gen", "Flei\u00b7sches", "Schuld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das beuget seinen Hals nicht unter die Gedult,", "tokens": ["Das", "beu\u00b7get", "sei\u00b7nen", "Hals", "nicht", "un\u00b7ter", "die", "Ge\u00b7dult", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die nach der Liebe Rath so selig ist, so s\u00fcsse,", "tokens": ["Die", "nach", "der", "Lie\u00b7be", "Rath", "so", "se\u00b7lig", "ist", ",", "so", "s\u00fcs\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "ADV", "ADJD", "VAFIN", "$,", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und machet, da\u00df das Kind die Hand des Vaters k\u00fcsse.", "tokens": ["Und", "ma\u00b7chet", ",", "da\u00df", "das", "Kind", "die", "Hand", "des", "Va\u00b7ters", "k\u00fcs\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wie aber ", "tokens": ["Wie", "a\u00b7ber"], "token_info": ["word", "word"], "pos": ["PWAV", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Genugsam eingesehn, gef\u00fchlt zu seiner Zeit;", "tokens": ["Ge\u00b7nug\u00b7sam", "ein\u00b7ge\u00b7sehn", ",", "ge\u00b7f\u00fchlt", "zu", "sei\u00b7ner", "Zeit", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So dringt ihn alles di\u00df zu hertzlichem Erbarmen:", "tokens": ["So", "dringt", "ihn", "al\u00b7les", "di\u00df", "zu", "hertz\u00b7li\u00b7chem", "Er\u00b7bar\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PDS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Schwachheit tr\u00e4get er auf seinen starcken Armen.", "tokens": ["Die", "Schwach\u00b7heit", "tr\u00e4\u00b7get", "er", "auf", "sei\u00b7nen", "star\u00b7cken", "Ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Wie selig mu\u00df nicht oft die tiefste Trauer seyn!", "tokens": ["Wie", "se\u00b7lig", "mu\u00df", "nicht", "oft", "die", "tiefs\u00b7te", "Trau\u00b7er", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es gehe nur das Hertz recht in den Zweck hinein;", "tokens": ["Es", "ge\u00b7he", "nur", "das", "Hertz", "recht", "in", "den", "Zweck", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sonst mu\u00df ein leichter Mensch uns mit dem Wandel sagen:", "tokens": ["Sonst", "mu\u00df", "ein", "leich\u00b7ter", "Mensch", "uns", "mit", "dem", "Wan\u00b7del", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Warum der grosse GOtt so tief, so wund geschlagen?", "tokens": ["Wa\u00b7rum", "der", "gros\u00b7se", "Gott", "so", "tief", ",", "so", "wund", "ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wenn so ein laues Hertz durch lange Heucheley", "tokens": ["Wenn", "so", "ein", "lau\u00b7es", "Hertz", "durch", "lan\u00b7ge", "Heu\u00b7che\u00b7ley"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Menschen glauben macht, als ob es redlich sey,", "tokens": ["Die", "Men\u00b7schen", "glau\u00b7ben", "macht", ",", "als", "ob", "es", "red\u00b7lich", "sey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,", "KOKOM", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und dann die Crone erst vom Haupte abgefallen;", "tokens": ["Und", "dann", "die", "Cro\u00b7ne", "erst", "vom", "Haup\u00b7te", "ab\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So zeigt, so bl\u00f6sset sich der Larve Schmach vor allen.", "tokens": ["So", "zeigt", ",", "so", "bl\u00f6s\u00b7set", "sich", "der", "Lar\u00b7ve", "Schmach", "vor", "al\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Sie, die ihr redlichs Hertz zu JEsu jedermann,", "tokens": ["Sie", ",", "die", "ihr", "red\u00b7lichs", "Hertz", "zu", "Je\u00b7su", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "APPR", "NE", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So vor als nach der Eh\u2019 in Christo kund gethan!", "tokens": ["So", "vor", "als", "nach", "der", "Eh'", "in", "Chris\u00b7to", "kund", "ge\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "KOKOM", "APPR", "ART", "NN", "APPR", "NE", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erlaube, (ob ich ihr die Trauer nicht verdencke,)", "tokens": ["Er\u00b7lau\u00b7be", ",", "(", "ob", "ich", "ihr", "die", "Trau\u00b7er", "nicht", "ver\u00b7den\u00b7cke", ",", ")"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "$(", "KOUS", "PPER", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ich ihr einen ", "tokens": ["Da\u00df", "ich", "ihr", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ART"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Der ists: ", "tokens": ["Der", "ists", ":"], "token_info": ["word", "word", "punct"], "pos": ["PDS", "VAFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Und s\u00e4ttigt den nach ihm hier ausgespannten Sinn;", "tokens": ["Und", "s\u00e4t\u00b7tigt", "den", "nach", "ihm", "hier", "aus\u00b7ge\u00b7spann\u00b7ten", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Jhr nimmt er das hinweg, was ihre Augen lieben,", "tokens": ["Ihr", "nimmt", "er", "das", "hin\u00b7weg", ",", "was", "ih\u00b7re", "Au\u00b7gen", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDS", "PTKVZ", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Damit sie sich nur blo\u00df an seiner Sch\u00f6nheit \u00fcben.", "tokens": ["Da\u00b7mit", "sie", "sich", "nur", "blo\u00df", "an", "sei\u00b7ner", "Sch\u00f6n\u00b7heit", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Darf aber, oder soll vielmehr mein schwacher Kiel,", "tokens": ["Darf", "a\u00b7ber", ",", "o\u00b7der", "soll", "viel\u00b7mehr", "mein", "schwa\u00b7cher", "Kiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$,", "KON", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In dieser kurtzen Schrift und enger Reime Ziel,", "tokens": ["In", "die\u00b7ser", "kurt\u00b7zen", "Schrift", "und", "en\u00b7ger", "Rei\u00b7me", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "KON", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Angedencken noch von ihrem Herrn ber\u00fchren,", "tokens": ["Das", "An\u00b7ge\u00b7den\u00b7cken", "noch", "von", "ih\u00b7rem", "Herrn", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wessenthalben mag ich ihn so sp\u00e4te f\u00fchren?", "tokens": ["Und", "wes\u00b7sent\u00b7hal\u00b7ben", "mag", "ich", "ihn", "so", "sp\u00e4\u00b7te", "f\u00fch\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "PPER", "ADV", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Gewi\u00df, ", "tokens": ["Ge\u00b7wi\u00df", ","], "token_info": ["word", "punct"], "pos": ["PTKANT", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Von deren Ende schreibt und r\u00fchmet man mit Recht:", "tokens": ["Von", "de\u00b7ren", "En\u00b7de", "schreibt", "und", "r\u00fch\u00b7met", "man", "mit", "Recht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "VVFIN", "KON", "VVFIN", "PIS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil man hier davon nicht allzuviel vernommen,", "tokens": ["Und", "weil", "man", "hier", "da\u00b7von", "nicht", "all\u00b7zu\u00b7viel", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "ADV", "PAV", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So bin ich wohlgemeint auf dieses Denckmahl kommen.", "tokens": ["So", "bin", "ich", "wohl\u00b7ge\u00b7meint", "auf", "die\u00b7ses", "Denck\u00b7mahl", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Der Drey und Zwantzigste, ein Mann, zu seiner Zeit,", "tokens": ["Der", "Drey", "und", "Zwant\u00b7zigs\u00b7te", ",", "ein", "Mann", ",", "zu", "sei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "KON", "NN", "$,", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Tritt unter das Panier, wo Christus commandiret.", "tokens": ["Tritt", "un\u00b7ter", "das", "Pa\u00b7nier", ",", "wo", "Chris\u00b7tus", "com\u00b7man\u00b7di\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "PWAV", "NE", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Jhr Edle dieser Zeit! die ihr ihn sonst gekannt,", "tokens": ["Ihr", "Ed\u00b7le", "die\u00b7ser", "Zeit", "!", "die", "ihr", "ihn", "sonst", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PDAT", "NN", "$.", "PRELS", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sagt, fehlt\u2019 es ihm an Muth, Geschicklichkeit, Verstand?", "tokens": ["Sagt", ",", "fehlt'", "es", "ihm", "an", "Muth", ",", "Ge\u00b7schick\u00b7lich\u00b7keit", ",", "Ver\u00b7stand", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was zwang ihn, euer Feld in einer Zeit zu r\u00e4umen,", "tokens": ["Was", "zwang", "ihn", ",", "eu\u00b7er", "Feld", "in", "ei\u00b7ner", "Zeit", "zu", "r\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo ihm das Krieges-Gl\u00fcck begonnt empor zu keimen?", "tokens": ["Wo", "ihm", "das", "Krie\u00b7ge\u00b7sG\u00b7l\u00fcck", "be\u00b7gonnt", "em\u00b7por", "zu", "kei\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "War unser lieber ", "tokens": ["War", "un\u00b7ser", "lie\u00b7ber"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Und schenckt er einem was? Wer warf ihm etwas f\u00fcr,", "tokens": ["Und", "schenckt", "er", "ei\u00b7nem", "was", "?", "Wer", "warf", "ihm", "et\u00b7was", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "PWS", "$.", "PWS", "VVFIN", "PPER", "ADV", "APPR", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer trotzt\u2019 und pochte ihn der Zeit aus eurem Orden?", "tokens": ["Wer", "trotzt'", "und", "poch\u00b7te", "ihn", "der", "Zeit", "aus", "eu\u00b7rem", "Or\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie aber ist er denn hernach zum Narren worden?", "tokens": ["Wie", "a\u00b7ber", "ist", "er", "denn", "her\u00b7nach", "zum", "Nar\u00b7ren", "wor\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Ists nicht? so bald er erst ein J\u00fcnger JEsu war,", "tokens": ["Ists", "nicht", "?", "so", "bald", "er", "erst", "ein", "J\u00fcn\u00b7ger", "Je\u00b7su", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$.", "ADV", "ADV", "PPER", "ADV", "ART", "NN", "NE", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So setzte es vor euch auch weiter nicht Gefahr?", "tokens": ["So", "setz\u00b7te", "es", "vor", "euch", "auch", "wei\u00b7ter", "nicht", "Ge\u00b7fahr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "ADV", "ADV", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil Kinder GOttes selbst die Schmach der Erden lieben,", "tokens": ["Weil", "Kin\u00b7der", "Got\u00b7tes", "selbst", "die", "Schmach", "der", "Er\u00b7den", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "ADV", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So habt ihr euren Spott fein ungestraft getrieben?", "tokens": ["So", "habt", "ihr", "eu\u00b7ren", "Spott", "fein", "un\u00b7ge\u00b7straft", "ge\u00b7trie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "ADJD", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Was sagt ihr, denen itzt das Hertz im Leibe sagt:", "tokens": ["Was", "sagt", "ihr", ",", "de\u00b7nen", "itzt", "das", "Hertz", "im", "Lei\u00b7be", "sagt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PRELS", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df sich ihr Ubermuth an ihn und andre wagt,", "tokens": ["Da\u00df", "sich", "ihr", "U\u00b7ber\u00b7muth", "an", "ihn", "und", "and\u00b7re", "wagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "APPR", "PPER", "KON", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und das absonderlich, wenn sie es weder h\u00f6ren,", "tokens": ["Und", "das", "ab\u00b7son\u00b7der\u00b7lich", ",", "wenn", "sie", "es", "we\u00b7der", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJD", "$,", "KOUS", "PPER", "PPER", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Noch, wegen des Befehls von ihrem Meister, wehren?", "tokens": ["Noch", ",", "we\u00b7gen", "des", "Be\u00b7fehls", "von", "ih\u00b7rem", "Meis\u00b7ter", ",", "weh\u00b7ren", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "O sclavisches Gem\u00fcth, o niedertr\u00e4chtger Geist!", "tokens": ["O", "scla\u00b7vi\u00b7sches", "Ge\u00b7m\u00fcth", ",", "o", "nie\u00b7der\u00b7tr\u00e4cht\u00b7ger", "Geist", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der sich in jener Zunft der Jrrdischen beweist!", "tokens": ["Der", "sich", "in", "je\u00b7ner", "Zunft", "der", "Jrr\u00b7di\u00b7schen", "be\u00b7weist", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PDAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kommt, \u00e4ndert euer Hertz, kommt, fallt zu JEsu F\u00fcssen:", "tokens": ["Kommt", ",", "\u00e4n\u00b7dert", "eu\u00b7er", "Hertz", ",", "kommt", ",", "fallt", "zu", "Je\u00b7su", "F\u00fcs\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "$,", "VVFIN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dann werdet ihr von Muth und Hertz zu sagen wissen.", "tokens": ["Dann", "wer\u00b7det", "ihr", "von", "Muth", "und", "Hertz", "zu", "sa\u00b7gen", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Es ist nicht Leugnens werth, ", "tokens": ["Es", "ist", "nicht", "Leug\u00b7nens", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nachdem er sich bekehrt, verwarf den eiteln Prei\u00df,", "tokens": ["Nach\u00b7dem", "er", "sich", "be\u00b7kehrt", ",", "ver\u00b7warf", "den", "ei\u00b7teln", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man sahe ihn nicht mehr von Rach-Begierde brennen;", "tokens": ["Man", "sa\u00b7he", "ihn", "nicht", "mehr", "von", "Rach\u00b7Be\u00b7gier\u00b7de", "bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wol aber Christi Creutz mit L\u00f6wen-Muth bekennen.", "tokens": ["Wol", "a\u00b7ber", "Chris\u00b7ti", "Creutz", "mit", "L\u00f6\u00b7wen\u00b7Muth", "be\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.19": {"line.1": {"text": "Ja, sprichst du, eben das wird wol sein Fehler seyn;", "tokens": ["Ja", ",", "sprichst", "du", ",", "e\u00b7ben", "das", "wird", "wol", "sein", "Feh\u00b7ler", "seyn", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "ADV", "PDS", "VAFIN", "ADV", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er eiferte zu sehr, er gieng ins Feuer ein;", "tokens": ["Er", "ei\u00b7fer\u00b7te", "zu", "sehr", ",", "er", "gieng", "ins", "Feu\u00b7er", "ein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "$,", "PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wohlan! so hatte er mit etwas Kampf zu wagen,", "tokens": ["Wo\u00b7hlan", "!", "so", "hat\u00b7te", "er", "mit", "et\u00b7was", "Kampf", "zu", "wa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VAFIN", "PPER", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Jhr aber, deren Gescht nach Ehr und Rache sch\u00e4umt,", "tokens": ["Ihr", "a\u00b7ber", ",", "de\u00b7ren", "Ge\u00b7scht", "nach", "Ehr", "und", "Ra\u00b7che", "sch\u00e4umt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PRELAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und die ihr GOtt den Grund von euren Hefen r\u00e4umt!", "tokens": ["Und", "die", "ihr", "Gott", "den", "Grund", "von", "eu\u00b7ren", "He\u00b7fen", "r\u00e4umt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was wollt ihr einen Held, erkannt an seinen Fr\u00fcchten,", "tokens": ["Was", "wollt", "ihr", "ei\u00b7nen", "Held", ",", "er\u00b7kannt", "an", "sei\u00b7nen", "Fr\u00fcch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ART", "NN", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit seiner Redlichkeit und tapfern Geiste richten?", "tokens": ["Mit", "sei\u00b7ner", "Red\u00b7lich\u00b7keit", "und", "tap\u00b7fern", "Geis\u00b7te", "rich\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Euch sey mit wenigem und jederman gesagt:", "tokens": ["Euch", "sey", "mit", "we\u00b7ni\u00b7gem", "und", "je\u00b7der\u00b7man", "ge\u00b7sagt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "KON", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer was in dieser Zeit zu GOttes Ehren wagt,", "tokens": ["Wer", "was", "in", "die\u00b7ser", "Zeit", "zu", "Got\u00b7tes", "Eh\u00b7ren", "wagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PWS", "APPR", "PDAT", "NN", "APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da seine Lieb und Furcht nichts mehr auf Erden gelten,", "tokens": ["Da", "sei\u00b7ne", "Lieb", "und", "Furcht", "nichts", "mehr", "auf", "Er\u00b7den", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "PIS", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den kan der treue Zeug\u2019 unm\u00f6glich dr\u00fcber schelten.", "tokens": ["Den", "kan", "der", "treu\u00b7e", "Zeug'", "un\u00b7m\u00f6g\u00b7lich", "dr\u00fc\u00b7ber", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ART", "ADJA", "NN", "ADJD", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wenn alle Herrliche in dieser gantzen Welt,", "tokens": ["Wenn", "al\u00b7le", "Herr\u00b7li\u00b7che", "in", "die\u00b7ser", "gant\u00b7zen", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn auch der meiste Theil sich JEsu zugesellt,", "tokens": ["Wenn", "auch", "der", "meis\u00b7te", "Theil", "sich", "Je\u00b7su", "zu\u00b7ge\u00b7sellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PRF", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sch\u00e4mete sich nicht sein Zeugni\u00df darzugeben;", "tokens": ["Und", "sch\u00e4\u00b7me\u00b7te", "sich", "nicht", "sein", "Zeug\u00b7ni\u00df", "dar\u00b7zu\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "PPOSAT", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So m\u00f6chte man, (und gern,) in gr\u00f6\u00dfrer Stille leben.", "tokens": ["So", "m\u00f6ch\u00b7te", "man", ",", "(", "und", "gern", ",", ")", "in", "gr\u00f6\u00df\u00b7rer", "Stil\u00b7le", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "$,", "$(", "KON", "ADV", "$,", "$(", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Da aber Christum nicht mit einem Wort bezeugt,", "tokens": ["Da", "a\u00b7ber", "Chris\u00b7tum", "nicht", "mit", "ei\u00b7nem", "Wort", "be\u00b7zeugt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer sich ein wenig nur von gutem Schrote deucht,", "tokens": ["Wer", "sich", "ein", "we\u00b7nig", "nur", "von", "gu\u00b7tem", "Schro\u00b7te", "deucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ART", "PIS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und der zu Schmach und Hohn sich wissentlich bequemet,", "tokens": ["Und", "der", "zu", "Schmach", "und", "Hohn", "sich", "wis\u00b7sent\u00b7lich", "be\u00b7que\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NN", "KON", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer sich des Heylands nicht vor denen Leuten sch\u00e4met:", "tokens": ["Wer", "sich", "des", "Hey\u00b7lands", "nicht", "vor", "de\u00b7nen", "Leu\u00b7ten", "sch\u00e4\u00b7met", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ART", "NN", "PTKNEG", "APPR", "PRELS", "NN", "VVFIN", "$."], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Da sage mir ein Mensch, so klug er ist, er sag:", "tokens": ["Da", "sa\u00b7ge", "mir", "ein", "Mensch", ",", "so", "klug", "er", "ist", ",", "er", "sag", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ob ich, und wer noch sonst den HErrn bekennen mag,", "tokens": ["Ob", "ich", ",", "und", "wer", "noch", "sonst", "den", "Herrn", "be\u00b7ken\u00b7nen", "mag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KON", "PWS", "ADV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Grossen dieser Welt und andre mehr verdrengen,", "tokens": ["Die", "Gros\u00b7sen", "die\u00b7ser", "Welt", "und", "and\u00b7re", "mehr", "ver\u00b7dren\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "KON", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.25": {"line.1": {"text": "Nicht so? der heisset doch ein Ehr-verge\u00dfner Mann,", "tokens": ["Nicht", "so", "?", "der", "heis\u00b7set", "doch", "ein", "Ehr\u00b7ver\u00b7ge\u00df\u00b7ner", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$.", "ART", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der einem F\u00fcrsten dient, und nimmt sich sein nicht an?", "tokens": ["Der", "ei\u00b7nem", "F\u00fcrs\u00b7ten", "dient", ",", "und", "nimmt", "sich", "sein", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "PRF", "PPOSAT", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob man ihm gleich mit Schwerdt und Stahl nicht m\u00f6rdlich", "tokens": ["Ob", "man", "ihm", "gleich", "mit", "Schwerdt", "und", "Stahl", "nicht", "m\u00f6rd\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "ADV", "APPR", "NN", "KON", "NN", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Jhn aber sch\u00e4ndlich h\u00f6hnt und in die Augen speyet?", "tokens": ["Jhn", "a\u00b7ber", "sch\u00e4nd\u00b7lich", "h\u00f6hnt", "und", "in", "die", "Au\u00b7gen", "spey\u00b7et", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVPP", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Der aber kan ein Christ nach allen Formen seyn,", "tokens": ["Der", "a\u00b7ber", "kan", "ein", "Christ", "nach", "al\u00b7len", "For\u00b7men", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VMFIN", "ART", "NN", "APPR", "PIAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der viele Tage geht, und f\u00e4llet ihm nicht ein,", "tokens": ["Der", "vie\u00b7le", "Ta\u00b7ge", "geht", ",", "und", "f\u00e4l\u00b7let", "ihm", "nicht", "ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An diesen seinen HErrn bey andern zu gedencken,", "tokens": ["An", "die\u00b7sen", "sei\u00b7nen", "Herrn", "bey", "an\u00b7dern", "zu", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PPOSAT", "NN", "APPR", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geschweige ihre Gunst um seine zu verschencken.", "tokens": ["Ge\u00b7schwei\u00b7ge", "ih\u00b7re", "Gunst", "um", "sei\u00b7ne", "zu", "ver\u00b7schen\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Wer bist denn du, o Mensch! da, wenn du ungescheut,", "tokens": ["Wer", "bist", "denn", "du", ",", "o", "Mensch", "!", "da", ",", "wenn", "du", "un\u00b7ge\u00b7scheut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "KON", "PPER", "$,", "FM", "NN", "$.", "ADV", "$,", "KOUS", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf deinem Kirchen-Stand, zu GOtt-geweyhter Zeit,", "tokens": ["Auf", "dei\u00b7nem", "Kir\u00b7chen\u00b7Stand", ",", "zu", "Got\u00b7tge\u00b7wey\u00b7hter", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df der dein K\u00f6nig ist, mit vollem Hals erth\u00f6nest,", "tokens": ["Da\u00df", "der", "dein", "K\u00f6\u00b7nig", "ist", ",", "mit", "vol\u00b7lem", "Hals", "er\u00b7th\u00f6\u00b7nest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPOSAT", "NN", "VAFIN", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den du den Abend noch mit Werck und Worten h\u00f6hnest?", "tokens": ["Den", "du", "den", "A\u00b7bend", "noch", "mit", "Werck", "und", "Wor\u00b7ten", "h\u00f6h\u00b7nest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Der Lehrer auf dem Holtz, wo man alleine spricht,", "tokens": ["Der", "Leh\u00b7rer", "auf", "dem", "Holtz", ",", "wo", "man", "al\u00b7lei\u00b7ne", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PWAV", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der rede. Denckest du, er treffe mich nur nicht;", "tokens": ["Der", "re\u00b7de", ".", "Den\u00b7ckest", "du", ",", "er", "tref\u00b7fe", "mich", "nur", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mir aber, den ein Brief von sechzehn Ahnen cr\u00f6net,", "tokens": ["Mir", "a\u00b7ber", ",", "den", "ein", "Brief", "von", "sech\u00b7zehn", "Ah\u00b7nen", "cr\u00f6\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PRELS", "ART", "NN", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geb\u00fchret dieses nicht: Wie w\u00fcrd\u2019 ich sonst geh\u00f6hnet!", "tokens": ["Ge\u00b7b\u00fch\u00b7ret", "die\u00b7ses", "nicht", ":", "Wie", "w\u00fcrd'", "ich", "sonst", "ge\u00b7h\u00f6h\u00b7net", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PTKNEG", "$.", "PWAV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "O Welt! man schenckte dir die T\u00e4ndeleyen gern!", "tokens": ["O", "Welt", "!", "man", "schenck\u00b7te", "dir", "die", "T\u00e4n\u00b7de\u00b7le\u00b7yen", "gern", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PIS", "VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der aufgeschwungne Geist ist von dem allen fern:", "tokens": ["Der", "auf\u00b7ge\u00b7schwung\u00b7ne", "Geist", "ist", "von", "dem", "al\u00b7len", "fern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "PIAT", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch soll man Zeit und Zwang in ihren W\u00fcrden lassen;", "tokens": ["Doch", "soll", "man", "Zeit", "und", "Zwang", "in", "ih\u00b7ren", "W\u00fcr\u00b7den", "las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was hindert einen das, um Christi Creutz zu fassen?", "tokens": ["Was", "hin\u00b7dert", "ei\u00b7nen", "das", ",", "um", "Chris\u00b7ti", "Creutz", "zu", "fas\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "PDS", "$,", "KOUI", "NE", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Der Adel dieser Welt ist etwas; aber still!", "tokens": ["Der", "A\u00b7del", "die\u00b7ser", "Welt", "ist", "et\u00b7was", ";", "a\u00b7ber", "still", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "VAFIN", "ADV", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die gute liebe Welt wei\u00df selbst nicht, was sie will:", "tokens": ["Die", "gu\u00b7te", "lie\u00b7be", "Welt", "wei\u00df", "selbst", "nicht", ",", "was", "sie", "will", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "ADV", "PTKNEG", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Knecht spielt einen Herrn; ein Herr kan ja nicht leben,", "tokens": ["Der", "Knecht", "spielt", "ei\u00b7nen", "Herrn", ";", "ein", "Herr", "kan", "ja", "nicht", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VMFIN", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er mu\u00df sich irgendswo in einen Dienst begeben.", "tokens": ["Er", "mu\u00df", "sich", "ir\u00b7gends\u00b7wo", "in", "ei\u00b7nen", "Dienst", "be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "So aber steht es nicht um Christi Adel-Brief,", "tokens": ["So", "a\u00b7ber", "steht", "es", "nicht", "um", "Chris\u00b7ti", "A\u00b7del\u00b7Brief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da der die Seele erst zum Priesterthum berief,", "tokens": ["Da", "der", "die", "See\u00b7le", "erst", "zum", "Pries\u00b7ter\u00b7thum", "be\u00b7rief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und zu der Crone selbst: Da ward sie freygebohren,", "tokens": ["Und", "zu", "der", "Cro\u00b7ne", "selbst", ":", "Da", "ward", "sie", "frey\u00b7ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "$.", "ADV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und war zu keinem Zwang des Sclaven-Stands erkohren.", "tokens": ["Und", "war", "zu", "kei\u00b7nem", "Zwang", "des", "Scla\u00b7ven\u00b7Stands", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Der K\u00f6nig, welchem wir als Knechte eigen sind,", "tokens": ["Der", "K\u00f6\u00b7nig", ",", "wel\u00b7chem", "wir", "als", "Knech\u00b7te", "ei\u00b7gen", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "KOUS", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nennt uns anders nicht, als Bruder, Freund und Kind,", "tokens": ["Der", "nennt", "uns", "an\u00b7ders", "nicht", ",", "als", "Bru\u00b7der", ",", "Freund", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es hei\u00dft: Wir dienen ihm; Er aber dient uns besser:", "tokens": ["Es", "hei\u00dft", ":", "Wir", "die\u00b7nen", "ihm", ";", "Er", "a\u00b7ber", "dient", "uns", "bes\u00b7ser", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "$.", "PPER", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er macht durch seinen Dienst uns alle Tage gr\u00f6sser.", "tokens": ["Er", "macht", "durch", "sei\u00b7nen", "Dienst", "uns", "al\u00b7le", "Ta\u00b7ge", "gr\u00f6s\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Und wir, wir solten uns ", "tokens": ["Und", "wir", ",", "wir", "sol\u00b7ten", "uns"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "PPER", "VMFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Vor dem geringen Schwarm der Unterthanen sch\u00e4men,", "tokens": ["Vor", "dem", "ge\u00b7rin\u00b7gen", "Schwarm", "der", "Un\u00b7ter\u00b7tha\u00b7nen", "sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und nicht fein \u00f6ffentlich uns diese Ehre nehmen?", "tokens": ["Und", "nicht", "fein", "\u00f6f\u00b7fent\u00b7lich", "uns", "die\u00b7se", "Eh\u00b7re", "neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "ADJD", "PPER", "PDAT", "NN", "VVINF", "$."], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.34": {"line.1": {"text": "O Vater! schencke uns den k\u00f6niglichen Sinn,", "tokens": ["O", "Va\u00b7ter", "!", "schen\u00b7cke", "uns", "den", "k\u00f6\u00b7nig\u00b7li\u00b7chen", "Sinn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der alles hinten l\u00e4\u00dft, auf da\u00df er dich gewinn,", "tokens": ["Der", "al\u00b7les", "hin\u00b7ten", "l\u00e4\u00dft", ",", "auf", "da\u00df", "er", "dich", "ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "$,", "APPR", "KOUS", "PPER", "PRF", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und g\u00f6nne mehreren, die itzo furchtsam schweigen,", "tokens": ["Und", "g\u00f6n\u00b7ne", "meh\u00b7re\u00b7ren", ",", "die", "it\u00b7zo", "furcht\u00b7sam", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVINF", "$,", "PRELS", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Ruhm, den hohen Ruhm, der treuen Lammes-Zeugen.", "tokens": ["Den", "Ruhm", ",", "den", "ho\u00b7hen", "Ruhm", ",", "der", "treu\u00b7en", "Lam\u00b7mes\u00b7Zeu\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Gieb Wei\u00dfheit, leite uns dir nach, untadelich,", "tokens": ["Gieb", "Wei\u00df\u00b7heit", ",", "lei\u00b7te", "uns", "dir", "nach", ",", "un\u00b7ta\u00b7de\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und deinem Gnaden-Ruf zu wandeln w\u00fcrdiglich:", "tokens": ["Und", "dei\u00b7nem", "Gna\u00b7den\u00b7Ruf", "zu", "wan\u00b7deln", "w\u00fcr\u00b7dig\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKZU", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gieb Liebe, alles die\u00df mit Sanftmuth zu ertragen,", "tokens": ["Gieb", "Lie\u00b7be", ",", "al\u00b7les", "die\u00df", "mit", "Sanft\u00b7muth", "zu", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "PIS", "PDS", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was man von unserm Thun will dencken oder sagen!", "tokens": ["Was", "man", "von", "un\u00b7serm", "Thun", "will", "den\u00b7cken", "o\u00b7der", "sa\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "APPR", "PPOSAT", "NN", "VMFIN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Du aber, treuer Knecht! geh eilends ein zur Ruh:", "tokens": ["Du", "a\u00b7ber", ",", "treu\u00b7er", "Knecht", "!", "geh", "ei\u00b7lends", "ein", "zur", "Ruh", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJA", "NN", "$.", "VVFIN", "ADV", "ART", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der s\u00fcsse Br\u00e4utigam schlie\u00dft selbst die Cammer zu:", "tokens": ["Der", "s\u00fcs\u00b7se", "Br\u00e4u\u00b7ti\u00b7gam", "schlie\u00dft", "selbst", "die", "Cam\u00b7mer", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dring auf, erl\u00f6ster Geist! zu dem, den du bekennet,", "tokens": ["Dring", "auf", ",", "er\u00b7l\u00f6s\u00b7ter", "Geist", "!", "zu", "dem", ",", "den", "du", "be\u00b7ken\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ADJA", "NN", "$.", "APPR", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der dich dermaleinst vor seinem Vater nennet.", "tokens": ["Und", "der", "dich", "der\u00b7ma\u00b7leinst", "vor", "sei\u00b7nem", "Va\u00b7ter", "nen\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}}}}