{"dta.poem.19128": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "CvI.  Auf seinen Sohn, Johann Ernst, und  \n der theuren Knaben Aeltesten, Matth.  \n Linnern, in Herrnhut.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Der Heyland ist ja noch bey seinem Volck daheim:", "tokens": ["Der", "Hey\u00b7land", "ist", "ja", "noch", "bey", "sei\u00b7nem", "Volck", "da\u00b7heim", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir haben in der Zeit von deinen Wallfarts-Tagen", "tokens": ["Wir", "ha\u00b7ben", "in", "der", "Zeit", "von", "dei\u00b7nen", "Wallf\u00b7arts\u00b7Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vier H\u00fctten eingelegt (vier Wohnungen von Leim.)", "tokens": ["Vier", "H\u00fct\u00b7ten", "ein\u00b7ge\u00b7legt", "(", "vier", "Woh\u00b7nun\u00b7gen", "von", "Leim", ".", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "VVPP", "$(", "CARD", "NN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Johann Ernsts kleiner Schutt ist noch nicht weggetra-\ngen. Das war ungefehr die Erzehlung, welche uns auff der R\u00fcck-\nReise zu Budi\u00dfin entgegen kam.", "tokens": ["Jo\u00b7hann", "Ernsts", "klei\u00b7ner", "Schutt", "ist", "noch", "nicht", "weg\u00b7ge\u00b7tra", "gen", ".", "Das", "war", "un\u00b7ge\u00b7fehr", "die", "Er\u00b7zeh\u00b7lung", ",", "wel\u00b7che", "uns", "auff", "der", "R\u00fc\u00b7ck", "Rei\u00b7se", "zu", "Bu\u00b7di\u00b7\u00dfin", "ent\u00b7ge\u00b7gen", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "VAFIN", "ADV", "PTKNEG", "TRUNC", "VVPP", "$.", "PDS", "VAFIN", "ADJD", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "TRUNC", "NN", "APPR", "NN", "APPO", "VVFIN", "$."], "meter": "--+--+-+-+-+---+-+--+-+--+-+-+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Di\u00df hatte mir ein Freund zur Nachricht mitgetheilt,", "tokens": ["Di\u00df", "hat\u00b7te", "mir", "ein", "Freund", "zur", "Nach\u00b7richt", "mit\u00b7ge\u00b7theilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als ich vor kurtzer Zeit auf Herrnhut zugeeilt.", "tokens": ["Als", "ich", "vor", "kurt\u00b7zer", "Zeit", "auf", "Herrn\u00b7hut", "zu\u00b7ge\u00b7eilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich trat in diesen Ort, der Christi Liebes-Ziel", "tokens": ["Ich", "trat", "in", "die\u00b7sen", "Ort", ",", "der", "Chris\u00b7ti", "Lie\u00b7bes\u00b7Ziel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "$,", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und ein Beh\u00e4ltni\u00df ist von vielen Gnaden-Zundern.", "tokens": ["Und", "ein", "Be\u00b7h\u00e4lt\u00b7ni\u00df", "ist", "von", "vie\u00b7len", "Gna\u00b7den\u00b7Zun\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich hemme meinen Trieb, denn was beschreibt ein Kiel,", "tokens": ["Ich", "hem\u00b7me", "mei\u00b7nen", "Trieb", ",", "denn", "was", "be\u00b7schreibt", "ein", "Kiel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "PWS", "VVFIN", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Der noch so wenigen recht offenbahret ist.", "tokens": ["Der", "noch", "so", "we\u00b7ni\u00b7gen", "recht", "of\u00b7fen\u00b7bah\u00b7ret", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PIAT", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "So mancherley Gesch\u00e4fft verhindert anzuzeigen:", "tokens": ["So", "man\u00b7cher\u00b7ley", "Ge\u00b7sch\u00e4fft", "ver\u00b7hin\u00b7dert", "an\u00b7zu\u00b7zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sanfft er ausgeschnaubt, wie ", "tokens": ["Wie", "sanfft", "er", "aus\u00b7ge\u00b7schnaubt", ",", "wie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "VVFIN", "PPER", "VVPP", "$,", "PWAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Als seines Vaters GOtt ihm rieff hinauf zu steigen;", "tokens": ["Als", "sei\u00b7nes", "Va\u00b7ters", "Gott", "ihm", "rieff", "hin\u00b7auf", "zu", "stei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "PPER", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie sein Geschwister selbst, das kaum zu lallen pflegt,", "tokens": ["Wie", "sein", "Ge\u00b7schwis\u00b7ter", "selbst", ",", "das", "kaum", "zu", "lal\u00b7len", "pflegt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu seinem letzten Dienst die Zunge ", "tokens": ["Zu", "sei\u00b7nem", "letz\u00b7ten", "Dienst", "die", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Johann Ernst geht dahin, und niemand singt ihm aus,", "tokens": ["Jo\u00b7hann", "Ernst", "geht", "da\u00b7hin", ",", "und", "nie\u00b7mand", "singt", "ihm", "aus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PAV", "$,", "KON", "PIS", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dar\u00fcber wolten sich verschiedene bewegen:", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "wol\u00b7ten", "sich", "ver\u00b7schie\u00b7de\u00b7ne", "be\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PRF", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein es wartete ein Schicksal auf mein Hau\u00df,", "tokens": ["Al\u00b7lein", "es", "war\u00b7te\u00b7te", "ein", "Schick\u00b7sal", "auf", "mein", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein meiner ", "tokens": ["Ein", "mei\u00b7ner"], "token_info": ["word", "word"], "pos": ["ART", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Mein theurer ", "tokens": ["Mein", "theu\u00b7rer"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.6": {"line.1": {"text": "Gedacht ichs, ", "tokens": ["Ge\u00b7dacht", "ichs", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "PIS", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Dich in das gr\u00fcnende Beh\u00e4ltni\u00df eingeschoben:", "tokens": ["Dich", "in", "das", "gr\u00fc\u00b7nen\u00b7de", "Be\u00b7h\u00e4lt\u00b7ni\u00df", "ein\u00b7ge\u00b7scho\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es k\u00e4m in kurtzer Zeit ein junger Held dahin,", "tokens": ["Es", "k\u00e4m", "in", "kurt\u00b7zer", "Zeit", "ein", "jun\u00b7ger", "Held", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dir sey darauff dein Lied, mir ", "tokens": ["Dir", "sey", "dar\u00b7auff", "dein", "Lied", ",", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "PAV", "PPOSAT", "NN", "$,", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gedacht ich das von ", "tokens": ["Ge\u00b7dacht", "ich", "das", "von"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Der seiner H\u00fctten Band so eilende zerrei\u00dft?", "tokens": ["Der", "sei\u00b7ner", "H\u00fct\u00b7ten", "Band", "so", "ei\u00b7len\u00b7de", "zer\u00b7rei\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "ADV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "W\u00e4r ich der Neuerung ein wenig zugethan,", "tokens": ["W\u00e4r", "ich", "der", "Neu\u00b7e\u00b7rung", "ein", "we\u00b7nig", "zu\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und bliebe nicht so gern bey alten guten Sitten;", "tokens": ["Und", "blie\u00b7be", "nicht", "so", "gern", "bey", "al\u00b7ten", "gu\u00b7ten", "Sit\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "ADV", "APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So g\u00e4b ich dieses mahl gewi\u00df die Frage an:", "tokens": ["So", "g\u00e4b", "ich", "die\u00b7ses", "mahl", "ge\u00b7wi\u00df", "die", "Fra\u00b7ge", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Warum der ", "tokens": ["Wa\u00b7rum", "der"], "token_info": ["word", "word"], "pos": ["PWAV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Doch HErr, es kehrte sich dein Eingeweide um,", "tokens": ["Doch", "Herr", ",", "es", "kehr\u00b7te", "sich", "dein", "Ein\u00b7ge\u00b7wei\u00b7de", "um", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PPER", "VVFIN", "PRF", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn ich so untreu w\u00e4r, und fragte dich: ", "tokens": ["Wenn", "ich", "so", "un\u00b7treu", "w\u00e4r", ",", "und", "frag\u00b7te", "dich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Mein Alles, hast du mich, so nimm auch diesen Theil", "tokens": ["Mein", "Al\u00b7les", ",", "hast", "du", "mich", ",", "so", "nimm", "auch", "die\u00b7sen", "Theil"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "PIS", "$,", "VAFIN", "PPER", "PRF", "$,", "ADV", "VVIMP", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von meinem (HErr du wei\u00dfts!) dir zugestorbnen Hertzen,", "tokens": ["Von", "mei\u00b7nem", "(", "Herr", "du", "wei\u00dfts", "!", ")", "dir", "zu\u00b7ge\u00b7storb\u00b7nen", "Hert\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "$(", "NN", "PPER", "VVFIN", "$.", "$(", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Creatur wars nicht, um die ich eine Weil", "tokens": ["Die", "Crea\u00b7tur", "wars", "nicht", ",", "um", "die", "ich", "ei\u00b7ne", "Weil"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "$,", "APPR", "PRELS", "PPER", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Mit deiner Seele rang, (nicht ohne allen Schmertzen,)", "tokens": ["Mit", "dei\u00b7ner", "See\u00b7le", "rang", ",", "(", "nicht", "oh\u00b7ne", "al\u00b7len", "Schmert\u00b7zen", ",", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "$(", "PTKNEG", "APPR", "PIAT", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}