{"textgrid.poem.33394": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Maurertugend", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie hei\u00dft die Sch\u00f6ne, die man bald", "tokens": ["Wie", "hei\u00dft", "die", "Sch\u00f6\u00b7ne", ",", "die", "man", "bald"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,", "PRELS", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als eine runzlichte Matrone,", "tokens": ["Als", "ei\u00b7ne", "runz\u00b7lich\u00b7te", "Mat\u00b7ro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bald sch\u00f6n bekr\u00e4nzt mit Rosen malt,", "tokens": ["Bald", "sch\u00f6n", "be\u00b7kr\u00e4nzt", "mit", "Ro\u00b7sen", "malt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und bald mit einer Dornenkrone?", "tokens": ["Und", "bald", "mit", "ei\u00b7ner", "Dor\u00b7nen\u00b7kro\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Sie selbst bleibt immer jung und sch\u00f6n,", "tokens": ["Sie", "selbst", "bleibt", "im\u00b7mer", "jung", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird nie dem Zahn der Zeit, zur Beute,", "tokens": ["Wird", "nie", "dem", "Zahn", "der", "Zeit", ",", "zur", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So sch\u00f6n sie Adam hat geseh'n,", "tokens": ["So", "sch\u00f6n", "sie", "A\u00b7dam", "hat", "ge\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So sch\u00f6n erscheint sie uns noch heute.", "tokens": ["So", "sch\u00f6n", "er\u00b7scheint", "sie", "uns", "noch", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ihr ganzer Reiz ist blo\u00df Natur,", "tokens": ["Ihr", "gan\u00b7zer", "Reiz", "ist", "blo\u00df", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nie darf die Kunst sich beigesellen;", "tokens": ["Nie", "darf", "die", "Kunst", "sich", "bei\u00b7ge\u00b7sel\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die feinste Schminke w\u00fcrde nur,", "tokens": ["Die", "feins\u00b7te", "Schmin\u00b7ke", "w\u00fcr\u00b7de", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Statt zu versch\u00f6nern, sie entstellen.", "tokens": ["Statt", "zu", "ver\u00b7sch\u00f6\u00b7nern", ",", "sie", "ent\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nett ist der Anzug, den sie tr\u00e4gt,", "tokens": ["Nett", "ist", "der", "An\u00b7zug", ",", "den", "sie", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch ohne Pracht und ohne Schimmer,", "tokens": ["Doch", "oh\u00b7ne", "Pracht", "und", "oh\u00b7ne", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihren sch\u00f6nen Busen deckt,", "tokens": ["Und", "ih\u00b7ren", "sch\u00f6\u00b7nen", "Bu\u00b7sen", "deckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Strau\u00df bescheid'ner Veilchen immer.", "tokens": ["Ein", "Strau\u00df", "be\u00b7schei\u00b7d'\u00b7ner", "Veil\u00b7chen", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJA", "NN", "ADV", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Trotz ihrer Jugend zeigt sie nie", "tokens": ["Trotz", "ih\u00b7rer", "Ju\u00b7gend", "zeigt", "sie", "nie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aufrichtig Liebenden sich bl\u00f6de,", "tokens": ["Auf\u00b7rich\u00b7tig", "Lie\u00b7ben\u00b7den", "sich", "bl\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "PRF", "ADJA", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Trotz ihrer Klugheit findet sie", "tokens": ["Trotz", "ih\u00b7rer", "Klug\u00b7heit", "fin\u00b7det", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch keiner ihrer Freier spr\u00f6de.", "tokens": ["Auch", "kei\u00b7ner", "ih\u00b7rer", "Frei\u00b7er", "spr\u00f6\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie will von Jedermann geliebt,", "tokens": ["Sie", "will", "von", "Je\u00b7der\u00b7mann", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Jedermann gesuchet werden,", "tokens": ["Von", "Je\u00b7der\u00b7mann", "ge\u00b7su\u00b7chet", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und jedem, der sich ihr ergibt,", "tokens": ["Und", "je\u00b7dem", ",", "der", "sich", "ihr", "er\u00b7gibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PRF", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist sie ein Himmelreich auf Erden.", "tokens": ["Ist", "sie", "ein", "Him\u00b7mel\u00b7reich", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sie ist nicht m\u00fcrrisch von Natur,", "tokens": ["Sie", "ist", "nicht", "m\u00fcr\u00b7risch", "von", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sanftmuth ist ihr angeboren:", "tokens": ["Die", "Sanft\u00b7muth", "ist", "ihr", "an\u00b7ge\u00b7bo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie poltert nie, sie fl\u00fcstert nur", "tokens": ["Sie", "pol\u00b7tert", "nie", ",", "sie", "fl\u00fcs\u00b7tert", "nur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Ungetreuen in die Ohren.", "tokens": ["Dem", "Un\u00b7ge\u00b7treu\u00b7en", "in", "die", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Sie ist nicht unst\u00e4t, und vergi\u00dft", "tokens": ["Sie", "ist", "nicht", "un\u00b7st\u00e4t", ",", "und", "ver\u00b7gi\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De\u00df', der sie liebt, zu keiner Stunde,", "tokens": ["De\u00df'", ",", "der", "sie", "liebt", ",", "zu", "kei\u00b7ner", "Stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie f\u00fchrt ihn bis an's Grab, und k\u00fc\u00dft", "tokens": ["Sie", "f\u00fchrt", "ihn", "bis", "an's", "Grab", ",", "und", "k\u00fc\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den letzten Seufzer ihm vom Munde.", "tokens": ["Den", "letz\u00b7ten", "Seuf\u00b7zer", "ihm", "vom", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie ist nicht eitel, spricht nicht viel,", "tokens": ["Sie", "ist", "nicht", "ei\u00b7tel", ",", "spricht", "nicht", "viel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4\u00dft nur im Stillen sich umarmen,", "tokens": ["L\u00e4\u00dft", "nur", "im", "Stil\u00b7len", "sich", "um\u00b7ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und wer zur Schau sie f\u00fchren will,", "tokens": ["Und", "wer", "zur", "Schau", "sie", "f\u00fch\u00b7ren", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPRART", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem windet sie sich aus den Armen.", "tokens": ["Dem", "win\u00b7det", "sie", "sich", "aus", "den", "Ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Auch hegt sie keinen Stolz, und freit", "tokens": ["Auch", "hegt", "sie", "kei\u00b7nen", "Stolz", ",", "und", "freit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht nach Geburt und Ehrentitel:", "tokens": ["Nicht", "nach", "Ge\u00b7burt", "und", "Eh\u00b7ren\u00b7ti\u00b7tel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie liebt den Mann im Purpurkleid", "tokens": ["Sie", "liebt", "den", "Mann", "im", "Pur\u00b7pur\u00b7kleid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht mehr, als den im Bauernkittel.", "tokens": ["Nicht", "mehr", ",", "als", "den", "im", "Bau\u00b7ern\u00b7kit\u00b7tel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "KOUS", "ART", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Kein Eigensinn lenkt ihre Wahl,", "tokens": ["Kein", "Ei\u00b7gen\u00b7sinn", "lenkt", "ih\u00b7re", "Wahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sie liebt den Christen, wie den Heiden,", "tokens": ["Sie", "liebt", "den", "Chris\u00b7ten", ",", "wie", "den", "Hei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und wei\u00df den Menschen \u00fcberall", "tokens": ["Und", "wei\u00df", "den", "Men\u00b7schen", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von seiner Liverei zu scheiden.", "tokens": ["Von", "sei\u00b7ner", "Li\u00b7ve\u00b7rei", "zu", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Sie macht stets froh und nie betr\u00fcbt,", "tokens": ["Sie", "macht", "stets", "froh", "und", "nie", "be\u00b7tr\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D'rum z\u00e4hlt sie auch ein Heer von Freuden,", "tokens": ["D'\u00b7rum", "z\u00e4hlt", "sie", "auch", "ein", "Heer", "von", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Sie wird in Ost und West geliebt,", "tokens": ["Sie", "wird", "in", "Ost", "und", "West", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geliebt sogar von ihren Feinden.", "tokens": ["Ge\u00b7liebt", "so\u00b7gar", "von", "ih\u00b7ren", "Fein\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Hat wer dies M\u00e4dchen je gekannt,", "tokens": ["Hat", "wer", "dies", "M\u00e4d\u00b7chen", "je", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PWS", "PDS", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wird er auch die Tugend kennen:", "tokens": ["So", "wird", "er", "auch", "die", "Tu\u00b7gend", "ken\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem Maurer ist sie wohl bekannt, \u2013", "tokens": ["Dem", "Mau\u00b7rer", "ist", "sie", "wohl", "be\u00b7kannt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie l\u00e4\u00dft von ihm sich Schwester nennen.", "tokens": ["Sie", "l\u00e4\u00dft", "von", "ihm", "sich", "Schwes\u00b7ter", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PRF", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}