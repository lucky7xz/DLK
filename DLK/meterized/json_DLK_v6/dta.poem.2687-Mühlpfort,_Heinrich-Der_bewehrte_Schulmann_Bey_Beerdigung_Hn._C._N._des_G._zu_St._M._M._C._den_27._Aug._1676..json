{"dta.poem.2687": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Der bewehrte Schulmann/  \n  Bey Beerdigung Hn. C. N. des   G.   zu St.  \n M. M.  C.  den 27. Aug. 1676.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein Lehrer/ gehst du auch nun Lebens-satt zu Grabe/", "tokens": ["Mein", "Leh\u00b7rer", "/", "gehst", "du", "auch", "nun", "Le\u00b7bens\u00b7satt", "zu", "Gra\u00b7be", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VVFIN", "PPER", "ADV", "ADV", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der meine Kindheit hat mit Musen-Milch ge-", "tokens": ["Der", "mei\u00b7ne", "Kind\u00b7heit", "hat", "mit", "Mu\u00b7sen\u00b7Milch", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "APPR", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich seufftze da\u00df ich nicht was Geister-reiches habe:", "tokens": ["Ich", "seufft\u00b7ze", "da\u00df", "ich", "nicht", "was", "Geis\u00b7ter\u00b7rei\u00b7ches", "ha\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "PTKNEG", "PWS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es solte deinem Sarch aus Liebe seyn geschenckt", "tokens": ["Es", "sol\u00b7te", "dei\u00b7nem", "Sarch", "aus", "Lie\u00b7be", "seyn", "ge\u00b7schenckt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "APPR", "NN", "PPOSAT", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du wohlbewehrter Mann der in dem schweren Stande/", "tokens": ["Du", "wohl\u00b7be\u00b7wehr\u00b7ter", "Mann", "der", "in", "dem", "schwe\u00b7ren", "Stan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein ander Hercules/ viel Ungeheur bek\u00e4mpfft;", "tokens": ["Ein", "an\u00b7der", "Her\u00b7cu\u00b7les", "/", "viel", "Un\u00b7ge\u00b7heur", "be\u00b7k\u00e4mpfft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Gibst nun die Seele GOtt/ den welcken Leib dem Sande/", "tokens": ["Gibst", "nun", "die", "See\u00b7le", "Gott", "/", "den", "wel\u00b7cken", "Leib", "dem", "San\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "$(", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und hast des Teuffels List/ den Hohn der Welt ged\u00e4mpfft.", "tokens": ["Und", "hast", "des", "Teuf\u00b7fels", "List", "/", "den", "Hohn", "der", "Welt", "ge\u00b7d\u00e4mpfft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "NE", "$(", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es heist die Danckbarkeit mich dir ein Denckmahl bauen;", "tokens": ["Es", "heist", "die", "Dan\u00b7ck\u00b7bar\u00b7keit", "mich", "dir", "ein", "Denck\u00b7mahl", "bau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Denn treuer Lehrer Flei\u00df verdient den h\u00f6chsten Danck.", "tokens": ["Denn", "treu\u00b7er", "Leh\u00b7rer", "Flei\u00df", "ver\u00b7dient", "den", "h\u00f6chs\u00b7ten", "Danck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dein Bildn\u00fc\u00df kan ich nicht in Ertzt und Marmel hauen;", "tokens": ["Dein", "Bild\u00b7n\u00fc\u00df", "kan", "ich", "nicht", "in", "Ertzt", "und", "Mar\u00b7mel", "hau\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PTKNEG", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Es fehlt mir an der Kunst/ und meine Faust ist kranck.", "tokens": ["Es", "fehlt", "mir", "an", "der", "Kunst", "/", "und", "mei\u00b7ne", "Faust", "ist", "kranck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Zu dem/ was helffen auch dergleichen Ehren-S\u00e4ulen/", "tokens": ["Zu", "dem", "/", "was", "helf\u00b7fen", "auch", "derg\u00b7lei\u00b7chen", "Eh\u00b7ren\u00b7S\u00e4u\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PWS", "VVFIN", "ADV", "PIS", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die zwar vom Lob\u2019 erf\u00fcllt von Wahrheit aber blo\u00df?", "tokens": ["Die", "zwar", "vom", "Lob'", "er\u00b7f\u00fcllt", "von", "Wahr\u00b7heit", "a\u00b7ber", "blo\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVPP", "APPR", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Genung/ da\u00df unsre Stadt dir kan den Ruhm ertheilen/", "tokens": ["Ge\u00b7nung", "/", "da\u00df", "uns\u00b7re", "Stadt", "dir", "kan", "den", "Ruhm", "er\u00b7thei\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOUS", "PPOSAT", "NN", "PPER", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wie du ihr junges Volck gef\u00fchrt zu Pindus Schlo\u00df.", "tokens": ["Wie", "du", "ihr", "jun\u00b7ges", "Volck", "ge\u00b7f\u00fchrt", "zu", "Pin\u00b7dus", "Schlo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "VVPP", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Di\u00df ist ein wichtig Ampt/ dem meuschlichen Geschlechte", "tokens": ["Di\u00df", "ist", "ein", "wich\u00b7tig", "Ampt", "/", "dem", "meuschli\u00b7chen", "Ge\u00b7schlech\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Hoch n\u00fctzbar/ und ein Grund vollkommner Policey.", "tokens": ["Hoch", "n\u00fctz\u00b7bar", "/", "und", "ein", "Grund", "voll\u00b7komm\u00b7ner", "Po\u00b7li\u00b7cey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$(", "KON", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wo gute Schulen sind/ da wachsen K\u00fcnst und Rechte;", "tokens": ["Wo", "gu\u00b7te", "Schu\u00b7len", "sind", "/", "da", "wach\u00b7sen", "K\u00fcnst", "und", "Rech\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VAFIN", "$(", "ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Da bl\u00fcht gemeines Heil/ und stirbt die Barbarey.", "tokens": ["Da", "bl\u00fcht", "ge\u00b7mei\u00b7nes", "Heil", "/", "und", "stirbt", "die", "Bar\u00b7ba\u00b7rey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$(", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die Nutzen nicht allein die Purpur h\u00e4lt umbgeben/", "tokens": ["Die", "Nut\u00b7zen", "nicht", "al\u00b7lein", "die", "Pur\u00b7pur", "h\u00e4lt", "umb\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und die der Ehren-Liecht auff hohen Stuffen f\u00fchrt.", "tokens": ["Und", "die", "der", "Eh\u00b7ren\u00b7Liecht", "auff", "ho\u00b7hen", "Stuf\u00b7fen", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die bey Regierungen und Staats-Gesch\u00e4fften leben/", "tokens": ["Die", "bey", "Re\u00b7gie\u00b7run\u00b7gen", "und", "Staats\u00b7Ge\u00b7sch\u00e4ff\u00b7ten", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.24": {"text": "Und derer Namen stets ein langer Titel ziert.", "tokens": ["Und", "de\u00b7rer", "Na\u00b7men", "stets", "ein", "lan\u00b7ger", "Ti\u00b7tel", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Nein: Wer die Jugend wei\u00df zur Tugend anzuweisen/", "tokens": ["Nein", ":", "Wer", "die", "Ju\u00b7gend", "wei\u00df", "zur", "Tu\u00b7gend", "an\u00b7zu\u00b7wei\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PWS", "ART", "NN", "VVFIN", "APPRART", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Von Lastern abzuziehn/ bey der verkehrten Welt:", "tokens": ["Von", "Las\u00b7tern", "ab\u00b7zu\u00b7ziehn", "/", "bey", "der", "ver\u00b7kehr\u00b7ten", "Welt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Lehrt/ wie Gerechtigkeit/ wie Gottesfurcht zu preisen/", "tokens": ["Lehrt", "/", "wie", "Ge\u00b7rech\u00b7tig\u00b7keit", "/", "wie", "Got\u00b7tes\u00b7furcht", "zu", "prei\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "NN", "$(", "KOKOM", "NN", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.28": {"text": "Und wie die Wei\u00dfheit sey weit k\u00f6stlicher als Geld.", "tokens": ["Und", "wie", "die", "Wei\u00df\u00b7heit", "sey", "weit", "k\u00f6st\u00b7li\u00b7cher", "als", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VAFIN", "ADJD", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Und welch ein edel Schatz verbleib ein rein Gewissen/", "tokens": ["Und", "welch", "ein", "e\u00b7del", "Schatz", "ver\u00b7bleib", "ein", "rein", "Ge\u00b7wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "ART", "ADJA", "NN", "VVFIN", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Das bey der letzten Fahrt den Tod vers\u00fcssen kan.", "tokens": ["Das", "bey", "der", "letz\u00b7ten", "Fahrt", "den", "Tod", "ver\u00b7s\u00fcs\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dem wird man ja mit Recht das Zeugn\u00fc\u00df geben m\u00fcssen/", "tokens": ["Dem", "wird", "man", "ja", "mit", "Recht", "das", "Zeug\u00b7n\u00fc\u00df", "ge\u00b7ben", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "ADV", "APPR", "NN", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Er sey f\u00fcr aller Welt ein Ehrenwehrter Mann.", "tokens": ["Er", "sey", "f\u00fcr", "al\u00b7ler", "Welt", "ein", "Eh\u00b7ren\u00b7wehr\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Gesetzt/ da\u00df auch solch Ampt nicht in die Augen strahlet/", "tokens": ["Ge\u00b7setzt", "/", "da\u00df", "auch", "solch", "Ampt", "nicht", "in", "die", "Au\u00b7gen", "strah\u00b7let", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "KOUS", "ADV", "PIAT", "NN", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Als wenn ein Cicero das gantze Rom bewegt.", "tokens": ["Als", "wenn", "ein", "Ci\u00b7ce\u00b7ro", "das", "gant\u00b7ze", "Rom", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ART", "ADJA", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und da\u00df die saure M\u00fch nie wird so theur bezahlet/", "tokens": ["Und", "da\u00df", "die", "sau\u00b7re", "M\u00fch", "nie", "wird", "so", "theur", "be\u00b7zah\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "VAFIN", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Als dem/ der \u00fcber Meer uns frembdes Gut zutr\u00e4gt.", "tokens": ["Als", "dem", "/", "der", "\u00fc\u00b7ber", "Meer", "uns", "fremb\u00b7des", "Gut", "zu\u00b7tr\u00e4gt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "ART", "APPR", "NN", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "So ist die Tugend doch ihr eigner Glantz und Krone/", "tokens": ["So", "ist", "die", "Tu\u00b7gend", "doch", "ihr", "eig\u00b7ner", "Glantz", "und", "Kro\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "PPOSAT", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wie gro\u00df die Finstern\u00fc\u00df: Sie dringt durch Wolck u\u00f1 Nacht.", "tokens": ["Wie", "gro\u00df", "die", "Fins\u00b7ter\u00b7n\u00fc\u00df", ":", "Sie", "dringt", "durch", "Wolck", "u\u00f1", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "$.", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Zu dem sagt GOttes Mund von einem grossen Lohne/", "tokens": ["Zu", "dem", "sagt", "Got\u00b7tes", "Mund", "von", "ei\u00b7nem", "gros\u00b7sen", "Loh\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "NN", "NN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Der Reichthum/ Sch\u00e4tz und Geld zu Spott und Schanden", "tokens": ["Der", "Reicht\u00b7hum", "/", "Sch\u00e4tz", "und", "Geld", "zu", "Spott", "und", "Schan\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "KON", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.41": {"text": "Es blendet uns der Schein der euserlichen Dinge/", "tokens": ["Es", "blen\u00b7det", "uns", "der", "Schein", "der", "eu\u00b7ser\u00b7li\u00b7chen", "Din\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Wir sehn das wahre Gut mit halben Augen an.", "tokens": ["Wir", "sehn", "das", "wah\u00b7re", "Gut", "mit", "hal\u00b7ben", "Au\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und was die Tugend lehrt/ das achten wir geringe/", "tokens": ["Und", "was", "die", "Tu\u00b7gend", "lehrt", "/", "das", "ach\u00b7ten", "wir", "ge\u00b7rin\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$(", "ART", "ADJA", "PPER", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Vertiefft im D\u00fcnckelwitz/ beth\u00f6rt durch falschen Wahn.", "tokens": ["Ver\u00b7tiefft", "im", "D\u00fcn\u00b7ckel\u00b7witz", "/", "be\u00b7th\u00f6rt", "durch", "fal\u00b7schen", "Wahn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$(", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Du selger N", "tokens": ["Du", "sel\u00b7ger", "N"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ADJA", "XY"], "meter": "-+-+", "measure": "iambic.di"}, "line.46": {"text": "Von keiner Herrligkeit noch stoltzer Pracht geziert;", "tokens": ["Von", "kei\u00b7ner", "Herr\u00b7lig\u00b7keit", "noch", "stolt\u00b7zer", "Pracht", "ge\u00b7ziert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "So bist du doch in dem dergleichen Meister worden/", "tokens": ["So", "bist", "du", "doch", "in", "dem", "derg\u00b7lei\u00b7chen", "Meis\u00b7ter", "wor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "PRELS", "PIS", "NN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Der tausend Seelen hat dem Himmel zugef\u00fchrt.", "tokens": ["Der", "tau\u00b7send", "See\u00b7len", "hat", "dem", "Him\u00b7mel", "zu\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Du hast die Gottesfurcht den untergebnen Knaben", "tokens": ["Du", "hast", "die", "Got\u00b7tes\u00b7furcht", "den", "un\u00b7ter\u00b7geb\u00b7nen", "Kna\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "In unverruckter Treu ersprie\u00dflich beygebracht;", "tokens": ["In", "un\u00b7ver\u00b7ruck\u00b7ter", "Treu", "er\u00b7sprie\u00df\u00b7lich", "bey\u00b7ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Und wustest/ da\u00df die offt ein schlechtes Zeugn\u00fc\u00df haben/", "tokens": ["Und", "wus\u00b7test", "/", "da\u00df", "die", "offt", "ein", "schlech\u00b7tes", "Zeug\u00b7n\u00fc\u00df", "ha\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "ART", "ADV", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Die man zwar f\u00fcr gelehrt/ doch nie f\u00fcr fromm geacht.", "tokens": ["Die", "man", "zwar", "f\u00fcr", "ge\u00b7lehrt", "/", "doch", "nie", "f\u00fcr", "fromm", "ge\u00b7acht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "APPR", "VVPP", "$(", "ADV", "ADV", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Denn war dein eintzig Flei\u00df den Grund recht wol zu legen.", "tokens": ["Denn", "war", "dein", "eint\u00b7zig", "Flei\u00df", "den", "Grund", "recht", "wol", "zu", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJD", "NN", "ART", "NN", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Wenn Sch\u00fclern der gebricht/ so s\u00e4en sie in Sand.", "tokens": ["Wenn", "Sch\u00fc\u00b7lern", "der", "ge\u00b7bricht", "/", "so", "s\u00e4\u00b7en", "sie", "in", "Sand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Der Seegen kam darzu/ du brachtest di\u00df zuwegen/", "tokens": ["Der", "See\u00b7gen", "kam", "dar\u00b7zu", "/", "du", "brach\u00b7test", "di\u00df", "zu\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$(", "PPER", "VVFIN", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Da\u00df zarten Kindern auch war gut Latein bekandt.", "tokens": ["Da\u00df", "zar\u00b7ten", "Kin\u00b7dern", "auch", "war", "gut", "La\u00b7tein", "be\u00b7kandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADV", "VAFIN", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Es wird ein Thraso wol ob diesem Lobspruch lachen:", "tokens": ["Es", "wird", "ein", "Thra\u00b7so", "wol", "ob", "die\u00b7sem", "Lob\u00b7spruch", "la\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "KOUS", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Doch wo bey erster Zucht wir hier saumseelig seyn/", "tokens": ["Doch", "wo", "bey", "ers\u00b7ter", "Zucht", "wir", "hier", "saum\u00b7see\u00b7lig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "ADJA", "NN", "PPER", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "So d\u00fcrffen wir uns denn kein andre Rechnung machen;", "tokens": ["So", "d\u00fcrf\u00b7fen", "wir", "uns", "denn", "kein", "and\u00b7re", "Rech\u00b7nung", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Der Fehler stellt sich auch im Ampt und Alter ein.", "tokens": ["Der", "Feh\u00b7ler", "stellt", "sich", "auch", "im", "Ampt", "und", "Al\u00b7ter", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPRART", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Denn bist du von der Bahn des Lehrens nie gewichen/", "tokens": ["Denn", "bist", "du", "von", "der", "Bahn", "des", "Leh\u00b7rens", "nie", "ge\u00b7wi\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Du hast die Tugenden den Hertzen eingepr\u00e4gt/", "tokens": ["Du", "hast", "die", "Tu\u00b7gen\u00b7den", "den", "Hert\u00b7zen", "ein\u00b7ge\u00b7pr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Und stets mit Ruhm belohnt: die Fehler ausgestrichen/", "tokens": ["Und", "stets", "mit", "Ruhm", "be\u00b7lohnt", ":", "die", "Feh\u00b7ler", "aus\u00b7ge\u00b7stri\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVPP", "$.", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Zum guten Beyspiel stets die Knaben angeregt.", "tokens": ["Zum", "gu\u00b7ten", "Bey\u00b7spiel", "stets", "die", "Kna\u00b7ben", "an\u00b7ge\u00b7regt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Jhr Flei\u00df/ war dein Triumff/ die Freud\u2019 im wolgerathen", "tokens": ["Ihr", "Flei\u00df", "/", "war", "dein", "Tri\u00b7umff", "/", "die", "Freud'", "im", "wol\u00b7ge\u00b7ra\u00b7then"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "VAFIN", "PPOSAT", "NN", "$(", "ART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Viel gr\u00f6sser/ als wenn Rom die B\u00fcrger-Meister macht.", "tokens": ["Viel", "gr\u00f6s\u00b7ser", "/", "als", "wenn", "Rom", "die", "B\u00fcr\u00b7ger\u00b7Meis\u00b7ter", "macht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KOKOM", "KOUS", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "So freut der G\u00e4rtner sich wenn seine junge Schnaten", "tokens": ["So", "freut", "der", "G\u00e4rt\u00b7ner", "sich", "wenn", "sei\u00b7ne", "jun\u00b7ge", "Schna\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Ein fruchtbar Sonnenschein zum Wachsthum aufgebracht.", "tokens": ["Ein", "frucht\u00b7bar", "Son\u00b7nen\u00b7schein", "zum", "Wach\u00b7sthum", "auf\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Und sol ich die Gedult bey dieser M\u00fch erwegen/", "tokens": ["Und", "sol", "ich", "die", "Ge\u00b7dult", "bey", "die\u00b7ser", "M\u00fch", "er\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Wie redlich hast du nicht du werther Grei\u00df getaurt!", "tokens": ["Wie", "red\u00b7lich", "hast", "du", "nicht", "du", "wert\u00b7her", "Grei\u00df", "ge\u00b7taurt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PTKNEG", "PPER", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Es hie\u00df ", "tokens": ["Es", "hie\u00df"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.72": {"text": "Wenn ihr verstockter Sinn mit Bo\u00dfheit stund verm aurt.", "tokens": ["Wenn", "ihr", "ver\u00b7stock\u00b7ter", "Sinn", "mit", "Bo\u00df\u00b7heit", "stund", "verm", "aurt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VVFIN", "APPRART", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Ja neun und dreyssig Jahr in solchem Zirckel lauffen/", "tokens": ["Ja", "neun", "und", "dreys\u00b7sig", "Jahr", "in", "sol\u00b7chem", "Zir\u00b7ckel", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "CARD", "KON", "CARD", "NN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Ist ein weit schwerer Werck als ein Olympisch Spiel.", "tokens": ["Ist", "ein", "weit", "schwe\u00b7rer", "Werck", "als", "ein", "O\u00b7lym\u00b7pisch", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJD", "ADJA", "NN", "KOKOM", "ART", "NN", "NN", "$."], "meter": "--++-+-+-+-+", "measure": "anapaest.init"}, "line.75": {"text": "Es bringe Griechenland sein Rennen gantz zu hauffen/", "tokens": ["Es", "brin\u00b7ge", "Grie\u00b7chen\u00b7land", "sein", "Ren\u00b7nen", "gantz", "zu", "hauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Sein Schwei\u00df/ sein Staub und M\u00fch/ sind nichts f\u00fcr diesem", "tokens": ["Sein", "Schwei\u00df", "/", "sein", "Staub", "und", "M\u00fch", "/", "sind", "nichts", "f\u00fcr", "die\u00b7sem"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "KON", "NN", "$(", "VAFIN", "PIS", "APPR", "PDAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.77": {"text": "Der arge Neid wei\u00df sonst dies\u2019 Arbeit stets zu tadeln/", "tokens": ["Der", "ar\u00b7ge", "Neid", "wei\u00df", "sonst", "dies'", "Ar\u00b7beit", "stets", "zu", "ta\u00b7deln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PDAT", "NN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Die er aus Z\u00e4rtligkeit doch nicht verrichten kan.", "tokens": ["Die", "er", "aus", "Z\u00e4rt\u00b7lig\u00b7keit", "doch", "nicht", "ver\u00b7rich\u00b7ten", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Hingegen wil GOtt so das Ampt und Lehrer adeln/", "tokens": ["Hin\u00b7ge\u00b7gen", "wil", "Gott", "so", "das", "Ampt", "und", "Leh\u00b7rer", "a\u00b7deln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "ADV", "ART", "NN", "KON", "NN", "VVINF", "$("], "meter": "+--++--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.80": {"text": "Da\u00df sie sind Sternen gleich/ mit Klarheit angethan.", "tokens": ["Da\u00df", "sie", "sind", "Ster\u00b7nen", "gleich", "/", "mit", "Klar\u00b7heit", "an\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "NN", "ADV", "$(", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Du Seelger Lehrer du/ den Creutz und Noth bewehret/", "tokens": ["Du", "Seel\u00b7ger", "Leh\u00b7rer", "du", "/", "den", "Creutz", "und", "Noth", "be\u00b7weh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "NE", "$(", "ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Schlaff in der Erden-Scho\u00df/ du hast genung gewacht.", "tokens": ["Schlaff", "in", "der", "Er\u00b7den\u00b7Scho\u00df", "/", "du", "hast", "ge\u00b7nung", "ge\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$(", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Du f\u00fchlst nicht mehr den Schmertz der deinen Leib verzehret/", "tokens": ["Du", "f\u00fchlst", "nicht", "mehr", "den", "Schmertz", "der", "dei\u00b7nen", "Leib", "ver\u00b7zeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ART", "NN", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Du sihst nicht mehr die Angst so dir offt hei\u00df gemacht.", "tokens": ["Du", "sihst", "nicht", "mehr", "die", "Angst", "so", "dir", "offt", "hei\u00df", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ART", "NN", "ADV", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Dein Leben schien wol recht ein Meer voll Bitterkeiten/", "tokens": ["Dein", "Le\u00b7ben", "schien", "wol", "recht", "ein", "Meer", "voll", "Bit\u00b7ter\u00b7kei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Als in des Wassers-Fluth der \u00e4ltste Sohn ertranck/", "tokens": ["Als", "in", "des", "Was\u00b7ser\u00b7sFluth", "der", "\u00e4lts\u00b7te", "Sohn", "er\u00b7tranck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Den andern kurtz hernach der Tod dich hie\u00df begleiten:", "tokens": ["Den", "an\u00b7dern", "kurtz", "her\u00b7nach", "der", "Tod", "dich", "hie\u00df", "be\u00b7glei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "ADV", "ART", "NN", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Wer sah nicht wie dein Geist im trauren da versanck!", "tokens": ["Wer", "sah", "nicht", "wie", "dein", "Geist", "im", "trau\u00b7ren", "da", "ver\u00b7sanck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "KOKOM", "PPOSAT", "NN", "APPRART", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Und was erwehn ich viel die Jammer-vollen F\u00e4lle?", "tokens": ["Und", "was", "er\u00b7wehn", "ich", "viel", "die", "Jam\u00b7mer\u00b7vol\u00b7len", "F\u00e4l\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ich sch\u00e4tze dich begl\u00fcckt/ der du hast obgesigt/", "tokens": ["Ich", "sch\u00e4t\u00b7ze", "dich", "be\u00b7gl\u00fcckt", "/", "der", "du", "hast", "ob\u00b7ge\u00b7sigt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "$(", "PRELS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Dein Schulen-Ampt vertauscht mit einer bessern Stelle/", "tokens": ["Dein", "Schu\u00b7len\u00b7Ampt", "ver\u00b7tauscht", "mit", "ei\u00b7ner", "bes\u00b7sern", "Stel\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Und Tr\u00fcbsal/ Angst und Noth/ zugleich begraben ligt.", "tokens": ["Und", "Tr\u00fcb\u00b7sal", "/", "Angst", "und", "Noth", "/", "zu\u00b7gleich", "be\u00b7gra\u00b7ben", "ligt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "NN", "KON", "NN", "$(", "ADV", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Kein Tagel\u00f6hner kan so nach dem Abend ruffen/", "tokens": ["Kein", "Ta\u00b7ge\u00b7l\u00f6h\u00b7ner", "kan", "so", "nach", "dem", "A\u00b7bend", "ruf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Da seiner Arbeits Last gew\u00fcnschtes Ende nimmt/", "tokens": ["Da", "sei\u00b7ner", "Ar\u00b7beits", "Last", "ge\u00b7w\u00fcnschtes", "En\u00b7de", "nimmt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NE", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.95": {"text": "Als du von deinem GOtt mit beten/ seufftzen/ hoffen/", "tokens": ["Als", "du", "von", "dei\u00b7nem", "Gott", "mit", "be\u00b7ten", "/", "seufft\u00b7zen", "/", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "APPR", "VVINF", "$(", "VVINF", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Dein St\u00fcndlein hast begehrt/ so \u00fcber dich bestimmt.", "tokens": ["Dein", "St\u00fcnd\u00b7lein", "hast", "be\u00b7gehrt", "/", "so", "\u00fc\u00b7ber", "dich", "be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$(", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Du bist wie Simeon in Frieden hingefahren/", "tokens": ["Du", "bist", "wie", "Si\u00b7me\u00b7on", "in", "Frie\u00b7den", "hin\u00b7ge\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "NE", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Von Kr\u00e4fften abgeschw\u00e4cht/ des sauren Lebens satt;", "tokens": ["Von", "Kr\u00e4ff\u00b7ten", "ab\u00b7ge\u00b7schw\u00e4cht", "/", "des", "sau\u00b7ren", "Le\u00b7bens", "satt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$(", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Nun schweben umb dich rumb der Cherubinen Schaaren/", "tokens": ["Nun", "schwe\u00b7ben", "umb", "dich", "rumb", "der", "Che\u00b7ru\u00b7bi\u00b7nen", "Schaa\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Da deine Herrligkeit kein Ziel noch Ende hat.", "tokens": ["Da", "dei\u00b7ne", "Herr\u00b7lig\u00b7keit", "kein", "Ziel", "noch", "En\u00b7de", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PIAT", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Mein Lehrer/ ich wil nicht dein ruhig Grab entweyhen/", "tokens": ["Mein", "Leh\u00b7rer", "/", "ich", "wil", "nicht", "dein", "ru\u00b7hig", "Grab", "ent\u00b7wey\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPER", "VMFIN", "PTKNEG", "PPOSAT", "ADJD", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Und schreibe weit entfernt von aller Heucheley:", "tokens": ["Und", "schrei\u00b7be", "weit", "ent\u00b7fernt", "von", "al\u00b7ler", "Heu\u00b7che\u00b7ley", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Mir wird gemeine Stadt den Beyfall gern verleyhen/", "tokens": ["Mir", "wird", "ge\u00b7mei\u00b7ne", "Stadt", "den", "Bey\u00b7fall", "gern", "ver\u00b7ley\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Da\u00df so ein Schulen-Mann ein edles Kleinod sey.", "tokens": ["Da\u00df", "so", "ein", "Schu\u00b7len\u00b7Mann", "ein", "ed\u00b7les", "Klei\u00b7nod", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}