{"textgrid.poem.43273": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1L: Immer fein nach der Schablone,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Immer fein nach der Schablone,", "tokens": ["Im\u00b7mer", "fein", "nach", "der", "Scha\u00b7blo\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Immer fein in dem Geleise!", "tokens": ["Im\u00b7mer", "fein", "in", "dem", "Ge\u00b7lei\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Leg' zurecht Dir Schmerz und Wonne", "tokens": ["Leg'", "zu\u00b7recht", "Dir", "Schmerz", "und", "Won\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach der hergebrachten Weise.", "tokens": ["Nach", "der", "her\u00b7ge\u00b7brach\u00b7ten", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und kann nicht in alle Formen", "tokens": ["Und", "kann", "nicht", "in", "al\u00b7le", "For\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PTKNEG", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein vertracktes Wesen passen,", "tokens": ["Dein", "ver\u00b7track\u00b7tes", "We\u00b7sen", "pas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Widerstrebt es dir, mit Normen,", "tokens": ["Wi\u00b7der\u00b7strebt", "es", "dir", ",", "mit", "Nor\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Altgewohnt, dich zu befassen,", "tokens": ["Alt\u00b7ge\u00b7wohnt", ",", "dich", "zu", "be\u00b7fas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ei, so lasse dich auch stutzen,", "tokens": ["Ei", ",", "so", "las\u00b7se", "dich", "auch", "stut\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lasse dich ein wenig blenden;", "tokens": ["Las\u00b7se", "dich", "ein", "we\u00b7nig", "blen\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Um die Form nicht zu beschmutzen,", "tokens": ["Um", "die", "Form", "nicht", "zu", "be\u00b7schmut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df den Inhalt lieber sch\u00e4nden.", "tokens": ["La\u00df", "den", "In\u00b7halt", "lie\u00b7ber", "sch\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Lasse langsam Dich dressiren", "tokens": ["Las\u00b7se", "lang\u00b7sam", "Dich", "dres\u00b7si\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu der Alltags-Kleingeld Phrase;", "tokens": ["Zu", "der", "All\u00b7tags\u00b7Klein\u00b7geld", "Phra\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lern' gleich Anderen brilliren", "tokens": ["Lern'", "gleich", "An\u00b7de\u00b7ren", "bril\u00b7li\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ADJA", "VVINF"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Mit der hohlsten Seifenblase.", "tokens": ["Mit", "der", "hohls\u00b7ten", "Sei\u00b7fen\u00b7bla\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Deinen Ruhm an allen Orten", "tokens": ["Dei\u00b7nen", "Ruhm", "an", "al\u00b7len", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Werden sie dann singen, sagen \u2013", "tokens": ["Wer\u00b7den", "sie", "dann", "sin\u00b7gen", ",", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$,", "VVINF", "$("], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "Aber was aus Dir geworden,", "tokens": ["A\u00b7ber", "was", "aus", "Dir", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "PPER", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Darfst Du selbst Dich niemals fragen.", "tokens": ["Darfst", "Du", "selbst", "Dich", "nie\u00b7mals", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}