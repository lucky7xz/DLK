{"textgrid.poem.55418": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Zahme Xenien", "genre": "verse", "period": "N.A.", "pub_year": 1825, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kein St\u00fcndchen schleiche dir vergebens,", "tokens": ["Kein", "St\u00fcnd\u00b7chen", "schlei\u00b7che", "dir", "ver\u00b7ge\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Benutze, was dir widerfahren.", "tokens": ["Be\u00b7nut\u00b7ze", ",", "was", "dir", "wi\u00b7der\u00b7fah\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Verdru\u00df ist auch ein Teil des Lebens,", "tokens": ["Ver\u00b7dru\u00df", "ist", "auch", "ein", "Teil", "des", "Le\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den sollen die Xenien bewahren.", "tokens": ["Den", "sol\u00b7len", "die", "Xe\u00b7ni\u00b7en", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Alles verdienet Reim und Flei\u00df,", "tokens": ["Al\u00b7les", "ver\u00b7die\u00b7net", "Reim", "und", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wenn man es recht zu sondern wei\u00df.", "tokens": ["Wenn", "man", "es", "recht", "zu", "son\u00b7dern", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "APPR", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gott gr\u00fc\u00df euch, Br\u00fcder,", "tokens": ["Gott", "gr\u00fc\u00df", "euch", ",", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "S\u00e4mtliche Oner und Aner!", "tokens": ["S\u00e4mt\u00b7li\u00b7che", "O\u00b7ner", "und", "A\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Ich bin Weltbewohner,", "tokens": ["Ich", "bin", "Welt\u00b7be\u00b7woh\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Bin Weimaraner,", "tokens": ["Bin", "Wei\u00b7ma\u00b7ra\u00b7ner", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Ich habe diesem edlen Kreis", "tokens": ["Ich", "ha\u00b7be", "die\u00b7sem", "ed\u00b7len", "Kreis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Bildung mich empfohlen,", "tokens": ["Durch", "Bil\u00b7dung", "mich", "emp\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und wer es etwa besser wei\u00df,", "tokens": ["Und", "wer", "es", "et\u00b7wa", "bes\u00b7ser", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der mag's woanders holen.", "tokens": ["Der", "mag's", "woan\u00b7ders", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "\u00bbwohin willst du dich wenden?\u00ab", "tokens": ["\u00bb", "wo\u00b7hin", "willst", "du", "dich", "wen\u00b7den", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nach Weimar-Jena, der gro\u00dfen Stadt,", "tokens": ["Nach", "Wei\u00b7ma\u00b7rJe\u00b7na", ",", "der", "gro\u00b7\u00dfen", "Stadt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Die an beiden Enden", "tokens": ["Die", "an", "bei\u00b7den", "En\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Viel Gutes hat.", "tokens": ["Viel", "Gu\u00b7tes", "hat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Gar nichts Neues sagt ihr mir!", "tokens": ["Gar", "nichts", "Neu\u00b7es", "sagt", "ihr", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Unvollkommen war ich ohne Zweifel.", "tokens": ["Un\u00b7voll\u00b7kom\u00b7men", "war", "ich", "oh\u00b7ne", "Zwei\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Was ihr an mir tadelt, dumme Teufel,", "tokens": ["Was", "ihr", "an", "mir", "ta\u00b7delt", ",", "dum\u00b7me", "Teu\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ich wei\u00df es besser als ihr!", "tokens": ["Ich", "wei\u00df", "es", "bes\u00b7ser", "als", "ihr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-++", "measure": "unknown.measure.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbsag mir doch, von deinen Gegnern", "tokens": ["\u00bb", "sag", "mir", "doch", ",", "von", "dei\u00b7nen", "Geg\u00b7nern"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVIMP", "PPER", "ADV", "$,", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warum willst du gar nichts wissen?\u00ab", "tokens": ["Wa\u00b7rum", "willst", "du", "gar", "nichts", "wis\u00b7sen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sag mir doch, ob du dahin trittst,", "tokens": ["Sag", "mir", "doch", ",", "ob", "du", "da\u00b7hin", "trittst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "KOUS", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo man in den Weg ........?", "tokens": ["Wo", "man", "in", "den", "Weg", "........", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIS", "APPR", "ART", "NN", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}