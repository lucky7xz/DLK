{"textgrid.poem.53522": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die arme Frau", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Mann? mein dicker Mann, der Dichter?", "tokens": ["Mein", "Mann", "?", "mein", "di\u00b7cker", "Mann", ",", "der", "Dich\u00b7ter", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du lieber Gott, da seid mir still!", "tokens": ["Du", "lie\u00b7ber", "Gott", ",", "da", "seid", "mir", "still", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NN", "$,", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Don Juan? Ein braver, schlichter", "tokens": ["Ein", "Don", "Juan", "?", "Ein", "bra\u00b7ver", ",", "schlich\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "NE", "$.", "ART", "ADJA", "$,", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Bourgeois \u2013 wie Gott ihn haben will.", "tokens": ["Bour\u00b7ge\u00b7ois", "\u2013", "wie", "Gott", "ihn", "ha\u00b7ben", "will", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PWAV", "NN", "PPER", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Da steht in seinen schmalen B\u00fcchern,", "tokens": ["Da", "steht", "in", "sei\u00b7nen", "schma\u00b7len", "B\u00fc\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wieviele Frauen er gek\u00fc\u00dft;", "tokens": ["wie\u00b7vie\u00b7le", "Frau\u00b7en", "er", "ge\u00b7k\u00fc\u00dft", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "von seidenen Haaren, seidenen T\u00fcchern,", "tokens": ["von", "sei\u00b7de\u00b7nen", "Haa\u00b7ren", ",", "sei\u00b7de\u00b7nen", "T\u00fc\u00b7chern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Begehren, Kitzel, Brunst, Gel\u00fcst . . .", "tokens": ["Be\u00b7geh\u00b7ren", ",", "Kit\u00b7zel", ",", "Brunst", ",", "Ge\u00b7l\u00fcst", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Liebwerte Schwestern, la\u00dft die Briefe,", "tokens": ["Lieb\u00b7wer\u00b7te", "Schwes\u00b7tern", ",", "la\u00dft", "die", "Brie\u00b7fe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "den anonymen Veilchenstrau\u00df!", "tokens": ["den", "an\u00b7o\u00b7ny\u00b7men", "Veil\u00b7chen\u00b7strau\u00df", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es k\u00f6nnt ihn st\u00f6ren, wenn er schliefe.", "tokens": ["Es", "k\u00f6nnt", "ihn", "st\u00f6\u00b7ren", ",", "wenn", "er", "schlie\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn meist ruht sich der Dicke aus.", "tokens": ["Denn", "meist", "ruht", "sich", "der", "Di\u00b7cke", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und faul und fett und so gefr\u00e4\u00dfig", "tokens": ["Und", "faul", "und", "fett", "und", "so", "ge\u00b7fr\u00e4\u00b7\u00dfig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ist er und immer indigniert.", "tokens": ["ist", "er", "und", "im\u00b7mer", "in\u00b7di\u00b7gniert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "ADV", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und dabei gluckert er unm\u00e4\u00dfig", "tokens": ["Und", "da\u00b7bei", "glu\u00b7ckert", "er", "un\u00b7m\u00e4\u00b7\u00dfig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "vom Rotwein, den er temperiert.", "tokens": ["vom", "Rot\u00b7wein", ",", "den", "er", "tem\u00b7pe\u00b7riert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "Ich sah euch wilder und erpichter", "tokens": ["Ich", "sah", "euch", "wil\u00b7der", "und", "er\u00b7pich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Tag zu Tag \u2013 ach! la\u00dft das sein!", "tokens": ["von", "Tag", "zu", "Tag", "\u2013", "ach", "!", "la\u00dft", "das", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$(", "ITJ", "$.", "VVIMP", "ART", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Mann? mein dicker Mann, der Dichter?", "tokens": ["Mein", "Mann", "?", "mein", "di\u00b7cker", "Mann", ",", "der", "Dich\u00b7ter", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In B\u00fcchern: ja.", "tokens": ["In", "B\u00fc\u00b7chern", ":", "ja", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$.", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Im Leben: nein.", "tokens": ["Im", "Le\u00b7ben", ":", "nein", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$.", "PTKANT", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}