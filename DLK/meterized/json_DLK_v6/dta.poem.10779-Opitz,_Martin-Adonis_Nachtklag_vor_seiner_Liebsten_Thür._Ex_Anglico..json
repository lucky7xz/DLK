{"dta.poem.10779": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Adonis   Nachtklag vor seiner Liebsten Th\u00fcr.  \n  Ex Anglico.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Mag dann/ ach Sch\u00e4tzelein/", "tokens": ["Mag", "dann", "/", "ach", "Sch\u00e4t\u00b7zel\u00b7ein", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$(", "XY", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Von euch keiner Gnaden schein", "tokens": ["Von", "euch", "kei\u00b7ner", "Gna\u00b7den", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PIAT", "NN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Widerfahren mir/", "tokens": ["Wi\u00b7der\u00b7fah\u00b7ren", "mir", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PPER", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Der ich lig vor ewrer Th\u00fcr/", "tokens": ["Der", "ich", "lig", "vor", "ew\u00b7rer", "Th\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Vnd netze diese Schwell", "tokens": ["Vnd", "net\u00b7ze", "die\u00b7se", "Schwell"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Mit manchem threnenbach/", "tokens": ["Mit", "man\u00b7chem", "thre\u00b7nen\u00b7bach", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die ich doch wieder schnell", "tokens": ["Die", "ich", "doch", "wie\u00b7der", "schnell"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Mit Seufftzen trucken mach.", "tokens": ["Mit", "Seufft\u00b7zen", "tru\u00b7cken", "mach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "So manches tr\u00f6pfflein", "tokens": ["So", "man\u00b7ches", "tr\u00f6pf\u00b7flein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Kan erweichen einen Stein/", "tokens": ["Kan", "er\u00b7wei\u00b7chen", "ei\u00b7nen", "Stein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ewer steinen Hertz", "tokens": ["E\u00b7wer", "stei\u00b7nen", "Hertz"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Kan erweichen gar kein schmertz.", "tokens": ["Kan", "er\u00b7wei\u00b7chen", "gar", "kein", "schmertz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "PIAT", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So komme dann/ o Todt/", "tokens": ["So", "kom\u00b7me", "dann", "/", "o", "Todt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$(", "FM", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Endt mir das leben mein", "tokens": ["Endt", "mir", "das", "le\u00b7ben", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDS", "VVFIN", "PPOSAT"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "In dieser harten Noth/", "tokens": ["In", "die\u00b7ser", "har\u00b7ten", "Noth", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Darinn ich leide Pein.", "tokens": ["Da\u00b7rinn", "ich", "lei\u00b7de", "Pein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Richten darff man mir", "tokens": ["Rich\u00b7ten", "darff", "man", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PIS", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Keine Marmor Grabes zier/", "tokens": ["Kei\u00b7ne", "Mar\u00b7mor", "Gra\u00b7bes", "zier", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur ein Wasem klein", "tokens": ["Nur", "ein", "Wa\u00b7sem", "klein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADJD"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Soll bedecken mein Gebein:", "tokens": ["Soll", "be\u00b7de\u00b7cken", "mein", "Ge\u00b7bein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit diesen Worten gr\u00fcn:", "tokens": ["Mit", "die\u00b7sen", "Wor\u00b7ten", "gr\u00fcn", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Der hie zu tode blieb/", "tokens": ["Der", "hie", "zu", "to\u00b7de", "blieb", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Den hat gebracht dahin/", "tokens": ["Den", "hat", "ge\u00b7bracht", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "VVPP", "PAV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Sein Trew vnd grosse Lieb.", "tokens": ["Sein", "Trew", "vnd", "gros\u00b7se", "Lieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Au\u00df mir dan\u0303 J\u00e4rlich", "tokens": ["Au\u00df", "mir", "da\u00f1", "J\u00e4r\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Rote R\u00f6\u00dflein liebelich", "tokens": ["Ro\u00b7te", "R\u00f6\u00df\u00b7lein", "lie\u00b7be\u00b7lich"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch vergi\u00df nit mein", "tokens": ["Auch", "ver\u00b7gi\u00df", "nit", "mein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PTKNEG", "PPOSAT"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Wachsen wird vnd Ro\u00dfmarein/", "tokens": ["Wach\u00b7sen", "wird", "vnd", "Ro\u00df\u00b7ma\u00b7rein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Drau\u00df manch verliebtes Hertz", "tokens": ["Drau\u00df", "manch", "ver\u00b7lieb\u00b7tes", "Hertz"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Zur\u00fcst ein Str\u00e4usselein/", "tokens": ["Zu\u00b7r\u00fcst", "ein", "Str\u00e4us\u00b7sel\u00b7ein", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Darmit in liebes schmertz", "tokens": ["Dar\u00b7mit", "in", "lie\u00b7bes", "schmertz"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Verehr den Liebsten sein.", "tokens": ["Ver\u00b7ehr", "den", "Liebs\u00b7ten", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wie? wann das Gl\u00fcck wolt/", "tokens": ["Wie", "?", "wann", "das", "Gl\u00fcck", "wolt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PWAV", "ART", "NN", "VMFIN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Da\u00df die Liebste kommen solt/", "tokens": ["Da\u00df", "die", "Liebs\u00b7te", "kom\u00b7men", "solt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd von vngefehr", "tokens": ["Vnd", "von", "vn\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Vber mir Spatzieren her/", "tokens": ["Vber", "mir", "Spat\u00b7zie\u00b7ren", "her", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "PTKVZ", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "Vnd lese diese Schrifft/", "tokens": ["Vnd", "le\u00b7se", "die\u00b7se", "Schrifft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vnd sich besinne mein/", "tokens": ["Vnd", "sich", "be\u00b7sin\u00b7ne", "mein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "PPOSAT", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df sie mir hab gestifft", "tokens": ["Da\u00df", "sie", "mir", "hab", "ge\u00b7stifft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Di\u00df vngl\u00fcck all allein:", "tokens": ["Di\u00df", "vn\u00b7gl\u00fcck", "all", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PIAT", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Als dann wird sie mich", "tokens": ["Als", "dann", "wird", "sie", "mich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "VAFIN", "PPER", "PRF"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Erst beweinen bitterlich/", "tokens": ["Erst", "be\u00b7wei\u00b7nen", "bit\u00b7ter\u00b7lich", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich nur zu trew/", "tokens": ["Da\u00df", "ich", "nur", "zu", "trew", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKA", "ADJD", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Sie gewesen nur zu schew/", "tokens": ["Sie", "ge\u00b7we\u00b7sen", "nur", "zu", "schew", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAPP", "ADV", "PTKA", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch fellt vieleicht herab", "tokens": ["Auch", "fellt", "vie\u00b7leicht", "her\u00b7ab"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Au\u00df jhren Aeugelein", "tokens": ["Au\u00df", "jhren", "A\u00b7e\u00b7u\u00b7ge\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Ein tr\u00f6pflein auff das Grab/", "tokens": ["Ein", "tr\u00f6pf\u00b7lein", "auff", "das", "Grab", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Erquicket mein gebein.", "tokens": ["Er\u00b7quic\u00b7ket", "mein", "ge\u00b7bein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Als dann erst werd ich", "tokens": ["Als", "dann", "erst", "werd", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "VAFIN", "PPER"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "In dem tode frewen mich/", "tokens": ["In", "dem", "to\u00b7de", "fre\u00b7wen", "mich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd in aller Leut", "tokens": ["Vnd", "in", "al\u00b7ler", "Leut"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Munde triumphieren weit.", "tokens": ["Mun\u00b7de", "tri\u00b7um\u00b7phie\u00b7ren", "weit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Adonis trew wirt sein.", "tokens": ["A\u00b7do\u00b7nis", "trew", "wirt", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Ber\u00fchmet weid vnd breit/", "tokens": ["Be\u00b7r\u00fch\u00b7met", "weid", "vnd", "breit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Euch aber wird die Pein", "tokens": ["Euch", "a\u00b7ber", "wird", "die", "Pein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Der Rache sein bereit.", "tokens": ["Der", "Ra\u00b7che", "sein", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}