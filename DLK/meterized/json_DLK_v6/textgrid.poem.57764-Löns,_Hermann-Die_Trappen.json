{"textgrid.poem.57764": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Die Trappen", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Lieben das bringt viele Freud,", "tokens": ["Das", "Lie\u00b7ben", "das", "bringt", "vie\u00b7le", "Freud", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Das Lieben das bringt oftmals Leid;", "tokens": ["Das", "Lie\u00b7ben", "das", "bringt", "oft\u00b7mals", "Leid", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PDS", "VVFIN", "ADV", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Es fiel ein Schnee verwich'ne Nacht,", "tokens": ["Es", "fiel", "ein", "Schnee", "ver\u00b7wich'\u00b7ne", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der hat mir Schimpf und Schand gebracht.", "tokens": ["Der", "hat", "mir", "Schimpf", "und", "Schand", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich kann nicht \u00fcber die Stra\u00dfe gehn,", "tokens": ["Ich", "kann", "nicht", "\u00fc\u00b7ber", "die", "Stra\u00b7\u00dfe", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Kann niemand ins Gesichte sehn;", "tokens": ["Kann", "nie\u00b7mand", "ins", "Ge\u00b7sich\u00b7te", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es gehen Trappen aus und ein", "tokens": ["Es", "ge\u00b7hen", "Trap\u00b7pen", "aus", "und", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "KON", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bei meinem Kammerfensterlein.", "tokens": ["Bei", "mei\u00b7nem", "Kam\u00b7mer\u00b7fens\u00b7ter\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Jedwedem ist nun offenbar,", "tokens": ["Jed\u00b7we\u00b7dem", "ist", "nun", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df heute Nacht wer bei mir war,", "tokens": ["Da\u00df", "heu\u00b7te", "Nacht", "wer", "bei", "mir", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "PWS", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer bei mir war die ganze Nacht;", "tokens": ["Wer", "bei", "mir", "war", "die", "gan\u00b7ze", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der b\u00f6se Schnee hat's kund gemacht.", "tokens": ["Der", "b\u00f6\u00b7se", "Schnee", "hat's", "kund", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich nahm den Besen in die Hand", "tokens": ["Ich", "nahm", "den", "Be\u00b7sen", "in", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hab ihn hin und hergewandt;", "tokens": ["Und", "hab", "ihn", "hin", "und", "her\u00b7ge\u00b7wandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKVZ", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Kehren half mir wenig mehr,", "tokens": ["Das", "Keh\u00b7ren", "half", "mir", "we\u00b7nig", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Nachbarn sahen alle her.", "tokens": ["Die", "Nach\u00b7barn", "sa\u00b7hen", "al\u00b7le", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und hab ich meinen Ehrentag,", "tokens": ["Und", "hab", "ich", "mei\u00b7nen", "Eh\u00b7ren\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Kr\u00e4nzelein ich tragen mag;", "tokens": ["Kein", "Kr\u00e4n\u00b7zel\u00b7ein", "ich", "tra\u00b7gen", "mag", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und trage ich ein Kr\u00e4nzelein,", "tokens": ["Und", "tra\u00b7ge", "ich", "ein", "Kr\u00e4n\u00b7zel\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So darf es blo\u00df ein halbes sein.", "tokens": ["So", "darf", "es", "blo\u00df", "ein", "hal\u00b7bes", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}