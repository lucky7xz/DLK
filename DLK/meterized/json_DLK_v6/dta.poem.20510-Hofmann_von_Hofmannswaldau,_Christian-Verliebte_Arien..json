{"dta.poem.20510": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die freyheit leg ich dir zu deinen f\u00fcssen/", "tokens": ["Die", "frey\u00b7heit", "leg", "ich", "dir", "zu", "dei\u00b7nen", "f\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "PPER", "PPER", "APPR", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und die vernunfft liegt auch dabey/", "tokens": ["Und", "die", "ver\u00b7nunfft", "liegt", "auch", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Damit nun alles deine sey/", "tokens": ["Da\u00b7mit", "nun", "al\u00b7les", "dei\u00b7ne", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PIS", "PPOSAT", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wird mein gantzer leib dir k\u00fcnfftig dienen m\u00fcssen/", "tokens": ["So", "wird", "mein", "gant\u00b7zer", "leib", "dir", "k\u00fcnff\u00b7tig", "die\u00b7nen", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "PPER", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wer so redlich liebt/ und auff dich denckt/ wie ich/", "tokens": ["Denn", "wer", "so", "red\u00b7lich", "liebt", "/", "und", "auff", "dich", "denckt", "/", "wie", "ich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADJD", "VVFIN", "$(", "KON", "APPR", "PPER", "VVFIN", "$(", "PWAV", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Beh\u00e4lt gewi\u00dflich nichts zum eigenthum vor sich.", "tokens": ["Be\u00b7h\u00e4lt", "ge\u00b7wi\u00df\u00b7lich", "nichts", "zum", "ei\u00b7gen\u00b7thum", "vor", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "APPRART", "NN", "APPR", "PRF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich wei\u00df/ Amanda/ dir ein mehres nicht zu geben/", "tokens": ["Ich", "wei\u00df", "/", "A\u00b7man\u00b7da", "/", "dir", "ein", "meh\u00b7res", "nicht", "zu", "ge\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "NE", "$(", "PPER", "ART", "PIS", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich reiche dir so viel ich kan;", "tokens": ["Ich", "rei\u00b7che", "dir", "so", "viel", "ich", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nimm nur mein hertz geneiget an/", "tokens": ["Nimm", "nur", "mein", "hertz", "ge\u00b7nei\u00b7get", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ohne deinem dienst verschworen hat zu leben/", "tokens": ["Das", "oh\u00b7ne", "dei\u00b7nem", "dienst", "ver\u00b7schwo\u00b7ren", "hat", "zu", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPOSAT", "NN", "VVPP", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Schleu\u00df dieses schlechte gut in dein beh\u00e4ltni\u00df ein/", "tokens": ["Schleu\u00df", "die\u00b7ses", "schlech\u00b7te", "gut", "in", "dein", "be\u00b7h\u00e4lt\u00b7ni\u00df", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und la\u00df vertrauligkeit desselben siegel seyn.", "tokens": ["Und", "la\u00df", "ver\u00b7trau\u00b7lig\u00b7keit", "des\u00b7sel\u00b7ben", "sie\u00b7gel", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "NN", "PDAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Du wirst mein sanfftes joch mit reiner seide zieren/", "tokens": ["Du", "wirst", "mein", "sanff\u00b7tes", "joch", "mit", "rei\u00b7ner", "sei\u00b7de", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Cs wird mich deine sch\u00f6ne hand/", "tokens": ["Cs", "wird", "mich", "dei\u00b7ne", "sch\u00f6\u00b7ne", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das attla\u00df weich- und weisse band", "tokens": ["Das", "att\u00b7la\u00df", "weich", "und", "weis\u00b7se", "band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In den bebl\u00fcmten krey\u00df der wollust-g\u00e4rten f\u00fchren.", "tokens": ["In", "den", "be\u00b7bl\u00fcm\u00b7ten", "krey\u00df", "der", "wol\u00b7lust\u00b7g\u00e4r\u00b7ten", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein geist schmeckt allbereit der blumen lieblichkeit/", "tokens": ["Mein", "geist", "schmeckt", "all\u00b7be\u00b7reit", "der", "blu\u00b7men", "lieb\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Damit Amanda mir das schlechte haupt bestreut.", "tokens": ["Da\u00b7mit", "A\u00b7man\u00b7da", "mir", "das", "schlech\u00b7te", "haupt", "be\u00b7streut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Durch deine h\u00f6ffligkeit/ so mit dir ist gebohren/", "tokens": ["Durch", "dei\u00b7ne", "h\u00f6ff\u00b7lig\u00b7keit", "/", "so", "mit", "dir", "ist", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ADV", "APPR", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dich/ als ihre schwester liebt/", "tokens": ["Und", "dich", "/", "als", "ih\u00b7re", "schwes\u00b7ter", "liebt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "KOKOM", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird ja dein sclave nicht betr\u00fcbt/", "tokens": ["Wird", "ja", "dein", "scla\u00b7ve", "nicht", "be\u00b7tr\u00fcbt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du hast noch keinen freund zum marterthum erkohren.", "tokens": ["Du", "hast", "noch", "kei\u00b7nen", "freund", "zum", "mar\u00b7ter\u00b7thum", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wei\u00df/ du wirst mich noch auff rosen heissen stehn/", "tokens": ["Ich", "wei\u00df", "/", "du", "wirst", "mich", "noch", "auff", "ro\u00b7sen", "heis\u00b7sen", "stehn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VAFIN", "PPER", "ADV", "APPR", "VVINF", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und meine sonne mir nicht lassen untergehn.", "tokens": ["Und", "mei\u00b7ne", "son\u00b7ne", "mir", "nicht", "las\u00b7sen", "un\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wer wolte sich durch dich nicht willig lassen binden/", "tokens": ["Wer", "wol\u00b7te", "sich", "durch", "dich", "nicht", "wil\u00b7lig", "las\u00b7sen", "bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "PPER", "PTKNEG", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das angenehme wunder-licht/", "tokens": ["Das", "an\u00b7ge\u00b7neh\u00b7me", "wun\u00b7der\u00b7licht", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So aus den sch\u00f6nen augen bricht/", "tokens": ["So", "aus", "den", "sch\u00f6\u00b7nen", "au\u00b7gen", "bricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4st nichts als morgenschein und s\u00fcsse lust empfinden.", "tokens": ["L\u00e4st", "nichts", "als", "mor\u00b7gen\u00b7schein", "und", "s\u00fcs\u00b7se", "lust", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "ADV", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die seuffzer/ so allhier das hertze fahren l\u00e4st/", "tokens": ["Die", "seuff\u00b7zer", "/", "so", "all\u00b7hier", "das", "hert\u00b7ze", "fah\u00b7ren", "l\u00e4st", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADV", "ART", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Hat nur der \u00fcberflu\u00df der anmuth ausgepre\u00dft.", "tokens": ["Hat", "nur", "der", "\u00fc\u00b7berf\u00b7lu\u00df", "der", "an\u00b7muth", "aus\u00b7ge\u00b7pre\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "La\u00df deinen treuen freund in diesen banden sterben/", "tokens": ["La\u00df", "dei\u00b7nen", "treu\u00b7en", "freund", "in", "die\u00b7sen", "ban\u00b7den", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Komm/ dr\u00fccke mir die augen zu/", "tokens": ["Komm", "/", "dr\u00fc\u00b7cke", "mir", "die", "au\u00b7gen", "zu", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "PPER", "ART", "NN", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nichts blendet mich so gut/ als du.", "tokens": ["Nichts", "blen\u00b7det", "mich", "so", "gut", "/", "als", "du", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADJD", "$(", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und meine freyheit kan nicht gr\u00f6ssern ruhm erwerben/", "tokens": ["Und", "mei\u00b7ne", "frey\u00b7heit", "kan", "nicht", "gr\u00f6s\u00b7sern", "ruhm", "er\u00b7wer\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "PTKNEG", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als wenn/ indem dein mund bey ihrer leiche lacht/", "tokens": ["Als", "wenn", "/", "in\u00b7dem", "dein", "mund", "bey", "ih\u00b7rer", "lei\u00b7che", "lacht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "$(", "KOUS", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dein lob ihr einen sarg von sammt und rosen macht.", "tokens": ["Dein", "lob", "ihr", "ei\u00b7nen", "sarg", "von", "sammt", "und", "ro\u00b7sen", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ART", "ADJD", "APPR", "VVFIN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}