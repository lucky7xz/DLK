{"textgrid.poem.49825": {"metadata": {"author": {"name": "Sachs, Hans", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es ligt ein dorf im Beierlant,", "genre": "verse", "period": "N.A.", "pub_year": 1558, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ligt ein dorf im Beierlant,", "tokens": ["Es", "ligt", "ein", "dorf", "im", "Bei\u00b7er\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dasselbig F\u00fcnsing ist genant,", "tokens": ["das\u00b7sel\u00b7big", "F\u00fcn\u00b7sing", "ist", "ge\u00b7nant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "darin etwan vor langen jarn", "tokens": ["da\u00b7rin", "et\u00b7wan", "vor", "lan\u00b7gen", "jarn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ser einfeltige bauren warn,", "tokens": ["ser", "ein\u00b7fel\u00b7ti\u00b7ge", "bau\u00b7ren", "warn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "t\u00f6lpisch, tol, grob und ungeschaffen,", "tokens": ["t\u00f6l\u00b7pisch", ",", "tol", ",", "grob", "und", "un\u00b7ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "als ob sie weren aus Schlauraffen.", "tokens": ["als", "ob", "sie", "we\u00b7ren", "aus", "Schlaur\u00b7af\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PPER", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "der bauren einer eins tags fant", "tokens": ["der", "bau\u00b7ren", "ei\u00b7ner", "eins", "tags", "fant"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PIS", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ein armbrost in dem walt gespant,", "tokens": ["ein", "arm\u00b7brost", "in", "dem", "walt", "ge\u00b7spant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "das ein jeger verzettet het.", "tokens": ["das", "ein", "je\u00b7ger", "ver\u00b7zet\u00b7tet", "het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "VVPP", "VAFIN", "$."], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.10": {"text": "als der F\u00fcnsinger sehen tet,", "tokens": ["als", "der", "F\u00fcn\u00b7sin\u00b7ger", "se\u00b7hen", "tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.11": {"text": "da west er gar nicht, was es war,", "tokens": ["da", "west", "er", "gar", "nicht", ",", "was", "es", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "iedoch schaut er es entlich zwar,", "tokens": ["ie\u00b7doch", "schaut", "er", "es", "ent\u00b7lich", "zwar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADJD", "ADV", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.13": {"text": "vermeint, es wer ein kreuze wert,", "tokens": ["ver\u00b7meint", ",", "es", "wer", "ein", "kreu\u00b7ze", "wert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "und hub es balt auf von der ert,", "tokens": ["und", "hub", "es", "balt", "auf", "von", "der", "ert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "APPR", "ART", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "k\u00fcst es und wolt es zu im schmucken,", "tokens": ["k\u00fcst", "es", "und", "wolt", "es", "zu", "im", "schmu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VMFIN", "PPER", "APPR", "APPRART", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "und als ers an sein brust wart drucken,", "tokens": ["und", "als", "ers", "an", "sein", "brust", "wart", "dru\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "da lie\u00df das armbrost und gieng ab,", "tokens": ["da", "lie\u00df", "das", "arm\u00b7brost", "und", "gieng", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "schlug dem bauren die nasen rab.", "tokens": ["schlug", "dem", "bau\u00b7ren", "die", "na\u00b7sen", "rab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.19": {"text": "das armbrost wurf er von im gar,", "tokens": ["das", "arm\u00b7brost", "wurf", "er", "von", "im", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "APPRART", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "sprach: er legst hie ein ganzes jar,", "tokens": ["sprach", ":", "er", "legst", "hie", "ein", "gan\u00b7zes", "jar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "ich wolt dich nicht mer heben auf!", "tokens": ["ich", "wolt", "dich", "nicht", "mer", "he\u00b7ben", "auf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "eins tags gieng der F\u00fcnsinger hauf", "tokens": ["eins", "tags", "gieng", "der", "F\u00fcn\u00b7sin\u00b7ger", "hauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "in walt und woltn eichel abschlagen", "tokens": ["in", "walt", "und", "woltn", "ei\u00b7chel", "ab\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "PWAV", "ADJD", "VVINF"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.24": {"text": "und iren seuen heimhin tragen.", "tokens": ["und", "i\u00b7ren", "seu\u00b7en", "heim\u00b7hin", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "als sie nun stigen auf die eichen,", "tokens": ["als", "sie", "nun", "sti\u00b7gen", "auf", "die", "ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "was eichel sie kunten erreichen,", "tokens": ["was", "ei\u00b7chel", "sie", "kun\u00b7ten", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.27": {"text": "schlugen sie mit den stangen ab.", "tokens": ["schlu\u00b7gen", "sie", "mit", "den", "stan\u00b7gen", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.28": {"text": "nun in eim solchen sich begab,", "tokens": ["nun", "in", "eim", "sol\u00b7chen", "sich", "be\u00b7gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PIAT", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "das ein ast mit eim bauren brach,", "tokens": ["das", "ein", "ast", "mit", "eim", "bau\u00b7ren", "brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "derhalb er gar hoch fiel, hernach", "tokens": ["der\u00b7halb", "er", "gar", "hoch", "fiel", ",", "her\u00b7nach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PAV", "PPER", "ADV", "ADJD", "VVFIN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "mit dem kopf in einr zwisel bhieng", "tokens": ["mit", "dem", "kopf", "in", "einr", "zwi\u00b7sel", "bhieng"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.32": {"text": "und ri\u00df ab den hals, aller ding", "tokens": ["und", "ri\u00df", "ab", "den", "hals", ",", "al\u00b7ler", "ding"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "PIAT", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.33": {"text": "fiel der k\u00f6rper rab in das gras,", "tokens": ["fiel", "der", "k\u00f6r\u00b7per", "rab", "in", "das", "gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.34": {"text": "der kopf in der zwisl bliben was.", "tokens": ["der", "kopf", "in", "der", "zwisl", "bli\u00b7ben", "was", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NE", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "als nun die baurn heim wolten gen,", "tokens": ["als", "nun", "die", "baurn", "heim", "wol\u00b7ten", "gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKVZ", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "fundens under dem baumen den,", "tokens": ["fun\u00b7dens", "un\u00b7der", "dem", "bau\u00b7men", "den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PDS", "VVFIN", "ART", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.37": {"text": "da fundens in on einen kopf,", "tokens": ["da", "fun\u00b7dens", "in", "on", "ei\u00b7nen", "kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "kenten in, das es war Liendl Topf,", "tokens": ["ken\u00b7ten", "in", ",", "das", "es", "war", "Liendl", "Topf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "$,", "PRELS", "PPER", "VAFIN", "NN", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.39": {"text": "stunden umb in, sahen in an,", "tokens": ["stun\u00b7den", "umb", "in", ",", "sa\u00b7hen", "in", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "APPR", "APPR", "$,", "VVFIN", "APPR", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.40": {"text": "sagten: wo hat ern kopf hin tan?", "tokens": ["sag\u00b7ten", ":", "wo", "hat", "ern", "kopf", "hin", "tan", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PWAV", "VAFIN", "VVINF", "VMFIN", "ADV", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.41": {"text": "wer wei\u00df, ob er sein kopf noch het,", "tokens": ["wer", "wei\u00df", ",", "ob", "er", "sein", "kopf", "noch", "het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "PPER", "VAINF", "VMFIN", "ADV", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.42": {"text": "als er mit uns raus laufen tet.", "tokens": ["als", "er", "mit", "uns", "raus", "lau\u00b7fen", "tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "---+-+--", "measure": "unknown.measure.di"}, "line.43": {"text": "Heinz T\u00f6lp sprach: ich gieng mit im her,", "tokens": ["Heinz", "T\u00f6lp", "sprach", ":", "ich", "gieng", "mit", "im", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "APPRART", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "wei\u00df aber ie nit, ob auch er", "tokens": ["wei\u00df", "a\u00b7ber", "ie", "nit", ",", "ob", "auch", "er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "PTKNEG", "$,", "KOUS", "ADV", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.45": {"text": "sein kopf gehabt hat oder nit;", "tokens": ["sein", "kopf", "ge\u00b7habt", "hat", "o\u00b7der", "nit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAPP", "VAFIN", "KON", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "wir w\u00f6lln sein frauen fragen mit,", "tokens": ["wir", "w\u00f6lln", "sein", "frau\u00b7en", "fra\u00b7gen", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "dieselbig wirt es wi\u00dfen wol.", "tokens": ["die\u00b7sel\u00b7big", "wirt", "es", "wi\u00b7\u00dfen", "wol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "als sie die fragten tumb und tol,", "tokens": ["als", "sie", "die", "frag\u00b7ten", "tumb", "und", "tol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "da tet die F\u00fcnsingerin sagen:", "tokens": ["da", "tet", "die", "F\u00fcn\u00b7sin\u00b7ge\u00b7rin", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "+--++--+-", "measure": "trochaic.tetra.relaxed"}, "line.50": {"text": "am sambstag hab ich im gezwagen,", "tokens": ["am", "sambs\u00b7tag", "hab", "ich", "im", "ge\u00b7zwa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "da het er seinen kopf ie noch,", "tokens": ["da", "het", "er", "sei\u00b7nen", "kopf", "ie", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "hernach so wei\u00df ich aber doch", "tokens": ["her\u00b7nach", "so", "wei\u00df", "ich", "a\u00b7ber", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.53": {"text": "nicht, ob ern kopf am sonntag het,", "tokens": ["nicht", ",", "ob", "ern", "kopf", "am", "sonn\u00b7tag", "het", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "KOUS", "ADJA", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.54": {"text": "wiewol ich mit im hab geret.", "tokens": ["wie\u00b7wol", "ich", "mit", "im", "hab", "ge\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "APPRART", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "so einfeltig war frau und man;", "tokens": ["so", "ein\u00b7fel\u00b7tig", "war", "frau", "und", "man", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADJD", "KON", "PIS", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.56": {"text": "trugn auch nicht andre kleider an,", "tokens": ["trugn", "auch", "nicht", "and\u00b7re", "klei\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.57": {"text": "vier ellen lodn nam einer doch", "tokens": ["vier", "el\u00b7len", "lodn", "nam", "ei\u00b7ner", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVINF", "VVFIN", "ART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "und schneit mitten darein ein loch", "tokens": ["und", "schneit", "mit\u00b7ten", "da\u00b7rein", "ein", "loch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PAV", "ART", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.59": {"text": "und henkt das tuch denn an den hals", "tokens": ["und", "henkt", "das", "tuch", "denn", "an", "den", "hals"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "und g\u00fcrt es denn zu im. eins mals", "tokens": ["und", "g\u00fcrt", "es", "denn", "zu", "im", ".", "eins", "mals"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "APPRART", "$.", "CARD", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.61": {"text": "ein F\u00fcnsinger fur in die stat", "tokens": ["ein", "F\u00fcn\u00b7sin\u00b7ger", "fur", "in", "die", "stat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.62": {"text": "mit treit, da er gesehen hat", "tokens": ["mit", "treit", ",", "da", "er", "ge\u00b7se\u00b7hen", "hat"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUS", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.63": {"text": "ein schneider r\u00f6ck und kleider machen;", "tokens": ["ein", "schnei\u00b7der", "r\u00f6ck", "und", "klei\u00b7der", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "gro\u00df wunder het er ob den sachen", "tokens": ["gro\u00df", "wun\u00b7der", "het", "er", "ob", "den", "sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "VAFIN", "PPER", "KOUS", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "und beschaut eben alle ding,", "tokens": ["und", "be\u00b7schaut", "e\u00b7ben", "al\u00b7le", "ding", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.66": {"text": "und als er darnach einsmals fieng", "tokens": ["und", "als", "er", "dar\u00b7nach", "eins\u00b7mals", "fi\u00b7eng"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PAV", "ADV", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.67": {"text": "ein gro\u00dfen kreb\u00df an einem bach,", "tokens": ["ein", "gro\u00b7\u00dfen", "kreb\u00df", "an", "ei\u00b7nem", "bach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "als der F\u00fcnsinger an im sach", "tokens": ["als", "der", "F\u00fcn\u00b7sin\u00b7ger", "an", "im", "sach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "an fodern f\u00fc\u00dfn zwo gro\u00dfe scher,", "tokens": ["an", "fo\u00b7dern", "f\u00fc\u00dfn", "zwo", "gro\u00b7\u00dfe", "scher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "APPR", "CARD", "ADJA", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "meint er, der kreb\u00df ein schneider wer,", "tokens": ["meint", "er", ",", "der", "kreb\u00df", "ein", "schnei\u00b7der", "wer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PRELS", "VVFIN", "ART", "ADJA", "PWS", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.71": {"text": "sein h\u00f6rner wern zwo nadel ganz,", "tokens": ["sein", "h\u00f6r\u00b7ner", "wern", "zwo", "na\u00b7del", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "und seine eier underm schwanz", "tokens": ["und", "sei\u00b7ne", "ei\u00b7er", "un\u00b7derm", "schwanz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.73": {"text": "das weren eitel kneulein zwirn.", "tokens": ["das", "we\u00b7ren", "ei\u00b7tel", "kneu\u00b7lein", "zwirn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "mit freuden tet er sich heim tirn,", "tokens": ["mit", "freu\u00b7den", "tet", "er", "sich", "heim", "tirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PRF", "PTKVZ", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.75": {"text": "all sein nachbauren sagen tet,", "tokens": ["all", "sein", "nach\u00b7bau\u00b7ren", "sa\u00b7gen", "tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.76": {"text": "ein schneider er gefangen het,", "tokens": ["ein", "schnei\u00b7der", "er", "ge\u00b7fan\u00b7gen", "het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "der m\u00fcst in allen kleider machen.", "tokens": ["der", "m\u00fcst", "in", "al\u00b7len", "klei\u00b7der", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.78": {"text": "die bauren brachten zu den sachen", "tokens": ["die", "bau\u00b7ren", "brach\u00b7ten", "zu", "den", "sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.79": {"text": "zum schulthei\u00df ir loden zu hauf", "tokens": ["zum", "schult\u00b7hei\u00df", "ir", "lo\u00b7den", "zu", "hauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "VVFIN", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.80": {"text": "und setzten den kreb\u00df oben drauf;", "tokens": ["und", "setz\u00b7ten", "den", "kreb\u00df", "o\u00b7ben", "drauf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.81": {"text": "der kruch auf dem tuch auf und ab,", "tokens": ["der", "kruch", "auf", "dem", "tuch", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.82": {"text": "fiel oft under den tisch hinab.", "tokens": ["fiel", "oft", "un\u00b7der", "den", "tisch", "hin\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.83": {"text": "Heinz T\u00f6tschinbrei sprach: es dunkt mich,", "tokens": ["Heinz", "T\u00f6t\u00b7schin\u00b7brei", "sprach", ":", "es", "dunkt", "mich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.84": {"text": "der unser schneider schemet sich,", "tokens": ["der", "un\u00b7ser", "schnei\u00b7der", "sche\u00b7met", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "wil nichts schneiden, weil wir zusehen,", "tokens": ["wil", "nichts", "schnei\u00b7den", ",", "weil", "wir", "zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.86": {"text": "und kan doch wol schneiden und nehen,", "tokens": ["und", "kan", "doch", "wol", "schnei\u00b7den", "und", "ne\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+--+----", "measure": "iambic.di.relaxed"}, "line.87": {"text": "secht, wie tet er sein scher stet wetzen!", "tokens": ["secht", ",", "wie", "tet", "er", "sein", "scher", "stet", "wet\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VVFIN", "PPER", "PPOSAT", "ADJA", "VVFIN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.88": {"text": "ich rat, wir w\u00f6lln im heint zusetzen", "tokens": ["ich", "rat", ",", "wir", "w\u00f6lln", "im", "heint", "zu\u00b7set\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.89": {"text": "ein liecht und w\u00f6lln all von im gen", "tokens": ["ein", "liecht", "und", "w\u00f6lln", "all", "von", "im", "gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "VVFIN", "PIAT", "APPR", "APPRART", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.90": {"text": "und allein la\u00dfen machen den.", "tokens": ["und", "al\u00b7lein", "la\u00b7\u00dfen", "ma\u00b7chen", "den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "VVFIN", "ART", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.91": {"text": "da folgten sie all seinem rat", "tokens": ["da", "folg\u00b7ten", "sie", "all", "sei\u00b7nem", "rat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "und giengen alle von im spat;", "tokens": ["und", "gien\u00b7gen", "al\u00b7le", "von", "im", "spat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "APPR", "APPRART", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "ein liecht man bei im brennen lie\u00df,", "tokens": ["ein", "liecht", "man", "bei", "im", "bren\u00b7nen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PIS", "APPR", "APPRART", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "das doch zu nacht der kreb\u00df umstie\u00df", "tokens": ["das", "doch", "zu", "nacht", "der", "kreb\u00df", "um\u00b7stie\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.95": {"text": "und z\u00fcndet dise loden an,", "tokens": ["und", "z\u00fcn\u00b7det", "di\u00b7se", "lo\u00b7den", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.96": {"text": "das also das ganz haus abbran.", "tokens": ["das", "al\u00b7so", "das", "ganz", "haus", "ab\u00b7bran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.97": {"text": "der kreb\u00df sich in ein loch verkroch;", "tokens": ["der", "kreb\u00df", "sich", "in", "ein", "loch", "ver\u00b7kroch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PRF", "APPR", "ART", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.98": {"text": "den fundn die tollen bauren doch", "tokens": ["den", "fundn", "die", "tol\u00b7len", "bau\u00b7ren", "doch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.99": {"text": "und umb sein gro\u00dfe missetat", "tokens": ["und", "umb", "sein", "gro\u00b7\u00dfe", "mis\u00b7se\u00b7tat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.100": {"text": "urteiltens in mit gmeinem rat", "tokens": ["ur\u00b7teil\u00b7tens", "in", "mit", "gmei\u00b7nem", "rat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.101": {"text": "und wurfen den kreb\u00df in ein brunnen.", "tokens": ["und", "wur\u00b7fen", "den", "kreb\u00df", "in", "ein", "brun\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.102": {"text": "nach dem sie gro\u00dfe forcht gewunnen,", "tokens": ["nach", "dem", "sie", "gro\u00b7\u00dfe", "forcht", "ge\u00b7wun\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.103": {"text": "f\u00fcllten den brunnen aus mit erden,", "tokens": ["f\u00fcll\u00b7ten", "den", "brun\u00b7nen", "aus", "mit", "er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.104": {"text": "auf das nicht mer solt ledig werden", "tokens": ["auf", "das", "nicht", "mer", "solt", "le\u00b7dig", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PTKNEG", "ADV", "VMFIN", "ADJD", "VAINF"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.105": {"text": "das unzifr, und ist seit gwonheit,", "tokens": ["das", "un\u00b7zifr", ",", "und", "ist", "seit", "gwon\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "KON", "VAFIN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.106": {"text": "wenn ein F\u00fcnsinger hat hochzeit,", "tokens": ["wenn", "ein", "F\u00fcn\u00b7sin\u00b7ger", "hat", "hoch\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.107": {"text": "mu\u00df er f\u00fcren ein fuder erden", "tokens": ["mu\u00df", "er", "f\u00fc\u00b7ren", "ein", "fu\u00b7der", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.108": {"text": "auf den kreb\u00df, nicht ledig zu werden;", "tokens": ["auf", "den", "kreb\u00df", ",", "nicht", "le\u00b7dig", "zu", "wer\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PTKNEG", "ADJD", "PTKZU", "VAINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.109": {"text": "ist gar ein hoher b\u00fchel worn,", "tokens": ["ist", "gar", "ein", "ho\u00b7her", "b\u00fc\u00b7hel", "worn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.110": {"text": "so w\u00fct auf den kreb\u00df noch ir zorn.", "tokens": ["so", "w\u00fct", "auf", "den", "kreb\u00df", "noch", "ir", "zorn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ADV", "PIAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.111": {"text": "lief noch einer durchs dorf zum teil", "tokens": ["lief", "noch", "ei\u00b7ner", "durchs", "dorf", "zum", "teil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "APPRART", "NN", "APPRART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.112": {"text": "und schrier: kreb\u00df feil, kreb\u00df feil, kreb\u00df feil!", "tokens": ["und", "schrier", ":", "kreb\u00df", "feil", ",", "kreb\u00df", "feil", ",", "kreb\u00df", "feil", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.113": {"text": "der w\u00fcrt gar \u00fcbel von in gschlagen,", "tokens": ["der", "w\u00fcrt", "gar", "\u00fc\u00b7bel", "von", "in", "gschla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ADV", "ADJD", "APPR", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.114": {"text": "so gro\u00df feintschaft dem kreb\u00df sie tragen.", "tokens": ["so", "gro\u00df", "feint\u00b7schaft", "dem", "kreb\u00df", "sie", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "ART", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.115": {"text": "derhalb treiben noch mit in heut", "tokens": ["der\u00b7halb", "trei\u00b7ben", "noch", "mit", "in", "heut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "APPR", "APPR", "ADV"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.116": {"text": "mancherlei fatzwerk etlich leut,", "tokens": ["man\u00b7cher\u00b7lei", "fatz\u00b7werk", "et\u00b7lich", "leut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.117": {"text": "und wo noch heut zu diser frist", "tokens": ["und", "wo", "noch", "heut", "zu", "di\u00b7ser", "frist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.118": {"text": "ein mensch tol und unbsunnen ist,", "tokens": ["ein", "mensch", "tol", "und", "unb\u00b7sun\u00b7nen", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "KON", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "t\u00f6lpet, ungschickt, so spricht man: der", "tokens": ["t\u00f6l\u00b7pet", ",", "ung\u00b7schickt", ",", "so", "spricht", "man", ":", "der"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "$,", "ADJD", "$,", "ADV", "VVFIN", "PIS", "$.", "ART"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.120": {"text": "ist gar ein rechter F\u00fcnsinger.", "tokens": ["ist", "gar", "ein", "rech\u00b7ter", "F\u00fcn\u00b7sin\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.121": {"text": "der man noch vil findt jenseits bachs", "tokens": ["der", "man", "noch", "vil", "findt", "jen\u00b7seits", "bachs"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "ADV", "ADV", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.122": {"text": "und auch herjesseits, spricht Hans Sachs.", "tokens": ["und", "auch", "her\u00b7jes\u00b7seits", ",", "spricht", "Hans", "Sachs", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}