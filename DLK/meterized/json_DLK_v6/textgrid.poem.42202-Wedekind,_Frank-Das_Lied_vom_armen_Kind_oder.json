{"textgrid.poem.42202": {"metadata": {"author": {"name": "Wedekind, Frank", "birth": "N.A.", "death": "N.A."}, "title": "Das Lied vom armen Kind oder", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war einmal ein armes Kind,", "tokens": ["Es", "war", "ein\u00b7mal", "ein", "ar\u00b7mes", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das war auf beiden Augen blind,", "tokens": ["Das", "war", "auf", "bei\u00b7den", "Au\u00b7gen", "blind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf beiden Augen blind;", "tokens": ["Auf", "bei\u00b7den", "Au\u00b7gen", "blind", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da kam ein alter Mann daher,", "tokens": ["Da", "kam", "ein", "al\u00b7ter", "Mann", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der h\u00f6rt auf keinem Ohre mehr,", "tokens": ["Der", "h\u00f6rt", "auf", "kei\u00b7nem", "Oh\u00b7re", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf keinem Ohre mehr.", "tokens": ["Auf", "kei\u00b7nem", "Oh\u00b7re", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Sie zogen miteinander dann,", "tokens": ["Sie", "zo\u00b7gen", "mi\u00b7tein\u00b7an\u00b7der", "dann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das blinde Kind, der taube Mann,", "tokens": ["Das", "blin\u00b7de", "Kind", ",", "der", "tau\u00b7be", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der arme, alte, taube Mann.", "tokens": ["Der", "ar\u00b7me", ",", "al\u00b7te", ",", "tau\u00b7be", "Mann", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So zogen sie vor eine T\u00fcr,", "tokens": ["So", "zo\u00b7gen", "sie", "vor", "ei\u00b7ne", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da kroch ein lahmes Weib herf\u00fcr,", "tokens": ["Da", "kroch", "ein", "lah\u00b7mes", "Weib", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein lahmes Weib herf\u00fcr.", "tokens": ["Ein", "lah\u00b7mes", "Weib", "her\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Bei einem Automobilungl\u00fcck", "tokens": ["Bei", "ei\u00b7nem", "Au\u00b7to\u00b7mo\u00b7bi\u00b7lun\u00b7gl\u00fcck"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Lie\u00df sie ihr linkes Bein zur\u00fcck,", "tokens": ["Lie\u00df", "sie", "ihr", "lin\u00b7kes", "Bein", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das ganze Bein zur\u00fcck.", "tokens": ["Das", "gan\u00b7ze", "Bein", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nun zogen weiter alle drei,", "tokens": ["Nun", "zo\u00b7gen", "wei\u00b7ter", "al\u00b7le", "drei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das Kind, der Mann, das Weib dabei,", "tokens": ["Das", "Kind", ",", "der", "Mann", ",", "das", "Weib", "da\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das arme, lahme Weib dabei.", "tokens": ["Das", "ar\u00b7me", ",", "lah\u00b7me", "Weib", "da\u00b7bei", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein M\u00e4gdlein z\u00e4hlte vierzig Jahr,", "tokens": ["Ein", "M\u00e4gd\u00b7lein", "z\u00e4hl\u00b7te", "vier\u00b7zig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Derweil sie stets noch Jungfrau war.", "tokens": ["Der\u00b7weil", "sie", "stets", "noch", "Jung\u00b7frau", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch keusche Jungfrau war.", "tokens": ["Noch", "keu\u00b7sche", "Jung\u00b7frau", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Um sie daf\u00fcr zu strafen hart,", "tokens": ["Um", "sie", "da\u00b7f\u00fcr", "zu", "stra\u00b7fen", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PAV", "PTKZU", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schuf Gott ihr einen Knebelbart,", "tokens": ["Schuf", "Gott", "ihr", "ei\u00b7nen", "Kne\u00b7bel\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr einen Knebelbart.", "tokens": ["Ihr", "ei\u00b7nen", "Kne\u00b7bel\u00b7bart", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Sie flehte: La\u00dft mich mit euch gehn,", "tokens": ["Sie", "fleh\u00b7te", ":", "La\u00dft", "mich", "mit", "euch", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ihr Lieben, la\u00dft mich mit euch gehn,", "tokens": ["Ihr", "Lie\u00b7ben", ",", "la\u00dft", "mich", "mit", "euch", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So wird noch Heil an mir geschehn!", "tokens": ["So", "wird", "noch", "Heil", "an", "mir", "ge\u00b7schehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Am Wege lag ein r\u00e4udiger Hund,", "tokens": ["Am", "We\u00b7ge", "lag", "ein", "r\u00e4u\u00b7di\u00b7ger", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der hatte keinen Zahn im Mund,", "tokens": ["Der", "hat\u00b7te", "kei\u00b7nen", "Zahn", "im", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht einen Zahn im Mund;", "tokens": ["Nicht", "ei\u00b7nen", "Zahn", "im", "Mund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Fand er mal einen Knochen auch,", "tokens": ["Fand", "er", "mal", "ei\u00b7nen", "Kno\u00b7chen", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er bracht ihn nicht in seinen Bauch.", "tokens": ["Er", "bracht", "ihn", "nicht", "in", "sei\u00b7nen", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn nicht in seinen Bauch.", "tokens": ["Ihn", "nicht", "in", "sei\u00b7nen", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nun trabte hinter den anderen vier,", "tokens": ["Nun", "trab\u00b7te", "hin\u00b7ter", "den", "an\u00b7de\u00b7ren", "vier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "CARD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Wiewohl es am Verenden schier,", "tokens": ["Wie\u00b7wohl", "es", "am", "Ver\u00b7en\u00b7den", "schier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Das alte, r\u00e4udige Hundetier.", "tokens": ["Das", "al\u00b7te", ",", "r\u00e4u\u00b7di\u00b7ge", "Hun\u00b7de\u00b7tier", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Ein Dichter lebt' in tiefster Not,", "tokens": ["Ein", "Dich\u00b7ter", "lebt'", "in", "tiefs\u00b7ter", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er starb den ewigen Hungertod,", "tokens": ["Er", "starb", "den", "e\u00b7wi\u00b7gen", "Hun\u00b7ger\u00b7tod", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den ewigen Hungertod.", "tokens": ["Den", "e\u00b7wi\u00b7gen", "Hun\u00b7ger\u00b7tod", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mit Herzblut schrieb er sein Gedicht,", "tokens": ["Mit", "Herz\u00b7blut", "schrieb", "er", "sein", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man druckt es nicht, man liest es nicht,", "tokens": ["Man", "druckt", "es", "nicht", ",", "man", "liest", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKNEG", "$,", "PIS", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und niemand kennt es nicht.", "tokens": ["Und", "nie\u00b7mand", "kennt", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Sein Leib war krank, sein Geist war wund,", "tokens": ["Sein", "Leib", "war", "krank", ",", "sein", "Geist", "war", "wund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Drum schlo\u00df er mit dem r\u00e4udigen Hund", "tokens": ["Drum", "schlo\u00df", "er", "mit", "dem", "r\u00e4u\u00b7di\u00b7gen", "Hund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Der Freundschaft heiligen Seelenbund.", "tokens": ["Der", "Freund\u00b7schaft", "hei\u00b7li\u00b7gen", "See\u00b7len\u00b7bund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Und dann schrieb er zu aller Gl\u00fcck", "tokens": ["Und", "dann", "schrieb", "er", "zu", "al\u00b7ler", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ein wundervolles Theaterst\u00fcck,", "tokens": ["Ein", "wun\u00b7der\u00b7vol\u00b7les", "The\u00b7a\u00b7ter\u00b7st\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein wundervolles St\u00fcck,", "tokens": ["Ein", "wun\u00b7der\u00b7vol\u00b7les", "St\u00fcck", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "In welchem die Personen sind", "tokens": ["In", "wel\u00b7chem", "die", "Per\u00b7so\u00b7nen", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ART", "NN", "VAFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Der taube Mann, das blinde Kind,", "tokens": ["Der", "tau\u00b7be", "Mann", ",", "das", "blin\u00b7de", "Kind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das arme, blinde Kind,", "tokens": ["Das", "ar\u00b7me", ",", "blin\u00b7de", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Das lahme Weib, die Jungfrau zart", "tokens": ["Das", "lah\u00b7me", "Weib", ",", "die", "Jung\u00b7frau", "zart"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mit ihrem langen Knebelbart,", "tokens": ["Mit", "ih\u00b7rem", "lan\u00b7gen", "Kne\u00b7bel\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Jungfrau mit dem Knebelbart.", "tokens": ["Die", "Jung\u00b7frau", "mit", "dem", "Kne\u00b7bel\u00b7bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und eh die n\u00e4chste Stund entflohn,", "tokens": ["Und", "eh", "die", "n\u00e4chs\u00b7te", "Stund", "ent\u00b7flohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Konnt jeder seine Rolle schon,", "tokens": ["Konnt", "je\u00b7der", "sei\u00b7ne", "Rol\u00b7le", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die ganze Rolle schon.", "tokens": ["Die", "gan\u00b7ze", "Rol\u00b7le", "schon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Verst\u00e4ndnisvoll f\u00fchrt die Regie", "tokens": ["Ver\u00b7st\u00e4nd\u00b7nis\u00b7voll", "f\u00fchrt", "die", "Re\u00b7gie"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das alte, r\u00e4udige Hundevieh,", "tokens": ["Das", "al\u00b7te", ",", "r\u00e4u\u00b7di\u00b7ge", "Hun\u00b7de\u00b7vieh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das r\u00e4udige Hundevieh.", "tokens": ["Das", "r\u00e4u\u00b7di\u00b7ge", "Hun\u00b7de\u00b7vieh", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Drauf ward das Schauspiel zensuriert", "tokens": ["Drauf", "ward", "das", "Schau\u00b7spiel", "zen\u00b7su\u00b7riert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und einstudiert und aufgef\u00fchrt", "tokens": ["Und", "ein\u00b7stu\u00b7diert", "und", "auf\u00b7ge\u00b7f\u00fchrt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVPP", "KON", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und ward ganz prachtvoll kritisiert.", "tokens": ["Und", "ward", "ganz", "pracht\u00b7voll", "kri\u00b7ti\u00b7siert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die K\u00fcnstler fanden viel Applaus,", "tokens": ["Die", "K\u00fcnst\u00b7ler", "fan\u00b7den", "viel", "Ap\u00b7plaus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man spannt dem Hund die Pferde aus", "tokens": ["Man", "spannt", "dem", "Hund", "die", "Pfer\u00b7de", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zieht ihn selbst nach Haus.", "tokens": ["Und", "zieht", "ihn", "selbst", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da gab's nun auch Tantiemen viel", "tokens": ["Da", "gab's", "nun", "auch", "Tan\u00b7tie\u00b7men", "viel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und hohe Gagen f\u00fcr das Spiel,", "tokens": ["Und", "ho\u00b7he", "Ga\u00b7gen", "f\u00fcr", "das", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das ungemein gefiel. \u2013", "tokens": ["Das", "un\u00b7ge\u00b7mein", "ge\u00b7fiel", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PDS", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Nachdem sie ganz Europa sah,", "tokens": ["Nach\u00b7dem", "sie", "ganz", "Eu\u00b7ro\u00b7pa", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da reisten sie nach Amerika,", "tokens": ["Da", "reis\u00b7ten", "sie", "nach", "A\u00b7me\u00b7ri\u00b7ka", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Nach Nord- und S\u00fcdamerika.", "tokens": ["Nach", "Nord", "und", "S\u00fcd\u00b7a\u00b7me\u00b7ri\u00b7ka", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Nun h\u00f6rt zum Schlu\u00df noch die Moral:", "tokens": ["Nun", "h\u00f6rt", "zum", "Schlu\u00df", "noch", "die", "Mo\u00b7ral", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebrechen sind oft sehr fatal,", "tokens": ["Ge\u00b7bre\u00b7chen", "sind", "oft", "sehr", "fa\u00b7tal", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind manchmal eine Qual;", "tokens": ["Sind", "manch\u00b7mal", "ei\u00b7ne", "Qual", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Frau Poesie schafft ohne Graus", "tokens": ["Frau", "Poe\u00b7sie", "schafft", "oh\u00b7ne", "Graus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "APPR", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Beneidenswertes Gl\u00fcck daraus,", "tokens": ["Be\u00b7nei\u00b7dens\u00b7wer\u00b7tes", "Gl\u00fcck", "da\u00b7raus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie schafft das Gl\u00fcck daraus.", "tokens": ["Sie", "schafft", "das", "Gl\u00fcck", "da\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Dann schwillt der Mut, dann schwillt der Bauch,", "tokens": ["Dann", "schwillt", "der", "Mut", ",", "dann", "schwillt", "der", "Bauch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und sei's bei einer Jungfrau auch. \u2013", "tokens": ["Und", "sei's", "bei", "ei\u00b7ner", "Jung\u00b7frau", "auch", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}