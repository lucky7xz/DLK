{"dta.poem.21816": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  \n  Felder-Freyheit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Die Freud' hat sich auffs Land begeben.", "tokens": ["Die", "Freud'", "hat", "sich", "auffs", "Land", "be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was mach\u2019 ich in der Stadt?", "tokens": ["Was", "mach'", "ich", "in", "der", "Stadt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Narr ist/ der allhier zu leben", "tokens": ["Ein", "Narr", "ist", "/", "der", "all\u00b7hier", "zu", "le\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$(", "ART", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auff! spannet an den leichten Wagen/", "tokens": ["Auff", "!", "span\u00b7net", "an", "den", "leich\u00b7ten", "Wa\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ich wil hin zu Rosillen jagen.", "tokens": ["ich", "wil", "hin", "zu", "Ro\u00b7sil\u00b7len", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das Lach-gesicht der Charitinnen", "tokens": ["Das", "Lach\u00b7ge\u00b7sicht", "der", "Cha\u00b7ri\u00b7tin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "gibt ihr ein Lust-geleit.", "tokens": ["gibt", "ihr", "ein", "Lust\u00b7ge\u00b7leit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Auff! trag mich Pegasus von hinnen", "tokens": ["Auff", "!", "trag", "mich", "Pe\u00b7ga\u00b7sus", "von", "hin\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "$.", "VVFIN", "PPER", "NE", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zu ihrer Freundligkeit/", "tokens": ["zu", "ih\u00b7rer", "Freund\u00b7lig\u00b7keit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "was acht\u2019 ich dieser \u00f6den Gassen/", "tokens": ["was", "acht'", "ich", "die\u00b7ser", "\u00f6\u00b7den", "Gas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wenn sie die Rosilis nicht fassen", "tokens": ["wenn", "sie", "die", "Ro\u00b7si\u00b7lis", "nicht", "fas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NE", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Selbst Venus wil zur Hirtin werden", "tokens": ["Selbst", "Ve\u00b7nus", "wil", "zur", "Hir\u00b7tin", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VMFIN", "APPRART", "NN", "VAINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "nu sie der Schaffe wacht.", "tokens": ["nu", "sie", "der", "Schaf\u00b7fe", "wacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Amor fleuget um die Heerden", "tokens": ["Der", "A\u00b7mor", "fleu\u00b7get", "um", "die", "Heer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und treibet ein zu Nacht.", "tokens": ["und", "trei\u00b7bet", "ein", "zu", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Erwei\u00df mit melken umzugehen/", "tokens": ["Er\u00b7wei\u00df", "mit", "mel\u00b7ken", "um\u00b7zu\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "VVINF", "VVIZU", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und lernt den schlanken Dr\u00fcschel drehen.", "tokens": ["und", "lernt", "den", "schlan\u00b7ken", "Dr\u00fcsc\u00b7hel", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sollt\u2019 ich mich denn des Pfl\u00fcgens sch\u00e4men/", "tokens": ["Sollt'", "ich", "mich", "denn", "des", "Pfl\u00fc\u00b7gens", "sch\u00e4\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wenn sie mir Essen bringt/", "tokens": ["wenn", "sie", "mir", "Es\u00b7sen", "bringt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mich um die Bauren-Arbeit gr\u00e4men/", "tokens": ["mich", "um", "die", "Bau\u00b7ren\u00b7A\u00b7rbeit", "gr\u00e4\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "wenn sie zu Abend singt", "tokens": ["wenn", "sie", "zu", "A\u00b7bend", "singt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "ein Lied/ das jene frohe Felder", "tokens": ["ein", "Lied", "/", "das", "je\u00b7ne", "fro\u00b7he", "Fel\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der Echo schikken in die W\u00e4lder?", "tokens": ["der", "E\u00b7cho", "schik\u00b7ken", "in", "die", "W\u00e4l\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Jezt brennt der Sonnen heisse Kerze", "tokens": ["Jezt", "brennt", "der", "Son\u00b7nen", "heis\u00b7se", "Ker\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "im wildem Hundes-stern:", "tokens": ["im", "wil\u00b7dem", "Hun\u00b7des\u00b7stern", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was acht\u2019 ich Hizze/ schrunden/ schwerze?", "tokens": ["Was", "acht'", "ich", "Hiz\u00b7ze", "/", "schrun\u00b7den", "/", "schwer\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "NN", "$(", "VVINF", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ist nur mein Kind nicht fern.", "tokens": ["ist", "nur", "mein", "Kind", "nicht", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Bey Jhr und ihres Hamels Glokke", "tokens": ["Bey", "Ihr", "und", "ih\u00b7res", "Ha\u00b7mels", "Glok\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zu Delfos schwieg die Pyte stille", "tokens": ["Zu", "Del\u00b7fos", "schwieg", "die", "Py\u00b7te", "stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als F\u00f6bus war entbrannt", "tokens": ["als", "F\u00f6\u00b7bus", "war", "ent\u00b7brannt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Jhm liebt\u2019 Admetus Schaaff-gebr\u00fclle", "tokens": ["Jhm", "liebt'", "Ad\u00b7me\u00b7tus", "Schaaff\u00b7ge\u00b7br\u00fcl\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "als Amor ihn verband:", "tokens": ["als", "A\u00b7mor", "ihn", "ver\u00b7band", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Au\u00df Liebe pflegt ein Gott der Heerden;", "tokens": ["Au\u00df", "Lie\u00b7be", "pflegt", "ein", "Gott", "der", "Heer\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Um Rosilis/ um meine Sch\u00f6ne?", "tokens": ["Um", "Ro\u00b7si\u00b7lis", "/", "um", "mei\u00b7ne", "Sch\u00f6\u00b7ne", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "$(", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "um welch\u2019 ich eine Stat", "tokens": ["um", "welch'", "ich", "ei\u00b7ne", "Stat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "nicht nur/ besondern alles h\u00f6ne/", "tokens": ["nicht", "nur", "/", "be\u00b7son\u00b7dern", "al\u00b7les", "h\u00f6\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$(", "VVFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "was W\u00e4ll\u2019 und Mauren hat.", "tokens": ["was", "W\u00e4ll'", "und", "Mau\u00b7ren", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Weg Memfis/ weg! weg alle Schl\u00f6sser", "tokens": ["Weg", "Mem\u00b7fis", "/", "weg", "!", "weg", "al\u00b7le", "Schl\u00f6s\u00b7ser"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "$(", "PTKVZ", "$.", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Rosillen Bauren-Hau\u00df ist gr\u00f6sser.", "tokens": ["Ro\u00b7sil\u00b7len", "Bau\u00b7ren\u00b7Hau\u00df", "ist", "gr\u00f6s\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die alte Welt wohnt\u2019 in den H\u00fctten", "tokens": ["Die", "al\u00b7te", "Welt", "wohnt'", "in", "den", "H\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und a\u00df die Eichel-nu\u00df/", "tokens": ["und", "a\u00df", "die", "Ei\u00b7chel\u00b7nu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Jhr Trunk stund\u2019 allen in der Mitten/", "tokens": ["Ihr", "Trunk", "stund'", "al\u00b7len", "in", "der", "Mit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein Brunn und heller Flu\u00df/", "tokens": ["ein", "Brunn", "und", "hel\u00b7ler", "Flu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "da hat sich Fillis beygesezzet", "tokens": ["da", "hat", "sich", "Fil\u00b7lis", "bey\u00b7ge\u00b7sez\u00b7zet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "NE", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und frey mit Koridon ergezzet.", "tokens": ["und", "frey", "mit", "Ko\u00b7ri\u00b7don", "er\u00b7gez\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Da war kein H\u00fcter/ der die Pforten", "tokens": ["Da", "war", "kein", "H\u00fc\u00b7ter", "/", "der", "die", "Pfor\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$(", "ART", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in harte Riegel schlo\u00df/", "tokens": ["in", "har\u00b7te", "Rie\u00b7gel", "schlo\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "die Freyheit war an allen Orten", "tokens": ["die", "Frey\u00b7heit", "war", "an", "al\u00b7len", "Or\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in ihrer Freyheit gro\u00df/", "tokens": ["in", "ih\u00b7rer", "Frey\u00b7heit", "gro\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es liebt\u2019 und herzte sich ein Jeder.", "tokens": ["Es", "liebt'", "und", "herz\u00b7te", "sich", "ein", "Je\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "ART", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kommt/ ihr Gebr\u00e4uche/ kommt doch wieder.", "tokens": ["Kommt", "/", "ihr", "Ge\u00b7br\u00e4u\u00b7che", "/", "kommt", "doch", "wie\u00b7der", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PPOSAT", "NN", "$(", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}