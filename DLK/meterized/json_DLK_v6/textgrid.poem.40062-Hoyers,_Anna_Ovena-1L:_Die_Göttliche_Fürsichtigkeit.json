{"textgrid.poem.40062": {"metadata": {"author": {"name": "Hoyers, Anna Ovena", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die G\u00f6ttliche F\u00fcrsichtigkeit", "genre": "verse", "period": "N.A.", "pub_year": 1619, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die G\u00f6ttliche F\u00fcrsichtigkeit", "tokens": ["Die", "G\u00f6tt\u00b7li\u00b7che", "F\u00fcr\u00b7sich\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich tr\u00f6sten kan in allem leit;", "tokens": ["Mich", "tr\u00f6s\u00b7ten", "kan", "in", "al\u00b7lem", "leit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMFIN", "APPR", "PIS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn was mir widerfahren thut/", "tokens": ["Denn", "was", "mir", "wi\u00b7der\u00b7fah\u00b7ren", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hei\u00df wie es woll/ b\u00f6\u00df oder gut/", "tokens": ["Hei\u00df", "wie", "es", "woll", "/", "b\u00f6\u00df", "o\u00b7der", "gut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "PPER", "ADV", "$(", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das alles regiert Gott allein:", "tokens": ["Das", "al\u00b7les", "re\u00b7giert", "Gott", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drumb kan ich allzeit fr\u00f6lich seyn.", "tokens": ["Drumb", "kan", "ich", "all\u00b7zeit", "fr\u00f6\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da\u00df ein G\u00f6ttlich F\u00fcrsehung sey/", "tokens": ["Da\u00df", "ein", "G\u00f6tt\u00b7lich", "F\u00fcr\u00b7se\u00b7hung", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VAFIN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mu\u00df jederman bekennen frey/", "tokens": ["Mu\u00df", "je\u00b7der\u00b7man", "be\u00b7ken\u00b7nen", "frey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dieweils so hell und offenbar/", "tokens": ["Die\u00b7weils", "so", "hell", "und", "of\u00b7fen\u00b7bar", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch in der heilgen Schrifft ist klar/", "tokens": ["Auch", "in", "der", "heil\u00b7gen", "Schrifft", "ist", "klar", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch welche alles wolgeziert/", "tokens": ["Durch", "wel\u00b7che", "al\u00b7les", "wol\u00b7ge\u00b7ziert", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verordnet und regiret wird.", "tokens": ["Ver\u00b7ord\u00b7net", "und", "re\u00b7gi\u00b7ret", "wird", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df auch ohn die kein ding auff erd", "tokens": ["Da\u00df", "auch", "ohn", "die", "kein", "ding", "auff", "erd"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "PIAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Geschehen ist/ und noch seyn werd/", "tokens": ["Ge\u00b7sche\u00b7hen", "ist", "/", "und", "noch", "seyn", "werd", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$(", "KON", "ADV", "VAINF", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wissen wir/ Gott sey lob und ehr/", "tokens": ["Wis\u00b7sen", "wir", "/", "Gott", "sey", "lob", "und", "ehr", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "NN", "VAFIN", "NN", "KON", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Denn es ist nichts von anfang her/", "tokens": ["Denn", "es", "ist", "nichts", "von", "an\u00b7fang", "her", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wird auch bi\u00df zum end nichts geschehn/", "tokens": ["Wird", "auch", "bi\u00df", "zum", "end", "nichts", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "APPRART", "NN", "PIS", "VVPP", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.12": {"text": "Das nicht zuvor von Gott ersehn.", "tokens": ["Das", "nicht", "zu\u00b7vor", "von", "Gott", "er\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Vnd wann wir ungezweiffelt di\u00df", "tokens": ["Vnd", "wann", "wir", "un\u00b7ge\u00b7zweif\u00b7felt", "di\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ADJD", "PDS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Glauben/ und halten f\u00fcr gewi\u00df/", "tokens": ["Glau\u00b7ben", "/", "und", "hal\u00b7ten", "f\u00fcr", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "VVFIN", "APPR", "ADV", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.15": {"text": "Da\u00df gar nichts geschicht ohn gefehr/", "tokens": ["Da\u00df", "gar", "nichts", "ge\u00b7schicht", "ohn", "ge\u00b7fehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "VVPP", "APPR", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.16": {"text": "Kan uns kein ungl\u00fcck seyn zu schwer;", "tokens": ["Kan", "uns", "kein", "un\u00b7gl\u00fcck", "seyn", "zu", "schwer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "ADJD", "VAINF", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Sondern wir k\u00f6nnen al\u00df Gott will/", "tokens": ["Son\u00b7dern", "wir", "k\u00f6n\u00b7nen", "al\u00df", "Gott", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "KOUS", "NN", "VMFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Ged\u00fcldig seyn und in der still/", "tokens": ["Ge\u00b7d\u00fcl\u00b7dig", "seyn", "und", "in", "der", "still", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "KON", "APPR", "ART", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Alles ertragen und au\u00dfstehn/", "tokens": ["Al\u00b7les", "er\u00b7tra\u00b7gen", "und", "au\u00df\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "KON", "VVINF", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.20": {"text": "Weil wir wissen es mu\u00df so gehn;", "tokens": ["Weil", "wir", "wis\u00b7sen", "es", "mu\u00df", "so", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.21": {"text": "Denn was kan doch mehr frewd im leben", "tokens": ["Denn", "was", "kan", "doch", "mehr", "frewd", "im", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VMFIN", "ADV", "PIAT", "NN", "APPRART", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Al\u00df die F\u00fcrsehung Gottes geben?", "tokens": ["Al\u00df", "die", "F\u00fcr\u00b7se\u00b7hung", "Got\u00b7tes", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.23": {"text": "Wir wissen wie die Schrifft vermeldt/", "tokens": ["Wir", "wis\u00b7sen", "wie", "die", "Schrifft", "ver\u00b7meldt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Da\u00df unser hare sind gezehlt/", "tokens": ["Da\u00df", "un\u00b7ser", "ha\u00b7re", "sind", "ge\u00b7zehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Ein Sperling ohn Gotts willen nicht", "tokens": ["Ein", "Sper\u00b7ling", "ohn", "Gotts", "wil\u00b7len", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Felt auff die Erde/ Christus spricht.", "tokens": ["Felt", "auff", "die", "Er\u00b7de", "/", "Chris\u00b7tus", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$(", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Wie solt nun dann uns Menschen doch/", "tokens": ["Wie", "solt", "nun", "dann", "uns", "Men\u00b7schen", "doch", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "ADV", "PPER", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Was gr\u00f6ssers widerfahren noch/", "tokens": ["Was", "gr\u00f6s\u00b7sers", "wi\u00b7der\u00b7fah\u00b7ren", "noch", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Ohn Gottes Willen und F\u00fcrsehn?", "tokens": ["Ohn", "Got\u00b7tes", "Wil\u00b7len", "und", "F\u00fcr\u00b7sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "F\u00fcrwar es kan je nicht geschehn.", "tokens": ["F\u00fcr\u00b7war", "es", "kan", "je", "nicht", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Vnd wenn ich di\u00df bey mir betracht/", "tokens": ["Vnd", "wenn", "ich", "di\u00df", "bey", "mir", "be\u00b7tracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "APPR", "PPER", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Mein Hertz f\u00fcr tausend Frewden lacht;", "tokens": ["Mein", "Hertz", "f\u00fcr", "tau\u00b7send", "Frew\u00b7den", "lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Auch in der gr\u00f6sten Trawrigkeit/", "tokens": ["Auch", "in", "der", "gr\u00f6s\u00b7ten", "Traw\u00b7rig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Kan es seyn voller Lust und Frewd;", "tokens": ["Kan", "es", "seyn", "vol\u00b7ler", "Lust", "und", "Frewd", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "ADJA", "NN", "KON", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.35": {"text": "Daf\u00fcr ich Gott lob/ prei\u00df und Ehr/", "tokens": ["Da\u00b7f\u00fcr", "ich", "Gott", "lob", "/", "prei\u00df", "und", "Ehr", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "NN", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Will sagen allzeit immermehr/", "tokens": ["Will", "sa\u00b7gen", "all\u00b7zeit", "im\u00b7mer\u00b7mehr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Das er durch seine Gnad und gunst/", "tokens": ["Das", "er", "durch", "sei\u00b7ne", "Gnad", "und", "gunst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Lauter/ ohn mein verdienst/ umb sonst/", "tokens": ["Lau\u00b7ter", "/", "ohn", "mein", "ver\u00b7dienst", "/", "umb", "sonst", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "APPR", "PPOSAT", "NN", "$(", "APPR", "ADV", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.39": {"text": "Zu der Erkentn\u00fc\u00df mich gebracht/", "tokens": ["Zu", "der", "Er\u00b7kent\u00b7n\u00fc\u00df", "mich", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Lob/ Ehr und Danck/ sey jhm gesagt;", "tokens": ["Lob", "/", "Ehr", "und", "Danck", "/", "sey", "jhm", "ge\u00b7sagt", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "$(", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Er walle auch zu seinen Ehrn/", "tokens": ["Er", "wal\u00b7le", "auch", "zu", "sei\u00b7nen", "Ehrn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Den Trost und di\u00df erkentn\u00fcs mehrn", "tokens": ["Den", "Trost", "und", "di\u00df", "er\u00b7kent\u00b7n\u00fcs", "mehrn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PDS", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "In mein'm und aller menschen hertzen/", "tokens": ["In", "mein'm", "und", "al\u00b7ler", "men\u00b7schen", "hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.44": {"text": "Dadurch auch lindern alle schmertzen/", "tokens": ["Da\u00b7durch", "auch", "lin\u00b7dern", "al\u00b7le", "schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADV", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Vmb Jesu Christ meins Herren willen/", "tokens": ["Vmb", "Je\u00b7su", "Christ", "meins", "Her\u00b7ren", "wil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Bitt ich woll Gott mein Wunsch erf\u00fcllen.", "tokens": ["Bitt", "ich", "woll", "Gott", "mein", "Wunsch", "er\u00b7f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VMFIN", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Amen Hanns Ovens Tochter spricht/", "tokens": ["A\u00b7men", "Hanns", "O\u00b7vens", "Toch\u00b7ter", "spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NN", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.48": {"text": "Gott erh\u00f6rt es/ sie zweiffelt nicht.", "tokens": ["Gott", "er\u00b7h\u00f6rt", "es", "/", "sie", "zweif\u00b7felt", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$(", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.3": {"line.1": {"text": "Gott Hat Vnser Hare Gezehlt.", "tokens": ["Gott", "Hat", "Vn\u00b7ser", "Ha\u00b7re", "Ge\u00b7zehlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Gott H\u00f6ret Vnd Heisset Gern.", "tokens": ["Gott", "H\u00f6\u00b7ret", "Vnd", "Heis\u00b7set", "Gern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Vnd g'reicht zu seinen Ehren.", "tokens": ["Vnd", "g'\u00b7reicht", "zu", "sei\u00b7nen", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Niemand kan solches wehren.", "tokens": ["Nie\u00b7mand", "kan", "sol\u00b7ches", "weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PIS", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Gl\u00fcck/ ungl\u00fcck/ todt und leben.", "tokens": ["Gl\u00fcck", "/", "un\u00b7gl\u00fcck", "/", "todt", "und", "le\u00b7ben", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "$(", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch sein F\u00fcrsehn/ merck eben.", "tokens": ["Durch", "sein", "F\u00fcr\u00b7sehn", "/", "merck", "e\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "NE", "ADV", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Der in all seinen sachen", "tokens": ["Der", "in", "all", "sei\u00b7nen", "sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ihm di\u00df kan nutzlich machen.", "tokens": ["Ihm", "di\u00df", "kan", "nutz\u00b7lich", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sein Gem\u00fcth \u00fcberwinden;", "tokens": ["Sein", "Ge\u00b7m\u00fcth", "\u00fc\u00b7berw\u00b7in\u00b7den", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "Kan er bald lindrung finden.", "tokens": ["Kan", "er", "bald", "lind\u00b7rung", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "F\u00fcr Eitel und Verg\u00e4nglich;", "tokens": ["F\u00fcr", "Ei\u00b7tel", "und", "Ver\u00b7g\u00e4ng\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Zu dem das \u00fcberschwencklich;", "tokens": ["Zu", "dem", "das", "\u00fc\u00b7bersc\u00b7hwenck\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Weltfrewd kan er leicht meiden;", "tokens": ["Welt\u00b7frewd", "kan", "er", "leicht", "mei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.12": {"text": "Kan er gedultig leiden;", "tokens": ["Kan", "er", "ge\u00b7dul\u00b7tig", "lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.13": {"text": "Er hab viel oder wenig/", "tokens": ["Er", "hab", "viel", "o\u00b7der", "we\u00b7nig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KON", "PIS", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "In Gott/ mit dem er einig;", "tokens": ["In", "Gott", "/", "mit", "dem", "er", "ei\u00b7nig", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "APPR", "PRELS", "PPER", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Nach Gottes wolgefallen;", "tokens": ["Nach", "Got\u00b7tes", "wol\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Auch allzeit in den allen.", "tokens": ["Auch", "all\u00b7zeit", "in", "den", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "PIAT", "$."], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Man kan Gott so viel gutes nicht", "tokens": ["Man", "kan", "Gott", "so", "viel", "gu\u00b7tes", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "NN", "ADV", "PIAT", "ADJA", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zutraw'n/ er ist noch besser.", "tokens": ["Zu\u00b7tra\u00b7w'n", "/", "er", "ist", "noch", "bes\u00b7ser", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gro\u00df \u00fcbelthat hab ich verricht/", "tokens": ["Gro\u00df", "\u00fc\u00b7belt\u00b7hat", "hab", "ich", "ver\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "PPER", "VVFIN", "$("], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch ist sein Gnad viel gr\u00f6sser.", "tokens": ["Doch", "ist", "sein", "Gnad", "viel", "gr\u00f6s\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So ich im Glauben nur nicht gleit/", "tokens": ["So", "ich", "im", "Glau\u00b7ben", "nur", "nicht", "gleit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPRART", "NN", "ADV", "PTKNEG", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sondern steh' vest ohn wancken/", "tokens": ["Son\u00b7dern", "steh'", "vest", "ohn", "wan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.7": {"text": "Bleibt wol vest sein Barmhertzigkeit/", "tokens": ["Bleibt", "wol", "vest", "sein", "Barm\u00b7hert\u00b7zig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der ich will Ewig dancken.", "tokens": ["Der", "ich", "will", "E\u00b7wig", "dan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "La\u00df mich in frewd und schmertz ja nicht von ihm wancken.", "tokens": ["La\u00df", "mich", "in", "frewd", "und", "schmertz", "ja", "nicht", "von", "ihm", "wan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "NN", "KON", "ADJD", "ADV", "PTKNEG", "APPR", "PPER", "VVINF", "$."], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}}}}}