{"textgrid.poem.51031": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Der Schulgeno\u00df", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wohin hat dich dein guter Stern gezogen,", "tokens": ["Wo\u00b7hin", "hat", "dich", "dein", "gu\u00b7ter", "Stern", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "O Schulgeno\u00df aus ersten Knabenjahren?", "tokens": ["O", "Schul\u00b7ge\u00b7no\u00df", "aus", "ers\u00b7ten", "Kna\u00b7ben\u00b7jah\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie weit sind auseinander wir gefahren", "tokens": ["Wie", "weit", "sind", "aus\u00b7ein\u00b7an\u00b7der", "wir", "ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In unsern Schifflein auf des Lebens Wogen!", "tokens": ["In", "un\u00b7sern", "Schif\u00b7flein", "auf", "des", "Le\u00b7bens", "Wo\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wenn wir die Untersten der Klasse waren,", "tokens": ["Wenn", "wir", "die", "Un\u00b7ters\u00b7ten", "der", "Klas\u00b7se", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Wie haben wir treuherzig uns betrogen,", "tokens": ["Wie", "ha\u00b7ben", "wir", "treu\u00b7her\u00b7zig", "uns", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Erfinderisch und schw\u00e4rmrisch uns belogen", "tokens": ["Er\u00b7fin\u00b7de\u00b7risch", "und", "schw\u00e4rm\u00b7risch", "uns", "be\u00b7lo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Von Avent\u00fcren, Liebschaft und Gefahren!", "tokens": ["Von", "A\u00b7ven\u00b7t\u00fc\u00b7ren", ",", "Lieb\u00b7schaft", "und", "Ge\u00b7fah\u00b7ren", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da seh ich just, beim Schimmer der Laterne,", "tokens": ["Da", "seh", "ich", "just", ",", "beim", "Schim\u00b7mer", "der", "La\u00b7ter\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie mir geb\u00fcckt, zerlumpt ein Vagabund", "tokens": ["Wie", "mir", "ge\u00b7b\u00fcckt", ",", "zer\u00b7lumpt", "ein", "Va\u00b7ga\u00b7bund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVPP", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit einem H\u00e4scher scheu vor\u00fcbergeht \u2013!", "tokens": ["Mit", "ei\u00b7nem", "H\u00e4\u00b7scher", "scheu", "vor\u00b7\u00fc\u00b7ber\u00b7geht", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "So also wendeten sich unsre Sterne?", "tokens": ["So", "al\u00b7so", "wen\u00b7de\u00b7ten", "sich", "uns\u00b7re", "Ster\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und so hat es gewuchert, unser Pfund?", "tokens": ["Und", "so", "hat", "es", "ge\u00b7wu\u00b7chert", ",", "un\u00b7ser", "Pfund", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "VVPP", "$,", "PPOSAT", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Du bist ein Schelm geworden \u2013 ich Poet!", "tokens": ["Du", "bist", "ein", "Schelm", "ge\u00b7wor\u00b7den", "\u2013", "ich", "Po\u00b7et", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VAPP", "$(", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}