{"textgrid.poem.46177": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Warum, ihr herren diser welt", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Warum, ihr herren diser welt", "tokens": ["Wa\u00b7rum", ",", "ihr", "her\u00b7ren", "di\u00b7ser", "welt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "PPOSAT", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "seid ihr den lastern so ergeben?", "tokens": ["seid", "ihr", "den", "las\u00b7tern", "so", "er\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wird euch ohn tugend euer geld,", "tokens": ["wird", "euch", "ohn", "tu\u00b7gend", "eu\u00b7er", "geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "nachdem ihr tot, wider beleben?", "tokens": ["nach\u00b7dem", "ihr", "tot", ",", "wi\u00b7der", "be\u00b7le\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "APPR", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Euch mag villeicht ein l\u00fcginmund", "tokens": ["Euch", "mag", "vil\u00b7leicht", "ein", "l\u00fc\u00b7gin\u00b7mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "um ein erbetteltes almosen", "tokens": ["um", "ein", "er\u00b7bet\u00b7tel\u00b7tes", "al\u00b7mo\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "mit liederlichem lied, ohn grund,", "tokens": ["mit", "lie\u00b7der\u00b7li\u00b7chem", "lied", ",", "ohn", "grund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ohn leben und geschmack, liebkosen:", "tokens": ["ohn", "le\u00b7ben", "und", "ge\u00b7schmack", ",", "lieb\u00b7ko\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "VVINF", "KON", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Doch kan ihr lied, wie eure ehr,", "tokens": ["Doch", "kan", "ihr", "lied", ",", "wie", "eu\u00b7re", "ehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "$,", "PWAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "die zugleich kriechend auf der erden", "tokens": ["die", "zu\u00b7gleich", "krie\u00b7chend", "auf", "der", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "seind allen ehrliebhabern schwer", "tokens": ["seind", "al\u00b7len", "e\u00b7hrlieb\u00b7ha\u00b7bern", "schwer"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "(recht euerm taback gleich) nicht mehr", "tokens": ["(", "recht", "eu\u00b7erm", "ta\u00b7back", "gleich", ")", "nicht", "mehr"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "ADV", "PPOSAT", "NN", "ADV", "$(", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "dan rauch, gestank und aschen werden.", "tokens": ["dan", "rauch", ",", "ge\u00b7stank", "und", "asc\u00b7hen", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "KON", "VVINF", "VAFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Ich, den des himmels g\u00fctigkeit", "tokens": ["Ich", ",", "den", "des", "him\u00b7mels", "g\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit einem solchen geist ergetzet,", "tokens": ["mit", "ei\u00b7nem", "sol\u00b7chen", "geist", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der r\u00fchmlich in die ewigkeit", "tokens": ["der", "r\u00fchm\u00b7lich", "in", "die", "e\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "bald einen werten namen setzet,", "tokens": ["bald", "ei\u00b7nen", "wer\u00b7ten", "na\u00b7men", "set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kan leider! jetz in dem Teutschland", "tokens": ["Kan", "lei\u00b7der", "!", "jetz", "in", "dem", "Teutschland"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "$.", "ADV", "APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "sehr wenig nach lob strebend finden,", "tokens": ["sehr", "we\u00b7nig", "nach", "lob", "stre\u00b7bend", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "weil vil sich lassen (pfui der schand!)", "tokens": ["weil", "vil", "sich", "las\u00b7sen", "(", "pfui", "der", "schand", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PRF", "VVINF", "$(", "ITJ", "ART", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "durch lust, forcht oder geiz verblinden.", "tokens": ["durch", "lust", ",", "forcht", "o\u00b7der", "geiz", "ver\u00b7blin\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VVFIN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Darum auch die, so wider recht", "tokens": ["Da\u00b7rum", "auch", "die", ",", "so", "wi\u00b7der", "recht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "ADV", "ART", "$,", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "stark oder faul endlich verderben", "tokens": ["stark", "o\u00b7der", "faul", "end\u00b7lich", "ver\u00b7der\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "ADV", "VVFIN"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.11": {"text": "und der wut oder tr\u00e4gheit knecht,", "tokens": ["und", "der", "wut", "o\u00b7der", "tr\u00e4g\u00b7heit", "knecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.12": {"text": "unmenschlich, teufelisch, torecht,", "tokens": ["un\u00b7menschlich", ",", "teu\u00b7fe\u00b7lisch", ",", "to\u00b7recht", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "den thieren gleich, ohn namen sterben.", "tokens": ["den", "thie\u00b7ren", "gleich", ",", "ohn", "na\u00b7men", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KOUI", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dan es nu recht, da\u00df die person,", "tokens": ["Dan", "es", "nu", "recht", ",", "da\u00df", "die", "per\u00b7son", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADJD", "$,", "KOUS", "ART", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "die in der that ihr wert erwiesen,", "tokens": ["die", "in", "der", "that", "ihr", "wert", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "VVFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und die schon hat der tugend kron,", "tokens": ["und", "die", "schon", "hat", "der", "tu\u00b7gend", "kron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "weltkundig werd und hoch gepriesen.", "tokens": ["welt\u00b7kun\u00b7dig", "werd", "und", "hoch", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Warum dan, mein freind, der du dir", "tokens": ["Wa\u00b7rum", "dan", ",", "mein", "freind", ",", "der", "du", "dir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "PPER"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "la\u00dft meine vers sehr wol gefallen,", "tokens": ["la\u00dft", "mei\u00b7ne", "vers", "sehr", "wol", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "la\u00df ich nach schuldiger geb\u00fchr", "tokens": ["la\u00df", "ich", "nach", "schul\u00b7di\u00b7ger", "ge\u00b7b\u00fchr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "von dir nicht mein gesang erschallen?", "tokens": ["von", "dir", "nicht", "mein", "ge\u00b7sang", "er\u00b7schal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "W\u00e4r mein undankbare tr\u00e4gheit", "tokens": ["W\u00e4r", "mein", "un\u00b7dank\u00b7ba\u00b7re", "tr\u00e4g\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.10": {"text": "nicht billich von dir anzuklagen,", "tokens": ["nicht", "bil\u00b7lich", "von", "dir", "an\u00b7zu\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "wan ich nicht solt mit der warheit", "tokens": ["wan", "ich", "nicht", "solt", "mit", "der", "war\u00b7heit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "VMFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "f\u00fcr der welt, deines lobs klarheit", "tokens": ["f\u00fcr", "der", "welt", ",", "dei\u00b7nes", "lobs", "klar\u00b7heit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.13": {"text": "zu singen, mich geb\u00fcrlich wagen?", "tokens": ["zu", "sin\u00b7gen", ",", "mich", "ge\u00b7b\u00fcr\u00b7lich", "wa\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die neun g\u00f6ttinnen, deren lehr", "tokens": ["Die", "neun", "g\u00f6t\u00b7tin\u00b7nen", ",", "de\u00b7ren", "lehr"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "CARD", "ADJA", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "belohnet uns mit gr\u00fcnen kr\u00e4nzen,", "tokens": ["be\u00b7loh\u00b7net", "uns", "mit", "gr\u00fc\u00b7nen", "kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "rein zu erhalten ihre ehr", "tokens": ["rein", "zu", "er\u00b7hal\u00b7ten", "ih\u00b7re", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "PTKZU", "VVINF", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "seind nicht wie huren, die fuchsschw\u00e4nzen;", "tokens": ["seind", "nicht", "wie", "hu\u00b7ren", ",", "die", "fuchs\u00b7schw\u00e4n\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "KOKOM", "VVINF", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch seind sie auch so gar stolz nicht,", "tokens": ["Doch", "seind", "sie", "auch", "so", "gar", "stolz", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wie jetz gemeinglich die jungfrauen,", "tokens": ["wie", "jetz", "ge\u00b7mein\u00b7glich", "die", "jung\u00b7frau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die mit gef\u00e4lschtem angesicht", "tokens": ["die", "mit", "ge\u00b7f\u00e4lschtem", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "mit saur ger\u00fcnzelten augbrauen,", "tokens": ["mit", "saur", "ge\u00b7r\u00fcn\u00b7zel\u00b7ten", "aug\u00b7brau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.9": {"text": "Mit einem kalten affenblick,", "tokens": ["Mit", "ei\u00b7nem", "kal\u00b7ten", "af\u00b7fen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "mit schimpflich l\u00e4chlendem angaffen", "tokens": ["mit", "schimpf\u00b7lich", "l\u00e4ch\u00b7len\u00b7dem", "an\u00b7gaf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "ein herz, das schon in ihrem strick", "tokens": ["ein", "herz", ",", "das", "schon", "in", "ih\u00b7rem", "strick"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sie ehret als sein bestes gl\u00fcck", "tokens": ["sie", "eh\u00b7ret", "als", "sein", "bes\u00b7tes", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "und liebend lobet, schnell abschaffen.", "tokens": ["und", "lie\u00b7bend", "lo\u00b7bet", ",", "schnell", "ab\u00b7schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Die tugend, als die beste frucht,", "tokens": ["Die", "tu\u00b7gend", ",", "als", "die", "bes\u00b7te", "frucht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die man in ihrer schul erfasset,", "tokens": ["die", "man", "in", "ih\u00b7rer", "schul", "er\u00b7fas\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "gebeut uns aller laster flucht", "tokens": ["ge\u00b7beut", "uns", "al\u00b7ler", "las\u00b7ter", "flucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und da\u00df der undank werd gehasset:", "tokens": ["und", "da\u00df", "der", "un\u00b7dank", "werd", "ge\u00b7has\u00b7set", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und ein lehrreiches lobgesang,", "tokens": ["Und", "ein", "lehr\u00b7rei\u00b7ches", "lob\u00b7ge\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit m\u00fch und zier recht ausgesetzet,", "tokens": ["mit", "m\u00fch", "und", "zier", "recht", "aus\u00b7ge\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "ab dessen fr\u00f6lich frischem klang", "tokens": ["ab", "des\u00b7sen", "fr\u00f6\u00b7lich", "fri\u00b7schem", "klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "ADJD", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "der g\u00f6tter herz sich selbs ergetzet,", "tokens": ["der", "g\u00f6t\u00b7ter", "herz", "sich", "selbs", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ist der dank f\u00fcr die, so mit gunst", "tokens": ["Ist", "der", "dank", "f\u00fcr", "die", ",", "so", "mit", "gunst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "APPR", "APPR", "ART", "$,", "ADV", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "gern der poeten lieb verbinden,", "tokens": ["gern", "der", "po\u00b7e\u00b7ten", "lieb", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "und lobet sie mit solcher kunst", "tokens": ["und", "lo\u00b7bet", "sie", "mit", "sol\u00b7cher", "kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "da\u00df sich die zeit bem\u00fcht umsunst,", "tokens": ["da\u00df", "sich", "die", "zeit", "be\u00b7m\u00fcht", "um\u00b7sunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "ihr stetes lob zu \u00fcberwinden.", "tokens": ["ihr", "ste\u00b7tes", "lob", "zu", "\u00fc\u00b7berw\u00b7in\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nu dir versprich ich und gelob", "tokens": ["Nu", "dir", "ver\u00b7sprich", "ich", "und", "ge\u00b7lob"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADJD", "PPER", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(will dir es auch steif ferners halten),", "tokens": ["(", "will", "dir", "es", "auch", "steif", "fer\u00b7ners", "hal\u00b7ten", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "PPER", "ADV", "ADJD", "ADV", "VVINF", "$(", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "da\u00df deiner tugend ruhm und lob", "tokens": ["da\u00df", "dei\u00b7ner", "tu\u00b7gend", "ruhm", "und", "lob"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "soll weder sterben, noch veralten;", "tokens": ["soll", "we\u00b7der", "ster\u00b7ben", ",", "noch", "ver\u00b7al\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dan ich will sie so tief und klar", "tokens": ["Dan", "ich", "will", "sie", "so", "tief", "und", "klar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VMFIN", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "der ewigkeit portal einetzen,", "tokens": ["der", "e\u00b7wig\u00b7keit", "por\u00b7tal", "ei\u00b7net\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df das allfressend starke jahr", "tokens": ["da\u00df", "das", "all\u00b7fres\u00b7send", "star\u00b7ke", "jahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "sie nicht soll \u00e4ndern noch verletzen:", "tokens": ["sie", "nicht", "soll", "\u00e4n\u00b7dern", "noch", "ver\u00b7let\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VMFIN", "VVINF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Ich will mit so getreuem mund", "tokens": ["Ich", "will", "mit", "so", "ge\u00b7treu\u00b7em", "mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "(wan ja die Musen nicht betriegen)", "tokens": ["(", "wan", "ja", "die", "Mu\u00b7sen", "nicht", "be\u00b7trie\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "ART", "NN", "PTKNEG", "VVFIN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "dein leben machen also kund,", "tokens": ["dein", "le\u00b7ben", "ma\u00b7chen", "al\u00b7so", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "da\u00df man sich darab alle stund", "tokens": ["da\u00df", "man", "sich", "da\u00b7rab", "al\u00b7le", "stund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "PAV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "soll, wie du dich ab mir, vern\u00fcgen.", "tokens": ["soll", ",", "wie", "du", "dich", "ab", "mir", ",", "ver\u00b7n\u00fc\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "$,", "PWAV", "PPER", "PRF", "APPR", "PPER", "$,", "VVPP", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Gleichwie man in der finstern nacht", "tokens": ["Gleich\u00b7wie", "man", "in", "der", "fins\u00b7tern", "nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "das firmament voll stern kan sehen:", "tokens": ["das", "fir\u00b7ma\u00b7ment", "voll", "stern", "kan", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "so sihet man der tugend pracht", "tokens": ["so", "si\u00b7het", "man", "der", "tu\u00b7gend", "pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "frisch bl\u00fchend nur auf dir bestehen.", "tokens": ["frisch", "bl\u00fc\u00b7hend", "nur", "auf", "dir", "be\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du bist recht den halbg\u00f6ttern gleich,", "tokens": ["Du", "bist", "recht", "den", "halb\u00b7g\u00f6t\u00b7tern", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ART", "NN", "ADV", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "vor alter zeit so hoch geehret,", "tokens": ["vor", "al\u00b7ter", "zeit", "so", "hoch", "ge\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und Amor wie Mars hat sein reich", "tokens": ["und", "A\u00b7mor", "wie", "Mars", "hat", "sein", "reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "KOKOM", "NN", "VAFIN", "PPOSAT", "ADJD"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "durch dein gesicht und herz vermehret:", "tokens": ["durch", "dein", "ge\u00b7sicht", "und", "herz", "ver\u00b7meh\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVPP", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zierd, h\u00f6flichkeit, verstand, wolstand,", "tokens": ["Zierd", ",", "h\u00f6f\u00b7lich\u00b7keit", ",", "ver\u00b7stand", ",", "wol\u00b7stand", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "VVFIN", "$,", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "die haben deine seel ganz innen,", "tokens": ["die", "ha\u00b7ben", "dei\u00b7ne", "seel", "ganz", "in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "da\u00df leichtlich du in allem land", "tokens": ["da\u00df", "leicht\u00b7lich", "du", "in", "al\u00b7lem", "land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJD", "PPER", "APPR", "PIS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "kanst mit dem mund und mit der hand", "tokens": ["kanst", "mit", "dem", "mund", "und", "mit", "der", "hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "der menschen herzen bald gewinnen.", "tokens": ["der", "men\u00b7schen", "her\u00b7zen", "bald", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Ja das gestirn, durch dessen reis", "tokens": ["Ja", "das", "ge\u00b7stirn", ",", "durch", "des\u00b7sen", "reis"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "ART", "NN", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die welt ihr t\u00e4glich lasset z\u00fcnden,", "tokens": ["die", "welt", "ihr", "t\u00e4g\u00b7lich", "las\u00b7set", "z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "VVFIN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sicht alles zwar in dem umkreis,", "tokens": ["sicht", "al\u00b7les", "zwar", "in", "dem", "um\u00b7kreis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "ART", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "kan aber niemand dir gleich finden:", "tokens": ["kan", "a\u00b7ber", "nie\u00b7mand", "dir", "gleich", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein glaub, treu und best\u00e4ndigkeit", "tokens": ["Dein", "glaub", ",", "treu", "und", "be\u00b7st\u00e4n\u00b7dig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "seind an purheit nicht zu vergleichen,", "tokens": ["seind", "an", "pur\u00b7heit", "nicht", "zu", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "wie dan auch deine dapferkeit", "tokens": ["wie", "dan", "auch", "dei\u00b7ne", "dap\u00b7fer\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "darf keines heldens k\u00fchnheit weichen:", "tokens": ["darf", "kei\u00b7nes", "hel\u00b7dens", "k\u00fchn\u00b7heit", "wei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und deines fr\u00fclings s\u00fc\u00dfe blust", "tokens": ["Und", "dei\u00b7nes", "fr\u00fc\u00b7lings", "s\u00fc\u00b7\u00dfe", "blust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "so lieblich riechet schon auf erden,", "tokens": ["so", "lieb\u00b7lich", "rie\u00b7chet", "schon", "auf", "er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "da\u00df das Teutschland in seiner brust", "tokens": ["da\u00df", "das", "Teutschland", "in", "sei\u00b7ner", "brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "mit wunder und mit gro\u00dfem lust", "tokens": ["mit", "wun\u00b7der", "und", "mit", "gro\u00b7\u00dfem", "lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "spricht, da\u00df dein herbst mu\u00df fruchtreich werden.", "tokens": ["spricht", ",", "da\u00df", "dein", "herbst", "mu\u00df", "fruch\u00b7treich", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPOSAT", "ADV", "VMFIN", "ADJD", "VAINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.9": {"line.1": {"text": "Doch wie vil fr\u00fcchten hat es schon", "tokens": ["Doch", "wie", "vil", "fr\u00fcch\u00b7ten", "hat", "es", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PIAT", "ADJA", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von deiner dapfern faust empfangen?", "tokens": ["von", "dei\u00b7ner", "dap\u00b7fern", "faust", "emp\u00b7fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sicht man nicht einen baum mit wohn", "tokens": ["sicht", "man", "nicht", "ei\u00b7nen", "baum", "mit", "wohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PTKNEG", "ART", "NN", "APPR", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "zumal voll blust und fr\u00fcchten hangen?", "tokens": ["zu\u00b7mal", "voll", "blust", "und", "fr\u00fcch\u00b7ten", "han\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "KON", "ADJA", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Also bist du; dir ist nicht gnug", "tokens": ["Al\u00b7so", "bist", "du", ";", "dir", "ist", "nicht", "gnug"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$.", "PPER", "VAFIN", "PTKNEG", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "pers\u00f6nlich einen hof zu zieren,", "tokens": ["per\u00b7s\u00f6n\u00b7lich", "ei\u00b7nen", "hof", "zu", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "beredt, erfahren, emsig, klug", "tokens": ["be\u00b7redt", ",", "er\u00b7fah\u00b7ren", ",", "em\u00b7sig", ",", "klug"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ADJD", "$,", "VVINF", "$,", "ADJD", "$,", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "in vilen sprachen zu studieren:", "tokens": ["in", "vi\u00b7len", "spra\u00b7chen", "zu", "stu\u00b7die\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Sondern du zeuchst herzhaft hinaus,", "tokens": ["Son\u00b7dern", "du", "zeuchst", "herz\u00b7haft", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "k\u00fchn in dem l\u00e4ger einzukehren,", "tokens": ["k\u00fchn", "in", "dem", "l\u00e4\u00b7ger", "ein\u00b7zu\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "ADJA", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "vil lieber dan in einem haus,", "tokens": ["vil", "lie\u00b7ber", "dan", "in", "ei\u00b7nem", "haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "da du dan deine feind mit graus,", "tokens": ["da", "du", "dan", "dei\u00b7ne", "feind", "mit", "graus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "was du erlernet, bald kanst lehren.", "tokens": ["was", "du", "er\u00b7ler\u00b7net", ",", "bald", "kanst", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ein schlechtes und verzagtes herz", "tokens": ["Ein", "schlech\u00b7tes", "und", "ver\u00b7zag\u00b7tes", "herz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "entsetzet sich ab den gefahren,", "tokens": ["ent\u00b7set\u00b7zet", "sich", "ab", "den", "ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "und seine forcht, die selbs ein schmerz,", "tokens": ["und", "sei\u00b7ne", "forcht", ",", "die", "selbs", "ein", "schmerz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "kan es nicht sicher gnug bewahren:", "tokens": ["kan", "es", "nicht", "si\u00b7cher", "gnug", "be\u00b7wah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Ja ist es nicht ein gro\u00dfe schmach,", "tokens": ["Ja", "ist", "es", "nicht", "ein", "gro\u00b7\u00dfe", "schmach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df die, die nur zu sterben leben,", "tokens": ["da\u00df", "die", ",", "die", "nur", "zu", "ster\u00b7ben", "le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "so faul von leib, von mut so schwach,", "tokens": ["so", "faul", "von", "leib", ",", "von", "mut", "so", "schwach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$,", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "sich darfen nicht dem krieg ergeben?", "tokens": ["sich", "dar\u00b7fen", "nicht", "dem", "krieg", "er\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PAV", "PTKNEG", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Sehr elend ist der durch kleinmut", "tokens": ["Sehr", "e\u00b7lend", "ist", "der", "durch", "klein\u00b7mut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "ART", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "mu\u00df krank auf seinem bet lang zagen,", "tokens": ["mu\u00df", "krank", "auf", "sei\u00b7nem", "bet", "lang", "za\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "APPR", "PPOSAT", "VVFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "und selig ist der, so sein blut,", "tokens": ["und", "se\u00b7lig", "ist", "der", ",", "so", "sein", "blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "$,", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "sein leben, seine ruh, sein gut,", "tokens": ["sein", "le\u00b7ben", ",", "sei\u00b7ne", "ruh", ",", "sein", "gut", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "f\u00fcr gottes ehr, in wind darf schlagen.", "tokens": ["f\u00fcr", "got\u00b7tes", "ehr", ",", "in", "wind", "darf", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Also thust du. Die weite welt", "tokens": ["Al\u00b7so", "thust", "du", ".", "Die", "wei\u00b7te", "welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "wird solches nimmermehr verschweigen,", "tokens": ["wird", "sol\u00b7ches", "nim\u00b7mer\u00b7mehr", "ver\u00b7schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und in dem Teutschland manches feld", "tokens": ["und", "in", "dem", "Teutschland", "man\u00b7ches", "feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "PIAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "wird solches allzeit gern bezeugen:", "tokens": ["wird", "sol\u00b7ches", "all\u00b7zeit", "gern", "be\u00b7zeu\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jedoch wan ich mit h\u00f6herm ton", "tokens": ["Je\u00b7doch", "wan", "ich", "mit", "h\u00f6\u00b7herm", "ton"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "einmal sing von dem potentaten,", "tokens": ["ein\u00b7mal", "sing", "von", "dem", "po\u00b7ten\u00b7ta\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "der dein, gleich wie auch du sein, wohn,", "tokens": ["der", "dein", ",", "gleich", "wie", "auch", "du", "sein", ",", "wohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPOSAT", "$,", "ADV", "KOKOM", "ADV", "PPER", "VAINF", "$,", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wan ich erkling laut seine thaten,", "tokens": ["wan", "ich", "er\u00b7kling", "laut", "sei\u00b7ne", "tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "APPR", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Alsdan soll dein und andrer preis,", "tokens": ["Als\u00b7dan", "soll", "dein", "und", "an\u00b7drer", "preis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "die ihm wol dienen, klar erschallen;", "tokens": ["die", "ihm", "wol", "die\u00b7nen", ",", "klar", "er\u00b7schal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "entzwischen la\u00df nach deiner weis", "tokens": ["ent\u00b7zwi\u00b7schen", "la\u00df", "nach", "dei\u00b7ner", "weis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "dir, Ponica, den schlechten flei\u00df,", "tokens": ["dir", ",", "Po\u00b7ni\u00b7ca", ",", "den", "schlech\u00b7ten", "flei\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "den mein herz reich macht, nicht misfallen.", "tokens": ["den", "mein", "herz", "reich", "macht", ",", "nicht", "mis\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVFIN", "$,", "PTKNEG", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}}}}