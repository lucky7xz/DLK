{"textgrid.poem.48567": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "16. Auf Frau Elisabeth Paulsens in Revel Ableben", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Soll ich tr\u00f6sten oder klagen?", "tokens": ["Soll", "ich", "tr\u00f6s\u00b7ten", "o\u00b7der", "kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was denn tu' ich erstlich nun?", "tokens": ["Was", "denn", "tu'", "ich", "erst\u00b7lich", "nun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hier ist Jammer, da Verzagen,", "tokens": ["Hier", "ist", "Jam\u00b7mer", ",", "da", "Ver\u00b7za\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "$,", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dort ein schmerzlichs Kl\u00e4glichtun,", "tokens": ["dort", "ein", "schmerz\u00b7lichs", "Kl\u00e4g\u00b7lich\u00b7tun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und wir sehn auf allen Seiten", "tokens": ["und", "wir", "sehn", "auf", "al\u00b7len", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Tod und Ohnmacht auf uns streiten.", "tokens": ["Tod", "und", "Ohn\u00b7macht", "auf", "uns", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Kind und Mutter sind erblichen,", "tokens": ["Kind", "und", "Mut\u00b7ter", "sind", "er\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihrer Jugend Glanz wird greis,", "tokens": ["ih\u00b7rer", "Ju\u00b7gend", "Glanz", "wird", "greis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sie sind todfarb' angestrichen,", "tokens": ["sie", "sind", "tod\u00b7fa\u00b7rb'", "an\u00b7ge\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "H\u00e4nd' und Herzen werden Eis.", "tokens": ["H\u00e4nd'", "und", "Her\u00b7zen", "wer\u00b7den", "Eis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wir auch sterben hin mit ihnen,", "tokens": ["Wir", "auch", "ster\u00b7ben", "hin", "mit", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "APPR", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die wir itzt ihr Grab bedienen.", "tokens": ["die", "wir", "itzt", "ihr", "Grab", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hier stehn die verweinten Alten;", "tokens": ["Hier", "stehn", "die", "ver\u00b7wein\u00b7ten", "Al\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "beider Herzen sind zerst\u00fcckt", "tokens": ["bei\u00b7der", "Her\u00b7zen", "sind", "zer\u00b7st\u00fcckt"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und durch einen Hieb gespalten:", "tokens": ["und", "durch", "ei\u00b7nen", "Hieb", "ge\u00b7spal\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "zwei der Liebsten sind entz\u00fcckt,", "tokens": ["zwei", "der", "Liebs\u00b7ten", "sind", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "zwei der Liebsten aller Lieben,", "tokens": ["zwei", "der", "Liebs\u00b7ten", "al\u00b7ler", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ART", "NN", "PIAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kind und Kindskind, sind geblieben.", "tokens": ["Kind", "und", "Kinds\u00b7kind", ",", "sind", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie des Atlas T\u00f6chter gehen", "tokens": ["Wie", "des", "At\u00b7las", "T\u00f6ch\u00b7ter", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "um des Sternenochsens H\u00e4upt,", "tokens": ["um", "des", "Ster\u00b7ne\u00b7noch\u00b7sens", "H\u00e4upt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn sie unumnebelt stehen", "tokens": ["wenn", "sie", "un\u00b7um\u00b7ne\u00b7belt", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und kein S\u00fcdwind sie vertreibt,", "tokens": ["und", "kein", "S\u00fcd\u00b7wind", "sie", "ver\u00b7treibt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wie die sieben hellen Kerzen,", "tokens": ["wie", "die", "sie\u00b7ben", "hel\u00b7len", "Ker\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "CARD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die sich in dem Arkas herzen,", "tokens": ["die", "sich", "in", "dem", "Ar\u00b7kas", "her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "also stunds um uns noch gestern;", "tokens": ["al\u00b7so", "stunds", "um", "uns", "noch", "ge\u00b7stern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "heute streut sichs in die Luft.", "tokens": ["heu\u00b7te", "streut", "sichs", "in", "die", "Luft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zweimal drei erbla\u00dfte Schwestern", "tokens": ["Zwei\u00b7mal", "drei", "er\u00b7bla\u00df\u00b7te", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "gehn und \u00e4chzen um die Gruft;", "tokens": ["gehn", "und", "\u00e4ch\u00b7zen", "um", "die", "Gruft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVINF", "KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sie, voll Tr\u00e4nen, sehn von fernen", "tokens": ["sie", ",", "voll", "Tr\u00e4\u00b7nen", ",", "sehn", "von", "fer\u00b7nen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ADJD", "NN", "$,", "VVFIN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ihren Teil stehn in den Sternen.", "tokens": ["ih\u00b7ren", "Teil", "stehn", "in", "den", "Ster\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Betr\u00fcbtste der Betr\u00fcbten", "tokens": ["Der", "Be\u00b7tr\u00b7\u00fcbts\u00b7te", "der", "Be\u00b7tr\u00fcb\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "ist alleine nur nicht hier.", "tokens": ["ist", "al\u00b7lei\u00b7ne", "nur", "nicht", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die sich vor so einig liebten", "tokens": ["Die", "sich", "vor", "so", "ei\u00b7nig", "lieb\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "ADV", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sind geteilt nun f\u00fcr und f\u00fcr,", "tokens": ["sind", "ge\u00b7teilt", "nun", "f\u00fcr", "und", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "ADV", "APPR", "KON", "APPR", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bis auch er wird hingelangen,", "tokens": ["bis", "auch", "er", "wird", "hin\u00b7ge\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "wo die Liebste hin ist gangen.", "tokens": ["wo", "die", "Liebs\u00b7te", "hin", "ist", "gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wahr ists, da\u00df sein furchtsams Herze", "tokens": ["Wahr", "ists", ",", "da\u00df", "sein", "furcht\u00b7sams", "Her\u00b7ze"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "manch betr\u00fcbter Traum erschreckt,", "tokens": ["manch", "be\u00b7tr\u00fcb\u00b7ter", "Traum", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn ihn der geheime Schmerze", "tokens": ["wenn", "ihn", "der", "ge\u00b7hei\u00b7me", "Schmer\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aus dem schweren Traum' erweckt,", "tokens": ["aus", "dem", "schwe\u00b7ren", "Traum'", "er\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und das traurige Gesichte", "tokens": ["und", "das", "trau\u00b7ri\u00b7ge", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "schwebt stets vor dem Augenlichte.", "tokens": ["schwebt", "stets", "vor", "dem", "Au\u00b7gen\u00b7lich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ursach' ist vollauf zu weinen,", "tokens": ["Ur\u00b7sach'", "ist", "vol\u00b7lauf", "zu", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "wenn wir sehn, was vor uns liegt,", "tokens": ["wenn", "wir", "sehn", ",", "was", "vor", "uns", "liegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "doch so sollen wir nicht scheinen", "tokens": ["doch", "so", "sol\u00b7len", "wir", "nicht", "schei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "als mit Zagen unvergn\u00fcgt", "tokens": ["als", "mit", "Za\u00b7gen", "un\u00b7ver\u00b7gn\u00fcgt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und den Heiden uns vergleichen,", "tokens": ["und", "den", "Hei\u00b7den", "uns", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die kein Trost nicht kan erweichen.", "tokens": ["die", "kein", "Trost", "nicht", "kan", "er\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Meine Freunde, klagt mit Ma\u00dfen!", "tokens": ["Mei\u00b7ne", "Freun\u00b7de", ",", "klagt", "mit", "Ma\u00b7\u00dfen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie sind, wo man ewig bleibt,", "tokens": ["Sie", "sind", ",", "wo", "man", "e\u00b7wig", "bleibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "da wir sie doch m\u00fcssen lassen.", "tokens": ["da", "wir", "sie", "doch", "m\u00fcs\u00b7sen", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tut doch, was ihr feste gl\u00e4ubt:", "tokens": ["Tut", "doch", ",", "was", "ihr", "fes\u00b7te", "gl\u00e4ubt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "welche selig sind gestorben", "tokens": ["wel\u00b7che", "se\u00b7lig", "sind", "ge\u00b7stor\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PRELS", "ADJD", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sein und bleiben unverdorben.", "tokens": ["sein", "und", "blei\u00b7ben", "un\u00b7ver\u00b7dor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAINF", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Sterben und geboren werden", "tokens": ["Ster\u00b7ben", "und", "ge\u00b7bo\u00b7ren", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "VVPP", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist das alte Tun der Welt.", "tokens": ["ist", "das", "al\u00b7te", "Tun", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses ist der Brauch der Erden,", "tokens": ["Die\u00b7ses", "ist", "der", "Brauch", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das sie Ewigs nichts nicht h\u00e4lt.", "tokens": ["das", "sie", "E\u00b7wigs", "nichts", "nicht", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was die Zeit vor hat geboren,", "tokens": ["Was", "die", "Zeit", "vor", "hat", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APPR", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wird mit ihr durch sie verloren.", "tokens": ["wird", "mit", "ihr", "durch", "sie", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "La\u00dft dem Himmel seinen Willen,", "tokens": ["La\u00dft", "dem", "Him\u00b7mel", "sei\u00b7nen", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gebt ihm g\u00fctlich, was er gab!", "tokens": ["gebt", "ihm", "g\u00fct\u00b7lich", ",", "was", "er", "gab", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Di\u00df mu\u00df doch die Erde f\u00fcllen,", "tokens": ["Di\u00df", "mu\u00df", "doch", "die", "Er\u00b7de", "f\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was nicht gerne will ins Grab.", "tokens": ["was", "nicht", "ger\u00b7ne", "will", "ins", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADV", "VMFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das ists, das wir einig wissen,", "tokens": ["Das", "ists", ",", "das", "wir", "ei\u00b7nig", "wis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da\u00df wir einmal sterben m\u00fcssen.", "tokens": ["da\u00df", "wir", "ein\u00b7mal", "ster\u00b7ben", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wie Viel' sind ihr hingefahren,", "tokens": ["Wie", "Viel'", "sind", "ihr", "hin\u00b7ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wo auch diese zogen hin,", "tokens": ["wo", "auch", "die\u00b7se", "zo\u00b7gen", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDS", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "in den sechsthalbtausent Jahren;", "tokens": ["in", "den", "sechst\u00b7halb\u00b7tau\u00b7sent", "Jah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle waren, was ich bin.", "tokens": ["Al\u00b7le", "wa\u00b7ren", ",", "was", "ich", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Alle wurden so zu Erden,", "tokens": ["Al\u00b7le", "wur\u00b7den", "so", "zu", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie wir alle werden werden.", "tokens": ["wie", "wir", "al\u00b7le", "wer\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIS", "VAINF", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Zwar es ist ein gro\u00dfer Schmerze,", "tokens": ["Zwar", "es", "ist", "ein", "gro\u00b7\u00dfer", "Schmer\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "doch gedenkt des Sch\u00f6pfers auch!", "tokens": ["doch", "ge\u00b7denkt", "des", "Sch\u00f6p\u00b7fers", "auch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er, das liebe Vaterherze,", "tokens": ["Er", ",", "das", "lie\u00b7be", "Va\u00b7ter\u00b7her\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "h\u00e4lt stets diesen seinen Brauch,", "tokens": ["h\u00e4lt", "stets", "die\u00b7sen", "sei\u00b7nen", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PDAT", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df er die auch herzlich liebet,", "tokens": ["da\u00df", "er", "die", "auch", "herz\u00b7lich", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die er herzlich hat betr\u00fcbet.", "tokens": ["die", "er", "herz\u00b7lich", "hat", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADJD", "VAFIN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Feind der Welt, du kanst den Seelen", "tokens": ["Feind", "der", "Welt", ",", "du", "kanst", "den", "See\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PPER", "VMFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ganz mit keiner Sichel zu!", "tokens": ["ganz", "mit", "kei\u00b7ner", "Si\u00b7chel", "zu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr die Leiber sind die H\u00f6len,", "tokens": ["F\u00fcr", "die", "Lei\u00b7ber", "sind", "die", "H\u00f6\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aber, sch\u00f6ner Himmel, du", "tokens": ["a\u00b7ber", ",", "sch\u00f6\u00b7ner", "Him\u00b7mel", ",", "du"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bist, alswie du hei\u00dfest Meister,", "tokens": ["bist", ",", "als\u00b7wie", "du", "hei\u00b7\u00dfest", "Meis\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KON", "PPER", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Herr und Wirt auch unsrer Geister!", "tokens": ["Herr", "und", "Wirt", "auch", "uns\u00b7rer", "Geis\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Weil die frommen Leichen rasten", "tokens": ["Weil", "die", "from\u00b7men", "Lei\u00b7chen", "ras\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und in ihren Kammern ruhn,", "tokens": ["und", "in", "ih\u00b7ren", "Kam\u00b7mern", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "abgetan von allen Lasten,", "tokens": ["ab\u00b7ge\u00b7tan", "von", "al\u00b7len", "Las\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die uns stets den Tod antun,", "tokens": ["die", "uns", "stets", "den", "Tod", "an\u00b7tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "unterde\u00df sind ihre Seelen,", "tokens": ["un\u00b7ter\u00b7de\u00df", "sind", "ih\u00b7re", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo man wei\u00df von keinem Qu\u00e4len.", "tokens": ["wo", "man", "wei\u00df", "von", "kei\u00b7nem", "Qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Die erfreuten Seraphinnen", "tokens": ["Die", "er\u00b7freu\u00b7ten", "Se\u00b7ra\u00b7phin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "streichen ihre Z\u00e4ren ab,", "tokens": ["strei\u00b7chen", "ih\u00b7re", "Z\u00e4\u00b7ren", "ab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und ein Teil der Cherubinnen", "tokens": ["und", "ein", "Teil", "der", "Che\u00b7ru\u00b7bin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "gehn als W\u00e4chter um das Grab,", "tokens": ["gehn", "als", "W\u00e4ch\u00b7ter", "um", "das", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NE", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df das schlummernde Gebeine", "tokens": ["da\u00df", "das", "schlum\u00b7mern\u00b7de", "Ge\u00b7bei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "ganz behalte was ist seine.", "tokens": ["ganz", "be\u00b7hal\u00b7te", "was", "ist", "sei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VAFIN", "PPOSAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Was uns zeitlich wird genommen,", "tokens": ["Was", "uns", "zeit\u00b7lich", "wird", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "soll einst ewig unser sein,", "tokens": ["soll", "einst", "e\u00b7wig", "un\u00b7ser", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "PPOSAT", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn der gro\u00dfe Tag wird kommen,", "tokens": ["wenn", "der", "gro\u00b7\u00dfe", "Tag", "wird", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der schon itzund bricht herein;", "tokens": ["der", "schon", "it\u00b7zund", "bricht", "her\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "denn so wollen wir stets k\u00fcssen,", "tokens": ["denn", "so", "wol\u00b7len", "wir", "stets", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "das wir itzt stets mangeln m\u00fcssen.", "tokens": ["das", "wir", "itzt", "stets", "man\u00b7geln", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}