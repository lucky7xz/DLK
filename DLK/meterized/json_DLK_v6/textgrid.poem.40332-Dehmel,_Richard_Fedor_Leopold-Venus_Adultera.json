{"textgrid.poem.40332": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Venus Adultera", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Komm, Schatz; komm, Katz; la\u00df das Wimmern!", "tokens": ["Komm", ",", "Schatz", ";", "komm", ",", "Katz", ";", "la\u00df", "das", "Wim\u00b7mern", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$.", "VVFIN", "$,", "NN", "$.", "VVIMP", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein, das darf dich nicht bek\u00fcmmern,", "tokens": ["Nein", ",", "das", "darf", "dich", "nicht", "be\u00b7k\u00fcm\u00b7mern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich nicht \u00bbtreu\u00ab bin; r\u00fcck nur her!", "tokens": ["da\u00df", "ich", "nicht", "\u00bb", "treu", "\u00ab", "bin", ";", "r\u00fcck", "nur", "her", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "$(", "ADJD", "$(", "VAFIN", "$.", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Komm, ich hab ein Dutzend Seelen;", "tokens": ["Komm", ",", "ich", "hab", "ein", "Dut\u00b7zend", "See\u00b7len", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wer kann all die Kammern z\u00e4hlen,", "tokens": ["wer", "kann", "all", "die", "Kam\u00b7mern", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIAT", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sechse stehn mir grade leer.", "tokens": ["sech\u00b7se", "stehn", "mir", "gra\u00b7de", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Sieh nicht auf den Ring an meinem Finger!", "tokens": ["Sieh", "nicht", "auf", "den", "Ring", "an", "mei\u00b7nem", "Fin\u00b7ger", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Hoh, mein Kind, ich bin viel j\u00fcnger", "tokens": ["Hoh", ",", "mein", "Kind", ",", "ich", "bin", "viel", "j\u00fcn\u00b7ger"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "als mein narbigtes Gesicht.", "tokens": ["als", "mein", "nar\u00b7big\u00b7tes", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00dft du, die Runzeln und die Hiebe", "tokens": ["Wei\u00dft", "du", ",", "die", "Run\u00b7zeln", "und", "die", "Hie\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "tun erst die W\u00fcrze zu Ehre und Liebe!", "tokens": ["tun", "erst", "die", "W\u00fcr\u00b7ze", "zu", "Eh\u00b7re", "und", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.6": {"text": "Ja, das nannt ich als Student schon Pflicht:", "tokens": ["Ja", ",", "das", "nannt", "ich", "als", "Stu\u00b7dent", "schon", "Pflicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VVFIN", "PPER", "KOUS", "NN", "ADV", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Viel geliebt! noch mehr getrunken!", "tokens": ["Viel", "ge\u00b7liebt", "!", "noch", "mehr", "ge\u00b7trun\u00b7ken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$.", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "kuscht euch, Unken und Hallunken!", "tokens": ["kuscht", "euch", ",", "Un\u00b7ken", "und", "Hal\u00b7lun\u00b7ken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "heida, wie der Schl\u00e4ger pfiff!", "tokens": ["hei\u00b7da", ",", "wie", "der", "Schl\u00e4\u00b7ger", "pfiff", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll das Leben dir was n\u00fctzen,", "tokens": ["Soll", "das", "Le\u00b7ben", "dir", "was", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "lerne brav dein Blut verspr\u00fctzen:", "tokens": ["ler\u00b7ne", "brav", "dein", "Blut", "ver\u00b7spr\u00fct\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nicht gezuckt! los! blick und triff! \u2013", "tokens": ["nicht", "ge\u00b7zuckt", "!", "los", "!", "blick", "und", "triff", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "VVPP", "$.", "PTKVZ", "$.", "ADJD", "KON", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Hast doch auch schon \u00bbBlut\u00ab verspritzt,", "tokens": ["Hast", "doch", "auch", "schon", "\u00bb", "Blut", "\u00ab", "ver\u00b7spritzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "$(", "NN", "$(", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "oft \u2013 \u2013 hui, wie dein Auge blitzt:", "tokens": ["oft", "\u2013", "\u2013", "hui", ",", "wie", "dein", "Au\u00b7ge", "blitzt", ":"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "$(", "FM.la", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "z\u00fcrnst wohl gar dem frechen Buben?", "tokens": ["z\u00fcrnst", "wohl", "gar", "dem", "fre\u00b7chen", "Bu\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was denn: Tr\u00e4nen?? o nicht doch! oh!", "tokens": ["Was", "denn", ":", "Tr\u00e4\u00b7nen", "??", "o", "nicht", "doch", "!", "oh", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "ADV", "$.", "NN", "FM", "FM", "PTKNEG", "ADV", "$.", "FM", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Herzchen, so'was lernt man so", "tokens": ["Herz\u00b7chen", ",", "so'\u00b7was", "lernt", "man", "so"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "VVFIN", "PIS", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "in der Luft der Ehestuben!", "tokens": ["in", "der", "Luft", "der", "E\u00b7hes\u00b7tu\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Komm: sei gut, Kind! gib mir die Hand!", "tokens": ["Komm", ":", "sei", "gut", ",", "Kind", "!", "gib", "mir", "die", "Hand", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "VAFIN", "ADJD", "$,", "NN", "$.", "VVIMP", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hast ja Mut, Kind \u2013 und hast Verstand:", "tokens": ["Hast", "ja", "Mut", ",", "Kind", "\u2013", "und", "hast", "Ver\u00b7stand", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "$,", "NN", "$(", "KON", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "nein, ich will dich nicht verf\u00fchren.", "tokens": ["nein", ",", "ich", "will", "dich", "nicht", "ver\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber gelt, du w\u00e4rst gern Braut?", "tokens": ["A\u00b7ber", "gelt", ",", "du", "w\u00e4rst", "gern", "Braut", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier das Venushalsband deiner Haut", "tokens": ["Hier", "das", "Ve\u00b7nus\u00b7hals\u00b7band", "dei\u00b7ner", "Haut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "l\u00e4\u00dft verhaltene W\u00fcnsche sp\u00fcren.", "tokens": ["l\u00e4\u00dft", "ver\u00b7hal\u00b7te\u00b7ne", "W\u00fcn\u00b7sche", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Sieh mich doch an, du: ich bin kein Dieb!", "tokens": ["Sieh", "mich", "doch", "an", ",", "du", ":", "ich", "bin", "kein", "Dieb", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKVZ", "$,", "PPER", "$.", "PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "habe das Halsband nur so lieb", "tokens": ["ha\u00b7be", "das", "Hals\u00b7band", "nur", "so", "lieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADV", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "und deine dunkeln Augenringe.", "tokens": ["und", "dei\u00b7ne", "dun\u00b7keln", "Au\u00b7gen\u00b7rin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sieh doch, mein Blick ist ein z\u00fcndender Pfeil,", "tokens": ["Sieh", "doch", ",", "mein", "Blick", "ist", "ein", "z\u00fcn\u00b7den\u00b7der", "Pfeil", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "spr\u00fchenden Fluges ein sausendes Seil:", "tokens": ["spr\u00fc\u00b7hen\u00b7den", "Flu\u00b7ges", "ein", "sau\u00b7sen\u00b7des", "Seil", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.6": {"text": "komm, durch H\u00f6llen und Himmel soll's uns schwingen!", "tokens": ["komm", ",", "durch", "H\u00f6l\u00b7len", "und", "Him\u00b7mel", "soll's", "uns", "schwin\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "APPR", "NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.8": {"line.1": {"text": "Ja \u2013 so wird aus Sehnsucht S\u00fcnde;", "tokens": ["Ja", "\u2013", "so", "wird", "aus", "Sehn\u00b7sucht", "S\u00fcn\u00b7de", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "VAFIN", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6lle, die den Himmel st\u00fcrmt.", "tokens": ["H\u00f6l\u00b7le", ",", "die", "den", "Him\u00b7mel", "st\u00fcrmt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seele \u00f6ffnet alle Schl\u00fcnde,", "tokens": ["See\u00b7le", "\u00f6ff\u00b7net", "al\u00b7le", "Schl\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die der Geist rings m\u00fchsam \u00fcbert\u00fcrmte.", "tokens": ["die", "der", "Geist", "rings", "m\u00fch\u00b7sam", "\u00fc\u00b7ber\u00b7t\u00fcrm\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Denn Natur sch\u00fcrt wieder alle Gluten,", "tokens": ["Denn", "Na\u00b7tur", "sch\u00fcrt", "wie\u00b7der", "al\u00b7le", "Glu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "die der Mensch beherrschte in Gedanken;", "tokens": ["die", "der", "Mensch", "be\u00b7herrschte", "in", "Ge\u00b7dan\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "l\u00fcstern lecken ihre Lavafluten", "tokens": ["l\u00fcs\u00b7tern", "le\u00b7cken", "ih\u00b7re", "La\u00b7va\u00b7flu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "an dem Erzger\u00fcst der heiligen Schranken.", "tokens": ["an", "dem", "Erz\u00b7ge\u00b7r\u00fcst", "der", "hei\u00b7li\u00b7gen", "Schran\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Wie es hinschmilzt! Wer kann's kalt beschauen?", "tokens": ["Wie", "es", "hin\u00b7schmilzt", "!", "Wer", "kann's", "kalt", "be\u00b7schau\u00b7en", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$.", "PWS", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Nur der Mond in seiner Leichenpracht.", "tokens": ["Nur", "der", "Mond", "in", "sei\u00b7ner", "Lei\u00b7chen\u00b7pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und die Seele badet sich im Grauen,", "tokens": ["Und", "die", "See\u00b7le", "ba\u00b7det", "sich", "im", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und der Geist buhlt mit der Nacht.", "tokens": ["und", "der", "Geist", "buhlt", "mit", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Bis er Frevel heckt wie Don Juan,", "tokens": ["Bis", "er", "Fre\u00b7vel", "heckt", "wie", "Don", "Juan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "KOKOM", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der nur l\u00fcstern war aus Qualengier,", "tokens": ["der", "nur", "l\u00fcs\u00b7tern", "war", "aus", "Qua\u00b7len\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "ein vom Teufelswahn verlockter Gottesmann,", "tokens": ["ein", "vom", "Teu\u00b7fels\u00b7wahn", "ver\u00b7lock\u00b7ter", "Got\u00b7tes\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "freudeloser als ein Tier.", "tokens": ["freu\u00b7de\u00b7lo\u00b7ser", "als", "ein", "Tier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Nein, nicht Lust war's, du Jungfr\u00e4uliche,", "tokens": ["Nein", ",", "nicht", "Lust", "wa\u00b7r's", ",", "du", "Jung\u00b7fr\u00e4u\u00b7li\u00b7che", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKNEG", "NN", "VAFIN", "$,", "PPER", "NN", "$,"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "als ich deine Opferfreude schmeckte;", "tokens": ["als", "ich", "dei\u00b7ne", "Op\u00b7fer\u00b7freu\u00b7de", "schmeck\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "ich geno\u00df nur das Abscheuliche,", "tokens": ["ich", "ge\u00b7no\u00df", "nur", "das", "Ab\u00b7scheu\u00b7li\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+--++--", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "zu entweihn dich Unbefleckte,", "tokens": ["zu", "ent\u00b7weihn", "dich", "Un\u00b7be\u00b7fleck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}