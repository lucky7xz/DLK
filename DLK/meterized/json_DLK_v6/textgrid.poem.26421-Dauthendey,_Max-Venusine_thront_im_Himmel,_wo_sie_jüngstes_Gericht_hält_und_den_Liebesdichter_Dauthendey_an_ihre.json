{"textgrid.poem.26421": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Venusine thront im Himmel, wo sie j\u00fcngstes Gericht h\u00e4lt und den Liebesdichter Dauthendey an ihre", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Brennend brannte Sonne", "tokens": ["Bren\u00b7nend", "brann\u00b7te", "Son\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "VVFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf die Weinbergmauern,", "tokens": ["Auf", "die", "Wein\u00b7berg\u00b7mau\u00b7ern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Selbst die Steine konnten", "tokens": ["Selbst", "die", "Stei\u00b7ne", "konn\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einem schwitzend dauern.", "tokens": ["Ei\u00b7nem", "schwit\u00b7zend", "dau\u00b7ern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "In dem juliblauen", "tokens": ["In", "dem", "ju\u00b7lib\u00b7lau\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Himmel standen Wolken", "tokens": ["Him\u00b7mel", "stan\u00b7den", "Wol\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wei\u00dfgedeckt zu schauen,", "tokens": ["Wei\u00df\u00b7ge\u00b7deckt", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wei\u00dfgedeckt wie Tische,", "tokens": ["Wei\u00df\u00b7ge\u00b7deckt", "wie", "Ti\u00b7sche", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die auf G\u00e4ste warten.", "tokens": ["Die", "auf", "G\u00e4s\u00b7te", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dauthendey, der Dichter,", "tokens": ["Dau\u00b7then\u00b7dey", ",", "der", "Dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sah's von seinem Garten.", "tokens": ["Sah's", "von", "sei\u00b7nem", "Gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Nahm vom Stall den Schimmel,", "tokens": ["Nahm", "vom", "Stall", "den", "Schim\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Den er t\u00e4glich reitet,", "tokens": ["Den", "er", "t\u00e4g\u00b7lich", "rei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sprengte in den Himmel.", "tokens": ["Spreng\u00b7te", "in", "den", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Sah der Erde V\u00e4ter", "tokens": ["Sah", "der", "Er\u00b7de", "V\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "An den Tischen schmausen;", "tokens": ["An", "den", "Ti\u00b7schen", "schmau\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "A\u00dfen, tranken, lachten", "tokens": ["A\u00b7\u00dfen", ",", "tran\u00b7ken", ",", "lach\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ohne lange Pausen.", "tokens": ["Oh\u00b7ne", "lan\u00b7ge", "Pau\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Biblische Gesichter", "tokens": ["Bib\u00b7li\u00b7sche", "Ge\u00b7sich\u00b7ter"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gr\u00fc\u00dften ihn gar h\u00f6flich,", "tokens": ["Gr\u00fc\u00df\u00b7ten", "ihn", "gar", "h\u00f6f\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihn, der Liebe Dichter.", "tokens": ["Ihn", ",", "der", "Lie\u00b7be", "Dich\u00b7ter."], "token_info": ["word", "punct", "word", "word", "abbreviation"], "pos": ["PPER", "$,", "ART", "NN", "NN"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Venusine selber,", "tokens": ["Ve\u00b7nu\u00b7si\u00b7ne", "sel\u00b7ber", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "ADV", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Frei von Kleid und Schleppe,", "tokens": ["Frei", "von", "Kleid", "und", "Schlep\u00b7pe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Rannte ihm entgegen", "tokens": ["Rann\u00b7te", "ihm", "ent\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "An der blauen Treppe.", "tokens": ["An", "der", "blau\u00b7en", "Trep\u00b7pe", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Fiel ihm in die Arme,", "tokens": ["Fiel", "ihm", "in", "die", "Ar\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lacht mit vollen Backen", "tokens": ["Lacht", "mit", "vol\u00b7len", "Ba\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Frei von Tr\u00e4n' und Harme.", "tokens": ["Frei", "von", "Tr\u00e4n'", "und", "Har\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "\u00bb\u00fcber Deinem Garten", "tokens": ["\u00bb", "\u00fc\u00b7ber", "Dei\u00b7nem", "Gar\u00b7ten"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Deckten wir die Tische.", "tokens": ["Deck\u00b7ten", "wir", "die", "Ti\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alle Speisen warten,", "tokens": ["Al\u00b7le", "Spei\u00b7sen", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Suppe, Omelett', Fische,", "tokens": ["Sup\u00b7pe", ",", "O\u00b7me\u00b7lett'", ",", "Fi\u00b7sche", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.10": {"line.1": {"text": "Kaviar und Kapaunen.", "tokens": ["Ka\u00b7vi\u00b7ar", "und", "Ka\u00b7pau\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Und die Musikanten", "tokens": ["Und", "die", "Mu\u00b7si\u00b7kan\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Rufen mit Posaunen.", "tokens": ["Ru\u00b7fen", "mit", "Po\u00b7sau\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Siehst Du Adam, Moses,", "tokens": ["Siehst", "Du", "A\u00b7dam", ",", "Mo\u00b7ses", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Abraham und Aron?", "tokens": ["Ab\u00b7ra\u00b7ham", "und", "A\u00b7ron", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Siehst Du Homer, Dante,", "tokens": ["Siehst", "Du", "Ho\u00b7mer", ",", "Dan\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "$,", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Goethe und auch Charon?", "tokens": ["Goe\u00b7the", "und", "auch", "Cha\u00b7ron", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADV", "NE", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "Heut ist \u203aJ\u00fcngst's Gerichte\u2039.", "tokens": ["Heut", "ist", "\u203a", "J\u00fcngst's", "Ge\u00b7rich\u00b7te", "\u2039", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "$(", "NE", "NN", "$(", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Deshalb kommt man n\u00e4mlich, \u2013", "tokens": ["Des\u00b7halb", "kommt", "man", "n\u00e4m\u00b7lich", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADV", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Flott wird die Geschichte.", "tokens": ["Flott", "wird", "die", "Ge\u00b7schich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.13": {"line.1": {"text": "Seit der Teufel neulich", "tokens": ["Seit", "der", "Teu\u00b7fel", "neu\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schnell aus Lieb gestorben,", "tokens": ["Schnell", "aus", "Lieb", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat er samt der H\u00f6lle", "tokens": ["Hat", "er", "samt", "der", "H\u00f6l\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "S' Himmelreich erworben.", "tokens": ["S'", "Him\u00b7mel\u00b7reich", "er\u00b7wor\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Himmlisches Gelichter,", "tokens": ["Himm\u00b7li\u00b7sches", "Ge\u00b7lich\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Platz\u00ab, ruft Venusine,", "tokens": ["Platz", "\u00ab", ",", "ruft", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "\u00bbplatz f\u00fcr meinen Dichter!\u00ab", "tokens": ["\u00bb", "platz", "f\u00fcr", "mei\u00b7nen", "Dich\u00b7ter", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Dauthendey mu\u00df sitzen", "tokens": ["Dau\u00b7then\u00b7dey", "mu\u00df", "sit\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["PAV", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ihr zur rechten Seite,", "tokens": ["Ihr", "zur", "rech\u00b7ten", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Er, der schon sein Lebtag", "tokens": ["Er", ",", "der", "schon", "sein", "Leb\u00b7tag"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PRELS", "ADV", "PPOSAT", "NN"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Um die Venus freite.", "tokens": ["Um", "die", "Ve\u00b7nus", "frei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Teufel sitzt zur Linken.", "tokens": ["Teu\u00b7fel", "sitzt", "zur", "Lin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venus, Teufel, Dichter", "tokens": ["Ve\u00b7nus", ",", "Teu\u00b7fel", ",", "Dich\u00b7ter"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NN", "$,", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dutzen sich und trinken.", "tokens": ["Dut\u00b7zen", "sich", "und", "trin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "KON", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Venusine dr\u00fcckte", "tokens": ["Ve\u00b7nu\u00b7si\u00b7ne", "dr\u00fcck\u00b7te"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Unterm Tisch die Zehen", "tokens": ["Un\u00b7term", "Tisch", "die", "Ze\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Beiden von den G\u00e4sten \u2013", "tokens": ["Bei\u00b7den", "von", "den", "G\u00e4s\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "$("], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Liebe mu\u00dft' entstehen.", "tokens": ["Lie\u00b7be", "mu\u00dft'", "ent\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Lange konnt's nicht dauern,", "tokens": ["Lan\u00b7ge", "konnt's", "nicht", "dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ward die Luft zu enge", "tokens": ["Ward", "die", "Luft", "zu", "en\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Selbst in Himmelsmauern.", "tokens": ["Selbst", "in", "Him\u00b7mels\u00b7mau\u00b7ern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Teufel eifers\u00fcchtig", "tokens": ["Teu\u00b7fel", "ei\u00b7fer\u00b7s\u00fcch\u00b7tig"], "token_info": ["word", "word"], "pos": ["NE", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lie\u00df sich gar nichts merken.", "tokens": ["Lie\u00df", "sich", "gar", "nichts", "mer\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dauthendey, erstickend,", "tokens": ["Dau\u00b7then\u00b7dey", ",", "er\u00b7sti\u00b7ckend", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mu\u00dft' am Wein sich st\u00e4rken.", "tokens": ["Mu\u00dft'", "am", "Wein", "sich", "st\u00e4r\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Die vom Testamente,", "tokens": ["Die", "vom", "Tes\u00b7ta\u00b7men\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Von dem alt und neuen,", "tokens": ["Von", "dem", "alt", "und", "neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "KON", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sagten: \u00bbProst Entente!\u00ab", "tokens": ["Sag\u00b7ten", ":", "\u00bb", "Prost", "En\u00b7ten\u00b7te", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "NN", "NN", "$.", "$("], "meter": "+--+--", "measure": "dactylic.di.plus"}}, "stanza.21": {"line.1": {"text": "Venusin verlegen", "tokens": ["Ve\u00b7nu\u00b7sin", "ver\u00b7le\u00b7gen"], "token_info": ["word", "word"], "pos": ["NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "K\u00fc\u00dfte ihren Dichter.", "tokens": ["K\u00fc\u00df\u00b7te", "ih\u00b7ren", "Dich\u00b7ter."], "token_info": ["word", "word", "abbreviation"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Teufel lachte vorne,", "tokens": ["Teu\u00b7fel", "lach\u00b7te", "vor\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Hinten schnitt er G'sichter.", "tokens": ["Hin\u00b7ten", "schnitt", "er", "G'\u00b7sich\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$."], "meter": "+-+----", "measure": "unknown.measure.di"}}, "stanza.22": {"line.1": {"text": "\u00bbbin ich nicht gestorben", "tokens": ["\u00bb", "bin", "ich", "nicht", "ge\u00b7stor\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "J\u00fcngst erst Dir zu Liebe", "tokens": ["J\u00fcngst", "erst", "Dir", "zu", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und jetzt unverdorben?\u00ab", "tokens": ["Und", "jetzt", "un\u00b7ver\u00b7dor\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Also fragte leise", "tokens": ["Al\u00b7so", "frag\u00b7te", "lei\u00b7se"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Teufel Venusine.", "tokens": ["Teu\u00b7fel", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-----", "measure": "dactylic.init"}, "line.3": {"text": "Diese aber teuflisch", "tokens": ["Die\u00b7se", "a\u00b7ber", "teuf\u00b7lisch"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Lacht mit Himmelsmiene:", "tokens": ["Lacht", "mit", "Him\u00b7mels\u00b7mie\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "\u00bbunter uns gesprochen", "tokens": ["\u00bb", "un\u00b7ter", "uns", "ge\u00b7spro\u00b7chen"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "APPR", "PPER", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hast Du einst nach Schwefel", "tokens": ["Hast", "Du", "einst", "nach", "Schwe\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Besser mir gerochen.", "tokens": ["Bes\u00b7ser", "mir", "ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Teufel, warst mir lieber,", "tokens": ["Teu\u00b7fel", ",", "warst", "mir", "lie\u00b7ber", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wie Du noch am Leben", "tokens": ["Wie", "Du", "noch", "am", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPRART", "NN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Wilder als ein Wilder,", "tokens": ["Wil\u00b7der", "als", "ein", "Wil\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die nicht Gnade geben.", "tokens": ["Die", "nicht", "Gna\u00b7de", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Heute hier im Himmel", "tokens": ["Heu\u00b7te", "hier", "im", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lieb ich mehr den Dichter,", "tokens": ["Lieb", "ich", "mehr", "den", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mehr selbst seinen Schimmel.\u00ab", "tokens": ["Mehr", "selbst", "sei\u00b7nen", "Schim\u00b7mel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Zornig ward der Teufel", "tokens": ["Zor\u00b7nig", "ward", "der", "Teu\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber alle Ma\u00dfen.", "tokens": ["\u00dc\u00b7ber", "al\u00b7le", "Ma\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wollte gerne wettern,", "tokens": ["Woll\u00b7te", "ger\u00b7ne", "wet\u00b7tern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Aber selbst das Hassen,", "tokens": ["A\u00b7ber", "selbst", "das", "Has\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Das ihm gut gestanden", "tokens": ["Das", "ihm", "gut", "ge\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Unten in der H\u00f6lle,", "tokens": ["Un\u00b7ten", "in", "der", "H\u00f6l\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kam ihm jetzt abhanden.", "tokens": ["Kam", "ihm", "jetzt", "ab\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.29": {"line.1": {"text": "G\u00fctig war der B\u00f6se", "tokens": ["G\u00fc\u00b7tig", "war", "der", "B\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gar nicht zu erkennen;", "tokens": ["Gar", "nicht", "zu", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00c4ngstlich von der Tafel", "tokens": ["\u00c4ngst\u00b7lich", "von", "der", "Ta\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Tat er weiterrennen,", "tokens": ["Tat", "er", "wei\u00b7ter\u00b7ren\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.30": {"line.1": {"text": "\u00c4ngstlich aus dem Saale", "tokens": ["\u00c4ngst\u00b7lich", "aus", "dem", "Saa\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Fort von allen Guten,", "tokens": ["Fort", "von", "al\u00b7len", "Gu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Fort vom Liebesmahle.", "tokens": ["Fort", "vom", "Lie\u00b7bes\u00b7mah\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.31": {"line.1": {"text": "An der blauen Treppe", "tokens": ["An", "der", "blau\u00b7en", "Trep\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Stand des Dichters Schimmel.", "tokens": ["Stand", "des", "Dich\u00b7ters", "Schim\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Diesen stiehlt der Teufel,", "tokens": ["Die\u00b7sen", "stiehlt", "der", "Teu\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,"], "meter": "+-+---", "measure": "unknown.measure.di"}, "line.4": {"text": "Reitet aus dem Himmel.", "tokens": ["Rei\u00b7tet", "aus", "dem", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.32": {"line.1": {"text": "Seine Wege m\u00fcnden", "tokens": ["Sei\u00b7ne", "We\u00b7ge", "m\u00fcn\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wieder auf die Erde,", "tokens": ["Wie\u00b7der", "auf", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will dort H\u00f6llen gr\u00fcnden.", "tokens": ["Will", "dort", "H\u00f6l\u00b7len", "gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.33": {"line.1": {"text": "Und dort wird er Zensor,", "tokens": ["Und", "dort", "wird", "er", "Zen\u00b7sor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Der den Dichter bindet,", "tokens": ["Der", "den", "Dich\u00b7ter", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kritikus daneben,", "tokens": ["Kri\u00b7ti\u00b7kus", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "PAV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der die Haut ihm schindet.", "tokens": ["Der", "die", "Haut", "ihm", "schin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Bis er davon m\u00fcde,", "tokens": ["Bis", "er", "da\u00b7von", "m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In dem Reichstag sitzet", "tokens": ["In", "dem", "Reichs\u00b7tag", "sit\u00b7zet"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und plaidiert f\u00fcrs Pr\u00fcde.", "tokens": ["Und", "plai\u00b7diert", "f\u00fcrs", "Pr\u00fc\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.35": {"line.1": {"text": "Aber alle Leiden,", "tokens": ["A\u00b7ber", "al\u00b7le", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die der Teufel dichtet,", "tokens": ["Die", "der", "Teu\u00b7fel", "dich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nicht dem Menschen schaden,", "tokens": ["Nicht", "dem", "Men\u00b7schen", "scha\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Der zur Venus fl\u00fcchtet.", "tokens": ["Der", "zur", "Ve\u00b7nus", "fl\u00fcch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.36": {"line.1": {"text": "Venus wird erl\u00f6sen", "tokens": ["Ve\u00b7nus", "wird", "er\u00b7l\u00f6\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["NE", "VAFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Alle ihre Dichter", "tokens": ["Al\u00b7le", "ih\u00b7re", "Dich\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von den Pr\u00fcden, B\u00f6sen.", "tokens": ["Von", "den", "Pr\u00fc\u00b7den", ",", "B\u00f6\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "Venus hat den Vorsitz", "tokens": ["Ve\u00b7nus", "hat", "den", "Vor\u00b7sitz"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "An den Himmelstischen,", "tokens": ["An", "den", "Him\u00b7mels\u00b7ti\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tut auch ihrem Liebling", "tokens": ["Tut", "auch", "ih\u00b7rem", "Lieb\u00b7ling"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Selbst den Mund abwischen.", "tokens": ["Selbst", "den", "Mund", "ab\u00b7wi\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.38": {"line.1": {"text": "Gar nichts mu\u00df er m\u00fcssen,", "tokens": ["Gar", "nichts", "mu\u00df", "er", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PPER", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "L\u00e4\u00dft den Teufel fluchen,", "tokens": ["L\u00e4\u00dft", "den", "Teu\u00b7fel", "flu\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Darf die Venus k\u00fcssen.", "tokens": ["Darf", "die", "Ve\u00b7nus", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "Kommt man in den Himmel,", "tokens": ["Kommt", "man", "in", "den", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Fragt Dich ins Gesichte", "tokens": ["Fragt", "Dich", "ins", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Venusin, als Richter", "tokens": ["Ve\u00b7nu\u00b7sin", ",", "als", "Rich\u00b7ter"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Von dem Weltgerichte:", "tokens": ["Von", "dem", "Welt\u00b7ge\u00b7rich\u00b7te", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.40": {"line.1": {"text": "\u00bbtat Dein Blut auch lieben", "tokens": ["\u00bb", "tat", "Dein", "Blut", "auch", "lie\u00b7ben"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Echt und ohne Logik?", "tokens": ["Echt", "und", "oh\u00b7ne", "Lo\u00b7gik", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Dann wird dageblieben.", "tokens": ["Dann", "wird", "da\u00b7ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.41": {"line.1": {"text": "Hast Du's nicht gelernet,", "tokens": ["Hast", "Du's", "nicht", "ge\u00b7ler\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PTKNEG", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Dann nochmals auf Erden", "tokens": ["Dann", "noch\u00b7mals", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Mu\u00dft zum echten lieben", "tokens": ["Mu\u00dft", "zum", "ech\u00b7ten", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPRART", "ADJA", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Du geboren werden.", "tokens": ["Du", "ge\u00b7bo\u00b7ren", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.42": {"line.1": {"text": "Dann zur\u00fcck zur Erde,", "tokens": ["Dann", "zu\u00b7r\u00fcck", "zur", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Lerne Feuer fangen,", "tokens": ["Ler\u00b7ne", "Feu\u00b7er", "fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wie die Dichterpferde!", "tokens": ["Wie", "die", "Dich\u00b7ter\u00b7pfer\u00b7de", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "Feurig ohn' Gedanke", "tokens": ["Feu\u00b7rig", "ohn'", "Ge\u00b7dan\u00b7ke"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nimm Unm\u00f6glichkeiten!", "tokens": ["Nimm", "Un\u00b7m\u00f6g\u00b7lich\u00b7kei\u00b7ten", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Herzen sattelfester", "tokens": ["Her\u00b7zen", "sat\u00b7tel\u00b7fes\u00b7ter"], "token_info": ["word", "word"], "pos": ["NN", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Als Gehirne reiten.", "tokens": ["Als", "Ge\u00b7hir\u00b7ne", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "Nicht mit Kritik-Miene", "tokens": ["Nicht", "mit", "Kri\u00b7ti\u00b7kMie\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schau aufs Ideale,", "tokens": ["Schau", "aufs", "I\u00b7dea\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Sonst flieht Venusine.\u00ab", "tokens": ["Sonst", "flieht", "Ve\u00b7nu\u00b7si\u00b7ne", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "NE", "$.", "$("], "meter": "-+----", "measure": "dactylic.init"}}, "stanza.45": {"line.1": {"text": "Lebt jetzt wohl ihr Menschen,", "tokens": ["Lebt", "jetzt", "wohl", "ihr", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die ihr dies gelesen!", "tokens": ["Die", "ihr", "dies", "ge\u00b7le\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PDS", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist euch manches fettig", "tokens": ["Ist", "euch", "man\u00b7ches", "fet\u00b7tig"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PIS", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und zu fett gewesen,", "tokens": ["Und", "zu", "fett", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKA", "ADJD", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Schleckt euch eure H\u00e4nde.", "tokens": ["Schleckt", "euch", "eu\u00b7re", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Von dem Venusreime", "tokens": ["Von", "dem", "Ve\u00b7nus\u00b7rei\u00b7me"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist jetzt dies das Ende.", "tokens": ["Ist", "jetzt", "dies", "das", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDS", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}