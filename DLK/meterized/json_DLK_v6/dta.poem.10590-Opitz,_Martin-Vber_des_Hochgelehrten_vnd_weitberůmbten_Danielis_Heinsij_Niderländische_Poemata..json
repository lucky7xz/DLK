{"dta.poem.10590": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "Vber des Hochgelehrten vnd weitber\u016fmbten  \n  Danielis Heinsij   Niderl\u00e4ndische Poemata.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1624", "urn": "urn:nbn:de:kobv:b4-200905197859", "language": ["de:0.99"], "booktitle": "Opitz, Martin: Teutsche P\u00f6emata und: Aristarchvs Wieder die verachtung Teutscher Sprach. Stra\u00dfburg, 1624."}, "poem": {"stanza.1": {"line.1": {"text": "Ihr Nymphen auff der Maa\u00df/ jhr Meer einwohnerinnen", "tokens": ["Ihr", "Nym\u00b7phen", "auff", "der", "Maa\u00df", "/", "jhr", "Meer", "ein\u00b7woh\u00b7ne\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$(", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hebt ewre H\u00e4upter auff/ erh\u00f6het ewre Sinnen/", "tokens": ["Hebt", "ew\u00b7re", "H\u00e4up\u00b7ter", "auff", "/", "er\u00b7h\u00f6\u00b7het", "ew\u00b7re", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Frew dich/ du sch\u00f6ner Rein/ vnd du gelehrte Statt/", "tokens": ["Frew", "dich", "/", "du", "sch\u00f6\u00b7ner", "Rein", "/", "vnd", "du", "ge\u00b7lehr\u00b7te", "Statt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "PPER", "ADJA", "NN", "$(", "KON", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Hungersnoth vnd Krieg zugleich getragen hat:", "tokens": ["Die", "Hun\u00b7gers\u00b7noth", "vnd", "Krieg", "zu\u00b7gleich", "ge\u00b7tra\u00b7gen", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der gantze Helicon ist bey dir eingezogen/", "tokens": ["Der", "gant\u00b7ze", "He\u00b7li\u00b7con", "ist", "bey", "dir", "ein\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach dem der hohe Geist von Gent hieher geflogen/", "tokens": ["Nach", "dem", "der", "ho\u00b7he", "Geist", "von", "Gent", "hie\u00b7her", "ge\u00b7flo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "APPR", "NN", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Tauben/ so zuvor dir Zeitung zugebracht/", "tokens": ["Die", "Tau\u00b7ben", "/", "so", "zu\u00b7vor", "dir", "Zei\u00b7tung", "zu\u00b7ge\u00b7bracht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ADV", "PPER", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hat Venus jetzt auch hier zu Burgerin gemacht/", "tokens": ["Hat", "Ve\u00b7nus", "jetzt", "auch", "hier", "zu", "Bur\u00b7ge\u00b7rin", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ADV", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Edle von der Does hat erstlich sie gelocket/", "tokens": ["Der", "Ed\u00b7le", "von", "der", "Does", "hat", "erst\u00b7lich", "sie", "ge\u00b7lo\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "VAFIN", "ADJD", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sein\u2019 Ida gleichfals offt an jhren Mund getrucket/", "tokens": ["Sein'", "I\u00b7da", "gleich\u00b7fals", "offt", "an", "jhren", "Mund", "ge\u00b7tru\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Sein\u2019 Ida die den Mars so jnniglich verwundt/", "tokens": ["Sein'", "I\u00b7da", "die", "den", "Mars", "so", "jn\u00b7nig\u00b7lich", "ver\u00b7wundt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "ART", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df er Schwerdt/ Schildt vnd Spie\u00df nicht lenger halten kundt.", "tokens": ["Da\u00df", "er", "Schwerdt", "/", "Schildt", "vnd", "Spie\u00df", "nicht", "len\u00b7ger", "hal\u00b7ten", "kundt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NE", "$(", "NN", "KON", "NN", "PTKNEG", "ADJD", "VVFIN", "PTKVZ", "$."], "meter": "--++-+-+-+-+", "measure": "anapaest.init"}, "line.13": {"text": "Die Thr\u00e4nen so vor Lieb au\u00df seinen Augen flossen/", "tokens": ["Die", "Thr\u00e4\u00b7nen", "so", "vor", "Lieb", "au\u00df", "sei\u00b7nen", "Au\u00b7gen", "flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Sind der Maranen Heer ins L\u00e4ger auch geschossen/", "tokens": ["Sind", "der", "Ma\u00b7ra\u00b7nen", "Heer", "ins", "L\u00e4\u00b7ger", "auch", "ge\u00b7schos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPRART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da ward es gar zu na\u00df. Sie liessen Leiden stehn/", "tokens": ["Da", "ward", "es", "gar", "zu", "na\u00df", ".", "Sie", "lies\u00b7sen", "Lei\u00b7den", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$.", "PPER", "VVFIN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Vnd f\u00fcrchteten/ die Flut m\u00f6cht an die Kr\u00f6ser gehn.", "tokens": ["Vnd", "f\u00fcrch\u00b7te\u00b7ten", "/", "die", "Flut", "m\u00f6cht", "an", "die", "Kr\u00f6\u00b7ser", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "ART", "NN", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So bald der Spanier nun vrlaub hat genommen", "tokens": ["So", "bald", "der", "Spa\u00b7nier", "nun", "vr\u00b7laub", "hat", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "ADJD", "VAFIN", "VVPP"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "De\u00df Wassers vngewohnt: Ist Pallas zu euch kommen/", "tokens": ["De\u00df", "Was\u00b7sers", "vn\u00b7ge\u00b7wohnt", ":", "Ist", "Pal\u00b7las", "zu", "euch", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "VAFIN", "NN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Vnd ", "tokens": ["Vnd"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.20": {"text": "Die dann au\u00df Niderland Athen vnd Romgemacht/", "tokens": ["Die", "dann", "au\u00df", "Ni\u00b7der\u00b7land", "A\u00b7then", "vnd", "Rom\u00b7ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NE", "NE", "KON", "NN", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Es war noch nicht genug/ der Held von Brennus Stamme/", "tokens": ["Es", "war", "noch", "nicht", "ge\u00b7nug", "/", "der", "Held", "von", "Bren\u00b7nus", "Stam\u00b7me", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "$(", "ART", "NN", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der grosse Scaliger/ steckt auff sein helle Flamme/", "tokens": ["Der", "gros\u00b7se", "Sca\u00b7li\u00b7ger", "/", "steckt", "auff", "sein", "hel\u00b7le", "Flam\u00b7me", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Die Franckreich war entf\u00fchrt: Ein Mann/ ein einig Mann", "tokens": ["Die", "Fran\u00b7ck\u00b7reich", "war", "ent\u00b7f\u00fchrt", ":", "Ein", "Mann", "/", "ein", "ei\u00b7nig", "Mann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "VVPP", "$.", "ART", "NN", "$(", "ART", "ADJD", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Der Adler in der Lusst/ redt alle V\u00f6lcker an/", "tokens": ["Der", "Ad\u00b7ler", "in", "der", "Lusst", "/", "redt", "al\u00b7le", "V\u00f6l\u00b7cker", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$(", "VVFIN", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Bi\u00df jhr auch Heinsius/ jhr Ph", "tokens": ["Bi\u00df", "jhr", "auch", "Hein\u00b7si\u00b7us", "/", "jhr", "Ph"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NE", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Ihr Sohn der Ewigkeit/ beguntet au\u00dfzubreiten", "tokens": ["Ihr", "Sohn", "der", "E\u00b7wig\u00b7keit", "/", "be\u00b7gun\u00b7tet", "au\u00df\u00b7zu\u00b7brei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "NN", "$(", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die Fl\u00fcgel der Vernunfst. Das kleine Vatterland", "tokens": ["Die", "Fl\u00fc\u00b7gel", "der", "Ver\u00b7nunfst", ".", "Das", "klei\u00b7ne", "Vat\u00b7ter\u00b7land"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Trotzt jetzt die grosse Welt mit ewerem Verstandt.", "tokens": ["Trotzt", "jetzt", "die", "gros\u00b7se", "Welt", "mit", "e\u00b7we\u00b7rem", "Ver\u00b7standt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.29": {"text": "Was Aristoteles/ was Socrates gelehret/", "tokens": ["Was", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "/", "was", "So\u00b7cra\u00b7tes", "ge\u00b7leh\u00b7ret", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "$(", "PWS", "NE", "VVPP", "$("], "meter": "-+-+----+--+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Was Orphe", "tokens": ["Was", "Or\u00b7phe"], "token_info": ["word", "word"], "pos": ["PWS", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.31": {"text": "Was Tullius gesagt/ was jergendt jemand kan/", "tokens": ["Was", "Tul\u00b7li\u00b7us", "ge\u00b7sagt", "/", "was", "jer\u00b7gendt", "je\u00b7mand", "kan", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "VVPP", "$(", "PWS", "PIS", "PIS", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Das sicht man jetzt von euch/ von euch/ jhr Gentscher Schwan.", "tokens": ["Das", "sicht", "man", "jetzt", "von", "euch", "/", "von", "euch", "/", "jhr", "Gent\u00b7scher", "Schwan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "PPER", "$(", "APPR", "PPER", "$(", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.34": {"text": "Wir wusten selber kaum von wannen wir geboren/", "tokens": ["Wir", "wus\u00b7ten", "sel\u00b7ber", "kaum", "von", "wan\u00b7nen", "wir", "ge\u00b7bo\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "VVFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Die Sprache/ vor der vor viel Feind erschrocken sindt/", "tokens": ["Die", "Spra\u00b7che", "/", "vor", "der", "vor", "viel", "Feind", "er\u00b7schro\u00b7cken", "sindt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "ART", "APPR", "PIAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Vergassen wir mit flei\u00df vnd schlugen sie in Windt.", "tokens": ["Ver\u00b7gas\u00b7sen", "wir", "mit", "flei\u00df", "vnd", "schlu\u00b7gen", "sie", "in", "Windt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Bi\u00df ewer fewrig Hertz ist endtlich au\u00dfgerissen/", "tokens": ["Bi\u00df", "e\u00b7wer", "few\u00b7rig", "Hertz", "ist", "endt\u00b7lich", "au\u00df\u00b7ge\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Vnd hat vns klar gemacht/ wie sch\u00e4ndtlich wir verliessen", "tokens": ["Vnd", "hat", "vns", "klar", "ge\u00b7macht", "/", "wie", "sch\u00e4ndt\u00b7lich", "wir", "ver\u00b7lies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "VVPP", "$(", "PWAV", "ADJD", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Was allen doch geb\u00fcrt: Wir redten gut Latein/", "tokens": ["Was", "al\u00b7len", "doch", "ge\u00b7b\u00fcrt", ":", "Wir", "red\u00b7ten", "gut", "La\u00b7tein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "VVPP", "$.", "PPER", "VVFIN", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Vnd wolte keiner nicht f\u00fcr Teutsch gescholten sein.", "tokens": ["Vnd", "wol\u00b7te", "kei\u00b7ner", "nicht", "f\u00fcr", "Teutsch", "ge\u00b7schol\u00b7ten", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "PTKNEG", "APPR", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Der war\u2019 weit vber Meer in Griechenland geflogen/", "tokens": ["Der", "wa\u00b7r'", "weit", "vber", "Meer", "in", "Grie\u00b7chen\u00b7land", "ge\u00b7flo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "APPR", "NN", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Der hatt Italien/ der Franckreich durchgezogen/", "tokens": ["Der", "hatt", "I\u00b7ta\u00b7li\u00b7en", "/", "der", "Fran\u00b7ck\u00b7reich", "durch\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NE", "$(", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.43": {"text": "Der prallte Spanisch her. Ihr habt sie recht verlacht/", "tokens": ["Der", "prall\u00b7te", "Spa\u00b7nisch", "her", ".", "Ihr", "habt", "sie", "recht", "ver\u00b7lacht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Vnd vnsre Muttersprach in jhren werth gebracht.", "tokens": ["Vnd", "vns\u00b7re", "Mut\u00b7ter\u00b7sprach", "in", "jhren", "werth", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.45": {"text": "Hierumb wirdt ewer Lob ohn alles ende bl\u00fchen/", "tokens": ["Hie\u00b7rumb", "wirdt", "e\u00b7wer", "Lob", "ohn", "al\u00b7les", "en\u00b7de", "bl\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Das ewige Geschrey von euch wirdt ferne ziehen/", "tokens": ["Das", "e\u00b7wi\u00b7ge", "Ge\u00b7schrey", "von", "euch", "wirdt", "fer\u00b7ne", "zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Von dar die sch\u00f6ne Sonn au\u00df jhrem Beth auffsteht/", "tokens": ["Von", "dar", "die", "sch\u00f6\u00b7ne", "Sonn", "au\u00df", "jhrem", "Be\u00b7th", "auffs\u00b7teht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKVZ", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Vnd widerumb zu ruh mit jhren Pferden geht.", "tokens": ["Vnd", "wi\u00b7de\u00b7rumb", "zu", "ruh", "mit", "jhren", "Pfer\u00b7den", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.49": {"text": "Ich auch/ weil jhr mir seyt im Schreiben vorgegangen/", "tokens": ["Ich", "auch", "/", "weil", "jhr", "mir", "seyt", "im", "Schrei\u00b7ben", "vor\u00b7ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "KOUS", "PPER", "PPER", "VAFIN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Was ich f\u00fcr Ruhm vnd Ehr durch Hochteutsch werd erlangen/", "tokens": ["Was", "ich", "f\u00fcr", "Ruhm", "vnd", "Ehr", "durch", "Hoch\u00b7teutsch", "werd", "er\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "NN", "KON", "NN", "APPR", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Will meinem Vatterlandt bekennen ohne schew/", "tokens": ["Will", "mei\u00b7nem", "Vat\u00b7ter\u00b7landt", "be\u00b7ken\u00b7nen", "oh\u00b7ne", "schew", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVFIN", "APPR", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Da\u00df ewre P\u00f6sy der meinen Mutter sey.", "tokens": ["Da\u00df", "ew\u00b7re", "P\u00f6\u00b7sy", "der", "mei\u00b7nen", "Mut\u00b7ter", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ART", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}}}}