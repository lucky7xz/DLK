{"textgrid.poem.55942": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Menschlichkeit: Namen schwankender Besitze,", "tokens": ["Menschlich\u00b7keit", ":", "Na\u00b7men", "schwan\u00b7ken\u00b7der", "Be\u00b7sit\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "noch unbest\u00e4tigter Bestand von Gl\u00fcck:", "tokens": ["noch", "un\u00b7be\u00b7st\u00e4\u00b7tig\u00b7ter", "Be\u00b7stand", "von", "Gl\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ist das unmenschlich, da\u00df zu dieser Spitze,", "tokens": ["ist", "das", "un\u00b7menschlich", ",", "da\u00df", "zu", "die\u00b7ser", "Spit\u00b7ze", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJD", "$,", "KOUS", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "zu diesem kleinen dichten Spitzenst\u00fcck", "tokens": ["zu", "die\u00b7sem", "klei\u00b7nen", "dich\u00b7ten", "Spit\u00b7zen\u00b7st\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "zwei Augen wurden? \u2013 Willst du sie zur\u00fcck?", "tokens": ["zwei", "Au\u00b7gen", "wur\u00b7den", "?", "\u2013", "Willst", "du", "sie", "zu\u00b7r\u00fcck", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "$.", "$(", "VMFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Du Langvergangene und schlie\u00dflich Blinde,", "tokens": ["Du", "Lang\u00b7ver\u00b7gan\u00b7ge\u00b7ne", "und", "schlie\u00df\u00b7lich", "Blin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ist deine Seligkeit in diesem Ding,", "tokens": ["ist", "dei\u00b7ne", "Se\u00b7lig\u00b7keit", "in", "die\u00b7sem", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zu welcher hin, wie zwischen Stamm und Rinde,", "tokens": ["zu", "wel\u00b7cher", "hin", ",", "wie", "zwi\u00b7schen", "Stamm", "und", "Rin\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "$,", "PWAV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dein gro\u00dfes F\u00fchlen, kleinverwandelt, ging?", "tokens": ["dein", "gro\u00b7\u00dfes", "F\u00fch\u00b7len", ",", "klein\u00b7ver\u00b7wan\u00b7delt", ",", "ging", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Durch einen Ri\u00df im Schicksal, eine L\u00fccke", "tokens": ["Durch", "ei\u00b7nen", "Ri\u00df", "im", "Schick\u00b7sal", ",", "ei\u00b7ne", "L\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "entzogst du deine Seele deiner Zeit;", "tokens": ["ent\u00b7zogst", "du", "dei\u00b7ne", "See\u00b7le", "dei\u00b7ner", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und sie ist so in diesem lichten St\u00fccke,", "tokens": ["und", "sie", "ist", "so", "in", "die\u00b7sem", "lich\u00b7ten", "St\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "da\u00df es mich l\u00e4cheln macht vor N\u00fctzlichkeit.", "tokens": ["da\u00df", "es", "mich", "l\u00e4\u00b7cheln", "macht", "vor", "N\u00fctz\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}