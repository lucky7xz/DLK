{"textgrid.poem.53884": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Das Ideal", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eine Villa im Gr\u00fcnen mit gro\u00dfer Terrasse,", "tokens": ["Ei\u00b7ne", "Vil\u00b7la", "im", "Gr\u00fc\u00b7nen", "mit", "gro\u00b7\u00dfer", "Ter\u00b7ras\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+--+-+--", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "vorn die Ostsee, hinten die Friedrichstra\u00dfe;", "tokens": ["vorn", "die", "Ost\u00b7see", ",", "hin\u00b7ten", "die", "Fried\u00b7rich\u00b7stra\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "mit sch\u00f6ner Aussicht, l\u00e4ndlich-mond\u00e4n,", "tokens": ["mit", "sch\u00f6\u00b7ner", "Aus\u00b7sicht", ",", "l\u00e4nd\u00b7lich\u00b7mon\u00b7d\u00e4n", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "vom Badezimmer ist die Zugspitze zu sehn \u2013", "tokens": ["vom", "Ba\u00b7de\u00b7zim\u00b7mer", "ist", "die", "Zug\u00b7spit\u00b7ze", "zu", "sehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "aber abends zum Kino hast dus nicht weit.", "tokens": ["a\u00b7ber", "a\u00b7bends", "zum", "Ki\u00b7no", "hast", "dus", "nicht", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPRART", "NN", "VAFIN", "NE", "PTKNEG", "ADJD", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Das Ganze schlicht, voller Bescheidenheit:", "tokens": ["Das", "Gan\u00b7ze", "schlicht", ",", "vol\u00b7ler", "Be\u00b7schei\u00b7den\u00b7heit", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Neun Zimmer, \u2013 nein, doch lieber zehn!", "tokens": ["Neun", "Zim\u00b7mer", ",", "\u2013", "nein", ",", "doch", "lie\u00b7ber", "zehn", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "$(", "PTKANT", "$,", "ADV", "ADV", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Dachgarten, wo die Eichen drauf stehn,", "tokens": ["Ein", "Dach\u00b7gar\u00b7ten", ",", "wo", "die", "Ei\u00b7chen", "drauf", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Radio, Zentralheizung, Vakuum,", "tokens": ["Ra\u00b7dio", ",", "Zent\u00b7ral\u00b7hei\u00b7zung", ",", "Va\u00b7ku\u00b7um", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "eine Dienerschaft, gut gezogen und stumm,", "tokens": ["ei\u00b7ne", "Die\u00b7ner\u00b7schaft", ",", "gut", "ge\u00b7zo\u00b7gen", "und", "stumm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "VVPP", "KON", "ADJD", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "eine s\u00fc\u00dfe Frau voller Rasse und Verve \u2013", "tokens": ["ei\u00b7ne", "s\u00fc\u00b7\u00dfe", "Frau", "vol\u00b7ler", "Ras\u00b7se", "und", "Ver\u00b7ve", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "KON", "NN", "$("], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "(und eine f\u00fcrs Wochenend, zur Reserve) \u2013,", "tokens": ["(", "und", "ei\u00b7ne", "f\u00fcrs", "Wo\u00b7che\u00b7nend", ",", "zur", "Re\u00b7ser\u00b7ve", ")", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "KON", "ART", "ADJA", "NN", "$,", "APPRART", "NN", "$(", "$(", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "eine Bibliothek und drumherum", "tokens": ["ei\u00b7ne", "Bib\u00b7lio\u00b7thek", "und", "drum\u00b7he\u00b7rum"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PAV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Einsamkeit und Hummelgesumm.", "tokens": ["Ein\u00b7sam\u00b7keit", "und", "Hum\u00b7mel\u00b7ge\u00b7summ", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Im Stall: Zwei Ponies, vier Vollbluthengste,", "tokens": ["Im", "Stall", ":", "Zwei", "Po\u00b7nies", ",", "vier", "Voll\u00b7blu\u00b7thengs\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "CARD", "NN", "$,", "CARD", "NN", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "acht Autos, Motorrad \u2013 alles lenkste", "tokens": ["acht", "Au\u00b7tos", ",", "Mo\u00b7tor\u00b7rad", "\u2013", "al\u00b7les", "lenks\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "NN", "$(", "PIS", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "nat\u00fcrlich selber \u2013 das w\u00e4r ja gelacht!", "tokens": ["na\u00b7t\u00fcr\u00b7lich", "sel\u00b7ber", "\u2013", "das", "w\u00e4r", "ja", "ge\u00b7lacht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "PDS", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und zwischendurch gehst du auf Hochwildjagd.", "tokens": ["Und", "zwi\u00b7schen\u00b7durch", "gehst", "du", "auf", "Hoch\u00b7wild\u00b7jagd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Ja, und das hab ich ganz vergessen:", "tokens": ["Ja", ",", "und", "das", "hab", "ich", "ganz", "ver\u00b7ges\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KON", "PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Prima K\u00fcche \u2013 erstes Essen \u2013", "tokens": ["Pri\u00b7ma", "K\u00fc\u00b7che", "\u2013", "ers\u00b7tes", "Es\u00b7sen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "alte Weine aus sch\u00f6nem Pokal \u2013", "tokens": ["al\u00b7te", "Wei\u00b7ne", "aus", "sch\u00f6\u00b7nem", "Po\u00b7kal", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "und egalweg bleibst du d\u00fcnn wie ein Aal.", "tokens": ["und", "e\u00b7gal\u00b7weg", "bleibst", "du", "d\u00fcnn", "wie", "ein", "Aal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und Geld. Und an Schmuck eine richtige Portion.", "tokens": ["Und", "Geld", ".", "Und", "an", "Schmuck", "ei\u00b7ne", "rich\u00b7ti\u00b7ge", "Por\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "KON", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.6": {"text": "Und noch ne Million und noch ne Million.", "tokens": ["Und", "noch", "ne", "Mil\u00b7li\u00b7on", "und", "noch", "ne", "Mil\u00b7li\u00b7on", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Reisen. Und fr\u00f6hliche Lebensbuntheit.", "tokens": ["Und", "Rei\u00b7sen", ".", "Und", "fr\u00f6h\u00b7li\u00b7che", "Le\u00b7bens\u00b7bunt\u00b7heit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "KON", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Und famose Kinder. Und ewige Gesundheit.", "tokens": ["Und", "fa\u00b7mo\u00b7se", "Kin\u00b7der", ".", "Und", "e\u00b7wi\u00b7ge", "Ge\u00b7sund\u00b7heit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "KON", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Aber, wie das so ist hienieden:", "tokens": ["A\u00b7ber", ",", "wie", "das", "so", "ist", "hien\u00b7ie\u00b7den", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PDS", "ADV", "VAFIN", "ADV", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "manchmal scheints so, als sei es beschieden", "tokens": ["manch\u00b7mal", "scheints", "so", ",", "als", "sei", "es", "be\u00b7schie\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "VVINF"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "nur p\u00f6ap\u00f6, das irdische Gl\u00fcck.", "tokens": ["nur", "p\u00f6a\u00b7p\u00f6", ",", "das", "ir\u00b7di\u00b7sche", "Gl\u00fcck", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Immer fehlt dir irgendein St\u00fcck.", "tokens": ["Im\u00b7mer", "fehlt", "dir", "ir\u00b7gend\u00b7ein", "St\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Hast du Geld, dann hast du nicht K\u00e4ten;", "tokens": ["Hast", "du", "Geld", ",", "dann", "hast", "du", "nicht", "K\u00e4\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "hast du die Frau, dann fehln dir Moneten \u2013", "tokens": ["hast", "du", "die", "Frau", ",", "dann", "fehln", "dir", "Mo\u00b7ne\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "NN", "$("], "meter": "+--+-+-+--", "measure": "iambic.tetra.invert"}, "line.7": {"text": "hast du die Geisha, dann st\u00f6rt dich der F\u00e4cher:", "tokens": ["hast", "du", "die", "Geis\u00b7ha", ",", "dann", "st\u00f6rt", "dich", "der", "F\u00e4\u00b7cher", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.8": {"text": "bald fehlt uns der Wein, bald fehlt uns der Becher.", "tokens": ["bald", "fehlt", "uns", "der", "Wein", ",", "bald", "fehlt", "uns", "der", "Be\u00b7cher", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Etwas ist immer.", "tokens": ["Et\u00b7was", "ist", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$."], "meter": "+-++-", "measure": "unknown.measure.tri"}}, "stanza.8": {"line.1": {"text": "Jedes Gl\u00fcck hat einen kleinen Stich.", "tokens": ["Je\u00b7des", "Gl\u00fcck", "hat", "ei\u00b7nen", "klei\u00b7nen", "Stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wir m\u00f6chten so viel: Haben. Sein. Und gelten.", "tokens": ["Wir", "m\u00f6ch\u00b7ten", "so", "viel", ":", "Ha\u00b7ben", ".", "Sein", ".", "Und", "gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "$.", "VAFIN", "$.", "PPOSAT", "$.", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df einer alles hat:", "tokens": ["Da\u00df", "ei\u00b7ner", "al\u00b7les", "hat", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIS", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "das ist selten.", "tokens": ["das", "ist", "sel\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "$."], "meter": "--+-", "measure": "anapaest.init"}}}}}