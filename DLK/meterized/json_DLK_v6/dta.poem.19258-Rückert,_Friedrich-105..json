{"dta.poem.19258": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "105.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1837", "urn": "urn:nbn:de:kobv:b4-200905195090", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nicht von der Sprache will ich sprechen, noch vom Licht", "tokens": ["Nicht", "von", "der", "Spra\u00b7che", "will", "ich", "spre\u00b7chen", ",", "noch", "vom", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Himmels, welches aus des Menschen Auge spricht;", "tokens": ["Des", "Him\u00b7mels", ",", "wel\u00b7ches", "aus", "des", "Men\u00b7schen", "Au\u00b7ge", "spricht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Noch will ich sprechen von der sprechenden Geberde,", "tokens": ["Noch", "will", "ich", "spre\u00b7chen", "von", "der", "spre\u00b7chen\u00b7den", "Ge\u00b7ber\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der herrschenden, die sich wei\u00df unterthan die Erde;", "tokens": ["Der", "herr\u00b7schen\u00b7den", ",", "die", "sich", "wei\u00df", "un\u00b7ter\u00b7than", "die", "Er\u00b7de", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PRF", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Bezeichnen will ich dir vier kleinre Menschheitszeichen,", "tokens": ["Be\u00b7zeich\u00b7nen", "will", "ich", "dir", "vier", "klein\u00b7re", "Menschheits\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PPER", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "L\u00e4cheln und Weinen nur, Err\u00f6then und Erbleichen.", "tokens": ["L\u00e4\u00b7cheln", "und", "Wei\u00b7nen", "nur", ",", "Er\u00b7r\u00f6\u00b7then", "und", "Er\u00b7blei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "$,", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.4": {"line.1": {"text": "Ein fl\u00fccht'ger Sonnenblick, ein Thau aus Wolken spr\u00fchend,", "tokens": ["Ein", "fl\u00fccht'\u00b7ger", "Son\u00b7nen\u00b7blick", ",", "ein", "Thau", "aus", "Wol\u00b7ken", "spr\u00fc\u00b7hend", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein leises Morgenroth anglimmend und verbl\u00fchend.", "tokens": ["Ein", "lei\u00b7ses", "Mor\u00b7gen\u00b7roth", "an\u00b7glim\u00b7mend", "und", "ver\u00b7bl\u00fc\u00b7hend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Von Farben der Natur an Erd' und Himmelsflur", "tokens": ["Von", "Far\u00b7ben", "der", "Na\u00b7tur", "an", "Erd'", "und", "Him\u00b7mels\u00b7flur"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verblieb im Angesicht des Menschen nur die Spur.", "tokens": ["Ver\u00b7blieb", "im", "An\u00b7ge\u00b7sicht", "des", "Men\u00b7schen", "nur", "die", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Farben selber sind der niedern Welt gew\u00e4hrt,", "tokens": ["Die", "Far\u00b7ben", "sel\u00b7ber", "sind", "der", "nie\u00b7dern", "Welt", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In seinem Angesicht sind sie zu Duft verkl\u00e4rt.", "tokens": ["In", "sei\u00b7nem", "An\u00b7ge\u00b7sicht", "sind", "sie", "zu", "Duft", "ver\u00b7kl\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der Himmel selber hat ihm aufgedr\u00fcckt die Zeichen,", "tokens": ["Der", "Him\u00b7mel", "sel\u00b7ber", "hat", "ihm", "auf\u00b7ge\u00b7dr\u00fcckt", "die", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "L\u00e4cheln und Weinen und Err\u00f6then und Erbleichen.", "tokens": ["L\u00e4\u00b7cheln", "und", "Wei\u00b7nen", "und", "Er\u00b7r\u00f6\u00b7then", "und", "Er\u00b7blei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.8": {"line.1": {"text": "Drum stehen diese vier nicht in des Menschen Macht;", "tokens": ["Drum", "ste\u00b7hen", "die\u00b7se", "vier", "nicht", "in", "des", "Men\u00b7schen", "Macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PDAT", "CARD", "PTKNEG", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein rechter Mensch ist, wer weint wenn er will und lacht.", "tokens": ["Kein", "rech\u00b7ter", "Mensch", "ist", ",", "wer", "weint", "wenn", "er", "will", "und", "lacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "$,", "PWS", "VVFIN", "KOUS", "PPER", "VMFIN", "KON", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Und wer nicht, weil er will, erbleicht mehr und err\u00f6thet,", "tokens": ["Und", "wer", "nicht", ",", "weil", "er", "will", ",", "er\u00b7bleicht", "mehr", "und", "er\u00b7r\u00f6t\u00b7het", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "$,", "KOUS", "PPER", "VMFIN", "$,", "VVFIN", "ADV", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der hat die Menschlichkeit mit Meuchelkunst get\u00f6dtet;", "tokens": ["Der", "hat", "die", "Menschlich\u00b7keit", "mit", "Meu\u00b7chel\u00b7kunst", "ge\u00b7t\u00f6d\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Der hat zerrissen selbst mit th\u00f6richtem Verrath", "tokens": ["Der", "hat", "zer\u00b7ris\u00b7sen", "selbst", "mit", "th\u00f6\u00b7rich\u00b7tem", "Ver\u00b7rath"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVPP", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sein adliches Diplom, ein schlechter Diplomat.", "tokens": ["Sein", "ad\u00b7li\u00b7ches", "Dip\u00b7lom", ",", "ein", "schlech\u00b7ter", "Dip\u00b7lo\u00b7mat", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}}, "stanza.11": {"line.1": {"text": "Hei\u00df' er ein Weiser nur, beherrschend die Natur,", "tokens": ["Hei\u00df'", "er", "ein", "Wei\u00b7ser", "nur", ",", "be\u00b7herr\u00b7schend", "die", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "ADV", "$,", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich und die Welt, er ist ein gro\u00dfer Affe nur;", "tokens": ["Sich", "und", "die", "Welt", ",", "er", "ist", "ein", "gro\u00b7\u00dfer", "Af\u00b7fe", "nur", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KON", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Statt l\u00e4cheln grinsen kann der Aff, statt weinen heulen,", "tokens": ["Statt", "l\u00e4\u00b7cheln", "grin\u00b7sen", "kann", "der", "Aff", ",", "statt", "wei\u00b7nen", "heu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VVINF", "VMFIN", "ART", "NN", "$,", "KOUI", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zeigt statt Erbleichen und Err\u00f6then farbige Beulen.", "tokens": ["Zeigt", "statt", "Er\u00b7blei\u00b7chen", "und", "Er\u00b7r\u00f6\u00b7then", "far\u00b7bi\u00b7ge", "Beu\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}}}}