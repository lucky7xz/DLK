{"dta.poem.12404": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Das Wiedersehen am Brunnen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es war einmal ein junger Knab,               ", "tokens": ["Es", "war", "ein\u00b7mal", "ein", "jun\u00b7ger", "Knab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der hat gefreit schon sieben Jahr", "tokens": ["Der", "hat", "ge\u00b7freit", "schon", "sie\u00b7ben", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NN", "ADV", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ein fein M\u00e4dlein, das ist wahr,", "tokens": ["Um", "ein", "fein", "M\u00e4d\u00b7lein", ",", "das", "ist", "wahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJD", "NN", "$,", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er konnt sie nicht erfreien.", "tokens": ["Er", "konnt", "sie", "nicht", "er\u00b7frei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "\u201eey komm den Abend junger Knab,", "tokens": ["\u201e", "ey", "komm", "den", "A\u00b7bend", "jun\u00b7ger", "Knab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ewenn finstre Nacht und Regen ist,", "tokens": ["\u201e", "wenn", "finst\u00b7re", "Nacht", "und", "Re\u00b7gen", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "ADJA", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ewenn niemand auf der Gasse ist,", "tokens": ["\u201e", "wenn", "nie\u00b7mand", "auf", "der", "Gas\u00b7se", "ist", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eherein will ich dich lassen.\u201c", "tokens": ["\u201e", "her\u00b7ein", "will", "ich", "dich", "las\u00b7sen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKVZ", "VMFIN", "PPER", "PRF", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der Tag verging, der Abend kam,", "tokens": ["Der", "Tag", "ver\u00b7ging", ",", "der", "A\u00b7bend", "kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der junge Knab geschlichen kam,", "tokens": ["Der", "jun\u00b7ge", "Knab", "ge\u00b7schli\u00b7chen", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er klopfet leise an die Th\u00fcr:", "tokens": ["Er", "klop\u00b7fet", "lei\u00b7se", "an", "die", "Th\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201esteh auf, ich bin daf\u00fcre.", "tokens": ["\u201e", "steh", "auf", ",", "ich", "bin", "da\u00b7f\u00fc\u00b7re", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "PPER", "VAFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201eich hab schon lang gestanden hier,", "tokens": ["\u201e", "ich", "hab", "schon", "lang", "ge\u00b7stan\u00b7den", "hier", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eich stand allhier wohl sieben Jahr.\u201c", "tokens": ["\u201e", "ich", "stand", "all\u00b7hier", "wohl", "sie\u00b7ben", "Jahr", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADV", "CARD", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ehast lang gestanden, das ist nicht wahr,", "tokens": ["\u201e", "hast", "lang", "ge\u00b7stan\u00b7den", ",", "das", "ist", "nicht", "wahr", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "VVPP", "$,", "PDS", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201eich hab noch nicht geschlafen.", "tokens": ["\u201e", "ich", "hab", "noch", "nicht", "ge\u00b7schla\u00b7fen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u201eich hab gelegn und hab gedacht,", "tokens": ["\u201e", "ich", "hab", "ge\u00b7legn", "und", "hab", "ge\u00b7dacht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVPP", "KON", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ewo nur mein Schatz noch bleiben mag,", "tokens": ["\u201e", "wo", "nur", "mein", "Schatz", "noch", "blei\u00b7ben", "mag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "PPOSAT", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eer macht mir allzulang, zu lang,", "tokens": ["\u201e", "er", "macht", "mir", "all\u00b7zu\u00b7lang", ",", "zu", "lang", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADJD", "$,", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201emir wird ganz angst und bange.\u201c", "tokens": ["\u201e", "mir", "wird", "ganz", "angst", "und", "ban\u00b7ge", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u201ewo ich so lang geblieben bin,", "tokens": ["\u201e", "wo", "ich", "so", "lang", "ge\u00b7blie\u00b7ben", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edas darf dir wohl gesaget seyn,", "tokens": ["\u201e", "das", "darf", "dir", "wohl", "ge\u00b7sa\u00b7get", "seyn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201ebey Bier und Wein, wo Jungfern seyn,", "tokens": ["\u201e", "bey", "Bier", "und", "Wein", ",", "wo", "Jung\u00b7fern", "seyn", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "KON", "NN", "$,", "PWAV", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eda bin ich allzeit gerne.\u201c", "tokens": ["\u201e", "da", "bin", "ich", "all\u00b7zeit", "ger\u00b7ne", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Es war wohl um die Mitternacht,", "tokens": ["Es", "war", "wohl", "um", "die", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der W\u00e4chter fing zu l\u00e4uten an:", "tokens": ["Der", "W\u00e4ch\u00b7ter", "fing", "zu", "l\u00e4u\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PTKZU", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201esteh auf, wer bey Feinsliebchen liegt,", "tokens": ["\u201e", "steh", "auf", ",", "wer", "bey", "Feins\u00b7lieb\u00b7chen", "liegt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "PWS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eder Tag kommt angeschlichen.\u201c", "tokens": ["\u201e", "der", "Tag", "kommt", "an\u00b7ge\u00b7schli\u00b7chen", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Das B\u00fcrschlein auf die Leiter sprang,", "tokens": ["Das", "B\u00fcr\u00b7schlein", "auf", "die", "Lei\u00b7ter", "sprang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schaut die Stern am Himmel dicht:", "tokens": ["Und", "schaut", "die", "Stern", "am", "Him\u00b7mel", "dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eich scheide nicht bis Tag anbricht,", "tokens": ["\u201e", "ich", "schei\u00b7de", "nicht", "bis", "Tag", "an\u00b7bricht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201ebis alle Sterne schwanden.\u201c", "tokens": ["\u201e", "bis", "al\u00b7le", "Ster\u00b7ne", "schwan\u00b7den", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PIAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Er sah das Morgensternlein nur,", "tokens": ["Er", "sah", "das", "Mor\u00b7gens\u00b7tern\u00b7lein", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als sich der Knab von ihr gewandt,", "tokens": ["Als", "sich", "der", "Knab", "von", "ihr", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das M\u00e4gdlein Morgens fr\u00fch aufstand,", "tokens": ["Das", "M\u00e4gd\u00b7lein", "Mor\u00b7gens", "fr\u00fch", "auf\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ging an den k\u00fchlen Brunnen.", "tokens": ["Ging", "an", "den", "k\u00fch\u00b7len", "Brun\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Begegnet ihr derselbig Knab,", "tokens": ["Be\u00b7geg\u00b7net", "ihr", "der\u00b7sel\u00b7big", "Knab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Nachts bey ihr geschlafen hat,", "tokens": ["Der", "Nachts", "bey", "ihr", "ge\u00b7schla\u00b7fen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel guten Morgen boten hat:", "tokens": ["Viel", "gu\u00b7ten", "Mor\u00b7gen", "bo\u00b7ten", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201egut Morgen mein Feinsliebchen.", "tokens": ["\u201e", "gut", "Mor\u00b7gen", "mein", "Feins\u00b7lieb\u00b7chen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201ewie hast geschlafen heute Nacht?\u201c", "tokens": ["\u201e", "wie", "hast", "ge\u00b7schla\u00b7fen", "heu\u00b7te", "Nacht", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VAFIN", "VVPP", "ADV", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eich hab gelegn in Liebchens Arm!", "tokens": ["\u201e", "ich", "hab", "ge\u00b7legn", "in", "Lieb\u00b7chens", "Arm", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eich hab geschlafen, da\u00df Gott erbarm,", "tokens": ["\u201e", "ich", "hab", "ge\u00b7schla\u00b7fen", ",", "da\u00df", "Gott", "er\u00b7barm", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VVPP", "$,", "KOUS", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "\u201emein Ehr hab ich verschlafen!\u201c", "tokens": ["\u201e", "mein", "Ehr", "hab", "ich", "ver\u00b7schla\u00b7fen", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}