{"dta.poem.9794": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Uber Sr. Churfl. Durchl. zu Brandenburg  \n Friedrich des Dritten  \n Erfreulichsten geburts-tag/  \n den 1 Julii 1692.  \n \u2020 \u2020 \u2020", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jndem wir bey der schweren zeit", "tokens": ["In\u00b7dem", "wir", "bey", "der", "schwe\u00b7ren", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das hertz mit vielen sorgen kr\u00e4ncken/", "tokens": ["Das", "hertz", "mit", "vie\u00b7len", "sor\u00b7gen", "kr\u00e4n\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Antwortet uns der himmel heut/", "tokens": ["Ant\u00b7wor\u00b7tet", "uns", "der", "him\u00b7mel", "heut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und spricht: Was kan ich euch mehr schencken?", "tokens": ["Und", "spricht", ":", "Was", "kan", "ich", "euch", "mehr", "schen\u00b7cken", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PWS", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Erhalt ich euren Friedrich nicht?", "tokens": ["Er\u00b7halt", "ich", "eu\u00b7ren", "Fried\u00b7rich", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den ich auch ferner will bewachen/", "tokens": ["Den", "ich", "auch", "fer\u00b7ner", "will", "be\u00b7wa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und dessen tugend euch verspricht/", "tokens": ["Und", "des\u00b7sen", "tu\u00b7gend", "euch", "ver\u00b7spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Euch allerseits begl\u00fcckt zu machen.", "tokens": ["Euch", "al\u00b7ler\u00b7seits", "be\u00b7gl\u00fcckt", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zwar hat mans bey dem tr\u00fcben blick", "tokens": ["Zwar", "hat", "mans", "bey", "dem", "tr\u00fc\u00b7ben", "blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des krieges noch nicht recht empfunden;", "tokens": ["Des", "krie\u00b7ges", "noch", "nicht", "recht", "emp\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch bindet sich auch unser gl\u00fcck", "tokens": ["Doch", "bin\u00b7det", "sich", "auch", "un\u00b7ser", "gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An keine selbst-gesetzte stunden.", "tokens": ["An", "kei\u00b7ne", "selbst\u00b7ge\u00b7setz\u00b7te", "stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was uns von dir/ mein F\u00fcrst/ bewust/", "tokens": ["Was", "uns", "von", "dir", "/", "mein", "F\u00fcrst", "/", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "$(", "PPOSAT", "NN", "$(", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hei\u00dft uns die sichre hoffnung fassen/", "tokens": ["Hei\u00dft", "uns", "die", "sich\u00b7re", "hoff\u00b7nung", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df du uns gl\u00fccklich machen must/", "tokens": ["Da\u00df", "du", "uns", "gl\u00fcck\u00b7lich", "ma\u00b7chen", "must", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wird dir nur zeit genug gelassen.", "tokens": ["Wird", "dir", "nur", "zeit", "ge\u00b7nug", "ge\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So mu\u00df bey deines festes schein/", "tokens": ["So", "mu\u00df", "bey", "dei\u00b7nes", "fes\u00b7tes", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wohlfahrt \u00fcber uns zu sch\u00fctten/", "tokens": ["Die", "wohl\u00b7fahrt", "\u00fc\u00b7ber", "uns", "zu", "sch\u00fct\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dis einzig unsre sorge seyn/", "tokens": ["Dis", "ein\u00b7zig", "uns\u00b7re", "sor\u00b7ge", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "PPOSAT", "NN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dir zeit und jahre zu erbitten.", "tokens": ["Dir", "zeit", "und", "jah\u00b7re", "zu", "er\u00b7bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der himmel/ der dir gn\u00e4dig ist/", "tokens": ["Der", "him\u00b7mel", "/", "der", "dir", "gn\u00e4\u00b7dig", "ist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verleih\u2019 uns nur dein langes leben!", "tokens": ["Ver\u00b7leih'", "uns", "nur", "dein", "lan\u00b7ges", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das \u00fcbrige wird durch die frist", "tokens": ["Das", "\u00fcb\u00b7ri\u00b7ge", "wird", "durch", "die", "frist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Uns dann schon deine tugend geben.", "tokens": ["Uns", "dann", "schon", "dei\u00b7ne", "tu\u00b7gend", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}