{"textgrid.poem.24550": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Als einer von See-Schaden disputirte/ und die Doctor-W\u00fcrde erlangte/ in Nahmen anderer", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hoch-wehrtgesch\u00e4tzter Freund/ der seines Flei\u00dfes Proben", "tokens": ["Hoch\u00b7wehrt\u00b7ge\u00b7sch\u00e4tz\u00b7ter", "Freund", "/", "der", "sei\u00b7nes", "Flei\u00b7\u00dfes", "Pro\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$(", "ART", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf diesem Saal-", "tokens": ["Auf", "die\u00b7sem", "Saa\u00b7l"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "TRUNC"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Wir suchen nicht hierdurch dein edles Thun zu loben/", "tokens": ["Wir", "su\u00b7chen", "nicht", "hier\u00b7durch", "dein", "ed\u00b7les", "Thun", "zu", "lo\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PAV", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie du dein ", "tokens": ["Und", "wie", "du", "dein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "PPOSAT"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Wir dencken nicht so wohl/ die Tugend raus zu streichen/", "tokens": ["Wir", "den\u00b7cken", "nicht", "so", "wohl", "/", "die", "Tu\u00b7gend", "raus", "zu", "strei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "$(", "ART", "NN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als dir aus Freudigkeit/ wie Freunde darzuthun/", "tokens": ["Als", "dir", "aus", "Freu\u00b7dig\u00b7keit", "/", "wie", "Freun\u00b7de", "dar\u00b7zu\u00b7thun", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$(", "KOKOM", "NN", "VVIZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie sehr es uns ergetzt/ da\u00df bey so edlen Zeichen/", "tokens": ["Wie", "sehr", "es", "uns", "er\u00b7getzt", "/", "da\u00df", "bey", "so", "ed\u00b7len", "Zei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "VVPP", "$(", "KOUS", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bey solcher Wissenschafft/ du dennoch nicht wilst ruhn.", "tokens": ["Bey", "sol\u00b7cher", "Wis\u00b7sen\u00b7schafft", "/", "du", "den\u00b7noch", "nicht", "wilst", "ruhn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$(", "PPER", "ADV", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df du den Schiffern gleich/ die einst die See durchfahren/", "tokens": ["Da\u00df", "du", "den", "Schif\u00b7fern", "gleich", "/", "die", "einst", "die", "See", "durch\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "$(", "ART", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zum neuen Lauffe schon die Seegel hast gespannt/", "tokens": ["Zum", "neu\u00b7en", "Lauf\u00b7fe", "schon", "die", "See\u00b7gel", "hast", "ge\u00b7spannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und da\u00df/ wenn sich in dir schon viele K\u00fcnste paaren/", "tokens": ["Und", "da\u00df", "/", "wenn", "sich", "in", "dir", "schon", "vie\u00b7le", "K\u00fcns\u00b7te", "paa\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$(", "KOUS", "PRF", "APPR", "PPER", "ADV", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dennoch zu mehren sey dein muntrer Geist entbrandt.", "tokens": ["Den\u00b7noch", "zu", "meh\u00b7ren", "sey", "dein", "mun\u00b7trer", "Geist", "ent\u00b7brandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "VAFIN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das Meer der Wissenschafft hat mancher kaum erblicket/", "tokens": ["Das", "Meer", "der", "Wis\u00b7sen\u00b7schafft", "hat", "man\u00b7cher", "kaum", "er\u00b7bli\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PIAT", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Kaum hat er eine Fahrt/ die kurtz genug/ gethan/", "tokens": ["Kaum", "hat", "er", "ei\u00b7ne", "Fahrt", "/", "die", "kurtz", "ge\u00b7nug", "/", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$(", "ART", "ADJD", "ADV", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So wird ihm der ", "tokens": ["So", "wird", "ihm", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART"], "meter": "-+--", "measure": "dactylic.init"}, "line.16": {"text": "Denn landet er geschwind faulen Br\u00fcdern an.", "tokens": ["Denn", "lan\u00b7det", "er", "ge\u00b7schwind", "fau\u00b7len", "Br\u00fc\u00b7dern", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Auf der Gelehrten See hei\u00dft dieses Schiffbruch leiden;", "tokens": ["Auf", "der", "Ge\u00b7lehr\u00b7ten", "See", "hei\u00dft", "die\u00b7ses", "Schiff\u00b7bruch", "lei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den untersuchest du/ und fliehest ihn zugleich.", "tokens": ["Den", "un\u00b7ter\u00b7su\u00b7chest", "du", "/", "und", "flie\u00b7hest", "ihn", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$(", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ein Edler wird mit dir die faule Sand-Banck meiden/", "tokens": ["Ein", "Ed\u00b7ler", "wird", "mit", "dir", "die", "fau\u00b7le", "San\u00b7dBanck", "mei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Er greift das Ruder an/ die Schiffarth macht ihn reich.", "tokens": ["Er", "greift", "das", "Ru\u00b7der", "an", "/", "die", "Schiff\u00b7arth", "macht", "ihn", "reich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Dem mu\u00df an Gut und Ehr das Strand-Recht alles rauben/", "tokens": ["Dem", "mu\u00df", "an", "Gut", "und", "Ehr", "das", "Stran\u00b7dRecht", "al\u00b7les", "rau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Der durch Begierden will sein eigner Sturm-Wind seyn.", "tokens": ["Der", "durch", "Be\u00b7gier\u00b7den", "will", "sein", "eig\u00b7ner", "Stur\u00b7mWind", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die den ", "tokens": ["Die", "den"], "token_info": ["word", "word"], "pos": ["ART", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.24": {"text": "Die sencken Gut und Blut selbst in Strudel ein.", "tokens": ["Die", "sen\u00b7cken", "Gut", "und", "Blut", "selbst", "in", "Stru\u00b7del", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.25": {"text": "Gewi\u00df die wilde See hat nicht so viele Klippen/", "tokens": ["Ge\u00b7wi\u00df", "die", "wil\u00b7de", "See", "hat", "nicht", "so", "vie\u00b7le", "Klip\u00b7pen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Als eine hohe Schul/ in der viel ", "tokens": ["Als", "ei\u00b7ne", "ho\u00b7he", "Schul", "/", "in", "der", "viel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "APPR", "ART", "PIAT"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.27": {"text": "Gesellschafft/ Spiel und Wein! und ihr verbuhlten Lippen/", "tokens": ["Ge\u00b7sell\u00b7schafft", "/", "Spiel", "und", "Wein", "!", "und", "ihr", "ver\u00b7buhl\u00b7ten", "Lip\u00b7pen", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "NN", "$.", "KON", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wer kennt und fliehet euch? ihr macht die meisten blind.", "tokens": ["Wer", "kennt", "und", "flie\u00b7het", "euch", "?", "ihr", "macht", "die", "meis\u00b7ten", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "ART", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Zwar pflegt ein Schiffer auch den Ancker einzusencken;", "tokens": ["Zwar", "pflegt", "ein", "Schif\u00b7fer", "auch", "den", "An\u00b7cker", "ein\u00b7zu\u00b7sen\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So ruhet manches mahl ein froher Musen Sohn;", "tokens": ["So", "ru\u00b7het", "man\u00b7ches", "mahl", "ein", "fro\u00b7her", "Mu\u00b7sen", "Sohn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Sein Geist ermuntert sich/ wer will es ihm verdencken?", "tokens": ["Sein", "Geist", "er\u00b7mun\u00b7tert", "sich", "/", "wer", "will", "es", "ihm", "ver\u00b7den\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "$(", "PWS", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Er tr\u00e4gt auf kleine Rast zweyfache Krafft davon.", "tokens": ["Er", "tr\u00e4gt", "auf", "klei\u00b7ne", "Rast", "zwey\u00b7fa\u00b7che", "Krafft", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Denn f\u00e4hret er/ wie Du/ Hochwehrter Freund gefahren/", "tokens": ["Denn", "f\u00e4h\u00b7ret", "er", "/", "wie", "Du", "/", "Hoch\u00b7wehr\u00b7ter", "Freund", "ge\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "PWAV", "PPER", "$(", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Sieht allen Sturm zur See mit Wei\u00dfheits Augen an.", "tokens": ["Sieht", "al\u00b7len", "Sturm", "zur", "See", "mit", "Wei\u00df\u00b7heits", "Au\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPRART", "NN", "APPR", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Urtheilt von Eigenthum der ausgeschmi\u00dfnen Wahren/", "tokens": ["Ur\u00b7theilt", "von", "Ei\u00b7gen\u00b7thum", "der", "aus\u00b7ge\u00b7schmi\u00df\u00b7nen", "Wah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "So standhafft/ und gelehrt/ wie Du anitzt gethan.", "tokens": ["So", "stand\u00b7hafft", "/", "und", "ge\u00b7lehrt", "/", "wie", "Du", "a\u00b7nitzt", "ge\u00b7than", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KON", "VVPP", "$(", "PWAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Wir freuen uns mit dir/ da\u00df die gelehrten Bl\u00e4tter/", "tokens": ["Wir", "freu\u00b7en", "uns", "mit", "dir", "/", "da\u00df", "die", "ge\u00b7lehr\u00b7ten", "Bl\u00e4t\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "$(", "KOUS", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Die Sturm und Ungl\u00fccks voll/ Du wohl durchsegelt hast/", "tokens": ["Die", "Sturm", "und", "Un\u00b7gl\u00fccks", "voll", "/", "Du", "wohl", "durch\u00b7se\u00b7gelt", "hast", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADJD", "$(", "PPER", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Dich gr\u00fc\u00df' auf dieser See hinfort beliebtes Wetter/", "tokens": ["Dich", "gr\u00fc\u00df'", "auf", "die\u00b7ser", "See", "hin\u00b7fort", "be\u00b7lieb\u00b7tes", "Wet\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Nach diesen aber auch Ehr- und Vergn\u00fcgungs Rast.", "tokens": ["Nach", "die\u00b7sen", "a\u00b7ber", "auch", "Ehr", "und", "Ver\u00b7gn\u00fc\u00b7gungs", "Rast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADV", "ADV", "TRUNC", "KON", "NN", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}}}}