{"textgrid.poem.52580": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Jaloux", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00e4tt ich Fl\u00fcgel, h\u00e4tt ich Waffen,", "tokens": ["H\u00e4tt", "ich", "Fl\u00fc\u00b7gel", ",", "h\u00e4tt", "ich", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wegzufliegen, oder keck,", "tokens": ["Weg\u00b7zu\u00b7flie\u00b7gen", ",", "o\u00b7der", "keck", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ich w\u00fcnsche, beizuschaffen,", "tokens": ["Was", "ich", "w\u00fcn\u00b7sche", ",", "bei\u00b7zu\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "O wir k\u00e4men bald vom Fleck \u2013", "tokens": ["O", "wir", "k\u00e4\u00b7men", "bald", "vom", "Fleck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "O wir k\u00e4men bald zum Zweck!", "tokens": ["O", "wir", "k\u00e4\u00b7men", "bald", "zum", "Zweck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Aber so nur zuzusehen,", "tokens": ["A\u00b7ber", "so", "nur", "zu\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00fcssen sehen, und vergehen", "tokens": ["M\u00fcs\u00b7sen", "se\u00b7hen", ",", "und", "ver\u00b7ge\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVINF", "$,", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So vor Wollen, Wuth und Wehen,", "tokens": ["So", "vor", "Wol\u00b7len", ",", "Wuth", "und", "We\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und im Zirkel nur sich drehn,", "tokens": ["Und", "im", "Zir\u00b7kel", "nur", "sich", "drehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "PRF", "VVINF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.5": {"text": "Wei\u00df der Teufel auszustehn!", "tokens": ["Wei\u00df", "der", "Teu\u00b7fel", "aus\u00b7zu\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "G\u00e4nzlich unzufrieden bin ich", "tokens": ["G\u00e4nz\u00b7lich", "un\u00b7zu\u00b7frie\u00b7den", "bin", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VAFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit mir wie ein lahmer Knecht,", "tokens": ["Mit", "mir", "wie", "ein", "lah\u00b7mer", "Knecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was wei\u00df ich, was beginn ich?", "tokens": ["Und", "was", "wei\u00df", "ich", ",", "was", "be\u00b7ginn", "ich", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab ich Unrecht, hab ich Recht?", "tokens": ["Hab", "ich", "Un\u00b7recht", ",", "hab", "ich", "Recht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrgen k\u00f6nnt ich mein Geschlecht!", "tokens": ["W\u00fcr\u00b7gen", "k\u00f6nnt", "ich", "mein", "Ge\u00b7schlecht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie die Reizende, die Reine,", "tokens": ["Sie", "die", "Rei\u00b7zen\u00b7de", ",", "die", "Rei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Die mir keinen Anla\u00df giebt,", "tokens": ["Die", "mir", "kei\u00b7nen", "An\u00b7la\u00df", "giebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich z\u00fcrne, da\u00df ich greine,", "tokens": ["Da\u00df", "ich", "z\u00fcr\u00b7ne", ",", "da\u00df", "ich", "grei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die ich liebe, die mich liebt,", "tokens": ["Die", "ich", "lie\u00b7be", ",", "die", "mich", "liebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hat mich so gekr\u00e4nkt betr\u00fcbt.", "tokens": ["Hat", "mich", "so", "ge\u00b7kr\u00e4nkt", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Donnert Wolken doch zusammen!", "tokens": ["Don\u00b7nert", "Wol\u00b7ken", "doch", "zu\u00b7sam\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ozeane \u00fcberschwellt!", "tokens": ["O\u00b7zea\u00b7ne", "\u00fc\u00b7bersc\u00b7hwellt", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Brechet aus, ihr Feuerflammen!", "tokens": ["Bre\u00b7chet", "aus", ",", "ihr", "Feu\u00b7er\u00b7flam\u00b7men", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Pra\u00dfle nieder, Himmelszelt!", "tokens": ["Pra\u00df\u00b7le", "nie\u00b7der", ",", "Him\u00b7mels\u00b7zelt", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Fahr in Asche, dumme Welt!", "tokens": ["Fahr", "in", "A\u00b7sche", ",", "dum\u00b7me", "Welt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}