{"textgrid.poem.34959": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "3.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nach der Schlacht bei Arabella", "tokens": ["Nach", "der", "Schlacht", "bei", "A\u00b7ra\u00b7bel\u00b7la"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Hat der gro\u00dfe Alexander", "tokens": ["Hat", "der", "gro\u00b7\u00dfe", "A\u00b7lex\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Land und Leute des Darius,", "tokens": ["Land", "und", "Leu\u00b7te", "des", "Da\u00b7ri\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ART", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Hof und Harem, Pferde, Weiber,", "tokens": ["Hof", "und", "Ha\u00b7rem", ",", "Pfer\u00b7de", ",", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "KON", "NE", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Elefanten und Dariken,", "tokens": ["E\u00b7lef\u00b7an\u00b7ten", "und", "Da\u00b7ri\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kron' und Zepter, goldnen Plunder,", "tokens": ["Kron'", "und", "Zep\u00b7ter", ",", "gold\u00b7nen", "Plun\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eingesteckt in seine weiten", "tokens": ["Ein\u00b7ge\u00b7steckt", "in", "sei\u00b7ne", "wei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mazedon'schen Pluderhosen.", "tokens": ["Ma\u00b7ze\u00b7don'\u00b7schen", "Plu\u00b7der\u00b7ho\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "In dem Zelt des gro\u00dfen K\u00f6nigs,", "tokens": ["In", "dem", "Zelt", "des", "gro\u00b7\u00dfen", "K\u00f6\u00b7nigs", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der entflohn, um nicht h\u00f6chstselbst", "tokens": ["Der", "ent\u00b7flohn", ",", "um", "nicht", "h\u00f6chst\u00b7selbst"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUI", "PTKNEG", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gleichfalls eingesteckt zu werden,", "tokens": ["Gleich\u00b7falls", "ein\u00b7ge\u00b7steckt", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fand der junge Held ein K\u00e4stchen,", "tokens": ["Fand", "der", "jun\u00b7ge", "Held", "ein", "K\u00e4st\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Eine kleine g\u00fcldne Truhe,", "tokens": ["Ei\u00b7ne", "klei\u00b7ne", "g\u00fcld\u00b7ne", "Tru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Miniaturbildwerken", "tokens": ["Mit", "Mi\u00b7ni\u00b7a\u00b7tur\u00b7bild\u00b7wer\u00b7ken"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit inkrustierten Steinen", "tokens": ["Und", "mit", "in\u00b7krus\u00b7tier\u00b7ten", "Stei\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und Kameen reich geschm\u00fcckt \u2013", "tokens": ["Und", "Ka\u00b7me\u00b7en", "reich", "ge\u00b7schm\u00fcckt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Dieses K\u00e4stchen, selbst ein Kleinod", "tokens": ["Die\u00b7ses", "K\u00e4st\u00b7chen", ",", "selbst", "ein", "Klei\u00b7nod"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "NN", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsch\u00e4tzbaren Wertes, diente", "tokens": ["Un\u00b7sch\u00e4tz\u00b7ba\u00b7ren", "Wer\u00b7tes", ",", "dien\u00b7te"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zur Bewahrung von Kleinodien,", "tokens": ["Zur", "Be\u00b7wah\u00b7rung", "von", "Klein\u00b7o\u00b7di\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NE", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Des Monarchen Leibjuwelen.", "tokens": ["Des", "Mon\u00b7ar\u00b7chen", "Leib\u00b7ju\u00b7we\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.6": {"line.1": {"text": "Letztre schenkte Alexander", "tokens": ["Letz\u00b7tre", "schenk\u00b7te", "A\u00b7lex\u00b7an\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An die Tapfern seines Heeres,", "tokens": ["An", "die", "Tap\u00b7fern", "sei\u00b7nes", "Hee\u00b7res", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Darob l\u00e4chelnd, da\u00df sich M\u00e4nner", "tokens": ["Da\u00b7rob", "l\u00e4\u00b7chelnd", ",", "da\u00df", "sich", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PRF", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kindisch freun an bunten Steinchen.", "tokens": ["Kin\u00b7disch", "freun", "an", "bun\u00b7ten", "Stein\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Eine kostbar sch\u00f6nste Gemme", "tokens": ["Ei\u00b7ne", "kost\u00b7bar", "sch\u00f6ns\u00b7te", "Gem\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schickte er der lieben Mutter;", "tokens": ["Schick\u00b7te", "er", "der", "lie\u00b7ben", "Mut\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War der Siegelring des Cyrus,", "tokens": ["War", "der", "Sie\u00b7gel\u00b7ring", "des", "Cy\u00b7rus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wurde jetzt zu einer Brosche.", "tokens": ["Wur\u00b7de", "jetzt", "zu", "ei\u00b7ner", "Bro\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Seinem alten Weltarschpauker", "tokens": ["Sei\u00b7nem", "al\u00b7ten", "Welt\u00b7ar\u00b7schpau\u00b7ker"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aristoteles, dem sandt er", "tokens": ["A\u00b7ris\u00b7to\u00b7te\u00b7les", ",", "dem", "sandt", "er"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Onyx f\u00fcr sein gro\u00dfes", "tokens": ["Ei\u00b7nen", "O\u00b7nyx", "f\u00fcr", "sein", "gro\u00b7\u00dfes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Naturalienkabinett.", "tokens": ["Na\u00b7tu\u00b7ra\u00b7li\u00b7en\u00b7ka\u00b7bi\u00b7nett", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "In dem K\u00e4stchen waren Perlen,", "tokens": ["In", "dem", "K\u00e4st\u00b7chen", "wa\u00b7ren", "Per\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine wunderbare Schnur,", "tokens": ["Ei\u00b7ne", "wun\u00b7der\u00b7ba\u00b7re", "Schnur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die der K\u00f6nigin Atossa", "tokens": ["Die", "der", "K\u00f6\u00b7ni\u00b7gin", "A\u00b7tos\u00b7sa"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einst geschenkt der falsche Smerdis \u2013", "tokens": ["Einst", "ge\u00b7schenkt", "der", "fal\u00b7sche", "Smer\u00b7dis", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Doch die Perlen waren echt \u2013", "tokens": ["Doch", "die", "Per\u00b7len", "wa\u00b7ren", "echt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der heitre Sieger gab sie", "tokens": ["Und", "der", "heit\u00b7re", "Sie\u00b7ger", "gab", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Einer sch\u00f6nen T\u00e4nzerin", "tokens": ["Ei\u00b7ner", "sch\u00f6\u00b7nen", "T\u00e4n\u00b7ze\u00b7rin"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus Korinth, mit Namen Thais.", "tokens": ["Aus", "Ko\u00b7rinth", ",", "mit", "Na\u00b7men", "Thais", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Diese trug sie in den Haaren,", "tokens": ["Die\u00b7se", "trug", "sie", "in", "den", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die bacchantisch aufgel\u00f6st,", "tokens": ["Die", "bac\u00b7chan\u00b7tisch", "auf\u00b7ge\u00b7l\u00f6st", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "In der Brandnacht, als sie tanzte", "tokens": ["In", "der", "Brand\u00b7nacht", ",", "als", "sie", "tanz\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu Persepolis und frech", "tokens": ["Zu", "Per\u00b7se\u00b7po\u00b7lis", "und", "frech"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "In die K\u00f6nigsburg geschleudert", "tokens": ["In", "die", "K\u00f6\u00b7nigs\u00b7burg", "ge\u00b7schleu\u00b7dert"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre Fackel, da\u00df laut prasselnd", "tokens": ["Ih\u00b7re", "Fa\u00b7ckel", ",", "da\u00df", "laut", "pras\u00b7selnd"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bald die Flammenlohe aufschlug,", "tokens": ["Bald", "die", "Flam\u00b7men\u00b7lo\u00b7he", "auf\u00b7schlug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Wie ein Feuerwerk zum Feste.", "tokens": ["Wie", "ein", "Feu\u00b7er\u00b7werk", "zum", "Fes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Nach dem Tod der sch\u00f6nen Thais,", "tokens": ["Nach", "dem", "Tod", "der", "sch\u00f6\u00b7nen", "Thais", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die an einer babylon'schen", "tokens": ["Die", "an", "ei\u00b7ner", "ba\u00b7by\u00b7lon'\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Krankheit starb zu Babylon,", "tokens": ["Krank\u00b7heit", "starb", "zu", "Ba\u00b7by\u00b7lon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wurden ihre Perlen dort", "tokens": ["Wur\u00b7den", "ih\u00b7re", "Per\u00b7len", "dort"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Auf dem B\u00f6rsensaal vergantert.", "tokens": ["Auf", "dem", "B\u00f6r\u00b7sen\u00b7saal", "ver\u00b7gan\u00b7tert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie erstand ein Pfaff' aus Memphis,", "tokens": ["Sie", "er\u00b7stand", "ein", "Pfaff'", "aus", "Mem\u00b7phis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der sie nach \u00c4gypten brachte,", "tokens": ["Der", "sie", "nach", "\u00c4\u00b7gyp\u00b7ten", "brach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo sie sp\u00e4ter auf dem Putztisch", "tokens": ["Wo", "sie", "sp\u00e4\u00b7ter", "auf", "dem", "Putz\u00b7tisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Der Kleopatra erschienen,", "tokens": ["Der", "Kleo\u00b7pat\u00b7ra", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die die sch\u00f6nste Perl' zerstampft", "tokens": ["Die", "die", "sch\u00f6ns\u00b7te", "Perl'", "zer\u00b7stampft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit Wein vermischt verschluckte,", "tokens": ["Und", "mit", "Wein", "ver\u00b7mischt", "ver\u00b7schluck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um Antonius zu foppen.", "tokens": ["Um", "An\u00b7to\u00b7ni\u00b7us", "zu", "fop\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "NE", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Mit dem letzten Omayaden", "tokens": ["Mit", "dem", "letz\u00b7ten", "Om\u00b7ay\u00b7a\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kam die Perlenschnur nach Spanien,", "tokens": ["Kam", "die", "Per\u00b7len\u00b7schnur", "nach", "Spa\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und sie schl\u00e4ngelte am Turban", "tokens": ["Und", "sie", "schl\u00e4n\u00b7gel\u00b7te", "am", "Tur\u00b7ban"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Des Kalifen zu Corduba.", "tokens": ["Des", "Ka\u00b7li\u00b7fen", "zu", "Cor\u00b7du\u00b7ba", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Abderam der Dritte trug sie", "tokens": ["Ab\u00b7de\u00b7ram", "der", "Drit\u00b7te", "trug", "sie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als Brustschleife beim Turnier,", "tokens": ["Als", "Brust\u00b7schlei\u00b7fe", "beim", "Tur\u00b7nier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Wo er drei\u00dfig goldne Ringe", "tokens": ["Wo", "er", "drei\u00b7\u00dfig", "gold\u00b7ne", "Rin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "CARD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Herz Zuleimas stach.", "tokens": ["Und", "das", "Herz", "Zu\u00b7lei\u00b7mas", "stach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Nach dem Fall der Mohrenherrschaft", "tokens": ["Nach", "dem", "Fall", "der", "Moh\u00b7ren\u00b7herr\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gingen zu den Christen \u00fcber", "tokens": ["Gin\u00b7gen", "zu", "den", "Chris\u00b7ten", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch die Perlen, und gerieten", "tokens": ["Auch", "die", "Per\u00b7len", ",", "und", "ge\u00b7rie\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den Kronschatz von Kastilien.", "tokens": ["In", "den", "Kron\u00b7schatz", "von", "Kas\u00b7ti\u00b7li\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Die kathol'schen Majest\u00e4ten", "tokens": ["Die", "ka\u00b7thol'\u00b7schen", "Ma\u00b7jes\u00b7t\u00e4\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Span'scher K\u00f6niginnen schm\u00fcckten", "tokens": ["Span'\u00b7scher", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "schm\u00fcck\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sich damit bei Hoffestspielen,", "tokens": ["Sich", "da\u00b7mit", "bei", "Hof\u00b7fest\u00b7spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PAV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stiergefechten, Prozessionen,", "tokens": ["Stier\u00b7ge\u00b7fech\u00b7ten", ",", "Pro\u00b7zes\u00b7si\u00b7o\u00b7nen", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "So wie auch Autodaf\u00e9s,", "tokens": ["So", "wie", "auch", "Au\u00b7to\u00b7daf\u00e9s", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Wo sie, auf Balkonen sitzend,", "tokens": ["Wo", "sie", ",", "auf", "Bal\u00b7ko\u00b7nen", "sit\u00b7zend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Sich erquickten am Geruche", "tokens": ["Sich", "er\u00b7quick\u00b7ten", "am", "Ge\u00b7ru\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von gebratnen alten Juden.", "tokens": ["Von", "ge\u00b7brat\u00b7nen", "al\u00b7ten", "Ju\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Sp\u00e4terhin gab Mendizabel,", "tokens": ["Sp\u00e4\u00b7ter\u00b7hin", "gab", "Men\u00b7di\u00b7za\u00b7bel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Satansenkel, diese Perlen", "tokens": ["Sa\u00b7tan\u00b7sen\u00b7kel", ",", "die\u00b7se", "Per\u00b7len"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In Versatz, um der Finanzen", "tokens": ["In", "Ver\u00b7satz", ",", "um", "der", "Fi\u00b7nan\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUI", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Defizit damit zu decken.", "tokens": ["De\u00b7fi\u00b7zit", "da\u00b7mit", "zu", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PAV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "An dem Hof der Tuilerien", "tokens": ["An", "dem", "Hof", "der", "Tu\u00b7i\u00b7le\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Kam die Schnur zuletzt zum Vorschein,", "tokens": ["Kam", "die", "Schnur", "zu\u00b7letzt", "zum", "Vor\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sie schimmerte am Halse", "tokens": ["Und", "sie", "schim\u00b7mer\u00b7te", "am", "Hal\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der Baronin Salomon.", "tokens": ["Der", "Ba\u00b7ro\u00b7nin", "Sa\u00b7lo\u00b7mon", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.23": {"line.1": {"text": "So erging's den sch\u00f6nen Perlen.", "tokens": ["So", "er\u00b7ging's", "den", "sch\u00f6\u00b7nen", "Per\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Minder abenteuerlich", "tokens": ["Min\u00b7der", "a\u00b7bent\u00b7eu\u00b7er\u00b7lich"], "token_info": ["word", "word"], "pos": ["NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ging's dem K\u00e4stchen, dies behielt", "tokens": ["Ging's", "dem", "K\u00e4st\u00b7chen", ",", "dies", "be\u00b7hielt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "ART", "NN", "$,", "PDS", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Alexander f\u00fcr sich selber.", "tokens": ["A\u00b7lex\u00b7an\u00b7der", "f\u00fcr", "sich", "sel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PRF", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Er verschlo\u00df darin die Lieder", "tokens": ["Er", "ver\u00b7schlo\u00df", "da\u00b7rin", "die", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Des ambrosischen Homeros,", "tokens": ["Des", "am\u00b7bro\u00b7si\u00b7schen", "Ho\u00b7me\u00b7ros", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Seines Lieblings, und zu H\u00e4upten", "tokens": ["Sei\u00b7nes", "Lieb\u00b7lings", ",", "und", "zu", "H\u00e4up\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seines Bettes in der Nacht", "tokens": ["Sei\u00b7nes", "Bet\u00b7tes", "in", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Stand das K\u00e4stchen \u2013 Schlief der K\u00f6nig,", "tokens": ["Stand", "das", "K\u00e4st\u00b7chen", "\u2013", "Schlief", "der", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stiegen draus hervor der Helden", "tokens": ["Stie\u00b7gen", "draus", "her\u00b7vor", "der", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PAV", "PTKVZ", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lichte Bilder, und sie schlichen", "tokens": ["Lich\u00b7te", "Bil\u00b7der", ",", "und", "sie", "schli\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "KON", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gaukelnd sich in seine Tr\u00e4ume.", "tokens": ["Gau\u00b7kelnd", "sich", "in", "sei\u00b7ne", "Tr\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Andre Zeiten, andre V\u00f6gel \u2013", "tokens": ["And\u00b7re", "Zei\u00b7ten", ",", "and\u00b7re", "V\u00f6\u00b7gel", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich, ich liebte weiland gleichfalls", "tokens": ["Ich", ",", "ich", "lieb\u00b7te", "wei\u00b7land", "gleich\u00b7falls"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PPER", "VVFIN", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Ges\u00e4nge von den Taten", "tokens": ["Die", "Ge\u00b7s\u00e4n\u00b7ge", "von", "den", "Ta\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Peliden, des Odysseus.", "tokens": ["Des", "Pe\u00b7li\u00b7den", ",", "des", "O\u00b7dys\u00b7seus", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NE", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.27": {"line.1": {"text": "Damals war so sonnengoldig", "tokens": ["Da\u00b7mals", "war", "so", "son\u00b7nen\u00b7gol\u00b7dig"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und so purpurn mir zumute,", "tokens": ["Und", "so", "pur\u00b7purn", "mir", "zu\u00b7mu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine Stirn umkr\u00e4nzte Weinlaub,", "tokens": ["Mei\u00b7ne", "Stirn", "um\u00b7kr\u00e4nz\u00b7te", "Wein\u00b7laub", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es t\u00f6nten die Fanfaren \u2013", "tokens": ["Und", "es", "t\u00f6n\u00b7ten", "die", "Fan\u00b7fa\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Still davon \u2013 gebrochen liegt", "tokens": ["Still", "da\u00b7von", "\u2013", "ge\u00b7bro\u00b7chen", "liegt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "PAV", "$(", "VVPP", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Jetzt mein stolzer Siegeswagen,", "tokens": ["Jetzt", "mein", "stol\u00b7zer", "Sie\u00b7ges\u00b7wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Panther, die ihn zogen,", "tokens": ["Und", "die", "Pan\u00b7ther", ",", "die", "ihn", "zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Sind verreckt, so wie die Weiber,", "tokens": ["Sind", "ver\u00b7reckt", ",", "so", "wie", "die", "Wei\u00b7ber", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Die mit Pauk' und Zimbelkl\u00e4ngen", "tokens": ["Die", "mit", "Pauk'", "und", "Zim\u00b7bel\u00b7kl\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NE", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mich umtanzten, und ich selbst", "tokens": ["Mich", "um\u00b7tanz\u00b7ten", ",", "und", "ich", "selbst"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4lze mich am Boden elend,", "tokens": ["W\u00e4l\u00b7ze", "mich", "am", "Bo\u00b7den", "e\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kr\u00fcppelelend \u2013 still davon \u2013", "tokens": ["Kr\u00fcp\u00b7pe\u00b7le\u00b7lend", "\u2013", "still", "da\u00b7von", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$(", "ADJD", "PAV", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.30": {"line.1": {"text": "Still davon \u2013 es ist die Rede", "tokens": ["Still", "da\u00b7von", "\u2013", "es", "ist", "die", "Re\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PAV", "$(", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem K\u00e4stchen des Darius,", "tokens": ["Von", "dem", "K\u00e4st\u00b7chen", "des", "Da\u00b7ri\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und ich dacht in meinem Sinne:", "tokens": ["Und", "ich", "dacht", "in", "mei\u00b7nem", "Sin\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00e4m ich in Besitz des K\u00e4stchens,", "tokens": ["K\u00e4m", "ich", "in", "Be\u00b7sitz", "des", "K\u00e4st\u00b7chens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Und mich zw\u00e4nge nicht Finanznot,", "tokens": ["Und", "mich", "zw\u00e4n\u00b7ge", "nicht", "Fi\u00b7nanz\u00b7not", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Gleich dasselbe zu versilbern,", "tokens": ["Gleich", "das\u00b7sel\u00b7be", "zu", "ver\u00b7sil\u00b7bern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "So verschl\u00f6sse ich darin", "tokens": ["So", "ver\u00b7schl\u00f6s\u00b7se", "ich", "da\u00b7rin"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Gedichte unsres Rabbi \u2013", "tokens": ["Die", "Ge\u00b7dich\u00b7te", "uns\u00b7res", "Rab\u00b7bi", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Des Jehuda ben Halevy", "tokens": ["Des", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Festges\u00e4nge, Klagelieder,", "tokens": ["Fest\u00b7ge\u00b7s\u00e4n\u00b7ge", ",", "Kla\u00b7ge\u00b7lie\u00b7der", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Ghaselen, Reisebilder", "tokens": ["Die", "Gha\u00b7se\u00b7len", ",", "Rei\u00b7se\u00b7bil\u00b7der"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Seiner Wallfahrt \u2013 alles lie\u00df' ich", "tokens": ["Sei\u00b7ner", "Wall\u00b7fahrt", "\u2013", "al\u00b7les", "lie\u00df'", "ich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PIS", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Von dem besten Zophar schreiben", "tokens": ["Von", "dem", "bes\u00b7ten", "Zop\u00b7har", "schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf der reinsten Pergamenthaut,", "tokens": ["Auf", "der", "reins\u00b7ten", "Per\u00b7ga\u00b7ment\u00b7haut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und ich legte diese Handschrift", "tokens": ["Und", "ich", "leg\u00b7te", "die\u00b7se", "Hand\u00b7schrift"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In das kleine goldne K\u00e4stchen.", "tokens": ["In", "das", "klei\u00b7ne", "gold\u00b7ne", "K\u00e4st\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Dieses stellt' ich auf den Tisch", "tokens": ["Die\u00b7ses", "stellt'", "ich", "auf", "den", "Tisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Neben meinem Bett, und k\u00e4men", "tokens": ["Ne\u00b7ben", "mei\u00b7nem", "Bett", ",", "und", "k\u00e4\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann die Freunde und erstaunten", "tokens": ["Dann", "die", "Freun\u00b7de", "und", "er\u00b7staun\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ob der Pracht der kleinen Truhe,", "tokens": ["Ob", "der", "Pracht", "der", "klei\u00b7nen", "Tru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Ob den seltnen Basreliefen,", "tokens": ["Ob", "den", "selt\u00b7nen", "Bas\u00b7re\u00b7li\u00b7e\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die so winzig, doch vollendet", "tokens": ["Die", "so", "win\u00b7zig", ",", "doch", "voll\u00b7en\u00b7det"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADV", "ADJD", "$,", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind zugleich, und ob den gro\u00dfen", "tokens": ["Sind", "zu\u00b7gleich", ",", "und", "ob", "den", "gro\u00b7\u00dfen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "$,", "KON", "KOUS", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Inkrustierten Edelsteinen \u2013", "tokens": ["In\u00b7krus\u00b7tier\u00b7ten", "E\u00b7del\u00b7stei\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "L\u00e4chelnd w\u00fcrd ich ihnen sagen:", "tokens": ["L\u00e4\u00b7chelnd", "w\u00fcrd", "ich", "ih\u00b7nen", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das ist nur die rohe Schale,", "tokens": ["Das", "ist", "nur", "die", "ro\u00b7he", "Scha\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die den bessern Schatz verschlie\u00dfet \u2013", "tokens": ["Die", "den", "bes\u00b7sern", "Schatz", "ver\u00b7schlie\u00b7\u00dfet", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier in diesem K\u00e4stchen liegen", "tokens": ["Hier", "in", "die\u00b7sem", "K\u00e4st\u00b7chen", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PDAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Diamanten, deren Lichter", "tokens": ["Di\u00b7a\u00b7man\u00b7ten", ",", "de\u00b7ren", "Lich\u00b7ter"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELAT", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Abglanz, Widerschein des Himmels,", "tokens": ["Ab\u00b7glanz", ",", "Wi\u00b7der\u00b7schein", "des", "Him\u00b7mels", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Herzblutgl\u00fchende Rubinen,", "tokens": ["Herz\u00b7blut\u00b7gl\u00fc\u00b7hen\u00b7de", "Ru\u00b7bi\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Fleckenlose Turkoasen,", "tokens": ["Fle\u00b7cken\u00b7lo\u00b7se", "Tur\u00b7ko\u00b7a\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Auch Smaragde der Verhei\u00dfung,", "tokens": ["Auch", "Sma\u00b7rag\u00b7de", "der", "Ver\u00b7hei\u00b7\u00dfung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Perlen, reiner noch als jene,", "tokens": ["Per\u00b7len", ",", "rei\u00b7ner", "noch", "als", "je\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "ADV", "KOKOM", "PDS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die der K\u00f6nigin Atossa", "tokens": ["Die", "der", "K\u00f6\u00b7ni\u00b7gin", "A\u00b7tos\u00b7sa"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einst geschenkt der falschen Smerdis,", "tokens": ["Einst", "ge\u00b7schenkt", "der", "fal\u00b7schen", "Smer\u00b7dis", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Und die sp\u00e4terhin geschm\u00fccket", "tokens": ["Und", "die", "sp\u00e4\u00b7ter\u00b7hin", "ge\u00b7schm\u00fc\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Notabilit\u00e4ten", "tokens": ["Al\u00b7le", "No\u00b7ta\u00b7bi\u00b7li\u00b7t\u00e4\u00b7ten"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser mondumkreisten Erde,", "tokens": ["Die\u00b7ser", "mond\u00b7um\u00b7kreis\u00b7ten", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Thais und Kleopatra,", "tokens": ["Thais", "und", "Kleo\u00b7pat\u00b7ra", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.40": {"line.1": {"text": "Isispriester, Mohrenf\u00fcrsten,", "tokens": ["I\u00b7sis\u00b7pries\u00b7ter", ",", "Moh\u00b7ren\u00b7f\u00fcrs\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch Hispaniens K\u00f6niginnen.", "tokens": ["Auch", "His\u00b7pa\u00b7ni\u00b7ens", "K\u00f6\u00b7ni\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und zuletzt die hochverehrte", "tokens": ["Und", "zu\u00b7letzt", "die", "hoch\u00b7ver\u00b7ehr\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Frau Baronin Salomon \u2013", "tokens": ["Frau", "Ba\u00b7ro\u00b7nin", "Sa\u00b7lo\u00b7mon", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Diese weltber\u00fchmten Perlen,", "tokens": ["Die\u00b7se", "welt\u00b7be\u00b7r\u00fchm\u00b7ten", "Per\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sie sind nur der bleiche Schleim", "tokens": ["Sie", "sind", "nur", "der", "blei\u00b7che", "Schleim"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Eines armen Austertiers,", "tokens": ["Ei\u00b7nes", "ar\u00b7men", "Aus\u00b7ter\u00b7tiers", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das im Meergrund bl\u00f6de kr\u00e4nkelt:", "tokens": ["Das", "im", "Meer\u00b7grund", "bl\u00f6\u00b7de", "kr\u00e4n\u00b7kelt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Doch die Perlen hier im K\u00e4stchen", "tokens": ["Doch", "die", "Per\u00b7len", "hier", "im", "K\u00e4st\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind entquollen einer sch\u00f6nen", "tokens": ["Sind", "ent\u00b7quol\u00b7len", "ei\u00b7ner", "sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "VVPP", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Menschenseele, die noch tiefer,", "tokens": ["Men\u00b7schen\u00b7see\u00b7le", ",", "die", "noch", "tie\u00b7fer", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Abgrundtiefer als das Weltmeer \u2013", "tokens": ["Ab\u00b7grund\u00b7tie\u00b7fer", "als", "das", "Welt\u00b7meer", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Denn es sind die Tr\u00e4nenperlen", "tokens": ["Denn", "es", "sind", "die", "Tr\u00e4\u00b7nen\u00b7per\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Des Jehuda ben Halevy,", "tokens": ["Des", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die er ob dem Untergang", "tokens": ["Die", "er", "ob", "dem", "Un\u00b7ter\u00b7gang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "KOUS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Von Jerusalem geweinet \u2013", "tokens": ["Von", "Je\u00b7ru\u00b7sa\u00b7lem", "ge\u00b7wei\u00b7net", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.44": {"line.1": {"text": "Perlentr\u00e4nen, die, verbunden", "tokens": ["Per\u00b7len\u00b7tr\u00e4\u00b7nen", ",", "die", ",", "ver\u00b7bun\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "PRELS", "$,", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch des Reimes goldnen Faden,", "tokens": ["Durch", "des", "Rei\u00b7mes", "gold\u00b7nen", "Fa\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus der Dichtkunst g\u00fcldnen Schmiede", "tokens": ["Aus", "der", "Dicht\u00b7kunst", "g\u00fcld\u00b7nen", "Schmie\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ein Lied hervorgegangen.", "tokens": ["Als", "ein", "Lied", "her\u00b7vor\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Dieses Perlentr\u00e4nenlied", "tokens": ["Die\u00b7ses", "Per\u00b7len\u00b7tr\u00e4\u00b7nen\u00b7lied"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist die vielber\u00fchmte Klage,", "tokens": ["Ist", "die", "viel\u00b7be\u00b7r\u00fchm\u00b7te", "Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die gesungen wird in allen", "tokens": ["Die", "ge\u00b7sun\u00b7gen", "wird", "in", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VVPP", "VAFIN", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weltzerstreuten Zelten Jakobs", "tokens": ["Welt\u00b7zer\u00b7streu\u00b7ten", "Zel\u00b7ten", "Ja\u00b7kobs"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.46": {"line.1": {"text": "An dem neunten Tag des Monats,", "tokens": ["An", "dem", "neun\u00b7ten", "Tag", "des", "Mo\u00b7nats", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Der gehei\u00dfen Ab, dem Jahrstag", "tokens": ["Der", "ge\u00b7hei\u00b7\u00dfen", "Ab", ",", "dem", "Jahr\u00b7stag"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von Jerusalems Zerst\u00f6rung", "tokens": ["Von", "Je\u00b7ru\u00b7sa\u00b7lems", "Zer\u00b7st\u00f6\u00b7rung"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch den Titus Vespasianus.", "tokens": ["Durch", "den", "Ti\u00b7tus", "Ves\u00b7pa\u00b7si\u00b7a\u00b7nus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "NE", "$."], "meter": "+-+--++-+", "measure": "trochaic.penta.relaxed"}}, "stanza.47": {"line.1": {"text": "Ja, das ist das Zionslied,", "tokens": ["Ja", ",", "das", "ist", "das", "Zi\u00b7ons\u00b7lied", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das Jehuda ben Halevy", "tokens": ["Das", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sterbend auf den heil'gen Tr\u00fcmmern", "tokens": ["Ster\u00b7bend", "auf", "den", "heil'\u00b7gen", "Tr\u00fcm\u00b7mern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von Jerusalem gesungen \u2013", "tokens": ["Von", "Je\u00b7ru\u00b7sa\u00b7lem", "ge\u00b7sun\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.48": {"line.1": {"text": "Barfu\u00df und im B\u00fc\u00dferkittel", "tokens": ["Bar\u00b7fu\u00df", "und", "im", "B\u00fc\u00b7\u00dfer\u00b7kit\u00b7tel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sa\u00df er dorten auf dem Bruchst\u00fcck", "tokens": ["Sa\u00df", "er", "dor\u00b7ten", "auf", "dem", "Bruchs\u00b7t\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einer umgest\u00fcrzten S\u00e4ule; \u2013", "tokens": ["Ei\u00b7ner", "um\u00b7ge\u00b7st\u00fcrz\u00b7ten", "S\u00e4u\u00b7le", ";", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis zur Brust herunter fiel", "tokens": ["Bis", "zur", "Brust", "her\u00b7un\u00b7ter", "fiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPRART", "NN", "APZR", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Wie ein greiser Wald sein Haupthaar,", "tokens": ["Wie", "ein", "grei\u00b7ser", "Wald", "sein", "Haupt\u00b7haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abenteuerlich beschattend", "tokens": ["A\u00b7bent\u00b7eu\u00b7er\u00b7lich", "be\u00b7schat\u00b7tend"], "token_info": ["word", "word"], "pos": ["ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das bek\u00fcmmert bleiche Antlitz", "tokens": ["Das", "be\u00b7k\u00fcm\u00b7mert", "blei\u00b7che", "Ant\u00b7litz"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den geisterhaften Augen \u2013", "tokens": ["Mit", "den", "geis\u00b7ter\u00b7haf\u00b7ten", "Au\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Also sa\u00df er und er sang,", "tokens": ["Al\u00b7so", "sa\u00df", "er", "und", "er", "sang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein Seher aus der Vorzeit", "tokens": ["Wie", "ein", "Se\u00b7her", "aus", "der", "Vor\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Anzuschaun \u2013 dem Grab entstiegen", "tokens": ["An\u00b7zu\u00b7schaun", "\u2013", "dem", "Grab", "ent\u00b7stie\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["FM.la", "$(", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schien Jeremias, der Alte \u2013", "tokens": ["Schien", "Je\u00b7re\u00b7mi\u00b7as", ",", "der", "Al\u00b7te", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.51": {"line.1": {"text": "Das Gev\u00f6gel der Ruinen", "tokens": ["Das", "Ge\u00b7v\u00f6\u00b7gel", "der", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Z\u00e4hmte schier der wilde Schmerzlaut", "tokens": ["Z\u00e4hm\u00b7te", "schier", "der", "wil\u00b7de", "Schmerz\u00b7laut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Des Gesanges, und die Geier", "tokens": ["Des", "Ge\u00b7san\u00b7ges", ",", "und", "die", "Gei\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahten horchend, fast mitleidig \u2013", "tokens": ["Nah\u00b7ten", "hor\u00b7chend", ",", "fast", "mit\u00b7lei\u00b7dig", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Doch ein frecher Sarazene", "tokens": ["Doch", "ein", "fre\u00b7cher", "Sa\u00b7ra\u00b7ze\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kam desselben Wegs geritten,", "tokens": ["Kam", "des\u00b7sel\u00b7ben", "Wegs", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hoch zu Ro\u00df, im Bug sich wiegend", "tokens": ["Hoch", "zu", "Ro\u00df", ",", "im", "Bug", "sich", "wie\u00b7gend"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "NN", "$,", "APPRART", "NN", "PRF", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die blanke Lanze schwingend \u2013", "tokens": ["Und", "die", "blan\u00b7ke", "Lan\u00b7ze", "schwin\u00b7gend", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "In die Brust des armen S\u00e4ngers", "tokens": ["In", "die", "Brust", "des", "ar\u00b7men", "S\u00e4n\u00b7gers"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stie\u00df er diesen Todesspeer,", "tokens": ["Stie\u00df", "er", "die\u00b7sen", "To\u00b7des\u00b7speer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er jagte rasch von dannen,", "tokens": ["Und", "er", "jag\u00b7te", "rasch", "von", "dan\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPR", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie ein Schattenbild befl\u00fcgelt.", "tokens": ["Wie", "ein", "Schat\u00b7ten\u00b7bild", "be\u00b7fl\u00fc\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Ruhig flo\u00df das Blut des Rabbi,", "tokens": ["Ru\u00b7hig", "flo\u00df", "das", "Blut", "des", "Rab\u00b7bi", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ruhig seinen Sang zu Ende", "tokens": ["Ru\u00b7hig", "sei\u00b7nen", "Sang", "zu", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sang er, und sein sterbeletzter", "tokens": ["Sang", "er", ",", "und", "sein", "ster\u00b7be\u00b7letz\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KON", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seufzer war Jerusalem! \u2013 \u2013", "tokens": ["Seuf\u00b7zer", "war", "Je\u00b7ru\u00b7sa\u00b7lem", "!", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "VAFIN", "NE", "$.", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.55": {"line.1": {"text": "Eine alte Sage meldet,", "tokens": ["Ei\u00b7ne", "al\u00b7te", "Sa\u00b7ge", "mel\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jener Sarazene sei", "tokens": ["Je\u00b7ner", "Sa\u00b7ra\u00b7ze\u00b7ne", "sei"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gar kein b\u00f6ser Mensch gewesen,", "tokens": ["Gar", "kein", "b\u00f6\u00b7ser", "Mensch", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern ein verkappter Engel,", "tokens": ["Son\u00b7dern", "ein", "ver\u00b7kapp\u00b7ter", "En\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Der vom Himmel ward gesendet,", "tokens": ["Der", "vom", "Him\u00b7mel", "ward", "ge\u00b7sen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gottes Liebling zu entr\u00fccken", "tokens": ["Got\u00b7tes", "Lieb\u00b7ling", "zu", "ent\u00b7r\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieser Erde und zu f\u00f6rdern", "tokens": ["Die\u00b7ser", "Er\u00b7de", "und", "zu", "f\u00f6r\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "KON", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ohne Qual ins Reich der Sel'gen.", "tokens": ["Oh\u00b7ne", "Qual", "ins", "Reich", "der", "Sel'\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Droben, hei\u00dft es, harrte seiner", "tokens": ["Dro\u00b7ben", ",", "hei\u00dft", "es", ",", "harr\u00b7te", "sei\u00b7ner"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPOSAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Empfang, der schmeichelhaft", "tokens": ["Ein", "Emp\u00b7fang", ",", "der", "schmei\u00b7chel\u00b7haft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ganz besonders f\u00fcr den Dichter,", "tokens": ["Ganz", "be\u00b7son\u00b7ders", "f\u00fcr", "den", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine himmlische Surprise.", "tokens": ["Ei\u00b7ne", "himm\u00b7li\u00b7sche", "Sur\u00b7pri\u00b7se", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Festlich kam das Chor der Engel", "tokens": ["Fest\u00b7lich", "kam", "das", "Chor", "der", "En\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihm entgegen mit Musik,", "tokens": ["Ihm", "ent\u00b7ge\u00b7gen", "mit", "Mu\u00b7sik", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und als Hymne gr\u00fc\u00dften ihn", "tokens": ["Und", "als", "Hym\u00b7ne", "gr\u00fc\u00df\u00b7ten", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seine eignen Verse, jenes", "tokens": ["Sei\u00b7ne", "eig\u00b7nen", "Ver\u00b7se", ",", "je\u00b7nes"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PDS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "Synagogenhochzeitkarmen,", "tokens": ["Syn\u00b7a\u00b7go\u00b7gen\u00b7hoch\u00b7zeit\u00b7kar\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jene Sabbathymen\u00e4en,", "tokens": ["Je\u00b7ne", "Sab\u00b7ba\u00b7thy\u00b7me\u00b7n\u00e4\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit den jauchzend wohlbekannten", "tokens": ["Mit", "den", "jauch\u00b7zend", "wohl\u00b7be\u00b7kann\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Melodien \u2013 welche T\u00f6ne!", "tokens": ["Me\u00b7lo\u00b7dien", "\u2013", "wel\u00b7che", "T\u00f6\u00b7ne", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "PWAT", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.60": {"line.1": {"text": "Englein bliesen auf Hoboen,", "tokens": ["En\u00b7glein", "blie\u00b7sen", "auf", "Ho\u00b7boen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Englein spielten Violine,", "tokens": ["En\u00b7glein", "spiel\u00b7ten", "Vi\u00b7o\u00b7li\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Andre strichen auch die Bratsche", "tokens": ["And\u00b7re", "stri\u00b7chen", "auch", "die", "Brat\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder schlugen Pauk' und Zimbel.", "tokens": ["O\u00b7der", "schlu\u00b7gen", "Pauk'", "und", "Zim\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Und das sang und klang so lieblich,", "tokens": ["Und", "das", "sang", "und", "klang", "so", "lieb\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und so lieblich in den weiten", "tokens": ["Und", "so", "lieb\u00b7lich", "in", "den", "wei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Himmelsr\u00e4umen widerhallt es:", "tokens": ["Him\u00b7mels\u00b7r\u00e4u\u00b7men", "wi\u00b7der\u00b7hallt", "es", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bblecho Daudi Likras Kalle.\u00ab", "tokens": ["\u00bb", "le\u00b7cho", "Dau\u00b7di", "Li\u00b7kras", "Kal\u00b7le", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "NE", "NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}