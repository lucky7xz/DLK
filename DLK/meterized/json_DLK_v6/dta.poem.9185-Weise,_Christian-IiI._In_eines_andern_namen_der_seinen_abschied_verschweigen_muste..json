{"dta.poem.9185": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "IiI.  \n In eines andern namen/ der seinen abschied  \n verschweigen muste.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ljebgen sol ich ietzt verschwiegen", "tokens": ["Ljeb\u00b7gen", "sol", "ich", "ietzt", "ver\u00b7schwie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder offenhertzig seyn/", "tokens": ["O\u00b7der", "of\u00b7fen\u00b7hert\u00b7zig", "seyn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sol ich mich und dich betriegen", "tokens": ["Sol", "ich", "mich", "und", "dich", "be\u00b7trie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder sag ich meine pein/", "tokens": ["O\u00b7der", "sag", "ich", "mei\u00b7ne", "pein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welche mich mit \u00fcberdru\u00df", "tokens": ["Wel\u00b7che", "mich", "mit", "\u00fc\u00b7berd\u00b7ru\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nach und nach verzehren mu\u00df.", "tokens": ["Nach", "und", "nach", "ver\u00b7zeh\u00b7ren", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Nein ich wil den mund bezwingen/", "tokens": ["Nein", "ich", "wil", "den", "mund", "be\u00b7zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn ich kan es nimmermehr", "tokens": ["Denn", "ich", "kan", "es", "nim\u00b7mer\u00b7mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Uber dieses hertze bringen/", "tokens": ["U\u00b7ber", "die\u00b7ses", "hert\u00b7ze", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wann es noch so hefftig w\u00e4r/", "tokens": ["Wann", "es", "noch", "so", "heff\u00b7tig", "w\u00e4r", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ich dir mit meiner pein", "tokens": ["Da\u00df", "ich", "dir", "mit", "mei\u00b7ner", "pein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wolte so beschwerlich seyn.", "tokens": ["Wol\u00b7te", "so", "be\u00b7schwer\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Dann so fern ich mu\u00df verreisen/", "tokens": ["Dann", "so", "fern", "ich", "mu\u00df", "ver\u00b7rei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PPER", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirst du meiner traurigkeit", "tokens": ["Wirst", "du", "mei\u00b7ner", "trau\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keinen grossen dienst erweisen", "tokens": ["Kei\u00b7nen", "gros\u00b7sen", "dienst", "er\u00b7wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch erregtes hertzenleid.", "tokens": ["Durch", "er\u00b7reg\u00b7tes", "hert\u00b7zen\u00b7leid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ach es ist genung daran/", "tokens": ["Ach", "es", "ist", "ge\u00b7nung", "da\u00b7ran", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PPER", "VAFIN", "ADV", "PAV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich mich nicht tr\u00f6sten kan.", "tokens": ["Da\u00df", "ich", "mich", "nicht", "tr\u00f6s\u00b7ten", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Ich sol alle lust vergessen", "tokens": ["Ich", "sol", "al\u00b7le", "lust", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welche meine seele liebt/", "tokens": ["Wel\u00b7che", "mei\u00b7ne", "see\u00b7le", "liebt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da die jahrs-zeit dir indessen", "tokens": ["Da", "die", "jahr\u00b7szeit", "dir", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "ADV"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Neuen fug zur freude gibt/", "tokens": ["Neu\u00b7en", "fug", "zur", "freu\u00b7de", "gibt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und dein s\u00fcsses m\u00fcndgen lacht/", "tokens": ["Und", "dein", "s\u00fcs\u00b7ses", "m\u00fcnd\u00b7gen", "lacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Weil mein kopff calender macht.", "tokens": ["Weil", "mein", "kopff", "ca\u00b7len\u00b7der", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NE", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "5. Niemand wird es wol vermeinen/", "tokens": ["Nie\u00b7mand", "wird", "es", "wol", "ver\u00b7mei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich auff dem sprunge steh:", "tokens": ["Da\u00df", "ich", "auff", "dem", "sprun\u00b7ge", "steh", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch der tag wird bald erscheinen/", "tokens": ["Doch", "der", "tag", "wird", "bald", "er\u00b7schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "VVINF", "$("], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "Welcher mein betr\u00fcbt ade/", "tokens": ["Wel\u00b7cher", "mein", "be\u00b7tr\u00fcbt", "a\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PPOSAT", "VVFIN", "ADV", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Das noch itzt im hertzen giert/", "tokens": ["Das", "noch", "itzt", "im", "hert\u00b7zen", "giert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Offentlich bekennen wird.", "tokens": ["Of\u00b7fent\u00b7lich", "be\u00b7ken\u00b7nen", "wird", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "6. Drum so sprech ich in gedancken:", "tokens": ["Drum", "so", "sprech", "ich", "in", "ge\u00b7dan\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Liebstes seelgen lebe wohl!", "tokens": ["Liebs\u00b7tes", "seel\u00b7gen", "le\u00b7be", "wohl", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wofern ich von dir wancken", "tokens": ["Und", "wo\u00b7fern", "ich", "von", "dir", "wan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "PPER", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und dich gantz verlassen soll/", "tokens": ["Und", "dich", "gantz", "ver\u00b7las\u00b7sen", "soll", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So bedanck ich allezeit", "tokens": ["So", "be\u00b7danck", "ich", "al\u00b7le\u00b7zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mich vor deine freundlichkeit.", "tokens": ["Mich", "vor", "dei\u00b7ne", "freund\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Und wo mein geh\u00e4uffter schmertzen", "tokens": ["Und", "wo", "mein", "ge\u00b7h\u00e4uff\u00b7ter", "schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPOSAT", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keine reden \u00fcbrig hat/", "tokens": ["Kei\u00b7ne", "re\u00b7den", "\u00fcb\u00b7rig", "hat", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "ADJD", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach so nimm in deinem hertzen", "tokens": ["Ach", "so", "nimm", "in", "dei\u00b7nem", "hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "VVIMP", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An des letzten grusses statt/", "tokens": ["An", "des", "letz\u00b7ten", "grus\u00b7ses", "statt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Den ich dir nicht geben kan/", "tokens": ["Den", "ich", "dir", "nicht", "ge\u00b7ben", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPER", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Meinen letzten seuftzer an.", "tokens": ["Mei\u00b7nen", "letz\u00b7ten", "seuft\u00b7zer", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}