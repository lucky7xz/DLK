{"dta.poem.15726": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "59.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1839", "urn": "urn:nbn:de:kobv:b4-200905195122", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "La\u00df dich nicht das Gewirr der Volksmundarten wirren,", "tokens": ["La\u00df", "dich", "nicht", "das", "Ge\u00b7wirr", "der", "Volks\u00b7mun\u00b7dar\u00b7ten", "wir\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Die durcheinander, selbst sich unverst\u00e4ndlich, schwirren.", "tokens": ["Die", "durch\u00b7ein\u00b7an\u00b7der", ",", "selbst", "sich", "un\u00b7ver\u00b7st\u00e4nd\u00b7lich", ",", "schwir\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADV", "PRF", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Vom heiligen Sanskrit sind W\u00f6rter, wie du wei\u00dft,", "tokens": ["Vom", "hei\u00b7li\u00b7gen", "Sans\u00b7krit", "sind", "W\u00f6r\u00b7ter", ",", "wie", "du", "wei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In allen, doch es ist ein andrer Grund und Geist.", "tokens": ["In", "al\u00b7len", ",", "doch", "es", "ist", "ein", "an\u00b7drer", "Grund", "und", "Geist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "$,", "KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Drei Sprachenst\u00e4mme gibts des menschlichen Vereins,", "tokens": ["Drei", "Spra\u00b7chen\u00b7st\u00e4m\u00b7me", "gibts", "des", "menschli\u00b7chen", "Ver\u00b7eins", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Semitisch und Sanskrit, und alles Uebrig' eins.", "tokens": ["Se\u00b7mi\u00b7tisch", "und", "Sans\u00b7krit", ",", "und", "al\u00b7les", "Ue\u00b7brig'", "eins", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,", "KON", "PIS", "ADV", "PIS", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Semitisch zeichnet aus tief innerliche Regung,", "tokens": ["Se\u00b7mi\u00b7tisch", "zeich\u00b7net", "aus", "tief", "in\u00b7ner\u00b7li\u00b7che", "Re\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Sanskritisch \u00e4u\u00dferer Gegliedertheit Bewegung,", "tokens": ["Sans\u00b7kri\u00b7tisch", "\u00e4u\u00b7\u00dfe\u00b7rer", "Ge\u00b7glie\u00b7der\u00b7theit", "Be\u00b7we\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Den dritten Stamm der Unbeweglichkeit Erstarrung,", "tokens": ["Den", "drit\u00b7ten", "Stamm", "der", "Un\u00b7be\u00b7weg\u00b7lich\u00b7keit", "Er\u00b7star\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gleichfern von Bildsamkeit und sicherer Beharrung.", "tokens": ["Gleich\u00b7fern", "von", "Bild\u00b7sam\u00b7keit", "und", "si\u00b7che\u00b7rer", "Be\u00b7har\u00b7rung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.6": {"line.1": {"text": "Die Felsenstarrheit kann nicht der Verwitterung", "tokens": ["Die", "Fel\u00b7sen\u00b7star\u00b7rheit", "kann", "nicht", "der", "Ver\u00b7wit\u00b7te\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PTKNEG", "ART", "NN"], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Entgehn, des Steinreichs Kern nicht der Zersplitterung;", "tokens": ["Ent\u00b7gehn", ",", "des", "Stein\u00b7reichs", "Kern", "nicht", "der", "Zer\u00b7split\u00b7te\u00b7rung", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "NN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Dagegen pflanzengleich die ersten Sprachen bl\u00fchn,", "tokens": ["Da\u00b7ge\u00b7gen", "pflan\u00b7zen\u00b7gleich", "die", "ers\u00b7ten", "Spra\u00b7chen", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die andern wie das Reich der Thierwelt Leben spr\u00fchn.", "tokens": ["Die", "an\u00b7dern", "wie", "das", "Reich", "der", "Thier\u00b7welt", "Le\u00b7ben", "spr\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "KOKOM", "ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Doch jene dritten, die sich all' einander gleichen", "tokens": ["Doch", "je\u00b7ne", "drit\u00b7ten", ",", "die", "sich", "all'", "ein\u00b7an\u00b7der", "glei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "ADJA", "$,", "PRELS", "PRF", "PIS", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "An Form, wie weit im Stoff sie auseinander weichen;", "tokens": ["An", "Form", ",", "wie", "weit", "im", "Stoff", "sie", "aus\u00b7ein\u00b7an\u00b7der", "wei\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "ADJD", "APPRART", "NN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Mechanisch ist ihr Bau, zuf\u00e4llig ihre Zeichen.", "tokens": ["Me\u00b7cha\u00b7nisch", "ist", "ihr", "Bau", ",", "zu\u00b7f\u00e4l\u00b7lig", "ih\u00b7re", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Auf Otaheite und Oweihi wird noch jetzt", "tokens": ["Auf", "O\u00b7ta\u00b7hei\u00b7te", "und", "O\u00b7wei\u00b7hi", "wird", "noch", "jetzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NE", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beim F\u00fcrstenwechsel neu die Sprachart festgesetzt.", "tokens": ["Beim", "F\u00fcrs\u00b7ten\u00b7wech\u00b7sel", "neu", "die", "Sprach\u00b7art", "fest\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Und jene K\u00f6nigin, als sie den Sohn gebar,", "tokens": ["Und", "je\u00b7ne", "K\u00f6\u00b7ni\u00b7gin", ",", "als", "sie", "den", "Sohn", "ge\u00b7bar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "KOUS", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schuf ihm zu Ehren um die Sprache ganz und gar.", "tokens": ["Schuf", "ihm", "zu", "Eh\u00b7ren", "um", "die", "Spra\u00b7che", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "ADV", "KON", "ADV", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.12": {"line.1": {"text": "Doch ihn ermordeten die unzufriednen Gro\u00dfen,", "tokens": ["Doch", "ihn", "er\u00b7mor\u00b7de\u00b7ten", "die", "un\u00b7zu\u00b7fried\u00b7nen", "Gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da ward die neue Sprach' auch wieder umgesto\u00dfen.", "tokens": ["Da", "ward", "die", "neu\u00b7e", "Sprach'", "auch", "wie\u00b7der", "um\u00b7ge\u00b7sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}