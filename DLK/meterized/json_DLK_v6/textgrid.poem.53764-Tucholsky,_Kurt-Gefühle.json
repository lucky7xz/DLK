{"textgrid.poem.53764": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Gef\u00fchle", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kennen Sie das Gef\u00fchl: \u203ad\u00e9j\u00e0 vu\u2039 \u2013?", "tokens": ["Ken\u00b7nen", "Sie", "das", "Ge\u00b7f\u00fchl", ":", "\u203a", "d\u00e9j\u00e0", "vu", "\u2039", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "FM", "FM", "FM", "FM", "$(", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Sie gehen zum Beispiel morgens fr\u00fch,", "tokens": ["Sie", "ge\u00b7hen", "zum", "Bei\u00b7spiel", "mor\u00b7gens", "fr\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "auf der Reise, in einem fremden Ort", "tokens": ["auf", "der", "Rei\u00b7se", ",", "in", "ei\u00b7nem", "frem\u00b7den", "Ort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "von der kleinen Hotelterrasse fort,", "tokens": ["von", "der", "klei\u00b7nen", "Ho\u00b7tel\u00b7ter\u00b7ras\u00b7se", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "wo die andern alle noch Zeitungen lesen.", "tokens": ["wo", "die", "an\u00b7dern", "al\u00b7le", "noch", "Zei\u00b7tun\u00b7gen", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "PIS", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Sie sind niemals in dem Dorf gewesen.", "tokens": ["Sie", "sind", "nie\u00b7mals", "in", "dem", "Dorf", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "VAPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Da gackert ein Huhn, da steht eine Leiter,", "tokens": ["Da", "ga\u00b7ckert", "ein", "Huhn", ",", "da", "steht", "ei\u00b7ne", "Lei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "und Sie fragen \u2013 denn Sie wissen nicht weiter \u2013", "tokens": ["und", "Sie", "fra\u00b7gen", "\u2013", "denn", "Sie", "wis\u00b7sen", "nicht", "wei\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "$(", "KON", "PPER", "VVFIN", "PTKNEG", "ADV", "$("], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "eine Bauersfrau mit riesiger Schute . . .", "tokens": ["ei\u00b7ne", "Bau\u00b7ers\u00b7frau", "mit", "rie\u00b7si\u00b7ger", "Schu\u00b7te", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Und pl\u00f6tzlich ist Ihnen so zumute", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "ist", "Ih\u00b7nen", "so", "zu\u00b7mu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADV", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "\u2013 wie Erinnerung, die leise entschwebt \u2013:", "tokens": ["\u2013", "wie", "E\u00b7rin\u00b7ne\u00b7rung", ",", "die", "lei\u00b7se", "ent\u00b7schwebt", "\u2013", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOKOM", "NN", "$,", "PRELS", "ADJD", "VVPP", "$(", "$."], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Das habe ich alles schon mal erlebt.", "tokens": ["Das", "ha\u00b7be", "ich", "al\u00b7les", "schon", "mal", "er\u00b7lebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PIS", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Kennen Sie das Hotelgef\u00fchl \u2013?", "tokens": ["Ken\u00b7nen", "Sie", "das", "Ho\u00b7tel\u00b7ge\u00b7f\u00fchl", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$(", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Sie sitzen zu Hause. Das Zimmer ist k\u00fchl.", "tokens": ["Sie", "sit\u00b7zen", "zu", "Hau\u00b7se", ".", "Das", "Zim\u00b7mer", "ist", "k\u00fchl", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Der Tee ist warm. Die Reihen der B\u00fccher", "tokens": ["Der", "Tee", "ist", "warm", ".", "Die", "Rei\u00b7hen", "der", "B\u00fc\u00b7cher"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "schimmern matt. Das sind Ihre Leinent\u00fccher,", "tokens": ["schim\u00b7mern", "matt", ".", "Das", "sind", "Ih\u00b7re", "Lei\u00b7nen\u00b7t\u00fc\u00b7cher", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Ihre Tassen, Ihre Kronen \u2013", "tokens": ["Ih\u00b7re", "Tas\u00b7sen", ",", "Ih\u00b7re", "Kro\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie wissen genau, da\u00df Sie hier wohnen.", "tokens": ["Sie", "wis\u00b7sen", "ge\u00b7nau", ",", "da\u00df", "Sie", "hier", "woh\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "KOUS", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Da sind Ihre Kinder, Ihre Alte, die gute \u2013", "tokens": ["Da", "sind", "Ih\u00b7re", "Kin\u00b7der", ",", "Ih\u00b7re", "Al\u00b7te", ",", "die", "gu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "ADJA", "$("], "meter": "--+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Und pl\u00f6tzlich ist Ihnen so fremd zumute:", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "ist", "Ih\u00b7nen", "so", "fremd", "zu\u00b7mu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Das geh\u00f6rt ja alles gar nicht mir . . .", "tokens": ["Das", "ge\u00b7h\u00f6rt", "ja", "al\u00b7les", "gar", "nicht", "mir", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PIS", "ADV", "PTKNEG", "PPER", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ich bin nur vor\u00fcbergehend hier.", "tokens": ["Ich", "bin", "nur", "vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7hend", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Kennen Sie . . . das ist schwer zu sagen.", "tokens": ["Ken\u00b7nen", "Sie", ".", ".", ".", "das", "ist", "schwer", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$.", "$.", "PDS", "VAFIN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Nicht das Hungergef\u00fchl. Nicht den leeren Magen.", "tokens": ["Nicht", "das", "Hun\u00b7ger\u00b7ge\u00b7f\u00fchl", ".", "Nicht", "den", "lee\u00b7ren", "Ma\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$.", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "+-+--++-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Sie haben ja eben erst Fr\u00fchst\u00fcck gegessen.", "tokens": ["Sie", "ha\u00b7ben", "ja", "e\u00b7ben", "erst", "Fr\u00fch\u00b7st\u00fcck", "ge\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "NN", "VVPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Sie d\u00fcrfen arbeiten, f\u00fcr die Interessen", "tokens": ["Sie", "d\u00fcr\u00b7fen", "ar\u00b7bei\u00b7ten", ",", "f\u00fcr", "die", "In\u00b7ter\u00b7es\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "des andern, um sich Brot zu kaufen", "tokens": ["des", "an\u00b7dern", ",", "um", "sich", "Brot", "zu", "kau\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "KOUI", "PRF", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und wieder ins B\u00fcro zu laufen.", "tokens": ["und", "wie\u00b7der", "ins", "B\u00fc\u00b7ro", "zu", "lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Hunger nicht.", "tokens": ["Hun\u00b7ger", "nicht", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKNEG", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Aber ein tiefes Hungern", "tokens": ["A\u00b7ber", "ein", "tie\u00b7fes", "Hun\u00b7gern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.9": {"text": "nach allem, was sch\u00f6n ist: nicht immer so lungern \u2013", "tokens": ["nach", "al\u00b7lem", ",", "was", "sch\u00f6n", "ist", ":", "nicht", "im\u00b7mer", "so", "lun\u00b7gern", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "ADJD", "VAFIN", "$.", "PTKNEG", "ADV", "ADV", "VVINF", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "auch einmal ausschlafen \u2013 reisen k\u00f6nnen \u2013", "tokens": ["auch", "ein\u00b7mal", "aus\u00b7schla\u00b7fen", "\u2013", "rei\u00b7sen", "k\u00f6n\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$(", "VVINF", "VMINF", "$("], "meter": "++-+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "sich auch einmal \u00dcberfl\u00fcssiges g\u00f6nnen.", "tokens": ["sich", "auch", "ein\u00b7mal", "\u00dc\u00b7berf\u00b7l\u00fcs\u00b7si\u00b7ges", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "NN", "VVINF", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Nicht immer nur Tag-f\u00fcr-Tag-Arbeiter,", "tokens": ["Nicht", "im\u00b7mer", "nur", "Tag\u00b7f\u00fcr\u00b7Tag\u00b7A\u00b7rbei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "ein bi\u00dfchen mehr, ein bi\u00dfchen weiter . . .", "tokens": ["ein", "bi\u00df\u00b7chen", "mehr", ",", "ein", "bi\u00df\u00b7chen", "wei\u00b7ter", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "PIS", "ADV", "$,", "ART", "PIS", "PTKVZ", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Sein Auskommen haben, jahraus, jahrein . . . ?", "tokens": ["Sein", "Aus\u00b7kom\u00b7men", "ha\u00b7ben", ",", "ja\u00b7hraus", ",", "ja\u00b7hrein", ".", ".", ".", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$,", "ADV", "$,", "PTKANT", "$.", "$.", "$.", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Es ist alles eine Nummer zu klein.", "tokens": ["Es", "ist", "al\u00b7les", "ei\u00b7ne", "Num\u00b7mer", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ART", "NN", "PTKA", "ADJD", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.16": {"text": "Hunger nach Farben, nach der Welt, die so weit \u2013", "tokens": ["Hun\u00b7ger", "nach", "Far\u00b7ben", ",", "nach", "der", "Welt", ",", "die", "so", "weit", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "$("], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.17": {"text": "Kurz: das Gef\u00fchl der Popligkeit.", "tokens": ["Kurz", ":", "das", "Ge\u00b7f\u00fchl", "der", "Pop\u00b7lig\u00b7keit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "ART", "NN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Eine alte, ewig b\u00f6se Geschichte.", "tokens": ["Ei\u00b7ne", "al\u00b7te", ",", "e\u00b7wig", "b\u00f6\u00b7se", "Ge\u00b7schich\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Aber dar\u00fcber macht man keine Gedichte.", "tokens": ["A\u00b7ber", "da\u00b7r\u00fc\u00b7ber", "macht", "man", "kei\u00b7ne", "Ge\u00b7dich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "PIAT", "NN", "$."], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}}}}}