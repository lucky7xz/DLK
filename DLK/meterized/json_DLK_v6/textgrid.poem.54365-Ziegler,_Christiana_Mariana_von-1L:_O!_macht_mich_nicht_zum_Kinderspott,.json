{"textgrid.poem.54365": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: O! macht mich nicht zum Kinderspott,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O! macht mich nicht zum Kinderspott,", "tokens": ["O", "!", "macht", "mich", "nicht", "zum", "Kin\u00b7der\u00b7spott", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor alt zu thun bewahr mich Gott,", "tokens": ["Vor", "alt", "zu", "thun", "be\u00b7wahr", "mich", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PTKZU", "VVINF", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das kommt mir niemals in den Sinn,", "tokens": ["Das", "kommt", "mir", "nie\u00b7mals", "in", "den", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wahr ich ehr- und redlich bin.", "tokens": ["So", "wahr", "ich", "ehr", "und", "red\u00b7lich", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "TRUNC", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die losen M\u00e4uler in der Stadt,", "tokens": ["Die", "lo\u00b7sen", "M\u00e4u\u00b7ler", "in", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und was sonst ein gut Herze hat,", "tokens": ["Und", "was", "sonst", "ein", "gut", "Her\u00b7ze", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ART", "ADJD", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die alle machen ein Geschrey", "tokens": ["Die", "al\u00b7le", "ma\u00b7chen", "ein", "Ge\u00b7schrey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als ob ich nicht wie vormals sey.", "tokens": ["Als", "ob", "ich", "nicht", "wie", "vor\u00b7mals", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PTKNEG", "KOKOM", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich liebe noch den Lautenschlag,", "tokens": ["Ich", "lie\u00b7be", "noch", "den", "Lau\u00b7ten\u00b7schlag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sing, und spiele Tag vor Tag.", "tokens": ["Ich", "sing", ",", "und", "spie\u00b7le", "Tag", "vor", "Tag", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An Zuspruch f\u00e4llt kein Mangel ein,", "tokens": ["An", "Zu\u00b7spruch", "f\u00e4llt", "kein", "Man\u00b7gel", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir m\u00fcssen oft beysammen seyn.", "tokens": ["Wir", "m\u00fcs\u00b7sen", "oft", "bey\u00b7sam\u00b7men", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Sch\u00e4fer scherzen wie zuvor,", "tokens": ["Die", "Sch\u00e4\u00b7fer", "scher\u00b7zen", "wie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KOKOM", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Nymphen schliessen mit den Chor;", "tokens": ["Die", "Nym\u00b7phen", "schlies\u00b7sen", "mit", "den", "Chor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Atalantens muntrer Kopf", "tokens": ["Und", "A\u00b7tal\u00b7an\u00b7tens", "mun\u00b7trer", "Kopf"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gleicht keinem Grill und Sauertopf.", "tokens": ["Gleicht", "kei\u00b7nem", "Grill", "und", "Sau\u00b7er\u00b7topf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach Damon denke nicht darauf,", "tokens": ["Ach", "Da\u00b7mon", "den\u00b7ke", "nicht", "da\u00b7rauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als hieng ich meine Leyer auf;", "tokens": ["Als", "hieng", "ich", "mei\u00b7ne", "Le\u00b7yer", "auf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein Kiel ist noch nicht aus gespritzt,", "tokens": ["Mein", "Kiel", "ist", "noch", "nicht", "aus", "ge\u00b7spritzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob Momus gleich die Feder spitzt.", "tokens": ["Ob", "Mo\u00b7mus", "gleich", "die", "Fe\u00b7der", "spitzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was willst du mit dem Psaltergsang?", "tokens": ["Was", "willst", "du", "mit", "dem", "Psal\u00b7ter\u00b7gsang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dergleichen armer S\u00fcnder Klang", "tokens": ["Derg\u00b7lei\u00b7chen", "ar\u00b7mer", "S\u00fcn\u00b7der", "Klang"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geh\u00f6rt vor N\u00e4scher insgemein,", "tokens": ["Ge\u00b7h\u00f6rt", "vor", "N\u00e4\u00b7scher", "ins\u00b7ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die schwach und satt von S\u00fcnden seyn.", "tokens": ["Die", "schwach", "und", "satt", "von", "S\u00fcn\u00b7den", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Du r\u00fchmst an mir ein hohes Herz,", "tokens": ["Du", "r\u00fchmst", "an", "mir", "ein", "ho\u00b7hes", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und das vergeht sich nicht im Scherz:", "tokens": ["Und", "das", "ver\u00b7geht", "sich", "nicht", "im", "Scherz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PRF", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wacht in sp\u00e4ter Jahre Lauf", "tokens": ["So", "wacht", "in", "sp\u00e4\u00b7ter", "Jah\u00b7re", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht erst ein b\u00f6s Gewissen auf.", "tokens": ["Nicht", "erst", "ein", "b\u00f6s", "Ge\u00b7wis\u00b7sen", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Gesetzt, ich n\u00e4hm auch einen Mann,", "tokens": ["Ge\u00b7setzt", ",", "ich", "n\u00e4hm", "auch", "ei\u00b7nen", "Mann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den man zum Nestor stellen kann,", "tokens": ["Den", "man", "zum", "Nes\u00b7tor", "stel\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So folgt doch lange noch nicht draus,", "tokens": ["So", "folgt", "doch", "lan\u00b7ge", "noch", "nicht", "draus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADV", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als w\u00e4r mit mir gleich alles aus.", "tokens": ["Als", "w\u00e4r", "mit", "mir", "gleich", "al\u00b7les", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "APPR", "PPER", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Kurz, meine Feder braucht gar nicht,", "tokens": ["Kurz", ",", "mei\u00b7ne", "Fe\u00b7der", "braucht", "gar", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sie hierinn ein Urtheil spricht.", "tokens": ["Da\u00df", "sie", "hie\u00b7rinn", "ein", "Ur\u00b7theil", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Vorwurf gehet mich nichts an,", "tokens": ["Der", "Vor\u00b7wurf", "ge\u00b7het", "mich", "nichts", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil ich kein Theil dran nehmen kann.", "tokens": ["Weil", "ich", "kein", "Theil", "dran", "neh\u00b7men", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "PAV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Mein Wittwenstand bleibt noch bestehn,", "tokens": ["Mein", "Witt\u00b7wen\u00b7stand", "bleibt", "noch", "be\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sehne mich nicht draus zugehn:", "tokens": ["Ich", "seh\u00b7ne", "mich", "nicht", "draus", "zu\u00b7gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "PAV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Freyheit ist ein edles Ding,", "tokens": ["Die", "Frey\u00b7heit", "ist", "ein", "ed\u00b7les", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie schwer ist der Verm\u00e4hlungsring.", "tokens": ["Wie", "schwer", "ist", "der", "Ver\u00b7m\u00e4h\u00b7lungs\u00b7ring", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Umgang, den man t\u00e4glich hat,", "tokens": ["Der", "Um\u00b7gang", ",", "den", "man", "t\u00e4g\u00b7lich", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ein vom Freund beschriebnes Blat", "tokens": ["Und", "ein", "vom", "Freund", "be\u00b7schrieb\u00b7nes", "Blat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPRART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vergn\u00fcgen mich, und noch weit mehr,", "tokens": ["Ver\u00b7gn\u00fc\u00b7gen", "mich", ",", "und", "noch", "weit", "mehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "KON", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenn ich in dem Keficht w\u00e4r.", "tokens": ["Als", "wenn", "ich", "in", "dem", "Ke\u00b7ficht", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}