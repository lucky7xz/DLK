{"dta.poem.9405": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "La\u00dfet uns Meyen und Kr\u00e4ntze bereiten/", "tokens": ["La\u00b7\u00dfet", "uns", "Me\u00b7yen", "und", "Kr\u00e4nt\u00b7ze", "be\u00b7rei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "KON", "NN", "VVINF", "$("], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sehet/ ach sehet die fr\u00f6lichen Zeiten!", "tokens": ["Se\u00b7het", "/", "ach", "se\u00b7het", "die", "fr\u00f6\u00b7li\u00b7chen", "Zei\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Sehet/ jhr Br\u00fcder/ und mercket hierbey/", "tokens": ["Se\u00b7het", "/", "jhr", "Br\u00fc\u00b7der", "/", "und", "mer\u00b7cket", "hier\u00b7bey", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PPOSAT", "NN", "$(", "KON", "VVFIN", "ADV", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Welche ver\u00e4nderung solches nur sey.", "tokens": ["Wel\u00b7che", "ver\u00b7\u00e4n\u00b7de\u00b7rung", "sol\u00b7ches", "nur", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PIAT", "ADV", "VAFIN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.2": {"line.1": {"text": "La\u00dfet uns Weinen und Trauren vertreiben/", "tokens": ["La\u00b7\u00dfet", "uns", "Wei\u00b7nen", "und", "Trau\u00b7ren", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Klagen und zagen soll heute verbleiben/", "tokens": ["Kla\u00b7gen", "und", "za\u00b7gen", "soll", "heu\u00b7te", "ver\u00b7blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "ADV", "VVINF", "$("], "meter": "+--+-+---+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Klagen und zagen veriaget jtzunb/", "tokens": ["Kla\u00b7gen", "und", "za\u00b7gen", "ve\u00b7ria\u00b7get", "jt\u00b7zunb", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "VVFIN", "ADV", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Heute seyd lustig und machet es kunt.", "tokens": ["Heu\u00b7te", "seyd", "lus\u00b7tig", "und", "ma\u00b7chet", "es", "kunt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.3": {"line.1": {"text": "La\u00dfet uns Zucker und Honig bestellen/", "tokens": ["La\u00b7\u00dfet", "uns", "Zu\u00b7cker", "und", "Ho\u00b7nig", "be\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "La\u00dfet uns holen die guten Gesellen/", "tokens": ["La\u00b7\u00dfet", "uns", "ho\u00b7len", "die", "gu\u00b7ten", "Ge\u00b7sel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "La\u00dfet herbringen den Spanischen Wein/", "tokens": ["La\u00b7\u00dfet", "her\u00b7brin\u00b7gen", "den", "Spa\u00b7ni\u00b7schen", "Wein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Weil wir anitzo beysammen hier seyn.", "tokens": ["Weil", "wir", "a\u00b7nit\u00b7zo", "bey\u00b7sam\u00b7men", "hier", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "VAINF", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}}, "stanza.4": {"line.1": {"text": "La\u00dfet uns b\u00fcrckene Meyer bestellen/", "tokens": ["La\u00b7\u00dfet", "uns", "b\u00fcr\u00b7cke\u00b7ne", "Me\u00b7yer", "be\u00b7stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Da\u00df wir Euch schencken Jhr guten Gesellen/", "tokens": ["Da\u00df", "wir", "Euch", "schen\u00b7cken", "Ihr", "gu\u00b7ten", "Ge\u00b7sel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "La\u00dfet den b\u00fcrckenen Meyer r\u00fcmbgehn/", "tokens": ["La\u00b7\u00dfet", "den", "b\u00fcr\u00b7cke\u00b7nen", "Me\u00b7yer", "r\u00fcmb\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "La\u00dfet die Gl\u00e4ser nicht stille so stehn.", "tokens": ["La\u00b7\u00dfet", "die", "Gl\u00e4\u00b7ser", "nicht", "stil\u00b7le", "so", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "VVFIN", "ADV", "VVINF", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00dfet den Malvasier heute besuchen/", "tokens": ["La\u00b7\u00dfet", "den", "Mal\u00b7va\u00b7sier", "heu\u00b7te", "be\u00b7su\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "La\u00dfet aufftragen Pasteten und Kuchen/", "tokens": ["La\u00b7\u00dfet", "auff\u00b7tra\u00b7gen", "Pas\u00b7te\u00b7ten", "und", "Ku\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "KON", "NN", "$("], "meter": "+-+--+---+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Gebet uns Gl\u00e4ser und Kr\u00fcge voll Bier/", "tokens": ["Ge\u00b7bet", "uns", "Gl\u00e4\u00b7ser", "und", "Kr\u00fc\u00b7ge", "voll", "Bier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "KON", "NN", "ADJD", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Weil wir anjtzo beysammen allhier.", "tokens": ["Weil", "wir", "anjt\u00b7zo", "bey\u00b7sam\u00b7men", "all\u00b7hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "--+-++--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "La\u00dfet die Lauten und Geigen erklingen/", "tokens": ["La\u00b7\u00dfet", "die", "Lau\u00b7ten", "und", "Gei\u00b7gen", "er\u00b7klin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "NN", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "La\u00dfet uns eylen zum tantze/ zum springen/", "tokens": ["La\u00b7\u00dfet", "uns", "ey\u00b7len", "zum", "tant\u00b7ze", "/", "zum", "sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "VVFIN", "$(", "APPRART", "VVINF", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "Nehmer die Kegel und bo\u00dfel in acht/", "tokens": ["Neh\u00b7mer", "die", "Ke\u00b7gel", "und", "bo\u00b7\u00dfel", "in", "acht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "APPR", "CARD", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "La\u00dfet uns spielen/ bi\u00df kommet die Nacht.", "tokens": ["La\u00b7\u00dfet", "uns", "spie\u00b7len", "/", "bi\u00df", "kom\u00b7met", "die", "Nacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "$(", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.7": {"line.1": {"text": "La\u00dfet uns geistlich- und weltliche Lieder", "tokens": ["La\u00b7\u00dfet", "uns", "geist\u00b7lich", "und", "welt\u00b7li\u00b7che", "Lie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "TRUNC", "KON", "ADJA", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Klingen und singen/ jhr lustigen Br\u00fcder/", "tokens": ["Klin\u00b7gen", "und", "sin\u00b7gen", "/", "jhr", "lus\u00b7ti\u00b7gen", "Br\u00fc\u00b7der", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "La\u00dfet uns letzen/ die Jugend vergcht/", "tokens": ["La\u00b7\u00dfet", "uns", "let\u00b7zen", "/", "die", "Ju\u00b7gend", "vergcht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "$(", "ART", "NN", "VVPP", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Wehmuth und trauren im Alter entsteht!", "tokens": ["Weh\u00b7muth", "und", "trau\u00b7ren", "im", "Al\u00b7ter", "ent\u00b7steht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}}}}