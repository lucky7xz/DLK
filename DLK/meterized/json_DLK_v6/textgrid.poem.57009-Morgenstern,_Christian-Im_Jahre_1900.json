{"textgrid.poem.57009": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Im Jahre 1900", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Ameisen oder Emsen", "tokens": ["Die", "A\u00b7mei\u00b7sen", "o\u00b7der", "Em\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sind so weit jetzt, da\u00df sie Gemsen", "tokens": ["sind", "so", "weit", "jetzt", ",", "da\u00df", "sie", "Gem\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "ADV", "$,", "KOUS", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sich als Sklaven halten (aus", "tokens": ["sich", "als", "Skla\u00b7ven", "hal\u00b7ten", "(", "aus"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PRF", "KOUS", "NN", "VVINF", "$(", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Gr\u00fcnden ihres K\u00f6rperbaus).", "tokens": ["Gr\u00fcn\u00b7den", "ih\u00b7res", "K\u00f6r\u00b7per\u00b7baus", ")", "."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Da sie selber sehr viel kleiner,", "tokens": ["Da", "sie", "sel\u00b7ber", "sehr", "viel", "klei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "so bedienen sie sich einer", "tokens": ["so", "be\u00b7die\u00b7nen", "sie", "sich", "ei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gemse oder zweier Gemsen", "tokens": ["Gem\u00b7se", "o\u00b7der", "zwei\u00b7er", "Gem\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "zu Gebirgspartien, die Emsen.", "tokens": ["zu", "Ge\u00b7birgs\u00b7par\u00b7ti\u00b7en", ",", "die", "Em\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ART", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Ist sodann ein Adlernest", "tokens": ["Ist", "so\u00b7dann", "ein", "Ad\u00b7ler\u00b7nest"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "abgesucht bis auf den Rest,", "tokens": ["ab\u00b7ge\u00b7sucht", "bis", "auf", "den", "Rest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "gehn sie endlich, zog der Weih", "tokens": ["gehn", "sie", "end\u00b7lich", ",", "zog", "der", "Weih"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "schon den Ameisb\u00e4ren bei,", "tokens": ["schon", "den", "A\u00b7meis\u00b7b\u00e4\u00b7ren", "bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "wieder ihm aus Horst und Rock \u2013", "tokens": ["wie\u00b7der", "ihm", "aus", "Horst", "und", "Rock", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NE", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und besteigen ihren Bock,", "tokens": ["und", "be\u00b7stei\u00b7gen", "ih\u00b7ren", "Bock", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der sie, wie ein Stein, der springt,", "tokens": ["der", "sie", ",", "wie", "ein", "Stein", ",", "der", "springt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "PWAV", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "heim zu ihrem H\u00fcgel bringt.", "tokens": ["heim", "zu", "ih\u00b7rem", "H\u00fc\u00b7gel", "bringt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Angepfl\u00f6ckt, so stehn die Gemsen", "tokens": ["An\u00b7ge\u00b7pfl\u00f6ckt", ",", "so", "stehn", "die", "Gem\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der N\u00e4he dort der Emsen,", "tokens": ["In", "der", "N\u00e4\u00b7he", "dort", "der", "Em\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "bei den L\u00e4usen u.s.w.", "tokens": ["bei", "den", "L\u00e4u\u00b7sen", "u.", "s.", "w."], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "abbreviation"], "pos": ["APPR", "ART", "NN", "APPR", "VVIMP", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "und verw\u00fcnschen ihre Reiter.", "tokens": ["und", "ver\u00b7w\u00fcn\u00b7schen", "ih\u00b7re", "Rei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}