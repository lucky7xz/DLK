{"textgrid.poem.41378": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Die Henne und der Smaragd", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Gl\u00fcckes h\u00e4mscher Eigensinn", "tokens": ["Des", "Gl\u00fc\u00b7ckes", "h\u00e4m\u00b7scher", "Ei\u00b7gen\u00b7sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wirft viele Sch\u00e4tze dieser Erden", "tokens": ["Wirft", "vie\u00b7le", "Sch\u00e4t\u00b7ze", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "PDAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Unw\u00fcrdigen Besitzern hin,", "tokens": ["Un\u00b7w\u00fcr\u00b7di\u00b7gen", "Be\u00b7sit\u00b7zern", "hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Durch Reichthum l\u00e4cherlich zu werden.", "tokens": ["Durch", "Reicht\u00b7hum", "l\u00e4\u00b7cher\u00b7lich", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wo findet beides sich zugleich:", "tokens": ["Wo", "fin\u00b7det", "bei\u00b7des", "sich", "zu\u00b7gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PIS", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geld und Verstand zu edlen Thaten?", "tokens": ["Geld", "und", "Ver\u00b7stand", "zu", "ed\u00b7len", "Tha\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vielleicht im tausendj\u00e4hrgen Reich,", "tokens": ["Viel\u00b7leicht", "im", "tau\u00b7send\u00b7j\u00e4hr\u00b7gen", "Reich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Wahrheit nicht in unsern Staaten.", "tokens": ["In", "Wahr\u00b7heit", "nicht", "in", "un\u00b7sern", "Staa\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Aus eines Bischofs Schatz verlor sich ein Smaragd,", "tokens": ["Aus", "ei\u00b7nes", "Bi\u00b7schofs", "Schatz", "ver\u00b7lor", "sich", "ein", "Sma\u00b7ragd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In dem ein helles Gr\u00fcn mit reinen Farben spielte,", "tokens": ["In", "dem", "ein", "hel\u00b7les", "Gr\u00fcn", "mit", "rei\u00b7nen", "Far\u00b7ben", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den, wegen strahlenreicher Pracht,", "tokens": ["Den", ",", "we\u00b7gen", "strah\u00b7len\u00b7rei\u00b7cher", "Pracht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein jeder, der ihn sah, f\u00fcr unvergleichlich hielte.", "tokens": ["Ein", "je\u00b7der", ",", "der", "ihn", "sah", ",", "f\u00fcr", "un\u00b7ver\u00b7gleich\u00b7lich", "hiel\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "APPR", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Dies Kleinod fand ein weiblich Thier,", "tokens": ["Dies", "Klei\u00b7nod", "fand", "ein", "weib\u00b7lich", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das von dem leichten Volk, so sich in Federn kleidet,", "tokens": ["Das", "von", "dem", "leich\u00b7ten", "Volk", ",", "so", "sich", "in", "Fe\u00b7dern", "klei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN", "$,", "ADV", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Kammes kronengleiche Zier,", "tokens": ["Des", "Kam\u00b7mes", "kro\u00b7nen\u00b7glei\u00b7che", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Wachsamkeit (die Phyllis nie beneidet)", "tokens": ["Die", "Wach\u00b7sam\u00b7keit", "(", "die", "Phyl\u00b7lis", "nie", "be\u00b7nei\u00b7det", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und treue Dummheit unterscheidet;", "tokens": ["Und", "treu\u00b7e", "Dumm\u00b7heit", "un\u00b7ter\u00b7schei\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Das blinde G\u00fctigkeit von guten M\u00e4nnern borgt,", "tokens": ["Das", "blin\u00b7de", "G\u00fc\u00b7tig\u00b7keit", "von", "gu\u00b7ten", "M\u00e4n\u00b7nern", "borgt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Junge fremder Art, als seine Zucht, versorgt.", "tokens": ["Und", "Jun\u00b7ge", "frem\u00b7der", "Art", ",", "als", "sei\u00b7ne", "Zucht", ",", "ver\u00b7sorgt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "$,", "KOUS", "PPOSAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Was that die Henne hier? Sie fand.", "tokens": ["Was", "that", "die", "Hen\u00b7ne", "hier", "?", "Sie", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "$.", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie fand; und finden ist die Kunst von vielen Erben;", "tokens": ["Sie", "fand", ";", "und", "fin\u00b7den", "ist", "die", "Kunst", "von", "vie\u00b7len", "Er\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KON", "VVINF", "VAFIN", "ART", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch beider Fund wird \u00fcbel angewandt:", "tokens": ["Doch", "bei\u00b7der", "Fund", "wird", "\u00fc\u00b7bel", "an\u00b7ge\u00b7wandt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn jene scharrt den Stein in Sand,", "tokens": ["Denn", "je\u00b7ne", "scharrt", "den", "Stein", "in", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und diesen kann ihr Gut kein wahres Gl\u00fcck erwerben.", "tokens": ["Und", "die\u00b7sen", "kann", "ihr", "Gut", "kein", "wah\u00b7res", "Gl\u00fcck", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PPER", "ADJD", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Fabel von dem Huhn und von dem Diamant", "tokens": ["Die", "Fa\u00b7bel", "von", "dem", "Huhn", "und", "von", "dem", "Di\u00b7a\u00b7mant"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "War mir und dir und tausenden bekannt.", "tokens": ["War", "mir", "und", "dir", "und", "tau\u00b7sen\u00b7den", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "PPER", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Freund! den Einwurf kannst du sparen.", "tokens": ["Mein", "Freund", "!", "den", "Ein\u00b7wurf", "kannst", "du", "spa\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ART", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie war bekannt vor tausend Jahren:", "tokens": ["Sie", "war", "be\u00b7kannt", "vor", "tau\u00b7send", "Jah\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr \u00e4ndert nur mein Reim die \u00e4u\u00dfere Gestalt;", "tokens": ["Ihr", "\u00e4n\u00b7dert", "nur", "mein", "Reim", "die", "\u00e4u\u00b7\u00dfe\u00b7re", "Ge\u00b7stalt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und keine Wahrheit wird zu alt.", "tokens": ["Und", "kei\u00b7ne", "Wahr\u00b7heit", "wird", "zu", "alt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}