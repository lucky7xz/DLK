{"textgrid.poem.42926": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "M\u00fcder Juniabend", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bl\u00fchende Kastanienzweige", "tokens": ["Bl\u00fc\u00b7hen\u00b7de", "Kas\u00b7ta\u00b7ni\u00b7en\u00b7zwei\u00b7ge"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Strecken ihre Tatzen vor.", "tokens": ["Stre\u00b7cken", "ih\u00b7re", "Tat\u00b7zen", "vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn ich jetzt das rechte Ohr,", "tokens": ["Wenn", "ich", "jetzt", "das", "rech\u00b7te", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil es taub ist, r\u00fcckw\u00e4rts neige,", "tokens": ["Weil", "es", "taub", "ist", ",", "r\u00fcck\u00b7w\u00e4rts", "nei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00f6re ich einen Spatzenchor.", "tokens": ["H\u00f6\u00b7re", "ich", "ei\u00b7nen", "Spat\u00b7zen\u00b7chor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Weil mich dessen Pl\u00e4rr so kalt", "tokens": ["Weil", "mich", "des\u00b7sen", "Pl\u00e4rr", "so", "kalt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "NN", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4\u00dft, und angeregt von Tatzen,", "tokens": ["L\u00e4\u00dft", ",", "und", "an\u00b7ge\u00b7regt", "von", "Tat\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVPP", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Suche ich jetzt mit Gewalt", "tokens": ["Su\u00b7che", "ich", "jetzt", "mit", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Pickel aufzukratzen,", "tokens": ["Ei\u00b7nen", "Pi\u00b7ckel", "auf\u00b7zu\u00b7krat\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der im Grund zwar noch nicht reif ist,", "tokens": ["Der", "im", "Grund", "zwar", "noch", "nicht", "reif", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ADV", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Doch mich hinten an der Scharte,", "tokens": ["Doch", "mich", "hin\u00b7ten", "an", "der", "Schar\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wo beim Affen noch der Schweif ist,", "tokens": ["Wo", "beim", "Af\u00b7fen", "noch", "der", "Schweif", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Schikaniert. Da pl\u00f6tzlich zischt", "tokens": ["Schi\u00b7ka\u00b7niert", ".", "Da", "pl\u00f6tz\u00b7lich", "zischt"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "ADV", "ADJD", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Schnupfen in die Speisekarte.", "tokens": ["Schnup\u00b7fen", "in", "die", "Spei\u00b7se\u00b7kar\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Rasches Taschentuch verwischt", "tokens": ["Ra\u00b7sches", "Ta\u00b7schen\u00b7tuch", "ver\u00b7wischt"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Rotz und Preise der Gem\u00fcse", "tokens": ["Rotz", "und", "Prei\u00b7se", "der", "Ge\u00b7m\u00fc\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Salate. Und ich gr\u00fc\u00dfe", "tokens": ["Und", "Sa\u00b7la\u00b7te", ".", "Und", "ich", "gr\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NE", "$.", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Dame, die vorbeigeht", "tokens": ["Ei\u00b7ne", "Da\u00b7me", ",", "die", "vor\u00b7bei\u00b7geht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Und mich kennt, mir auch gef\u00e4llt.", "tokens": ["Und", "mich", "kennt", ",", "mir", "auch", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wobei leise was entzweigeht,", "tokens": ["Wo\u00b7bei", "lei\u00b7se", "was", "ent\u00b7zwei\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PWS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Was den Hosentr\u00e4ger h\u00e4lt.", "tokens": ["Was", "den", "Ho\u00b7sen\u00b7tr\u00e4\u00b7ger", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}