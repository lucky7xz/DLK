{"dta.poem.18621": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n Aut ad Doctorem Ducit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Wiewohl man hat noch einen Fund ersonnen/", "tokens": ["Wie\u00b7wohl", "man", "hat", "noch", "ei\u00b7nen", "Fund", "er\u00b7son\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VAFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn alles nun zerronnen/", "tokens": ["Wenn", "al\u00b7les", "nun", "zer\u00b7ron\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So sucht ein Luder sich ein liederliches Weib/", "tokens": ["So", "sucht", "ein", "Lu\u00b7der", "sich", "ein", "lie\u00b7der\u00b7li\u00b7ches", "Weib", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das wacker Pfenn'ge hat/", "tokens": ["Das", "wa\u00b7cker", "Pfenn'\u00b7ge", "hat", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dadurch erkaufft er sich den Doctor Grad.", "tokens": ["Da\u00b7durch", "er\u00b7kaufft", "er", "sich", "den", "Doc\u00b7tor", "Grad", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Da tr\u00e4get nun der Esel eine Crone.", "tokens": ["Da", "tr\u00e4\u00b7get", "nun", "der", "E\u00b7sel", "ei\u00b7ne", "Cro\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ein Ochse kriegt der Wei\u00dfheit edlen Hut.", "tokens": ["Ein", "O\u00b7chse", "kriegt", "der", "Wei\u00df\u00b7heit", "ed\u00b7len", "Hut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ein Schwein erlangt den ersten Rang", "tokens": ["Ein", "Schwein", "er\u00b7langt", "den", "ers\u00b7ten", "Rang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Seht was der Hencker thut.", "tokens": ["Seht", "was", "der", "Hen\u00b7cker", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Wer wolte sich nicht desperat geberden/", "tokens": ["Wer", "wol\u00b7te", "sich", "nicht", "des\u00b7pe\u00b7rat", "ge\u00b7ber\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wenn man kan Doctor werden.", "tokens": ["Wenn", "man", "kan", "Doc\u00b7tor", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VMFIN", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "So richtet nun das Sprichwort also ein:", "tokens": ["So", "rich\u00b7tet", "nun", "das", "Sprich\u00b7wort", "al\u00b7so", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Soldate M\u00fcnch und Doctor Titel", "tokens": ["Sol\u00b7da\u00b7te", "M\u00fcnch", "und", "Doc\u00b7tor", "Ti\u00b7tel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "NE", "KON", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Das m\u00fcssen die extremen Mittel", "tokens": ["Das", "m\u00fcs\u00b7sen", "die", "ext\u00b7re\u00b7men", "Mit\u00b7tel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.15": {"text": "Vor desperate Kerles seyn.", "tokens": ["Vor", "des\u00b7pe\u00b7ra\u00b7te", "Ker\u00b7les", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}