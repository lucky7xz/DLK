{"dta.poem.20386": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "An Sr. Excellentz/  \n den Herrn geheimden Rath Stryck/  \n \u00fcber die verm\u00e4hlung seines Herrn Sohns/ mit  \n Tit. Jungf. Alexanderin.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich habe/ grosser mann/ zehn jahre dich gekannt/", "tokens": ["Ich", "ha\u00b7be", "/", "gros\u00b7ser", "mann", "/", "zehn", "jah\u00b7re", "dich", "ge\u00b7kannt", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "ADJA", "NN", "$(", "CARD", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und drey jahr dich geh\u00f6rt; gleichwohl ist meine hand/", "tokens": ["Und", "drey", "jahr", "dich", "ge\u00b7h\u00f6rt", ";", "gleich\u00b7wohl", "ist", "mei\u00b7ne", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "PPER", "VVFIN", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die manchem st\u00fcmper offt ein ehren-lied geschrieben/", "tokens": ["Die", "man\u00b7chem", "st\u00fcm\u00b7per", "offt", "ein", "eh\u00b7ren\u00b7lied", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dir dein verdientes lob mit fleisse schuldig blieben.", "tokens": ["Dir", "dein", "ver\u00b7dien\u00b7tes", "lob", "mit", "fleis\u00b7se", "schul\u00b7dig", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit fleisse denckestu? Ja/ grosser Stryck/ mit flei\u00df;", "tokens": ["Mit", "fleis\u00b7se", "den\u00b7ckes\u00b7tu", "?", "Ja", "/", "gros\u00b7ser", "Stryck", "/", "mit", "flei\u00df", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PDS", "$.", "PTKANT", "$(", "ADJA", "NN", "$(", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn du hast alles zwar/ was man zu r\u00fchmen wei\u00df.", "tokens": ["Denn", "du", "hast", "al\u00b7les", "zwar", "/", "was", "man", "zu", "r\u00fch\u00b7men", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIS", "ADV", "$(", "PWS", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die mutter hat dich nicht mit grober milch erzogen;", "tokens": ["Die", "mut\u00b7ter", "hat", "dich", "nicht", "mit", "gro\u00b7ber", "milch", "er\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PTKNEG", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Musen sind dir mehr/ als du begehrst/ gewogen/", "tokens": ["Die", "Mu\u00b7sen", "sind", "dir", "mehr", "/", "als", "du", "be\u00b7gehrst", "/", "ge\u00b7wo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "VVFIN", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und gehn/ wohin du ziehst/ mit vollem hauffen nach.", "tokens": ["Und", "gehn", "/", "wo\u00b7hin", "du", "ziehst", "/", "mit", "vol\u00b7lem", "hauf\u00b7fen", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "PWAV", "PPER", "VVFIN", "$(", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dein thun ist wohlbedacht/ und wie ein stiller bach/", "tokens": ["Dein", "thun", "ist", "wohl\u00b7be\u00b7dacht", "/", "und", "wie", "ein", "stil\u00b7ler", "bach", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVINF", "VAFIN", "ADJD", "$(", "KON", "PWAV", "ART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der kein ger\u00e4usche macht/ und doch mehr nutzen bringet/", "tokens": ["Der", "kein", "ge\u00b7r\u00e4u\u00b7sche", "macht", "/", "und", "doch", "mehr", "nut\u00b7zen", "brin\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "VVFIN", "$(", "KON", "ADV", "ADV", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Als mancher wilder strohm/ der wall und tamm durchdringet.", "tokens": ["Als", "man\u00b7cher", "wil\u00b7der", "strohm", "/", "der", "wall", "und", "tamm", "durch\u00b7drin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "$(", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nechst diesem bist du sch\u00f6n und herrlich anzusehn/", "tokens": ["Nechst", "die\u00b7sem", "bist", "du", "sch\u00f6n", "und", "herr\u00b7lich", "an\u00b7zu\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "VVIZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und darffst die worte nicht erst in dem munde drehn/", "tokens": ["Und", "darffst", "die", "wor\u00b7te", "nicht", "erst", "in", "dem", "mun\u00b7de", "drehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "NN", "PTKNEG", "ADV", "APPR", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nicht auff die n\u00e4gel schaun/ nicht mit dem halse dehnen/", "tokens": ["Nicht", "auff", "die", "n\u00e4\u00b7gel", "schaun", "/", "nicht", "mit", "dem", "hal\u00b7se", "deh\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVINF", "$(", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und gantze tackte lang an einer sylbe stehnen.", "tokens": ["Und", "gant\u00b7ze", "tack\u00b7te", "lang", "an", "ei\u00b7ner", "syl\u00b7be", "steh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Denn deine wissenschafft ist lauter werck und that/", "tokens": ["Denn", "dei\u00b7ne", "wis\u00b7sen\u00b7schafft", "ist", "lau\u00b7ter", "werck", "und", "that", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PIAT", "NN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und wei\u00df nicht/ wie dem ist/ der viel gelesen hat/", "tokens": ["Und", "wei\u00df", "nicht", "/", "wie", "dem", "ist", "/", "der", "viel", "ge\u00b7le\u00b7sen", "hat", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$(", "KOKOM", "PDS", "VAFIN", "$(", "ART", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der einen b\u00fccher-kram in seinem kopffe tr\u00e4get/", "tokens": ["Der", "ei\u00b7nen", "b\u00fc\u00b7cher\u00b7kram", "in", "sei\u00b7nem", "kopf\u00b7fe", "tr\u00e4\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und dennoch alle krafft mit ihnen niederleget.", "tokens": ["Und", "den\u00b7noch", "al\u00b7le", "krafft", "mit", "ih\u00b7nen", "nie\u00b7der\u00b7le\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Mit kurtzem: die natur hat/ da sie dich gemacht/", "tokens": ["Mit", "kurt\u00b7zem", ":", "die", "na\u00b7tur", "hat", "/", "da", "sie", "dich", "ge\u00b7macht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$.", "ART", "NN", "VAFIN", "$(", "KOUS", "PPER", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Mehr auff ein wunderwerck als einen mensch gedacht;", "tokens": ["Mehr", "auff", "ein", "wun\u00b7der\u00b7werck", "als", "ei\u00b7nen", "mensch", "ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KOKOM", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und hat/ was sieben sonst besonders haben sollen/", "tokens": ["Und", "hat", "/", "was", "sie\u00b7ben", "sonst", "be\u00b7son\u00b7ders", "ha\u00b7ben", "sol\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$(", "PWS", "VVFIN", "ADV", "ADV", "VAINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Der welt in dir allein beysammen zeigen wollen.", "tokens": ["Der", "welt", "in", "dir", "al\u00b7lein", "bey\u00b7sam\u00b7men", "zei\u00b7gen", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "ADV", "VVINF", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "So w\u00fcrdig als du bist/ so sehr wirst du geliebt/", "tokens": ["So", "w\u00fcr\u00b7dig", "als", "du", "bist", "/", "so", "sehr", "wirst", "du", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "VAFIN", "$(", "ADV", "ADV", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Kein hoff ist/ so dir nicht geneigte blicke giebt;", "tokens": ["Kein", "hoff", "ist", "/", "so", "dir", "nicht", "ge\u00b7neig\u00b7te", "bli\u00b7cke", "giebt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$(", "ADV", "PPER", "PTKNEG", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Die K\u00f6n\u2019ge suchen dich auff mehr als hundert meilen.", "tokens": ["Die", "K\u00f6n'\u00b7ge", "su\u00b7chen", "dich", "auff", "mehr", "als", "hun\u00b7dert", "mei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PIS", "KOKOM", "CARD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und liesse sich dein leib/ wie dein verstand/ zertheilen/", "tokens": ["Und", "lies\u00b7se", "sich", "dein", "leib", "/", "wie", "dein", "ver\u00b7stand", "/", "zer\u00b7thei\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "NN", "$(", "KOKOM", "PPOSAT", "VVFIN", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "So w\u00fcrdest du bereits in halb Europa seyn.", "tokens": ["So", "w\u00fcr\u00b7dest", "du", "be\u00b7reits", "in", "halb", "Eu\u00b7ro\u00b7pa", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "ADJD", "NE", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Di\u00df alles/ sag ich/ schreibt dich zwar den sternen ein/", "tokens": ["Di\u00df", "al\u00b7les", "/", "sag", "ich", "/", "schreibt", "dich", "zwar", "den", "ster\u00b7nen", "ein", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "$(", "VVIMP", "PPER", "$(", "VVFIN", "PPER", "ADV", "ART", "ADJA", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und ist wohl r\u00fchmens werth; Allein wie/ nach der lehre", "tokens": ["Und", "ist", "wohl", "r\u00fch\u00b7mens", "werth", ";", "Al\u00b7lein", "wie", "/", "nach", "der", "leh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ADJD", "$.", "ADV", "KOKOM", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Des weisen Solons/ auch bey vollem gut und ehre", "tokens": ["Des", "wei\u00b7sen", "So\u00b7lons", "/", "auch", "bey", "vol\u00b7lem", "gut", "und", "eh\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "APPR", "ADJA", "ADJD", "KON", "VVFIN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.33": {"text": "Kein mensch/ bevor er stirbt/ sich gl\u00fccklich achten kan/", "tokens": ["Kein", "mensch", "/", "be\u00b7vor", "er", "stirbt", "/", "sich", "gl\u00fcck\u00b7lich", "ach\u00b7ten", "kan", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "KOUS", "PPER", "VVFIN", "$(", "PRF", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So war hingegen ich/ und stecke noch im wahn/", "tokens": ["So", "war", "hin\u00b7ge\u00b7gen", "ich", "/", "und", "ste\u00b7cke", "noch", "im", "wahn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPER", "$(", "KON", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Da\u00df sich ein vater erst kan einen vater nennen/", "tokens": ["Da\u00df", "sich", "ein", "va\u00b7ter", "erst", "kan", "ei\u00b7nen", "va\u00b7ter", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Wenn er sich selbst nicht mehr kan vor den kindern kennen.", "tokens": ["Wenn", "er", "sich", "selbst", "nicht", "mehr", "kan", "vor", "den", "kin\u00b7dern", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "ADV", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Drum schien dein wohlseyn mir voll kummer und gefahr/", "tokens": ["Drum", "schien", "dein", "wohl\u00b7seyn", "mir", "voll", "kum\u00b7mer", "und", "ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "PPER", "ADJD", "NN", "KON", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.38": {"text": "So lange nicht dein sohn in gleichem stande war.", "tokens": ["So", "lan\u00b7ge", "nicht", "dein", "sohn", "in", "glei\u00b7chem", "stan\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "APPR", "ADJA", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Denn ob ich schon gesehn/ wie du ihn aufferzogen/", "tokens": ["Denn", "ob", "ich", "schon", "ge\u00b7sehn", "/", "wie", "du", "ihn", "auf\u00b7fer\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "$(", "PWAV", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Wie er der wei\u00dfheit milch zu Dantzig eingesogen/", "tokens": ["Wie", "er", "der", "wei\u00df\u00b7heit", "milch", "zu", "Dant\u00b7zig", "ein\u00b7ge\u00b7so\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Zu Wittenberg vor flei\u00df und eyfer offt gebrannt/", "tokens": ["Zu", "Wit\u00b7ten\u00b7berg", "vor", "flei\u00df", "und", "ey\u00b7fer", "offt", "ge\u00b7brannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "KON", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Auff reisen keinen blick unfruchtbar angewandt/", "tokens": ["Auff", "rei\u00b7sen", "kei\u00b7nen", "blick", "un\u00b7frucht\u00b7bar", "an\u00b7ge\u00b7wandt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PIAT", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und die gesundheit eh\u2019/ als seine zeit verschwendet;", "tokens": ["Und", "die", "ge\u00b7sund\u00b7heit", "eh'", "/", "als", "sei\u00b7ne", "zeit", "ver\u00b7schwen\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "$(", "KOUS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Ja/ ob ich gleich gesehn/ wie er den lauff vollendet/", "tokens": ["Ja", "/", "ob", "ich", "gleich", "ge\u00b7sehn", "/", "wie", "er", "den", "lauff", "voll\u00b7en\u00b7det", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "KOUS", "PPER", "ADV", "VVPP", "$(", "PWAV", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Sich auff die renne-bahn der lehrer schon gestellt/", "tokens": ["Sich", "auff", "die", "ren\u00b7ne\u00b7bahn", "der", "leh\u00b7rer", "schon", "ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Und di\u00df in Halle thut/ was dich in aller welt", "tokens": ["Und", "di\u00df", "in", "Hal\u00b7le", "thut", "/", "was", "dich", "in", "al\u00b7ler", "welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "APPR", "NE", "VVFIN", "$(", "PWS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Zu einem wunder macht; So fehlte seinem leben", "tokens": ["Zu", "ei\u00b7nem", "wun\u00b7der", "macht", ";", "So", "fehl\u00b7te", "sei\u00b7nem", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Doch etwas/ so ihm leicht den garaus konte geben:", "tokens": ["Doch", "et\u00b7was", "/", "so", "ihm", "leicht", "den", "ga\u00b7raus", "kon\u00b7te", "ge\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ADV", "PPER", "ADJD", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Ich meyne eine frau. Nichts ist so allgemein/", "tokens": ["Ich", "mey\u00b7ne", "ei\u00b7ne", "frau", ".", "Nichts", "ist", "so", "all\u00b7ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PIS", "VAFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Als eine nacht verm\u00e4hlt/ und schon geqv\u00e4let seyn.", "tokens": ["Als", "ei\u00b7ne", "nacht", "ver\u00b7m\u00e4hlt", "/", "und", "schon", "ge\u00b7qv\u00e4\u00b7let", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$(", "KON", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Der aussatz findet sich auch an dem sch\u00f6nsten leibe/", "tokens": ["Der", "aus\u00b7satz", "fin\u00b7det", "sich", "auch", "an", "dem", "sch\u00f6ns\u00b7ten", "lei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Und Socrates hat recht/ da\u00df mancher nur beym weibe", "tokens": ["Und", "So\u00b7cra\u00b7tes", "hat", "recht", "/", "da\u00df", "man\u00b7cher", "nur", "beym", "wei\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VAFIN", "ADJD", "$(", "KOUS", "PIS", "ADV", "APPRART", "VVFIN"], "meter": "--+----+-+-+-", "measure": "anapaest.init"}, "line.53": {"text": "Zwey gute tage hat: den einen/ da er freyt/", "tokens": ["Zwey", "gu\u00b7te", "ta\u00b7ge", "hat", ":", "den", "ei\u00b7nen", "/", "da", "er", "freyt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VAFIN", "$.", "ART", "ART", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Den andern/ da er sie mit erden \u00fcberstreut.", "tokens": ["Den", "an\u00b7dern", "/", "da", "er", "sie", "mit", "er\u00b7den", "\u00fc\u00b7bers\u00b7treut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "KOUS", "PPER", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Heut aber hat dich GOtt hierinnen auch erh\u00f6ret;", "tokens": ["Heut", "a\u00b7ber", "hat", "dich", "Gott", "hie\u00b7rin\u00b7nen", "auch", "er\u00b7h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "NN", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Dein sohn ist wohl beweibt/ dein hau\u00df ist wohl vermehret/", "tokens": ["Dein", "sohn", "ist", "wohl", "be\u00b7weibt", "/", "dein", "hau\u00df", "ist", "wohl", "ver\u00b7meh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVFIN", "$(", "PPOSAT", "NN", "VAFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und nimmt ein solches kind zu seiner tochter an/", "tokens": ["Und", "nimmt", "ein", "sol\u00b7ches", "kind", "zu", "sei\u00b7ner", "toch\u00b7ter", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIAT", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Das himmel und vernunfft nicht besser bilden kan/", "tokens": ["Das", "him\u00b7mel", "und", "ver\u00b7nunfft", "nicht", "bes\u00b7ser", "bil\u00b7den", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und man hier k\u00fcnfftig auch wird ohne namen kennen;", "tokens": ["Und", "man", "hier", "k\u00fcnff\u00b7tig", "auch", "wird", "oh\u00b7ne", "na\u00b7men", "ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "ADJD", "ADV", "VAFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Denn wer sie nennen will/ darff nur die sch\u00f6nste nennen.", "tokens": ["Denn", "wer", "sie", "nen\u00b7nen", "will", "/", "darff", "nur", "die", "sch\u00f6ns\u00b7te", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$(", "VMFIN", "ADV", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Und nun begreiff ich erst/ was mancher nicht bedenckt/", "tokens": ["Und", "nun", "be\u00b7greiff", "ich", "erst", "/", "was", "man\u00b7cher", "nicht", "be\u00b7denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "$(", "PWS", "PIS", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Warum dir die natur nur einen sohn geschenckt.", "tokens": ["Wa\u00b7rum", "dir", "die", "na\u00b7tur", "nur", "ei\u00b7nen", "sohn", "ge\u00b7schenckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Sie wuste dich so wohl in st\u00fccke nicht zu fassen/", "tokens": ["Sie", "wus\u00b7te", "dich", "so", "wohl", "in", "st\u00fc\u00b7cke", "nicht", "zu", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Drum wolte sie dich gantz und nicht gest\u00fcmpelt lassen.", "tokens": ["Drum", "wol\u00b7te", "sie", "dich", "gantz", "und", "nicht", "ge\u00b7st\u00fcm\u00b7pelt", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PRF", "ADV", "KON", "PTKNEG", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "O hocherhobner mann! dein lob-lied ist zu schwer;", "tokens": ["O", "ho\u00b7cher\u00b7hob\u00b7ner", "mann", "!", "dein", "lob\u00b7lied", "ist", "zu", "schwer", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "PPOSAT", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wo n\u00e4hm\u2019 ich doch papier/ wo dint\u2019 und federn her?", "tokens": ["Wo", "n\u00e4hm'", "ich", "doch", "pa\u00b7pier", "/", "wo", "dint'", "und", "fe\u00b7dern", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ADJD", "$(", "PWAV", "VVFIN", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Die worte w\u00fcrden eh\u2019/ als deine thaten fehlen;", "tokens": ["Die", "wor\u00b7te", "w\u00fcr\u00b7den", "eh'", "/", "als", "dei\u00b7ne", "tha\u00b7ten", "feh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "$(", "KOKOM", "PPOSAT", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "So kan ich mich auch nicht in diesen orden zehlen/", "tokens": ["So", "kan", "ich", "mich", "auch", "nicht", "in", "die\u00b7sen", "or\u00b7den", "zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "PTKNEG", "APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Der mit der schnellen post zum Musen-berge reist/", "tokens": ["Der", "mit", "der", "schnel\u00b7len", "post", "zum", "Mu\u00b7sen\u00b7ber\u00b7ge", "reist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Der ver\u00dfe/ wie ein brunn das wasser/ von sich geu\u00dft/", "tokens": ["Der", "ver\u00b7\u00dfe", "/", "wie", "ein", "brunn", "das", "was\u00b7ser", "/", "von", "sich", "geu\u00dft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "KOKOM", "ART", "NN", "ART", "ADJA", "$(", "APPR", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Und zehen bogen kunst aus einem ermel sch\u00fcttelt.", "tokens": ["Und", "ze\u00b7hen", "bo\u00b7gen", "kunst", "aus", "ei\u00b7nem", "er\u00b7mel", "sch\u00fct\u00b7telt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "VVFIN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Die sorgen haben mir die kr\u00e4ffte schon verr\u00fcttelt;", "tokens": ["Die", "sor\u00b7gen", "ha\u00b7ben", "mir", "die", "kr\u00e4ff\u00b7te", "schon", "ver\u00b7r\u00fct\u00b7telt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Und ich empfinde zwar zum reimen einen sinn/", "tokens": ["Und", "ich", "emp\u00b7fin\u00b7de", "zwar", "zum", "rei\u00b7men", "ei\u00b7nen", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPRART", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Doch auch bey weitem nicht/ da\u00df ich ein tichter bin.", "tokens": ["Doch", "auch", "bey", "wei\u00b7tem", "nicht", "/", "da\u00df", "ich", "ein", "tich\u00b7ter", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIS", "PTKNEG", "$(", "KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Wiewohl du fragest nichts nach tichtern und poeten;", "tokens": ["Wie\u00b7wohl", "du", "fra\u00b7gest", "nichts", "nach", "tich\u00b7tern", "und", "po\u00b7e\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PIS", "APPR", "ADJA", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Denn dein erleuchter ruhm hat keinen glantz von n\u00f6then.", "tokens": ["Denn", "dein", "er\u00b7leuch\u00b7ter", "ruhm", "hat", "kei\u00b7nen", "glantz", "von", "n\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "PIAT", "NN", "APPR", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Wer schreibt/ was du gethan/ und saget/ wer du bist/", "tokens": ["Wer", "schreibt", "/", "was", "du", "ge\u00b7than", "/", "und", "sa\u00b7get", "/", "wer", "du", "bist", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "PWS", "PPER", "VVPP", "$(", "KON", "VVFIN", "$(", "PWS", "PPER", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Hat so viel wahres schon/ da\u00df er der kunst vergist.", "tokens": ["Hat", "so", "viel", "wah\u00b7res", "schon", "/", "da\u00df", "er", "der", "kunst", "ver\u00b7gist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "ADJA", "ADV", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Drum la\u00df ich andere bey diesem feste singen/", "tokens": ["Drum", "la\u00df", "ich", "an\u00b7de\u00b7re", "bey", "die\u00b7sem", "fes\u00b7te", "sin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PIS", "APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und weil dein wohlseyn doch nicht h\u00f6her ist zu bringen/", "tokens": ["Und", "weil", "dein", "wohl\u00b7seyn", "doch", "nicht", "h\u00f6\u00b7her", "ist", "zu", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.81": {"text": "So w\u00fcnsch ich/ wie vormahls Philippus hat gedacht/", "tokens": ["So", "w\u00fcnsch", "ich", "/", "wie", "vor\u00b7mahls", "Phil\u00b7ip\u00b7pus", "hat", "ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOKOM", "ADV", "NE", "VAFIN", "VVPP", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.82": {"text": "Als man ihm einen tag vier gute posten bracht:", "tokens": ["Als", "man", "ihm", "ei\u00b7nen", "tag", "vier", "gu\u00b7te", "pos\u00b7ten", "bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ART", "NN", "CARD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Der himmel m\u00f6ge doch/ dafern er ja will plagen/", "tokens": ["Der", "him\u00b7mel", "m\u00f6\u00b7ge", "doch", "/", "da\u00b7fern", "er", "ja", "will", "pla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "$(", "KOUS", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Auff dieses gl\u00fccke nur mit kleinen ruthen schlagen.", "tokens": ["Auff", "die\u00b7ses", "gl\u00fc\u00b7cke", "nur", "mit", "klei\u00b7nen", "ru\u00b7then", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}