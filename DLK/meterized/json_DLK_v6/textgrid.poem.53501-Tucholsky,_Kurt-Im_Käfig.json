{"textgrid.poem.53501": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Im K\u00e4fig", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hinter den dicken St\u00e4ben meiner Ideale", "tokens": ["Hin\u00b7ter", "den", "di\u00b7cken", "St\u00e4\u00b7ben", "mei\u00b7ner", "I\u00b7dea\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "lauf ich von einer Wand zur andern Wand.", "tokens": ["lauf", "ich", "von", "ei\u00b7ner", "Wand", "zur", "an\u00b7dern", "Wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da drau\u00dfen gehen Kinderm\u00e4dchen, Generale,", "tokens": ["Da", "drau\u00b7\u00dfen", "ge\u00b7hen", "Kin\u00b7der\u00b7m\u00e4d\u00b7chen", ",", "Ge\u00b7ne\u00b7ra\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Frau Lederh\u00e4ndlerswitwe mit dem Herrn Amant . . .", "tokens": ["Frau", "Le\u00b7der\u00b7h\u00e4nd\u00b7lers\u00b7wit\u00b7we", "mit", "dem", "Herrn", "A\u00b7mant", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "NN", "APPR", "ART", "NN", "NE", "$.", "$.", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.2": {"line.1": {"text": "Manchmal sieht einer her. Mit leeren Blicken:", "tokens": ["Manch\u00b7mal", "sieht", "ei\u00b7ner", "her", ".", "Mit", "lee\u00b7ren", "Bli\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$.", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ah so! ein Tiger \u2013 ja, das arme Tier . . .", "tokens": ["Ah", "so", "!", "ein", "Ti\u00b7ger", "\u2013", "ja", ",", "das", "ar\u00b7me", "Tier", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "ADV", "$.", "ART", "NN", "$(", "PTKANT", "$,", "ART", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann sprechen sie von \u00bbTantchen auch was schicken", "tokens": ["Dann", "spre\u00b7chen", "sie", "von", "\u00bb", "Tant\u00b7chen", "auch", "was", "schi\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "$(", "NN", "ADV", "PIS", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in Pergamentpapier\u00ab.", "tokens": ["in", "Per\u00b7ga\u00b7ment\u00b7pa\u00b7pier", "\u00ab", "."], "token_info": ["word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich m\u00f6cht so gern hinaus. Ich streck und dehn mich \u2013", "tokens": ["Ich", "m\u00f6cht", "so", "gern", "hin\u00b7aus", ".", "Ich", "streck", "und", "dehn", "mich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "PTKVZ", "$.", "PPER", "VVFIN", "KON", "VVIMP", "PPER", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die habens gut, mit ihrer gro\u00dfen Zeit!", "tokens": ["die", "ha\u00b7bens", "gut", ",", "mit", "ih\u00b7rer", "gro\u00b7\u00dfen", "Zeit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADJD", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sind gewi\u00df nicht rein, und doch: ich sehn mich", "tokens": ["Sie", "sind", "ge\u00b7wi\u00df", "nicht", "rein", ",", "und", "doch", ":", "ich", "sehn", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,", "KON", "ADV", "$.", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "nach der Gemeinsamkeit,", "tokens": ["nach", "der", "Ge\u00b7mein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "++-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der Tiger g\u00e4hnt. Er k\u00e4m so gern geloffen . . .", "tokens": ["Der", "Ti\u00b7ger", "g\u00e4hnt", ".", "Er", "k\u00e4m", "so", "gern", "ge\u00b7lof\u00b7fen", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "ADV", "VVPP", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch seines K\u00e4figs St\u00e4be halten dicht.", "tokens": ["Doch", "sei\u00b7nes", "K\u00e4\u00b7figs", "St\u00e4\u00b7be", "hal\u00b7ten", "dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und lie\u00df der W\u00e4rter selbst die T\u00fcre offen:", "tokens": ["Und", "lie\u00df", "der", "W\u00e4r\u00b7ter", "selbst", "die", "T\u00fc\u00b7re", "of\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Man geht ja nicht.", "tokens": ["Man", "geht", "ja", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}