{"dta.poem.12972": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Aria  \n Von der hoffnung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Was beginnt ihr? ihr gedancken!", "tokens": ["Was", "be\u00b7ginnt", "ihr", "?", "ihr", "ge\u00b7dan\u00b7cken", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sollen eure finstre schrancken", "tokens": ["Sol\u00b7len", "eu\u00b7re", "finst\u00b7re", "schran\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Lauter labyrinthe seyn?", "tokens": ["Lau\u00b7ter", "la\u00b7by\u00b7rin\u00b7the", "seyn", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kn\u00fcpfft ihr nichts, als zweiffels-knoten?", "tokens": ["Kn\u00fcpfft", "ihr", "nichts", ",", "als", "zweif\u00b7fels\u00b7kno\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "$,", "KOUS", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nein, ach nein! mit diesen noten", "tokens": ["Nein", ",", "ach", "nein", "!", "mit", "die\u00b7sen", "no\u00b7ten"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "XY", "PTKANT", "$.", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Stimmt mein hertze gar nicht ein.", "tokens": ["Stimmt", "mein", "hert\u00b7ze", "gar", "nicht", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich will hoffen; ob die sternen", "tokens": ["Ich", "will", "hof\u00b7fen", ";", "ob", "die", "ster\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "KOUS", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich gleich itzt von mir entfernen,", "tokens": ["Sich", "gleich", "itzt", "von", "mir", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nicht scheinen, wie ich will.", "tokens": ["Und", "nicht", "schei\u00b7nen", ",", "wie", "ich", "will", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "$,", "PWAV", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die geduld kan alles beugen:", "tokens": ["Die", "ge\u00b7duld", "kan", "al\u00b7les", "beu\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Offt bringt ein gela\u00dfnes schweigen", "tokens": ["Offt", "bringt", "ein", "ge\u00b7la\u00df\u00b7nes", "schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns am besten an das ziel.", "tokens": ["Uns", "am", "bes\u00b7ten", "an", "das", "ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKA", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Darum weicht, ihr phantasien!", "tokens": ["Da\u00b7rum", "weicht", ",", "ihr", "phan\u00b7ta\u00b7si\u00b7en", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PPER", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Euer \u00e4ngstliches bem\u00fchen", "tokens": ["Eu\u00b7er", "\u00e4ngst\u00b7li\u00b7ches", "be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schifft auf lauter Syrten zu.", "tokens": ["Schifft", "auf", "lau\u00b7ter", "Syr\u00b7ten", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nur best\u00e4ndigkeit, mein hertze!", "tokens": ["Nur", "be\u00b7st\u00e4n\u00b7dig\u00b7keit", ",", "mein", "hert\u00b7ze", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Steiffer hoffnung lichte kertze", "tokens": ["Steif\u00b7fer", "hoff\u00b7nung", "lich\u00b7te", "kert\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zeigt die beste bahn zur ruh!", "tokens": ["Zeigt", "die", "bes\u00b7te", "bahn", "zur", "ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "La\u00df die wilden wellen toben,", "tokens": ["La\u00df", "die", "wil\u00b7den", "wel\u00b7len", "to\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwimmt dein schiff doch immer oben!", "tokens": ["Schwimmt", "dein", "schiff", "doch", "im\u00b7mer", "o\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist dein ancker doch noch gantz.", "tokens": ["Ist", "dein", "an\u00b7cker", "doch", "noch", "gantz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf den stillen wohllust-b\u00e4then,", "tokens": ["Auf", "den", "stil\u00b7len", "wohl\u00b7lust\u00b7b\u00e4then", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo wir sanfft und sicher treten,", "tokens": ["Wo", "wir", "sanfft", "und", "si\u00b7cher", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "KON", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Cr\u00f6net uns kein sieges-crantz.", "tokens": ["Cr\u00f6\u00b7net", "uns", "kein", "sie\u00b7ges\u00b7crantz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "F\u00fcrchtest du dich f\u00fcr dem stranden:", "tokens": ["F\u00fcrch\u00b7test", "du", "dich", "f\u00fcr", "dem", "stran\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hoffnung macht niemals zu schanden/", "tokens": ["Hoff\u00b7nung", "macht", "nie\u00b7mals", "zu", "schan\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Wenn sie nur vernunfft regiert.", "tokens": ["Wenn", "sie", "nur", "ver\u00b7nunfft", "re\u00b7giert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Manchmal wird ein leichter nachen", "tokens": ["Manch\u00b7mal", "wird", "ein", "leich\u00b7ter", "na\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Unter klippen, sturm und krachen", "tokens": ["Un\u00b7ter", "klip\u00b7pen", ",", "sturm", "und", "kra\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "VVINF", "$,", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In den sichern port gef\u00fchrt.", "tokens": ["In", "den", "si\u00b7chern", "port", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Muscheln \u00f6ffnen ihre schaalen,", "tokens": ["Mu\u00b7scheln", "\u00f6ff\u00b7nen", "ih\u00b7re", "schaa\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bis das licht der morgen-strahlen", "tokens": ["Bis", "das", "licht", "der", "mor\u00b7gen\u00b7strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie mit glantz und thau erf\u00fcllt.", "tokens": ["Sie", "mit", "glantz", "und", "thau", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Zeit und witz kan perlen fangen", "tokens": ["Zeit", "und", "witz", "kan", "per\u00b7len", "fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VMFIN", "VVINF", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ein ruhiges verlangen", "tokens": ["Und", "ein", "ru\u00b7hi\u00b7ges", "ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Bleibt gewi\u00df nicht ungestillt.", "tokens": ["Bleibt", "ge\u00b7wi\u00df", "nicht", "un\u00b7ge\u00b7stillt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}