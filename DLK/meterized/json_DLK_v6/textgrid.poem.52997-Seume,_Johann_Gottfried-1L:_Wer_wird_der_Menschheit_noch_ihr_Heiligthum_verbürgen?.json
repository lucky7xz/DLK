{"textgrid.poem.52997": {"metadata": {"author": {"name": "Seume, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer wird der Menschheit noch ihr Heiligthum verb\u00fcrgen?", "genre": "verse", "period": "N.A.", "pub_year": 1786, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer wird der Menschheit noch ihr Heiligthum verb\u00fcrgen?", "tokens": ["Wer", "wird", "der", "Menschheit", "noch", "ihr", "Hei\u00b7lig\u00b7thum", "ver\u00b7b\u00fcr\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Bey jedem Tritt ist Scorpion.", "tokens": ["Bey", "je\u00b7dem", "Tritt", "ist", "Scor\u00b7pi\u00b7on", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der hohe Wahnsinn schwelgt, wo die Hy\u00e4nen w\u00fcrgen,", "tokens": ["Der", "ho\u00b7he", "Wahn\u00b7sinn", "schwelgt", ",", "wo", "die", "Hy\u00b7\u00e4\u00b7nen", "w\u00fcr\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und spricht entsetzlich Hohn.", "tokens": ["Und", "spricht", "ent\u00b7setz\u00b7lich", "Hohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Hier h\u00e4lt die Tyranney mit ihrer Eisenruthe", "tokens": ["Hier", "h\u00e4lt", "die", "Ty\u00b7ran\u00b7ney", "mit", "ih\u00b7rer", "Ei\u00b7sen\u00b7ru\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch blutig alte B\u00fcttelzucht,", "tokens": ["Noch", "blu\u00b7tig", "al\u00b7te", "B\u00fct\u00b7tel\u00b7zucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Inde\u00df gepl\u00fcndert dort ein Volk dem Aftergute", "tokens": ["In\u00b7de\u00df", "ge\u00b7pl\u00fcn\u00b7dert", "dort", "ein", "Volk", "dem", "Af\u00b7ter\u00b7gu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVPP", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Frevelfreyheit flucht.", "tokens": ["Der", "Fre\u00b7vel\u00b7frey\u00b7heit", "flucht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich las das gro\u00dfe Buch, in welchem die Verbrecher", "tokens": ["Ich", "las", "das", "gro\u00b7\u00dfe", "Buch", ",", "in", "wel\u00b7chem", "die", "Ver\u00b7bre\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "APPR", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf Marmor an dem Schandpfahl stehn:", "tokens": ["Auf", "Mar\u00b7mor", "an", "dem", "Schand\u00b7pfahl", "stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf jedem Blatte schl\u00e4gt die Schuldigen ein R\u00e4cher", "tokens": ["Auf", "je\u00b7dem", "Blat\u00b7te", "schl\u00e4gt", "die", "Schul\u00b7di\u00b7gen", "ein", "R\u00e4\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "F\u00fcr irgend ein Vergebn.", "tokens": ["F\u00fcr", "ir\u00b7gend", "ein", "Ver\u00b7gebn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Noch trifft des Persers Hand, der Sclavenvater l\u00e4chelt,", "tokens": ["Noch", "trifft", "des", "Per\u00b7sers", "Hand", ",", "der", "Scla\u00b7ven\u00b7va\u00b7ter", "l\u00e4\u00b7chelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im Trunk den Knaben in das Herz;", "tokens": ["Im", "Trunk", "den", "Kna\u00b7ben", "in", "das", "Herz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Sulla, wenn um ihn die Stadt Verw\u00fcstung r\u00f6chelt,", "tokens": ["Und", "Sul\u00b7la", ",", "wenn", "um", "ihn", "die", "Stadt", "Ver\u00b7w\u00fcs\u00b7tung", "r\u00f6\u00b7chelt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "KOUS", "APPR", "PPER", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Schreibt Todesschrift zum Scherz.", "tokens": ["Schreibt", "To\u00b7des\u00b7schrift", "zum", "Scherz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Man baut mit Riesenkraft am Celtenkapitole", "tokens": ["Man", "baut", "mit", "Rie\u00b7sen\u00b7kraft", "am", "Cel\u00b7ten\u00b7ka\u00b7pi\u00b7to\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und donnert von dem Tempel her;", "tokens": ["Und", "don\u00b7nert", "von", "dem", "Tem\u00b7pel", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Molochsopfer gl\u00fchn dem steigenden Idole", "tokens": ["Und", "Mo\u00b7loch\u00b7sop\u00b7fer", "gl\u00fchn", "dem", "stei\u00b7gen\u00b7den", "I\u00b7do\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vom Meere bis ans Meer.", "tokens": ["Vom", "Mee\u00b7re", "bis", "ans", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die alte Hyder zischt mit allen ihren Giften", "tokens": ["Die", "al\u00b7te", "Hy\u00b7der", "zischt", "mit", "al\u00b7len", "ih\u00b7ren", "Gif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Neuling an, und Blitz und Dolch", "tokens": ["Den", "Neu\u00b7ling", "an", ",", "und", "Blitz", "und", "Dolch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schl\u00e4gt; wo sie k\u00e4mpfen flieht der Segen von den Triften", "tokens": ["Schl\u00e4gt", ";", "wo", "sie", "k\u00e4mp\u00b7fen", "flieht", "der", "Se\u00b7gen", "von", "den", "Trif\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "PWAV", "PPER", "VVINF", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "W\u00e4chst Schierling nur und Lolch.", "tokens": ["W\u00e4chst", "Schier\u00b7ling", "nur", "und", "Lolch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Von jeder Alpe bricht der Tod aus Feuerschlinden,", "tokens": ["Von", "je\u00b7der", "Al\u00b7pe", "bricht", "der", "Tod", "aus", "Feu\u00b7er\u00b7schlin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und in dem Waldstrom rauschet Blut;", "tokens": ["Und", "in", "dem", "Wald\u00b7strom", "rau\u00b7schet", "Blut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Heerdenh\u00fcther blickt mit Angst aus Felsengr\u00fcnden", "tokens": ["Der", "Heer\u00b7den\u00b7h\u00fct\u00b7her", "blickt", "mit", "Angst", "aus", "Fel\u00b7sen\u00b7gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nach seiner H\u00fctte Gluth;", "tokens": ["Nach", "sei\u00b7ner", "H\u00fct\u00b7te", "Gluth", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Sieht seinen Friedenshain von \u00c4xten nieder st\u00fcrzen,", "tokens": ["Sieht", "sei\u00b7nen", "Frie\u00b7dens\u00b7hain", "von", "\u00c4x\u00b7ten", "nie\u00b7der", "st\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sieht, wie das Ro\u00df die Saat zerstampft,", "tokens": ["Sieht", ",", "wie", "das", "Ro\u00df", "die", "Saat", "zer\u00b7stampft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie sich die W\u00fcthenden zu der Zerst\u00f6rung sch\u00fcrzen,", "tokens": ["Wie", "sich", "die", "W\u00fct\u00b7hen\u00b7den", "zu", "der", "Zer\u00b7st\u00f6\u00b7rung", "sch\u00fcr\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie die Gegend dampft;", "tokens": ["Und", "wie", "die", "Ge\u00b7gend", "dampft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Sieht sprachlos auf, und bebt, und kalte Tropfen zittern", "tokens": ["Sieht", "sprach\u00b7los", "auf", ",", "und", "bebt", ",", "und", "kal\u00b7te", "Trop\u00b7fen", "zit\u00b7tern"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "$,", "KON", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Bebenden die Stirn herab.", "tokens": ["Dem", "Be\u00b7ben\u00b7den", "die", "Stirn", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Inde\u00df sinkt unter der Verheerung Ungewittern", "tokens": ["In\u00b7de\u00df", "sinkt", "un\u00b7ter", "der", "Ver\u00b7hee\u00b7rung", "Un\u00b7ge\u00b7wit\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein ganzer Gau ins Grab.", "tokens": ["Ein", "gan\u00b7zer", "Gau", "ins", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Mit unverwandtem Blick und der Vergeltung Miene", "tokens": ["Mit", "un\u00b7ver\u00b7wand\u00b7tem", "Blick", "und", "der", "Ver\u00b7gel\u00b7tung", "Mie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Spricht Nemesis ihr Flammenwort;", "tokens": ["Spricht", "Ne\u00b7me\u00b7sis", "ihr", "Flam\u00b7men\u00b7wort", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der milde Genius weint \u00fcber der Ruine", "tokens": ["Der", "mil\u00b7de", "Ge\u00b7nius", "weint", "\u00fc\u00b7ber", "der", "Ru\u00b7i\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+--++-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und geht voll Wehmuth fort.", "tokens": ["Und", "geht", "voll", "Weh\u00b7muth", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Hat endlich schrecklich uns das Heer der Blasphemieen", "tokens": ["Hat", "end\u00b7lich", "schreck\u00b7lich", "uns", "das", "Heer", "der", "Blas\u00b7phe\u00b7mi\u00b7een"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dort vor dem Richter angeklagt,", "tokens": ["Dort", "vor", "dem", "Rich\u00b7ter", "an\u00b7ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df nun die Geyerwuth der stygischen Harpyen", "tokens": ["Da\u00df", "nun", "die", "Ge\u00b7yer\u00b7wuth", "der", "sty\u00b7gi\u00b7schen", "Har\u00b7py\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+--+--+--+--", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "Uns an der Seele nagt?", "tokens": ["Uns", "an", "der", "See\u00b7le", "nagt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Durch Leichen schreiten kalt, mit ihrer wilden Horde,", "tokens": ["Durch", "Lei\u00b7chen", "schrei\u00b7ten", "kalt", ",", "mit", "ih\u00b7rer", "wil\u00b7den", "Hor\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADJD", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Tilly und die Attila,", "tokens": ["Die", "Til\u00b7ly", "und", "die", "At\u00b7ti\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als w\u00e4re wieder nun mit ihrem alten Morde", "tokens": ["Als", "w\u00e4\u00b7re", "wie\u00b7der", "nun", "mit", "ih\u00b7rem", "al\u00b7ten", "Mor\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Zeit des Faustrechts da.", "tokens": ["Die", "Zeit", "des", "Faus\u00b7trechts", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wir harreten noch j\u00fcngst, den Blick in Morgenr\u00f6the,", "tokens": ["Wir", "har\u00b7re\u00b7ten", "noch", "j\u00fcngst", ",", "den", "Blick", "in", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Astr\u00e4a, deiner Wiederkunft:", "tokens": ["A\u00b7str\u00e4a", ",", "dei\u00b7ner", "Wie\u00b7der\u00b7kunft", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Morgenr\u00f6the schwand, und auf der neuen \u00d6de", "tokens": ["Die", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", "schwand", ",", "und", "auf", "der", "neu\u00b7en", "\u00d6\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bleibt kaum ein Strahl Vernunft.", "tokens": ["Bleibt", "kaum", "ein", "Strahl", "Ver\u00b7nunft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Mit Ruthen peitschte man, und nun mit Scorpionen.", "tokens": ["Mit", "Ru\u00b7then", "peitschte", "man", ",", "und", "nun", "mit", "Scor\u00b7pi\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "$,", "KON", "ADV", "APPR", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Areopagitenspruch", "tokens": ["Der", "A\u00b7reo\u00b7pa\u00b7gi\u00b7ten\u00b7spruch"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hielt seine Spenden aus f\u00fcr die in H\u00fctten wohnen;", "tokens": ["Hielt", "sei\u00b7ne", "Spen\u00b7den", "aus", "f\u00fcr", "die", "in", "H\u00fct\u00b7ten", "woh\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "APPR", "ART", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sprach Segen, und gibt Fluch.", "tokens": ["Sprach", "Se\u00b7gen", ",", "und", "gibt", "Fluch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "KON", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Was ist der Unterschied, wer L\u00e4nder ausgesogen?", "tokens": ["Was", "ist", "der", "Un\u00b7ter\u00b7schied", ",", "wer", "L\u00e4n\u00b7der", "aus\u00b7ge\u00b7so\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "PWS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ob der Satrap, ob der Pr\u00e4lat?", "tokens": ["Ob", "der", "Sat\u00b7rap", ",", "ob", "der", "Pr\u00e4\u00b7lat", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ob F\u00fcrstenschwelgerey, ob freche Demagogen?", "tokens": ["Ob", "F\u00fcrs\u00b7ten\u00b7schwel\u00b7ge\u00b7rey", ",", "ob", "fre\u00b7che", "De\u00b7ma\u00b7go\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die That bleibt stets die That.", "tokens": ["Die", "That", "bleibt", "stets", "die", "That", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Sonst fabelte der M\u00f6nch der Dummheit Heiligkeiten", "tokens": ["Sonst", "fa\u00b7bel\u00b7te", "der", "M\u00f6nch", "der", "Dumm\u00b7heit", "Hei\u00b7lig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit breitem Wolkenangesicht,", "tokens": ["Mit", "brei\u00b7tem", "Wol\u00b7ken\u00b7an\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo mit dem Schild des Lichts jetzt grimm nach allen Seiten", "tokens": ["Wo", "mit", "dem", "Schild", "des", "Lichts", "jetzt", "grimm", "nach", "al\u00b7len", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "NN", "ADV", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der neue Schwindler spricht.", "tokens": ["Der", "neu\u00b7e", "Schwind\u00b7ler", "spricht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "R\u00fchmt, wie ihr wollt, das Recht, die Freyheit und die Siege", "tokens": ["R\u00fchmt", ",", "wie", "ihr", "wollt", ",", "das", "Recht", ",", "die", "Frey\u00b7heit", "und", "die", "Sie\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "PPER", "VMFIN", "$,", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der alten gro\u00dfen Tiberstadt,", "tokens": ["Der", "al\u00b7ten", "gro\u00b7\u00dfen", "Ti\u00b7ber\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Spartakus, der Knecht, vor allen in dem Kriege", "tokens": ["Wo", "Spar\u00b7ta\u00b7kus", ",", "der", "Knecht", ",", "vor", "al\u00b7len", "in", "dem", "Krie\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "$,", "ART", "NN", "$,", "APPR", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Ehrenrolle hat;", "tokens": ["Die", "Eh\u00b7ren\u00b7rol\u00b7le", "hat", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Wo man den B\u00fcrger peitscht, vor dem Karthago zittert,", "tokens": ["Wo", "man", "den", "B\u00fcr\u00b7ger", "peitscht", ",", "vor", "dem", "Kar\u00b7tha\u00b7go", "zit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo Kato Sclavenhandel treibt,", "tokens": ["Wo", "Ka\u00b7to", "Scla\u00b7ven\u00b7han\u00b7del", "treibt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo man mit Menschenfleisch zum Schmaus Mur\u00e4nen f\u00fcttert,", "tokens": ["Wo", "man", "mit", "Men\u00b7schen\u00b7fleisch", "zum", "Schmaus", "Mu\u00b7r\u00e4\u00b7nen", "f\u00fct\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "APPRART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die sich Lukull verschreibt.", "tokens": ["Die", "sich", "Lu\u00b7kull", "ver\u00b7schreibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "NE", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Der Himmel sch\u00fctze mich und meine bessern Br\u00fcder", "tokens": ["Der", "Him\u00b7mel", "sch\u00fct\u00b7ze", "mich", "und", "mei\u00b7ne", "bes\u00b7sern", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor ", "tokens": ["Vor"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Erzeugt durch Unvernunft, ern\u00e4hrte sie die Hyder", "tokens": ["Er\u00b7zeugt", "durch", "Un\u00b7ver\u00b7nunft", ",", "er\u00b7n\u00e4hr\u00b7te", "sie", "die", "Hy\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von Andrer Sclaverey.", "tokens": ["Von", "A\u00b7ndrer", "Scla\u00b7ve\u00b7rey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Wenn hier der Celte Karl den orthodoxen Glauben", "tokens": ["Wenn", "hier", "der", "Cel\u00b7te", "Karl", "den", "or\u00b7tho\u00b7do\u00b7xen", "Glau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NE", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Dolchen von Bajonne lehrt,", "tokens": ["Mit", "Dol\u00b7chen", "von", "Ba\u00b7jon\u00b7ne", "lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort Phalaris-Anton mit Morden und mit Rauben", "tokens": ["Dort", "Pha\u00b7la\u00b7ris\u00b7An\u00b7ton", "mit", "Mor\u00b7den", "und", "mit", "Rau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Die Vaterstadt verheert;", "tokens": ["Die", "Va\u00b7ter\u00b7stadt", "ver\u00b7heert", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Wenn Nero Rom verbrennt und Robespierre B\u00fcrgern", "tokens": ["Wenn", "Ne\u00b7ro", "Rom", "ver\u00b7brennt", "und", "Ro\u00b7be\u00b7spier\u00b7re", "B\u00fcr\u00b7gern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "VVFIN", "KON", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch Mienen Todesurtheil spricht,", "tokens": ["Durch", "Mie\u00b7nen", "To\u00b7des\u00b7urt\u00b7heil", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie w\u00fcrgten alle k\u00fchn; wer war von allen W\u00fcrgern", "tokens": ["Sie", "w\u00fcrg\u00b7ten", "al\u00b7le", "k\u00fchn", ";", "wer", "war", "von", "al\u00b7len", "W\u00fcr\u00b7gern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "$.", "PWS", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der gr\u00f6\u00dfte B\u00f6sewicht?", "tokens": ["Der", "gr\u00f6\u00df\u00b7te", "B\u00f6\u00b7se\u00b7wicht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Vernunft, wann wirst du einst die wahre Freyheit setzen,", "tokens": ["Ver\u00b7nunft", ",", "wann", "wirst", "du", "einst", "die", "wah\u00b7re", "Frey\u00b7heit", "set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor welcher Recht und Ordnung geht?", "tokens": ["Vor", "wel\u00b7cher", "Recht", "und", "Ord\u00b7nung", "geht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die kein Tribun, kein F\u00fcrst, kein Bonze zu verletzen", "tokens": ["Die", "kein", "Tri\u00b7bun", ",", "kein", "F\u00fcrst", ",", "kein", "Bon\u00b7ze", "zu", "ver\u00b7let\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich frevelnd untersteht?", "tokens": ["Sich", "fre\u00b7velnd", "un\u00b7ter\u00b7steht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Erw\u00e4rme du mein Herz, des Lebens G\u00f6tterflamme,", "tokens": ["Er\u00b7w\u00e4r\u00b7me", "du", "mein", "Herz", ",", "des", "Le\u00b7bens", "G\u00f6t\u00b7ter\u00b7flam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die tief durch meine Seele gl\u00fcht,", "tokens": ["Die", "tief", "durch", "mei\u00b7ne", "See\u00b7le", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df nicht mein Auge kalt rund um sich her verdamme,", "tokens": ["Da\u00df", "nicht", "mein", "Au\u00b7ge", "kalt", "rund", "um", "sich", "her", "ver\u00b7dam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "PPOSAT", "NN", "ADJD", "ADJD", "APPR", "PRF", "APZR", "VVFIN", "$,"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Wenn es die Gr\u00e4uel sieht;", "tokens": ["Wenn", "es", "die", "Gr\u00e4u\u00b7el", "sieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Da\u00df Kleinmuth nicht und Angst zuletzt mich niederziehen,", "tokens": ["Da\u00df", "Klein\u00b7muth", "nicht", "und", "Angst", "zu\u00b7letzt", "mich", "nie\u00b7der\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "KON", "NN", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn h\u00f6hnend Druck und Willk\u00fchr siegt,", "tokens": ["Wenn", "h\u00f6h\u00b7nend", "Druck", "und", "Will\u00b7k\u00fchr", "siegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn weit, weit aufgerollt, wohin die Blicke fliehen,", "tokens": ["Wenn", "weit", ",", "weit", "auf\u00b7ge\u00b7rollt", ",", "wo\u00b7hin", "die", "Bli\u00b7cke", "flie\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "ADJD", "VVPP", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die S\u00fcndenmappe liegt.", "tokens": ["Die", "S\u00fcn\u00b7den\u00b7map\u00b7pe", "liegt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Bleib, Genius, damit uns nicht die Hoffnung schwinde,", "tokens": ["Bleib", ",", "Ge\u00b7nius", ",", "da\u00b7mit", "uns", "nicht", "die", "Hoff\u00b7nung", "schwin\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KOUS", "PPER", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Die \u00fcber der Ruine schwebt,", "tokens": ["Die", "\u00fc\u00b7ber", "der", "Ru\u00b7i\u00b7ne", "schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Da\u00df bald die Menschheit sich aus der Geburtsangst winde,", "tokens": ["Da\u00df", "bald", "die", "Menschheit", "sich", "aus", "der", "Ge\u00b7burt\u00b7sangst", "win\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "In der sie jetzo bebt.", "tokens": ["In", "der", "sie", "jet\u00b7zo", "bebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Hilf du uns, G\u00f6ttlicher, ihr Heiligthum bewahren,", "tokens": ["Hilf", "du", "uns", ",", "G\u00f6tt\u00b7li\u00b7cher", ",", "ihr", "Hei\u00b7lig\u00b7thum", "be\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPER", "$,", "NN", "$,", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das im Orkan sich fast verlor,", "tokens": ["Das", "im", "Or\u00b7kan", "sich", "fast", "ver\u00b7lor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "PRF", "ADV", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und trag' es herrlicher aus t\u00f6dtlichen Gefahren", "tokens": ["Und", "trag'", "es", "herr\u00b7li\u00b7cher", "aus", "t\u00f6dt\u00b7li\u00b7chen", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und heiliger empor.", "tokens": ["Und", "hei\u00b7li\u00b7ger", "em\u00b7por", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}