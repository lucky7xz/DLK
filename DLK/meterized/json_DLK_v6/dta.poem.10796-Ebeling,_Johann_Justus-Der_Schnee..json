{"dta.poem.10796": {"metadata": {"author": {"name": "Ebeling, Johann Justus", "birth": "N.A.", "death": "N.A."}, "title": "Der Schnee.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1747", "urn": "urn:nbn:de:kobv:b4-200905198774", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die Wunder der verschlo\u00dfnen Luft,", "tokens": ["Die", "Wun\u00b7der", "der", "ver\u00b7schlo\u00df\u00b7nen", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind theils bekandt, theils noch ver-", "tokens": ["Sind", "theils", "be\u00b7kandt", ",", "theils", "noch", "ver"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "ADV", "ADV", "TRUNC"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wir sehen wenn die d\u00fcstre Kluft,", "tokens": ["Wir", "se\u00b7hen", "wenn", "die", "d\u00fcst\u00b7re", "Kluft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Wolken d\u00fcnn Geweb zerbrochen;", "tokens": ["Der", "Wol\u00b7ken", "d\u00fcnn", "Ge\u00b7web", "zer\u00b7bro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So wird die Welt zur Winterszeit,", "tokens": ["So", "wird", "die", "Welt", "zur", "Win\u00b7ter\u00b7szeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Schnee, als Wolle \u00fcberstreut", "tokens": ["Mit", "Schnee", ",", "als", "Wol\u00b7le", "\u00fc\u00b7bers\u00b7treut"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "KOUS", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Aus dessen haarigt d\u00fcnnen Spizzen,", "tokens": ["Aus", "des\u00b7sen", "haa\u00b7rigt", "d\u00fcn\u00b7nen", "Spiz\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Schimmerreichen Strahlen blizzen.", "tokens": ["Die", "Schim\u00b7mer\u00b7rei\u00b7chen", "Strah\u00b7len", "bliz\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie wird der Schnee alda formirt,", "tokens": ["Wie", "wird", "der", "Schnee", "al\u00b7da", "for\u00b7mirt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "So wollen wir, wie sichs geb\u00fchrt,", "tokens": ["So", "wol\u00b7len", "wir", ",", "wie", "sichs", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Kenntnis eures Witzes preisen.", "tokens": ["Das", "Kennt\u00b7nis", "eu\u00b7res", "Wit\u00b7zes", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jhr scharffen Forscher der Natur,", "tokens": ["Ihr", "scharf\u00b7fen", "For\u00b7scher", "der", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durchdringt der L\u00fcffte dunkle Spur,", "tokens": ["Durch\u00b7dringt", "der", "L\u00fcff\u00b7te", "dunk\u00b7le", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sagt an, wie wird der Dunst gebohren,", "tokens": ["Sagt", "an", ",", "wie", "wird", "der", "Dunst", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PWAV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der durch die K\u00e4lte ist gefroren.", "tokens": ["Der", "durch", "die", "K\u00e4l\u00b7te", "ist", "ge\u00b7fro\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Schnee k\u00f6mt aus dem Wolkenschlauch,", "tokens": ["Der", "Schnee", "k\u00f6mt", "aus", "dem", "Wol\u00b7ken\u00b7schlauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies k\u00f6nnen wir als wahr begreiffen,", "tokens": ["Dies", "k\u00f6n\u00b7nen", "wir", "als", "wahr", "be\u00b7greif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "KOUS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Jhr lehrt da\u00df durch der Winde Hauch,", "tokens": ["Ihr", "lehrt", "da\u00df", "durch", "der", "Win\u00b7de", "Hauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die D\u00fcnste sich zusammen h\u00e4uffen.", "tokens": ["Die", "D\u00fcns\u00b7te", "sich", "zu\u00b7sam\u00b7men", "h\u00e4uf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Luft die ihren Auffenthalt,", "tokens": ["Die", "Luft", "die", "ih\u00b7ren", "Auf\u00b7fent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In ienen Kreisen hat, ist kalt,", "tokens": ["In", "ie\u00b7nen", "Krei\u00b7sen", "hat", ",", "ist", "kalt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und kan, wie leichtlich auszufinden,", "tokens": ["Und", "kan", ",", "wie", "leicht\u00b7lich", "aus\u00b7zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "PWAV", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Teilchens an einander binden.", "tokens": ["Die", "Teil\u00b7chens", "an", "ein\u00b7an\u00b7der", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Allein erkl\u00e4rt uns wie der Schnee,", "tokens": ["Al\u00b7lein", "er\u00b7kl\u00e4rt", "uns", "wie", "der", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der aus dem Lufftkreis abwerts flieget,", "tokens": ["Der", "aus", "dem", "Lufft\u00b7kreis", "ab\u00b7werts", "flie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sich in der kalten Himmels H\u00f6h,", "tokens": ["Sich", "in", "der", "kal\u00b7ten", "Him\u00b7mels", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So wunderbar zusammen f\u00fcget.", "tokens": ["So", "wun\u00b7der\u00b7bar", "zu\u00b7sam\u00b7men", "f\u00fc\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Woher entstehet die Gestalt", "tokens": ["Wo\u00b7her", "ent\u00b7ste\u00b7het", "die", "Ge\u00b7stalt"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In ienem d\u00fcstern Auffenthalt;", "tokens": ["In", "ie\u00b7nem", "d\u00fcs\u00b7tern", "Auf\u00b7fent\u00b7halt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer macht die Flokken in der Ferne", "tokens": ["Wer", "macht", "die", "Flok\u00b7ken", "in", "der", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So ekkigt, wie formirte Sterne?", "tokens": ["So", "ek\u00b7kigt", ",", "wie", "for\u00b7mir\u00b7te", "Ster\u00b7ne", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "ADJA", "NN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Die Weisen die den Stagirit,", "tokens": ["Die", "Wei\u00b7sen", "die", "den", "Sta\u00b7gi\u00b7rit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu ihren blinden F\u00fchrer w\u00e4hlen,", "tokens": ["Zu", "ih\u00b7ren", "blin\u00b7den", "F\u00fch\u00b7rer", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die sehen, was kein Mensche sieht,", "tokens": ["Die", "se\u00b7hen", ",", "was", "kein", "Men\u00b7sche", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn sie uns ihren Wahn erz\u00e4hlen.", "tokens": ["Wenn", "sie", "uns", "ih\u00b7ren", "Wahn", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie meinen, die ", "tokens": ["Sie", "mei\u00b7nen", ",", "die"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Das Unding welches alles schafft,", "tokens": ["Das", "Un\u00b7ding", "wel\u00b7ches", "al\u00b7les", "schafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das wir nicht klar begreiffen k\u00f6nnen,", "tokens": ["Das", "wir", "nicht", "klar", "be\u00b7greif\u00b7fen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "ADJD", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sei hier die Ursach auch zu nennen.", "tokens": ["Sei", "hier", "die", "Ur\u00b7sach", "auch", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ein andrer prahlt mit der Jdee,", "tokens": ["Ein", "an\u00b7drer", "prahlt", "mit", "der", "Jdee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Die durch ihr wunderbar Formiren,", "tokens": ["Die", "durch", "ihr", "wun\u00b7der\u00b7bar", "For\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der L\u00fcffte Schaum, den kalten Schnee,", "tokens": ["Der", "L\u00fcff\u00b7te", "Schaum", ",", "den", "kal\u00b7ten", "Schnee", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit solcher Bildung k\u00f6nne zieren.", "tokens": ["Mit", "sol\u00b7cher", "Bil\u00b7dung", "k\u00f6n\u00b7ne", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Fragt nicht aus Witz und Neubegier:", "tokens": ["Fragt", "nicht", "aus", "Witz", "und", "Neu\u00b7be\u00b7gier", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was stellt sich dieser Weise f\u00fcr", "tokens": ["Was", "stellt", "sich", "die\u00b7ser", "Wei\u00b7se", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "PDAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "An den Jdeen? bei dem Erkl\u00e4ren,", "tokens": ["An", "den", "Jdeen", "?", "bei", "dem", "Er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Wird er euch neue R\u00e4thfel lehren.", "tokens": ["Wird", "er", "euch", "neu\u00b7e", "R\u00e4th\u00b7fel", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die, welche unsers Sch\u00f6pfers Siz,", "tokens": ["Die", ",", "wel\u00b7che", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Siz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "PPOSAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ausgespannten Raum ergr\u00fcndet;", "tokens": ["Den", "aus\u00b7ge\u00b7spann\u00b7ten", "Raum", "er\u00b7gr\u00fcn\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und deren wollgesch\u00e4rfter Witz", "tokens": ["Und", "de\u00b7ren", "woll\u00b7ge\u00b7sch\u00e4rf\u00b7ter", "Witz"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In dunklen Tieffen Klarheit findet,", "tokens": ["In", "dunk\u00b7len", "Tief\u00b7fen", "Klar\u00b7heit", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Erw\u00e4hlen eine andre Art,", "tokens": ["Er\u00b7w\u00e4h\u00b7len", "ei\u00b7ne", "and\u00b7re", "Art", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie sich des Schnees Dunst verpaart:", "tokens": ["Wie", "sich", "des", "Schnees", "Dunst", "ver\u00b7paart", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.7": {"text": "Sie meinen, da\u00df der D\u00fcnste Schwingen,", "tokens": ["Sie", "mei\u00b7nen", ",", "da\u00df", "der", "D\u00fcns\u00b7te", "Schwin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die steif, sich an einander hingen.", "tokens": ["Die", "steif", ",", "sich", "an", "ein\u00b7an\u00b7der", "hin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PRF", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wenn sich der L\u00fcffte Kreis bewegt,", "tokens": ["Wenn", "sich", "der", "L\u00fcff\u00b7te", "Kreis", "be\u00b7wegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der voll von kleinen Theilen schwimmet,", "tokens": ["Der", "voll", "von", "klei\u00b7nen", "Thei\u00b7len", "schwim\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Dunst sich zu dem andern schl\u00e4gt,", "tokens": ["Ein", "Dunst", "sich", "zu", "dem", "an\u00b7dern", "schl\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Darin noch etwas W\u00e4rme glimmet:", "tokens": ["Da\u00b7rin", "noch", "et\u00b7was", "W\u00e4r\u00b7me", "glim\u00b7met", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So wird wenn eins zum andern fliegt,", "tokens": ["So", "wird", "wenn", "eins", "zum", "an\u00b7dern", "fliegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "KOUS", "PIS", "APPRART", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein ieder Dunst gekr\u00fcmmt, gebiegt,", "tokens": ["Ein", "ie\u00b7der", "Dunst", "ge\u00b7kr\u00fcmmt", ",", "ge\u00b7biegt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da sie sich drauf geschwind vereinen,", "tokens": ["Da", "sie", "sich", "drauf", "ge\u00b7schwind", "ver\u00b7ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als runde Wassertropfen scheinen.", "tokens": ["Als", "run\u00b7de", "Was\u00b7ser\u00b7trop\u00b7fen", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Hingegen wenn die Lufft erfrorn,", "tokens": ["Hin\u00b7ge\u00b7gen", "wenn", "die", "Lufft", "er\u00b7frorn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So h\u00e4tten auch die Wasser D\u00fcnste,", "tokens": ["So", "h\u00e4t\u00b7ten", "auch", "die", "Was\u00b7ser", "D\u00fcns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bewegung und die W\u00e4rm verlohrn,", "tokens": ["Be\u00b7we\u00b7gung", "und", "die", "W\u00e4rm", "ver\u00b7lohrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und so entst\u00fcnde ein Gespinste,", "tokens": ["Und", "so", "ent\u00b7st\u00fcn\u00b7de", "ein", "Ge\u00b7spins\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das starr sich an einander hengt,", "tokens": ["Das", "starr", "sich", "an", "ein\u00b7an\u00b7der", "hengt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie Flokken drauf zusammen drengt;", "tokens": ["Wie", "Flok\u00b7ken", "drauf", "zu\u00b7sam\u00b7men", "drengt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PAV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und durch den Trieb von regen Winden,", "tokens": ["Und", "durch", "den", "Trieb", "von", "re\u00b7gen", "Win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Entst\u00fcnde nachmahls ihr Verbinden.", "tokens": ["Ent\u00b7st\u00fcn\u00b7de", "nach\u00b7mahls", "ihr", "Ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nachdem der Druk den Schnee regiert,", "tokens": ["Nach\u00b7dem", "der", "Druk", "den", "Schnee", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn D\u00fcnste an einander stehen,", "tokens": ["Wenn", "D\u00fcns\u00b7te", "an", "ein\u00b7an\u00b7der", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "W\u00fcrd nachmahls die Gestalt formirt,", "tokens": ["W\u00fcrd", "nach\u00b7mahls", "die", "Ge\u00b7stalt", "for\u00b7mirt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die wir bei seinem Fallen sehen.", "tokens": ["Die", "wir", "bei", "sei\u00b7nem", "Fal\u00b7len", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So k\u00fcnstlich dieses ausgedacht,", "tokens": ["So", "k\u00fcnst\u00b7lich", "die\u00b7ses", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PDAT", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie in der Lufft der Schnee gemacht:", "tokens": ["Wie", "in", "der", "Lufft", "der", "Schnee", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So m\u00fcssen sie doch eingestehen,", "tokens": ["So", "m\u00fcs\u00b7sen", "sie", "doch", "ein\u00b7ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df es kein Auge klar gesehen.", "tokens": ["Da\u00df", "es", "kein", "Au\u00b7ge", "klar", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Zeugung bleibet unbekandt,", "tokens": ["Die", "Zeu\u00b7gung", "blei\u00b7bet", "un\u00b7be\u00b7kandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Werkstat bleibet uns verschlossen;", "tokens": ["Die", "Werk\u00b7stat", "blei\u00b7bet", "uns", "ver\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo in der L\u00fcffte weiten Land,", "tokens": ["Wo", "in", "der", "L\u00fcff\u00b7te", "wei\u00b7ten", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dies weisse Dunstgew\u00e4chs entsprossen.", "tokens": ["Dies", "weis\u00b7se", "Dunst\u00b7ge\u00b7w\u00e4chs", "ent\u00b7spros\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Den Erdenball mit Schnee bestreut,", "tokens": ["Den", "Er\u00b7den\u00b7ball", "mit", "Schnee", "be\u00b7streut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kan ihn in denen Lufftgefilden,", "tokens": ["Kan", "ihn", "in", "de\u00b7nen", "Lufft\u00b7ge\u00b7fil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PRELS", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Ganz anders, als wir denken, bilden.", "tokens": ["Ganz", "an\u00b7ders", ",", "als", "wir", "den\u00b7ken", ",", "bil\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}