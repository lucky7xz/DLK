{"dta.poem.9567": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auff ein ihm verehrtes band.  \n C. E.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Njm/ Venus/ dieses band aus meinen frohen h\u00e4nden/", "tokens": ["Njm", "/", "Ve\u00b7nus", "/", "die\u00b7ses", "band", "aus", "mei\u00b7nen", "fro\u00b7hen", "h\u00e4n\u00b7den", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "PDS", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das mir von Solimen j\u00fcngsthin geschencket ist/", "tokens": ["Das", "mir", "von", "So\u00b7li\u00b7men", "j\u00fcng\u00b7sthin", "ge\u00b7schen\u00b7cket", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "ADV", "VVPP", "VAFIN", "$("], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Ich hab es tausendmahl zu guter letzt gek\u00fcst/", "tokens": ["Ich", "hab", "es", "tau\u00b7send\u00b7mahl", "zu", "gu\u00b7ter", "letzt", "ge\u00b7k\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "ADJA", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und will es dir hiemit in deinen tempel senden.", "tokens": ["Und", "will", "es", "dir", "hie\u00b7mit", "in", "dei\u00b7nen", "tem\u00b7pel", "sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "PAV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "H\u00e4ng/ wo du wilt/ es auff an deinen g\u00fcldnen w\u00e4nden/", "tokens": ["H\u00e4ng", "/", "wo", "du", "wilt", "/", "es", "auff", "an", "dei\u00b7nen", "g\u00fcld\u00b7nen", "w\u00e4n\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWAV", "PPER", "VMFIN", "$(", "PPER", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und beut der strengen zeit/ die stahl und marmel frist/", "tokens": ["Und", "beut", "der", "stren\u00b7gen", "zeit", "/", "die", "stahl", "und", "mar\u00b7mel", "frist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df sie nicht gierig sey/ durch falsche t\u00fcck und list", "tokens": ["Da\u00df", "sie", "nicht", "gie\u00b7rig", "sey", "/", "durch", "fal\u00b7sche", "t\u00fcck", "und", "list"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VAFIN", "$(", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem bande weh zu thun/ noch seine pracht zu sch\u00e4nden.", "tokens": ["Dem", "ban\u00b7de", "weh", "zu", "thun", "/", "noch", "sei\u00b7ne", "pracht", "zu", "sch\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$(", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nim es/ als erstlinge der reinsten freundschafft/ hin/", "tokens": ["Nim", "es", "/", "als", "erst\u00b7lin\u00b7ge", "der", "reins\u00b7ten", "freund\u00b7schafft", "/", "hin", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PPER", "$(", "KOKOM", "VVFIN", "ART", "ADJA", "NN", "$(", "PTKVZ", "$("], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Du siehst/ da\u00df ich getreu/ gerecht und danckbar bin/", "tokens": ["Du", "siehst", "/", "da\u00df", "ich", "ge\u00b7treu", "/", "ge\u00b7recht", "und", "dan\u00b7ck\u00b7bar", "bin", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "ADJD", "$(", "ADJD", "KON", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.11": {"text": "Drum f\u00f6rdre/ wie du pflegst/ mein gl\u00fcck auff dieser erden/", "tokens": ["Drum", "f\u00f6rd\u00b7re", "/", "wie", "du", "pflegst", "/", "mein", "gl\u00fcck", "auff", "die\u00b7ser", "er\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$(", "PWAV", "PPER", "VVFIN", "$(", "PPOSAT", "NN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Schaff/ da\u00df mir Solime das hertze selber schenckt;", "tokens": ["Schaff", "/", "da\u00df", "mir", "So\u00b7li\u00b7me", "das", "hert\u00b7ze", "sel\u00b7ber", "schenckt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "KOUS", "PPER", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Und wenn dein knecht alsdenn nicht ewig an dich denckt/", "tokens": ["Und", "wenn", "dein", "knecht", "als\u00b7denn", "nicht", "e\u00b7wig", "an", "dich", "denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "ADJD", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So la\u00df ihn aller gunst auf eins verlustig werden.", "tokens": ["So", "la\u00df", "ihn", "al\u00b7ler", "gunst", "auf", "eins", "ver\u00b7lus\u00b7tig", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PIAT", "NN", "APPR", "PIS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}