{"textgrid.poem.48428": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "6. Auf des ehrnvesten und wolgelahrten Herrn Reineri Brockmans, der griechischen Sprache Professorn am Gymnasio zu Reval, und der erbarn viel ehren- und tugendreichen Jungfrauen Dorotheen Temme Hochzeit", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Kom, sch\u00f6ner Tag, und du, o s\u00fc\u00dfer Schein,", "tokens": ["Kom", ",", "sch\u00f6\u00b7ner", "Tag", ",", "und", "du", ",", "o", "s\u00fc\u00b7\u00dfer", "Schein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$,", "KON", "PPER", "$,", "FM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wie lange wilst du denn noch au\u00dfen sein?", "tokens": ["wie", "lan\u00b7ge", "wilst", "du", "denn", "noch", "au\u00b7\u00dfen", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ADV", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kom, brich doch an! Die Laute liegt schon fertig,", "tokens": ["Kom", ",", "brich", "doch", "an", "!", "Die", "Lau\u00b7te", "liegt", "schon", "fer\u00b7tig", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVIMP", "ADV", "PTKVZ", "$.", "ART", "NN", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die Saiten stehn. Bist du nur gegenw\u00e4rtig,", "tokens": ["die", "Sai\u00b7ten", "stehn", ".", "Bist", "du", "nur", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "so soll ein Lied dir werden ausgef\u00fchrt,", "tokens": ["so", "soll", "ein", "Lied", "dir", "wer\u00b7den", "aus\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "das dich erhebt und deinen Herren ziert.", "tokens": ["das", "dich", "er\u00b7hebt", "und", "dei\u00b7nen", "Her\u00b7ren", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ach, da\u00df du itzt, da\u00df du noch heute k\u00e4mest", "tokens": ["Ach", ",", "da\u00df", "du", "itzt", ",", "da\u00df", "du", "noch", "heu\u00b7te", "k\u00e4\u00b7mest"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KOUS", "PPER", "ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "und mir di\u00df Leid, di\u00df m\u00fcde Warten n\u00e4hmest!", "tokens": ["und", "mir", "di\u00df", "Leid", ",", "di\u00df", "m\u00fc\u00b7de", "War\u00b7ten", "n\u00e4h\u00b7mest", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PDS", "NN", "$,", "PDS", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.9": {"text": "Kom, sch\u00f6ner Tag, und du, o s\u00fc\u00dfer Schein,", "tokens": ["Kom", ",", "sch\u00f6\u00b7ner", "Tag", ",", "und", "du", ",", "o", "s\u00fc\u00b7\u00dfer", "Schein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$,", "KON", "PPER", "$,", "FM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "wie lange wilst du denn noch au\u00dfen sein?", "tokens": ["wie", "lan\u00b7ge", "wilst", "du", "denn", "noch", "au\u00b7\u00dfen", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "ADV", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Herr, wer er auch wird sein, der etwas auf wird schreiben,", "tokens": ["Herr", ",", "wer", "er", "auch", "wird", "sein", ",", "der", "et\u00b7was", "auf", "wird", "schrei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "ADV", "VAFIN", "VAINF", "$,", "PRELS", "ADV", "APPR", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "das bis zum Ende hin der grauen Zeit kan bleiben,", "tokens": ["das", "bis", "zum", "En\u00b7de", "hin", "der", "grau\u00b7en", "Zeit", "kan", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPRART", "NN", "ADV", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "das seinen Tod verlacht, der wird auch zeigen an,", "tokens": ["das", "sei\u00b7nen", "Tod", "ver\u00b7lacht", ",", "der", "wird", "auch", "zei\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "VVPP", "$,", "PRELS", "VAFIN", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "was di\u00df sei f\u00fcr ein Werk, das itzo wird getan,", "tokens": ["was", "di\u00df", "sei", "f\u00fcr", "ein", "Werk", ",", "das", "it\u00b7zo", "wird", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VAFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "und wie, und wer es tut. Er wird voraus vermelden", "tokens": ["und", "wie", ",", "und", "wer", "es", "tut", ".", "Er", "wird", "vo\u00b7raus", "ver\u00b7mel\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "$,", "KON", "PWS", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "den unverzagten Mut, das Gl\u00fccke zweier Helden,", "tokens": ["den", "un\u00b7ver\u00b7zag\u00b7ten", "Mut", ",", "das", "Gl\u00fc\u00b7cke", "zwei\u00b7er", "Hel\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "die alle Furcht und Neid geschlagen unter sich,", "tokens": ["die", "al\u00b7le", "Furcht", "und", "Neid", "ge\u00b7schla\u00b7gen", "un\u00b7ter", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "KON", "NN", "VVPP", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "vor keiner M\u00fch' erbla\u00dft, bis da\u00df sie ritterlich", "tokens": ["vor", "kei\u00b7ner", "M\u00fch'", "er\u00b7bla\u00dft", ",", "bis", "da\u00df", "sie", "rit\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,", "KON", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "den teuren Dank verdient. Er wird den Lauf der Sachen", "tokens": ["den", "teu\u00b7ren", "Dank", "ver\u00b7dient", ".", "Er", "wird", "den", "Lauf", "der", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "PPER", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "durch sein ber\u00fchmbtes Buch gleich als wie sch\u00f6ner machen,", "tokens": ["durch", "sein", "be\u00b7r\u00fchmb\u00b7tes", "Buch", "gleich", "als", "wie", "sch\u00f6\u00b7ner", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADV", "KOUS", "KOKOM", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "ein ", "tokens": ["ein"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.12": {"text": "und was der alte Brauch noch heute l\u00f6blich r\u00fchmbt,", "tokens": ["und", "was", "der", "al\u00b7te", "Brauch", "noch", "heu\u00b7te", "l\u00f6b\u00b7lich", "r\u00fchmbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "auch nicht zu schelten ist. Der Brunnquell aller Tage,", "tokens": ["auch", "nicht", "zu", "schel\u00b7ten", "ist", ".", "Der", "Brunn\u00b7quell", "al\u00b7ler", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$.", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "der Gott, den Delos ehrt, tritt auf der Sternenwage", "tokens": ["der", "Gott", ",", "den", "De\u00b7los", "ehrt", ",", "tritt", "auf", "der", "Ster\u00b7nen\u00b7wa\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "mit seiner Pracht herf\u00fcr, sagt von der hohen Bahn", "tokens": ["mit", "sei\u00b7ner", "Pracht", "her\u00b7f\u00fcr", ",", "sagt", "von", "der", "ho\u00b7hen", "Bahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "den Namen, den ihr f\u00fchrt, der runden Erden an.", "tokens": ["den", "Na\u00b7men", ",", "den", "ihr", "f\u00fchrt", ",", "der", "run\u00b7den", "Er\u00b7den", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Drumb kommen wir auch ietzt. Dem Himmel will gedanket,", "tokens": ["Drumb", "kom\u00b7men", "wir", "auch", "ietzt", ".", "Dem", "Him\u00b7mel", "will", "ge\u00b7dan\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADV", "$.", "ART", "NN", "VMFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "euch Gl\u00fcck gew\u00fcndschet sein. Euch hat noch nie gewanket", "tokens": ["euch", "Gl\u00fcck", "ge\u00b7w\u00fcnd\u00b7schet", "sein", ".", "Euch", "hat", "noch", "nie", "ge\u00b7wan\u00b7ket"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVPP", "VAINF", "$.", "PPER", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "die G\u00f6ttin, die ein Rad und leichte Fl\u00fcgel f\u00fchrt,", "tokens": ["die", "G\u00f6t\u00b7tin", ",", "die", "ein", "Rad", "und", "leich\u00b7te", "Fl\u00fc\u00b7gel", "f\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "weil Vorsicht und Verstand in eurem Tun regiert.", "tokens": ["weil", "Vor\u00b7sicht", "und", "Ver\u00b7stand", "in", "eu\u00b7rem", "Tun", "re\u00b7giert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der teure ", "tokens": ["Der", "teu\u00b7re"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.22": {"text": "macht seine Cimbren froh, erbauet neue St\u00e4dte,", "tokens": ["macht", "sei\u00b7ne", "Cim\u00b7bren", "froh", ",", "er\u00b7bau\u00b7et", "neu\u00b7e", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJD", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "vermehrt sein reiches Land, l\u00e4\u00dft einer andern Welt", "tokens": ["ver\u00b7mehrt", "sein", "rei\u00b7ches", "Land", ",", "l\u00e4\u00dft", "ei\u00b7ner", "an\u00b7dern", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "durch euch sein Herze sehn, hat alles heimgestellt", "tokens": ["durch", "euch", "sein", "Her\u00b7ze", "sehn", ",", "hat", "al\u00b7les", "heim\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "PPOSAT", "NN", "VVINF", "$,", "VAFIN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "in euer weises Tun. So hoher H\u00e4upter H\u00e4user", "tokens": ["in", "eu\u00b7er", "wei\u00b7ses", "Tun", ".", "So", "ho\u00b7her", "H\u00e4up\u00b7ter", "H\u00e4u\u00b7ser"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "ADV", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "verbinden sich durch euch; der Reu\u00dfen gro\u00dfe Kaiser,", "tokens": ["ver\u00b7bin\u00b7den", "sich", "durch", "euch", ";", "der", "Reu\u00b7\u00dfen", "gro\u00b7\u00dfe", "Kai\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "$.", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "der hei\u00dft euch seinen Freund. Der edle Saphian", "tokens": ["der", "hei\u00dft", "euch", "sei\u00b7nen", "Freund", ".", "Der", "ed\u00b7le", "Sa\u00b7phi\u00b7an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "wird bald erfahren auch, was eure Treue kan,", "tokens": ["wird", "bald", "er\u00b7fah\u00b7ren", "auch", ",", "was", "eu\u00b7re", "Treu\u00b7e", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVINF", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "die seinen Nutzen sucht und unser Land vermehret.", "tokens": ["die", "sei\u00b7nen", "Nut\u00b7zen", "sucht", "und", "un\u00b7ser", "Land", "ver\u00b7meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ihr seid der L\u00e4nder Heil, macht, da\u00df der Morgen kehret", "tokens": ["Ihr", "seid", "der", "L\u00e4n\u00b7der", "Heil", ",", "macht", ",", "da\u00df", "der", "Mor\u00b7gen", "keh\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "VVFIN", "$,", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "in unsern Abend ein, da\u00df sich die Mitternacht", "tokens": ["in", "un\u00b7sern", "A\u00b7bend", "ein", ",", "da\u00df", "sich", "die", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "KOUS", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "mit beiden wie verm\u00e4hlt und eine Freundschaft macht,", "tokens": ["mit", "bei\u00b7den", "wie", "ver\u00b7m\u00e4hlt", "und", "ei\u00b7ne", "Freund\u00b7schaft", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KOKOM", "VVPP", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "die mit der Welt gleich lebt. Ihr \u00f6ffnet uns die L\u00e4nder,", "tokens": ["die", "mit", "der", "Welt", "gleich", "lebt", ".", "Ihr", "\u00f6ff\u00b7net", "uns", "die", "L\u00e4n\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "die noch verschlossen sind, zieht der Verb\u00fcndn\u00fc\u00df B\u00e4nder", "tokens": ["die", "noch", "ver\u00b7schlos\u00b7sen", "sind", ",", "zieht", "der", "Ver\u00b7b\u00fcnd\u00b7n\u00fc\u00df", "B\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVPP", "VAFIN", "$,", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.35": {"text": "umb ferne Gr\u00e4nzen her, setzt sichern Glauben ein", "tokens": ["umb", "fer\u00b7ne", "Gr\u00e4n\u00b7zen", "her", ",", "setzt", "si\u00b7chern", "Glau\u00b7ben", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$,", "VVFIN", "ADJA", "NN", "ART"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "und lehrt ein frembdes Volk, wie es uns treu mu\u00df sein.", "tokens": ["und", "lehrt", "ein", "fremb\u00b7des", "Volk", ",", "wie", "es", "uns", "treu", "mu\u00df", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "PWAV", "PPER", "PRF", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Der Preis ist euer Lohn. So nehme nun die Gaben,", "tokens": ["Der", "Preis", "ist", "eu\u00b7er", "Lohn", ".", "So", "neh\u00b7me", "nun", "die", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "die wir vor euer Heil den Sternen vorbracht haben,", "tokens": ["die", "wir", "vor", "eu\u00b7er", "Heil", "den", "Ster\u00b7nen", "vor\u00b7bracht", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "der H\u00f6chste gn\u00e4dig an! Er sei euch f\u00f6rder gut", "tokens": ["der", "H\u00f6chs\u00b7te", "gn\u00e4\u00b7dig", "an", "!", "Er", "sei", "euch", "f\u00f6r\u00b7der", "gut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJD", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "und segne, was ihr treibt, als wie er t\u00e4glich tut!", "tokens": ["und", "seg\u00b7ne", ",", "was", "ihr", "treibt", ",", "als", "wie", "er", "t\u00e4g\u00b7lich", "tut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,", "KOUS", "PWAV", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "So binden wir euch an, die ihr euch habt verbunden", "tokens": ["So", "bin\u00b7den", "wir", "euch", "an", ",", "die", "ihr", "euch", "habt", "ver\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "PTKVZ", "$,", "PRELS", "PPER", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "mit Woltun l\u00e4ngst vorhin. Seht diese s\u00fc\u00dfen Stunden", "tokens": ["mit", "Wol\u00b7tun", "l\u00e4ngst", "vor\u00b7hin", ".", "Seht", "die\u00b7se", "s\u00fc\u00b7\u00dfen", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADV", "ADV", "$.", "VVFIN", "PDAT", "ADJA", "NN"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.43": {"text": "noch tausentmal wie ietzt! Ein Wundsch ist unser Band,", "tokens": ["noch", "tau\u00b7sent\u00b7mal", "wie", "ietzt", "!", "Ein", "Wund\u00b7sch", "ist", "un\u00b7ser", "Band", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KOKOM", "ADV", "$.", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--++-++-+-+", "measure": "iambic.septa.relaxed"}, "line.44": {"text": "das nicht wird aufgel\u00f6st, als durch der G\u00fcnste Hand.", "tokens": ["das", "nicht", "wird", "auf\u00b7ge\u00b7l\u00f6st", ",", "als", "durch", "der", "G\u00fcns\u00b7te", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VAFIN", "VVPP", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Du aber, altes Jahr, verj\u00fcngre deine Glieder,", "tokens": ["Du", "a\u00b7ber", ",", "al\u00b7tes", "Jahr", ",", "ver\u00b7j\u00fcng\u00b7re", "dei\u00b7ne", "Glie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJA", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "zeuch deinen Zierrat an, nim neue Kr\u00e4fte wieder,", "tokens": ["zeuch", "dei\u00b7nen", "Zier\u00b7rat", "an", ",", "nim", "neu\u00b7e", "Kr\u00e4f\u00b7te", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "PTKVZ", "$,", "APPRART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "sei deiner Jugend gleich! November werde Mai,", "tokens": ["sei", "dei\u00b7ner", "Ju\u00b7gend", "gleich", "!", "No\u00b7vem\u00b7ber", "wer\u00b7de", "Mai", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "$.", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "mach, da\u00df f\u00fcr wei\u00dfen Schnee es wei\u00dfe Lilgen schnei',", "tokens": ["mach", ",", "da\u00df", "f\u00fcr", "wei\u00b7\u00dfen", "Schnee", "es", "wei\u00b7\u00dfe", "Lil\u00b7gen", "schnei'", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "APPR", "ADJA", "NN", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.49": {"text": "hei\u00df da sein Lust f\u00fcr Frost! Ihr armen Etesinnen", "tokens": ["hei\u00df", "da", "sein", "Lust", "f\u00fcr", "Frost", "!", "Ihr", "ar\u00b7men", "E\u00b7te\u00b7sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADV", "PPOSAT", "NN", "APPR", "NN", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "haucht unsern Winter an, und ihr, ihr Najadinnen,", "tokens": ["haucht", "un\u00b7sern", "Win\u00b7ter", "an", ",", "und", "ihr", ",", "ihr", "Na\u00b7ja\u00b7din\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "KON", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "sprengt laulicht Wasser aus, da\u00df aller Blumen Zier", "tokens": ["sprengt", "lau\u00b7licht", "Was\u00b7ser", "aus", ",", "da\u00df", "al\u00b7ler", "Blu\u00b7men", "Zier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "NN", "PTKVZ", "$,", "KOUS", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "aus der verlebten Welt vom Neuen komm' herf\u00fcr!", "tokens": ["aus", "der", "ver\u00b7leb\u00b7ten", "Welt", "vom", "Neu\u00b7en", "komm'", "her\u00b7f\u00fcr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ist er itzo schon von hinnen,", "tokens": ["Ist", "er", "it\u00b7zo", "schon", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mein und euer gro\u00dfer Freund,", "tokens": ["mein", "und", "eu\u00b7er", "gro\u00b7\u00dfer", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ihr ber\u00fchmbten Castalinnen", "tokens": ["ihr", "be\u00b7r\u00fchmb\u00b7ten", "Cas\u00b7ta\u00b7lin\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "tut drumb nicht, als wie ihr meint,", "tokens": ["tut", "drumb", "nicht", ",", "als", "wie", "ihr", "meint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "PTKNEG", "$,", "KOUS", "KOKOM", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df der sch\u00f6nste seiner Tage", "tokens": ["da\u00df", "der", "sch\u00f6ns\u00b7te", "sei\u00b7ner", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "unbeschenkt sich von uns trage!", "tokens": ["un\u00b7be\u00b7schenkt", "sich", "von", "uns", "tra\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nicht so, Meine! Stimmt die Saiten", "tokens": ["Nicht", "so", ",", "Mei\u00b7ne", "!", "Stimmt", "die", "Sai\u00b7ten"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "$,", "PPOSAT", "$.", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mischt euren Ton darein!", "tokens": ["und", "mischt", "eu\u00b7ren", "Ton", "da\u00b7rein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "La\u00dft uns heut umb Freude streiten!", "tokens": ["La\u00dft", "uns", "heut", "umb", "Freu\u00b7de", "strei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Di\u00df soll unser Reichtumb sein,", "tokens": ["Di\u00df", "soll", "un\u00b7ser", "Reich\u00b7tumb", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df wir ihm zu Dienst und Ehren", "tokens": ["da\u00df", "wir", "ihm", "zu", "Dienst", "und", "Eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "ein kurz Liedlein lassen h\u00f6ren.", "tokens": ["ein", "kurz", "Lied\u00b7lein", "las\u00b7sen", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hier rinnt unsre Hippocrene,", "tokens": ["Hier", "rinnt", "uns\u00b7re", "Hip\u00b7po\u00b7cre\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Pindus und sein Volk ist hier,", "tokens": ["Pin\u00b7dus", "und", "sein", "Volk", "ist", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "das ein hohes Lobget\u00f6ne", "tokens": ["das", "ein", "ho\u00b7hes", "Lob\u00b7ge\u00b7t\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ausschreit ihm und uns zur Zier,", "tokens": ["aus\u00b7schreit", "ihm", "und", "uns", "zur", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und die blo\u00dfen Charitinnen", "tokens": ["und", "die", "blo\u00b7\u00dfen", "Cha\u00b7ri\u00b7tin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "tanzen uns nach unsern Sinnen.", "tokens": ["tan\u00b7zen", "uns", "nach", "un\u00b7sern", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Euch, o Edler, euch zur Freude", "tokens": ["Euch", ",", "o", "Ed\u00b7ler", ",", "euch", "zur", "Freu\u00b7de"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "FM", "NN", "$,", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sieht Apollo g\u00fcldner aus,", "tokens": ["sieht", "A\u00b7pol\u00b7lo", "g\u00fcld\u00b7ner", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Luna h\u00e4ngt all ihr Geschmeide", "tokens": ["Lu\u00b7na", "h\u00e4ngt", "all", "ihr", "Ge\u00b7schmei\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PIAT", "PPOSAT", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "an ihr vollgestirntes Haus,", "tokens": ["an", "ihr", "voll\u00b7ges\u00b7tirn\u00b7tes", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df der sch\u00f6ne Tag dem Zeichen", "tokens": ["da\u00df", "der", "sch\u00f6\u00b7ne", "Tag", "dem", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der noch sch\u00f6nern Nacht mu\u00df weichen.", "tokens": ["der", "noch", "sch\u00f6\u00b7nern", "Nacht", "mu\u00df", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Der beschneite Hornung stehet", "tokens": ["Der", "be\u00b7schnei\u00b7te", "Hor\u00b7nung", "ste\u00b7het"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und streicht seinen Eisbart aus.", "tokens": ["und", "streicht", "sei\u00b7nen", "Eis\u00b7bart", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00c4olus, der alte, gehet,", "tokens": ["\u00c4\u00b7o\u00b7lus", ",", "der", "al\u00b7te", ",", "ge\u00b7het", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hemmet seiner Knechte Lauf", "tokens": ["hem\u00b7met", "sei\u00b7ner", "Knech\u00b7te", "Lauf"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und l\u00e4\u00dft keinen von so vielen", "tokens": ["und", "l\u00e4\u00dft", "kei\u00b7nen", "von", "so", "vie\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "APPR", "ADV", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "als den linden Westwind spielen.", "tokens": ["als", "den", "lin\u00b7den", "West\u00b7wind", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Das Verh\u00e4ngn\u00fc\u00df dr\u00fcckt sein Siegel", "tokens": ["Das", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "dr\u00fcckt", "sein", "Sie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in das blaue Himmelsfeld.", "tokens": ["in", "das", "blau\u00b7e", "Him\u00b7mels\u00b7feld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fama schwingt die Augenfl\u00fcgel", "tokens": ["Fa\u00b7ma", "schwingt", "die", "Au\u00b7gen\u00b7fl\u00fc\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und ruft durch die Sternenwelt,", "tokens": ["und", "ruft", "durch", "die", "Ster\u00b7nen\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "da\u00df forthin auf unsrer Erden", "tokens": ["da\u00df", "for\u00b7thin", "auf", "uns\u00b7rer", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "g\u00fcldne Zeit durch euch soll werden.", "tokens": ["g\u00fcld\u00b7ne", "Zeit", "durch", "euch", "soll", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPER", "VMFIN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "La\u00df es sein, mein Sinn, und schweige,", "tokens": ["La\u00df", "es", "sein", ",", "mein", "Sinn", ",", "und", "schwei\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VAINF", "$,", "PPOSAT", "NN", "$,", "KON", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "stelle deine Seufzer ein!", "tokens": ["stel\u00b7le", "dei\u00b7ne", "Seuf\u00b7zer", "ein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlechte Seelen, die sind feige,", "tokens": ["Schlech\u00b7te", "See\u00b7len", ",", "die", "sind", "fei\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die nur von der Erden sein.", "tokens": ["die", "nur", "von", "der", "Er\u00b7den", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Denke, denke, was du denkst,", "tokens": ["Den\u00b7ke", ",", "den\u00b7ke", ",", "was", "du", "denkst", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "da\u00df du dich so abekr\u00e4nkst!", "tokens": ["da\u00df", "du", "dich", "so", "a\u00b7be\u00b7kr\u00e4nkst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ein beherzetes Gem\u00fcte", "tokens": ["Ein", "be\u00b7her\u00b7ze\u00b7tes", "Ge\u00b7m\u00fc\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weichet keinem Gl\u00fccke nicht,", "tokens": ["wei\u00b7chet", "kei\u00b7nem", "Gl\u00fc\u00b7cke", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "es erfrischet sein Gebl\u00fcte", "tokens": ["es", "er\u00b7fri\u00b7schet", "sein", "Ge\u00b7bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn den andern ihres bricht,", "tokens": ["wenn", "den", "an\u00b7dern", "ih\u00b7res", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "PPOSAT", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "lacht und weinet nicht zu viel,", "tokens": ["lacht", "und", "wei\u00b7net", "nicht", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "will stets was sein Gl\u00fccke will.", "tokens": ["will", "stets", "was", "sein", "Gl\u00fc\u00b7cke", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PWS", "PPOSAT", "NN", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Wenn der Stahl den Stein bestreichet,", "tokens": ["Wenn", "der", "Stahl", "den", "Stein", "be\u00b7strei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so wird er erst rein und scharf.", "tokens": ["so", "wird", "er", "erst", "rein", "und", "scharf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du, mein Sinn, bists, der ihm gleichet,", "tokens": ["Du", ",", "mein", "Sinn", ",", "bists", ",", "der", "ihm", "glei\u00b7chet", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ADV", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der auch Glanz und Sch\u00e4rfe darf.", "tokens": ["der", "auch", "Glanz", "und", "Sch\u00e4r\u00b7fe", "darf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "KON", "NN", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Unfall ists, der auf uns wacht", "tokens": ["Un\u00b7fall", "ists", ",", "der", "auf", "uns", "wacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "PRELS", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und die M\u00e4nner m\u00e4nlich macht.", "tokens": ["und", "die", "M\u00e4n\u00b7ner", "m\u00e4n\u00b7lich", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ein bewehreter Soldate,", "tokens": ["Ein", "be\u00b7weh\u00b7re\u00b7ter", "Sol\u00b7da\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der vor keinem Tode zagt,", "tokens": ["der", "vor", "kei\u00b7nem", "To\u00b7de", "zagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "suchet ihm zu fr\u00fch und spate", "tokens": ["su\u00b7chet", "ihm", "zu", "fr\u00fch", "und", "spa\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKA", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einen Feind, mit dem ers wagt.", "tokens": ["ei\u00b7nen", "Feind", ",", "mit", "dem", "ers", "wagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "PIS", "VVFIN", "$."], "meter": "+-+--++", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Ein gro\u00df Herze bricht heraus,", "tokens": ["Ein", "gro\u00df", "Her\u00b7ze", "bricht", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "fordert stets sein Ungl\u00fcck aus.", "tokens": ["for\u00b7dert", "stets", "sein", "Un\u00b7gl\u00fcck", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Mein! was n\u00fctzet doch das Klagen,", "tokens": ["Mein", "!", "was", "n\u00fct\u00b7zet", "doch", "das", "Kla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df die Liebste nicht ist hier?", "tokens": ["da\u00df", "die", "Liebs\u00b7te", "nicht", "ist", "hier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mi\u00dftreu ists, so wir verzagen,", "tokens": ["Mi\u00df\u00b7treu", "ists", ",", "so", "wir", "ver\u00b7za\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "ADV", "PPER", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "sie ist allzeit \u00e4hnlich ihr.", "tokens": ["sie", "ist", "all\u00b7zeit", "\u00e4hn\u00b7lich", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wahrer Liebe treue Pflicht", "tokens": ["Wah\u00b7rer", "Lie\u00b7be", "treu\u00b7e", "Pflicht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "mindert sich durch Absein nicht.", "tokens": ["min\u00b7dert", "sich", "durch", "Ab\u00b7sein", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Dennoch ist sie in dem Herzen,", "tokens": ["Den\u00b7noch", "ist", "sie", "in", "dem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist sie aus den Augen schon.", "tokens": ["ist", "sie", "aus", "den", "Au\u00b7gen", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dieses, was du nennest Schmerzen,", "tokens": ["Die\u00b7ses", ",", "was", "du", "nen\u00b7nest", "Schmer\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "ist der rechte Liebe Lohn,", "tokens": ["ist", "der", "rech\u00b7te", "Lie\u00b7be", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die sie f\u00fchlet gleich wie du", "tokens": ["die", "sie", "f\u00fch\u00b7let", "gleich", "wie", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "VVFIN", "ADV", "KOKOM", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "und noch duppelt mehr darzu.", "tokens": ["und", "noch", "dup\u00b7pelt", "mehr", "dar\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "liebet dich noch wie vorhin.", "tokens": ["lie\u00b7bet", "dich", "noch", "wie", "vor\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Umb die du dich so betr\u00fcbest,", "tokens": ["Umb", "die", "du", "dich", "so", "be\u00b7tr\u00fc\u00b7best", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wirst du wieder sehn, mein Sinn,", "tokens": ["wirst", "du", "wie\u00b7der", "sehn", ",", "mein", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und das wird dir lieber sein", "tokens": ["und", "das", "wird", "dir", "lie\u00b7ber", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "PPER", "ADV", "PPOSAT"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "als auf Regen Sonnenschein!", "tokens": ["als", "auf", "Re\u00b7gen", "Son\u00b7nen\u00b7schein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Kommet bald, ihr sch\u00f6nen Tage,", "tokens": ["Kom\u00b7met", "bald", ",", "ihr", "sch\u00f6\u00b7nen", "Ta\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "komme bald, du s\u00fc\u00dfe Zeit,", "tokens": ["kom\u00b7me", "bald", ",", "du", "s\u00fc\u00b7\u00dfe", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df ich frei und fr\u00f6hlich sage:", "tokens": ["da\u00df", "ich", "frei", "und", "fr\u00f6h\u00b7lich", "sa\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weg, erbla\u00dfte Traurigkeit!", "tokens": ["Weg", ",", "er\u00b7bla\u00df\u00b7te", "Trau\u00b7rig\u00b7keit", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ist und bleibet stets bei mir.", "tokens": ["ist", "und", "blei\u00b7bet", "stets", "bei", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wer ihnen traut, pfl\u00fcgt in die Winde", "tokens": ["Wer", "ih\u00b7nen", "traut", ",", "pfl\u00fcgt", "in", "die", "Win\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und s\u00e4et auf die wilde See,", "tokens": ["und", "s\u00e4et", "auf", "die", "wil\u00b7de", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "mi\u00dft des verborgnen Meeres Gr\u00fcnde,", "tokens": ["mi\u00dft", "des", "ver\u00b7borg\u00b7nen", "Mee\u00b7res", "Gr\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "schreibt sein Ged\u00e4chtn\u00fc\u00df in den Schnee,", "tokens": ["schreibt", "sein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "in", "den", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "sch\u00f6pft wie die Schwestern ohne Liebe", "tokens": ["sch\u00f6pft", "wie", "die", "Schwes\u00b7tern", "oh\u00b7ne", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "das Wasser mit durchbohrtem Siebe.", "tokens": ["das", "Was\u00b7ser", "mit", "durch\u00b7bohr\u00b7tem", "Sie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Der schnelle Wind f\u00e4hrt ohne Z\u00fcgel,", "tokens": ["Der", "schnel\u00b7le", "Wind", "f\u00e4hrt", "oh\u00b7ne", "Z\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ein leichter Pfeil eilt auf Gewin,", "tokens": ["ein", "leich\u00b7ter", "Pfeil", "eilt", "auf", "Ge\u00b7win", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der starke Blitz hat frische Fl\u00fcgel,", "tokens": ["der", "star\u00b7ke", "Blitz", "hat", "fri\u00b7sche", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein strenger Fall scheust pl\u00f6tzlich hin:", "tokens": ["ein", "stren\u00b7ger", "Fall", "scheust", "pl\u00f6tz\u00b7lich", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "f\u00fcr ihren Sinnen sind nicht schnelle", "tokens": ["f\u00fcr", "ih\u00b7ren", "Sin\u00b7nen", "sind", "nicht", "schnel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wind', Pfeile, Blitz' und Wasserf\u00e4lle.", "tokens": ["Wind'", ",", "Pfei\u00b7le", ",", "Blitz'", "und", "Was\u00b7ser\u00b7f\u00e4l\u00b7le", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Ich bin froh, da\u00df ich was habe,", "tokens": ["Ich", "bin", "froh", ",", "da\u00df", "ich", "was", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "PIS", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das man dennoch hassen kan,", "tokens": ["das", "man", "den\u00b7noch", "has\u00b7sen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "und was geht mir daran abe,", "tokens": ["und", "was", "geht", "mir", "da\u00b7ran", "a\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "PAV", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df mich jener schel sicht an?", "tokens": ["da\u00df", "mich", "je\u00b7ner", "schel", "sicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Leid' ich von der Tugend wegen,", "tokens": ["Leid'", "ich", "von", "der", "Tu\u00b7gend", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "so wird mir sein Fluch zu Segen.", "tokens": ["so", "wird", "mir", "sein", "Fluch", "zu", "Se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Neid ist nur bei hohen Sachen", "tokens": ["Neid", "ist", "nur", "bei", "ho\u00b7hen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und die nicht gemeine sind,", "tokens": ["und", "die", "nicht", "ge\u00b7mei\u00b7ne", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PTKNEG", "ADJA", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "hierein setzt er seinen Rachen;", "tokens": ["hier\u00b7ein", "setzt", "er", "sei\u00b7nen", "Ra\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "des Gel\u00fccks Gef\u00e4hrt' und Kind", "tokens": ["des", "Ge\u00b7l\u00fccks", "Ge\u00b7f\u00e4hrt'", "und", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "steigt und f\u00e4llt mit seinem Rade,", "tokens": ["steigt", "und", "f\u00e4llt", "mit", "sei\u00b7nem", "Ra\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wenn es Zorn braucht oder Gnade.", "tokens": ["wenn", "es", "Zorn", "braucht", "o\u00b7der", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Gro\u00dfe Dannen, hohe Fichten,", "tokens": ["Gro\u00b7\u00dfe", "Dan\u00b7nen", ",", "ho\u00b7he", "Fich\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die best\u00fcrmt des Nordwinds Zorn,", "tokens": ["die", "be\u00b7st\u00fcrmt", "des", "Nord\u00b7winds", "Zorn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der doch nichts dran aus kan richten:", "tokens": ["der", "doch", "nichts", "dran", "aus", "kan", "rich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "PAV", "APZR", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "keine hat kein Haar verlorn.", "tokens": ["kei\u00b7ne", "hat", "kein", "Haar", "ver\u00b7lorn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "VAFIN", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer der Tugend an will siegen,", "tokens": ["Wer", "der", "Tu\u00b7gend", "an", "will", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "APZR", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "pfleget allzeit zu erliegen.", "tokens": ["pfle\u00b7get", "all\u00b7zeit", "zu", "er\u00b7lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Kaphareus verlacht die Wellen,", "tokens": ["Ka\u00b7pha\u00b7reus", "ver\u00b7lacht", "die", "Wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die sich an ihm lehnen auf.", "tokens": ["die", "sich", "an", "ihm", "leh\u00b7nen", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "APPR", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Scylla l\u00e4\u00dft die Wogen bellen,", "tokens": ["Scyl\u00b7la", "l\u00e4\u00dft", "die", "Wo\u00b7gen", "bel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "auch nicht so viel giebt sie drauf.", "tokens": ["auch", "nicht", "so", "viel", "giebt", "sie", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "La\u00df das Ungl\u00fcck' auf sie gehen,", "tokens": ["La\u00df", "das", "Un\u00b7gl\u00fcck", "auf", "sie", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Tugend steht, wie Klippen stehen.", "tokens": ["Tu\u00b7gend", "steht", ",", "wie", "Klip\u00b7pen", "ste\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PWAV", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Rost verzehrt den stillen Degen;", "tokens": ["Rost", "ver\u00b7zehrt", "den", "stil\u00b7len", "De\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "stehnde S\u00fcmpfe werden faul,", "tokens": ["stehn\u00b7de", "S\u00fcmp\u00b7fe", "wer\u00b7den", "faul", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00fcft' auch, die sich nicht bewegen;", "tokens": ["L\u00fcft'", "auch", ",", "die", "sich", "nicht", "be\u00b7we\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "PRF", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "unberitten dient kein Gaul;", "tokens": ["un\u00b7be\u00b7rit\u00b7ten", "dient", "kein", "Gaul", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00fcssiggang verderbt die Jugend;", "tokens": ["M\u00fcs\u00b7sig\u00b7gang", "ver\u00b7derbt", "die", "Ju\u00b7gend", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "unge\u00fcbt versch\u00e4lt die Tugend.", "tokens": ["un\u00b7ge\u00b7\u00fcbt", "ver\u00b7sch\u00e4lt", "die", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Tugend, die ist niemals m\u00fcssig,", "tokens": ["Tu\u00b7gend", ",", "die", "ist", "nie\u00b7mals", "m\u00fcs\u00b7sig", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sucht ihr allzeit einen Feind", "tokens": ["sucht", "ihr", "all\u00b7zeit", "ei\u00b7nen", "Feind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nie der Arbeit \u00fcberdr\u00fcssig,", "tokens": ["nie", "der", "Ar\u00b7beit", "\u00fc\u00b7berd\u00b7r\u00fcs\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aller M\u00fche steter Freund.", "tokens": ["al\u00b7ler", "M\u00fc\u00b7he", "ste\u00b7ter", "Freund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihre Sinnen und Gedanken", "tokens": ["Ih\u00b7re", "Sin\u00b7nen", "und", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind: stets laufen in dem Schranken.", "tokens": ["sind", ":", "stets", "lau\u00b7fen", "in", "dem", "Schran\u00b7ken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$.", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Die ber\u00fchmbten Dattelst\u00e4mme", "tokens": ["Die", "be\u00b7r\u00fchmb\u00b7ten", "Dat\u00b7tel\u00b7st\u00e4m\u00b7me"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "heben ihre Last empor,", "tokens": ["he\u00b7ben", "ih\u00b7re", "Last", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und tun zwischen solcher Klemme", "tokens": ["und", "tun", "zwi\u00b7schen", "sol\u00b7cher", "Klem\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "reicher ihre Zier hervor.", "tokens": ["rei\u00b7cher", "ih\u00b7re", "Zier", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ein stark Herze wird erblicket,", "tokens": ["Ein", "stark", "Her\u00b7ze", "wird", "er\u00b7bli\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "VAFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wenn es sein Verh\u00e4ngn\u00fc\u00df dr\u00fccket.", "tokens": ["wenn", "es", "sein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "dr\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Aus den ausgequetschten Trauben", "tokens": ["Aus", "den", "aus\u00b7ge\u00b7quetschten", "Trau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "k\u00f6mpt Ly\u00e4us s\u00fc\u00dfer Saft.", "tokens": ["k\u00f6mpt", "Ly\u00b7\u00e4us", "s\u00fc\u00b7\u00dfer", "Saft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Eine Rose hat, bei Glauben,", "tokens": ["Ei\u00b7ne", "Ro\u00b7se", "hat", ",", "bei", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ungerieben schw\u00e4chre Kraft.", "tokens": ["un\u00b7ge\u00b7rie\u00b7ben", "schw\u00e4ch\u00b7re", "Kraft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Tugend schmeckt und reucht gepresset,", "tokens": ["Tu\u00b7gend", "schmeckt", "und", "reucht", "ge\u00b7pres\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "welche Kost ihr Weisen esset.", "tokens": ["wel\u00b7che", "Kost", "ihr", "Wei\u00b7sen", "es\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.27": {"line.1": {"text": "Bellet, ihr erz\u00fcrnten Hunde,", "tokens": ["Bel\u00b7let", ",", "ihr", "er\u00b7z\u00fcrn\u00b7ten", "Hun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bellt die stille Ph\u00f6ben an:", "tokens": ["bellt", "die", "stil\u00b7le", "Ph\u00f6\u00b7ben", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sie bleibt wol, wo sie vor stunde,", "tokens": ["sie", "bleibt", "wol", ",", "wo", "sie", "vor", "stun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und h\u00e4lt ihre hohe Bahn.", "tokens": ["und", "h\u00e4lt", "ih\u00b7re", "ho\u00b7he", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Weisheit ist zu hoch gestiegen,", "tokens": ["Weis\u00b7heit", "ist", "zu", "hoch", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKA", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "da kein Ha\u00df ihr nach kan fliegen.", "tokens": ["da", "kein", "Ha\u00df", "ihr", "nach", "kan", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PPOSAT", "APPR", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Jene, die ich sie sein lasse,", "tokens": ["Je\u00b7ne", ",", "die", "ich", "sie", "sein", "las\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "PPER", "VAINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die nicht mehr sind als nur sein,", "tokens": ["die", "nicht", "mehr", "sind", "als", "nur", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VAFIN", "KOKOM", "ADV", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "sind nicht wert, da\u00df ich sie hasse,", "tokens": ["sind", "nicht", "wert", ",", "da\u00df", "ich", "sie", "has\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "reich an Nichts, klug auf den Schein.", "tokens": ["reich", "an", "Nichts", ",", "klug", "auf", "den", "Schein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PIS", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wahn ists, des ein Weiser lachet,", "tokens": ["Wahn", "ists", ",", "des", "ein", "Wei\u00b7ser", "la\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ART", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der sie so voll Hoffart machet.", "tokens": ["der", "sie", "so", "voll", "Hof\u00b7fart", "ma\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Unser P\u00f6fel hat die Sitten:", "tokens": ["Un\u00b7ser", "P\u00f6\u00b7fel", "hat", "die", "Sit\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "schilt, was er nicht haben kan,", "tokens": ["schilt", ",", "was", "er", "nicht", "ha\u00b7ben", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "PTKNEG", "VAINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "tadelt, warumb er mu\u00df bitten,", "tokens": ["ta\u00b7delt", ",", "wa\u00b7rumb", "er", "mu\u00df", "bit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sieht den Nachbar hart drumb an,", "tokens": ["sieht", "den", "Nach\u00b7bar", "hart", "drumb", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "PAV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und an dem er mu\u00df verzweifeln,", "tokens": ["und", "an", "dem", "er", "mu\u00df", "ver\u00b7zwei\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRELS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "das verg\u00f6nnt er allen Teufeln.", "tokens": ["das", "ver\u00b7g\u00f6nnt", "er", "al\u00b7len", "Teu\u00b7feln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Bessern soll michs, nicht betr\u00fcben,", "tokens": ["Bes\u00b7sern", "soll", "michs", ",", "nicht", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "$,", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df mich der zu tadeln pflag.", "tokens": ["da\u00df", "mich", "der", "zu", "ta\u00b7deln", "pflag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wer nicht etwas hat zu lieben,", "tokens": ["Wer", "nicht", "et\u00b7was", "hat", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "ADV", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hat nicht, was man hassen mag.", "tokens": ["hat", "nicht", ",", "was", "man", "has\u00b7sen", "mag."], "token_info": ["word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "PTKNEG", "$,", "PRELS", "PIS", "VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und umb was mich dieser neidet,", "tokens": ["Und", "umb", "was", "mich", "die\u00b7ser", "nei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRELS", "PPER", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ist, an dem er Mangel leidet.", "tokens": ["ist", ",", "an", "dem", "er", "Man\u00b7gel", "lei\u00b7det", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "PRELS", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Ich kan Einem ja verg\u00f6nnen,", "tokens": ["Ich", "kan", "Ei\u00b7nem", "ja", "ver\u00b7g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df er seines Maules braucht,", "tokens": ["da\u00df", "er", "sei\u00b7nes", "Mau\u00b7les", "braucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "redet er mir nicht zu Sinnen;", "tokens": ["re\u00b7det", "er", "mir", "nicht", "zu", "Sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wie bald ist ein Wort verhaucht!", "tokens": ["wie", "bald", "ist", "ein", "Wort", "ver\u00b7haucht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "H\u00fcte dich nur f\u00fcr den Taten!", "tokens": ["H\u00fc\u00b7te", "dich", "nur", "f\u00fcr", "den", "Ta\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gott, der wird den L\u00fcgen raten.", "tokens": ["Gott", ",", "der", "wird", "den", "L\u00fc\u00b7gen", "ra\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Steht denn meine Schand' und Ehre", "tokens": ["Steht", "denn", "mei\u00b7ne", "Schand'", "und", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so in Eines Lob und Schmach?", "tokens": ["so", "in", "Ei\u00b7nes", "Lob", "und", "Schmach", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weit gefehlt! Wenn dieses w\u00e4re,", "tokens": ["Weit", "ge\u00b7fehlt", "!", "Wenn", "die\u00b7ses", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$.", "KOUS", "PDS", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so g\u00e4b' auch kein Weiser nach.", "tokens": ["so", "g\u00e4b'", "auch", "kein", "Wei\u00b7ser", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "In die Zeit sich schicken k\u00fcnnen,", "tokens": ["In", "die", "Zeit", "sich", "schi\u00b7cken", "k\u00fcn\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "k\u00fcnnen nur ge\u00fcbte Sinnen.", "tokens": ["k\u00fcn\u00b7nen", "nur", "ge\u00b7\u00fcb\u00b7te", "Sin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Di\u00df mein redliches Gewissen", "tokens": ["Di\u00df", "mein", "red\u00b7li\u00b7ches", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist mir Zeuge gnug f\u00fcr mich.", "tokens": ["ist", "mir", "Zeu\u00b7ge", "gnug", "f\u00fcr", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NN", "ADV", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wes ich allzeit mich beflissen,", "tokens": ["Wes", "ich", "all\u00b7zeit", "mich", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wissen zwene: Gott und ich.", "tokens": ["wis\u00b7sen", "zwe\u00b7ne", ":", "Gott", "und", "ich", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "CARD", "$.", "NN", "KON", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Welcher Alles will verfechten,", "tokens": ["Wel\u00b7cher", "Al\u00b7les", "will", "ver\u00b7fech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "der mu\u00df heut' und allzeit rechten.", "tokens": ["der", "mu\u00df", "heut'", "und", "all\u00b7zeit", "rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "KON", "ADV", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Jupiter, wie hoch er sitzet,", "tokens": ["Ju\u00b7pi\u00b7ter", ",", "wie", "hoch", "er", "sit\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ist nicht von den L\u00e4strern frei.", "tokens": ["ist", "nicht", "von", "den", "L\u00e4st\u00b7rern", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn er allzeit w\u00fcrd' erhitzet,", "tokens": ["Wenn", "er", "all\u00b7zeit", "w\u00fcrd'", "er\u00b7hit\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn man ihn schilt ohne Scheu,", "tokens": ["wenn", "man", "ihn", "schilt", "oh\u00b7ne", "Scheu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "so w\u00fcrd' er in kurzen Weilen", "tokens": ["so", "w\u00fcrd'", "er", "in", "kur\u00b7zen", "Wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "werden arm an Blitz und Keilen.", "tokens": ["wer\u00b7den", "arm", "an", "Blitz", "und", "Kei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Will dich Einer nicht begr\u00fc\u00dfen,", "tokens": ["Will", "dich", "Ei\u00b7ner", "nicht", "be\u00b7gr\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so beh\u00e4ltst du deinen Dank.", "tokens": ["so", "be\u00b7h\u00e4ltst", "du", "dei\u00b7nen", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Setzt er dich schon nicht auf K\u00fcssen,", "tokens": ["Setzt", "er", "dich", "schon", "nicht", "auf", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "PTKNEG", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sei vergn\u00fcgt mit blo\u00dfer Bank!", "tokens": ["sei", "ver\u00b7gn\u00fcgt", "mit", "blo\u00b7\u00dfer", "Bank", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er und alle, die dich hassen,", "tokens": ["Er", "und", "al\u00b7le", ",", "die", "dich", "has\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PIS", "$,", "PRELS", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "m\u00fcssen doch dich dich sein lassen.", "tokens": ["m\u00fcs\u00b7sen", "doch", "dich", "dich", "sein", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPER", "PRF", "PPOSAT", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "La\u00df sie sein, die Theons-Br\u00fcder,", "tokens": ["La\u00df", "sie", "sein", ",", "die", "The\u00b7ons\u00b7Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VAINF", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die Geschwister Zoilus',", "tokens": ["die", "Ge\u00b7schwis\u00b7ter", "Zoi\u00b7lus'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "und la\u00df deine guten Lieder,", "tokens": ["und", "la\u00df", "dei\u00b7ne", "gu\u00b7ten", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "die der Ha\u00df auch lieben mu\u00df,", "tokens": ["die", "der", "Ha\u00df", "auch", "lie\u00b7ben", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die die Unehr' auch mu\u00df ehren,", "tokens": ["die", "die", "Un\u00b7ehr'", "auch", "mu\u00df", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "umb die Fl\u00fc\u00df und P\u00fcscher h\u00f6ren!", "tokens": ["umb", "die", "Fl\u00fc\u00df", "und", "P\u00fc\u00b7scher", "h\u00f6\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Er, der liebste deiner Tage,", "tokens": ["Er", ",", "der", "liebs\u00b7te", "dei\u00b7ner", "Ta\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "den der g\u00fcldne Titan tr\u00e4gt", "tokens": ["den", "der", "g\u00fcld\u00b7ne", "Ti\u00b7tan", "tr\u00e4gt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "auf der hohen Sternenwage", "tokens": ["auf", "der", "ho\u00b7hen", "Ster\u00b7nen\u00b7wa\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und in diese Stunden legt,", "tokens": ["und", "in", "die\u00b7se", "Stun\u00b7den", "legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "er, der liebste, hei\u00dft uns lachen", "tokens": ["er", ",", "der", "liebs\u00b7te", ",", "hei\u00dft", "uns", "la\u00b7chen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ART", "ADJA", "$,", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und mit dir uns lustig machen.", "tokens": ["und", "mit", "dir", "uns", "lus\u00b7tig", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Wol! Damit du seist gebunden,", "tokens": ["Wol", "!", "Da\u00b7mit", "du", "seist", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "KOUS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "so sei dieser Eppichstrau\u00df", "tokens": ["so", "sei", "die\u00b7ser", "Ep\u00b7pich\u00b7strau\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PDAT", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "in dein wei\u00dfes Haar gewunden!", "tokens": ["in", "dein", "wei\u00b7\u00dfes", "Haar", "ge\u00b7wun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Freund, es geht auf L\u00f6sen aus!", "tokens": ["Freund", ",", "es", "geht", "auf", "L\u00f6\u00b7sen", "aus", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Du wirst nicht ohn' deinen Schaden", "tokens": ["Du", "wirst", "nicht", "ohn'", "dei\u00b7nen", "Scha\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "uns darf\u00fcr ein m\u00fcssen laden.", "tokens": ["uns", "dar\u00b7f\u00fcr", "ein", "m\u00fcs\u00b7sen", "la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PAV", "PTKVZ", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Wir sind da, wir treuen Dreie,", "tokens": ["Wir", "sind", "da", ",", "wir", "treu\u00b7en", "Drei\u00b7e", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die du mehr als vor nun kennst,", "tokens": ["die", "du", "mehr", "als", "vor", "nun", "kennst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "KOKOM", "APPR", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "die du dir verkn\u00fcpfst aufs Neue,", "tokens": ["die", "du", "dir", "ver\u00b7kn\u00fcpfst", "aufs", "Neu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVFIN", "APPRART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df du sie mehr deine nennst.", "tokens": ["da\u00df", "du", "sie", "mehr", "dei\u00b7ne", "nennst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "PPOSAT", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wir sind da mit dem Verlangen,", "tokens": ["Wir", "sind", "da", "mit", "dem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "was du denn nun an wirst fangen.", "tokens": ["was", "du", "denn", "nun", "an", "wirst", "fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "APZR", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Folge, Bruder, was zu \u00fcben", "tokens": ["Fol\u00b7ge", ",", "Bru\u00b7der", ",", "was", "zu", "\u00fc\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "PRELS", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wir und Zeit und Himmel hei\u00dft!", "tokens": ["wir", "und", "Zeit", "und", "Him\u00b7mel", "hei\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein! wer wolte Den doch lieben,", "tokens": ["Mein", "!", "wer", "wol\u00b7te", "Den", "doch", "lie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$.", "PWS", "VMFIN", "ART", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der sich stets der Lust entrei\u00dft?", "tokens": ["der", "sich", "stets", "der", "Lust", "ent\u00b7rei\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn ists Zeit, da\u00df wir uns gr\u00e4men,", "tokens": ["Denn", "ists", "Zeit", ",", "da\u00df", "wir", "uns", "gr\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wenn wir unsers Gl\u00fccks uns sch\u00e4men?", "tokens": ["wenn", "wir", "un\u00b7sers", "Gl\u00fccks", "uns", "sch\u00e4\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Brauch' der Zeit! Die leichten Stunden", "tokens": ["Brauch'", "der", "Zeit", "!", "Die", "leich\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "schie\u00dfen schneller als kein Flu\u00df.", "tokens": ["schie\u00b7\u00dfen", "schnel\u00b7ler", "als", "kein", "Flu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KOKOM", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zeit hat Fl\u00fcgel angebunden,", "tokens": ["Zeit", "hat", "Fl\u00fc\u00b7gel", "an\u00b7ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gl\u00fccke steht auf glattem Fu\u00df,", "tokens": ["Gl\u00fc\u00b7cke", "steht", "auf", "glat\u00b7tem", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und die hat nur vornen Haare,", "tokens": ["und", "die", "hat", "nur", "vor\u00b7nen", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die nicht allzeit k\u00f6mpt im Jahre.", "tokens": ["die", "nicht", "all\u00b7zeit", "k\u00f6mpt", "im", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.42": {"line.1": {"text": "Gott wei\u00df was wir morgen machen;", "tokens": ["Gott", "wei\u00df", "was", "wir", "mor\u00b7gen", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PWS", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "heute la\u00df uns lustig sein!", "tokens": ["heu\u00b7te", "la\u00df", "uns", "lus\u00b7tig", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Trauren, Frohsein, Weinen, Lachen,", "tokens": ["Trau\u00b7ren", ",", "Froh\u00b7sein", ",", "Wei\u00b7nen", ",", "La\u00b7chen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ziehn bald bei uns aus, bald ein.", "tokens": ["ziehn", "bald", "bei", "uns", "aus", ",", "bald", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "PTKVZ", "$,", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wol dem, welcher ist vergn\u00fcget,", "tokens": ["Wol", "dem", ",", "wel\u00b7cher", "ist", "ver\u00b7gn\u00fc\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PWAT", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie sich sein Verh\u00e4ngn\u00fc\u00df f\u00fcget!", "tokens": ["wie", "sich", "sein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "f\u00fc\u00b7get", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Bringt uns Lauten, Geigen, Fl\u00f6ten!", "tokens": ["Bringt", "uns", "Lau\u00b7ten", ",", "Gei\u00b7gen", ",", "Fl\u00f6\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Junger, hole das Regal!", "tokens": ["Jun\u00b7ger", ",", "ho\u00b7le", "das", "Re\u00b7gal", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die Musik kan Trauren t\u00f6ten,", "tokens": ["Die", "Mu\u00b7sik", "kan", "Trau\u00b7ren", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "VVFIN", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "sie zertreibt der Sinnen Qual.", "tokens": ["sie", "zer\u00b7treibt", "der", "Sin\u00b7nen", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Auch die G\u00f6tter sind betr\u00fcbet,", "tokens": ["Auch", "die", "G\u00f6t\u00b7ter", "sind", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wo nicht sie die Freude giebet.", "tokens": ["wo", "nicht", "sie", "die", "Freu\u00b7de", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Wenn wir edlen Menschen sitzen", "tokens": ["Wenn", "wir", "ed\u00b7len", "Men\u00b7schen", "sit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "umb den Ofen und ein Glas,", "tokens": ["umb", "den", "O\u00b7fen", "und", "ein", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und an Seel' und Leibern hitzen,", "tokens": ["und", "an", "Seel'", "und", "Lei\u00b7bern", "hit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so ist besser Nichts als das,", "tokens": ["so", "ist", "bes\u00b7ser", "Nichts", "als", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "PIS", "KOKOM", "PDS", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "da\u00df man bei so s\u00fc\u00dfen Dingen", "tokens": ["da\u00df", "man", "bei", "so", "s\u00fc\u00b7\u00dfen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "auch l\u00e4\u00dft s\u00fc\u00dfe Lieder klingen.", "tokens": ["auch", "l\u00e4\u00dft", "s\u00fc\u00b7\u00dfe", "Lie\u00b7der", "klin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Her die Schalen! Frisch, ihr Br\u00fcder!", "tokens": ["Her", "die", "Scha\u00b7len", "!", "Frisch", ",", "ihr", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "NE", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir sind heut' und morgen hier.", "tokens": ["Wir", "sind", "heut'", "und", "mor\u00b7gen", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KON", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich warlich komme wieder,", "tokens": ["Da\u00df", "ich", "war\u00b7lich", "kom\u00b7me", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "so gilt, Herr ", "tokens": ["so", "gilt", ",", "Herr"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "$,", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "der Trunk dieses weiten R\u00f6mers", "tokens": ["der", "Trunk", "die\u00b7ses", "wei\u00b7ten", "R\u00f6\u00b7mers"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PDAT", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "auf Gesundheit unsers ", "tokens": ["auf", "Ge\u00b7sund\u00b7heit", "un\u00b7sers"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "der Sandstrich, dessen Feld gr\u00e4nzt mit dem Tarterlande", "tokens": ["der", "Sand\u00b7strich", ",", "des\u00b7sen", "Feld", "gr\u00e4nzt", "mit", "dem", "Tar\u00b7ter\u00b7lan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und von der wei\u00dfen See l\u00e4uft zum Bahuverstrande,", "tokens": ["und", "von", "der", "wei\u00b7\u00dfen", "See", "l\u00e4uft", "zum", "Ba\u00b7hu\u00b7ver\u00b7stran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "aus dem kein Strom nicht fleust und der doch viel schlurft ein,", "tokens": ["aus", "dem", "kein", "Strom", "nicht", "fleust", "und", "der", "doch", "viel", "schlurft", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "PTKNEG", "VVFIN", "KON", "ART", "ADV", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "so da\u00df die Erde sie schlingt oder Sonnenschein.", "tokens": ["so", "da\u00df", "die", "Er\u00b7de", "sie", "schlingt", "o\u00b7der", "Son\u00b7nen\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "PPER", "VVFIN", "KON", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.47": {"line.1": {"text": "da\u00df auch in der Barbarei", "tokens": ["da\u00df", "auch", "in", "der", "Bar\u00b7ba\u00b7rei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Alles nicht barbarisch sei.", "tokens": ["Al\u00b7les", "nicht", "bar\u00b7ba\u00b7risch", "sei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PTKNEG", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "So viel Athen und Rom an Weisheit Sch\u00f6nes hat,", "tokens": ["So", "viel", "A\u00b7then", "und", "Rom", "an", "Weis\u00b7heit", "Sch\u00f6\u00b7nes", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NE", "APPR", "NN", "NE", "VAFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "so viel hat Beides dir gegeben in der Tat,", "tokens": ["so", "viel", "hat", "Bei\u00b7des", "dir", "ge\u00b7ge\u00b7ben", "in", "der", "Tat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PIS", "PPER", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "o du der Musen Zier und Lust der Charitinnen,", "tokens": ["o", "du", "der", "Mu\u00b7sen", "Zier", "und", "Lust", "der", "Cha\u00b7ri\u00b7tin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "PPER", "ART", "NN", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "den jeder lieben mu\u00df, der Liebe kan beginnen!", "tokens": ["den", "je\u00b7der", "lie\u00b7ben", "mu\u00df", ",", "der", "Lie\u00b7be", "kan", "be\u00b7gin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VMFIN", "$,", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich ehre deinen Geist und wundre mich der Kunst,", "tokens": ["Ich", "eh\u00b7re", "dei\u00b7nen", "Geist", "und", "wund\u00b7re", "mich", "der", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "doch \u00fcbertrifft sie zwei der Freundschaft werte Gunst.", "tokens": ["doch", "\u00fc\u00b7bert\u00b7rifft", "sie", "zwei", "der", "Freund\u00b7schaft", "wer\u00b7te", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "CARD", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich wei\u00df nicht, was ich vor und nach an dir soll lieben.", "tokens": ["Ich", "wei\u00df", "nicht", ",", "was", "ich", "vor", "und", "nach", "an", "dir", "soll", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "PTKVZ", "KON", "APPR", "APPR", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Di\u00df wei\u00df ich, du bist mir ganz in den Sinn geschrieben.", "tokens": ["Di\u00df", "wei\u00df", "ich", ",", "du", "bist", "mir", "ganz", "in", "den", "Sinn", "ge\u00b7schrie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.49": {"line.1": {"text": "Ja, Leben, ich bin angez\u00fcndet", "tokens": ["Ja", ",", "Le\u00b7ben", ",", "ich", "bin", "an\u00b7ge\u00b7z\u00fcn\u00b7det"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von deiner Liebe keuschen Brunst.", "tokens": ["von", "dei\u00b7ner", "Lie\u00b7be", "keu\u00b7schen", "Brunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was meine freien Sinnen bindet,", "tokens": ["Was", "mei\u00b7ne", "frei\u00b7en", "Sin\u00b7nen", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das sind die Ketten deiner Gunst.", "tokens": ["das", "sind", "die", "Ket\u00b7ten", "dei\u00b7ner", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Wie selten sind sie sonst beisammen", "tokens": ["Wie", "sel\u00b7ten", "sind", "sie", "sonst", "bei\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ein Leib und Geist an Zier gleich reich!", "tokens": ["ein", "Leib", "und", "Geist", "an", "Zier", "gleich", "reich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Di\u00df duppelt meiner Liebe Flammen:", "tokens": ["Di\u00df", "dup\u00b7pelt", "mei\u00b7ner", "Lie\u00b7be", "Flam\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bei dir ist Schmuck und Zucht zugleich.", "tokens": ["bei", "dir", "ist", "Schmuck", "und", "Zucht", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Der Glanz, die Sch\u00f6nheit, das Geb\u00e4rden", "tokens": ["Der", "Glanz", ",", "die", "Sch\u00f6n\u00b7heit", ",", "das", "Ge\u00b7b\u00e4r\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "war dich zu lieben \u00fcbrig satt,", "tokens": ["war", "dich", "zu", "lie\u00b7ben", "\u00fcb\u00b7rig", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKZU", "VVINF", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "doch mu\u00df di\u00df vor ger\u00fchmet werden,", "tokens": ["doch", "mu\u00df", "di\u00df", "vor", "ge\u00b7r\u00fch\u00b7met", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PDS", "APPR", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df deine Jugend Tugend hat.", "tokens": ["da\u00df", "dei\u00b7ne", "Ju\u00b7gend", "Tu\u00b7gend", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "So kom und la\u00df mich werden innen", "tokens": ["So", "kom", "und", "la\u00df", "mich", "wer\u00b7den", "in\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVIMP", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der sch\u00f6nen Freuden s\u00fc\u00dfen Frucht!", "tokens": ["der", "sch\u00f6\u00b7nen", "Freu\u00b7den", "s\u00fc\u00b7\u00dfen", "Frucht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schatz, dich allein besitzen k\u00f6nnen,", "tokens": ["Schatz", ",", "dich", "al\u00b7lein", "be\u00b7sit\u00b7zen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADV", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ist einig, was mein Herze sucht!", "tokens": ["ist", "ei\u00b7nig", ",", "was", "mein", "Her\u00b7ze", "sucht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}