{"textgrid.poem.37957": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Der best\u00e4ndige Freyer", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Andreas lieber Schutzpatron,", "tokens": ["A\u00b7ndre\u00b7as", "lie\u00b7ber", "Schutz\u00b7pat\u00b7ron", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gib mir doch nur einen Mann!", "tokens": ["Gib", "mir", "doch", "nur", "ei\u00b7nen", "Mann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "R\u00e4che doch jezt meinen Hohn,", "tokens": ["R\u00e4\u00b7che", "doch", "jezt", "mei\u00b7nen", "Hohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sieh mein sch\u00f6nes Alter an!", "tokens": ["Sieh", "mein", "sch\u00f6\u00b7nes", "Al\u00b7ter", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Krieg ich einen oder keinen? \u2013 Einen.", "tokens": ["Krieg", "ich", "ei\u00b7nen", "o\u00b7der", "kei\u00b7nen", "?", "\u2013", "Ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NN", "PPER", "ART", "KON", "PIAT", "$.", "$(", "ART", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Einen krieg ich? Das ist sch\u00f6n!", "tokens": ["Ei\u00b7nen", "krieg", "ich", "?", "Das", "ist", "sch\u00f6n", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "$.", "PDS", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird er auch best\u00e4ndig seyn?", "tokens": ["Wird", "er", "auch", "be\u00b7st\u00e4n\u00b7dig", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird er auch zu andern gehn?", "tokens": ["Wird", "er", "auch", "zu", "an\u00b7dern", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder sucht er mir allein", "tokens": ["O\u00b7der", "sucht", "er", "mir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und sonst keiner zu gefallen? \u2013 Allen.", "tokens": ["Und", "sonst", "kei\u00b7ner", "zu", "ge\u00b7fal\u00b7len", "?", "\u2013", "Al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KON", "ADV", "PIS", "PTKZU", "VVINF", "$.", "$(", "NE", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Allen? Ey das w\u00e4r nicht gut!", "tokens": ["Al\u00b7len", "?", "Ey", "das", "w\u00e4r", "nicht", "gut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "PDS", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist er sch\u00f6n und wohlgestalt?", "tokens": ["Ist", "er", "sch\u00f6n", "und", "wohl\u00b7ge\u00b7stalt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ists ein Mensch der viel verthut?", "tokens": ["Ists", "ein", "Mensch", "der", "viel", "ver\u00b7thut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ART", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ists ein Witwer? Ist er alt?", "tokens": ["Ists", "ein", "Wit\u00b7wer", "?", "Ist", "er", "alt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$.", "VAFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist er hitzig oder k\u00e4ltlich? \u2013 Aeltlich.", "tokens": ["Ist", "er", "hit\u00b7zig", "o\u00b7der", "k\u00e4lt\u00b7lich", "?", "\u2013", "A\u00b7elt\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADJD", "$.", "$(", "ADJD", "$."], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}}, "stanza.4": {"line.1": {"text": "Aeltlich? Aber doch galant?", "tokens": ["A\u00b7elt\u00b7lich", "?", "A\u00b7ber", "doch", "ga\u00b7lant", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun so sage mir geschwind:", "tokens": ["Nun", "so", "sa\u00b7ge", "mir", "ge\u00b7schwind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer ist ihm denn anverwandt,", "tokens": ["Wer", "ist", "ihm", "denn", "an\u00b7ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und wer seine Freunde sind?", "tokens": ["Und", "wer", "sei\u00b7ne", "Freun\u00b7de", "sind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sind sie auch von meines Gleichen? \u2013 Leichen.", "tokens": ["Sind", "sie", "auch", "von", "mei\u00b7nes", "Glei\u00b7chen", "?", "\u2013", "Lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$.", "$(", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Leichen? Ey, so erbt er viel!", "tokens": ["Lei\u00b7chen", "?", "Ey", ",", "so", "erbt", "er", "viel", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat er auch ein eignes Haus,", "tokens": ["Hat", "er", "auch", "ein", "eig\u00b7nes", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn er mich nun haben will:", "tokens": ["Wenn", "er", "mich", "nun", "ha\u00b7ben", "will", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und wie sieht es drinnen aus?", "tokens": ["Und", "wie", "sieht", "es", "drin\u00b7nen", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist es auch von h\u00fcbscher L\u00e4nge? \u2013 Enge.", "tokens": ["Ist", "es", "auch", "von", "h\u00fcb\u00b7scher", "L\u00e4n\u00b7ge", "?", "\u2013", "En\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$.", "$(", "NE", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Enge? Ey wer fragt darnach?", "tokens": ["En\u00b7ge", "?", "Ey", "wer", "fragt", "dar\u00b7nach", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "PWS", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wenn er nur ein gr\u00f6\u00dfres schafft.", "tokens": ["Wenn", "er", "nur", "ein", "gr\u00f6\u00df\u00b7res", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie stehts ums Schlafgemach?", "tokens": ["Und", "wie", "stehts", "ums", "Schlaf\u00b7ge\u00b7mach", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "APPRART", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Ist das Bette auch von Tafft,", "tokens": ["Ist", "das", "Bet\u00b7te", "auch", "von", "Tafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo ich drinnen liegen werde? \u2013 Erde.", "tokens": ["Wo", "ich", "drin\u00b7nen", "lie\u00b7gen", "wer\u00b7de", "?", "\u2013", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VVINF", "VAFIN", "$.", "$(", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Erde? Das klingt wunderlich,", "tokens": ["Er\u00b7de", "?", "Das", "klingt", "wun\u00b7der\u00b7lich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PDS", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein sehr nachdenklich Wort!", "tokens": ["Ist", "ein", "sehr", "nach\u00b7denk\u00b7lich", "Wort", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADV", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Andreas, ach! ich bitte dich,", "tokens": ["A\u00b7ndre\u00b7as", ",", "ach", "!", "ich", "bit\u00b7te", "dich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ITJ", "$.", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sage mir doch auch den Ort,", "tokens": ["Sa\u00b7ge", "mir", "doch", "auch", "den", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo du ihn hast aufgehoben: \u2013 Oben.", "tokens": ["Wo", "du", "ihn", "hast", "auf\u00b7ge\u00b7ho\u00b7ben", ":", "\u2013", "O\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VAFIN", "VVPP", "$.", "$(", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Oben hat er seinen Platz?", "tokens": ["O\u00b7ben", "hat", "er", "sei\u00b7nen", "Platz", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nun, so merk' ich meine Noth,", "tokens": ["Nun", ",", "so", "merk'", "ich", "mei\u00b7ne", "Noth", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der mir jezt beschriebene Schatz", "tokens": ["Der", "mir", "jezt", "be\u00b7schrie\u00b7be\u00b7ne", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ist vielleicht wohl gar schon todt,", "tokens": ["Ist", "viel\u00b7leicht", "wohl", "gar", "schon", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist mir sonst nichts \u00fcbrig blieben? \u2013 Lieben.", "tokens": ["Ist", "mir", "sonst", "nichts", "\u00fcb\u00b7rig", "blie\u00b7ben", "?", "\u2013", "Lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIS", "ADJD", "VVFIN", "$.", "$(", "ADJA", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Lieben soll ich nun das Grab?", "tokens": ["Lie\u00b7ben", "soll", "ich", "nun", "das", "Grab", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "VMFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach! wie manches Herzeleid,", "tokens": ["Ach", "!", "wie", "man\u00b7ches", "Her\u00b7ze\u00b7leid", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PWAV", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich keinen haben mag,", "tokens": ["Weil", "ich", "kei\u00b7nen", "ha\u00b7ben", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "VAINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier in dieser Sterblichkeit,", "tokens": ["Hier", "in", "die\u00b7ser", "Sterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Keinen Krummen, keinen Lahmen! \u2013 Amen.", "tokens": ["Kei\u00b7nen", "Krum\u00b7men", ",", "kei\u00b7nen", "Lah\u00b7men", "!", "\u2013", "A\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$.", "$(", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}