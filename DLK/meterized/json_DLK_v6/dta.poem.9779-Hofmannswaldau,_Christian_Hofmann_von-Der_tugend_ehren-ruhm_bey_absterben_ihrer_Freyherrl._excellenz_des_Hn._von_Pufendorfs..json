{"dta.poem.9779": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der tugend ehren-ruhm bey absterben ihrer  \n Freyherrl. excellenz des Hn. von Pufendorfs.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Njm/ grosser Pufendorff! nicht ungen\u00e4dig auff/", "tokens": ["Njm", "/", "gros\u00b7ser", "Pu\u00b7fen\u00b7dorff", "!", "nicht", "un\u00b7ge\u00b7n\u00e4\u00b7dig", "auff", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADJA", "NN", "$.", "PTKNEG", "ADJD", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich bey deiner bahr auch lasse thr\u00e4nen fl\u00fcssen.", "tokens": ["Da\u00df", "ich", "bey", "dei\u00b7ner", "bahr", "auch", "las\u00b7se", "thr\u00e4\u00b7nen", "fl\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "VVFIN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn weil die wehmuth mich gantz aus mich selbst gerissen/", "tokens": ["Denn", "weil", "die", "weh\u00b7muth", "mich", "gantz", "aus", "mich", "selbst", "ge\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PPER", "ADV", "APPR", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So kan ich meinem schmertz nicht hemmen seinen lauff.", "tokens": ["So", "kan", "ich", "mei\u00b7nem", "schmertz", "nicht", "hem\u00b7men", "sei\u00b7nen", "lauff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich w\u00fcnschte/ da\u00df mein geist recht hoch sich k\u00f6nte schwingen/", "tokens": ["Ich", "w\u00fcnschte", "/", "da\u00df", "mein", "geist", "recht", "hoch", "sich", "k\u00f6n\u00b7te", "schwin\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPOSAT", "NN", "ADJD", "ADJD", "PRF", "VMFIN", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und dir ein pr\u00e4chtig lied bey deinem grabe singen.", "tokens": ["Und", "dir", "ein", "pr\u00e4ch\u00b7tig", "lied", "bey", "dei\u00b7nem", "gra\u00b7be", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch wird dein sanffter geist/ der nichts von schn\u00f6der pracht", "tokens": ["Doch", "wird", "dein", "sanff\u00b7ter", "geist", "/", "der", "nichts", "von", "schn\u00f6\u00b7der", "pracht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN", "$(", "ART", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wort-gepr\u00e4ngen hielt/ auch einfalt nicht verschm\u00e4hen;", "tokens": ["Und", "wor\u00b7tge\u00b7pr\u00e4n\u00b7gen", "hielt", "/", "auch", "ein\u00b7falt", "nicht", "ver\u00b7schm\u00e4\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "$(", "ADV", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Hat Artaxerxes doch das hertz nur angesehen/", "tokens": ["Hat", "Ar\u00b7ta\u00b7xe\u00b7rxes", "doch", "das", "hertz", "nur", "an\u00b7ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als in der hand ein knecht ihm wasser hat gebracht.", "tokens": ["Als", "in", "der", "hand", "ein", "knecht", "ihm", "was\u00b7ser", "hat", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN", "PPER", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum gl\u00e4ntzt mein reim schon nicht von gold und edelsteinen/", "tokens": ["Drum", "gl\u00e4ntzt", "mein", "reim", "schon", "nicht", "von", "gold", "und", "e\u00b7del\u00b7stei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "APPR", "NN", "KON", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So g\u00f6nne/ da\u00df ich nur mag mit papier erscheinen.", "tokens": ["So", "g\u00f6n\u00b7ne", "/", "da\u00df", "ich", "nur", "mag", "mit", "pa\u00b7pier", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "PPER", "ADV", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich seh/ da\u00df Teutschland itzt legt flor und schleyer an/", "tokens": ["Ich", "seh", "/", "da\u00df", "Teutschland", "itzt", "legt", "flor", "und", "schle\u00b7yer", "an", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "NE", "ADV", "VVFIN", "VVFIN", "KON", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und die gelehrte schaar empfindet leid und schmertzen/", "tokens": ["Und", "die", "ge\u00b7lehr\u00b7te", "schaar", "emp\u00b7fin\u00b7det", "leid", "und", "schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADJD", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als der dein todes-fall geht leider so zu hertzen/", "tokens": ["Als", "der", "dein", "to\u00b7des\u00b7fall", "geht", "lei\u00b7der", "so", "zu", "hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df sie vor traurigkeit sich kaum begreiffen kan.", "tokens": ["Da\u00df", "sie", "vor", "trau\u00b7rig\u00b7keit", "sich", "kaum", "be\u00b7greif\u00b7fen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie steht best\u00fcrtzt/ erbla\u00dft mit kl\u00e4glichen geberden/", "tokens": ["Sie", "steht", "be\u00b7st\u00fcrtzt", "/", "er\u00b7bla\u00dft", "mit", "kl\u00e4g\u00b7li\u00b7chen", "ge\u00b7ber\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$(", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weil ihre klugen man tr\u00e4gt nach und nach zur erden.", "tokens": ["Weil", "ih\u00b7re", "klu\u00b7gen", "man", "tr\u00e4gt", "nach", "und", "nach", "zur", "er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "PIS", "VVFIN", "APPR", "KON", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Was aber sag ich doch? ist Teutschland nur allein/", "tokens": ["Was", "a\u00b7ber", "sag", "ich", "doch", "?", "ist", "Teutschland", "nur", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "ADV", "$.", "VAFIN", "NE", "ADV", "ADV", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das dich/ o theurer mann/ bejammert und beklaget?", "tokens": ["Das", "dich", "/", "o", "theu\u00b7rer", "mann", "/", "be\u00b7jam\u00b7mert", "und", "be\u00b7kla\u00b7get", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "$(", "FM", "ADJD", "NN", "$(", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich d\u00fcnckt/ Europa selbst/ von dem du viel gesaget", "tokens": ["Mich", "d\u00fcnckt", "/", "Eu\u00b7ro\u00b7pa", "selbst", "/", "von", "dem", "du", "viel", "ge\u00b7sa\u00b7get"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "NE", "ADV", "$(", "APPR", "PRELS", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und seinen staat erzehlt/ wird meistens traurig seyn;", "tokens": ["Und", "sei\u00b7nen", "staat", "er\u00b7zehlt", "/", "wird", "meis\u00b7tens", "trau\u00b7rig", "seyn", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$(", "VAFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn weil dein hoher ruhm weit in der welt erklungen/", "tokens": ["Denn", "weil", "dein", "ho\u00b7her", "ruhm", "weit", "in", "der", "welt", "er\u00b7klun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "ADJA", "NN", "ADJD", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So wird von musen auch dein tod ietzt weit besungen.", "tokens": ["So", "wird", "von", "mu\u00b7sen", "auch", "dein", "tod", "ietzt", "weit", "be\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "VMFIN", "ADV", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Di\u00df ist gewi\u00df: da\u00df du sein prei\u00df gewesen bist/", "tokens": ["Di\u00df", "ist", "ge\u00b7wi\u00df", ":", "da\u00df", "du", "sein", "prei\u00df", "ge\u00b7we\u00b7sen", "bist", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "$.", "KOUS", "PPER", "PPOSAT", "NN", "VAPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit dem es dieser zeit so herrlich k\u00f6nte prangen;", "tokens": ["Mit", "dem", "es", "die\u00b7ser", "zeit", "so", "herr\u00b7lich", "k\u00f6n\u00b7te", "pran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PDAT", "NN", "ADV", "ADJD", "VMFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In Norden ist durch dich ein solch licht aufgegangen/", "tokens": ["In", "Nor\u00b7den", "ist", "durch", "dich", "ein", "solch", "licht", "auf\u00b7ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "APPR", "PPER", "ART", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das die gelehrte welt zum Pharus nun erkiest.", "tokens": ["Das", "die", "ge\u00b7lehr\u00b7te", "welt", "zum", "Pha\u00b7rus", "nun", "er\u00b7kiest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich schweige! was itzund der Brennen land wird sagen/", "tokens": ["Ich", "schwei\u00b7ge", "!", "was", "it\u00b7zund", "der", "Bren\u00b7nen", "land", "wird", "sa\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "ADV", "ART", "ADJA", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da deines gleichen es nicht leichtlich wird erfragen.", "tokens": ["Da", "dei\u00b7nes", "glei\u00b7chen", "es", "nicht", "leicht\u00b7lich", "wird", "er\u00b7fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "PPER", "PTKNEG", "ADJD", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Zwar ist verwegenheit/ da\u00df ich mich untersteh/", "tokens": ["Zwar", "ist", "ver\u00b7we\u00b7gen\u00b7heit", "/", "da\u00df", "ich", "mich", "un\u00b7ter\u00b7steh", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "$(", "KOUS", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein welt geprie\u00dfnes thun zu r\u00fchmen und zu loben/", "tokens": ["Dein", "welt", "ge\u00b7prie\u00df\u00b7nes", "thun", "zu", "r\u00fch\u00b7men", "und", "zu", "lo\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "VVINF", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Apelles wolte nicht vom schuster seyn erhoben/", "tokens": ["A\u00b7pel\u00b7les", "wol\u00b7te", "nicht", "vom", "schus\u00b7ter", "seyn", "er\u00b7ho\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PTKNEG", "APPRART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als er sein urtheil schwang von schuhen in die h\u00f6h.", "tokens": ["Als", "er", "sein", "ur\u00b7theil", "schwang", "von", "schu\u00b7hen", "in", "die", "h\u00f6h", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "APPR", "ADJA", "APPR", "ART", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum machs ichs nach der art der Indianer-weisen/", "tokens": ["Drum", "machs", "ichs", "nach", "der", "art", "der", "In\u00b7di\u00b7a\u00b7ner\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "APPR", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die dr\u00fccken ihren mund/ wenn sie was grosses preisen.", "tokens": ["Die", "dr\u00fc\u00b7cken", "ih\u00b7ren", "mund", "/", "wenn", "sie", "was", "gros\u00b7ses", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$(", "KOUS", "PPER", "PIS", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Viel l\u00e4nder reisen durch/ viel sachen sehen an/", "tokens": ["Viel", "l\u00e4n\u00b7der", "rei\u00b7sen", "durch", "/", "viel", "sa\u00b7chen", "se\u00b7hen", "an", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "APPR", "$(", "ADV", "VVINF", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von k\u00fcnsten mancher art viel stunden herzuschw\u00e4tzen/", "tokens": ["Von", "k\u00fcns\u00b7ten", "man\u00b7cher", "art", "viel", "stun\u00b7den", "her\u00b7zu\u00b7schw\u00e4t\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PIAT", "NN", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und fast zu jedem ding ein wunder-wort zu setzen/", "tokens": ["Und", "fast", "zu", "je\u00b7dem", "ding", "ein", "wun\u00b7der\u00b7wort", "zu", "set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Scheint zwar/ da\u00df der was wei\u00df/ doch offters wenig kan:", "tokens": ["Scheint", "zwar", "/", "da\u00df", "der", "was", "wei\u00df", "/", "doch", "off\u00b7ters", "we\u00b7nig", "kan", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "KOUS", "ART", "PWS", "VVFIN", "$(", "ADV", "ADV", "PIS", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn wenn es k\u00f6mmt/ da\u00df man was kluges her soll schreiben/", "tokens": ["Denn", "wenn", "es", "k\u00f6mmt", "/", "da\u00df", "man", "was", "klu\u00b7ges", "her", "soll", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "PIS", "PWS", "ADJA", "APZR", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da mu\u00df ein plauder-held gewi\u00df zu hause bleiben.", "tokens": ["Da", "mu\u00df", "ein", "plau\u00b7der\u00b7held", "ge\u00b7wi\u00df", "zu", "hau\u00b7se", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Laufft in die alte zeit/ und schaut was Griechenland", "tokens": ["Laufft", "in", "die", "al\u00b7te", "zeit", "/", "und", "schaut", "was", "Grie\u00b7chen\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$(", "KON", "VVFIN", "PWS", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vor m\u00e4nner zeigen kan/ die hochber\u00fchmt gewesen/", "tokens": ["Vor", "m\u00e4n\u00b7ner", "zei\u00b7gen", "kan", "/", "die", "hoch\u00b7be\u00b7r\u00fchmt", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVINF", "VMFIN", "$(", "ART", "ADJD", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was Aristoteles und Plato euch l\u00e4st lesen/", "tokens": ["Was", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "und", "Pla\u00b7to", "euch", "l\u00e4st", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "KON", "NE", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was vom Thucydides und Strabo ist bekant:", "tokens": ["Was", "vom", "Thu\u00b7cy\u00b7di\u00b7des", "und", "Stra\u00b7bo", "ist", "be\u00b7kant", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "KON", "NE", "VAFIN", "ADJD", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Di\u00df hat zwar wohl sein lob/ doch nicht/ so diesem gleichet/", "tokens": ["Di\u00df", "hat", "zwar", "wohl", "sein", "lob", "/", "doch", "nicht", "/", "so", "die\u00b7sem", "glei\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PPOSAT", "NN", "$(", "ADV", "PTKNEG", "$(", "ADV", "PDAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was unsers seligsten gelehrter kiel erreichet.", "tokens": ["Was", "un\u00b7sers", "se\u00b7ligs\u00b7ten", "ge\u00b7lehr\u00b7ter", "kiel", "er\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.9": {"line.1": {"text": "Sucht alte R\u00f6mer auf/ und nehmt den Livius/", "tokens": ["Sucht", "al\u00b7te", "R\u00f6\u00b7mer", "auf", "/", "und", "nehmt", "den", "Li\u00b7vius", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "APPR", "$(", "KON", "VVFIN", "ART", "NE", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "So viel von selbigem noch \u00fcbrig ist geblieben/", "tokens": ["So", "viel", "von", "sel\u00b7bi\u00b7gem", "noch", "\u00fcb\u00b7rig", "ist", "ge\u00b7blie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "ADV", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der f\u00fcrsten psalter-buch/ was Tacitus geschrieben/", "tokens": ["Der", "f\u00fcrs\u00b7ten", "psal\u00b7ter\u00b7buch", "/", "was", "Ta\u00b7ci\u00b7tus", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PWS", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von dem der vorwitz stets was gleiches finden mu\u00df/", "tokens": ["Von", "dem", "der", "vor\u00b7witz", "stets", "was", "glei\u00b7ches", "fin\u00b7den", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "ADV", "PWS", "PIS", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sich auf unsre zeit und unsern staat l\u00e4st ziehen/", "tokens": ["So", "sich", "auf", "uns\u00b7re", "zeit", "und", "un\u00b7sern", "staat", "l\u00e4st", "zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Les\u2019t ietzt den Pufendorff! ihr werdet jene fliehen.", "tokens": ["Les't", "ietzt", "den", "Pu\u00b7fen\u00b7dorff", "!", "ihr", "wer\u00b7det", "je\u00b7ne", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$.", "PPER", "VAFIN", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Es r\u00fchme Gallien den Gramond und Thuan/", "tokens": ["Es", "r\u00fch\u00b7me", "Gal\u00b7li\u00b7en", "den", "Gra\u00b7mond", "und", "Thu\u00b7an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ART", "NN", "KON", "NE", "$("], "meter": "-+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.2": {"text": "Den Serre/ den Mornay/ und andre kluge geister/", "tokens": ["Den", "Ser\u00b7re", "/", "den", "Mor\u00b7nay", "/", "und", "and\u00b7re", "klu\u00b7ge", "geis\u00b7ter", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "KON", "ADJA", "ADJA", "NN", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Es poche Spanien/ Saavedra sey der meister/", "tokens": ["Es", "po\u00b7che", "Spa\u00b7ni\u00b7en", "/", "Saa\u00b7ve\u00b7dra", "sey", "der", "meis\u00b7ter", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$(", "NE", "VAFIN", "ART", "NN", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Der nur die k\u00f6nige staats-klugheit lehren kan;", "tokens": ["Der", "nur", "die", "k\u00f6\u00b7ni\u00b7ge", "staats\u00b7klug\u00b7heit", "leh\u00b7ren", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es lasse Niederland den Meteran auffstehen/", "tokens": ["Es", "las\u00b7se", "Nie\u00b7der\u00b7land", "den", "Me\u00b7te\u00b7ran", "auffs\u00b7te\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Auch selbst dem Grotius wird Pufendorff vorgehen.", "tokens": ["Auch", "selbst", "dem", "Gro\u00b7ti\u00b7us", "wird", "Pu\u00b7fen\u00b7dorff", "vor\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NE", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Was wunder! da dein geist allhier sich schwang so hoch/", "tokens": ["Was", "wun\u00b7der", "!", "da", "dein", "geist", "all\u00b7hier", "sich", "schwang", "so", "hoch", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "KOUS", "PPOSAT", "NN", "ADV", "PRF", "VVFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und den verstand und witz kont allenthalben zeigen/", "tokens": ["Und", "den", "ver\u00b7stand", "und", "witz", "kont", "al\u00b7len\u00b7thal\u00b7ben", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KON", "NN", "VMFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df drauff die ehre dich hie\u00df ihren thron besteigen?", "tokens": ["Da\u00df", "drauff", "die", "eh\u00b7re", "dich", "hie\u00df", "ih\u00b7ren", "thron", "be\u00b7stei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ART", "VVFIN", "PPER", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn stand kommt durch verstand; die tugend adelt noch.", "tokens": ["Denn", "stand", "kommt", "durch", "ver\u00b7stand", ";", "die", "tu\u00b7gend", "a\u00b7delt", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "APPR", "VVFIN", "$.", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer mit verstande nur und tugenden kan prangen/", "tokens": ["Wer", "mit", "ver\u00b7stan\u00b7de", "nur", "und", "tu\u00b7gen\u00b7den", "kan", "pran\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ADJA", "ADV", "KON", "NN", "VMFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der wird auch mit der zeit so stand/ als gut/ erlangen.", "tokens": ["Der", "wird", "auch", "mit", "der", "zeit", "so", "stand", "/", "als", "gut", "/", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "ART", "NN", "ADV", "VVFIN", "$(", "KOUS", "ADJD", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Der Gothen tapffrer Carl vertraute dir den staat/", "tokens": ["Der", "Go\u00b7then", "tapf\u00b7frer", "Carl", "ver\u00b7trau\u00b7te", "dir", "den", "staat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NE", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach diesem musten dich die Brennus-helden haben/", "tokens": ["Nach", "die\u00b7sem", "mus\u00b7ten", "dich", "die", "Bren\u00b7nus\u00b7hel\u00b7den", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VMFIN", "PRF", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allwo dein kluger sinn und hohen geistes gaben", "tokens": ["All\u00b7wo", "dein", "klu\u00b7ger", "sinn", "und", "ho\u00b7hen", "geis\u00b7tes", "ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "ADJA", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich h\u00f6chst-verwunderlich der welt gewiesen hat.", "tokens": ["Sich", "h\u00f6chst\u00b7ver\u00b7wun\u00b7der\u00b7lich", "der", "welt", "ge\u00b7wie\u00b7sen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn diese kan man recht vor grosse f\u00fcrsten zehlen/", "tokens": ["Denn", "die\u00b7se", "kan", "man", "recht", "vor", "gros\u00b7se", "f\u00fcrs\u00b7ten", "zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PIS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die kluge diener selbst sich wissen zu erwehlen.", "tokens": ["Die", "klu\u00b7ge", "die\u00b7ner", "selbst", "sich", "wis\u00b7sen", "zu", "er\u00b7weh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PRF", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Zu Rom kam niemand vor in ehren-tempel ein/", "tokens": ["Zu", "Rom", "kam", "nie\u00b7mand", "vor", "in", "eh\u00b7ren\u00b7tem\u00b7pel", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "APPR", "APPR", "NE", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der durch den tempel nicht der tugend war gegangen;", "tokens": ["Der", "durch", "den", "tem\u00b7pel", "nicht", "der", "tu\u00b7gend", "war", "ge\u00b7gan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PTKNEG", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Alsdenn so kont er erst des adels w\u00fcrd erlangen/", "tokens": ["Als\u00b7denn", "so", "kont", "er", "erst", "des", "a\u00b7dels", "w\u00fcrd", "er\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie muste nicht durch geld und list erkauffet seyn;", "tokens": ["Sie", "mus\u00b7te", "nicht", "durch", "geld", "und", "list", "er\u00b7kauf\u00b7fet", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPR", "NN", "KON", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn tugend ist der stamm/ daraus der adel sprie\u00dfet/", "tokens": ["Denn", "tu\u00b7gend", "ist", "der", "stamm", "/", "da\u00b7raus", "der", "a\u00b7del", "sprie\u00b7\u00dfet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ART", "NN", "$(", "PAV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die quell/ aus welcher gl\u00fcck und aller wohlstand flie\u00dfet.", "tokens": ["Die", "quell", "/", "aus", "wel\u00b7cher", "gl\u00fcck", "und", "al\u00b7ler", "wohl\u00b7stand", "flie\u00b7\u00dfet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "APPR", "PWAT", "NN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Es zehlt offt mancher zwar viel edler ahnen her/", "tokens": ["Es", "zehlt", "offt", "man\u00b7cher", "zwar", "viel", "ed\u00b7ler", "ah\u00b7nen", "her", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "ADV", "PIAT", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er bl\u00e4ht sich dr\u00fcber auff/ und pocht auff sein geschlechte/", "tokens": ["Er", "bl\u00e4ht", "sich", "dr\u00fc\u00b7ber", "auff", "/", "und", "pocht", "auff", "sein", "ge\u00b7schlech\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PAV", "APPR", "$(", "KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Blickt andre finster an/ als etwa seine knechte/", "tokens": ["Blickt", "and\u00b7re", "fins\u00b7ter", "an", "/", "als", "et\u00b7wa", "sei\u00b7ne", "knech\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "PTKVZ", "$(", "KOKOM", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denckt: ob ein weiser ihm nicht gleich und edel w\u00e4r?", "tokens": ["Denckt", ":", "ob", "ein", "wei\u00b7ser", "ihm", "nicht", "gleich", "und", "e\u00b7del", "w\u00e4r", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "KOUS", "ART", "ADJA", "PPER", "PTKNEG", "ADV", "KON", "ADJD", "VAFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Wenn aber man von ihm nimt weg des adels nahmen/", "tokens": ["Wenn", "a\u00b7ber", "man", "von", "ihm", "nimt", "weg", "des", "a\u00b7dels", "nah\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "APPR", "PPER", "VVFIN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So ist sein zierrath hin; Er steht gleich wie die lahmen.", "tokens": ["So", "ist", "sein", "zier\u00b7rath", "hin", ";", "Er", "steht", "gleich", "wie", "die", "lah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "ADV", "KOKOM", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Viel andre macht der Mars durch blutvergiessen gro\u00df;", "tokens": ["Viel", "and\u00b7re", "macht", "der", "Mars", "durch", "blut\u00b7ver\u00b7gies\u00b7sen", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ART", "NN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch/ wo nicht sind gepaart die feder und der degen/", "tokens": ["Doch", "/", "wo", "nicht", "sind", "ge\u00b7paart", "die", "fe\u00b7der", "und", "der", "de\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWAV", "PTKNEG", "VAFIN", "VVPP", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Vor denen welt und volck sich mu\u00df zu f\u00fcssen legen/", "tokens": ["Vor", "de\u00b7nen", "welt", "und", "volck", "sich", "mu\u00df", "zu", "f\u00fcs\u00b7sen", "le\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "KON", "NN", "PRF", "VMFIN", "PTKZU", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So steht der held nur halb/ und ohne degen blo\u00df.", "tokens": ["So", "steht", "der", "held", "nur", "halb", "/", "und", "oh\u00b7ne", "de\u00b7gen", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "VVFIN", "ADV", "ADJD", "$(", "KON", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn di\u00df ist nicht genug den hut mit federn zieren/", "tokens": ["Denn", "di\u00df", "ist", "nicht", "ge\u00b7nug", "den", "hut", "mit", "fe\u00b7dern", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "APPR", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Viel sch\u00f6ner/ wer sie wei\u00df auch in der hand zu f\u00fchren.", "tokens": ["Viel", "sch\u00f6\u00b7ner", "/", "wer", "sie", "wei\u00df", "auch", "in", "der", "hand", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "PWS", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Wie aber? soll nicht der so gut als jener seyn/", "tokens": ["Wie", "a\u00b7ber", "?", "soll", "nicht", "der", "so", "gut", "als", "je\u00b7ner", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$.", "VMFIN", "PTKNEG", "ART", "ADV", "ADJD", "KOKOM", "PDS", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der seinen adelstand durch tugend hat erworben/", "tokens": ["Der", "sei\u00b7nen", "a\u00b7del\u00b7stand", "durch", "tu\u00b7gend", "hat", "er\u00b7wor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als der/ der ihn geerbt von ahnen die gestorben?", "tokens": ["Als", "der", "/", "der", "ihn", "ge\u00b7erbt", "von", "ah\u00b7nen", "die", "ge\u00b7stor\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$(", "PRELS", "PPER", "VVPP", "APPR", "VVFIN", "ART", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man sch\u00e4tzt von h\u00f6herm werth den neusten edelstein.", "tokens": ["Man", "sch\u00e4tzt", "von", "h\u00f6\u00b7herm", "werth", "den", "neus\u00b7ten", "e\u00b7del\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ADJD", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nach art und eigenschafft der sterblichen im leben/", "tokens": ["Nach", "art", "und", "ei\u00b7gen\u00b7schafft", "der", "sterb\u00b7li\u00b7chen", "im", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "ART", "ADJA", "APPRART", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sind di\u00df die edelsten/ die nach dem h\u00f6chsten streben.", "tokens": ["Sind", "di\u00df", "die", "e\u00b7dels\u00b7ten", "/", "die", "nach", "dem", "h\u00f6chs\u00b7ten", "stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "$(", "ART", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}}, "stanza.17": {"line.1": {"text": "Zwar hat wohl immerzu kunst und geschickligkeit", "tokens": ["Zwar", "hat", "wohl", "im\u00b7mer\u00b7zu", "kunst", "und", "ge\u00b7schick\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PTKVZ", "KON", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das ungl\u00fcck/ da\u00df zu ihr sich gern der neid gesellet/", "tokens": ["Das", "un\u00b7gl\u00fcck", "/", "da\u00df", "zu", "ihr", "sich", "gern", "der", "neid", "ge\u00b7sel\u00b7let", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOUS", "APPR", "PPER", "PRF", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der ihren ehren-ruhm verkleinert und verg\u00e4llet;", "tokens": ["Der", "ih\u00b7ren", "eh\u00b7ren\u00b7ruhm", "ver\u00b7klei\u00b7nert", "und", "ver\u00b7g\u00e4l\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch b\u00f6ser menschen thun besteht nur kurtze zeit/", "tokens": ["Doch", "b\u00f6\u00b7ser", "men\u00b7schen", "thun", "be\u00b7steht", "nur", "kurt\u00b7ze", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "VVINF", "VVFIN", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie m\u00fcssen insgemein selbst schlechten nachklang haben:", "tokens": ["Sie", "m\u00fcs\u00b7sen", "ins\u00b7ge\u00b7mein", "selbst", "schlech\u00b7ten", "nach\u00b7klang", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "VVFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn offt wird nahm und ruhm mit ihrer haut begraben.", "tokens": ["Denn", "offt", "wird", "nahm", "und", "ruhm", "mit", "ih\u00b7rer", "haut", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "VVFIN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Ob schon die sonne selbst/ das auge dieser welt/", "tokens": ["Ob", "schon", "die", "son\u00b7ne", "selbst", "/", "das", "au\u00b7ge", "die\u00b7ser", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "$(", "ART", "NN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die uns viel gutes thut/ und alles lebend machet/", "tokens": ["Die", "uns", "viel", "gu\u00b7tes", "thut", "/", "und", "al\u00b7les", "le\u00b7bend", "ma\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "ADJA", "VVFIN", "$(", "KON", "PIS", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von v\u00f6lckern wilder art verflucht wird und verlachet/", "tokens": ["Von", "v\u00f6l\u00b7ckern", "wil\u00b7der", "art", "ver\u00b7flucht", "wird", "und", "ver\u00b7la\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVPP", "VAFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auch von dem himmel offt mit wolcken gantz verstellt/", "tokens": ["Auch", "von", "dem", "him\u00b7mel", "offt", "mit", "wol\u00b7cken", "gantz", "ver\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "APPR", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bleibt sie doch sonn/ und kan ihr nichts den ruhm entziehen/", "tokens": ["Bleibt", "sie", "doch", "sonn", "/", "und", "kan", "ihr", "nichts", "den", "ruhm", "ent\u00b7zie\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$(", "KON", "VMFIN", "PPER", "PIS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ob flederm\u00e4use gleich und eulen selbe fliehen.", "tokens": ["Ob", "fle\u00b7der\u00b7m\u00e4u\u00b7se", "gleich", "und", "eu\u00b7len", "sel\u00b7be", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "KON", "ADJA", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Drum wer will etwas seyn/ der zeige sich der welt", "tokens": ["Drum", "wer", "will", "et\u00b7was", "seyn", "/", "der", "zei\u00b7ge", "sich", "der", "welt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "PWS", "VMFIN", "PIS", "VAINF", "$(", "ART", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und thu wie du gethan/ gelehret und geschrieben;", "tokens": ["Und", "thu", "wie", "du", "ge\u00b7than", "/", "ge\u00b7leh\u00b7ret", "und", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOKOM", "PPER", "VVPP", "$(", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wird man gleichfals auch ihn ehren/ loben/ lieben/", "tokens": ["So", "wird", "man", "gleich\u00b7fals", "auch", "ihn", "eh\u00b7ren", "/", "lo\u00b7ben", "/", "lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "ADV", "PPER", "VVINF", "$(", "VVINF", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es ist ja nicht genug/ da\u00df man nur urtheil f\u00e4llt.", "tokens": ["Es", "ist", "ja", "nicht", "ge\u00b7nug", "/", "da\u00df", "man", "nur", "ur\u00b7theil", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "$(", "KOUS", "PIS", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dort konte Momus zwar viel tadeln und verlachen/", "tokens": ["Dort", "kon\u00b7te", "Mo\u00b7mus", "zwar", "viel", "ta\u00b7deln", "und", "ver\u00b7la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "ADV", "ADV", "VVINF", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch aber selber nicht was schlechtes besser machen.", "tokens": ["Doch", "a\u00b7ber", "sel\u00b7ber", "nicht", "was", "schlech\u00b7tes", "bes\u00b7ser", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PTKNEG", "PWS", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Du stellst/ mein Pufendorff/ ein herrlich muster dar!", "tokens": ["Du", "stellst", "/", "mein", "Pu\u00b7fen\u00b7dorff", "/", "ein", "herr\u00b7lich", "mus\u00b7ter", "dar", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPOSAT", "NN", "$(", "ART", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein unerm\u00fcdter flei\u00df und feurige begierde", "tokens": ["Dein", "un\u00b7er\u00b7m\u00fcd\u00b7ter", "flei\u00df", "und", "feu\u00b7ri\u00b7ge", "be\u00b7gier\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hat sich der welt gezeigt in recht vollkommner zierde/", "tokens": ["Hat", "sich", "der", "welt", "ge\u00b7zeigt", "in", "recht", "voll\u00b7komm\u00b7ner", "zier\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "VVPP", "APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wiese/ da\u00df an dir was mehr als edles war.", "tokens": ["Und", "wie\u00b7se", "/", "da\u00df", "an", "dir", "was", "mehr", "als", "ed\u00b7les", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "KOUS", "APPR", "PPER", "PWS", "PIS", "KOKOM", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Staats-rechts- und wei\u00dfheit-lehr/ beschreibung der geschichte/", "tokens": ["Staats\u00b7rechts", "und", "wei\u00df\u00b7heit\u00b7lehr", "/", "be\u00b7schrei\u00b7bung", "der", "ge\u00b7schich\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJD", "$(", "NN", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und sitten-kunst spielt ietzt von dir mit neuem lichte.", "tokens": ["Und", "sit\u00b7ten\u00b7kunst", "spielt", "ietzt", "von", "dir", "mit", "neu\u00b7em", "lich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Ach ungemeiner geist! ach schmertzlicher verlust!", "tokens": ["Ach", "un\u00b7ge\u00b7mei\u00b7ner", "geist", "!", "ach", "schmertz\u00b7li\u00b7cher", "ver\u00b7lust", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "$.", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Soll denn dein edler kiel schon feyer-abend machen/", "tokens": ["Soll", "denn", "dein", "ed\u00b7ler", "kiel", "schon", "feyer\u00b7a\u00b7bend", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVINF", "$("], "meter": "---+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und uns nicht ferner mehr beschreiben kluge sachen?", "tokens": ["Und", "uns", "nicht", "fer\u00b7ner", "mehr", "be\u00b7schrei\u00b7ben", "klu\u00b7ge", "sa\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADV", "ADV", "ADJD", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vergebens! denn der schlu\u00df des H\u00f6chsten spricht: du must!", "tokens": ["Ver\u00b7ge\u00b7bens", "!", "denn", "der", "schlu\u00df", "des", "H\u00f6chs\u00b7ten", "spricht", ":", "du", "must", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$.", "KON", "ART", "NN", "ART", "NN", "VVFIN", "$.", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es achtet nicht der tod natur- und v\u00f6lcker-rechte/", "tokens": ["Es", "ach\u00b7tet", "nicht", "der", "tod", "na\u00b7tur", "und", "v\u00f6lcker\u00b7rech\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "TRUNC", "KON", "NN", "$("], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.6": {"text": "Er raubt ohn unterscheid die herren wie die knechte.", "tokens": ["Er", "raubt", "ohn", "un\u00b7ter\u00b7scheid", "die", "her\u00b7ren", "wie", "die", "knech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "KOKOM", "ART", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Gott theilt zwar iedes ding nach maa\u00df und zahlen ein;", "tokens": ["Gott", "theilt", "zwar", "ie\u00b7des", "ding", "nach", "maa\u00df", "und", "zah\u00b7len", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PIAT", "NN", "APPR", "VVFIN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch unser vorwitz hat noch nicht gewi\u00df ergr\u00fcndet/", "tokens": ["Doch", "un\u00b7ser", "vor\u00b7witz", "hat", "noch", "nicht", "ge\u00b7wi\u00df", "er\u00b7gr\u00fcn\u00b7det", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Warum manch mensch sein end im staffel-jahre findet", "tokens": ["Wa\u00b7rum", "manch", "mensch", "sein", "end", "im", "staf\u00b7fel\u00b7jah\u00b7re", "fin\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "PPOSAT", "NN", "APPRART", "ADJA", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und neun und sieben ihm gef\u00e4hrlich sollen seyn?", "tokens": ["Und", "neun", "und", "sie\u00b7ben", "ihm", "ge\u00b7f\u00e4hr\u00b7lich", "sol\u00b7len", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "KON", "VVFIN", "PPER", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df neun und viertzig meist und drey und sechzig jahre", "tokens": ["Da\u00df", "neun", "und", "viert\u00b7zig", "meist", "und", "drey", "und", "sech\u00b7zig", "jah\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "CARD", "KON", "CARD", "ADV", "KON", "CARD", "KON", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die klugen mehrentheils gebracht zur todten-bahre.", "tokens": ["Die", "klu\u00b7gen", "meh\u00b7ren\u00b7theils", "ge\u00b7bracht", "zur", "tod\u00b7ten\u00b7bah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Betr\u00fcbte/ derer hertz in blut und thr\u00e4nen schwimmt/", "tokens": ["Be\u00b7tr\u00fcb\u00b7te", "/", "de\u00b7rer", "hertz", "in", "blut", "und", "thr\u00e4\u00b7nen", "schwimmt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PDS", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df euer ehgemahl und vater ist erblasset;", "tokens": ["Da\u00df", "eu\u00b7er", "eh\u00b7ge\u00b7mahl", "und", "va\u00b7ter", "ist", "er\u00b7blas\u00b7set", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hemmt eure traurigkeit/ wo ihr euch selbst nicht hasset!", "tokens": ["Hemmt", "eu\u00b7re", "trau\u00b7rig\u00b7keit", "/", "wo", "ihr", "euch", "selbst", "nicht", "has\u00b7set", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$(", "PWAV", "PPER", "PPER", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl dem! der aus der welt so r\u00fchmlich abschied nimt/", "tokens": ["Wohl", "dem", "!", "der", "aus", "der", "welt", "so", "r\u00fchm\u00b7lich", "ab\u00b7schied", "nimt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$.", "ART", "APPR", "ART", "NN", "ADV", "ADJD", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und vor dis jammerthal den himmel kan ererben;", "tokens": ["Und", "vor", "dis", "jam\u00b7mer\u00b7thal", "den", "him\u00b7mel", "kan", "er\u00b7er\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDS", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es bleibet doch dabey: wir m\u00fcssen alle sterben.", "tokens": ["Es", "blei\u00b7bet", "doch", "da\u00b7bey", ":", "wir", "m\u00fcs\u00b7sen", "al\u00b7le", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Was ist das leben doch? nichts als gebrechlich gla\u00df;", "tokens": ["Was", "ist", "das", "le\u00b7ben", "doch", "?", "nichts", "als", "ge\u00b7brech\u00b7lich", "gla\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "VVFIN", "ADV", "$.", "PIS", "KOKOM", "ADJD", "VVFIN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein nebel/ wie di\u00df wort wird umgekehrt gelesen/", "tokens": ["Ein", "ne\u00b7bel", "/", "wie", "di\u00df", "wort", "wird", "um\u00b7ge\u00b7kehrt", "ge\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KOKOM", "PDS", "NN", "VAFIN", "ADJD", "VVPP", "$("], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Der unvermerckt verraucht/ als w\u00e4r er nie gewesen;", "tokens": ["Der", "un\u00b7ver\u00b7merckt", "ver\u00b7raucht", "/", "als", "w\u00e4r", "er", "nie", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVPP", "$(", "KOKOM", "VAFIN", "PPER", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein meer voll angst und leid; ein leicht verdorrend gra\u00df;", "tokens": ["Ein", "meer", "voll", "angst", "und", "leid", ";", "ein", "leicht", "ver\u00b7dor\u00b7rend", "gra\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "KON", "ADJD", "$.", "ART", "ADJD", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein schau-platz/ den der mensch mit thr\u00e4nen mu\u00df beschreiten/", "tokens": ["Ein", "schau\u00b7platz", "/", "den", "der", "mensch", "mit", "thr\u00e4\u00b7nen", "mu\u00df", "be\u00b7schrei\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ART", "NN", "APPR", "VVINF", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und die abtretende auch thr\u00e4nende begleiten.", "tokens": ["Und", "die", "ab\u00b7tre\u00b7ten\u00b7de", "auch", "thr\u00e4\u00b7nen\u00b7de", "be\u00b7glei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADV", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Drum stellt das klagen ein/ was geist und leben schw\u00e4cht/", "tokens": ["Drum", "stellt", "das", "kla\u00b7gen", "ein", "/", "was", "geist", "und", "le\u00b7ben", "schw\u00e4cht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PDS", "VVFIN", "ART", "$(", "PWS", "ADJD", "KON", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und doch nicht m\u00e4chtig ist die leichen auffzuwecken!", "tokens": ["Und", "doch", "nicht", "m\u00e4ch\u00b7tig", "ist", "die", "lei\u00b7chen", "auff\u00b7zu\u00b7we\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADJD", "VAFIN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es lebt der seligste nun sonder qual und schrecken/", "tokens": ["Es", "lebt", "der", "se\u00b7ligs\u00b7te", "nun", "son\u00b7der", "qual", "und", "schre\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADV", "ADJA", "NN", "KON", "VVFIN", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und h\u00f6rt von engeln ietzt ein g\u00f6ttlich v\u00f6lcker-recht:", "tokens": ["Und", "h\u00f6rt", "von", "en\u00b7geln", "ietzt", "ein", "g\u00f6tt\u00b7lich", "v\u00f6lcker\u00b7recht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ADV", "ART", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er sitzt nunmehr bey GOtt in diamantnen zimmern/", "tokens": ["Er", "sitzt", "nun\u00b7mehr", "bey", "Gott", "in", "di\u00b7a\u00b7mant\u00b7nen", "zim\u00b7mern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "APPR", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wo pracht und herrligkeit wird sonder ende schimmern.", "tokens": ["Wo", "pracht", "und", "herr\u00b7lig\u00b7keit", "wird", "son\u00b7der", "en\u00b7de", "schim\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "KON", "NN", "VAFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Was weint ihr? weinet nicht! wischt eure wangen ab!", "tokens": ["Was", "weint", "ihr", "?", "wei\u00b7net", "nicht", "!", "wischt", "eu\u00b7re", "wan\u00b7gen", "ab", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VVFIN", "PTKNEG", "$.", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gott der die wunden schl\u00e4gt/ der wird sie auch verbinden/", "tokens": ["Gott", "der", "die", "wun\u00b7den", "schl\u00e4gt", "/", "der", "wird", "sie", "auch", "ver\u00b7bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ART", "ADJA", "VVFIN", "$(", "ART", "VAFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Und wider euren schmertz ein heilsam pflaster finden.", "tokens": ["Und", "wi\u00b7der", "eu\u00b7ren", "schmertz", "ein", "heil\u00b7sam", "pflas\u00b7ter", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er bleibt der wittwen trost/ der waysen schutz und stab.", "tokens": ["Er", "bleibt", "der", "witt\u00b7wen", "trost", "/", "der", "way\u00b7sen", "schutz", "und", "stab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "G\u00f6nnt nur dem seligsten/ da\u00df er vorangegangen/", "tokens": ["G\u00f6nnt", "nur", "dem", "se\u00b7ligs\u00b7ten", "/", "da\u00df", "er", "vor\u00b7an\u00b7ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "$(", "KOUS", "PPER", "VVPP", "$("], "meter": "--+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Er wird euch einst im reich der herrligkeit empfangen.", "tokens": ["Er", "wird", "euch", "einst", "im", "reich", "der", "herr\u00b7lig\u00b7keit", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPRART", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Nun schlaff mein Pufendorff! schlaff bi\u00df an grossen tag.", "tokens": ["Nun", "schlaff", "mein", "Pu\u00b7fen\u00b7dorff", "!", "schlaff", "bi\u00df", "an", "gros\u00b7sen", "tag", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ach wie viel angst und noth wirst du doch noch verschlaffen/", "tokens": ["Ach", "wie", "viel", "angst", "und", "noth", "wirst", "du", "doch", "noch", "ver\u00b7schlaf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "VVPP", "KON", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein donnrend feld-geschrey/ kein schwirren grauser waffen", "tokens": ["Kein", "donn\u00b7rend", "feld\u00b7ge\u00b7schrey", "/", "kein", "schwir\u00b7ren", "grau\u00b7ser", "waf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJD", "NN", "$(", "PIAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist m\u00e4chtig/ da\u00df es dir die ruhe st\u00f6ren mag.", "tokens": ["Ist", "m\u00e4ch\u00b7tig", "/", "da\u00df", "es", "dir", "die", "ru\u00b7he", "st\u00f6\u00b7ren", "mag."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VAFIN", "ADJD", "$(", "KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Man klagt da\u00df deine hand den frieden nicht beschreibet;", "tokens": ["Man", "klagt", "da\u00df", "dei\u00b7ne", "hand", "den", "frie\u00b7den", "nicht", "be\u00b7schrei\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOUS", "PPOSAT", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du aber lebst bey GOtt/ wo ewig friede bleibet.", "tokens": ["Du", "a\u00b7ber", "lebst", "bey", "Gott", "/", "wo", "e\u00b7wig", "frie\u00b7de", "blei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "NN", "$(", "PWAV", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Betr\u00fcbte stehet auf! last uns von hinnen gehn!", "tokens": ["Be\u00b7tr\u00fcb\u00b7te", "ste\u00b7het", "auf", "!", "last", "uns", "von", "hin\u00b7nen", "gehn", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$.", "VVFIN", "PPER", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sonne sinckt zur ruh/ kommt aber morgen wieder.", "tokens": ["Die", "son\u00b7ne", "sinckt", "zur", "ruh", "/", "kommt", "a\u00b7ber", "mor\u00b7gen", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$(", "VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Legt buch und ehren-schild itzt bey dem grabe nieder!", "tokens": ["Legt", "buch", "und", "eh\u00b7ren\u00b7schild", "itzt", "bey", "dem", "gra\u00b7be", "nie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "ADJD", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des ruhmes g\u00fcldne fahn soll bey den sternen stehn;", "tokens": ["Des", "ruh\u00b7mes", "g\u00fcld\u00b7ne", "fahn", "soll", "bey", "den", "ster\u00b7nen", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VVINF", "VMFIN", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und glaubt: so lange noch die welt wird b\u00fccher schreiben/", "tokens": ["Und", "glaubt", ":", "so", "lan\u00b7ge", "noch", "die", "welt", "wird", "b\u00fc\u00b7cher", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "ADV", "ADV", "ADV", "ART", "NN", "VAFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wird Pufendorffes lob und nahm unsterblich bleiben.", "tokens": ["Wird", "Pu\u00b7fen\u00b7dorf\u00b7fes", "lob", "und", "nahm", "uns\u00b7terb\u00b7lich", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "KON", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}