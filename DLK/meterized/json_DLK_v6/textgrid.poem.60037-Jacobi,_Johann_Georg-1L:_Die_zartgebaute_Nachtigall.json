{"textgrid.poem.60037": {"metadata": {"author": {"name": "Jacobi, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die zartgebaute Nachtigall", "genre": "verse", "period": "N.A.", "pub_year": 1777, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die zartgebaute Nachtigall", "tokens": ["Die", "zart\u00b7ge\u00b7bau\u00b7te", "Nach\u00b7ti\u00b7gall"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verbarg sich vor dem gro\u00dfen Schall", "tokens": ["Ver\u00b7barg", "sich", "vor", "dem", "gro\u00b7\u00dfen", "Schall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der noch entfernten Donnerschl\u00e4ge;", "tokens": ["Der", "noch", "ent\u00b7fern\u00b7ten", "Don\u00b7ner\u00b7schl\u00e4\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht weit von ihr, am offnen Wege,", "tokens": ["Nicht", "weit", "von", "ihr", ",", "am", "off\u00b7nen", "We\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPR", "PPER", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sa\u00df ungesch\u00fctzt, mit seiner Brut,", "tokens": ["Sa\u00df", "un\u00b7ge\u00b7sch\u00fctzt", ",", "mit", "sei\u00b7ner", "Brut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein schwarzer Rabe, voller Muth,", "tokens": ["Ein", "schwar\u00b7zer", "Ra\u00b7be", ",", "vol\u00b7ler", "Muth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und h\u00f6rte kaum die Donnerschl\u00e4ge.", "tokens": ["Und", "h\u00f6r\u00b7te", "kaum", "die", "Don\u00b7ner\u00b7schl\u00e4\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da sah die bange S\u00e4ngerinn", "tokens": ["Da", "sah", "die", "ban\u00b7ge", "S\u00e4n\u00b7ge\u00b7rinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach ihrem k\u00fchnen Nachbar hin.", "tokens": ["Nach", "ih\u00b7rem", "k\u00fch\u00b7nen", "Nach\u00b7bar", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbwarum\u00ab, so klagte sie bescheiden,", "tokens": ["\u00bb", "wa\u00b7rum", "\u00ab", ",", "so", "klag\u00b7te", "sie", "be\u00b7schei\u00b7den", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$(", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbmu\u00df diesen R\u00e4uber ich beneiden?", "tokens": ["\u00bb", "mu\u00df", "die\u00b7sen", "R\u00e4u\u00b7ber", "ich", "be\u00b7nei\u00b7den", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PDAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mich nennen Wiese, Busch und Flur,", "tokens": ["Mich", "nen\u00b7nen", "Wie\u00b7se", ",", "Busch", "und", "Flur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.6": {"text": "Den kleinen G\u00fcnstling der Natur;", "tokens": ["Den", "klei\u00b7nen", "G\u00fcnst\u00b7ling", "der", "Na\u00b7tur", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und doppelt f\u00fchl' ich jedes Leiden.\u00ab", "tokens": ["Und", "dop\u00b7pelt", "f\u00fchl'", "ich", "je\u00b7des", "Lei\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Sch\u00e4fer, der vor\u00fcbergieng,", "tokens": ["Ein", "Sch\u00e4\u00b7fer", ",", "der", "vor\u00b7\u00fc\u00b7berg\u00b7ieng", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vernahm den Klageton, und fieng", "tokens": ["Ver\u00b7nahm", "den", "Kla\u00b7ge\u00b7ton", ",", "und", "fi\u00b7eng"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Den Fr\u00fchlingsbothen an zu fragen:", "tokens": ["Den", "Fr\u00fch\u00b7lings\u00b7bo\u00b7then", "an", "zu", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbob nicht die Luft, an heitern Tagen,", "tokens": ["\u00bb", "ob", "nicht", "die", "Luft", ",", "an", "hei\u00b7tern", "Ta\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PTKNEG", "ART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ob nicht das erste Gr\u00fcn, im May,", "tokens": ["Ob", "nicht", "das", "ers\u00b7te", "Gr\u00fcn", ",", "im", "May", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "ADJA", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Nachtigallen sch\u00f6ner sey,", "tokens": ["Den", "Nach\u00b7ti\u00b7gal\u00b7len", "sch\u00f6\u00b7ner", "sey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als denen, welche nimmer klagen\u00ab?", "tokens": ["Als", "de\u00b7nen", ",", "wel\u00b7che", "nim\u00b7mer", "kla\u00b7gen", "\u00ab", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "ADV", "VVINF", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der weise Sch\u00e4fer hatte Recht.", "tokens": ["Der", "wei\u00b7se", "Sch\u00e4\u00b7fer", "hat\u00b7te", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es giebt ein nervichtes Geschlecht", "tokens": ["Es", "giebt", "ein", "ner\u00b7vich\u00b7tes", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Von unerschrocknen M\u00e4nnerseelen;", "tokens": ["Von", "un\u00b7er\u00b7schrock\u00b7nen", "M\u00e4n\u00b7ner\u00b7see\u00b7len", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch aus ihren heisern Kehlen", "tokens": ["Je\u00b7doch", "aus", "ih\u00b7ren", "hei\u00b7sern", "Keh\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geht keine G\u00f6ttermelodie,", "tokens": ["Geht", "kei\u00b7ne", "G\u00f6t\u00b7ter\u00b7me\u00b7lo\u00b7die", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+----", "measure": "unknown.measure.di"}, "line.6": {"text": "Und Rabenkinder werden nie", "tokens": ["Und", "Ra\u00b7ben\u00b7kin\u00b7der", "wer\u00b7den", "nie"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu still behorchten Philomelen.", "tokens": ["Zu", "still", "be\u00b7horch\u00b7ten", "Phi\u00b7lo\u00b7me\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}