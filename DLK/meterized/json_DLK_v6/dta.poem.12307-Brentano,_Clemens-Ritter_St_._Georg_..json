{"dta.poem.12307": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Ritter St .  Georg .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "In einem See sehr gro\u00df und tief,               ", "tokens": ["In", "ei\u00b7nem", "See", "sehr", "gro\u00df", "und", "tief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein b\u00f6ser Drach sich sehen lie\u00df.", "tokens": ["Ein", "b\u00f6\u00b7ser", "Drach", "sich", "se\u00b7hen", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Dem ganzen Land er Schrecken bringt,", "tokens": ["Dem", "gan\u00b7zen", "Land", "er", "Schre\u00b7cken", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Menschen und viel Vieh verschlingt,", "tokens": ["Viel", "Men\u00b7schen", "und", "viel", "Vieh", "ver\u00b7schlingt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und mit des Rachens b\u00f6sem Duft", "tokens": ["Und", "mit", "des", "Ra\u00b7chens", "b\u00f6\u00b7sem", "Duft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vergiftet er ringsum die Luft.", "tokens": ["Ver\u00b7gif\u00b7tet", "er", "ring\u00b7sum", "die", "Luft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Da\u00df er nicht dringe zu der Stadt,", "tokens": ["Da\u00df", "er", "nicht", "drin\u00b7ge", "zu", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beschlo\u00df man in gemeinem Rath,", "tokens": ["Be\u00b7schlo\u00df", "man", "in", "ge\u00b7mei\u00b7nem", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Zwey Schaaf zu geben alle Tag,", "tokens": ["Zwey", "Schaaf", "zu", "ge\u00b7ben", "al\u00b7le", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKZU", "VVINF", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um abzuwenden diese Plag.", "tokens": ["Um", "ab\u00b7zu\u00b7wen\u00b7den", "die\u00b7se", "Plag", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "VVIZU", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Und da die Schaaf schier all dahin,", "tokens": ["Und", "da", "die", "Schaaf", "schier", "all", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "PIAT", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erdachten sie noch andern Sinn,", "tokens": ["Er\u00b7dach\u00b7ten", "sie", "noch", "an\u00b7dern", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Zu geben einen Menschen dar,", "tokens": ["Zu", "ge\u00b7ben", "ei\u00b7nen", "Men\u00b7schen", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der durch das Loos gew\u00e4hlet war.", "tokens": ["Der", "durch", "das", "Loos", "ge\u00b7w\u00e4h\u00b7let", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Das Loos ging um so lang und viel,", "tokens": ["Das", "Loos", "ging", "um", "so", "lang", "und", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADV", "ADJD", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bis es aufs K\u00f6nigs-Tochter fiel.", "tokens": ["Bis", "es", "aufs", "K\u00f6\u00b7nigs\u00b7Toch\u00b7ter", "fiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der K\u00f6nig sprach zu'n Burgern gleich:", "tokens": ["Der", "K\u00f6\u00b7nig", "sprach", "zu'n", "Bur\u00b7gern", "gleich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201enehmt hin mein halbes K\u00f6nigreich!", "tokens": ["\u201e", "nehmt", "hin", "mein", "hal\u00b7bes", "K\u00f6\u00b7nig\u00b7reich", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.10": {"line.1": {"text": "\u201eich gebe auch an Gut und Gold,", "tokens": ["\u201e", "ich", "ge\u00b7be", "auch", "an", "Gut", "und", "Gold", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201evon Silber und Geld so viel ihr wollt,", "tokens": ["\u201e", "von", "Sil\u00b7ber", "und", "Geld", "so", "viel", "ihr", "wollt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "KON", "NN", "ADV", "ADV", "PPER", "VMFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "\u201eauf da\u00df mein Tochter, die einig Erb,", "tokens": ["\u201e", "auf", "da\u00df", "mein", "Toch\u00b7ter", ",", "die", "ei\u00b7nig", "Erb", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "KOUS", "PPOSAT", "NN", "$,", "PRELS", "ADJD", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u201enoch lebe, nicht so b\u00f6\u00df verderb.\u201c", "tokens": ["\u201e", "noch", "le\u00b7be", ",", "nicht", "so", "b\u00f6\u00df", "ver\u00b7derb", ".", "\u201c"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "PTKNEG", "ADV", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Das Volk ein gro\u00df Geschrey beginnt:", "tokens": ["Das", "Volk", "ein", "gro\u00df", "Ge\u00b7schrey", "be\u00b7ginnt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eeinem andern ist auch lieb sein Kind!", "tokens": ["\u201e", "ei\u00b7nem", "an\u00b7dern", "ist", "auch", "lieb", "sein", "Kind", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "VAFIN", "ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "\u201eh\u00e4ltst du mit deiner Tochter nicht", "tokens": ["\u201e", "h\u00e4ltst", "du", "mit", "dei\u00b7ner", "Toch\u00b7ter", "nicht"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eden Schlu\u00df, den du selbst aufgericht,", "tokens": ["\u201e", "den", "Schlu\u00df", ",", "den", "du", "selbst", "auf\u00b7ge\u00b7richt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "\u201eso brennen wir dich zu der Stund", "tokens": ["\u201e", "so", "bren\u00b7nen", "wir", "dich", "zu", "der", "Stund"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201esammt deinem Pallast auf den Grund.\u201c", "tokens": ["\u201e", "sammt", "dei\u00b7nem", "Pal\u00b7last", "auf", "den", "Grund", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Da nun der K\u00f6nig Ernst ersah,", "tokens": ["Da", "nun", "der", "K\u00f6\u00b7nig", "Ernst", "er\u00b7sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz leidig er zu ihnen sprach:", "tokens": ["Ganz", "lei\u00b7dig", "er", "zu", "ih\u00b7nen", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "\u201eso gebet mir doch nur acht Tag,", "tokens": ["\u201e", "so", "ge\u00b7bet", "mir", "doch", "nur", "acht", "Tag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "ADV", "CARD", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "\u201eda\u00df ich der Tochter Leid beklag.\u201c", "tokens": ["\u201e", "da\u00df", "ich", "der", "Toch\u00b7ter", "Leid", "be\u00b7klag", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "NN", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Darnach sprach er zur Tochter sein:", "tokens": ["Dar\u00b7nach", "sprach", "er", "zur", "Toch\u00b7ter", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201each Tochter, liebste Tochter mein!", "tokens": ["\u201e", "ach", "Toch\u00b7ter", ",", "liebs\u00b7te", "Toch\u00b7ter", "mein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "$,", "ADJA", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "\u201eso mu\u00df ich dich jetzt sterben sehn,", "tokens": ["\u201e", "so", "mu\u00df", "ich", "dich", "jetzt", "ster\u00b7ben", "sehn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "PRF", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund all mein Tag in Trauren stehn.\u201c", "tokens": ["\u201e", "und", "all", "mein", "Tag", "in", "Trau\u00b7ren", "stehn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PIAT", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Da nun die Zeit verschwunden war,", "tokens": ["Da", "nun", "die", "Zeit", "ver\u00b7schwun\u00b7den", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lauft bald das Volk zum Pallast dar,", "tokens": ["Lauft", "bald", "das", "Volk", "zum", "Pal\u00b7last", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Und drohet ihm mit Schwerdt und Feuer,", "tokens": ["Und", "dro\u00b7het", "ihm", "mit", "Schwerdt", "und", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie schrien hinauf gar ungeheuer:", "tokens": ["Sie", "schri\u00b7en", "hin\u00b7auf", "gar", "un\u00b7ge\u00b7heu\u00b7er", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "\u201ewillst du um deiner Tochter Leben,", "tokens": ["\u201e", "willst", "du", "um", "dei\u00b7ner", "Toch\u00b7ter", "Le\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edein ganzes Volk dem Drachen geben?\u201c", "tokens": ["\u201e", "dein", "gan\u00b7zes", "Volk", "dem", "Dra\u00b7chen", "ge\u00b7ben", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Da es nicht anders m\u00f6cht gesein,", "tokens": ["Da", "es", "nicht", "an\u00b7ders", "m\u00f6cht", "ge\u00b7sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VMFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab er zuletzt den Willen drein.", "tokens": ["Gab", "er", "zu\u00b7letzt", "den", "Wil\u00b7len", "drein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Er kleidet sie in k\u00f6niglich Wat,", "tokens": ["Er", "klei\u00b7det", "sie", "in", "k\u00f6\u00b7nig\u00b7lich", "Wat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mit Weinen und Klagen er sie umfaht.", "tokens": ["Mit", "Wei\u00b7nen", "und", "Kla\u00b7gen", "er", "sie", "um\u00b7faht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PPER", "PPER", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.24": {"line.1": {"text": "Er sprach: \u201eAch weh mir armen Mann!", "tokens": ["Er", "sprach", ":", "\u201e", "Ach", "weh", "mir", "ar\u00b7men", "Mann", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ITJ", "ADV", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ewas soll ich jetzund fangen an?", "tokens": ["\u201e", "was", "soll", "ich", "je\u00b7tzund", "fan\u00b7gen", "an", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "\u201edie Hochzeit dein war ich bedacht", "tokens": ["\u201e", "die", "Hoch\u00b7zeit", "dein", "war", "ich", "be\u00b7dacht"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "PPOSAT", "VAFIN", "PPER", "VVPP"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u201ezu halten bald mit herrlicher Pracht,", "tokens": ["\u201e", "zu", "hal\u00b7ten", "bald", "mit", "herr\u00b7li\u00b7cher", "Pracht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.26": {"line.1": {"text": "\u201emit Trommeln und mit Saitenspiel,", "tokens": ["\u201e", "mit", "Trom\u00b7meln", "und", "mit", "Sai\u00b7ten\u00b7spiel", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ezu haben Lust und Freuden viel.", "tokens": ["\u201e", "zu", "ha\u00b7ben", "Lust", "und", "Freu\u00b7den", "viel", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VAINF", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "\u201eso mu\u00df ich mich nun dein verwegen,", "tokens": ["\u201e", "so", "mu\u00df", "ich", "mich", "nun", "dein", "ver\u00b7we\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "PRF", "ADV", "PPOSAT", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund dich dem grausen Drachen geben.", "tokens": ["\u201e", "und", "dich", "dem", "grau\u00b7sen", "Dra\u00b7chen", "ge\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PRF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "\u201each Gott, da\u00df ich vor dir w\u00e4r todt,", "tokens": ["\u201e", "ach", "Gott", ",", "da\u00df", "ich", "vor", "dir", "w\u00e4r", "todt", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "$,", "KOUS", "PPER", "APPR", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eda\u00df ich nicht seh dein Blut so roth.\u201c", "tokens": ["\u201e", "da\u00df", "ich", "nicht", "seh", "dein", "Blut", "so", "roth", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PTKNEG", "VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Er gab ihr weinend manchen Ku\u00df,", "tokens": ["Er", "gab", "ihr", "wei\u00b7nend", "man\u00b7chen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein T\u00f6chterlein fiel ihm zu Fu\u00df:", "tokens": ["Sein", "T\u00f6ch\u00b7ter\u00b7lein", "fiel", "ihm", "zu", "Fu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.30": {"line.1": {"text": "\u201elebt wohl, lebt wohl Herr Vater mein!", "tokens": ["\u201e", "lebt", "wohl", ",", "lebt", "wohl", "Herr", "Va\u00b7ter", "mein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "VVFIN", "ADV", "NN", "NN", "PPOSAT", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "\u201egern sterb ich um des Volkes Pein.\u201c", "tokens": ["\u201e", "gern", "sterb", "ich", "um", "des", "Vol\u00b7kes", "Pein", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Der K\u00f6nig schied mit Ach und Weh,", "tokens": ["Der", "K\u00f6\u00b7nig", "schied", "mit", "Ach", "und", "Weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man f\u00fchrt sein Kind zum Drachensee.", "tokens": ["Man", "f\u00fchrt", "sein", "Kind", "zum", "Dra\u00b7chen\u00b7see", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Als sie da sa\u00df in Trauren schwer,", "tokens": ["Als", "sie", "da", "sa\u00df", "in", "Trau\u00b7ren", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da ritt der Ritter Georg daher.", "tokens": ["Da", "ritt", "der", "Rit\u00b7ter", "Ge\u00b7org", "da\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "PAV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "\u201eo Jungfrau zart! gieb mir Bescheid,", "tokens": ["\u201e", "o", "Jung\u00b7frau", "zart", "!", "gieb", "mir", "Be\u00b7scheid", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "ADJD", "$.", "VVIMP", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ewarum stehst du in solchem Leid?\u201c", "tokens": ["\u201e", "wa\u00b7rum", "stehst", "du", "in", "sol\u00b7chem", "Leid", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Die Jungfrau sprach: \u201eFlieh bald von hier!", "tokens": ["Die", "Jung\u00b7frau", "sprach", ":", "\u201e", "Flieh", "bald", "von", "hier", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "ADV", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eda\u00df du nicht sterben mu\u00dft mit mir.\u201c", "tokens": ["\u201e", "da\u00df", "du", "nicht", "ster\u00b7ben", "mu\u00dft", "mit", "mir", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Er sprach: \u201eO Jungfrau f\u00fcrcht dich nicht,", "tokens": ["Er", "sprach", ":", "\u201e", "O", "Jung\u00b7frau", "f\u00fcrcht", "dich", "nicht", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201evielmehr mit Kurzem mich bericht,", "tokens": ["\u201e", "viel\u00b7mehr", "mit", "Kur\u00b7zem", "mich", "be\u00b7richt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "\u201ewas deuts, da\u00df ihr allein da weint,", "tokens": ["\u201e", "was", "deuts", ",", "da\u00df", "ihr", "al\u00b7lein", "da", "weint", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PDS", "$,", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eein gro\u00dfes Volk herum erscheint?\u201c", "tokens": ["\u201e", "ein", "gro\u00b7\u00dfes", "Volk", "he\u00b7rum", "er\u00b7scheint", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "APZR", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Die Jungfrau sprach: \u201eIch merk ohn Scherz,", "tokens": ["Die", "Jung\u00b7frau", "sprach", ":", "\u201e", "Ich", "merk", "ohn", "Scherz", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eihr habt ein mannlichs Ritter Herz;", "tokens": ["\u201e", "ihr", "habt", "ein", "mann\u00b7lichs", "Rit\u00b7ter", "Herz", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "\u201ewas wollt ihr hier verderben,", "tokens": ["\u201e", "was", "wollt", "ihr", "hier", "ver\u00b7der\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u201eund mit mir sch\u00e4ndlich sterben.\u201c", "tokens": ["\u201e", "und", "mit", "mir", "sch\u00e4nd\u00b7lich", "ster\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "APPR", "PPER", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Dann sagt sie ihm, wie hart und schwer,", "tokens": ["Dann", "sagt", "sie", "ihm", ",", "wie", "hart", "und", "schwer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "PWAV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie alle Sach ergangen w\u00e4r.", "tokens": ["Wie", "al\u00b7le", "Sach", "er\u00b7gan\u00b7gen", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Da sprach der edle Ritter gut:", "tokens": ["Da", "sprach", "der", "ed\u00b7le", "Rit\u00b7ter", "gut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201egetr\u00f6stet seyd, habt freien Muth!", "tokens": ["\u201e", "ge\u00b7tr\u00f6s\u00b7tet", "seyd", ",", "habt", "frei\u00b7en", "Muth", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "$,", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "\u201eich will durch H\u00fclf von Gottes Sohn,", "tokens": ["\u201e", "ich", "will", "durch", "H\u00fclf", "von", "Got\u00b7tes", "Sohn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "APPR", "NN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eeuch ritterlichen Beistand thun.\u201c", "tokens": ["\u201e", "euch", "rit\u00b7ter\u00b7li\u00b7chen", "Bei\u00b7stand", "thun", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Er bleibet fest, sie warnt ihn sehr,", "tokens": ["Er", "blei\u00b7bet", "fest", ",", "sie", "warnt", "ihn", "sehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da kam der greuliche Drach daher.", "tokens": ["Da", "kam", "der", "greu\u00b7li\u00b7che", "Drach", "da\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PAV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.43": {"line.1": {"text": "\u201eflieht Ritter! schont das junge Leben,", "tokens": ["\u201e", "flieht", "Rit\u00b7ter", "!", "schont", "das", "jun\u00b7ge", "Le\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NN", "$.", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eihr m\u00fc\u00dft sonst euren Leib drum geben.\u201c", "tokens": ["\u201e", "ihr", "m\u00fc\u00dft", "sonst", "eu\u00b7ren", "Leib", "drum", "ge\u00b7ben", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PPOSAT", "NN", "PAV", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Der Ritter sitzt geschwind zu Ro\u00df,", "tokens": ["Der", "Rit\u00b7ter", "sitzt", "ge\u00b7schwind", "zu", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und eilet zu dem Drachen gro\u00df.", "tokens": ["Und", "ei\u00b7let", "zu", "dem", "Dra\u00b7chen", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Das heilige Kreuz macht er vor sich,", "tokens": ["Das", "hei\u00b7li\u00b7ge", "Kreuz", "macht", "er", "vor", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPR", "PRF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Gar christenlich und ritterlich,", "tokens": ["Gar", "chris\u00b7ten\u00b7lich", "und", "rit\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Dann rannt er an mit seinem Spie\u00df,", "tokens": ["Dann", "rannt", "er", "an", "mit", "sei\u00b7nem", "Spie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den er tief in den Drachen stie\u00df,", "tokens": ["Den", "er", "tief", "in", "den", "Dra\u00b7chen", "stie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.47": {"line.1": {"text": "Da\u00df g\u00e4hling er zur Erden sank,", "tokens": ["Da\u00df", "g\u00e4h\u00b7ling", "er", "zur", "Er\u00b7den", "sank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und saget Gott dem Herren Dank.", "tokens": ["Und", "sa\u00b7get", "Gott", "dem", "Her\u00b7ren", "Dank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Da sprach er zu der Jungfrau zart:", "tokens": ["Da", "sprach", "er", "zu", "der", "Jung\u00b7frau", "zart", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eder Drache l\u00e4\u00dft von seiner Art.", "tokens": ["\u201e", "der", "Dra\u00b7che", "l\u00e4\u00dft", "von", "sei\u00b7ner", "Art", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "\u201edrum f\u00fcrcht euch gar nicht dieses Falls,", "tokens": ["\u201e", "drum", "f\u00fcrcht", "euch", "gar", "nicht", "die\u00b7ses", "Falls", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201elegt euren G\u00fcrtel ihm um den Hals.\u201c", "tokens": ["\u201e", "legt", "eu\u00b7ren", "G\u00fcr\u00b7tel", "ihm", "um", "den", "Hals", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.50": {"line.1": {"text": "Als sie das th\u00e4t, ging er zu Stund,", "tokens": ["Als", "sie", "das", "th\u00e4t", ",", "ging", "er", "zu", "Stund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihm wie ein gez\u00e4hmter Hund.", "tokens": ["Mit", "ihm", "wie", "ein", "ge\u00b7z\u00e4hm\u00b7ter", "Hund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Er f\u00fchrt ihn so zur Stadt hinein,", "tokens": ["Er", "f\u00fchrt", "ihn", "so", "zur", "Stadt", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da flohen vor ihm gro\u00df und klein.", "tokens": ["Da", "flo\u00b7hen", "vor", "ihm", "gro\u00df", "und", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Der Ritter winket ihnen, sprach:", "tokens": ["Der", "Rit\u00b7ter", "win\u00b7ket", "ih\u00b7nen", ",", "sprach", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ebleibt hie und f\u00fcrchtet kein Ungemach.", "tokens": ["\u201e", "bleibt", "hie", "und", "f\u00fcrch\u00b7tet", "kein", "Un\u00b7ge\u00b7mach", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.53": {"line.1": {"text": "\u201eich bin darum zu euch gesendt,", "tokens": ["\u201e", "ich", "bin", "da\u00b7rum", "zu", "euch", "ge\u00b7sendt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PAV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eda\u00df ihr den wahren Gott erkennt.", "tokens": ["\u201e", "da\u00df", "ihr", "den", "wah\u00b7ren", "Gott", "er\u00b7kennt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "\u201ewann ihr euch dann wollt taufen lahn,", "tokens": ["\u201e", "wann", "ihr", "euch", "dann", "wollt", "tau\u00b7fen", "lahn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund Christi Glauben nehmen an,", "tokens": ["\u201e", "und", "Chris\u00b7ti", "Glau\u00b7ben", "neh\u00b7men", "an", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "NE", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "\u201eso schlag ich diesen Drachen todt,", "tokens": ["\u201e", "so", "schlag", "ich", "die\u00b7sen", "Dra\u00b7chen", "todt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PDAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201ehelf euch damit aus aller Noth.\u201c", "tokens": ["\u201e", "helf", "euch", "da\u00b7mit", "aus", "al\u00b7ler", "Noth", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PAV", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Alsbald kam da durch Gottes Kraft:", "tokens": ["Als\u00b7bald", "kam", "da", "durch", "Got\u00b7tes", "Kraft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur Tauf die ganze Heidenschaft.", "tokens": ["Zur", "Tauf", "die", "gan\u00b7ze", "Hei\u00b7den\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Da zog der Ritter aus sein Schwerdt,", "tokens": ["Da", "zog", "der", "Rit\u00b7ter", "aus", "sein", "Schwerdt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schlug den Drachen zu der Erd.", "tokens": ["Und", "schlug", "den", "Dra\u00b7chen", "zu", "der", "Erd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Der K\u00f6nig bot dem heilgen Mann", "tokens": ["Der", "K\u00f6\u00b7nig", "bot", "dem", "heil\u00b7gen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel Silber und Gold zu Ehren an,", "tokens": ["Viel", "Sil\u00b7ber", "und", "Gold", "zu", "Eh\u00b7ren", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.59": {"line.1": {"text": "Das schlug der Ritter alles aus,", "tokens": ["Das", "schlug", "der", "Rit\u00b7ter", "al\u00b7les", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man solls den Armen theilen aus.", "tokens": ["Man", "solls", "den", "Ar\u00b7men", "thei\u00b7len", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Als er nun schier wollt ziehen ab,", "tokens": ["Als", "er", "nun", "schier", "wollt", "zie\u00b7hen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VMFIN", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Lehr er noch dem K\u00f6nig gab:", "tokens": ["Die", "Lehr", "er", "noch", "dem", "K\u00f6\u00b7nig", "gab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "\u201edie Kirche Gottes des Herren dein,", "tokens": ["\u201e", "die", "Kir\u00b7che", "Got\u00b7tes", "des", "Her\u00b7ren", "dein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201ela\u00df dir allzeit befohlen seyn.\u201c", "tokens": ["\u201e", "la\u00df", "dir", "all\u00b7zeit", "be\u00b7foh\u00b7len", "seyn", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADV", "VVPP", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Der K\u00f6nig baute auch mit Flei\u00df,", "tokens": ["Der", "K\u00f6\u00b7nig", "bau\u00b7te", "auch", "mit", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Mutter Gottes zu Lob und Preis,", "tokens": ["Der", "Mut\u00b7ter", "Got\u00b7tes", "zu", "Lob", "und", "Preis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.63": {"line.1": {"text": "Eine Kirche sch\u00f6n und herrlich gro\u00df,", "tokens": ["Ei\u00b7ne", "Kir\u00b7che", "sch\u00f6n", "und", "herr\u00b7lich", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Aus der ein kleiner Brunn herflo\u00df..", "tokens": ["Aus", "der", "ein", "klei\u00b7ner", "Brunn", "her\u00b7flo\u00df", ".."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}