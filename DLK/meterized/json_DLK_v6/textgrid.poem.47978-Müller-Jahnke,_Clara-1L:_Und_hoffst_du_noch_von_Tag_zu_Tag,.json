{"textgrid.poem.47978": {"metadata": {"author": {"name": "M\u00fcller-Jahnke, Clara", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und hoffst du noch von Tag zu Tag,", "genre": "verse", "period": "N.A.", "pub_year": 1882, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und hoffst du noch von Tag zu Tag,", "tokens": ["Und", "hoffst", "du", "noch", "von", "Tag", "zu", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ob's endlich Fr\u00fchling werden mag?", "tokens": ["ob's", "end\u00b7lich", "Fr\u00fch\u00b7ling", "wer\u00b7den", "mag", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es h\u00fcllt den goldnen Sonnenschein", "tokens": ["Es", "h\u00fcllt", "den", "gold\u00b7nen", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ein grauer Wolkenschleier ein;", "tokens": ["ein", "grau\u00b7er", "Wol\u00b7ken\u00b7schlei\u00b7er", "ein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "durch kahle B\u00e4ume braust der Nord,", "tokens": ["durch", "kah\u00b7le", "B\u00e4u\u00b7me", "braust", "der", "Nord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "kein gr\u00fcner Hauch, kein Bl\u00e4ttchen dort;", "tokens": ["kein", "gr\u00fc\u00b7ner", "Hauch", ",", "kein", "Bl\u00e4tt\u00b7chen", "dort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und wagt sich unterm Moose dicht", "tokens": ["und", "wagt", "sich", "un\u00b7term", "Moo\u00b7se", "dicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ein Bl\u00fcmchen k\u00fchn hervor ans Licht,", "tokens": ["ein", "Bl\u00fcm\u00b7chen", "k\u00fchn", "her\u00b7vor", "ans", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "da trifft es rauh des Sturmes Ku\u00df,", "tokens": ["da", "trifft", "es", "rauh", "des", "Stur\u00b7mes", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "so da\u00df es schauernd sterben mu\u00df.", "tokens": ["so", "da\u00df", "es", "schau\u00b7ernd", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und doch \u2013 der Mai steht vor der T\u00fcr:", "tokens": ["Und", "doch", "\u2013", "der", "Mai", "steht", "vor", "der", "T\u00fcr", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2013 Ich klopfe lang; wer \u00f6ffnet mir?", "tokens": ["\u2013", "Ich", "klop\u00b7fe", "lang", ";", "wer", "\u00f6ff\u00b7net", "mir", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADJD", "$.", "PWS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer \u00f6ffnet meiner Fr\u00fchlingslust", "tokens": ["Wer", "\u00f6ff\u00b7net", "mei\u00b7ner", "Fr\u00fch\u00b7lings\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die ganze volle Menschenbrust?", "tokens": ["die", "gan\u00b7ze", "vol\u00b7le", "Men\u00b7schen\u00b7brust", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer \u00f6ffnet meinem Sonnenschein", "tokens": ["Wer", "\u00f6ff\u00b7net", "mei\u00b7nem", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein Herz, von Trug und Torheit rein?", "tokens": ["ein", "Herz", ",", "von", "Trug", "und", "Tor\u00b7heit", "rein", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wer \u00f6ffnet meiner Herrlichkeit", "tokens": ["Wer", "\u00f6ff\u00b7net", "mei\u00b7ner", "Herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "ein Auge, da\u00df sich dran erfreut?!", "tokens": ["ein", "Au\u00b7ge", ",", "da\u00df", "sich", "dran", "er\u00b7freut", "?!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PRF", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Menschen hasten eilends fort;", "tokens": ["Die", "Men\u00b7schen", "has\u00b7ten", "ei\u00b7lends", "fort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "durch kahle Zweige braust der Nord.", "tokens": ["durch", "kah\u00b7le", "Zwei\u00b7ge", "braust", "der", "Nord", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schl\u00e4gt dein Herz im w\u00e4rmern Schlag,", "tokens": ["Und", "schl\u00e4gt", "dein", "Herz", "im", "w\u00e4r\u00b7mern", "Schlag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "zu Boden dr\u00fcckts das Ungemach,", "tokens": ["zu", "Bo\u00b7den", "dr\u00fcckts", "das", "Un\u00b7ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und tritt aus deines Hauptes Tor", "tokens": ["und", "tritt", "aus", "dei\u00b7nes", "Haup\u00b7tes", "Tor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein Lichtgedanke k\u00fchn hervor,", "tokens": ["ein", "Licht\u00b7ge\u00b7dan\u00b7ke", "k\u00fchn", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "ihn trifft des Lebens eis'ger Ku\u00df,", "tokens": ["ihn", "trifft", "des", "Le\u00b7bens", "eis'\u00b7ger", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "so da\u00df er schauernd sterben mu\u00df . . .", "tokens": ["so", "da\u00df", "er", "schau\u00b7ernd", "ster\u00b7ben", "mu\u00df", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVINF", "VMFIN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und fragst du noch von Tag zu Tag,", "tokens": ["Und", "fragst", "du", "noch", "von", "Tag", "zu", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wann's endlich Fr\u00fchling werden mag?", "tokens": ["wann's", "end\u00b7lich", "Fr\u00fch\u00b7ling", "wer\u00b7den", "mag", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}