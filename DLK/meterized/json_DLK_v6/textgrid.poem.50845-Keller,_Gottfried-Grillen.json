{"textgrid.poem.50845": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Grillen", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Poesie ist wie ein Kind,", "tokens": ["Die", "Poe\u00b7sie", "ist", "wie", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Das einsam Kr\u00e4nze windet,", "tokens": ["Das", "ein\u00b7sam", "Kr\u00e4n\u00b7ze", "win\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bald lacht und plaudert mit dem Wind,", "tokens": ["Bald", "lacht", "und", "plau\u00b7dert", "mit", "dem", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bald einen Schwank erfindet", "tokens": ["Bald", "ei\u00b7nen", "Schwank", "er\u00b7fin\u00b7det"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und wunderliche M\u00e4rchen spinnt,", "tokens": ["Und", "wun\u00b7der\u00b7li\u00b7che", "M\u00e4r\u00b7chen", "spinnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dann inneh\u00e4lt und traurig sinnt.", "tokens": ["Dann", "in\u00b7ne\u00b7h\u00e4lt", "und", "trau\u00b7rig", "sinnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Als ich vergangne Mitternacht", "tokens": ["Als", "ich", "ver\u00b7gang\u00b7ne", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In d\u00fcsterm Sinnen schwebte,", "tokens": ["In", "d\u00fcs\u00b7term", "Sin\u00b7nen", "schweb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da hab ich still und bang gedacht:", "tokens": ["Da", "hab", "ich", "still", "und", "bang", "ge\u00b7dacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie, wenn nicht mehr erlebte", "tokens": ["Wie", ",", "wenn", "nicht", "mehr", "er\u00b7leb\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PTKNEG", "ADV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich nun den Morgenglockenschlag?", "tokens": ["Ich", "nun", "den", "Mor\u00b7gen\u00b7glo\u00b7cken\u00b7schlag", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer wei\u00df denn, was geschehen mag?", "tokens": ["Wer", "wei\u00df", "denn", ",", "was", "ge\u00b7sche\u00b7hen", "mag", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$,", "PWS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Da schrieb ich einen langen Brief", "tokens": ["Da", "schrieb", "ich", "ei\u00b7nen", "lan\u00b7gen", "Brief"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An alle, die mich lieben;", "tokens": ["An", "al\u00b7le", ",", "die", "mich", "lie\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was mir im Herzen wacht' und schlief,", "tokens": ["Was", "mir", "im", "Her\u00b7zen", "wacht'", "und", "schlief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab ich hineingeschrieben,", "tokens": ["Hab", "ich", "hin\u00b7ein\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Damit beim Scheiden aus der Welt", "tokens": ["Da\u00b7mit", "beim", "Schei\u00b7den", "aus", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein Haus, mein Herz sei wohl bestellt.", "tokens": ["Mein", "Haus", ",", "mein", "Herz", "sei", "wohl", "be\u00b7stellt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich schrieb mein ganzes Leben auf", "tokens": ["Ich", "schrieb", "mein", "gan\u00b7zes", "Le\u00b7ben", "auf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und auch mein ganzes Wissen;", "tokens": ["Und", "auch", "mein", "gan\u00b7zes", "Wis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Irrt\u00fcmer wuchsen mir zu Hauf,", "tokens": ["Irr\u00b7t\u00fc\u00b7mer", "wuch\u00b7sen", "mir", "zu", "Hauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich z\u00e4hlte sie beflissen;", "tokens": ["Ich", "z\u00e4hl\u00b7te", "sie", "be\u00b7flis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Folgt auch des Guten sch\u00f6nrer Spur,", "tokens": ["Folgt", "auch", "des", "Gu\u00b7ten", "sch\u00f6n\u00b7rer", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch war's fast eine Nachschrift nur!", "tokens": ["Doch", "wa\u00b7r's", "fast", "ei\u00b7ne", "Nach\u00b7schrift", "nur", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Den Lieblingsdichter legt ich hin,", "tokens": ["Den", "Lieb\u00b7lings\u00b7dich\u00b7ter", "legt", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Daneben aufgeschlagen,", "tokens": ["Da\u00b7ne\u00b7ben", "auf\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als w\u00e4r das Fehlende darin", "tokens": ["Als", "w\u00e4r", "das", "Feh\u00b7len\u00b7de", "da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "ART", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Freunde zu erfragen;", "tokens": ["F\u00fcr", "Freun\u00b7de", "zu", "er\u00b7fra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und den und jenen guten Spruch", "tokens": ["Und", "den", "und", "je\u00b7nen", "gu\u00b7ten", "Spruch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "KON", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bezeichnet ich in manchem Buch.", "tokens": ["Be\u00b7zeich\u00b7net", "ich", "in", "man\u00b7chem", "Buch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Darauf verbrannt ich viel Papier", "tokens": ["Da\u00b7rauf", "ver\u00b7brannt", "ich", "viel", "Pa\u00b7pier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und r\u00e4umte in den Schr\u00e4nken,", "tokens": ["Und", "r\u00e4um\u00b7te", "in", "den", "Schr\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "St\u00fcrzt um mein leeres Trinkgeschirr,", "tokens": ["St\u00fcrzt", "um", "mein", "lee\u00b7res", "Trink\u00b7ge\u00b7schirr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und auf den Fensterb\u00e4nken,", "tokens": ["Und", "auf", "den", "Fens\u00b7ter\u00b7b\u00e4n\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wo ein paar magre Str\u00e4ucher bl\u00fchn,", "tokens": ["Wo", "ein", "paar", "mag\u00b7re", "Str\u00e4u\u00b7cher", "bl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Legt ich gebrochne Knospen hin.", "tokens": ["Legt", "ich", "ge\u00b7broch\u00b7ne", "Knos\u00b7pen", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Drin ich in Tagen, rauh und mild,", "tokens": ["Drin", "ich", "in", "Ta\u00b7gen", ",", "rauh", "und", "mild", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald sang und wieder weinte:", "tokens": ["Bald", "sang", "und", "wie\u00b7der", "wein\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich schuf mein Zimmer so zum Bild,", "tokens": ["Ich", "schuf", "mein", "Zim\u00b7mer", "so", "zum", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie ich zu sein vermeinte;", "tokens": ["Wie", "ich", "zu", "sein", "ver\u00b7mein\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKZU", "VAINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "So war ich endlich konterfeit", "tokens": ["So", "war", "ich", "end\u00b7lich", "kon\u00b7ter\u00b7feit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nach tief geheimster Eitelkeit.", "tokens": ["Nach", "tief", "ge\u00b7heims\u00b7ter", "Ei\u00b7tel\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Mit grauendem Gedankenspiel", "tokens": ["Mit", "grau\u00b7en\u00b7dem", "Ge\u00b7dan\u00b7ken\u00b7spiel"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Legt ich mich sodann nieder;", "tokens": ["Legt", "ich", "mich", "so\u00b7dann", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch bald versanken tief im Pf\u00fchl,", "tokens": ["Doch", "bald", "ver\u00b7san\u00b7ken", "tief", "im", "Pf\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entschlafen, Haupt und Glieder.", "tokens": ["Ent\u00b7schla\u00b7fen", ",", "Haupt", "und", "Glie\u00b7der", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Todesphantasie, ein Schaum,", "tokens": ["Die", "To\u00b7desp\u00b7han\u00b7ta\u00b7sie", ",", "ein", "Schaum", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zerflo\u00df im trivialsten Traum.", "tokens": ["Zer\u00b7flo\u00df", "im", "tri\u00b7vi\u00b7als\u00b7ten", "Traum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Und auch der Traum floh vor dem Tag;", "tokens": ["Und", "auch", "der", "Traum", "floh", "vor", "dem", "Tag", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ich erschrak, erwachend,", "tokens": ["Und", "ich", "er\u00b7schrak", ",", "er\u00b7wa\u00b7chend", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als ich da schnell besonnen lag,", "tokens": ["Als", "ich", "da", "schnell", "be\u00b7son\u00b7nen", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Leben mich umlachend.", "tokens": ["Das", "Le\u00b7ben", "mich", "um\u00b7la\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie war mir wunderlich und fremd", "tokens": ["Wie", "war", "mir", "wun\u00b7der\u00b7lich", "und", "fremd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im angema\u00dften Leichenhemd!", "tokens": ["Im", "an\u00b7ge\u00b7ma\u00df\u00b7ten", "Lei\u00b7chen\u00b7hemd", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Das Zimmer war voll Sonnenschein", "tokens": ["Das", "Zim\u00b7mer", "war", "voll", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und von der Drossel Schmettern,", "tokens": ["Und", "von", "der", "Dros\u00b7sel", "Schmet\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Hagel schlug zum Fenster ein", "tokens": ["Ein", "Ha\u00b7gel", "schlug", "zum", "Fens\u00b7ter", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von wei\u00dfen Bl\u00fctenbl\u00e4ttern;", "tokens": ["Von", "wei\u00b7\u00dfen", "Bl\u00fc\u00b7ten\u00b7bl\u00e4t\u00b7tern", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Der Fr\u00fchlingsschimmer \u00fcberflog", "tokens": ["Der", "Fr\u00fch\u00b7lings\u00b7schim\u00b7mer", "\u00fc\u00b7berf\u00b7log"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Totenkram, den ich erlog.", "tokens": ["Den", "To\u00b7ten\u00b7kram", ",", "den", "ich", "er\u00b7log", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und auch der Brief, den ich gemacht,", "tokens": ["Und", "auch", "der", "Brief", ",", "den", "ich", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War gl\u00e4nzend \u00fcberzogen;", "tokens": ["War", "gl\u00e4n\u00b7zend", "\u00fc\u00b7berz\u00b7o\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich las nun wieder mit Bedacht", "tokens": ["Ich", "las", "nun", "wie\u00b7der", "mit", "Be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den vollgeschriebnen Bogen;", "tokens": ["Den", "voll\u00b7ge\u00b7schrieb\u00b7nen", "Bo\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Am Ende aber, klar und rein,", "tokens": ["Am", "En\u00b7de", "a\u00b7ber", ",", "klar", "und", "rein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch ein paar Zeilen Sonnenschein:", "tokens": ["Noch", "ein", "paar", "Zei\u00b7len", "Son\u00b7nen\u00b7schein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbdu magst noch f\u00fcrder unentwegt", "tokens": ["\u00bb", "du", "magst", "noch", "f\u00fcr\u00b7der", "un\u00b7ent\u00b7wegt"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VMFIN", "ADV", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In dieser Lenzluft hauchen:", "tokens": ["In", "die\u00b7ser", "Lenz\u00b7luft", "hau\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Ist's dr\u00fcben nicht zu brauchen.", "tokens": ["Ist's", "dr\u00fc\u00b7ben", "nicht", "zu", "brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es bricht kein Herz so arm und klein,", "tokens": ["Es", "bricht", "kein", "Herz", "so", "arm", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es mu\u00df dem Tod gewachsen sein.", "tokens": ["Es", "mu\u00df", "dem", "Tod", "ge\u00b7wach\u00b7sen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Doch baue nicht zu sehr darauf!", "tokens": ["Doch", "bau\u00b7e", "nicht", "zu", "sehr", "da\u00b7rauf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PTKA", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gott wird uns Tage senden,", "tokens": ["Gott", "wird", "uns", "Ta\u00b7ge", "sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "NN", "VVINF", "$,"], "meter": "++-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die mit verdoppelt schnellem Lauf", "tokens": ["Die", "mit", "ver\u00b7dop\u00b7pelt", "schnel\u00b7lem", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die schwerste Arbeit enden,", "tokens": ["Die", "schwers\u00b7te", "Ar\u00b7beit", "en\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wo mancher Geist, der sinnt und schweift,", "tokens": ["Wo", "man\u00b7cher", "Geist", ",", "der", "sinnt", "und", "schweift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "$,", "PRELS", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Sturm dem Tod entgegenreift.\u00ab", "tokens": ["Im", "Sturm", "dem", "Tod", "ent\u00b7ge\u00b7gen\u00b7reift", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}