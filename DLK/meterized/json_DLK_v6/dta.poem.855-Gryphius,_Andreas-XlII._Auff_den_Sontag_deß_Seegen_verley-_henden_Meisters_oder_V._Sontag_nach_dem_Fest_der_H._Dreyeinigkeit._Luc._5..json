{"dta.poem.855": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XlII.  Auff den Sontag de\u00df Seegen verley-  \n henden Meisters oder  V.  Sontag nach dem  \n Fest der H. Dreyeinigkeit. Luc. 5.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Der ist vmbsonst bem\u00fcht wer viel bey Nacht wil fangen/ ", "tokens": ["Der", "ist", "vmbsonst", "be\u00b7m\u00fcht", "wer", "viel", "bey", "Nacht", "wil", "fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVFIN", "PWS", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wen S\u00fcnden Finstern\u00fc\u00df de\u00df Himmels glantz ver-", "tokens": ["Wen", "S\u00fcn\u00b7den", "Fins\u00b7ter\u00b7n\u00fc\u00df", "de\u00df", "Him\u00b7mels", "glantz", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "NN", "ART", "NN", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "deckt ", "tokens": ["deckt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Wen grawen/ blindheit/ furcht/ der Sternen Schar er-", "tokens": ["Wen", "gra\u00b7wen", "/", "blind\u00b7heit", "/", "furcht", "/", "der", "Ster\u00b7nen", "Schar", "er"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$(", "NN", "$(", "NN", "$(", "ART", "NN", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "schreckt ", "tokens": ["schreckt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Ist auch durch h\u00f6chsten schwei\u00df kein Seegen zuerlangen", "tokens": ["Ist", "auch", "durch", "h\u00f6chs\u00b7ten", "schwei\u00df", "kein", "See\u00b7gen", "zu\u00b7er\u00b7lan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "ADJA", "VVFIN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wer nicht auff Christus wort ins arbeit Schiff gegangen", "tokens": ["Wer", "nicht", "auff", "Chris\u00b7tus", "wort", "ins", "ar\u00b7beit", "Schiff", "ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "APPR", "NE", "NN", "APPRART", "NN", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den hilfft nicht m\u00fch vnd flei\u00df/ wer drauff sein Netz aus-", "tokens": ["Den", "hilfft", "nicht", "m\u00fch", "vnd", "flei\u00df", "/", "wer", "drauff", "sein", "Netz", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "ADJD", "KON", "NN", "$(", "PWS", "PAV", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "streckt: ", "tokens": ["streckt", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Vnd nicht voll schwartzer schuld/ voll tr\u00fcber wercke steckt", "tokens": ["Vnd", "nicht", "voll", "schwart\u00b7zer", "schuld", "/", "voll", "tr\u00fc\u00b7ber", "wer\u00b7cke", "steckt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ADJD", "ADJA", "NN", "$(", "ADJD", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der wird durch Gottes gunst mit vollen z\u00fcgen prangen.", "tokens": ["Der", "wird", "durch", "Got\u00b7tes", "gunst", "mit", "vol\u00b7len", "z\u00fc\u00b7gen", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O wahres gnaden Licht la\u00df deine Stral\u2019 aufgehn/", "tokens": ["O", "wah\u00b7res", "gna\u00b7den", "Licht", "la\u00df", "dei\u00b7ne", "Stral'", "auf\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Treib weg was dunckel hei\u00dft/ bleib in dem Schifflin stehn", "tokens": ["Treib", "weg", "was", "dun\u00b7ckel", "hei\u00dft", "/", "bleib", "in", "dem", "Schiff\u00b7lin", "stehn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PWS", "ADJD", "VVFIN", "$(", "VVFIN", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd la\u00df durch deine Lehr mich reich an Tugend werden.", "tokens": ["Vnd", "la\u00df", "durch", "dei\u00b7ne", "Lehr", "mich", "reich", "an", "Tu\u00b7gend", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "APPR", "PPOSAT", "NN", "PPER", "ADJD", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Da\u00df ich dem N\u00e4chsten stets in seiner Noth beyspring\u2019", "tokens": ["Da\u00df", "ich", "dem", "N\u00e4chs\u00b7ten", "stets", "in", "sei\u00b7ner", "Noth", "bey\u00b7spring'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In demuth mich erkenn/ vnd dein Gebott vollbring", "tokens": ["In", "de\u00b7muth", "mich", "er\u00b7kenn", "/", "vnd", "dein", "Ge\u00b7bott", "voll\u00b7bring"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "$(", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd willig wenn du ruffst/ verlasse Kahn vnd Erden.", "tokens": ["Vnd", "wil\u00b7lig", "wenn", "du", "ruffst", "/", "ver\u00b7las\u00b7se", "Kahn", "vnd", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOUS", "PPER", "VVFIN", "$(", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}