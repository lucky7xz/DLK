{"textgrid.poem.53970": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Lied f\u00fcrs Grammophon", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gib mir deine Hand,", "tokens": ["Gib", "mir", "dei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Du, im fernen Land \u2013", "tokens": ["Du", ",", "im", "fer\u00b7nen", "Land", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "APPRART", "ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Wie die \u00c4therwellen flitzen", "tokens": ["Wie", "die", "\u00c4t\u00b7her\u00b7wel\u00b7len", "flit\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcber Dr\u00e4hte, wo die Raben sitzen,", "tokens": ["\u00fc\u00b7ber", "Dr\u00e4h\u00b7te", ",", "wo", "die", "Ra\u00b7ben", "sit\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "saust meine Liebe dir zu . . .", "tokens": ["saust", "mei\u00b7ne", "Lie\u00b7be", "dir", "zu", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$.", "$.", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "du \u2013", "tokens": ["du", "\u2013"], "token_info": ["word", "punct"], "pos": ["PPER", "$("], "meter": "-", "measure": "single.down"}, "line.9": {"text": "tu \u2013 tu \u2013 tu \u2013 mmm \u2013", "tokens": ["tu", "\u2013", "tu", "\u2013", "tu", "\u2013", "mmm", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "NE", "$(", "FM.la", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Wenn du mich liebst, so singt dein Blut,", "tokens": ["Wenn", "du", "mich", "liebst", ",", "so", "singt", "dein", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Ach, wenn du nicht da bist, bin ich dir so gut,", "tokens": ["Ach", ",", "wenn", "du", "nicht", "da", "bist", ",", "bin", "ich", "dir", "so", "gut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VAFIN", "$,", "VAFIN", "PPER", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Dein, dein L\u00e4cheln l\u00e4\u00dft mir keine Ruh . . .", "tokens": ["Dein", ",", "dein", "L\u00e4\u00b7cheln", "l\u00e4\u00dft", "mir", "kei\u00b7ne", "Ruh", ".", ".", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "$,", "PPOSAT", "NN", "VVFIN", "PPER", "PIAT", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Man kann von oben l\u00e4cheln,", "tokens": ["Man", "kann", "von", "o\u00b7ben", "l\u00e4\u00b7cheln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "man kann von unten l\u00e4cheln,", "tokens": ["man", "kann", "von", "un\u00b7ten", "l\u00e4\u00b7cheln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "man kann daneben l\u00e4cheln \u2013", "tokens": ["man", "kann", "da\u00b7ne\u00b7ben", "l\u00e4\u00b7cheln", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PAV", "VVFIN", "$("], "meter": "+----+-", "measure": "dactylic.init"}, "line.9": {"text": "wie l\u00e4chelst du?", "tokens": ["wie", "l\u00e4\u00b7chelst", "du", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "tu \u2013 tu \u2013 tu \u2013 mmm \u2013", "tokens": ["tu", "\u2013", "tu", "\u2013", "tu", "\u2013", "mmm", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "NE", "$(", "FM.la", "$("], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Meine, die will mich verlassen,", "tokens": ["Mei\u00b7ne", ",", "die", "will", "mich", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$,", "PDS", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Deiner, der will dich fassen,", "tokens": ["Dei\u00b7ner", ",", "der", "will", "dich", "fas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$,", "PRELS", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Kehr zu ihm zur\u00fcck!", "tokens": ["Kehr", "zu", "ihm", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Vielleicht ist das das Gl\u00fcck . . .", "tokens": ["Viel\u00b7leicht", "ist", "das", "das", "Gl\u00fcck", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ich guck in den Mond immerzu \u2013", "tokens": ["Ich", "guck", "in", "den", "Mond", "im\u00b7mer\u00b7zu", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "oh, so blue \u2013 mmm \u2013", "tokens": ["oh", ",", "so", "blue", "\u2013", "mmm", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "VVFIN", "$(", "FM.la", "$("], "meter": "+---", "measure": "dactylic.init"}}, "stanza.4": {"line.1": {"text": "Wie man auch setzt im Leben,", "tokens": ["Wie", "man", "auch", "setzt", "im", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "man tippt doch immer daneben,", "tokens": ["man", "tippt", "doch", "im\u00b7mer", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "PAV", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Wir sitzen mit unsern Gef\u00fchlen", "tokens": ["Wir", "sit\u00b7zen", "mit", "un\u00b7sern", "Ge\u00b7f\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "meistens zwischen zwei St\u00fchlen \u2013", "tokens": ["meis\u00b7tens", "zwi\u00b7schen", "zwei", "St\u00fch\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "und was bleibt, ist des Herzens Ironie . . .", "tokens": ["und", "was", "bleibt", ",", "ist", "des", "Her\u00b7zens", "I\u00b7ro\u00b7nie", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PWS", "VVFIN", "$,", "VAFIN", "ART", "NN", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Lucindy!", "tokens": ["Lu\u00b7cin\u00b7dy", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Lucindy \u2013!", "tokens": ["Lu\u00b7cin\u00b7dy", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NE", "$(", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}