{"textgrid.poem.48311": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "4. Erstes Bataillon Garde (1780)", "genre": "verse", "period": "N.A.", "pub_year": 1888, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Erstes Bataillon Garde. Parad' oder Schlacht", "tokens": ["Ers\u00b7tes", "Ba\u00b7tail\u00b7lon", "Gar\u00b7de", ".", "Pa\u00b7rad'", "o\u00b7der", "Schlacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "NN", "$.", "NN", "KON", "NN"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Ihm wenig \u00bbDifferenzen\u00ab macht.", "tokens": ["Ihm", "we\u00b7nig", "\u00bb", "Dif\u00b7fe\u00b7ren\u00b7zen", "\u00ab", "macht", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$(", "NN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob in Potsdam sie trommelnd auf Wache ziehn,", "tokens": ["Ob", "in", "Pots\u00b7dam", "sie", "trom\u00b7melnd", "auf", "Wa\u00b7che", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NE", "PPER", "ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Ob sie stehen und fallen bei Kolin,", "tokens": ["Ob", "sie", "ste\u00b7hen", "und", "fal\u00b7len", "bei", "Ko\u00b7lin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Ob Patronenverknattern, ob Kugelpfiff,", "tokens": ["Ob", "Pat\u00b7ro\u00b7nen\u00b7ver\u00b7knat\u00b7tern", ",", "ob", "Ku\u00b7gel\u00b7pfiff", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Immer derselbe feste Griff,", "tokens": ["Im\u00b7mer", "der\u00b7sel\u00b7be", "fes\u00b7te", "Griff", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Dieselbe Ruh'. Jede Miene dr\u00fcckt aus:", "tokens": ["Die\u00b7sel\u00b7be", "Ruh'", ".", "Je\u00b7de", "Mie\u00b7ne", "dr\u00fcckt", "aus", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$.", "PIAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "\u00bbich geh\u00f6r' zur Familie, bin mit vom Haus.\u00ab", "tokens": ["\u00bb", "ich", "ge\u00b7h\u00f6r'", "zur", "Fa\u00b7mi\u00b7lie", ",", "bin", "mit", "vom", "Haus", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "NN", "$,", "VAFIN", "APPR", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Ihrer viere sitzen im Knapphans-Zelt.", "tokens": ["Ih\u00b7rer", "vie\u00b7re", "sit\u00b7zen", "im", "Knapp\u00b7hans\u00b7Zelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Eine Kottbuser hat sich jeder bestellt,", "tokens": ["Ei\u00b7ne", "Kott\u00b7bu\u00b7ser", "hat", "sich", "je\u00b7der", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "PIS", "VVFIN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Einen Kornus dazu; das Bier ist frisch.", "tokens": ["Ei\u00b7nen", "Kor\u00b7nus", "da\u00b7zu", ";", "das", "Bier", "ist", "frisch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Ein Berliner setzt sich mit an den Tisch,", "tokens": ["Ein", "Ber\u00b7li\u00b7ner", "setzt", "sich", "mit", "an", "den", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Ein Berliner Budiker \u2013 da w\u00e4hrt's nicht lange,", "tokens": ["Ein", "Ber\u00b7li\u00b7ner", "Bu\u00b7di\u00b7ker", "\u2013", "da", "w\u00e4hrt's", "nicht", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "VAFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+---+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Plapperm\u00fchl' ist im besten Gange.", "tokens": ["Plap\u00b7per\u00b7m\u00fchl'", "ist", "im", "bes\u00b7ten", "Gan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "\u00bbwahrhaftig, ihr habt die sch\u00f6nste Montur,", "tokens": ["\u00bb", "wahr\u00b7haf\u00b7tig", ",", "ihr", "habt", "die", "sch\u00f6ns\u00b7te", "Mon\u00b7tur", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+---", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Litzen, Paspel, Silberschnur,", "tokens": ["Lit\u00b7zen", ",", "Pas\u00b7pel", ",", "Sil\u00b7ber\u00b7schnur", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Blechm\u00fctzen wie Gold, gut Traktement,", "tokens": ["Blech\u00b7m\u00fct\u00b7zen", "wie", "Gold", ",", "gut", "Trak\u00b7te\u00b7ment", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KOKOM", "NN", "$,", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und der K\u00f6nig jeden von euch kennt.", "tokens": ["Und", "der", "K\u00f6\u00b7nig", "je\u00b7den", "von", "euch", "kennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PIAT", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.11": {"text": "Erstes Bataillon Garde, Prachtkerle vor all'n,", "tokens": ["Ers\u00b7tes", "Ba\u00b7tail\u00b7lon", "Gar\u00b7de", ",", "Pracht\u00b7ker\u00b7le", "vor", "all'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$,", "NN", "APPR", "NE", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Solch G\u00f6tterleben sollt' mir gefall'n.\u00ab", "tokens": ["Solch", "G\u00f6t\u00b7ter\u00b7le\u00b7ben", "sollt'", "mir", "ge\u00b7fall'", "n.", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Drei schwiegen. Endlich der vierte spricht:", "tokens": ["Drei", "schwie\u00b7gen", ".", "End\u00b7lich", "der", "vier\u00b7te", "spricht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VVINF", "$.", "ADV", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbne, Freund Berliner! ", "tokens": ["\u00bb", "ne", ",", "Freund", "Ber\u00b7li\u00b7ner", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NN", "NE", "$."], "meter": "-+---", "measure": "dactylic.init"}, "line.3": {"text": "Eine propre Montur, was soll uns ", "tokens": ["Ei\u00b7ne", "prop\u00b7re", "Mon\u00b7tur", ",", "was", "soll", "uns"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PWS", "VMFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Unser G\u00f6tter- is blo\u00df ein Jammerleben.", "tokens": ["Un\u00b7ser", "G\u00f6t\u00b7ter", "is", "blo\u00df", "ein", "Jam\u00b7mer\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "TRUNC", "FM", "ADV", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Potsdam, o du verfluchtes Loch,", "tokens": ["Pots\u00b7dam", ",", "o", "du", "ver\u00b7fluch\u00b7tes", "Loch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fchrst du doch heut' in die H\u00f6lle noch", "tokens": ["F\u00fchrst", "du", "doch", "heut'", "in", "die", "H\u00f6l\u00b7le", "noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "ADV"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Und n\u00e4hmst ", "tokens": ["Und", "n\u00e4hmst"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Da w\u00e4r' auch ", "tokens": ["Da", "w\u00e4r'", "auch"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ich mein' den da oben, \u2013 uns l\u00e4g' nichts dran,", "tokens": ["Ich", "mein'", "den", "da", "o\u00b7ben", ",", "\u2013", "uns", "l\u00e4g'", "nichts", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADV", "ADV", "$,", "$(", "PPER", "VVFIN", "PIS", "PAV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Is doch blo\u00df ein Qu\u00e4lgeist und Tyrann,", "tokens": ["Is", "doch", "blo\u00df", "ein", "Qu\u00e4l\u00b7geist", "und", "Ty\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-++--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Schont nicht Fremde, nicht Landeskinder,", "tokens": ["Schont", "nicht", "Frem\u00b7de", ",", "nicht", "Lan\u00b7des\u00b7kin\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "NN", "$,", "PTKNEG", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.12": {"text": "Immer derselbe Menschenschinder,", "tokens": ["Im\u00b7mer", "der\u00b7sel\u00b7be", "Men\u00b7schen\u00b7schin\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Immer dieselbe verfluchte Ravage \u2013", "tokens": ["Im\u00b7mer", "die\u00b7sel\u00b7be", "ver\u00b7fluch\u00b7te", "Ra\u00b7va\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "$("], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "Potsdam, o du gro\u00dfe Blamage!\u00ab", "tokens": ["Pots\u00b7dam", ",", "o", "du", "gro\u00b7\u00dfe", "Bla\u00b7ma\u00b7ge", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "FM", "PPER", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Das war dem Berliner nach seinem Sinn,", "tokens": ["Das", "war", "dem", "Ber\u00b7li\u00b7ner", "nach", "sei\u00b7nem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er l\u00e4chelte pfiffig vor sich hin:", "tokens": ["Er", "l\u00e4\u00b7chel\u00b7te", "pfif\u00b7fig", "vor", "sich", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbich sag' das schon lange. Was hat er denn gro\u00df?", "tokens": ["\u00bb", "ich", "sag'", "das", "schon", "lan\u00b7ge", ".", "Was", "hat", "er", "denn", "gro\u00df", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADV", "ADV", "$.", "PWS", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Gro\u00dfe Fenstern hat er, sonst is nich viel los.", "tokens": ["Gro\u00b7\u00dfe", "Fens\u00b7tern", "hat", "er", ",", "sonst", "is", "nich", "viel", "los", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "$,", "ADV", "FM", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Und reden kann er. Na, das kann jeder,", "tokens": ["Und", "re\u00b7den", "kann", "er", ".", "Na", ",", "das", "kann", "je\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PPER", "$.", "ITJ", "$,", "PDS", "VMFIN", "PIS", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Da lachten all' vier, und der eine spricht:", "tokens": ["Da", "lach\u00b7ten", "all'", "vier", ",", "und", "der", "ei\u00b7ne", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "CARD", "$,", "KON", "ART", "PIS", "VVFIN", "$."], "meter": "-+-----+-+", "measure": "dactylic.init"}, "line.2": {"text": "\u00bbne, Freund Budiker, ", "tokens": ["\u00bb", "ne", ",", "Freund", "Bu\u00b7di\u00b7ker", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NN", "NE", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Zuh\u00f6ren kannst du, wenn wir mal fluchen,", "tokens": ["Zu\u00b7h\u00f6\u00b7ren", "kannst", "du", ",", "wenn", "wir", "mal", "flu\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+----+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Aber du darfst es nicht selber versuchen,", "tokens": ["A\u00b7ber", "du", "darfst", "es", "nicht", "sel\u00b7ber", "ver\u00b7su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Wir d\u00fcrfen frech sein und schimpfen und schw\u00f6ren,", "tokens": ["Wir", "d\u00fcr\u00b7fen", "frech", "sein", "und", "schimp\u00b7fen", "und", "schw\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VAINF", "KON", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Weil wir selber mit zugeh\u00f6ren,", "tokens": ["Weil", "wir", "sel\u00b7ber", "mit", "zu\u00b7ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Wir d\u00fcrfen reden von Menschenschinder,", "tokens": ["Wir", "d\u00fcr\u00b7fen", "re\u00b7den", "von", "Men\u00b7schen\u00b7schin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Daf\u00fcr sind wir seine Kinder;", "tokens": ["Da\u00b7f\u00fcr", "sind", "wir", "sei\u00b7ne", "Kin\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.9": {"text": "Potsdam, o du verfluchtes Loch,", "tokens": ["Pots\u00b7dam", ",", "o", "du", "ver\u00b7fluch\u00b7tes", "Loch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Unser gro\u00dfer K\u00f6nig. Gott soll mich verderben,", "tokens": ["Un\u00b7ser", "gro\u00b7\u00dfer", "K\u00f6\u00b7nig", ".", "Gott", "soll", "mich", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "Wollt' ich nicht gleich f\u00fcr Fritzen sterben.\u00ab", "tokens": ["Wollt'", "ich", "nicht", "gleich", "f\u00fcr", "Frit\u00b7zen", "ster\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}