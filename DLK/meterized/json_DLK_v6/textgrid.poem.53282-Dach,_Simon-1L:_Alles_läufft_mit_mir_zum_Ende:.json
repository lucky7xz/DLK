{"textgrid.poem.53282": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Alles l\u00e4ufft mit mir zum Ende:", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alles l\u00e4ufft mit mir zum Ende:", "tokens": ["Al\u00b7les", "l\u00e4ufft", "mit", "mir", "zum", "En\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine H\u00e4nde,", "tokens": ["Mei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "F\u00fc\u00df vnd Arme sind verdorrt,", "tokens": ["F\u00fc\u00df", "vnd", "Ar\u00b7me", "sind", "ver\u00b7dorrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch die Fackel meiner Augen", "tokens": ["Auch", "die", "Fa\u00b7ckel", "mei\u00b7ner", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wil nicht taugen,", "tokens": ["Wil", "nicht", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Geist vnd Leben eilen fort.", "tokens": ["Geist", "vnd", "Le\u00b7ben", "ei\u00b7len", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wo der Todt, die Pest der Erden,", "tokens": ["Wo", "der", "Todt", ",", "die", "Pest", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Recht kan werden", "tokens": ["Recht", "kan", "wer\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["NN", "VMFIN", "VAINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Anzusehen abgemahlt,", "tokens": ["An\u00b7zu\u00b7se\u00b7hen", "ab\u00b7ge\u00b7mahlt", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00fcssen jhm die Arm vnd Beine", "tokens": ["M\u00fcs\u00b7sen", "jhm", "die", "Arm", "vnd", "Bei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Recht wie meine", "tokens": ["Recht", "wie", "mei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "KOKOM", "PPOSAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Vnd nicht anders sein gestalt.", "tokens": ["Vnd", "nicht", "an\u00b7ders", "sein", "ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PPOSAT", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Meines edlen Geistes Kr\u00e4ffte,", "tokens": ["Mei\u00b7nes", "ed\u00b7len", "Geis\u00b7tes", "Kr\u00e4ff\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Gesch\u00e4ffte", "tokens": ["Die", "Ge\u00b7sch\u00e4ff\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Meiner Sinnen nehmen ab,", "tokens": ["Mei\u00b7ner", "Sin\u00b7nen", "neh\u00b7men", "ab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nichts ist anders zu besorgen", "tokens": ["Nichts", "ist", "an\u00b7ders", "zu", "be\u00b7sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als vor Morgen", "tokens": ["Als", "vor", "Mor\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Noch zu scheiden in das Grab.", "tokens": ["Noch", "zu", "schei\u00b7den", "in", "das", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Seele, wenn du nun di\u00df Leben", "tokens": ["See\u00b7le", ",", "wenn", "du", "nun", "di\u00df", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "ADV", "PDS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hin solst geben,", "tokens": ["Hin", "solst", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "So entschlage dich der Noth,", "tokens": ["So", "ent\u00b7schla\u00b7ge", "dich", "der", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dencke, da\u00df du zu den Frommen", "tokens": ["Den\u00b7cke", ",", "da\u00df", "du", "zu", "den", "From\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht kanst kommen", "tokens": ["Nicht", "kanst", "kom\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "VMFIN", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Als nur einig durch den Todt.", "tokens": ["Als", "nur", "ei\u00b7nig", "durch", "den", "Todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "La\u00df dich seine finstre Hecken", "tokens": ["La\u00df", "dich", "sei\u00b7ne", "finst\u00b7re", "He\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht erschrecken,", "tokens": ["Nicht", "er\u00b7schre\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "S\u00fc\u00df vnd sanfft zwar thut er nicht,", "tokens": ["S\u00fc\u00df", "vnd", "sanfft", "zwar", "thut", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber eh wir es verstehen", "tokens": ["A\u00b7ber", "eh", "wir", "es", "ver\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wird auffgehen", "tokens": ["Wird", "auff\u00b7ge\u00b7hen"], "token_info": ["word", "word"], "pos": ["VAFIN", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Des gew\u00fcnschten Lebens Licht.", "tokens": ["Des", "ge\u00b7w\u00fcnschten", "Le\u00b7bens", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.6": {"line.1": {"text": "Hie, von dannen wir abfahren", "tokens": ["Hie", ",", "von", "dan\u00b7nen", "wir", "ab\u00b7fah\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "APPR", "ADV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu den Scharen", "tokens": ["Zu", "den", "Scha\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.3": {"text": "Der verstorbnen, schmertzt es wol,", "tokens": ["Der", "ver\u00b7storb\u00b7nen", ",", "schmertzt", "es", "wol", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber dort auff jener Seiten", "tokens": ["A\u00b7ber", "dort", "auff", "je\u00b7ner", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist kein streiten,", "tokens": ["Ist", "kein", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Sondern alles Frewden voll.", "tokens": ["Son\u00b7dern", "al\u00b7les", "Frew\u00b7den", "voll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Da sind erst die rechte H\u00fctten", "tokens": ["Da", "sind", "erst", "die", "rech\u00b7te", "H\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wo kein W\u00fcten", "tokens": ["Wo", "kein", "W\u00fc\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PIAT", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Der verdamten Tyranney,", "tokens": ["Der", "ver\u00b7dam\u00b7ten", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern das nur ist zu schawen", "tokens": ["Son\u00b7dern", "das", "nur", "ist", "zu", "scha\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "ADV", "VAFIN", "PTKZU", "VVINF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Was wir Trawen,", "tokens": ["Was", "wir", "Tra\u00b7wen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "PPER", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Da\u00df es ewig vns erfrew'.", "tokens": ["Da\u00df", "es", "e\u00b7wig", "vns", "er\u00b7fre\u00b7w'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "H\u00fclle dich in Christi Wunden,", "tokens": ["H\u00fcl\u00b7le", "dich", "in", "Chris\u00b7ti", "Wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der empfunden", "tokens": ["Der", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Was zu leiden dir geb\u00fchrt,", "tokens": ["Was", "zu", "lei\u00b7den", "dir", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKZU", "VVINF", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "La\u00df dich dein beth\u00f6rt ver\u00fcben", "tokens": ["La\u00df", "dich", "dein", "be\u00b7th\u00f6rt", "ver\u00b7\u00fc\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPOSAT", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nicht betr\u00fcben,", "tokens": ["Nicht", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Er hat alles au\u00dfgef\u00fchrt.", "tokens": ["Er", "hat", "al\u00b7les", "au\u00df\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Gibt er nicht zu Gottes Rechten", "tokens": ["Gibt", "er", "nicht", "zu", "Got\u00b7tes", "Rech\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Den Geschlechten", "tokens": ["Den", "Ge\u00b7schlech\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Der Erwehlten jhre Lust?", "tokens": ["Der", "Er\u00b7wehl\u00b7ten", "jhre", "Lust", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Er wird, wann du k\u00f6mpst gegangen,", "tokens": ["Er", "wird", ",", "wann", "du", "k\u00f6mpst", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "VVFIN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dich vmbfangen,", "tokens": ["Dich", "vmb\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Vnd einschliessen seiner Brust.", "tokens": ["Vnd", "ein\u00b7schlies\u00b7sen", "sei\u00b7ner", "Brust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Wir sind alle durch sein Sterben", "tokens": ["Wir", "sind", "al\u00b7le", "durch", "sein", "Ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmels Erben,", "tokens": ["Him\u00b7mels", "Er\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Ja er wird des Todes Pein,", "tokens": ["Ja", "er", "wird", "des", "To\u00b7des", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die du wirst empfinden m\u00fcssen,", "tokens": ["Die", "du", "wirst", "emp\u00b7fin\u00b7den", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VAFIN", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dir vers\u00fcssen,", "tokens": ["Dir", "ver\u00b7s\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Da\u00df sie nur ein Schlaff wird seyn.", "tokens": ["Da\u00df", "sie", "nur", "ein", "Schlaff", "wird", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VAFIN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Legt euch nun geruhig nieder,", "tokens": ["Legt", "euch", "nun", "ge\u00b7ru\u00b7hig", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine Glieder,", "tokens": ["Mei\u00b7ne", "Glie\u00b7der", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Eben wie jhr vmb die Nacht", "tokens": ["E\u00b7ben", "wie", "jhr", "vmb", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "PPER", "APPR", "ART", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Euch die Kr\u00e4ffte zu erholen,", "tokens": ["Euch", "die", "Kr\u00e4ff\u00b7te", "zu", "er\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gott befohlen,", "tokens": ["Gott", "be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Vnd zu Bett' offt habt gemacht.", "tokens": ["Vnd", "zu", "Bett'", "offt", "habt", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ruhet frey von allem Jammer", "tokens": ["Ru\u00b7het", "frey", "von", "al\u00b7lem", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPR", "PIS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Kammer,", "tokens": ["In", "der", "Kam\u00b7mer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.3": {"text": "Die Gott fest verriegeln wird,", "tokens": ["Die", "Gott", "fest", "ver\u00b7rie\u00b7geln", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "VAFIN", "$,"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Vnd sie, wenn jhr solt erwachen,", "tokens": ["Vnd", "sie", ",", "wenn", "jhr", "solt", "er\u00b7wa\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.5": {"text": "Auff erst machen,", "tokens": ["Auff", "erst", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Selbst des Lebens Th\u00fcr vnd Hirt.", "tokens": ["Selbst", "des", "Le\u00b7bens", "Th\u00fcr", "vnd", "Hirt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Alsdann solt jhr ewrer Seelen", "tokens": ["Als\u00b7dann", "solt", "jhr", "ew\u00b7rer", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Au\u00df der H\u00f6len", "tokens": ["Au\u00df", "der", "H\u00f6\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Anvertrawt den Herren sehn,", "tokens": ["An\u00b7ver\u00b7trawt", "den", "Her\u00b7ren", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch in seinen wahren Frewden", "tokens": ["Euch", "in", "sei\u00b7nen", "wah\u00b7ren", "Frew\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ewig weiden,", "tokens": ["E\u00b7wig", "wei\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Thun was hie nicht kan geschehn.", "tokens": ["Thun", "was", "hie", "nicht", "kan", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ADV", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Gute Nacht, o Welt, sambt allen", "tokens": ["Gu\u00b7te", "Nacht", ",", "o", "Welt", ",", "sambt", "al\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "FM", "NN", "$,", "VVFIN", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die noch wallen", "tokens": ["Die", "noch", "wal\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADV", "VVINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Hie auff deinem tr\u00fcben Meer!", "tokens": ["Hie", "auff", "dei\u00b7nem", "tr\u00fc\u00b7ben", "Meer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Schaw, ich werd' jetzt auffgenommen", "tokens": ["Schaw", ",", "ich", "werd'", "jetzt", "auff\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Zu den Frommen", "tokens": ["Zu", "den", "From\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Vnd dem grossen Himmels Heer!", "tokens": ["Vnd", "dem", "gros\u00b7sen", "Him\u00b7mels", "Heer", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Welche mit mir hie begehren", "tokens": ["Wel\u00b7che", "mit", "mir", "hie", "be\u00b7geh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "APPR", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einzukehren,", "tokens": ["Ein\u00b7zu\u00b7keh\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Schawen, da\u00df sie nur die Ruh,", "tokens": ["Scha\u00b7wen", ",", "da\u00df", "sie", "nur", "die", "Ruh", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Christum, sich nicht m\u00f6gen sch\u00e4men", "tokens": ["Chris\u00b7tum", ",", "sich", "nicht", "m\u00f6\u00b7gen", "sch\u00e4\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRF", "PTKNEG", "VMFIN", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Anzunehmen", "tokens": ["An\u00b7zu\u00b7neh\u00b7men"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Vnd gehn auff jhr St\u00fcndlein zu.", "tokens": ["Vnd", "gehn", "auff", "jhr", "St\u00fcnd\u00b7lein", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Die jhr Ende stets betrachten", "tokens": ["Die", "jhr", "En\u00b7de", "stets", "be\u00b7trach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd verachten", "tokens": ["Vnd", "ver\u00b7ach\u00b7ten"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dieser Welt verkehrten Sinn,", "tokens": ["Die\u00b7ser", "Welt", "ver\u00b7kehr\u00b7ten", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jesum, bi\u00df sie gantz erkalten,", "tokens": ["Je\u00b7sum", ",", "bi\u00df", "sie", "gantz", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gl\u00e4ubig halten,", "tokens": ["Gl\u00e4u\u00b7big", "hal\u00b7ten", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Fahren sanfft vnd seelig hin.", "tokens": ["Fah\u00b7ren", "sanfft", "vnd", "see\u00b7lig", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}