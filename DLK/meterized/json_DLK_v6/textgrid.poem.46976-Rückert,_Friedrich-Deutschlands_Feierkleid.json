{"textgrid.poem.46976": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Deutschlands Feierkleid", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mit wie herrlich weitem Kleide,", "tokens": ["Mit", "wie", "herr\u00b7lich", "wei\u00b7tem", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ganz bedeckend deinen Leib,", "tokens": ["Ganz", "be\u00b7de\u00b7ckend", "dei\u00b7nen", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nntest du in Samt und Seide", "tokens": ["K\u00f6nn\u00b7test", "du", "in", "Samt", "und", "Sei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Prangen, Deutschland, edles Weib!", "tokens": ["Pran\u00b7gen", ",", "Deutschland", ",", "ed\u00b7les", "Weib", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "Da du aus dem Sack der Aschen", "tokens": ["Da", "du", "aus", "dem", "Sack", "der", "A\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Standest auf nach langer Rast", "tokens": ["Stan\u00b7dest", "auf", "nach", "lan\u00b7ger", "Rast"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Endlich, und dein Kleid gewaschen", "tokens": ["End\u00b7lich", ",", "und", "dein", "Kleid", "ge\u00b7wa\u00b7schen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KON", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem Blut des Feindes hast!", "tokens": ["In", "dem", "Blut", "des", "Fein\u00b7des", "hast", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wenn nur in der Hand des B\u00f6sen", "tokens": ["Wenn", "nur", "in", "der", "Hand", "des", "B\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Deines Kleides nicht ein St\u00fcck,", "tokens": ["Dei\u00b7nes", "Klei\u00b7des", "nicht", "ein", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Statt es ganz dir einzul\u00f6sen,", "tokens": ["Statt", "es", "ganz", "dir", "ein\u00b7zu\u00b7l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Man vergessend lie\u00df zur\u00fcck!", "tokens": ["Man", "ver\u00b7ges\u00b7send", "lie\u00df", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wenn nur jetzt nicht deine Kinder", "tokens": ["Wenn", "nur", "jetzt", "nicht", "dei\u00b7ne", "Kin\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "PTKNEG", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In nicht liebevollem Streit", "tokens": ["In", "nicht", "lie\u00b7be\u00b7vol\u00b7lem", "Streit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PTKNEG", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jedes f\u00fcr sich einen Flinder", "tokens": ["Je\u00b7des", "f\u00fcr", "sich", "ei\u00b7nen", "Flin\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "APPR", "PRF", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Riss' aus ihrer Mutter Kleid!", "tokens": ["Riss'", "aus", "ih\u00b7rer", "Mut\u00b7ter", "Kleid", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Mit wie herrlich weitem Kleide,", "tokens": ["Mit", "wie", "herr\u00b7lich", "wei\u00b7tem", "Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ganz bedeckend deinen Leib,", "tokens": ["Ganz", "be\u00b7de\u00b7ckend", "dei\u00b7nen", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nntest du in Samt und Seide", "tokens": ["K\u00f6nn\u00b7test", "du", "in", "Samt", "und", "Sei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Prangen, Deutschland, edles Weib!", "tokens": ["Pran\u00b7gen", ",", "Deutschland", ",", "ed\u00b7les", "Weib", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}}}}