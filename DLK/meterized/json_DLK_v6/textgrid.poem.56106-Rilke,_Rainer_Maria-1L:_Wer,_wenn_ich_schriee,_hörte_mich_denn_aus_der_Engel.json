{"textgrid.poem.56106": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer, wenn ich schriee, h\u00f6rte mich denn aus der Engel", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer, wenn ich schriee, h\u00f6rte mich denn aus der Engel", "tokens": ["Wer", ",", "wenn", "ich", "schri\u00b7ee", ",", "h\u00f6r\u00b7te", "mich", "denn", "aus", "der", "En\u00b7gel"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ordnungen? und gesetzt selbst, es n\u00e4hme", "tokens": ["Ord\u00b7nun\u00b7gen", "?", "und", "ge\u00b7setzt", "selbst", ",", "es", "n\u00e4h\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "KON", "VVPP", "ADV", "$,", "PPER", "VVFIN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "einer mich pl\u00f6tzlich ans Herz: ich verginge von seinem", "tokens": ["ei\u00b7ner", "mich", "pl\u00f6tz\u00b7lich", "ans", "Herz", ":", "ich", "ver\u00b7gin\u00b7ge", "von", "sei\u00b7nem"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "PRF", "ADJD", "APPRART", "NN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.4": {"text": "st\u00e4rkeren Dasein. Denn das Sch\u00f6ne ist nichts", "tokens": ["st\u00e4r\u00b7ke\u00b7ren", "Da\u00b7sein", ".", "Denn", "das", "Sch\u00f6\u00b7ne", "ist", "nichts"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "KON", "ART", "NN", "VAFIN", "PIS"], "meter": "+---+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "als des Schrecklichen Anfang, den wir noch grade ertragen,", "tokens": ["als", "des", "Schreck\u00b7li\u00b7chen", "An\u00b7fang", ",", "den", "wir", "noch", "gra\u00b7de", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "und wir bewundern es so, weil es gelassen verschm\u00e4ht,", "tokens": ["und", "wir", "be\u00b7wun\u00b7dern", "es", "so", ",", "weil", "es", "ge\u00b7las\u00b7sen", "ver\u00b7schm\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "VVPP", "VVPP", "$,"], "meter": "-+-+---+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "uns zu zerst\u00f6ren. Ein jeder Engel ist schrecklich.", "tokens": ["uns", "zu", "zer\u00b7st\u00f6\u00b7ren", ".", "Ein", "je\u00b7der", "En\u00b7gel", "ist", "schreck\u00b7lich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$.", "ART", "PIAT", "NN", "VAFIN", "ADJD", "$."], "meter": "---+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Und so verhalt ich mich denn und verschlucke den Lockruf", "tokens": ["Und", "so", "ver\u00b7halt", "ich", "mich", "denn", "und", "ver\u00b7schlu\u00b7cke", "den", "Lock\u00b7ruf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "ADV", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "dunkelen Schluchzens. Ach, wen verm\u00f6gen", "tokens": ["dun\u00b7ke\u00b7len", "Schluch\u00b7zens", ".", "Ach", ",", "wen", "ver\u00b7m\u00f6\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "ITJ", "$,", "PWS", "VVFIN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "wir denn zu brauchen? Engel nicht, Menschen nicht,", "tokens": ["wir", "denn", "zu", "brau\u00b7chen", "?", "En\u00b7gel", "nicht", ",", "Men\u00b7schen", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$.", "NE", "PTKNEG", "$,", "NN", "PTKNEG", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "und die findigen Tiere merken es schon,", "tokens": ["und", "die", "fin\u00b7di\u00b7gen", "Tie\u00b7re", "mer\u00b7ken", "es", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "da\u00df wir nicht sehr verl\u00e4\u00dflich zu Haus sind", "tokens": ["da\u00df", "wir", "nicht", "sehr", "ver\u00b7l\u00e4\u00df\u00b7lich", "zu", "Haus", "sind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADJD", "APPR", "NN", "VAFIN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "in der gedeuteten Welt. Es bleibt uns vielleicht", "tokens": ["in", "der", "ge\u00b7deu\u00b7te\u00b7ten", "Welt", ".", "Es", "bleibt", "uns", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.6": {"text": "irgend ein Baum an dem Abhang, da\u00df wir ihn t\u00e4glich", "tokens": ["ir\u00b7gend", "ein", "Baum", "an", "dem", "Ab\u00b7hang", ",", "da\u00df", "wir", "ihn", "t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "ADJD"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.7": {"text": "wieders\u00e4hen; es bleibt uns die Stra\u00dfe von gestern", "tokens": ["wie\u00b7der\u00b7s\u00e4\u00b7hen", ";", "es", "bleibt", "uns", "die", "Stra\u00b7\u00dfe", "von", "ge\u00b7stern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "NN"], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "und das verzogene Treusein einer Gewohnheit,", "tokens": ["und", "das", "ver\u00b7zo\u00b7ge\u00b7ne", "Treu\u00b7sein", "ei\u00b7ner", "Ge\u00b7wohn\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "---+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "der es bei uns gefiel, und so blieb sie und ging nicht.", "tokens": ["der", "es", "bei", "uns", "ge\u00b7fiel", ",", "und", "so", "blieb", "sie", "und", "ging", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPER", "VVFIN", "$,", "KON", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "PTKNEG", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}}, "stanza.4": {"line.1": {"text": "O und die Nacht, die Nacht, wenn der Wind voller Weltraum", "tokens": ["O", "und", "die", "Nacht", ",", "die", "Nacht", ",", "wenn", "der", "Wind", "vol\u00b7ler", "Welt\u00b7raum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "ART", "NN", "$,", "ART", "NN", "$,", "KOUS", "ART", "NN", "ADJA", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}}, "stanza.5": {"line.1": {"text": "uns am Angesicht zehrt \u2013, wem bliebe sie nicht, die ersehnte,", "tokens": ["uns", "am", "An\u00b7ge\u00b7sicht", "zehrt", "\u2013", ",", "wem", "blie\u00b7be", "sie", "nicht", ",", "die", "er\u00b7sehn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVFIN", "$(", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "sanft entt\u00e4uschende, welche dem einzelnen Herzen", "tokens": ["sanft", "ent\u00b7t\u00e4u\u00b7schen\u00b7de", ",", "wel\u00b7che", "dem", "ein\u00b7zel\u00b7nen", "Her\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADJA", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "m\u00fchsam bevorsteht. Ist sie den Liebenden leichter?", "tokens": ["m\u00fch\u00b7sam", "be\u00b7vor\u00b7steht", ".", "Ist", "sie", "den", "Lie\u00b7ben\u00b7den", "leich\u00b7ter", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$.", "VAFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "+-------+--+-", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Ach, sie verdecken sich nur mit einander ihr Los.", "tokens": ["Ach", ",", "sie", "ver\u00b7de\u00b7cken", "sich", "nur", "mit", "ein\u00b7an\u00b7der", "ihr", "Los", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PRF", "ADV", "APPR", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Wei\u00dft du's ", "tokens": ["Wei\u00dft", "du's"], "token_info": ["word", "word"], "pos": ["VVFIN", "NE"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "zu den R\u00e4umen hinzu, die wir atmen; vielleicht da\u00df die V\u00f6gel", "tokens": ["zu", "den", "R\u00e4u\u00b7men", "hin\u00b7zu", ",", "die", "wir", "at\u00b7men", ";", "viel\u00b7leicht", "da\u00df", "die", "V\u00f6\u00b7gel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "PRELS", "PPER", "VVINF", "$.", "ADV", "KOUS", "ART", "NN"], "meter": "--+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "die erweiterte Luft f\u00fchlen mit innigerm Flug.", "tokens": ["die", "er\u00b7wei\u00b7ter\u00b7te", "Luft", "f\u00fch\u00b7len", "mit", "in\u00b7ni\u00b7germ", "Flug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Ja, die Fr\u00fchlinge brauchten dich wohl. Es muteten manche", "tokens": ["Ja", ",", "die", "Fr\u00fch\u00b7lin\u00b7ge", "brauch\u00b7ten", "dich", "wohl", ".", "Es", "mu\u00b7te\u00b7ten", "man\u00b7che"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "PPER", "ADV", "$.", "PPER", "VMFIN", "PIS"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Sterne dir zu, da\u00df du sie sp\u00fcrtest. Es hob", "tokens": ["Ster\u00b7ne", "dir", "zu", ",", "da\u00df", "du", "sie", "sp\u00fcr\u00b7test", ".", "Es", "hob"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$.", "PPER", "VVFIN"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "sich eine Woge heran im Vergangenen, oder", "tokens": ["sich", "ei\u00b7ne", "Wo\u00b7ge", "he\u00b7ran", "im", "Ver\u00b7gan\u00b7ge\u00b7nen", ",", "o\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PRF", "ART", "NN", "PTKVZ", "APPRART", "NN", "$,", "KON"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "da du vor\u00fcberkamst am ge\u00f6ffneten Fenster,", "tokens": ["da", "du", "vor\u00b7\u00fc\u00b7ber\u00b7kamst", "am", "ge\u00b7\u00f6ff\u00b7ne\u00b7ten", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "gab eine Geige sich hin. Das alles war Auftrag.", "tokens": ["gab", "ei\u00b7ne", "Gei\u00b7ge", "sich", "hin", ".", "Das", "al\u00b7les", "war", "Auf\u00b7trag", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "PTKVZ", "$.", "ART", "PIS", "VAFIN", "NN", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "Aber bew\u00e4ltigtest du's? Warst du nicht immer", "tokens": ["A\u00b7ber", "be\u00b7w\u00e4l\u00b7tig\u00b7test", "du's", "?", "Warst", "du", "nicht", "im\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "$.", "VAFIN", "PPER", "PTKNEG", "ADV"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "noch von Erwartung zerstreut, als k\u00fcndigte alles", "tokens": ["noch", "von", "Er\u00b7war\u00b7tung", "zer\u00b7streut", ",", "als", "k\u00fcn\u00b7dig\u00b7te", "al\u00b7les"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVPP", "$,", "KOUS", "VVFIN", "PIS"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.8": {"text": "eine Geliebte dir an? (Wo willst du sie bergen,", "tokens": ["ei\u00b7ne", "Ge\u00b7lieb\u00b7te", "dir", "an", "?", "(", "Wo", "willst", "du", "sie", "ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "$.", "$(", "PWAV", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "da doch die gro\u00dfen fremden Gedanken bei dir", "tokens": ["da", "doch", "die", "gro\u00b7\u00dfen", "frem\u00b7den", "Ge\u00b7dan\u00b7ken", "bei", "dir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "ADJA", "NN", "APPR", "PPER"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "aus und ein gehn und \u00f6fters bleiben bei Nacht.)", "tokens": ["aus", "und", "ein", "gehn", "und", "\u00f6f\u00b7ters", "blei\u00b7ben", "bei", "Nacht", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKVZ", "KON", "ART", "VVINF", "KON", "ADV", "VVINF", "APPR", "NN", "$.", "$("], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.11": {"text": "Sehnt es dich aber, so singe die Liebenden; lange", "tokens": ["Sehnt", "es", "dich", "a\u00b7ber", ",", "so", "sin\u00b7ge", "die", "Lie\u00b7ben\u00b7den", ";", "lan\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "$,", "ADV", "VVFIN", "ART", "NN", "$.", "ADV"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.12": {"text": "noch nicht unsterblich genug ist ihr ber\u00fchmtes Gef\u00fchl.", "tokens": ["noch", "nicht", "uns\u00b7terb\u00b7lich", "ge\u00b7nug", "ist", "ihr", "be\u00b7r\u00fchm\u00b7tes", "Ge\u00b7f\u00fchl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.13": {"text": "Jene, du neidest sie fast, Verlassenen, die du", "tokens": ["Je\u00b7ne", ",", "du", "nei\u00b7dest", "sie", "fast", ",", "Ver\u00b7las\u00b7se\u00b7nen", ",", "die", "du"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PDS", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "PRELS", "PPER"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "so viel liebender fandst als die Gestillten. Beginn", "tokens": ["so", "viel", "lie\u00b7ben\u00b7der", "fandst", "als", "die", "Ge\u00b7still\u00b7ten", ".", "Be\u00b7ginn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "ADJD", "VVFIN", "KOKOM", "ART", "NN", "$.", "NN"], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.15": {"text": "immer von neuem die nie zu erreichende Preisung;", "tokens": ["im\u00b7mer", "von", "neu\u00b7em", "die", "nie", "zu", "er\u00b7rei\u00b7chen\u00b7de", "Prei\u00b7sung", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "ART", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.16": {"text": "denk: es erh\u00e4lt sich der Held, selbst der Untergang war ihm", "tokens": ["denk", ":", "es", "er\u00b7h\u00e4lt", "sich", "der", "Held", ",", "selbst", "der", "Un\u00b7ter\u00b7gang", "war", "ihm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "PPER", "VVFIN", "PRF", "ART", "NN", "$,", "ADV", "ART", "NN", "VAFIN", "PPER"], "meter": "+--+--+--+-+--", "measure": "dactylic.tri.plus"}, "line.17": {"text": "nur ein Vorwand, zu sein: seine letzte Geburt.", "tokens": ["nur", "ein", "Vor\u00b7wand", ",", "zu", "sein", ":", "sei\u00b7ne", "letz\u00b7te", "Ge\u00b7burt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PTKZU", "VAINF", "$.", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Aber die Liebenden nimmt die ersch\u00f6pfte Natur", "tokens": ["A\u00b7ber", "die", "Lie\u00b7ben\u00b7den", "nimmt", "die", "er\u00b7sch\u00f6pf\u00b7te", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.19": {"text": "in sich zur\u00fcck, als w\u00e4ren nicht zweimal die Kr\u00e4fte,", "tokens": ["in", "sich", "zu\u00b7r\u00fcck", ",", "als", "w\u00e4\u00b7ren", "nicht", "zwei\u00b7mal", "die", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "PTKVZ", "$,", "KOKOM", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "dieses zu leisten. Hast du der Gaspara Stampa", "tokens": ["die\u00b7ses", "zu", "leis\u00b7ten", ".", "Hast", "du", "der", "Gas\u00b7pa\u00b7ra", "Stam\u00b7pa"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "PTKZU", "VVINF", "$.", "VAFIN", "PPER", "ART", "NN", "NE"], "meter": "+--+--+-++--+", "measure": "dactylic.di.plus"}, "line.21": {"text": "denn gen\u00fcgend gedacht, da\u00df irgend ein M\u00e4dchen,", "tokens": ["denn", "ge\u00b7n\u00fc\u00b7gend", "ge\u00b7dacht", ",", "da\u00df", "ir\u00b7gend", "ein", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$,", "KOUS", "ADV", "ART", "NN", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.22": {"text": "dem der Geliebte entging, am gesteigerten Beispiel", "tokens": ["dem", "der", "Ge\u00b7lieb\u00b7te", "ent\u00b7ging", ",", "am", "ge\u00b7stei\u00b7ger\u00b7ten", "Bei\u00b7spiel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "APPRART", "ADJA", "NN"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.23": {"text": "dieser Liebenden f\u00fchlt: da\u00df ich w\u00fcrde wie sie?", "tokens": ["die\u00b7ser", "Lie\u00b7ben\u00b7den", "f\u00fchlt", ":", "da\u00df", "ich", "w\u00fcr\u00b7de", "wie", "sie", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "$.", "KOUS", "PPER", "VAFIN", "KOKOM", "PPER", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.24": {"text": "Sollen nicht endlich uns diese \u00e4ltesten Schmerzen", "tokens": ["Sol\u00b7len", "nicht", "end\u00b7lich", "uns", "die\u00b7se", "\u00e4l\u00b7tes\u00b7ten", "Schmer\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "ADV", "PPER", "PDAT", "ADJA", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.25": {"text": "fruchtbarer werden? Ist es nicht Zeit, da\u00df wir liebend", "tokens": ["frucht\u00b7ba\u00b7rer", "wer\u00b7den", "?", "Ist", "es", "nicht", "Zeit", ",", "da\u00df", "wir", "lie\u00b7bend"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VAINF", "$.", "VAFIN", "PPER", "PTKNEG", "NN", "$,", "KOUS", "PPER", "ADJD"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.26": {"text": "uns vom Geliebten befrein und es bebend bestehn:", "tokens": ["uns", "vom", "Ge\u00b7lieb\u00b7ten", "be\u00b7fr\u00b7ein", "und", "es", "be\u00b7bend", "be\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKVZ", "KON", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.27": {"text": "wie der Pfeil die Sehne besteht, um gesammelt im Absprung", "tokens": ["wie", "der", "Pfeil", "die", "Seh\u00b7ne", "be\u00b7steht", ",", "um", "ge\u00b7sam\u00b7melt", "im", "Ab\u00b7sprung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$,", "KOUI", "VVPP", "APPRART", "NN"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}}, "stanza.9": {"line.1": {"text": "Stimmen, Stimmen. H\u00f6re, mein Herz, wie sonst nur", "tokens": ["Stim\u00b7men", ",", "Stim\u00b7men", ".", "H\u00f6\u00b7re", ",", "mein", "Herz", ",", "wie", "sonst", "nur"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$.", "NE", "$,", "PPOSAT", "NN", "$,", "PWAV", "ADV", "ADV"], "meter": "+-+-+--+---", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Heilige h\u00f6rten: da\u00df sie der riesige Ruf", "tokens": ["Hei\u00b7li\u00b7ge", "h\u00f6r\u00b7ten", ":", "da\u00df", "sie", "der", "rie\u00b7si\u00b7ge", "Ruf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "VVFIN", "$.", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "aufhob vom Boden; sie aber knieten,", "tokens": ["auf\u00b7hob", "vom", "Bo\u00b7den", ";", "sie", "a\u00b7ber", "knie\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "$.", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Unm\u00f6gliche, weiter und achtetens nicht:", "tokens": ["Un\u00b7m\u00f6g\u00b7li\u00b7che", ",", "wei\u00b7ter", "und", "ach\u00b7te\u00b7tens", "nicht", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "KON", "ADV", "PTKNEG", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "die Stimme, bei weitem. Aber das Wehende h\u00f6re,", "tokens": ["die", "Stim\u00b7me", ",", "bei", "wei\u00b7tem", ".", "A\u00b7ber", "das", "We\u00b7hen\u00b7de", "h\u00f6\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PIS", "$.", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "die ununterbrochene Nachricht, die aus Stille sich bildet.", "tokens": ["die", "un\u00b7un\u00b7ter\u00b7bro\u00b7che\u00b7ne", "Nach\u00b7richt", ",", "die", "aus", "Stil\u00b7le", "sich", "bil\u00b7det", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "APPR", "NN", "PRF", "VVFIN", "$."], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Es rauscht jetzt von jenen jungen Toten zu dir.", "tokens": ["Es", "rauscht", "jetzt", "von", "je\u00b7nen", "jun\u00b7gen", "To\u00b7ten", "zu", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDAT", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Wo immer du eintratst, redete nicht in Kirchen", "tokens": ["Wo", "im\u00b7mer", "du", "ein\u00b7tratst", ",", "re\u00b7de\u00b7te", "nicht", "in", "Kir\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "VVFIN", "$,", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "zu Rom und Neapel ruhig ihr Schicksal dich an?", "tokens": ["zu", "Rom", "und", "Nea\u00b7pel", "ru\u00b7hig", "ihr", "Schick\u00b7sal", "dich", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "ADJD", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Oder es trug eine Inschrift sich erhaben dir auf,", "tokens": ["O\u00b7der", "es", "trug", "ei\u00b7ne", "In\u00b7schrift", "sich", "er\u00b7ha\u00b7ben", "dir", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PRF", "ADJD", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+---+--+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "wie neulich die Tafel in Santa Maria Formosa.", "tokens": ["wie", "neu\u00b7lich", "die", "Ta\u00b7fel", "in", "San\u00b7ta", "Ma\u00b7ria", "For\u00b7mo\u00b7sa", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "APPR", "NE", "NE", "NE", "$."], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.12": {"text": "Was sie mir wollen? leise soll ich des Unrechts", "tokens": ["Was", "sie", "mir", "wol\u00b7len", "?", "lei\u00b7se", "soll", "ich", "des", "Un\u00b7rechts"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PPER", "VMFIN", "$.", "ADJD", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Anschein abtun, der ihrer Geister", "tokens": ["An\u00b7schein", "ab\u00b7tun", ",", "der", "ih\u00b7rer", "Geis\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "$,", "PRELS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "reine Bewegung manchmal ein wenig behindert.", "tokens": ["rei\u00b7ne", "Be\u00b7we\u00b7gung", "manch\u00b7mal", "ein", "we\u00b7nig", "be\u00b7hin\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "ART", "PIS", "VVPP", "$."], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}}, "stanza.10": {"line.1": {"text": "Freilich ist es seltsam, die Erde nicht mehr zu bewohnen,", "tokens": ["Frei\u00b7lich", "ist", "es", "selt\u00b7sam", ",", "die", "Er\u00b7de", "nicht", "mehr", "zu", "be\u00b7woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "ART", "NN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "kaum erlernte Gebr\u00e4uche nicht mehr zu \u00fcben,", "tokens": ["kaum", "er\u00b7lern\u00b7te", "Ge\u00b7br\u00e4u\u00b7che", "nicht", "mehr", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Rosen, und andern eigens versprechenden Dingen", "tokens": ["Ro\u00b7sen", ",", "und", "an\u00b7dern", "ei\u00b7gens", "ver\u00b7spre\u00b7chen\u00b7den", "Din\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "KON", "PIS", "ADV", "ADJA", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "nicht die Bedeutung menschlicher Zukunft zu geben;", "tokens": ["nicht", "die", "Be\u00b7deu\u00b7tung", "menschli\u00b7cher", "Zu\u00b7kunft", "zu", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "das, was man war in unendlich \u00e4ngstlichen H\u00e4nden,", "tokens": ["das", ",", "was", "man", "war", "in", "un\u00b7end\u00b7lich", "\u00e4ngst\u00b7li\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PIS", "VAFIN", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "nicht mehr zu sein, und selbst den eigenen Namen", "tokens": ["nicht", "mehr", "zu", "sein", ",", "und", "selbst", "den", "ei\u00b7ge\u00b7nen", "Na\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "PTKZU", "VAINF", "$,", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "wegzulassen wie ein zerbrochenes Spielzeug.", "tokens": ["weg\u00b7zu\u00b7las\u00b7sen", "wie", "ein", "zer\u00b7bro\u00b7che\u00b7nes", "Spiel\u00b7zeug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Seltsam, die W\u00fcnsche nicht weiter zu w\u00fcnschen. Seltsam,", "tokens": ["Selt\u00b7sam", ",", "die", "W\u00fcn\u00b7sche", "nicht", "wei\u00b7ter", "zu", "w\u00fcn\u00b7schen", ".", "Selt\u00b7sam", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$.", "NE", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.9": {"text": "alles, was sich bezog, so lose im Raume", "tokens": ["al\u00b7les", ",", "was", "sich", "be\u00b7zog", ",", "so", "lo\u00b7se", "im", "Rau\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVFIN", "$,", "ADV", "VVFIN", "APPRART", "NN"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "flattern zu sehen. Und das Totsein ist m\u00fchsam", "tokens": ["flat\u00b7tern", "zu", "se\u00b7hen", ".", "Und", "das", "Tot\u00b7sein", "ist", "m\u00fch\u00b7sam"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVINF", "PTKZU", "VVINF", "$.", "KON", "ART", "NN", "VAFIN", "ADJD"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.11": {"text": "und voller Nachholn, da\u00df man allm\u00e4hlich ein wenig", "tokens": ["und", "vol\u00b7ler", "Nach\u00b7holn", ",", "da\u00df", "man", "all\u00b7m\u00e4h\u00b7lich", "ein", "we\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "KOUS", "PIS", "ADJD", "ART", "PIS"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Ewigkeit sp\u00fcrt. \u2013 Aber Lebendige machen", "tokens": ["E\u00b7wig\u00b7keit", "sp\u00fcrt", ".", "\u2013", "A\u00b7ber", "Le\u00b7ben\u00b7di\u00b7ge", "ma\u00b7chen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "$.", "$(", "KON", "NN", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.13": {"text": "alle den Fehler, da\u00df sie zu stark unterscheiden.", "tokens": ["al\u00b7le", "den", "Feh\u00b7ler", ",", "da\u00df", "sie", "zu", "stark", "un\u00b7ter\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "$,", "KOUS", "PPER", "PTKA", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Engel (sagt man) w\u00fc\u00dften oft nicht, ob sie unter", "tokens": ["En\u00b7gel", "(", "sagt", "man", ")", "w\u00fc\u00df\u00b7ten", "oft", "nicht", ",", "ob", "sie", "un\u00b7ter"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "PIS", "$(", "VVFIN", "ADV", "PTKNEG", "$,", "KOUS", "PPER", "APPR"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.15": {"text": "Lebenden gehn oder Toten. Die ewige Str\u00f6mung", "tokens": ["Le\u00b7ben\u00b7den", "gehn", "o\u00b7der", "To\u00b7ten", ".", "Die", "e\u00b7wi\u00b7ge", "Str\u00f6\u00b7mung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVINF", "KON", "NN", "$.", "ART", "ADJA", "NN"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.16": {"text": "rei\u00dft durch beide Bereiche alle Alter", "tokens": ["rei\u00dft", "durch", "bei\u00b7de", "Be\u00b7rei\u00b7che", "al\u00b7le", "Al\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "PIAT", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "immer mit sich und \u00fcbert\u00f6nt sie in beiden.", "tokens": ["im\u00b7mer", "mit", "sich", "und", "\u00fc\u00b7ber\u00b7t\u00f6nt", "sie", "in", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "KON", "VVFIN", "PPER", "APPR", "PIAT", "$."], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Schlie\u00dflich brauchen sie uns nicht mehr, die Fr\u00fcheentr\u00fcckten,", "tokens": ["Schlie\u00df\u00b7lich", "brau\u00b7chen", "sie", "uns", "nicht", "mehr", ",", "die", "Fr\u00fc\u00b7heen\u00b7tr\u00fcck\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "ADV", "$,", "ART", "NN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "man entw\u00f6hnt sich des Irdischen sanft, wie man den Br\u00fcsten", "tokens": ["man", "ent\u00b7w\u00f6hnt", "sich", "des", "Ir\u00b7di\u00b7schen", "sanft", ",", "wie", "man", "den", "Br\u00fcs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "ART", "NN", "ADJD", "$,", "PWAV", "PIS", "ART", "NN"], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "milde der Mutter entw\u00e4chst. Aber wir, die so gro\u00dfe", "tokens": ["mil\u00b7de", "der", "Mut\u00b7ter", "ent\u00b7w\u00e4chst", ".", "A\u00b7ber", "wir", ",", "die", "so", "gro\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$.", "KON", "PPER", "$,", "PRELS", "ADV", "ADJA"], "meter": "+--+--+---+-+-", "measure": "dactylic.tri.plus"}, "line.4": {"text": "Geheimnisse brauchen, denen aus Trauer so oft", "tokens": ["Ge\u00b7heim\u00b7nis\u00b7se", "brau\u00b7chen", ",", "de\u00b7nen", "aus", "Trau\u00b7er", "so", "oft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "$,", "PRELS", "APPR", "NN", "ADV", "ADV"], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "seliger Fortschritt entspringt \u2013: ", "tokens": ["se\u00b7li\u00b7ger", "Fort\u00b7schritt", "ent\u00b7springt", "\u2013", ":"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$(", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.6": {"text": "Ist die Sage umsonst, da\u00df einst in der Klage um Linos", "tokens": ["Ist", "die", "Sa\u00b7ge", "um\u00b7sonst", ",", "da\u00df", "einst", "in", "der", "Kla\u00b7ge", "um", "Li\u00b7nos"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "ADV", "$,", "KOUS", "ADV", "APPR", "ART", "NN", "APPR", "NE"], "meter": "--+--+-+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "wagende erste Musik d\u00fcrre Erstarrung durchdrang;", "tokens": ["wa\u00b7gen\u00b7de", "ers\u00b7te", "Mu\u00b7sik", "d\u00fcr\u00b7re", "Er\u00b7star\u00b7rung", "durch\u00b7drang", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}, "line.8": {"text": "da\u00df erst im erschrockenen Raum, dem ein beinah g\u00f6ttlicher J\u00fcngling", "tokens": ["da\u00df", "erst", "im", "er\u00b7schro\u00b7cke\u00b7nen", "Raum", ",", "dem", "ein", "bei\u00b7nah", "g\u00f6tt\u00b7li\u00b7cher", "J\u00fcng\u00b7ling"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPRART", "ADJA", "NN", "$,", "PRELS", "ART", "ADV", "ADJA", "NN"], "meter": "-+--+--+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "pl\u00f6tzlich f\u00fcr immer enttrat, das Leere in jene", "tokens": ["pl\u00f6tz\u00b7lich", "f\u00fcr", "im\u00b7mer", "ent\u00b7trat", ",", "das", "Lee\u00b7re", "in", "je\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ADV", "VVFIN", "$,", "ART", "NN", "APPR", "PDAT"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Schwingung geriet, die uns jetzt hinrei\u00dft und tr\u00f6stet und hilft.", "tokens": ["Schwin\u00b7gung", "ge\u00b7riet", ",", "die", "uns", "jetzt", "hin\u00b7rei\u00dft", "und", "tr\u00f6s\u00b7tet", "und", "hilft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}}}}}