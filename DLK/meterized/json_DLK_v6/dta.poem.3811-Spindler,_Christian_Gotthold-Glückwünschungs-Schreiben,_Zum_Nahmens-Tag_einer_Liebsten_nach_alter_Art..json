{"dta.poem.3811": {"metadata": {"author": {"name": "Spindler, Christian Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "Gl\u00fcckw\u00fcnschungs-Schreiben,  \n Zum  Nahmens-Tag  einer Liebsten/  \n nach alter Art.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1745", "urn": "urn:nbn:de:kobv:b4-20581-9", "language": ["de:0.99"], "booktitle": "Spindler, Christian Gotthold: Unschuldige Jugend-Fr\u00fcchte. Leipzig, 1745."}, "poem": {"stanza.1": {"line.1": {"text": "Du trautes Kind, dein Nahmens-Fest,", "tokens": ["Du", "trau\u00b7tes", "Kind", ",", "dein", "Nah\u00b7mens\u00b7Fest", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sich nun wieder feyren l\u00e4st,", "tokens": ["Das", "sich", "nun", "wie\u00b7der", "fey\u00b7ren", "l\u00e4st", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADV", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die\u00df giebet mir nun auch f\u00fchrwahr", "tokens": ["Die\u00df", "gie\u00b7bet", "mir", "nun", "auch", "f\u00fchr\u00b7wahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die tr\u00f6stlich fein und liebe Lahr,", "tokens": ["Die", "tr\u00f6st\u00b7lich", "fein", "und", "lie\u00b7be", "Lahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "KON", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ich schreib nun auf die\u00df Papir", "tokens": ["Da\u00df", "ich", "schreib", "nun", "auf", "die\u00df", "Pa\u00b7pir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADV", "APPR", "PDS", "NN"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Aus meines Hertzens sein Begier.", "tokens": ["Aus", "mei\u00b7nes", "Hert\u00b7zens", "sein", "Be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ich ehr dein M\u00fcndlein roth und wei\u00df", "tokens": ["Ich", "ehr", "dein", "M\u00fcnd\u00b7lein", "roth", "und", "wei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "PPOSAT", "NN", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und liebe es mit grossen Flei\u00df,", "tokens": ["Und", "lie\u00b7be", "es", "mit", "gros\u00b7sen", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ich w\u00fcnsche dir ein feines Hau\u00df,", "tokens": ["Ich", "w\u00fcn\u00b7sche", "dir", "ein", "fei\u00b7nes", "Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Uns beyde nein, und nicht heraus;", "tokens": ["Uns", "bey\u00b7de", "nein", ",", "und", "nicht", "he\u00b7raus", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "PTKANT", "$,", "KON", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und wenn ich noch was w\u00fcnschen solt,", "tokens": ["Und", "wenn", "ich", "noch", "was", "w\u00fcn\u00b7schen", "solt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "So w\u00fcnsch ich ihr sehr vieles Gold,", "tokens": ["So", "w\u00fcnsch", "ich", "ihr", "sehr", "vie\u00b7les", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Wie auch viel Silber allzumahl,", "tokens": ["Wie", "auch", "viel", "Sil\u00b7ber", "all\u00b7zu\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "O! Liebes Kind! ohn alle Quaal/", "tokens": ["O", "!", "Lie\u00b7bes", "Kind", "!", "ohn", "al\u00b7le", "Qua\u00b7al", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADJA", "NN", "$.", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Benebst von sch\u00f6nen Edelgestein", "tokens": ["Be\u00b7nebst", "von", "sch\u00f6\u00b7nen", "E\u00b7del\u00b7ge\u00b7stein"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.16": {"text": "Ein Bettgestell, uns beyde nein.", "tokens": ["Ein", "Bett\u00b7ge\u00b7stell", ",", "uns", "bey\u00b7de", "nein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "PIS", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Denn du bist mir ins Hertz gebildt", "tokens": ["Denn", "du", "bist", "mir", "ins", "Hertz", "ge\u00b7bildt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PPER", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Als wie ein Helm in einen Schild.", "tokens": ["Als", "wie", "ein", "Helm", "in", "ei\u00b7nen", "Schild", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und dieses ist auch allzu fein,", "tokens": ["Und", "die\u00b7ses", "ist", "auch", "all\u00b7zu", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "O! allersch\u00f6nstes Turtt\u00e4ublein.", "tokens": ["O", "!", "al\u00b7ler\u00b7sch\u00f6ns\u00b7tes", "Turt\u00b7t\u00e4ub\u00b7lein", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "So theil ich dir mein Hertze mit,", "tokens": ["So", "theil", "ich", "dir", "mein", "Hert\u00b7ze", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "PPER", "PPOSAT", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wie dort in jenem alten Lied:", "tokens": ["Wie", "dort", "in", "je\u00b7nem", "al\u00b7ten", "Lied", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Du solst stets meine Liebste bleib\u2019n,", "tokens": ["Du", "solst", "stets", "mei\u00b7ne", "Liebs\u00b7te", "bleib'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Bi\u00df der Wind thut Rosen treib\u2019n,", "tokens": ["Bi\u00df", "der", "Wind", "thut", "Ro\u00b7sen", "treib'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.25": {"text": "Bi\u00df eine Feder wiegt ein Pfund", "tokens": ["Bi\u00df", "ei\u00b7ne", "Fe\u00b7der", "wiegt", "ein", "Pfund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und ein Haase jagt den Hund,", "tokens": ["Und", "ein", "Haa\u00b7se", "jagt", "den", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.27": {"text": "Bi\u00df ein Krebs Baumwolle spint", "tokens": ["Bi\u00df", "ein", "Krebs", "Baum\u00b7wol\u00b7le", "spint"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN"], "meter": "+-++--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Und man Licht mit Schnee anz\u00fcnd,", "tokens": ["Und", "man", "Licht", "mit", "Schnee", "an\u00b7z\u00fcnd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "NN", "APPR", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.29": {"text": "Bi\u00df ein M\u00fchlstein schwimt \u00fcbern Rhein,", "tokens": ["Bi\u00df", "ein", "M\u00fchl\u00b7stein", "schwimt", "\u00fc\u00b7bern", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "NE", "$,"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.30": {"text": "So lang soll unsre Liebe seyn.", "tokens": ["So", "lang", "soll", "uns\u00b7re", "Lie\u00b7be", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Du nun o! klein Wald-V\u00f6gelein,", "tokens": ["Du", "nun", "o", "!", "klein", "Wald\u00b7V\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "FM", "$.", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "O! Lerch, du solst der Bothe seyn,", "tokens": ["O", "!", "Lerch", ",", "du", "solst", "der", "Bo\u00b7the", "seyn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "$,", "PPER", "VMFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "O! singe meiner Liebsten f\u00fcr,", "tokens": ["O", "!", "sin\u00b7ge", "mei\u00b7ner", "Liebs\u00b7ten", "f\u00fcr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPOSAT", "NN", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Von meiner Liebe nach Geb\u00fchr!", "tokens": ["Von", "mei\u00b7ner", "Lie\u00b7be", "nach", "Ge\u00b7b\u00fchr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Fleuch hin, komm balde wieder her,", "tokens": ["Fleuch", "hin", ",", "komm", "bal\u00b7de", "wie\u00b7der", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Und bring Antwort ohn all Beschwehr.", "tokens": ["Und", "bring", "Ant\u00b7wort", "ohn", "all", "Be\u00b7schwehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "APPR", "PIAT", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.37": {"text": "Es ist die\u00df kleine Brieffelein", "tokens": ["Es", "ist", "die\u00df", "klei\u00b7ne", "Brief\u00b7fe\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Besiegelt mit dem Hertzen mein.", "tokens": ["Be\u00b7sie\u00b7gelt", "mit", "dem", "Hert\u00b7zen", "mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Ich la\u00df dich nicht bi\u00df in das Grab,", "tokens": ["Ich", "la\u00df", "dich", "nicht", "bi\u00df", "in", "das", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.40": {"text": "Denn ist es aus, damit schab ab.", "tokens": ["Denn", "ist", "es", "aus", ",", "da\u00b7mit", "schab", "ab", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKVZ", "$,", "PAV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Ich w\u00fcnsche, da\u00df dein Nahmens-Tag", "tokens": ["Ich", "w\u00fcn\u00b7sche", ",", "da\u00df", "dein", "Nah\u00b7mens\u00b7Tag"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Sehr offt noch wieder kommen mag.", "tokens": ["Sehr", "offt", "noch", "wie\u00b7der", "kom\u00b7men", "mag."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ADV", "ADV", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Bin ich auch gleich hier ungenennt,", "tokens": ["Bin", "ich", "auch", "gleich", "hier", "un\u00b7ge\u00b7nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "So bin ich doch sehr wohl bekennt;", "tokens": ["So", "bin", "ich", "doch", "sehr", "wohl", "be\u00b7kennt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Und da ich nunmehr schliessen soll,", "tokens": ["Und", "da", "ich", "nun\u00b7mehr", "schlies\u00b7sen", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Geliebte Traute, lebe wohl.", "tokens": ["Ge\u00b7lieb\u00b7te", "Trau\u00b7te", ",", "le\u00b7be", "wohl", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}