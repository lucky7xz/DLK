{"dta.poem.2736": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Der genesene Eneas/  \n Bey Beerdigung Hn. H. H. den 31. Julii  \n 1679.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich wil hier nicht der Helden Kern", "tokens": ["Ich", "wil", "hier", "nicht", "der", "Hel\u00b7den", "Kern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den muthigen Eneas weisen/", "tokens": ["Den", "mut\u00b7hi\u00b7gen", "E\u00b7neas", "wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Den als des Vaterlandes Stern", "tokens": ["Den", "als", "des", "Va\u00b7ter\u00b7lan\u00b7des", "Stern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Beyspiel die Geschichte preisen/", "tokens": ["Und", "Bey\u00b7spiel", "die", "Ge\u00b7schich\u00b7te", "prei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn er den abgelebten Alten", "tokens": ["Wenn", "er", "den", "ab\u00b7ge\u00b7leb\u00b7ten", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den Vater auff die Schultern legt", "tokens": ["Den", "Va\u00b7ter", "auff", "die", "Schul\u00b7tern", "legt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und mitten durch die Flammen tr\u00e4gt/", "tokens": ["Und", "mit\u00b7ten", "durch", "die", "Flam\u00b7men", "tr\u00e4gt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Umb so sein Leben zu erhalten.", "tokens": ["Umb", "so", "sein", "Le\u00b7ben", "zu", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Betr\u00fcbtste/ diese Kindes-Pflicht", "tokens": ["Be\u00b7tr\u00b7\u00fcbts\u00b7te", "/", "die\u00b7se", "Kin\u00b7des\u00b7Pflicht"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$(", "PDAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Treu w\u00e4r auch an euch erschienen/", "tokens": ["Und", "Treu", "w\u00e4r", "auch", "an", "euch", "er\u00b7schie\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVINF", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wenn damit etwas ausgericht/", "tokens": ["Wenn", "da\u00b7mit", "et\u00b7was", "aus\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PAV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und es dem Vater m\u00f6gen dienen.", "tokens": ["Und", "es", "dem", "Va\u00b7ter", "m\u00f6\u00b7gen", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jhr h\u00e4ttet ihn von seinen Ketten", "tokens": ["Ihr", "h\u00e4t\u00b7tet", "ihn", "von", "sei\u00b7nen", "Ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und Banden gerne frey gemacht/", "tokens": ["Und", "Ban\u00b7den", "ger\u00b7ne", "frey", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ja alle Mittel ausgedacht/", "tokens": ["Ja", "al\u00b7le", "Mit\u00b7tel", "aus\u00b7ge\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ob Menschen H\u00fclffe k\u00f6nte retten.", "tokens": ["Ob", "Men\u00b7schen", "H\u00fclf\u00b7fe", "k\u00f6n\u00b7te", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Allein hier galt noch Kunst noch Cur/", "tokens": ["Al\u00b7lein", "hier", "galt", "noch", "Kunst", "noch", "Cur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "NN", "ADV", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch des Eneas Witz und St\u00e4rcke/", "tokens": ["Noch", "des", "E\u00b7neas", "Witz", "und", "St\u00e4r\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Es leitet uns des Glaubens Spur", "tokens": ["Es", "lei\u00b7tet", "uns", "des", "Glau\u00b7bens", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auff des Eneas Wunderwercke/", "tokens": ["Auff", "des", "E\u00b7neas", "Wun\u00b7der\u00b7wer\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der acht Jahr unbeweglich ligen", "tokens": ["Der", "acht", "Jahr", "un\u00b7be\u00b7weg\u00b7lich", "li\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In seinen h\u00f6chsten Schmertzen mu\u00df/", "tokens": ["In", "sei\u00b7nen", "h\u00f6chs\u00b7ten", "Schmert\u00b7zen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Zu dem aus Eckel und Verdru\u00df", "tokens": ["Zu", "dem", "aus", "E\u00b7ckel", "und", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich ferner wil kein Artzt verf\u00fcgen.", "tokens": ["Sich", "fer\u00b7ner", "wil", "kein", "Artzt", "ver\u00b7f\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein Wort das des Apostels Mund", "tokens": ["Ein", "Wort", "das", "des", "A\u00b7pos\u00b7tels", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ART", "NN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Vom Himmel abgeschickt gesprochen:", "tokens": ["Vom", "Him\u00b7mel", "ab\u00b7ge\u00b7schickt", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dein JEsus mache dich gesund/", "tokens": ["Dein", "Je\u00b7sus", "ma\u00b7che", "dich", "ge\u00b7sund", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das hat der Kranckheit Weh\u2019 gebrochen.", "tokens": ["Das", "hat", "der", "Kran\u00b7ck\u00b7heit", "Weh'", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Steh\u2019 auff und geh\u2019 aus deinem Bette/", "tokens": ["Steh'", "auff", "und", "geh'", "aus", "dei\u00b7nem", "Bet\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Heiland gibt dir neue Krafft/", "tokens": ["Dein", "Hei\u00b7land", "gibt", "dir", "neu\u00b7e", "Krafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das Ubel ist gantz weggeschafft/", "tokens": ["Das", "U\u00b7bel", "ist", "gantz", "weg\u00b7ge\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Eneas mercke wer dich rette!", "tokens": ["E\u00b7neas", "mer\u00b7cke", "wer", "dich", "ret\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Mu\u00df nicht Machaon und Galen", "tokens": ["Mu\u00df", "nicht", "Ma\u00b7cha\u00b7on", "und", "Ga\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und Theophrast hier schamroth werden/", "tokens": ["Und", "Theo\u00b7ph\u00b7rast", "hier", "scham\u00b7roth", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Wort heist den Eneas gehn/", "tokens": ["Ein", "Wort", "heist", "den", "E\u00b7neas", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$("], "meter": "+++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Ein Wort benimmt ihn der Beschwerden.", "tokens": ["Ein", "Wort", "be\u00b7nimmt", "ihn", "der", "Be\u00b7schwer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie freudig sieht er seinen Glauben", "tokens": ["Wie", "freu\u00b7dig", "sieht", "er", "sei\u00b7nen", "Glau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch Hoffen und Gedult bew\u00e4hrt", "tokens": ["Durch", "Hof\u00b7fen", "und", "Ge\u00b7dult", "be\u00b7w\u00e4hrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ihm nun H\u00fclffe wiederf\u00e4hrt/", "tokens": ["Da\u00df", "ihm", "nun", "H\u00fclf\u00b7fe", "wie\u00b7der\u00b7f\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und niemand diesen Trost kan rauben.", "tokens": ["Und", "nie\u00b7mand", "die\u00b7sen", "Trost", "kan", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PDAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Betr\u00fcbtste/ solt' euch dieses nicht", "tokens": ["Be\u00b7tr\u00b7\u00fcbts\u00b7te", "/", "solt'", "euch", "die\u00b7ses", "nicht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$(", "VMFIN", "PPER", "PDS", "PTKNEG"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein kr\u00e4fftig Lehr-Exempel geben:", "tokens": ["Ein", "kr\u00e4ff\u00b7tig", "Lehr\u00b7Exem\u00b7pel", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie war der Vater zugericht?", "tokens": ["Wie", "war", "der", "Va\u00b7ter", "zu\u00b7ge\u00b7richt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie abgemergelt schien sein Leben?", "tokens": ["Wie", "ab\u00b7ge\u00b7mer\u00b7gelt", "schien", "sein", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie h\u00e4uffte sich die Qual der Schmertzen?", "tokens": ["Wie", "h\u00e4uff\u00b7te", "sich", "die", "Qual", "der", "Schmert\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "War er ohn Thr\u00e4nen anzuschau\u2019n?", "tokens": ["War", "er", "ohn", "Thr\u00e4\u00b7nen", "an\u00b7zu\u00b7schau'n", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Must ihm nicht f\u00fcr sich selbsten grau\u2019n?", "tokens": ["Must", "ihm", "nicht", "f\u00fcr", "sich", "selbs\u00b7ten", "grau'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und bluteten nicht eure Hertzen?", "tokens": ["Und", "blu\u00b7te\u00b7ten", "nicht", "eu\u00b7re", "Hert\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich glaube wer im Kercker sitzt/", "tokens": ["Ich", "glau\u00b7be", "wer", "im", "Ker\u00b7cker", "sitzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und st\u00fcndlich soll sein Urtheil h\u00f6ren/", "tokens": ["Und", "st\u00fcnd\u00b7lich", "soll", "sein", "Ur\u00b7theil", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df der in solcher Angst nicht schwitzt/", "tokens": ["Da\u00df", "der", "in", "sol\u00b7cher", "Angst", "nicht", "schwitzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "PIAT", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als durch Gebeine/ Marck und R\u00f6hren", "tokens": ["Als", "durch", "Ge\u00b7bei\u00b7ne", "/", "Marck", "und", "R\u00f6h\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dem liebsten Vater es gedrungen/", "tokens": ["Dem", "liebs\u00b7ten", "Va\u00b7ter", "es", "ge\u00b7drun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er den letzten Zuspruch nicht/", "tokens": ["Da\u00df", "er", "den", "letz\u00b7ten", "Zu\u00b7spruch", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Durch Worte mehr an euch verricht", "tokens": ["Durch", "Wor\u00b7te", "mehr", "an", "euch", "ver\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil ihm gehemmt das Band der Zungen.", "tokens": ["Weil", "ihm", "ge\u00b7hemmt", "das", "Band", "der", "Zun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch druckt er tausend Seuffzer lo\u00df/", "tokens": ["Doch", "druckt", "er", "tau\u00b7send", "Seuff\u00b7zer", "lo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat in Himmel sich geschwungen/", "tokens": ["Und", "hat", "in", "Him\u00b7mel", "sich", "ge\u00b7schwun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Glaube wuchs und wurde gro\u00df/", "tokens": ["Sein", "Glau\u00b7be", "wuchs", "und", "wur\u00b7de", "gro\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Je mehr die Schmertzen ihn besprungen/", "tokens": ["Je", "mehr", "die", "Schmert\u00b7zen", "ihn", "be\u00b7sprun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie peinlich auch die Niederlage/", "tokens": ["Wie", "pein\u00b7lich", "auch", "die", "Nie\u00b7der\u00b7la\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So hofft\u2019 er auff des H Erren Mund", "tokens": ["So", "hofft'", "er", "auff", "des", "H", "Er\u00b7ren", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "Der sprechen w\u00fcrde: ", "tokens": ["Der", "spre\u00b7chen", "w\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VAFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und Franck und frey von aller Plage.", "tokens": ["Und", "Franck", "und", "frey", "von", "al\u00b7ler", "Pla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sein Glaube hat auch nicht gefehlt", "tokens": ["Sein", "Glau\u00b7be", "hat", "auch", "nicht", "ge\u00b7fehlt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er ist geheilt in dessen Namen/", "tokens": ["Er", "ist", "ge\u00b7heilt", "in", "des\u00b7sen", "Na\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "PRELAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der unsre Jahre schon gezehlt/", "tokens": ["Der", "uns\u00b7re", "Jah\u00b7re", "schon", "ge\u00b7zehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Eh\u2019 als wir auff den Welt-Krei\u00df kamen.", "tokens": ["Eh'", "als", "wir", "auff", "den", "Welt\u00b7Krei\u00df", "ka\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jetzt geht er nun in seine Kammer/", "tokens": ["Jetzt", "geht", "er", "nun", "in", "sei\u00b7ne", "Kam\u00b7mer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und schleust die Th\u00fcre nach sich zu/", "tokens": ["Und", "schleust", "die", "Th\u00fc\u00b7re", "nach", "sich", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PRF", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Geneust der ungest\u00f6rten Ruh", "tokens": ["Ge\u00b7neust", "der", "un\u00b7ge\u00b7st\u00f6r\u00b7ten", "Ruh"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und wei\u00df nicht mehr von Noth und Jammer.", "tokens": ["Und", "wei\u00df", "nicht", "mehr", "von", "Noth", "und", "Jam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Eneas mag aus Kindes-Pflicht", "tokens": ["E\u00b7neas", "mag", "aus", "Kin\u00b7des\u00b7Pflicht"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Den alt und schwachen Vater tragen:", "tokens": ["Den", "alt", "und", "schwa\u00b7chen", "Va\u00b7ter", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wir wollen von dem Glaubens-Licht", "tokens": ["Wir", "wol\u00b7len", "von", "dem", "Glau\u00b7bens\u00b7Licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und des Eneas Hoffen sagen:", "tokens": ["Und", "des", "E\u00b7neas", "Hof\u00b7fen", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer sich auff JEsum hat gegr\u00fcndet", "tokens": ["Wer", "sich", "auff", "Je\u00b7sum", "hat", "ge\u00b7gr\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "APPR", "NE", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der wird an Leib und Seele heil:", "tokens": ["Der", "wird", "an", "Leib", "und", "See\u00b7le", "heil", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gewi\u00df da\u00df auch dergleichen Theil", "tokens": ["Ge\u00b7wi\u00df", "da\u00df", "auch", "derg\u00b7lei\u00b7chen", "Theil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ADV", "PIS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Herr Henisch in dem Grabe findet.", "tokens": ["Herr", "He\u00b7nisch", "in", "dem", "Gra\u00b7be", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Er hat so lang es GOtt verliehn", "tokens": ["Er", "hat", "so", "lang", "es", "Gott", "ver\u00b7liehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PPER", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr eure Wolfahrt stets gewachet/", "tokens": ["F\u00fcr", "eu\u00b7re", "Wol\u00b7fahrt", "stets", "ge\u00b7wa\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Viel rauhe Wege m\u00fcssen ziehn/", "tokens": ["Viel", "rau\u00b7he", "We\u00b7ge", "m\u00fcs\u00b7sen", "ziehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn Krieg und Raub ihm Furcht gemachet.", "tokens": ["Wenn", "Krieg", "und", "Raub", "ihm", "Furcht", "ge\u00b7ma\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nun aber ruhet er in Frieden/", "tokens": ["Nun", "a\u00b7ber", "ru\u00b7het", "er", "in", "Frie\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Di\u00df was verwesen soll und kan/", "tokens": ["Di\u00df", "was", "ver\u00b7we\u00b7sen", "soll", "und", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVINF", "VMFIN", "KON", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ist nur von ihm hinweg gethan/", "tokens": ["Ist", "nur", "von", "ihm", "hin\u00b7weg", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "APZR", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sonst ist er von euch ungeschieden.", "tokens": ["Sonst", "ist", "er", "von", "euch", "un\u00b7ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Je mehr ihr seine Vater-Treu", "tokens": ["Je", "mehr", "ihr", "sei\u00b7ne", "Va\u00b7ter\u00b7Treu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sein Ged\u00e4chtn\u00fc\u00df werdet ehren/", "tokens": ["Und", "sein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "wer\u00b7det", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Je mehr legt ihr euch Seegen bey/", "tokens": ["Je", "mehr", "legt", "ihr", "euch", "See\u00b7gen", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "NN", "APPR", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und k\u00f6nnt Eneas Lobspruch h\u00f6ren.", "tokens": ["Und", "k\u00f6nnt", "E\u00b7neas", "Lob\u00b7spruch", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "NN", "VVINF", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.5": {"text": "Eneas aber Heilung f\u00fchlet", "tokens": ["E\u00b7neas", "a\u00b7ber", "Hei\u00b7lung", "f\u00fch\u00b7let"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Der Vater/ der numehr gesund/", "tokens": ["Der", "Va\u00b7ter", "/", "der", "nu\u00b7mehr", "ge\u00b7sund", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der/ ob zwar mit verschlo\u00dfnem Mund", "tokens": ["Der", "/", "ob", "zwar", "mit", "ver\u00b7schlo\u00df\u00b7nem", "Mund"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "$(", "KOUS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Jhm doch das beste Theil erzielet.", "tokens": ["Jhm", "doch", "das", "bes\u00b7te", "Theil", "er\u00b7zie\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}