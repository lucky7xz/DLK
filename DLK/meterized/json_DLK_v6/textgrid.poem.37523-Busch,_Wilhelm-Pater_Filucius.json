{"textgrid.poem.37523": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Pater Filucius", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00f6chst erfreulich und belehrend", "tokens": ["H\u00f6chst", "er\u00b7freu\u00b7lich", "und", "be\u00b7leh\u00b7rend"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist es doch f\u00fcr jedermann,", "tokens": ["Ist", "es", "doch", "f\u00fcr", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PIS", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn er allerlei Geschichten", "tokens": ["Wenn", "er", "al\u00b7ler\u00b7lei", "Ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lesen oder h\u00f6ren kann.", "tokens": ["Le\u00b7sen", "o\u00b7der", "h\u00f6\u00b7ren", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "So zum Beispiel die Geschichte", "tokens": ["So", "zum", "Bei\u00b7spiel", "die", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem Gottlieb Michael,", "tokens": ["Von", "dem", "Gott\u00b7lieb", "Mic\u00b7hael", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der bis dato sich beholfen", "tokens": ["Der", "bis", "da\u00b7to", "sich", "be\u00b7hol\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NE", "PRF", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So lala als Junggesell.", "tokens": ["So", "la\u00b7la", "als", "Jung\u00b7ge\u00b7sell", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KOUS", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Zwo bejahrte fromme Tanten", "tokens": ["Zwo", "be\u00b7jahr\u00b7te", "from\u00b7me", "Tan\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lenken seinen Hausbestand;", "tokens": ["Len\u00b7ken", "sei\u00b7nen", "Haus\u00b7be\u00b7stand", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und Petrine und Pauline", "tokens": ["Und", "Pet\u00b7ri\u00b7ne", "und", "Pau\u00b7li\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "NE"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.4": {"text": "Werden diese zwo benannt.", "tokens": ["Wer\u00b7den", "die\u00b7se", "zwo", "be\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "CARD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Au\u00dferdem, mu\u00df ich bemerken,", "tokens": ["Au\u00b7\u00dfer\u00b7dem", ",", "mu\u00df", "ich", "be\u00b7mer\u00b7ken", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist noch eine Base da,", "tokens": ["Ist", "noch", "ei\u00b7ne", "Ba\u00b7se", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00fcbsch gestaltet, kluggelehrig,", "tokens": ["H\u00fcbsch", "ge\u00b7stal\u00b7tet", ",", "klug\u00b7ge\u00b7leh\u00b7rig", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "N\u00e4mlich die Angelika.", "tokens": ["N\u00e4m\u00b7lich", "die", "An\u00b7ge\u00b7li\u00b7ka", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Wo viel zarte H\u00e4nde walten \u2013", "tokens": ["Wo", "viel", "zar\u00b7te", "H\u00e4n\u00b7de", "wal\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Na, das ist so wie es ist!", "tokens": ["Na", ",", "das", "ist", "so", "wie", "es", "ist", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PDS", "VAFIN", "ADV", "KOKOM", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kellerschl\u00fcssel, Bodenschl\u00fcssel", "tokens": ["Kel\u00b7ler\u00b7schl\u00fcs\u00b7sel", ",", "Bo\u00b7den\u00b7schl\u00fcs\u00b7sel"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchren leicht zu Zank und Zwist.", "tokens": ["F\u00fch\u00b7ren", "leicht", "zu", "Zank", "und", "Zwist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ebenso in Kochgeschichten", "tokens": ["E\u00b7ben\u00b7so", "in", "Koch\u00b7ge\u00b7schich\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einigt man sich \u00f6fters schwer.", "tokens": ["Ei\u00b7nigt", "man", "sich", "\u00f6f\u00b7ters", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gottlieb k\u00f6nnte lange warten,", "tokens": ["Gott\u00b7lieb", "k\u00f6nn\u00b7te", "lan\u00b7ge", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn Angelika nicht w\u00e4r.", "tokens": ["Wenn", "An\u00b7ge\u00b7li\u00b7ka", "nicht", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PTKNEG", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie besorgt die Abendsuppe", "tokens": ["Sie", "be\u00b7sorgt", "die", "A\u00b7bend\u00b7sup\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Still und sorgsam und geschwind;", "tokens": ["Still", "und", "sorg\u00b7sam", "und", "ge\u00b7schwind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gottlieb zwickt sie in die Backe:", "tokens": ["Gott\u00b7lieb", "zwickt", "sie", "in", "die", "Ba\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u00bbdanke sehr, mein gutes Kind!\u00ab", "tokens": ["\u00bb", "dan\u00b7ke", "sehr", ",", "mein", "gu\u00b7tes", "Kind", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Grimmig schauen itzt die Tanten", "tokens": ["Grim\u00b7mig", "schau\u00b7en", "itzt", "die", "Tan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses liebe M\u00e4dchen an:", "tokens": ["Die\u00b7ses", "lie\u00b7be", "M\u00e4d\u00b7chen", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbei, was mu\u00df man da bemerken?", "tokens": ["\u00bb", "ei", ",", "was", "mu\u00df", "man", "da", "be\u00b7mer\u00b7ken", "?"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PWS", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das tut ja wie Frau und Mann!\u00ab", "tokens": ["Das", "tut", "ja", "wie", "Frau", "und", "Mann", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ADV", "KOKOM", "NN", "KON", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Dennoch und trotz allediesem", "tokens": ["Den\u00b7noch", "und", "trotz", "al\u00b7le\u00b7die\u00b7sem"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "KON", "APPR", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Geht die Wirtschaft doch so so. \u2013", "tokens": ["Geht", "die", "Wirt\u00b7schaft", "doch", "so", "so", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADV", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber aber, aber aber", "tokens": ["A\u00b7ber", "a\u00b7ber", ",", "a\u00b7ber", "a\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$,", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jetzt kommt der Filuzio.", "tokens": ["Jetzt", "kommt", "der", "Fi\u00b7lu\u00b7zio", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "N\u00e4mlich dieser Jesuiter", "tokens": ["N\u00e4m\u00b7lich", "die\u00b7ser", "Je\u00b7su\u00b7i\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Merkt schon l\u00e4ngst mit Geldbegier", "tokens": ["Merkt", "schon", "l\u00e4ngst", "mit", "Geld\u00b7be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf den Gottlieb sein Verm\u00f6gen,", "tokens": ["Auf", "den", "Gott\u00b7lieb", "sein", "Ver\u00b7m\u00f6\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denkend: \u00bbAch, wo krieg ich dir?\u00ab", "tokens": ["Den\u00b7kend", ":", "\u00bb", "Ach", ",", "wo", "krieg", "ich", "dir", "?", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$.", "$(", "ITJ", "$,", "PWAV", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Allererst pirscht er sich leise", "tokens": ["Al\u00b7le\u00b7rerst", "pirscht", "er", "sich", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinter die Angelika,", "tokens": ["Hin\u00b7ter", "die", "An\u00b7ge\u00b7li\u00b7ka", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Die er \u00c4pfelmus bereitend", "tokens": ["Die", "er", "\u00c4p\u00b7fel\u00b7mus", "be\u00b7rei\u00b7tend"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An dem Herde stehen sah.", "tokens": ["An", "dem", "Her\u00b7de", "ste\u00b7hen", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und er spricht mit Vaterstimme:", "tokens": ["Und", "er", "spricht", "mit", "Va\u00b7ter\u00b7stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbmeine Tochter, Gott zum Gru\u00df!\u00ab", "tokens": ["\u00bb", "mei\u00b7ne", "Toch\u00b7ter", ",", "Gott", "zum", "Gru\u00df", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "NN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlapp! da hat er im Gesichte", "tokens": ["Schlapp", "!", "da", "hat", "er", "im", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$.", "ADV", "VAFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Schleef voll Appelmus.", "tokens": ["Ei\u00b7nen", "Schleef", "voll", "Ap\u00b7pel\u00b7mus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Dieses pl\u00f6tzliche Ereignis", "tokens": ["Die\u00b7ses", "pl\u00f6tz\u00b7li\u00b7che", "Er\u00b7eig\u00b7nis"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut ihm in der Seele leid. \u2013", "tokens": ["Tut", "ihm", "in", "der", "See\u00b7le", "leid", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, man will auch hier schon wieder", "tokens": ["Ach", ",", "man", "will", "auch", "hier", "schon", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so wie die Geistlichkeit!! \u2013", "tokens": ["Nicht", "so", "wie", "die", "Geist\u00b7lich\u00b7keit", "!!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Doch die gute Tante Trine", "tokens": ["Doch", "die", "gu\u00b7te", "Tan\u00b7te", "Tri\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sehnt sich ja so lange schon", "tokens": ["Sehnt", "sich", "ja", "so", "lan\u00b7ge", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nach dem Troste einer frommen,", "tokens": ["Nach", "dem", "Tros\u00b7te", "ei\u00b7ner", "from\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Klerikalen Mannsperson. \u2013", "tokens": ["Kle\u00b7ri\u00b7ka\u00b7len", "Manns\u00b7per\u00b7son", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Da ist eher was zu machen. \u2013", "tokens": ["Da", "ist", "e\u00b7her", "was", "zu", "ma\u00b7chen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "PTKZU", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Luzi macht sich lieb und wert,", "tokens": ["Lu\u00b7zi", "macht", "sich", "lieb", "und", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er ihr als Angebinde", "tokens": ["Weil", "er", "ihr", "als", "An\u00b7ge\u00b7bin\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schrupp, den kleinen Hund, beschert.", "tokens": ["Schrupp", ",", "den", "klei\u00b7nen", "Hund", ",", "be\u00b7schert", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Schrupp ist wirklich auch possierlich.", "tokens": ["Schrupp", "ist", "wirk\u00b7lich", "auch", "pos\u00b7sier\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er gehorchet auf das Wort,", "tokens": ["Er", "ge\u00b7hor\u00b7chet", "auf", "das", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Holt herbei, was ihm befohlen,", "tokens": ["Holt", "her\u00b7bei", ",", "was", "ihm", "be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn es hei\u00dfet: \u00bbSchrupp, apport!\u00ab", "tokens": ["Wenn", "es", "hei\u00b7\u00dfet", ":", "\u00bb", "Schrupp", ",", "ap\u00b7port", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "$(", "NE", "$,", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Hei\u00dft es: \u00bbLiebes Schrupperl, singe!\u00ab", "tokens": ["Hei\u00dft", "es", ":", "\u00bb", "Lie\u00b7bes", "Schrup\u00b7perl", ",", "sin\u00b7ge", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "ADJA", "NN", "$,", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00e4ngt er sch\u00f6n zu singen an;", "tokens": ["F\u00e4ngt", "er", "sch\u00f6n", "zu", "sin\u00b7gen", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Spielt man etwas auf der Fl\u00f6te,", "tokens": ["Spielt", "man", "et\u00b7was", "auf", "der", "Fl\u00f6\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hupft er, was er hupfen kann.", "tokens": ["Hupft", "er", ",", "was", "er", "hup\u00b7fen", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Wenn es hei\u00dfet: \u00bbWo ist 's Ketzerl?\u00ab", "tokens": ["Wenn", "es", "hei\u00b7\u00dfet", ":", "\u00bb", "Wo", "ist", "'s", "Ket\u00b7zerl", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "$(", "PWAV", "VAFIN", "PPER", "NN", "$.", "$("], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Wird er wie ein Borstentier;", "tokens": ["Wird", "er", "wie", "ein", "Bors\u00b7ten\u00b7tier", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und vor seinem Knurren eilet", "tokens": ["Und", "vor", "sei\u00b7nem", "Knur\u00b7ren", "ei\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tante Line aus der T\u00fcr.", "tokens": ["Tan\u00b7te", "Li\u00b7ne", "aus", "der", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Spricht man aber diese Worte:", "tokens": ["Spricht", "man", "a\u00b7ber", "die\u00b7se", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00bbschrupp, was tun die sch\u00f6nen Herrn?\u00ab", "tokens": ["\u00bb", "schrupp", ",", "was", "tun", "die", "sch\u00f6\u00b7nen", "Herrn", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "PWS", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Gleich k\u00fc\u00dft er die Tante Trine,", "tokens": ["Gleich", "k\u00fc\u00dft", "er", "die", "Tan\u00b7te", "Tri\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Und sie lacht und hat es gern.", "tokens": ["Und", "sie", "lacht", "und", "hat", "es", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "KON", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Eines nur erzeugt Bedenken.", "tokens": ["Ei\u00b7nes", "nur", "er\u00b7zeugt", "Be\u00b7den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVPP", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schrupp entwickelt letzterzeit", "tokens": ["Schrupp", "ent\u00b7wi\u00b7ckelt", "letz\u00b7ter\u00b7zeit"], "token_info": ["word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem Hinterfu\u00dfe eine", "tokens": ["Mit", "dem", "Hin\u00b7ter\u00b7fu\u00b7\u00dfe", "ei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Merkliche Gesch\u00e4ftigkeit.", "tokens": ["Merk\u00b7li\u00b7che", "Ge\u00b7sch\u00e4f\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Mancher hat in diesen Dingen", "tokens": ["Man\u00b7cher", "hat", "in", "die\u00b7sen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine gl\u00fcckliche Natur.", "tokens": ["Ei\u00b7ne", "gl\u00fcck\u00b7li\u00b7che", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tante Trine, zum Exempel,", "tokens": ["Tan\u00b7te", "Tri\u00b7ne", ",", "zum", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "F\u00fchlt von allem keine Spur,", "tokens": ["F\u00fchlt", "von", "al\u00b7lem", "kei\u00b7ne", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIS", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Wohingegen Tante Line", "tokens": ["Wo\u00b7hin\u00b7ge\u00b7gen", "Tan\u00b7te", "Li\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "NN", "NE"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Keine rechte Ruh genie\u00dft,", "tokens": ["Kei\u00b7ne", "rech\u00b7te", "Ruh", "ge\u00b7nie\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Wenn sie abends, wie gew\u00f6hnlich,", "tokens": ["Wenn", "sie", "a\u00b7bends", ",", "wie", "ge\u00b7w\u00f6hn\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "PWAV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Hauspostille liest.", "tokens": ["In", "der", "Haus\u00b7pos\u00b7til\u00b7le", "liest", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Und auch Gottlieb mu\u00df versp\u00fcren,", "tokens": ["Und", "auch", "Gott\u00b7lieb", "mu\u00df", "ver\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "VMFIN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ganz besonders in der Nacht,", "tokens": ["Ganz", "be\u00b7son\u00b7ders", "in", "der", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Da\u00df es hier", "tokens": ["Da\u00df", "es", "hier"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.27": {"line.1": {"text": "und da", "tokens": ["und", "da"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "-+", "measure": "iambic.single"}}, "stanza.28": {"line.1": {"text": "und dorten", "tokens": ["und", "dor\u00b7ten"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Immer kribbelkrabbel macht.", "tokens": ["Im\u00b7mer", "krib\u00b7bel\u00b7krab\u00b7bel", "macht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Prickeln ist zwar auch zuwider,", "tokens": ["Pri\u00b7ckeln", "ist", "zwar", "auch", "zu\u00b7wi\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch zumeist die Jagderei;", "tokens": ["Doch", "zu\u00b7meist", "die", "Jag\u00b7de\u00b7rei", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit Recht soll man bedenken,", "tokens": ["Und", "mit", "Recht", "soll", "man", "be\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie dies zu verhindern sei.", "tokens": ["Wie", "dies", "zu", "ver\u00b7hin\u00b7dern", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.30": {"line.1": {"text": "Mancher liebt das Exmittieren;", "tokens": ["Man\u00b7cher", "liebt", "das", "Ex\u00b7mit\u00b7tie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Sache geht ja auch.", "tokens": ["Und", "die", "Sa\u00b7che", "geht", "ja", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber sicher und am besten \u2013", "tokens": ["A\u00b7ber", "si\u00b7cher", "und", "am", "bes\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "PTKA", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Knacks! \u2013 ist doch der alte Brauch.", "tokens": ["Knacks", "!", "\u2013", "ist", "doch", "der", "al\u00b7te", "Brauch", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Freilich ist hier gar kein Ende.", "tokens": ["Frei\u00b7lich", "ist", "hier", "gar", "kein", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Man gelanget nicht zum Ziel.", "tokens": ["Man", "ge\u00b7lan\u00b7get", "nicht", "zum", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Jeder ruft: \u00bbWie ist es m\u00f6glich?\u00ab", "tokens": ["Je\u00b7der", "ruft", ":", "\u00bb", "Wie", "ist", "es", "m\u00f6g\u00b7lich", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "$.", "$(", "PWAV", "VAFIN", "PPER", "ADJD", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis man auf den Schrupp verfiel.", "tokens": ["Bis", "man", "auf", "den", "Schrupp", "ver\u00b7fiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Zwar die Tante und Filuzi", "tokens": ["Zwar", "die", "Tan\u00b7te", "und", "Fi\u00b7lu\u00b7zi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Rufen beide tief gekr\u00e4nkt:", "tokens": ["Ru\u00b7fen", "bei\u00b7de", "tief", "ge\u00b7kr\u00e4nkt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbengelrein ist sein Gefieder!\u00ab \u2013", "tokens": ["\u00bb", "en\u00b7gel\u00b7rein", "ist", "sein", "Ge\u00b7fie\u00b7der", "!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber Schrupp wird eingezw\u00e4ngt.", "tokens": ["A\u00b7ber", "Schrupp", "wird", "ein\u00b7ge\u00b7zw\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "In ein Fa\u00df voll Tobakslauge", "tokens": ["In", "ein", "Fa\u00df", "voll", "To\u00b7baks\u00b7lau\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tunkt man ihn mit Haut und Haar,", "tokens": ["Tunkt", "man", "ihn", "mit", "Haut", "und", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Ob er gleich sich heftig str\u00e4ubte", "tokens": ["Ob", "er", "gleich", "sich", "hef\u00b7tig", "str\u00e4ub\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PRF", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und durchaus dagegen war.", "tokens": ["Und", "durc\u00b7haus", "da\u00b7ge\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PAV", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.35": {"line.1": {"text": "Drauf so wird in einem Stalle", "tokens": ["Drauf", "so", "wird", "in", "ei\u00b7nem", "Stal\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er mit Vorsicht interniert,", "tokens": ["Er", "mit", "Vor\u00b7sicht", "in\u00b7ter\u00b7niert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bis, was man zu tadeln findet,", "tokens": ["Bis", ",", "was", "man", "zu", "ta\u00b7deln", "fin\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PRELS", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So allm\u00e4hlich sich verliert.", "tokens": ["So", "all\u00b7m\u00e4h\u00b7lich", "sich", "ver\u00b7liert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.36": {"line.1": {"text": "Anderseits bemerkt man dieses", "tokens": ["An\u00b7der\u00b7seits", "be\u00b7merkt", "man", "die\u00b7ses"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unter gro\u00dfem Herzeleid.", "tokens": ["Un\u00b7ter", "gro\u00b7\u00dfem", "Her\u00b7ze\u00b7leid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, man will auch hier schon wieder", "tokens": ["Ach", ",", "man", "will", "auch", "hier", "schon", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so wie die Geistlichkeit!!", "tokens": ["Nicht", "so", "wie", "die", "Geist\u00b7lich\u00b7keit", "!!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jetzt w\u00e4r alles gut gewesen,", "tokens": ["Jetzt", "w\u00e4r", "al\u00b7les", "gut", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00e4re Schrupp kein B\u00f6sewicht. \u2013", "tokens": ["W\u00e4\u00b7re", "Schrupp", "kein", "B\u00f6\u00b7se\u00b7wicht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NE", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Er gew\u00f6hnt sich an das Kauen,", "tokens": ["Er", "ge\u00b7w\u00f6hnt", "sich", "an", "das", "Kau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und das l\u00e4\u00dft und l\u00e4\u00dft er nicht.", "tokens": ["Und", "das", "l\u00e4\u00dft", "und", "l\u00e4\u00dft", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "KON", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Hat er Gottlieb seine Stiefel", "tokens": ["Hat", "er", "Gott\u00b7lieb", "sei\u00b7ne", "Stie\u00b7fel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "PPOSAT", "NN"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Nicht zur H\u00e4lfte aufgezehrt?", "tokens": ["Nicht", "zur", "H\u00e4lf\u00b7te", "auf\u00b7ge\u00b7zehrt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Tante Linens Hauspostille,", "tokens": ["Tan\u00b7te", "Li\u00b7nens", "Haus\u00b7pos\u00b7til\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat er die nicht auch zerst\u00f6rt?", "tokens": ["Hat", "er", "die", "nicht", "auch", "zer\u00b7st\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "PTKNEG", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Zwar die Tante und Filuzi", "tokens": ["Zwar", "die", "Tan\u00b7te", "und", "Fi\u00b7lu\u00b7zi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Blicken mitleidsvoll empor:", "tokens": ["Bli\u00b7cken", "mit\u00b7le\u00b7ids\u00b7voll", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "\u00bbarmes gutes Schruppuppupperl!", "tokens": ["\u00bb", "ar\u00b7mes", "gu\u00b7tes", "Schrup\u00b7pup\u00b7pup\u00b7perl", "!"], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer haben sie was vor!!\u00ab", "tokens": ["Im\u00b7mer", "ha\u00b7ben", "sie", "was", "vor", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Ja, es lie\u00dfe sich ertragen,", "tokens": ["Ja", ",", "es", "lie\u00b7\u00dfe", "sich", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4te Schrupp nur dieses blo\u00df;", "tokens": ["T\u00e4\u00b7te", "Schrupp", "nur", "die\u00b7ses", "blo\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "PDAT", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcrde Schrupp nicht augenscheinlich", "tokens": ["W\u00fcr\u00b7de", "Schrupp", "nicht", "au\u00b7gen\u00b7schein\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKNEG", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Scham- und ruch- und r\u00fccksichtslos.", "tokens": ["Scham", "und", "ruch", "und", "r\u00fcck\u00b7sichts\u00b7los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "TRUNC", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Und so mu\u00df er denn empfinden,", "tokens": ["Und", "so", "mu\u00df", "er", "denn", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df zuletzt die b\u00f6se Tat", "tokens": ["Da\u00df", "zu\u00b7letzt", "die", "b\u00f6\u00b7se", "Tat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr den \u00dcbelt\u00e4ter selber", "tokens": ["F\u00fcr", "den", "\u00dc\u00b7belt\u00b7\u00e4\u00b7ter", "sel\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unbequeme Folgen hat.", "tokens": ["Un\u00b7be\u00b7que\u00b7me", "Fol\u00b7gen", "hat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "Anderseits bemerkt man dieses", "tokens": ["An\u00b7der\u00b7seits", "be\u00b7merkt", "man", "die\u00b7ses"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur mit tiefem Herzeleid.", "tokens": ["Nur", "mit", "tie\u00b7fem", "Her\u00b7ze\u00b7leid", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, man will auch hier schon wieder", "tokens": ["Ach", ",", "man", "will", "auch", "hier", "schon", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so wie die Geistlichkeit!", "tokens": ["Nicht", "so", "wie", "die", "Geist\u00b7lich\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Leichter schmiegt sich Seel an Seele", "tokens": ["Leich\u00b7ter", "schmiegt", "sich", "Seel", "an", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PRF", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der schmerzensreichen Stund,", "tokens": ["In", "der", "schmer\u00b7zens\u00b7rei\u00b7chen", "Stund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und man schw\u00f6rt in der Berg\u00e8re", "tokens": ["Und", "man", "schw\u00f6rt", "in", "der", "Ber\u00b7g\u00e8\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich den ew'gen Freundschaftsbund.", "tokens": ["Sich", "den", "ew'\u00b7gen", "Freund\u00b7schafts\u00b7bund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Aber wie sie da so sitzen,", "tokens": ["A\u00b7ber", "wie", "sie", "da", "so", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00d6ffnet pl\u00f6tzlich sich die T\u00fcr.", "tokens": ["\u00d6ff\u00b7net", "pl\u00f6tz\u00b7lich", "sich", "die", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gottlieb ruft mit rauher Stimme:", "tokens": ["Gott\u00b7lieb", "ruft", "mit", "rau\u00b7her", "Stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u00bbei ei ei, was macht man hier?\u00ab", "tokens": ["\u00bb", "ei", "ei", "ei", ",", "was", "macht", "man", "hier", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "FM", "FM", "$,", "PWS", "VVFIN", "PIS", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Freilich h\u00fcllen sich die beiden", "tokens": ["Frei\u00b7lich", "h\u00fcl\u00b7len", "sich", "die", "bei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schnell in fromme Lieder ein;", "tokens": ["Schnell", "in", "from\u00b7me", "Lie\u00b7der", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch nur kurze Zeit erschallen", "tokens": ["Doch", "nur", "kur\u00b7ze", "Zeit", "er\u00b7schal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Diese sch\u00f6nen Melodein.", "tokens": ["Die\u00b7se", "sch\u00f6\u00b7nen", "Me\u00b7lo\u00b7dein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Ach, die weltlichen Gewalten! \u2013", "tokens": ["Ach", ",", "die", "welt\u00b7li\u00b7chen", "Ge\u00b7wal\u00b7ten", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch des Armes Muskelkraft", "tokens": ["Durch", "des", "Ar\u00b7mes", "Mus\u00b7kel\u00b7kraft"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wird der fromme Pater Luzi", "tokens": ["Wird", "der", "from\u00b7me", "Pa\u00b7ter", "Lu\u00b7zi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wirbelartig fortgeschafft.", "tokens": ["Wir\u00b7be\u00b7lar\u00b7tig", "fort\u00b7ge\u00b7schafft", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Dieses pl\u00f6tzliche Ereignis", "tokens": ["Die\u00b7ses", "pl\u00f6tz\u00b7li\u00b7che", "Er\u00b7eig\u00b7nis"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut ihm in der Seele leid.", "tokens": ["Tut", "ihm", "in", "der", "See\u00b7le", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, man will auch hier schon wieder", "tokens": ["Ach", ",", "man", "will", "auch", "hier", "schon", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so wie die Geistlichkeit!!", "tokens": ["Nicht", "so", "wie", "die", "Geist\u00b7lich\u00b7keit", "!!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Schlimm ist's Schrupp dabei ergangen,", "tokens": ["Schlimm", "ist's", "Schrupp", "da\u00b7bei", "er\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "NN", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil er sich hineingemengt;", "tokens": ["Weil", "er", "sich", "hin\u00b7ein\u00b7ge\u00b7mengt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem Fu\u00dfe unvermutet", "tokens": ["Mit", "dem", "Fu\u00b7\u00dfe", "un\u00b7ver\u00b7mu\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchlt er sich zur\u00fcckgedr\u00e4ngt.", "tokens": ["F\u00fchlt", "er", "sich", "zu\u00b7r\u00fcck\u00b7ge\u00b7dr\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Pater Luzi aber schleichet", "tokens": ["Pa\u00b7ter", "Lu\u00b7zi", "a\u00b7ber", "schlei\u00b7chet"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NE", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heimlich lauschend um das Haus.", "tokens": ["Heim\u00b7lich", "lau\u00b7schend", "um", "das", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein pechschwarzes Ei der Rache", "tokens": ["Ein", "pech\u00b7schwar\u00b7zes", "Ei", "der", "Ra\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Br\u00fctet seine Seele aus.", "tokens": ["Br\u00fc\u00b7tet", "sei\u00b7ne", "See\u00b7le", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Gottlieb seine Abendsuppe", "tokens": ["Gott\u00b7lieb", "sei\u00b7ne", "A\u00b7bend\u00b7sup\u00b7pe"], "token_info": ["word", "word", "word"], "pos": ["NE", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stehet am gewohnten Ort. \u2013", "tokens": ["Ste\u00b7het", "am", "ge\u00b7wohn\u00b7ten", "Ort", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Husch! da steigt wer durch das Fenster;", "tokens": ["Husch", "!", "da", "steigt", "wer", "durch", "das", "Fens\u00b7ter", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "PWS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Husch! jetzt ist er wieder fort.", "tokens": ["Husch", "!", "jetzt", "ist", "er", "wie\u00b7der", "fort", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VAFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Gottlieb, der im Nebenzimmer", "tokens": ["Gott\u00b7lieb", ",", "der", "im", "Ne\u00b7ben\u00b7zim\u00b7mer"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "APPRART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Eben seine H\u00e4nde wusch,", "tokens": ["E\u00b7ben", "sei\u00b7ne", "H\u00e4n\u00b7de", "wusch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieht's zum Gl\u00fcck und da\u00df der T\u00e4ter", "tokens": ["Sieht's", "zum", "Gl\u00fcck", "und", "da\u00df", "der", "T\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPRART", "NN", "KON", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lauschend sitzt im Fliederbusch.", "tokens": ["Lau\u00b7schend", "sitzt", "im", "Flie\u00b7der\u00b7busch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Jetzt hebt Gottlieb, friedlich l\u00e4chelnd,", "tokens": ["Jetzt", "hebt", "Gott\u00b7lieb", ",", "fried\u00b7lich", "l\u00e4\u00b7chelnd", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Von dem Tisch den Suppentopf.", "tokens": ["Von", "dem", "Tisch", "den", "Sup\u00b7pen\u00b7topf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Bratsch! \u2013 Die Br\u00fche samt der Schale", "tokens": ["Bratsch", "!", "\u2013", "Die", "Br\u00fc\u00b7he", "samt", "der", "Scha\u00b7le"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "$(", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommt Filuzi auf den Kopf.", "tokens": ["Kommt", "Fi\u00b7lu\u00b7zi", "auf", "den", "Kopf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Diese eklige Geschichte", "tokens": ["Die\u00b7se", "ek\u00b7li\u00b7ge", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut ihm in der Seele leid.", "tokens": ["Tut", "ihm", "in", "der", "See\u00b7le", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, man will auch hier schon wieder", "tokens": ["Ach", ",", "man", "will", "auch", "hier", "schon", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so wie die Geistlichkeit!", "tokens": ["Nicht", "so", "wie", "die", "Geist\u00b7lich\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Schrupp, der nur ein wenig leckte,", "tokens": ["Schrupp", ",", "der", "nur", "ein", "we\u00b7nig", "leck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "ART", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zieht es alle Glieder krumm;", "tokens": ["Zieht", "es", "al\u00b7le", "Glie\u00b7der", "krumm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn ein namenloser Jammer", "tokens": ["Denn", "ein", "na\u00b7men\u00b7lo\u00b7ser", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "W\u00fchlt in seinem Leib herum.", "tokens": ["W\u00fchlt", "in", "sei\u00b7nem", "Leib", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Pater Luzi, finster blickend,", "tokens": ["Pa\u00b7ter", "Lu\u00b7zi", ",", "fins\u00b7ter", "bli\u00b7ckend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "ADJD", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heimlich schleichend um das Haus,", "tokens": ["Heim\u00b7lich", "schlei\u00b7chend", "um", "das", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hlt zu neuem Rachezwecke", "tokens": ["W\u00e4hlt", "zu", "neu\u00b7em", "Ra\u00b7che\u00b7zwe\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zwo verwogne Lumpen aus. \u2013", "tokens": ["Zwo", "ver\u00b7wog\u00b7ne", "Lum\u00b7pen", "aus", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "ADJA", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Einer hei\u00dft der Inter-Nazi", "tokens": ["Ei\u00b7ner", "hei\u00dft", "der", "In\u00b7ter\u00b7Na\u00b7zi"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und der zweite Jean Lecaq,", "tokens": ["Und", "der", "zwei\u00b7te", "Jean", "Le\u00b7caq", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle beide wohl zu brauchen,", "tokens": ["Al\u00b7le", "bei\u00b7de", "wohl", "zu", "brau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIS", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn es mangelt Geld im Sack.", "tokens": ["Denn", "es", "man\u00b7gelt", "Geld", "im", "Sack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Eben wandelt in der stillen", "tokens": ["E\u00b7ben", "wan\u00b7delt", "in", "der", "stil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abendk\u00fchle der Natur", "tokens": ["A\u00b7bend\u00b7k\u00fch\u00b7le", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word"], "pos": ["NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Base Gelika im Garten \u2013", "tokens": ["Ba\u00b7se", "Ge\u00b7li\u00b7ka", "im", "Gar\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Horch! Da t\u00f6nt der Racheschwur!", "tokens": ["Horch", "!", "Da", "t\u00f6nt", "der", "Ra\u00b7ch\u00b7e\u00b7schwur", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.59": {"line.1": {"text": "Tieferschrocken, angstbefl\u00fcgelt", "tokens": ["Tie\u00b7fer\u00b7schro\u00b7cken", ",", "angst\u00b7be\u00b7fl\u00fc\u00b7gelt"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eilet sie ins Haus geschwind.", "tokens": ["Ei\u00b7let", "sie", "ins", "Haus", "ge\u00b7schwind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gottlieb k\u00fc\u00dft sie auf die Backe:", "tokens": ["Gott\u00b7lieb", "k\u00fc\u00dft", "sie", "auf", "die", "Ba\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbdanke sehr, mein gutes Kind!\u00ab", "tokens": ["\u00bb", "dan\u00b7ke", "sehr", ",", "mein", "gu\u00b7tes", "Kind", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.60": {"line.1": {"text": "Schleunig sucht er seine Freunde,", "tokens": ["Schleu\u00b7nig", "sucht", "er", "sei\u00b7ne", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gl\u00fccklich trifft er sie zu Haus.", "tokens": ["Gl\u00fcck\u00b7lich", "trifft", "er", "sie", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4chter Hiebel ist der erste,", "tokens": ["W\u00e4ch\u00b7ter", "Hie\u00b7bel", "ist", "der", "ers\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Freudig ruft er: \u00bbSabel raus!\u00ab", "tokens": ["Freu\u00b7dig", "ruft", "er", ":", "\u00bb", "Sa\u00b7bel", "raus", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "$.", "$(", "NE", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "Meister Fibel, als der zweite,", "tokens": ["Meis\u00b7ter", "Fi\u00b7bel", ",", "als", "der", "zwei\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KOUS", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vielerprobt im Amt der Lehr,", "tokens": ["Vie\u00b7ler\u00b7probt", "im", "Amt", "der", "Lehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Greift in die bekannte Ecke", "tokens": ["Greift", "in", "die", "be\u00b7kann\u00b7te", "E\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den Worten: \u00bbKn\u00fcppel her!\u00ab", "tokens": ["Mit", "den", "Wor\u00b7ten", ":", "\u00bb", "Kn\u00fcp\u00b7pel", "her", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$(", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Bullerstiebel ist der dritte. \u2013", "tokens": ["Bul\u00b7ler\u00b7stie\u00b7bel", "ist", "der", "drit\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kaum vernimmt er so und so,", "tokens": ["Kaum", "ver\u00b7nimmt", "er", "so", "und", "so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KON", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fa\u00dft er auch schon nach der Gabel", "tokens": ["Fa\u00dft", "er", "auch", "schon", "nach", "der", "Ga\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit dem Rufe: \u00bbNu man to!\u00ab", "tokens": ["Mit", "dem", "Ru\u00b7fe", ":", "\u00bb", "Nu", "man", "to", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$(", "ADV", "PIS", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Nun hat Schrupp, dieweil er leidend,", "tokens": ["Nun", "hat", "Schrupp", ",", "die\u00b7weil", "er", "lei\u00b7dend", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$,", "KOUS", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich in Gottliebs Bett gelegt,", "tokens": ["Sich", "in", "Gott\u00b7liebs", "Bett", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NE", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie er, wenn man nicht zugegen,", "tokens": ["Wie", "er", ",", "wenn", "man", "nicht", "zu\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "KOUS", "PIS", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch wohl sonst zu tuen pflegt.", "tokens": ["Auch", "wohl", "sonst", "zu", "tu\u00b7en", "pflegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Zw\u00f6lfe dr\u00f6hnt es auf dem Turme. \u2013", "tokens": ["Zw\u00f6l\u00b7fe", "dr\u00f6hnt", "es", "auf", "dem", "Tur\u00b7me", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leise macht man: Pistpistpist!", "tokens": ["Lei\u00b7se", "macht", "man", ":", "Pist\u00b7pist\u00b7pist", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "$.", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drei Gestalten huschen n\u00e4her", "tokens": ["Drei", "Ge\u00b7stal\u00b7ten", "hu\u00b7schen", "n\u00e4\u00b7her"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An das Bett voll Hinterlist.", "tokens": ["An", "das", "Bett", "voll", "Hin\u00b7ter\u00b7list", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Weh, jetzt trifft der Dolch, der spitze,", "tokens": ["Weh", ",", "jetzt", "trifft", "der", "Dolch", ",", "der", "spit\u00b7ze", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Kn\u00fcppel, dick und rauh,", "tokens": ["Und", "der", "Kn\u00fcp\u00b7pel", ",", "dick", "und", "rauh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und die Taschenmitralj\u00f6se \u2013", "tokens": ["Und", "die", "Ta\u00b7schen\u00b7mi\u00b7tral\u00b7j\u00f6\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber Schrupp macht: \u00bbAuwauwau!\u00ab", "tokens": ["A\u00b7ber", "Schrupp", "macht", ":", "\u00bb", "Au\u00b7wau\u00b7wau", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "ITJ", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "In demselbigten Momente", "tokens": ["In", "dem\u00b7sel\u00b7big\u00b7ten", "Mo\u00b7men\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "--+--+--", "measure": "anapaest.di.plus"}, "line.2": {"text": "Donnert es von hinten: \u00bbDrauf!!\u00ab", "tokens": ["Don\u00b7nert", "es", "von", "hin\u00b7ten", ":", "\u00bb", "Drauf", "!!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "$.", "$(", "PAV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein blasser Todesschrecken", "tokens": ["Und", "ein", "blas\u00b7ser", "To\u00b7des\u00b7schre\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hindert jeden Weiterlauf.", "tokens": ["Hin\u00b7dert", "je\u00b7den", "Wei\u00b7ter\u00b7lauf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.67": {"line.1": {"text": "Pater Luzi ganz besonders", "tokens": ["Pa\u00b7ter", "Lu\u00b7zi", "ganz", "be\u00b7son\u00b7ders"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NE", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Macht sich ahnungsvoll bereit.", "tokens": ["Macht", "sich", "ah\u00b7nungs\u00b7voll", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, man will auch hier schon wieder", "tokens": ["Ach", ",", "man", "will", "auch", "hier", "schon", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "PIS", "VMFIN", "ADV", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht so wie die Geistlichkeit!!", "tokens": ["Nicht", "so", "wie", "die", "Geist\u00b7lich\u00b7keit", "!!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Hei! Wie Fibels Waffe sauset!", "tokens": ["Hei", "!", "Wie", "Fi\u00b7bels", "Waf\u00b7fe", "sau\u00b7set", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "Hei\u00dfa! Wie der Sabel blitzt! \u2013", "tokens": ["Hei\u00b7\u00dfa", "!", "Wie", "der", "Sa\u00b7bel", "blitzt", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PWAV", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Zwiefach ist der Stich der Gabel,", "tokens": ["Zwie\u00b7fach", "ist", "der", "Stich", "der", "Ga\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil sie zwiefach zugespitzt. \u2013", "tokens": ["Weil", "sie", "zwie\u00b7fach", "zu\u00b7ge\u00b7spitzt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Motten fliegen, Haare sausen;", "tokens": ["Mot\u00b7ten", "flie\u00b7gen", ",", "Haa\u00b7re", "sau\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das gibt Leben in das Haus.", "tokens": ["Das", "gibt", "Le\u00b7ben", "in", "das", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Hulterpulter! Durch das Fenster", "tokens": ["Hul\u00b7ter\u00b7pul\u00b7ter", "!", "Durch", "das", "Fens\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Springt man in die Nacht hinaus.", "tokens": ["Springt", "man", "in", "die", "Nacht", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.73": {"line.1": {"text": "Klacks! da stecken sie im Drecke.", "tokens": ["Klacks", "!", "da", "ste\u00b7cken", "sie", "im", "Dre\u00b7cke", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00c4ngstlich zappelt noch der Fu\u00df. \u2013", "tokens": ["\u00c4ngst\u00b7lich", "zap\u00b7pelt", "noch", "der", "Fu\u00df", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "ADV", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Stimme h\u00f6rt man klagen:", "tokens": ["Ei\u00b7ne", "Stim\u00b7me", "h\u00f6rt", "man", "kla\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bboh, Filu \u2013 Filucius!!\u00ab \u2013", "tokens": ["\u00bb", "oh", ",", "Fi\u00b7lu", "\u2013", "Fi\u00b7lu\u00b7cius", "!!", "\u00ab", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["$(", "FM", "$,", "NE", "$(", "NE", "$.", "$(", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.74": {"line.1": {"text": "\u00bbkinder, das hat gut gegangen!\u00ab", "tokens": ["\u00bb", "kin\u00b7der", ",", "das", "hat", "gut", "ge\u00b7gan\u00b7gen", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "$,", "PDS", "VAFIN", "ADJD", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rufet Gottlieb hocherfreut;", "tokens": ["Ru\u00b7fet", "Gott\u00b7lieb", "ho\u00b7cher\u00b7freut", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbwein herbei! Denn zu vermelden", "tokens": ["\u00bb", "wein", "her\u00b7bei", "!", "Denn", "zu", "ver\u00b7mel\u00b7den"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "NN", "PTKVZ", "$.", "KON", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hab ich eine Neuigkeit.", "tokens": ["Hab", "ich", "ei\u00b7ne", "Neu\u00b7ig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "L\u00e4nger will ich nicht mehr hausen", "tokens": ["L\u00e4n\u00b7ger", "will", "ich", "nicht", "mehr", "hau\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PTKNEG", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie seither als Junggesell.", "tokens": ["Wie", "sei\u00b7ther", "als", "Jung\u00b7ge\u00b7sell", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KOKOM", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hier Angelika, die gute,", "tokens": ["Hier", "An\u00b7ge\u00b7li\u00b7ka", ",", "die", "gu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "ART", "ADJA", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Werde Madam Michael.\u00ab", "tokens": ["Wer\u00b7de", "Ma\u00b7dam", "Mic\u00b7hael", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "NE", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.76": {"line.1": {"text": "Drauf ergreift das Wort Herr Fibel,", "tokens": ["Drauf", "er\u00b7greift", "das", "Wort", "Herr", "Fi\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und er spricht: \u00bbEiei! Sieh da!", "tokens": ["Und", "er", "spricht", ":", "\u00bb", "Ei\u00b7ei", "!", "Sieh", "da", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "NN", "$.", "NE", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich erlaube mir zu singen:", "tokens": ["Ich", "er\u00b7lau\u00b7be", "mir", "zu", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vivat Hoch! Halleluja!!!\u00ab", "tokens": ["Vi\u00b7vat", "Hoch", "!", "Hal\u00b7le\u00b7lu\u00b7ja", "!!!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "$.", "NE", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}