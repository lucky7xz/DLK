{"dta.poem.15787": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "47.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1839", "urn": "urn:nbn:de:kobv:b4-200905195122", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df nicht ein Mensch die Sprach' erfunden, glaubt ihr lang,", "tokens": ["Da\u00df", "nicht", "ein", "Mensch", "die", "Sprach'", "er\u00b7fun\u00b7den", ",", "glaubt", "ihr", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ART", "NN", "VVPP", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und da\u00df sie mit und aus der Menschheit selbst entsprang.", "tokens": ["Und", "da\u00df", "sie", "mit", "und", "aus", "der", "Menschheit", "selbst", "ent\u00b7sprang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "KON", "APPR", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "Doch meint ihr, da\u00df ein Mensch einmal erfand die Schrift,", "tokens": ["Doch", "meint", "ihr", ",", "da\u00df", "ein", "Mensch", "ein\u00b7mal", "er\u00b7fand", "die", "Schrift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als sei kein Zauber auch Buchstab' und Schreibestift!", "tokens": ["Als", "sei", "kein", "Zau\u00b7ber", "auch", "Buch\u00b7stab'", "und", "Schrei\u00b7be\u00b7stift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PIAT", "NN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch nicht ein Zauberer, ein Gott gewesen w\u00e4re,", "tokens": ["Doch", "nicht", "ein", "Zau\u00b7be\u00b7rer", ",", "ein", "Gott", "ge\u00b7we\u00b7sen", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "NN", "$,", "ART", "NN", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer dem Gedanken so gerundet seine Sf\u00e4re.", "tokens": ["Wer", "dem", "Ge\u00b7dan\u00b7ken", "so", "ge\u00b7run\u00b7det", "sei\u00b7ne", "Sf\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVPP", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Denn kleinres Wunder nicht ist da\u00df man schreibt, als spricht;", "tokens": ["Denn", "klein\u00b7res", "Wun\u00b7der", "nicht", "ist", "da\u00df", "man", "schreibt", ",", "als", "spricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKNEG", "VAFIN", "KOUS", "PIS", "VVFIN", "$,", "KOUS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In zweien Spiegeln bricht sich gleich des Geistes Licht.", "tokens": ["In", "zwei\u00b7en", "Spie\u00b7geln", "bricht", "sich", "gleich", "des", "Geis\u00b7tes", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PRF", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der eine Spiegel wirft das Bild dem andern zu,", "tokens": ["Der", "ei\u00b7ne", "Spie\u00b7gel", "wirft", "das", "Bild", "dem", "an\u00b7dern", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "ART", "NN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und \u00e4u\u00dferlich wie dort dich hier erkennest du.", "tokens": ["Und", "\u00e4u\u00b7\u00dfer\u00b7lich", "wie", "dort", "dich", "hier", "er\u00b7ken\u00b7nest", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ADV", "PPER", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Schrift ist mit der Sprach' und wie sie selbst entstanden,", "tokens": ["Die", "Schrift", "ist", "mit", "der", "Sprach'", "und", "wie", "sie", "selbst", "ent\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "KON", "PWAV", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In beiden nur ist ganz der Menschheit Bild vorhanden.", "tokens": ["In", "bei\u00b7den", "nur", "ist", "ganz", "der", "Menschheit", "Bild", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADV", "VAFIN", "ADV", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Du sagst: ein Unterschied sei zwischen Schrift und Schalle,", "tokens": ["Du", "sagst", ":", "ein", "Un\u00b7ter\u00b7schied", "sei", "zwi\u00b7schen", "Schrift", "und", "Schal\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil alle sprechen, doch nicht schreiben k\u00f6nnen alle;", "tokens": ["Weil", "al\u00b7le", "spre\u00b7chen", ",", "doch", "nicht", "schrei\u00b7ben", "k\u00f6n\u00b7nen", "al\u00b7le", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "$,", "ADV", "PTKNEG", "VVINF", "VMFIN", "PIS", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Drum sei die Sprache wol der Menschheit selbst entsprungen,", "tokens": ["Drum", "sei", "die", "Spra\u00b7che", "wol", "der", "Menschheit", "selbst", "ent\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Doch nur Erfindsamen die Schreibekunst gelungen.", "tokens": ["Doch", "nur", "Er\u00b7find\u00b7sa\u00b7men", "die", "Schrei\u00b7be\u00b7kunst", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Das hei\u00dft: Das Denken hab' ein Denker ausgedacht,", "tokens": ["Das", "hei\u00dft", ":", "Das", "Den\u00b7ken", "hab'", "ein", "Den\u00b7ker", "aus\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$.", "ART", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil auch nicht jeder Mensch Gebrauch vom Denken macht!", "tokens": ["Weil", "auch", "nicht", "je\u00b7der", "Mensch", "Ge\u00b7brauch", "vom", "Den\u00b7ken", "macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "PIAT", "NN", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}