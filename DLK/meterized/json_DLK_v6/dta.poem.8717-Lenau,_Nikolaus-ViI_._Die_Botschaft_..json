{"dta.poem.8717": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "ViI .  \n  Die Botschaft .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1832", "urn": "urn:nbn:de:kobv:b4-200905193572", "language": ["de:0.99"], "booktitle": "Lenau, Nikolaus: Gedichte. Stuttgart, 1832."}, "poem": {"stanza.1": {"line.1": {"text": "Nach Saint-Germain zum Verkaufe", "tokens": ["Nach", "Saint\u00b7Ger\u00b7main", "zum", "Ver\u00b7kau\u00b7fe"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "APPRART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Tr\u00e4gt ein H\u00e4uflein Bauersleute,", "tokens": ["Tr\u00e4gt", "ein", "H\u00e4uf\u00b7lein", "Bau\u00b7ers\u00b7leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was der Herbst mit vollen H\u00e4nden", "tokens": ["Was", "der", "Herbst", "mit", "vol\u00b7len", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihm auf Flur und Garten streute.", "tokens": ["Ihm", "auf", "Flur", "und", "Gar\u00b7ten", "streu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Neben schwer beladnem Wagen", "tokens": ["Ne\u00b7ben", "schwer", "be\u00b7lad\u00b7nem", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00e4\u00dft der Mann die Gei\u00dfel knallen,", "tokens": ["L\u00e4\u00dft", "der", "Mann", "die", "Gei\u00b7\u00dfel", "knal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der B\u00e4urin feinem Korbe", "tokens": ["In", "der", "B\u00e4u\u00b7rin", "fei\u00b7nem", "Kor\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird das schmucke Obst gefallen.", "tokens": ["Wird", "das", "schmu\u00b7cke", "Obst", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Mit Geschichten, frohen Possen,", "tokens": ["Mit", "Ge\u00b7schich\u00b7ten", ",", "fro\u00b7hen", "Pos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und nun wieder mit Ges\u00e4ngen", "tokens": ["Und", "nun", "wie\u00b7der", "mit", "Ge\u00b7s\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Suchen sie sich wegzustehlen", "tokens": ["Su\u00b7chen", "sie", "sich", "weg\u00b7zu\u00b7steh\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ueber ihres Weges L\u00e4ngen.", "tokens": ["Ue\u00b7ber", "ih\u00b7res", "We\u00b7ges", "L\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Hinter ihnen Pferdgetrappel:", "tokens": ["Hin\u00b7ter", "ih\u00b7nen", "Pferd\u00b7ge\u00b7trap\u00b7pel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und sie stehen, und sie schweigen,", "tokens": ["Und", "sie", "ste\u00b7hen", ",", "und", "sie", "schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und neugierig nach den Reitern", "tokens": ["Und", "neu\u00b7gie\u00b7rig", "nach", "den", "Rei\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aug' und Ohr sie r\u00fcckw\u00e4rts neigen.", "tokens": ["Aug'", "und", "Ohr", "sie", "r\u00fcck\u00b7w\u00e4rts", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "In noch nie gesehner Eile,", "tokens": ["In", "noch", "nie", "ge\u00b7seh\u00b7ner", "Ei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Brausend gleich emp\u00f6rten Wogen,", "tokens": ["Brau\u00b7send", "gleich", "em\u00b7p\u00f6r\u00b7ten", "Wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In noch nie gesehnen Trachten", "tokens": ["In", "noch", "nie", "ge\u00b7seh\u00b7nen", "Trach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kommt die Schaar herangeflogen.", "tokens": ["Kommt", "die", "Schaar", "her\u00b7an\u00b7ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer? wohin? woher des Weges?", "tokens": ["Wer", "?", "wo\u00b7hin", "?", "wo\u00b7her", "des", "We\u00b7ges", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PWAV", "$.", "PWAV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rufen die erstaunten Bauern;", "tokens": ["Ru\u00b7fen", "die", "er\u00b7staun\u00b7ten", "Bau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch mit Staub die Rosseshufe", "tokens": ["Doch", "mit", "Staub", "die", "Ros\u00b7ses\u00b7hu\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihnen schnell den Mund vermauern. \u2014", "tokens": ["Ih\u00b7nen", "schnell", "den", "Mund", "ver\u00b7mau\u00b7ern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADJD", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Es ist Christoph Gonsiewski", "tokens": ["Es", "ist", "Chris\u00b7toph", "Gon\u00b7siews\u00b7ki"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von Smolensk der Wojewode,", "tokens": ["Von", "Smo\u00b7lensk", "der", "Wo\u00b7je\u00b7wo\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der mit seinen Weggef\u00e4hrten", "tokens": ["Der", "mit", "sei\u00b7nen", "Weg\u00b7ge\u00b7f\u00e4hr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Manches Ro\u00df gejagt zu Tode.", "tokens": ["Man\u00b7ches", "Ro\u00df", "ge\u00b7jagt", "zu", "To\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Nimmer l\u00e4nger soll Johannes", "tokens": ["Nim\u00b7mer", "l\u00e4n\u00b7ger", "soll", "Jo\u00b7han\u00b7nes"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VMFIN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schmachten in den Kerkermauern;", "tokens": ["Schmach\u00b7ten", "in", "den", "Ker\u00b7ker\u00b7mau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wladyslaw, sein treuer Bruder,", "tokens": ["Wla\u00b7dy\u00b7slaw", ",", "sein", "treu\u00b7er", "Bru\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchlt herzinniges Bedauern.", "tokens": ["F\u00fchlt", "her\u00b7zin\u00b7ni\u00b7ges", "Be\u00b7dau\u00b7ern", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Wladyslaw, der Polenk\u00f6nig,", "tokens": ["Wla\u00b7dy\u00b7slaw", ",", "der", "Po\u00b7len\u00b7k\u00f6\u00b7nig", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nig auch im Schwedenlande,", "tokens": ["K\u00f6\u00b7nig", "auch", "im", "Schwe\u00b7den\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist emp\u00f6rt in tiefster Seele", "tokens": ["Ist", "em\u00b7p\u00f6rt", "in", "tiefs\u00b7ter", "See\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ueber Frankreichs freche Schande.", "tokens": ["Ue\u00b7ber", "Fran\u00b7kreichs", "fre\u00b7che", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und er lie\u00df zu seinen Boten", "tokens": ["Und", "er", "lie\u00df", "zu", "sei\u00b7nen", "Bo\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Z\u00fcrnend seine Stimme tosen,", "tokens": ["Z\u00fcr\u00b7nend", "sei\u00b7ne", "Stim\u00b7me", "to\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das Wort das er gesendet", "tokens": ["Und", "das", "Wort", "das", "er", "ge\u00b7sen\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "An den K\u00f6nig der Franzosen,", "tokens": ["An", "den", "K\u00f6\u00b7nig", "der", "Fran\u00b7zo\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ist ein Blitz in sie gefahren,", "tokens": ["Ist", "ein", "Blitz", "in", "sie", "ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der sie nun fortrei\u00dft geschwinde,", "tokens": ["Der", "sie", "nun", "for\u00b7trei\u00dft", "ge\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unaufhaltsam nach dem Orte,", "tokens": ["Un\u00b7auf\u00b7halt\u00b7sam", "nach", "dem", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo er, freigelassen, z\u00fcnde. \u2014", "tokens": ["Wo", "er", ",", "frei\u00b7ge\u00b7las\u00b7sen", ",", "z\u00fcn\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "$,", "VVFIN", "$,", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "In dem Schlosse zu Saint-Germain", "tokens": ["In", "dem", "Schlos\u00b7se", "zu", "Saint\u00b7Ger\u00b7main"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Schnauben schon die m\u00fcden Renner,", "tokens": ["Schnau\u00b7ben", "schon", "die", "m\u00fc\u00b7den", "Ren\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor den argbetroffnen K\u00f6nig", "tokens": ["Vor", "den", "arg\u00b7be\u00b7troff\u00b7nen", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Treten die sarmat'schen M\u00e4nner.", "tokens": ["Tre\u00b7ten", "die", "sar\u00b7mat'\u00b7schen", "M\u00e4n\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Schwei\u00df entrollt den k\u00fchnen Stirnen,", "tokens": ["Schwei\u00df", "ent\u00b7rollt", "den", "k\u00fch\u00b7nen", "Stir\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ihr Auge gl\u00fcht im Zorne,", "tokens": ["Und", "ihr", "Au\u00b7ge", "gl\u00fcht", "im", "Zor\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Drohend klirren ihre S\u00e4bel,", "tokens": ["Dro\u00b7hend", "klir\u00b7ren", "ih\u00b7re", "S\u00e4\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre blutgetr\u00e4nkten Sporne.", "tokens": ["Ih\u00b7re", "blut\u00b7ge\u00b7tr\u00e4nk\u00b7ten", "Spor\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Und zum K\u00f6nig nun beginnet", "tokens": ["Und", "zum", "K\u00f6\u00b7nig", "nun", "be\u00b7gin\u00b7net"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gonsiewski so zu reden:", "tokens": ["Gon\u00b7siews\u00b7ki", "so", "zu", "re\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "\u201ewladyslaw hat uns gesendet,", "tokens": ["\u201e", "wla\u00b7dy\u00b7slaw", "hat", "uns", "ge\u00b7sen\u00b7det", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Herr der Polen und der Schweden:", "tokens": ["Herr", "der", "Po\u00b7len", "und", "der", "Schwe\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "ART", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Habt Ihr nicht noch diese Stunde", "tokens": ["Habt", "Ihr", "nicht", "noch", "die\u00b7se", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seinen Bruder freigesprochen,", "tokens": ["Sei\u00b7nen", "Bru\u00b7der", "frei\u00b7ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Soll an Euch und Eurem Lande", "tokens": ["Soll", "an", "Euch", "und", "Eu\u00b7rem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "PPER", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Blutig seyn die Schmach gerochen!", "tokens": ["Blu\u00b7tig", "seyn", "die", "Schmach", "ge\u00b7ro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Da\u00df der Prinz das Land durchsp\u00e4hte,", "tokens": ["Da\u00df", "der", "Prinz", "das", "Land", "durch\u00b7sp\u00e4h\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Euch an Spanien zu verrathen,", "tokens": ["Euch", "an", "Spa\u00b7ni\u00b7en", "zu", "ver\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist nur eine schn\u00f6de L\u00fcge", "tokens": ["Ist", "nur", "ei\u00b7ne", "schn\u00f6\u00b7de", "L\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eures t\u00fcckischen Pr\u00e4laten,", "tokens": ["Eu\u00b7res", "t\u00fc\u00b7cki\u00b7schen", "Pr\u00e4\u00b7la\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Eine L\u00fcge, ausgebr\u00fctet,", "tokens": ["Ei\u00b7ne", "L\u00fc\u00b7ge", ",", "aus\u00b7ge\u00b7br\u00fc\u00b7tet", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von der Kirche grimmstem Geier;", "tokens": ["Von", "der", "Kir\u00b7che", "grimms\u00b7tem", "Gei\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und in Eurer faulen Krone", "tokens": ["Und", "in", "Eu\u00b7rer", "fau\u00b7len", "Kro\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nistet dieses Ungeheuer! \u2014", "tokens": ["Nis\u00b7tet", "die\u00b7ses", "Un\u00b7ge\u00b7heu\u00b7er", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Oestreich, Spanien und Italien", "tokens": ["O\u00b7e\u00b7streich", ",", "Spa\u00b7ni\u00b7en", "und", "I\u00b7ta\u00b7li\u00b7en"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NE", "KON", "NE"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Werden sich an Polen halten,", "tokens": ["Wer\u00b7den", "sich", "an", "Po\u00b7len", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+----+-", "measure": "dactylic.init"}, "line.3": {"text": "Eure Macht und Johanns Kerker", "tokens": ["Eu\u00b7re", "Macht", "und", "Jo\u00b7hanns", "Ker\u00b7ker"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schnell mit ", "tokens": ["Schnell", "mit"], "token_info": ["word", "word"], "pos": ["ADJD", "APPR"], "meter": "++", "measure": "spondeus"}}, "stanza.19": {"line.1": {"text": "Zornesbleich und furchtergriffen,", "tokens": ["Zor\u00b7nes\u00b7bleich", "und", "furch\u00b7ter\u00b7grif\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tiefbesch\u00e4met, starrt zur Erde", "tokens": ["Tief\u00b7be\u00b7sch\u00e4\u00b7met", ",", "starrt", "zur", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nig Ludwig, \u2014 und gebietet,", "tokens": ["K\u00f6\u00b7nig", "Lud\u00b7wig", ",", "und", "ge\u00b7bie\u00b7tet", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "$(", "KON", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Da\u00df der Prinz befreiet werde.", "tokens": ["Da\u00df", "der", "Prinz", "be\u00b7frei\u00b7et", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}