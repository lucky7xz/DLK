{"textgrid.poem.25704": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ist ", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist ", "tokens": ["Ist"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Da\u00df ich Latein soll lernen?", "tokens": ["Da\u00df", "ich", "La\u00b7tein", "soll", "ler\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er denkt mit guten Worten wohl,", "tokens": ["Er", "denkt", "mit", "gu\u00b7ten", "Wor\u00b7ten", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Schulfuchs! mich zu k\u00f6rnen?", "tokens": ["Der", "Schul\u00b7fuchs", "!", "mich", "zu", "k\u00f6r\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch k\u00f6rn' er nur, mein Herr Pedant!", "tokens": ["Doch", "k\u00f6rn'", "er", "nur", ",", "mein", "Herr", "Pe\u00b7dant", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wir haben auch, Gottlob! Verstand.", "tokens": ["Wir", "ha\u00b7ben", "auch", ",", "Gott\u00b7lob", "!", "Ver\u00b7stand", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "NN", "$.", "NN", "$."], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Ha ha! Wer auf dem Kopfe geht,", "tokens": ["Ha", "ha", "!", "Wer", "auf", "dem", "Kop\u00b7fe", "geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "PWS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mag glauben, da\u00df die Raben", "tokens": ["Mag", "glau\u00b7ben", ",", "da\u00df", "die", "Ra\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Und F\u00fcchse, wie im Ph\u00e4drus steht,", "tokens": ["Und", "F\u00fcch\u00b7se", ",", "wie", "im", "Ph\u00e4d\u00b7rus", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Vordem gesprochen haben.", "tokens": ["Vor\u00b7dem", "ge\u00b7spro\u00b7chen", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Ph\u00e4drus ist ein Narr, wie ", "tokens": ["Der", "Ph\u00e4d\u00b7rus", "ist", "ein", "Narr", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NE", "VAFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "L\u00fcgt nur! Mir bindet ihr nichts auf.", "tokens": ["L\u00fcgt", "nur", "!", "Mir", "bin\u00b7det", "ihr", "nichts", "auf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Franz\u00f6sisch lern' ich noch zur Noth", "tokens": ["Fran\u00b7z\u00f6\u00b7sisch", "lern'", "ich", "noch", "zur", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wohl etwas radebrechen;", "tokens": ["Wohl", "et\u00b7was", "ra\u00b7de\u00b7bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Ich Narr werd' immer bla\u00df und roth,", "tokens": ["Ich", "Narr", "werd'", "im\u00b7mer", "bla\u00df", "und", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wenn Fr\u00e4ulein mit mir sprechen,", "tokens": ["Wenn", "Fr\u00e4u\u00b7lein", "mit", "mir", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Und ich bei ihrem: ", "tokens": ["Und", "ich", "bei", "ih\u00b7rem", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.18": {"text": "Wie Butter an der Sonne steh'.", "tokens": ["Wie", "But\u00b7ter", "an", "der", "Son\u00b7ne", "steh'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Was soll ich \u00fcbrigens mich noch", "tokens": ["Was", "soll", "ich", "\u00fcb\u00b7ri\u00b7gens", "mich", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Mit Christenthume plagen?", "tokens": ["Mit", "Chris\u00b7ten\u00b7thu\u00b7me", "pla\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Ja! pros't die Mahlzeit! wei\u00df ich doch", "tokens": ["Ja", "!", "pros't", "die", "Mahl\u00b7zeit", "!", "wei\u00df", "ich", "doch"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "VVFIN", "ART", "NN", "$.", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Die Catechismus-Fragen.", "tokens": ["Die", "Ca\u00b7te\u00b7chis\u00b7mus\u00b7Fra\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Was geht mich Doctor ", "tokens": ["Was", "geht", "mich", "Doc\u00b7tor"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "NN"], "meter": "-+---", "measure": "dactylic.init"}, "line.24": {"text": "Daf\u00fcr bin ich ein Edelmann!", "tokens": ["Da\u00b7f\u00fcr", "bin", "ich", "ein", "E\u00b7del\u00b7mann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Ich lasse lieber fix daf\u00fcr", "tokens": ["Ich", "las\u00b7se", "lie\u00b7ber", "fix", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Die Jungen exerciren,", "tokens": ["Die", "Jun\u00b7gen", "ex\u00b7er\u00b7ci\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "Und \u00fcbe mich, als Offizier", "tokens": ["Und", "\u00fc\u00b7be", "mich", ",", "als", "Of\u00b7fi\u00b7zier"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Sie wacker auszuschmieren,", "tokens": ["Sie", "wa\u00b7cker", "aus\u00b7zu\u00b7schmie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.29": {"text": "Und trommle meinen Zapfenstreich", "tokens": ["Und", "tromm\u00b7le", "mei\u00b7nen", "Zap\u00b7fen\u00b7streich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Dem besten Trommelschl\u00e4ger gleich.", "tokens": ["Dem", "bes\u00b7ten", "Trom\u00b7mel\u00b7schl\u00e4\u00b7ger", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Auch kann ich \u00fcber Z\u00e4une hin", "tokens": ["Auch", "kann", "ich", "\u00fc\u00b7ber", "Z\u00e4u\u00b7ne", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Mit unserm Schimmel setzen,", "tokens": ["Mit", "un\u00b7serm", "Schim\u00b7mel", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.33": {"text": "Und, ohne mich zu r\u00fchmen, bin", "tokens": ["Und", ",", "oh\u00b7ne", "mich", "zu", "r\u00fch\u00b7men", ",", "bin"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Ich Meister schon im Hetzen.", "tokens": ["Ich", "Meis\u00b7ter", "schon", "im", "Het\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "Und unser Kammerk\u00e4tzchen wehrt \u2013", "tokens": ["Und", "un\u00b7ser", "Kam\u00b7mer\u00b7k\u00e4tz\u00b7chen", "wehrt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Doch still! da\u00df es Mama nicht h\u00f6rt.", "tokens": ["Doch", "still", "!", "da\u00df", "es", "Ma\u00b7ma", "nicht", "h\u00f6rt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$.", "KOUS", "PPER", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Ha! hab' ich erst einmal das Gut:", "tokens": ["Ha", "!", "hab'", "ich", "erst", "ein\u00b7mal", "das", "Gut", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Das soll ein Leben werden!", "tokens": ["Das", "soll", "ein", "Le\u00b7ben", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.39": {"text": "Mit meinem gro\u00dfen Federhut'", "tokens": ["Mit", "mei\u00b7nem", "gro\u00b7\u00dfen", "Fe\u00b7der\u00b7hut'"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Und Hunden, J\u00e4gern, Pferden", "tokens": ["Und", "Hun\u00b7den", ",", "J\u00e4\u00b7gern", ",", "Pfer\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["KON", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.41": {"text": "Und Bauren, will ich Tag und Nacht", "tokens": ["Und", "Bau\u00b7ren", ",", "will", "ich", "Tag", "und", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "VMFIN", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Heraus zur Hetz' und Klapperjagd.", "tokens": ["He\u00b7raus", "zur", "Hetz'", "und", "Klap\u00b7per\u00b7jagd", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "Verdammt! das Ding steigt mir zu Kopf,", "tokens": ["Ver\u00b7dammt", "!", "das", "Ding", "steigt", "mir", "zu", "Kopf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.45": {"text": "Erwisch' ich ihn einmal beim Schopf':", "tokens": ["Er\u00b7wi\u00b7sch'", "ich", "ihn", "ein\u00b7mal", "beim", "Schopf'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.46": {"text": "Ich schlag' ihm blaue Flecken;", "tokens": ["Ich", "schlag'", "ihm", "blau\u00b7e", "Fle\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.47": {"text": "Und werd' ich gar Gerichtsherr noch,", "tokens": ["Und", "werd'", "ich", "gar", "Ge\u00b7richts\u00b7herr", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Dann sollst du mir ins Hundeloch!", "tokens": ["Dann", "sollst", "du", "mir", "ins", "Hun\u00b7de\u00b7loch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}