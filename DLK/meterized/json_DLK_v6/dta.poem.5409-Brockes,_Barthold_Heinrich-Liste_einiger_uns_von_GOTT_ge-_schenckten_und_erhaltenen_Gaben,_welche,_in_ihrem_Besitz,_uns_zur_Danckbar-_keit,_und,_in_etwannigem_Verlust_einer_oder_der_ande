{"dta.poem.5409": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Liste einiger uns von  GOTT  ge-  \n schenckten und erhaltenen Gaben,  \n welche, in ihrem Besitz, uns zur Danckbar-  \n keit, und, in etwannigem Verlust einer oder  \n der andern, durch die Menge der uns noch  \n gelassenen, zu einem vern\u00fcnftigen Trost billig  \n dienen solten. Diesen von uns besessenen G\u00fc-  \n tern sind einige entfernte Plagen, wof\u00fcr  \n GOtt uns beh\u00fctet, beygef\u00fcget.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "La\u00dft uns wenigstens versuchen (um den Undanck zu\nbesch\u00e4men,", "tokens": ["La\u00dft", "uns", "we\u00b7nigs\u00b7tens", "ver\u00b7su\u00b7chen", "(", "um", "den", "Un\u00b7danck", "zu", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$(", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Welcher uns so str\u00e4flich macht) einen neuen Weg zu", "tokens": ["Wel\u00b7cher", "uns", "so", "str\u00e4f\u00b7lich", "macht", ")", "ei\u00b7nen", "neu\u00b7en", "Weg", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAT", "PPER", "ADV", "ADJD", "VVFIN", "$(", "ART", "ADJA", "NN", "APPR"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Ob vielleicht die grosse Menge aller uns geschenckten G\u00fcter,", "tokens": ["Ob", "viel\u00b7leicht", "die", "gros\u00b7se", "Men\u00b7ge", "al\u00b7ler", "uns", "ge\u00b7schenck\u00b7ten", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PIAT", "PRF", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Wenn wir sie beysammen sehn, die verblendeten Gem\u00fcther", "tokens": ["Wenn", "wir", "sie", "bey\u00b7sam\u00b7men", "sehn", ",", "die", "ver\u00b7blen\u00b7de\u00b7ten", "Ge\u00b7m\u00fc\u00b7ther"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VVINF", "$,", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Aus dem Schlaffe der Gewohnheit etwan zu erwecken", "tokens": ["Aus", "dem", "Schlaf\u00b7fe", "der", "Ge\u00b7wohn\u00b7heit", "et\u00b7wan", "zu", "er\u00b7we\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.2": {"line.1": {"text": "Wann nun jeder sich der N\u00e4chste und sich selbst em-", "tokens": ["Wann", "nun", "je\u00b7der", "sich", "der", "N\u00e4chs\u00b7te", "und", "sich", "selbst", "em"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PIS", "PRF", "ART", "ADJA", "KON", "PRF", "ADV", "TRUNC"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Fang ich von den Wunder-Gaben unsers C\u00f6rpers billig an:", "tokens": ["Fang", "ich", "von", "den", "Wun\u00b7der\u00b7Ga\u00b7ben", "un\u00b7sers", "C\u00f6r\u00b7pers", "bil\u00b7lig", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.3": {"line.1": {"text": "Haare, Gaum, Gehirn und Wangen, Lippen, Finger,\nAugen-Lieder,\nH\u00fcfte, Dr\u00fcsen, Eingeweide, Knorpel, Kehle, Hal\u00df und\nSchlund\nN\u00e4gel, Kniee, Rippen, Achseln, Muskeln und viel andre\nGlieder:", "tokens": ["Haa\u00b7re", ",", "Gaum", ",", "Ge\u00b7hirn", "und", "Wan\u00b7gen", ",", "Lip\u00b7pen", ",", "Fin\u00b7ger", ",", "Au\u00b7gen\u00b7Lie\u00b7der", ",", "H\u00fcf\u00b7te", ",", "Dr\u00fc\u00b7sen", ",", "Ein\u00b7ge\u00b7wei\u00b7de", ",", "Knor\u00b7pel", ",", "Keh\u00b7le", ",", "Hal\u00df", "und", "Schlund", "N\u00e4\u00b7gel", ",", "Kni\u00b7ee", ",", "Rip\u00b7pen", ",", "Ach\u00b7seln", ",", "Mus\u00b7keln", "und", "viel", "and\u00b7re", "Glie\u00b7der", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-++-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Da\u00df die ", "tokens": ["Da\u00df", "die"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Durch viel ", "tokens": ["Durch", "viel"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Da zumahl am gantzen C\u00f6rper keine Stell\u2019, auch noch so", "tokens": ["Da", "zu\u00b7mahl", "am", "gant\u00b7zen", "C\u00f6r\u00b7per", "kei\u00b7ne", "Stell'", ",", "auch", "noch", "so"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN", "PIAT", "NN", "$,", "ADV", "ADV", "ADV"], "meter": "--+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.6": {"text": "Die bey uns nicht Schmertzen f\u00e4hig, nicht empfindlich ist", "tokens": ["Die", "bey", "uns", "nicht", "Schmert\u00b7zen", "f\u00e4\u00b7hig", ",", "nicht", "emp\u00b7find\u00b7lich", "ist"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "PPER", "PTKNEG", "NN", "ADJD", "$,", "PTKNEG", "ADJD", "VAFIN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Da\u00df von allen diesen Theilen ", "tokens": ["Da\u00df", "von", "al\u00b7len", "die\u00b7sen", "Thei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df kein ", "tokens": ["Da\u00df", "kein"], "token_info": ["word", "word"], "pos": ["KOUS", "PIAT"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Keine ", "tokens": ["Kei\u00b7ne"], "token_info": ["word"], "pos": ["PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Keine ", "tokens": ["Kei\u00b7ne"], "token_info": ["word"], "pos": ["PIAT"], "meter": "+-", "measure": "trochaic.single"}, "line.11": {"text": "Schwehrer Hust, Geschw\u00fchre, Friesel, mancherley Be-\nsch\u00e4digung,\nDarm-Gicht, Br\u00fcche, Taub- und Blindheit, Schwindel,\nSchlag-Flu\u00df, Seiten-Stechen,", "tokens": ["Schweh\u00b7rer", "Hust", ",", "Ge\u00b7schw\u00fch\u00b7re", ",", "Frie\u00b7sel", ",", "man\u00b7cher\u00b7ley", "Be", "sch\u00e4\u00b7di\u00b7gung", ",", "Dar\u00b7mGicht", ",", "Br\u00fc\u00b7che", ",", "Taub", "und", "Blind\u00b7heit", ",", "Schwin\u00b7del", ",", "Schlag\u00b7Flu\u00df", ",", "Sei\u00b7ten\u00b7Ste\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "PIAT", "TRUNC", "NN", "$,", "NN", "$,", "NN", "$,", "TRUNC", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+--+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.12": {"text": "Nebst viel ", "tokens": ["Nebst", "viel"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "--", "measure": "unknown.measure.zero"}, "line.13": {"text": "Da\u00df nicht minder unser Geist, von ", "tokens": ["Da\u00df", "nicht", "min\u00b7der", "un\u00b7ser", "Geist", ",", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PTKNEG", "ADV", "PPOSAT", "NN", "$,", "APPR"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Schwermuth, Unruh, Angst, Verwirrung, und von\nschwartzen Sorgen frey;", "tokens": ["Schwer\u00b7muth", ",", "Un\u00b7ruh", ",", "Angst", ",", "Ver\u00b7wir\u00b7rung", ",", "und", "von", "schwart\u00b7zen", "Sor\u00b7gen", "frey", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "KON", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.4": {"line.1": {"text": "Diese von uns ferne Qvalen, die uns alle dr\u00fccken k\u00f6nnen,", "tokens": ["Die\u00b7se", "von", "uns", "fer\u00b7ne", "Qva\u00b7len", ",", "die", "uns", "al\u00b7le", "dr\u00fc\u00b7cken", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "ADJA", "NN", "$,", "PRELS", "PPER", "PIS", "VVINF", "VMINF", "$,"], "meter": "+---+-+-+-+-+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Sind die nicht von solchem Wehrt, da\u00df wir dem ein Danck-", "tokens": ["Sind", "die", "nicht", "von", "sol\u00b7chem", "Wehrt", ",", "da\u00df", "wir", "dem", "ein", "Dan\u00b7ck"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "PTKNEG", "APPR", "PIAT", "NN", "$,", "KOUS", "PPER", "ART", "ART", "TRUNC"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Der mit V\u00e4terlicher Vorsorg\u2019, auf so viele Weis\u2019 und Art,", "tokens": ["Der", "mit", "V\u00e4\u00b7ter\u00b7li\u00b7cher", "Vor\u00b7sor\u00b7g'", ",", "auf", "so", "vie\u00b7le", "Weis'", "und", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "$,", "APPR", "ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Leib und Seele bi\u00df daher vor so mancher Qual bewahrt,", "tokens": ["Leib", "und", "See\u00b7le", "bi\u00df", "da\u00b7her", "vor", "so", "man\u00b7cher", "Qual", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "PAV", "APPR", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Ja da\u00df von so vielen Plagen nicht nur ", "tokens": ["Ja", "da\u00df", "von", "so", "vie\u00b7len", "Pla\u00b7gen", "nicht", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "KOUS", "APPR", "ADV", "PIAT", "NN", "PTKNEG", "ADV"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Sondern oft ", "tokens": ["Son\u00b7dern", "oft"], "token_info": ["word", "word"], "pos": ["KON", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "La\u00dft uns denn nun weiter gehn, und der G\u00fcter Meng\u2019", "tokens": ["La\u00dft", "uns", "denn", "nun", "wei\u00b7ter", "gehn", ",", "und", "der", "G\u00fc\u00b7ter", "Meng'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "ADV", "VVINF", "$,", "KON", "ART", "NN", "NE"], "meter": "--+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Die sich um, und bey, und an uns, \u00fcberall vor Augen legen;", "tokens": ["Die", "sich", "um", ",", "und", "bey", ",", "und", "an", "uns", ",", "\u00fc\u00b7be\u00b7rall", "vor", "Au\u00b7gen", "le\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKVZ", "$,", "KON", "PTKVZ", "$,", "KON", "APPR", "PPER", "$,", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Wie viel Millionen Guts zeigt die Qvell der W\u00e4rm\u2019 und", "tokens": ["Wie", "viel", "Mil\u00b7lion\u00b7en", "Guts", "zeigt", "die", "Qvell", "der", "W\u00e4rm'", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "NN", "VVFIN", "ART", "NN", "ART", "NN", "KON"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Auch des wundersch\u00f6nen Lichts und der Fruchtbarkeit, ", "tokens": ["Auch", "des", "wun\u00b7der\u00b7sch\u00f6\u00b7nen", "Lichts", "und", "der", "Frucht\u00b7bar\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Auf dem Erd-Kreis \u00fcberall! Was ist nicht im ", "tokens": ["Auf", "dem", "Erd\u00b7Kreis", "\u00fc\u00b7be\u00b7rall", "!", "Was", "ist", "nicht", "im"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "$.", "PWS", "VAFIN", "PTKNEG", "APPRART"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "In den ", "tokens": ["In", "den"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "In den ", "tokens": ["In", "den"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.14": {"text": "Und vor eine Wunder-Menge, uns allein zum Nutz, zu", "tokens": ["Und", "vor", "ei\u00b7ne", "Wun\u00b7der\u00b7Men\u00b7ge", ",", "uns", "al\u00b7lein", "zum", "Nutz", ",", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PPER", "ADV", "APPRART", "NN", "$,", "APPR"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.15": {"text": "Was hat nicht die ", "tokens": ["Was", "hat", "nicht", "die"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PTKNEG", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Da\u00df man sich nicht nur zur ", "tokens": ["Da\u00df", "man", "sich", "nicht", "nur", "zur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "PTKNEG", "ADV", "APPRART"], "meter": "+---+-", "measure": "dactylic.init"}, "line.17": {"text": "An mit kunst-verbundnen Wundern der Natur, zu aller", "tokens": ["An", "mit", "kunst\u00b7ver\u00b7bund\u00b7nen", "Wun\u00b7dern", "der", "Na\u00b7tur", ",", "zu", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "APPR", "ADJA", "NN", "ART", "NN", "$,", "APPR", "PIAT"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.18": {"text": "Durch Betrachtung und Erk\u00e4nntni\u00df, mit dem h\u00f6chsten", "tokens": ["Durch", "Be\u00b7trach\u00b7tung", "und", "Er\u00b7k\u00e4nnt\u00b7ni\u00df", ",", "mit", "dem", "h\u00f6chs\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.5": {"line.1": {"text": "La\u00dft uns denn der Dinge Menge, die uns ", "tokens": ["La\u00dft", "uns", "denn", "der", "Din\u00b7ge", "Men\u00b7ge", ",", "die", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "NN", "$,", "PRELS", "PPER"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Auch die uns dabey ", "tokens": ["Auch", "die", "uns", "da\u00b7bey"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "PPER", "PAV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Werden wir nur ihre Zahl, blos dem Nahmen nach,", "tokens": ["Wer\u00b7den", "wir", "nur", "ih\u00b7re", "Zahl", ",", "blos", "dem", "Nah\u00b7men", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "$,", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "M\u00f6gt\u2019 die Menge die erstaunlich, uns vielleicht zum Danck", "tokens": ["M\u00f6gt'", "die", "Men\u00b7ge", "die", "er\u00b7staun\u00b7lich", ",", "uns", "viel\u00b7leicht", "zum", "Danck"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "ART", "ADJD", "$,", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "Aller ", "tokens": ["Al\u00b7ler"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Das uns all\u2019 erfreu\u2019nde ", "tokens": ["Das", "uns", "all'", "er\u00b7freu'n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "PPER", "PIAT", "ADJA"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.8": {"text": "V\u00f6gel, wild- und zahme Thiere, Ochsen, K\u00fche, Schaaf'\nund Pferde,\nLaub und Kr\u00e4uter, Gras und Blumen, Brodt und K\u00e4se,\nWein und Bier,\nAepfel, Birne, Rocken, Weitzen, tausend Feld- und\nGarten-Fr\u00fcchte,", "tokens": ["V\u00f6\u00b7gel", ",", "wild", "und", "zah\u00b7me", "Thie\u00b7re", ",", "Och\u00b7sen", ",", "K\u00fc\u00b7he", ",", "Schaaf'", "und", "Pfer\u00b7de", ",", "Laub", "und", "Kr\u00e4u\u00b7ter", ",", "Gras", "und", "Blu\u00b7men", ",", "Brodt", "und", "K\u00e4\u00b7se", ",", "Wein", "und", "Bier", ",", "A\u00b7e\u00b7pfel", ",", "Bir\u00b7ne", ",", "Ro\u00b7cken", ",", "Weit\u00b7zen", ",", "tau\u00b7send", "Feld", "und", "Gar\u00b7ten\u00b7Fr\u00fcch\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "TRUNC", "KON", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "CARD", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Acker, Wiesen, Wald und Feld, tausend Land- und See-\nGerichte,", "tokens": ["A\u00b7cker", ",", "Wie\u00b7sen", ",", "Wald", "und", "Feld", ",", "tau\u00b7send", "Lan\u00b7d", "und", "See", "Ge\u00b7rich\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "CARD", "TRUNC", "KON", "TRUNC", "NN", "$,"], "meter": "+-+-+-+--+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.10": {"text": "Eyer, Milch und Mehl und Butter, B\u00fccher, Feder und\nPapier,", "tokens": ["Ey\u00b7er", ",", "Milch", "und", "Mehl", "und", "But\u00b7ter", ",", "B\u00fc\u00b7cher", ",", "Fe\u00b7der", "und", "Pa\u00b7pier", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Rede, Schriften, und Erfindung, Arbeit, Ruhe,\ns\u00fcsse Tr\u00e4ume,", "tokens": ["Re\u00b7de", ",", "Schrif\u00b7ten", ",", "und", "Er\u00b7fin\u00b7dung", ",", "Ar\u00b7beit", ",", "Ru\u00b7he", ",", "s\u00fcs\u00b7se", "Tr\u00e4u\u00b7me", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.12": {"text": "Weiche Betten, Tuch und Decken, Speise, Tranck,\nBeqvemlichkeit,", "tokens": ["Wei\u00b7che", "Bet\u00b7ten", ",", "Tuch", "und", "De\u00b7cken", ",", "Spei\u00b7se", ",", "Tranck", ",", "Be\u00b7qvem\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.13": {"text": "Peltzwerck, Haus-Ger\u00e4hte, Zimmer, Freyheit, Friede,\nSicherheit,", "tokens": ["Pelt\u00b7zwerck", ",", "Haus\u00b7Ge\u00b7r\u00e4h\u00b7te", ",", "Zim\u00b7mer", ",", "Frey\u00b7heit", ",", "Frie\u00b7de", ",", "Si\u00b7cher\u00b7heit", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.14": {"text": "H\u00e4user, G\u00e4rten, St\u00e4ll' und Scheuren, Vorwerck, Obst-\nund wilde B\u00e4ume,", "tokens": ["H\u00e4u\u00b7ser", ",", "G\u00e4r\u00b7ten", ",", "St\u00e4ll'", "und", "Scheu\u00b7ren", ",", "Vor\u00b7werck", ",", "Obst", "und", "wil\u00b7de", "B\u00e4u\u00b7me", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "TRUNC", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.6": {"line.1": {"text": "Fuhr-Werck, Futter f\u00fcr das Vieh, Knecht' und M\u00e4gde,\nHanf und Flachs,\nDistillier-Kunst, Tisch und St\u00fchle, Druckereyen, Far-\nben, Wachs,", "tokens": ["Fuhr\u00b7\u00b7Werck", ",", "Fut\u00b7ter", "f\u00fcr", "das", "Vieh", ",", "Knecht'", "und", "M\u00e4g\u00b7de", ",", "Hanf", "und", "Flachs", ",", "Di\u00b7stil\u00b7lier\u00b7Kunst", ",", "Tisch", "und", "St\u00fch\u00b7le", ",", "Dru\u00b7cke\u00b7re\u00b7yen", ",", "Fa\u00b7r", "ben", ",", "Wachs", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "APPR", "ART", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "VVINF", "$,", "NN", "$,"], "meter": "+-+-+-+--+-+-+-+--+-+-+-+-+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Mancherley ", "tokens": ["Man\u00b7cher\u00b7ley"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Schirm vor Frost, vor Sturm und Nebel, vor dem Re-\ngen Dach und Fach,\nBrenn-Holtz, Nahrung, Erbschaft, Freunde, Fleis,\nGesundheit, Appetit,", "tokens": ["Schirm", "vor", "Frost", ",", "vor", "Sturm", "und", "Ne\u00b7bel", ",", "vor", "dem", "Re", "gen", "Dach", "und", "Fach", ",", "Brenn\u00b7Holtz", ",", "Nah\u00b7rung", ",", "Erb\u00b7schaft", ",", "Freun\u00b7de", ",", "Fleis", ",", "Ge\u00b7sund\u00b7heit", ",", "Ap\u00b7pe\u00b7tit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN", "$,", "APPR", "ART", "TRUNC", "APPR", "NN", "KON", "NN", "$,", "NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Wolgerahtne Kinder, Eltern, gut Gemahl, und\nAnverwandte,", "tokens": ["Wol\u00b7ge\u00b7raht\u00b7ne", "Kin\u00b7der", ",", "El\u00b7tern", ",", "gut", "Ge\u00b7mahl", ",", "und", "An\u00b7ver\u00b7wand\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "ADJD", "NN", "$,", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Obrigkeiten, Z\u00fcnfte, St\u00e4nde, gute Nachtbarschaft,\nBekannte,", "tokens": ["Ob\u00b7rig\u00b7kei\u00b7ten", ",", "Z\u00fcnf\u00b7te", ",", "St\u00e4n\u00b7de", ",", "gu\u00b7te", "Nacht\u00b7bar\u00b7schaft", ",", "Be\u00b7kann\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "$,", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Schiffahrt, Handel, Geld und Baarschaft, Habe,\nKaufmannschaft, Credit,", "tokens": ["Schif\u00b7fahrt", ",", "Han\u00b7del", ",", "Geld", "und", "Baar\u00b7schaft", ",", "Ha\u00b7be", ",", "Kauf\u00b7mann\u00b7schaft", ",", "Cre\u00b7dit", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Ueberlegung, gute Neigung, Wissenschaften und Vernunft,", "tokens": ["Ue\u00b7ber\u00b7le\u00b7gung", ",", "gu\u00b7te", "Nei\u00b7gung", ",", "Wis\u00b7sen\u00b7schaf\u00b7ten", "und", "Ver\u00b7nunft", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Witz, Begrif, Ged\u00e4chtni\u00df, K\u00fcnste, K\u00fcnstler, Hand-\nwerck, Artzeney,", "tokens": ["Witz", ",", "Be\u00b7grif", ",", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", ",", "K\u00fcns\u00b7te", ",", "K\u00fcnst\u00b7ler", ",", "Han\u00b7d", "werck", ",", "Art\u00b7ze\u00b7ney", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "TRUNC", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.9": {"text": "Poesie, Mathesis, Schulen, Recht, Music und\nMahlerey,", "tokens": ["Poe\u00b7sie", ",", "Ma\u00b7the\u00b7sis", ",", "Schu\u00b7len", ",", "Recht", ",", "Mu\u00b7sic", "und", "Mah\u00b7le\u00b7rey", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}, "line.10": {"text": "Ein Vergn\u00fcgen an der Arbeit, fr\u00f6liche Zusammenkunft,", "tokens": ["Ein", "Ver\u00b7gn\u00fc\u00b7gen", "an", "der", "Ar\u00b7beit", ",", "fr\u00f6\u00b7li\u00b7che", "Zu\u00b7sam\u00b7men\u00b7kunft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Schutz vor Ueberfall, Verdienst, Sprachen und Ge-\nschicklichkeit,", "tokens": ["Schutz", "vor", "Ue\u00b7ber\u00b7fall", ",", "Ver\u00b7dienst", ",", "Spra\u00b7chen", "und", "Ge", "schick\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "$,", "NN", "KON", "TRUNC", "NN", "$,"], "meter": "+-+-+-++-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.12": {"text": "Ueberflu\u00df, ein redlich Hertz, Billigkeit, Zufriedenheit,", "tokens": ["Ue\u00b7berf\u00b7lu\u00df", ",", "ein", "red\u00b7lich", "Hertz", ",", "Bil\u00b7lig\u00b7keit", ",", "Zu\u00b7frie\u00b7den\u00b7heit", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJD", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-++-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.13": {"text": "Hofnung, Zuflucht, Trost im Ungl\u00fcck, mit Bedacht\nspatzieren gehen,", "tokens": ["Hof\u00b7nung", ",", "Zu\u00b7flucht", ",", "Trost", "im", "Un\u00b7gl\u00fcck", ",", "mit", "Be\u00b7dacht", "spat\u00b7zie\u00b7ren", "ge\u00b7hen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPRART", "NN", "$,", "APPR", "NN", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.14": {"text": "Und, nebst dienlicher ", "tokens": ["Und", ",", "nebst", "dien\u00b7li\u00b7cher"], "token_info": ["word", "punct", "word", "word"], "pos": ["KON", "$,", "APPR", "PDAT"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.15": {"text": "Nicht zu heftige Begierden, ein beqvemer Auffenthalt,", "tokens": ["Nicht", "zu", "hef\u00b7ti\u00b7ge", "Be\u00b7gier\u00b7den", ",", "ein", "be\u00b7qve\u00b7mer", "Auf\u00b7fent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.16": {"text": "Guter Anstand in den Sitten, eine leidliche Gestalt,", "tokens": ["Gu\u00b7ter", "An\u00b7stand", "in", "den", "Sit\u00b7ten", ",", "ei\u00b7ne", "leid\u00b7li\u00b7che", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.7": {"line.1": {"text": "Nebst viel ", "tokens": ["Nebst", "viel"], "token_info": ["word", "word"], "pos": ["APPR", "PIAT"], "meter": "--", "measure": "unknown.measure.zero"}, "line.2": {"text": "Wie sie die Natur uns beut, wir geschickt uns zu ergetzen.", "tokens": ["Wie", "sie", "die", "Na\u00b7tur", "uns", "beut", ",", "wir", "ge\u00b7schickt", "uns", "zu", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der so holden ", "tokens": ["Der", "so", "hol\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADV", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "D\u00e4mmrung, Fr\u00fch- und Abend-R\u00f6the, in des Himmels\ntieffen Ferne\nSo viel gl\u00e4ntzende Planeten, so viel Millionen Sterne,", "tokens": ["D\u00e4mm\u00b7rung", ",", "Fr\u00fch", "und", "A\u00b7ben\u00b7dR\u00f6\u00b7the", ",", "in", "des", "Him\u00b7mels", "tief\u00b7fen", "Fer\u00b7ne", "So", "viel", "gl\u00e4nt\u00b7zen\u00b7de", "Pla\u00b7ne\u00b7ten", ",", "so", "viel", "Mil\u00b7lion\u00b7en", "Ster\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "TRUNC", "KON", "NN", "$,", "APPR", "ART", "NN", "ADJA", "NN", "ADV", "PIAT", "ADJA", "NN", "$,", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-+-+--+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Und, auf unsrer Welt, f\u00fcr uns, ", "tokens": ["Und", ",", "auf", "uns\u00b7rer", "Welt", ",", "f\u00fcr", "uns", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPER", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Die so n\u00fctzliche ", "tokens": ["Die", "so", "n\u00fctz\u00b7li\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADV", "ADJA"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.7": {"text": "Kupfer, Stahl und Zinn und Me\u00dfing, Salben, Oel\nund Specerey,", "tokens": ["Kup\u00b7fer", ",", "Stahl", "und", "Zinn", "und", "Me\u00b7\u00dfing", ",", "Sal\u00b7ben", ",", "O\u00b7el", "und", "Spe\u00b7ce\u00b7rey", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.8": {"text": "Aus so weit entfernten L\u00e4ndern, ", "tokens": ["Aus", "so", "weit", "ent\u00b7fern\u00b7ten", "L\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Die zu Land, und durch die ", "tokens": ["Die", "zu", "Land", ",", "und", "durch", "die"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "$,", "KON", "APPR", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Holde Blumen in dem Fr\u00fchling, und im Herbst den s\u00fcs-\nsen Most,", "tokens": ["Hol\u00b7de", "Blu\u00b7men", "in", "dem", "Fr\u00fch\u00b7ling", ",", "und", "im", "Herbst", "den", "s\u00fcs", "sen", "Most", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$,", "KON", "APPRART", "NN", "ART", "TRUNC", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Ansehn und ein gut Gewissen, GOttes-Furcht, ein gut\nExempel,", "tokens": ["An\u00b7sehn", "und", "ein", "gut", "Ge\u00b7wis\u00b7sen", ",", "Got\u00b7tes\u00b7Furcht", ",", "ein", "gut", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "ADJD", "NN", "$,", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "+--+--+-+-+--+-+", "measure": "dactylic.di.plus"}, "line.12": {"text": "Ruhigs Schlafen, muntres Wachen, fr\u00f6lichs Essen,\nEhr' und Ruhm,\nHofnung, Freudigkeit, Erk\u00e4nntni\u00df, Menschen-Liebe,\nChristenthum,", "tokens": ["Ru\u00b7higs", "Schla\u00b7fen", ",", "mun\u00b7tres", "Wa\u00b7chen", ",", "fr\u00f6\u00b7lichs", "Es\u00b7sen", ",", "Ehr'", "und", "Ruhm", ",", "Hof\u00b7nung", ",", "Freu\u00b7dig\u00b7keit", ",", "Er\u00b7k\u00e4nnt\u00b7ni\u00df", ",", "Men\u00b7schen\u00b7Lie\u00b7be", ",", "Chris\u00b7ten\u00b7thum", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.13": {"text": "Flei\u00df, Gesetze, gute Lehrer, Ordnung, Policey und Tempel.", "tokens": ["Flei\u00df", ",", "Ge\u00b7set\u00b7ze", ",", "gu\u00b7te", "Leh\u00b7rer", ",", "Ord\u00b7nung", ",", "Po\u00b7li\u00b7cey", "und", "Tem\u00b7pel", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADJA", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.8": {"line.1": {"text": "Ausser noch viel andern G\u00fctern, Leibes-Gl\u00fccks-und See-\nlen-Gaben,", "tokens": ["Aus\u00b7ser", "noch", "viel", "an\u00b7dern", "G\u00fc\u00b7tern", ",", "Lei\u00b7bes\u00b7G\u00b7l\u00fccks\u00b7\u00b7und", "See", "len\u00b7Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIAT", "ADJA", "NN", "$,", "NN", "TRUNC", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Die wir von des Sch\u00f6pfers Weisheit, Macht und Lieb'\nempfangen haben.", "tokens": ["Die", "wir", "von", "des", "Sch\u00f6p\u00b7fers", "Weis\u00b7heit", ",", "Macht", "und", "Lieb'", "emp\u00b7fan\u00b7gen", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "NN", "$,", "NN", "KON", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.9": {"line.1": {"text": "Wann nun auch entferntes Uebel ebenfals ein Gl\u00fcck", "tokens": ["Wann", "nun", "auch", "ent\u00b7fern\u00b7tes", "Ue\u00b7bel", "e\u00b7ben\u00b7fals", "ein", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ADJA", "NN", "ADV", "ART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "M\u00fcssen wir auch deren Mangel billig als ein Gl\u00fcck erkennen.", "tokens": ["M\u00fcs\u00b7sen", "wir", "auch", "de\u00b7ren", "Man\u00b7gel", "bil\u00b7lig", "als", "ein", "Gl\u00fcck", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PRELAT", "NN", "ADJD", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "La\u00dft uns denn auch davon etwas uns zum Trost annoch", "tokens": ["La\u00dft", "uns", "denn", "auch", "da\u00b7von", "et\u00b7was", "uns", "zum", "Trost", "an\u00b7noch"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ADV", "PAV", "ADV", "PPER", "APPRART", "NN", "ADV"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "Und mit Ehrfurcht, da\u00df der Sch\u00f6pfer uns daf\u00fcr bewahrt,", "tokens": ["Und", "mit", "Ehr\u00b7furcht", ",", "da\u00df", "der", "Sch\u00f6p\u00b7fer", "uns", "da\u00b7f\u00fcr", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "KOUS", "ART", "NN", "PPER", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "Theurung, Krieg und Tyranney, Ha\u00df, Verachtung,\nUngedult,", "tokens": ["Theu\u00b7rung", ",", "Krieg", "und", "Ty\u00b7ran\u00b7ney", ",", "Ha\u00df", ",", "Ver\u00b7ach\u00b7tung", ",", "Un\u00b7ge\u00b7dult", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Trauer, Zwang, Verlust und Bande, Schifbruch,\nUeberschwemmung, Brand,", "tokens": ["Trau\u00b7er", ",", "Zwang", ",", "Ver\u00b7lust", "und", "Ban\u00b7de", ",", "Schif\u00b7bruch", ",", "Ue\u00b7ber\u00b7schwem\u00b7mung", ",", "Brand", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Aufruhr, ungerahtne Kinder, Schimpf, Verl\u00e4umdung,\nUnverstand,", "tokens": ["Auf\u00b7ruhr", ",", "un\u00b7ge\u00b7raht\u00b7ne", "Kin\u00b7der", ",", "Schimpf", ",", "Ver\u00b7l\u00e4um\u00b7dung", ",", "Un\u00b7ver\u00b7stand", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Zanck und Rachgier, Zagheit, Eifer, Schand' und Un-\nvers\u00f6hnlichkeit,", "tokens": ["Zanck", "und", "Rach\u00b7gier", ",", "Zag\u00b7heit", ",", "Ei\u00b7fer", ",", "Schand'", "und", "Un", "ver\u00b7s\u00f6hn\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "TRUNC", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Schrecken, Uebermuth und Unflei\u00df, Tummheit, Un-\nzufriedenheit,", "tokens": ["Schre\u00b7cken", ",", "Ue\u00b7ber\u00b7muth", "und", "Un\u00b7flei\u00df", ",", "Tumm\u00b7heit", ",", "Un", "zu\u00b7frie\u00b7den\u00b7heit", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "TRUNC", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.10": {"text": "Diebe, R\u00e4uber, und Verf\u00fchrer, Unbeqvehmlichkeit\nund Pein,\nStreit, Verbannung, Ueberdru\u00df, Spott wenn wir in\nN\u00f6then seyn,", "tokens": ["Die\u00b7be", ",", "R\u00e4u\u00b7ber", ",", "und", "Ver\u00b7f\u00fch\u00b7rer", ",", "Un\u00b7be\u00b7qvehm\u00b7lich\u00b7keit", "und", "Pein", ",", "Streit", ",", "Ver\u00b7ban\u00b7nung", ",", "Ue\u00b7berd\u00b7ru\u00df", ",", "Spott", "wenn", "wir", "in", "N\u00f6\u00b7then", "seyn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "KON", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KOUS", "PPER", "APPR", "NN", "VAINF", "$,"], "meter": "+-+-+-+-+-+-+-+--+-+--+-+-+-+", "measure": "trochaic.octa.plus"}, "line.11": {"text": "Neid, Belagerung', Verfolgung, Mord, Verrath,\nBetrug und Feinde,\nKummer, Vergewaltigung, Jrrthum, Thorheit,\nfalsche Freunde.", "tokens": ["Neid", ",", "Be\u00b7la\u00b7ge\u00b7rung'", ",", "Ver\u00b7fol\u00b7gung", ",", "Mord", ",", "Ver\u00b7rath", ",", "Be\u00b7trug", "und", "Fein\u00b7de", ",", "Kum\u00b7mer", ",", "Ver\u00b7ge\u00b7wal\u00b7ti\u00b7gung", ",", "Jrr\u00b7thum", ",", "Thor\u00b7heit", ",", "fal\u00b7sche", "Freun\u00b7de", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-+-+-+--+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.10": {"line.1": {"text": "Dieses sey vor dieses mahl nun genug. Wo in der", "tokens": ["Die\u00b7ses", "sey", "vor", "die\u00b7ses", "mahl", "nun", "ge\u00b7nug", ".", "Wo", "in", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "PDAT", "ADV", "ADV", "ADV", "$.", "PWAV", "APPR", "ART"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Etwas \u00fcberzeigendes, da\u00df wir GOtt zum Danck verbunden;", "tokens": ["Et\u00b7was", "\u00fc\u00b7berz\u00b7ei\u00b7gen\u00b7des", ",", "da\u00df", "wir", "Gott", "zum", "Danck", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "$,", "KOUS", "PPER", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Wird es in der grossen Menge seiner Gaben ja gefunden,", "tokens": ["Wird", "es", "in", "der", "gros\u00b7sen", "Men\u00b7ge", "sei\u00b7ner", "Ga\u00b7ben", "ja", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "ADJA", "NN", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Die er uns nicht nur geschencket, die er uns so lang\u2019 erh\u00e4lt.", "tokens": ["Die", "er", "uns", "nicht", "nur", "ge\u00b7schen\u00b7cket", ",", "die", "er", "uns", "so", "lang'", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PRF", "PTKNEG", "ADV", "VVPP", "$,", "PRELS", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.5": {"text": "M\u00f6gten wir ein solch Register dann und wann nur \u00fcber-", "tokens": ["M\u00f6g\u00b7ten", "wir", "ein", "solch", "Re\u00b7gis\u00b7ter", "dann", "und", "wann", "nur", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "PIAT", "NN", "ADV", "KON", "PWAV", "ADV", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.6": {"text": "Sollte man fast hoffen m\u00fcssen, von der Unempfindlichkeit,", "tokens": ["Soll\u00b7te", "man", "fast", "hof\u00b7fen", "m\u00fcs\u00b7sen", ",", "von", "der", "Un\u00b7emp\u00b7find\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "VVINF", "VMINF", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Von dem schwartzen Undancks-Laster, ungerechtem", "tokens": ["Von", "dem", "schwart\u00b7zen", "Un\u00b7dancks\u00b7Las\u00b7ter", ",", "un\u00b7ge\u00b7rech\u00b7tem"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Von der selbst-gemachten Schwermuth, Klag\u2019 und Mur-", "tokens": ["Von", "der", "selbst\u00b7ge\u00b7mach\u00b7ten", "Schwer\u00b7muth", ",", "Klag'", "und", "Mur"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "NN", "KON", "TRUNC"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Sonderlich wenn wir erwegen, wie doch so gering\u2019 und", "tokens": ["Son\u00b7der\u00b7lich", "wenn", "wir", "er\u00b7we\u00b7gen", ",", "wie", "doch", "so", "ge\u00b7ring'", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "$,", "PWAV", "ADV", "ADV", "ADJD", "KON"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.10": {"text": "Unser aller W\u00fcrdigkeiten, menschliche Verdienste seyn.", "tokens": ["Un\u00b7ser", "al\u00b7ler", "W\u00fcr\u00b7dig\u00b7kei\u00b7ten", ",", "menschli\u00b7che", "Ver\u00b7diens\u00b7te", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "$,", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}}}}}