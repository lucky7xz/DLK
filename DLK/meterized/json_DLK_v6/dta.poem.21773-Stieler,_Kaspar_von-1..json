{"dta.poem.21773": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn mich mein Kind wil traurig sehn", "tokens": ["Wenn", "mich", "mein", "Kind", "wil", "trau\u00b7rig", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VMFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und Blut au\u00df meinem Herzen pressen", "tokens": ["und", "Blut", "au\u00df", "mei\u00b7nem", "Her\u00b7zen", "pres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sag/ Rosilis/ Ach! meine Fromme:", "tokens": ["Sag", "/", "Ro\u00b7si\u00b7lis", "/", "Ach", "!", "mei\u00b7ne", "From\u00b7me", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "NE", "$(", "ITJ", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Woher dir doch der Argwohn komme.", "tokens": ["Wo\u00b7her", "dir", "doch", "der", "Arg\u00b7wohn", "kom\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hat ein verboo\u00dfter L\u00e4ster-Mund", "tokens": ["Hat", "ein", "ver\u00b7boo\u00df\u00b7ter", "L\u00e4s\u00b7ter\u00b7Mund"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mich irgend bey dir angegeben:", "tokens": ["mich", "ir\u00b7gend", "bey", "dir", "an\u00b7ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bekenn es/ Rosilis/ mein Leben/", "tokens": ["Be\u00b7kenn", "es", "/", "Ro\u00b7si\u00b7lis", "/", "mein", "Le\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "NE", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "thu mir die falschen L\u00fcgen kund.", "tokens": ["thu", "mir", "die", "fal\u00b7schen", "L\u00fc\u00b7gen", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch offenbahrung/ Red\u2019 und Frage", "tokens": ["Durch", "of\u00b7fen\u00b7bah\u00b7rung", "/", "Red'", "und", "Fra\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wird offt gewehrt der b\u00f6sen Sage.", "tokens": ["wird", "offt", "ge\u00b7wehrt", "der", "b\u00f6\u00b7sen", "Sa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich bin ja mir wol nicht bewust", "tokens": ["Ich", "bin", "ja", "mir", "wol", "nicht", "be\u00b7wust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "ADV", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ich mich wor vergriffen h\u00e4tte.", "tokens": ["da\u00df", "ich", "mich", "wor", "ver\u00b7grif\u00b7fen", "h\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "NE", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lang ich hang\u2019 an deine Kette/", "tokens": ["So", "lang", "ich", "hang'", "an", "dei\u00b7ne", "Ket\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und deine Gunst r\u00fchrt meine Brust:", "tokens": ["und", "dei\u00b7ne", "Gunst", "r\u00fchrt", "mei\u00b7ne", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist nichts geschehn mit meinem wissen", "tokens": ["Ist", "nichts", "ge\u00b7schehn", "mit", "mei\u00b7nem", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "VVPP", "APPR", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "drau\u00df du was b\u00f6ses k\u00f6ntest schliessen.", "tokens": ["drau\u00df", "du", "was", "b\u00f6\u00b7ses", "k\u00f6n\u00b7test", "schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PIS", "ADJA", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Kein einger Mund hat mich ger\u00fchrt", "tokens": ["Kein", "ein\u00b7ger", "Mund", "hat", "mich", "ge\u00b7r\u00fchrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hastu mich wo mit einer scherzen", "tokens": ["Has\u00b7tu", "mich", "wo", "mit", "ei\u00b7ner", "scher\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PWAV", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "gesehn? Wor Heucheley gesp\u00fcrt?", "tokens": ["ge\u00b7sehn", "?", "Wor", "Heu\u00b7che\u00b7ley", "ge\u00b7sp\u00fcrt", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ader wolt\u2019 ich au\u00df mir reissen", "tokens": ["Die", "A\u00b7der", "wolt'", "ich", "au\u00df", "mir", "reis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und selber vor die Hunde schmeissen.", "tokens": ["und", "sel\u00b7ber", "vor", "die", "Hun\u00b7de", "schmeis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich bin und werd\u2019 auch ewig sein", "tokens": ["Ich", "bin", "und", "werd'", "auch", "e\u00b7wig", "sein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KON", "VAFIN", "ADV", "ADJD", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie ich mich einmahl dir versprochen/", "tokens": ["wie", "ich", "mich", "ein\u00b7mahl", "dir", "ver\u00b7spro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mein Eyd verbleibet unzerbrochen/", "tokens": ["mein", "Eyd", "ver\u00b7blei\u00b7bet", "un\u00b7zer\u00b7bro\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Erde nimmer feste stehen", "tokens": ["die", "Er\u00b7de", "nim\u00b7mer", "fes\u00b7te", "ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und alles drunt- und dr\u00fcber gehen.", "tokens": ["und", "al\u00b7les", "drunt", "und", "dr\u00fc\u00b7ber", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "TRUNC", "KON", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar r\u00fchm\u2019 ich meine Liebe nicht", "tokens": ["Zwar", "r\u00fchm'", "ich", "mei\u00b7ne", "Lie\u00b7be", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie der wol hundert Schw\u00fcre machet", "tokens": ["wie", "der", "wol", "hun\u00b7dert", "Schw\u00fc\u00b7re", "ma\u00b7chet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADV", "CARD", "NN", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "indessen unterm Hute lachet/", "tokens": ["in\u00b7des\u00b7sen", "un\u00b7term", "Hu\u00b7te", "la\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hab\u2019 ich dir schon ins Angesicht", "tokens": ["hab'", "ich", "dir", "schon", "ins", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "niemahl von grosser Gunst gepralet", "tokens": ["nie\u00b7mahl", "von", "gros\u00b7ser", "Gunst", "ge\u00b7pra\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und falsche Berge hingemahlet;", "tokens": ["und", "fal\u00b7sche", "Ber\u00b7ge", "hin\u00b7ge\u00b7mah\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So wei\u00df es doch mein Herz allein/", "tokens": ["So", "wei\u00df", "es", "doch", "mein", "Herz", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mein Herz/ da\u00df dich/ sonst keine kennet/", "tokens": ["mein", "Herz", "/", "da\u00df", "dich", "/", "sonst", "kei\u00b7ne", "ken\u00b7net", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "KOUS", "PPER", "$(", "ADV", "PIAT", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und nur in deinen Flammen brennet/", "tokens": ["und", "nur", "in", "dei\u00b7nen", "Flam\u00b7men", "bren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df du die einige wirst sein/", "tokens": ["da\u00df", "du", "die", "ei\u00b7ni\u00b7ge", "wirst", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PIS", "VAFIN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die/ bi\u00df der Tod mich auff-wird reiben/", "tokens": ["die", "/", "bi\u00df", "der", "Tod", "mich", "auf\u00b7fwird", "rei\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "APPR", "ART", "NN", "PRF", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Di\u00df schwer\u2019 ich bey der sch\u00f6nen Lust", "tokens": ["Di\u00df", "schwer'", "ich", "bey", "der", "sch\u00f6\u00b7nen", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "bey denen Freuden-vollen Stunden/", "tokens": ["bey", "de\u00b7nen", "Freu\u00b7den\u00b7vol\u00b7len", "Stun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJA", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "die wir so offtermahls empfunden:", "tokens": ["die", "wir", "so", "off\u00b7ter\u00b7mahls", "emp\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey dein- und meiner treuen Brust.", "tokens": ["Bey", "dein", "und", "mei\u00b7ner", "treu\u00b7en", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich wil ich nimmermehr vergessen.", "tokens": ["Dich", "wil", "ich", "nim\u00b7mer\u00b7mehr", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So h\u00f6r doch auff mein Herz zufressen.", "tokens": ["So", "h\u00f6r", "doch", "auff", "mein", "Herz", "zu\u00b7fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}