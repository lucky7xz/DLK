{"dta.poem.3097": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "142.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Das Leben ist zu kurz, um alles zu erlernen,", "tokens": ["Das", "Le\u00b7ben", "ist", "zu", "kurz", ",", "um", "al\u00b7les", "zu", "er\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "APPR", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was lernensw\u00fcrdig ist im Nahen und im Fernen.", "tokens": ["Was", "ler\u00b7nens\u00b7w\u00fcr\u00b7dig", "ist", "im", "Na\u00b7hen", "und", "im", "Fer\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "APPRART", "NN", "KON", "APPRART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Allein die Ewigkeit ist lang genug dazu;", "tokens": ["Al\u00b7lein", "die", "E\u00b7wig\u00b7keit", "ist", "lang", "ge\u00b7nug", "da\u00b7zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "ADJD", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Aussicht freue dich, Geist, ewig lernest du.", "tokens": ["Der", "Aus\u00b7sicht", "freu\u00b7e", "dich", ",", "Geist", ",", "e\u00b7wig", "ler\u00b7nest", "du", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "NN", "$,", "ADJD", "VVFIN", "PPER", "$."], "meter": "-+-+--++-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Und ewig lernest du nicht aus, denn ewig streckt", "tokens": ["Und", "e\u00b7wig", "ler\u00b7nest", "du", "nicht", "aus", ",", "denn", "e\u00b7wig", "streckt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Ew'ge weiter sich, das Ziel um Ziel dir steckt.", "tokens": ["Das", "Ew'\u00b7ge", "wei\u00b7ter", "sich", ",", "das", "Ziel", "um", "Ziel", "dir", "steckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "PRF", "$,", "ART", "NN", "APPR", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Nicht Ein Ziel, sondern eins ums andre zu gewinnen,", "tokens": ["Nicht", "Ein", "Ziel", ",", "son\u00b7dern", "eins", "ums", "and\u00b7re", "zu", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "KON", "PIS", "APPRART", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beginne muthig nur das endlose Beginnen!", "tokens": ["Be\u00b7gin\u00b7ne", "mut\u00b7hig", "nur", "das", "end\u00b7lo\u00b7se", "Be\u00b7gin\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Lern' alles was du magst! nichts ist ganz unerheblich;", "tokens": ["Lern'", "al\u00b7les", "was", "du", "magst", "!", "nichts", "ist", "ganz", "un\u00b7er\u00b7heb\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PWS", "PPER", "VMFIN", "$.", "PIS", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auch das Vergebliche gelernt ist nicht vergeblich.", "tokens": ["Auch", "das", "Ver\u00b7geb\u00b7li\u00b7che", "ge\u00b7lernt", "ist", "nicht", "ver\u00b7geb\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Du lerntest wenigstens die gro\u00dfe Kunst daran,", "tokens": ["Du", "lern\u00b7test", "we\u00b7nigs\u00b7tens", "die", "gro\u00b7\u00dfe", "Kunst", "da\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu lernen. Alles lernt, wer erst das Lernen kan.", "tokens": ["Zu", "ler\u00b7nen", ".", "Al\u00b7les", "lernt", ",", "wer", "erst", "das", "Ler\u00b7nen", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "PIS", "VVFIN", "$,", "PWS", "ADV", "ART", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}