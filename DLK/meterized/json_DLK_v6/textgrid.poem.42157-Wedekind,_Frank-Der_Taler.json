{"textgrid.poem.42157": {"metadata": {"author": {"name": "Wedekind, Frank", "birth": "N.A.", "death": "N.A."}, "title": "Der Taler", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Blitzt der Taler im Sonnenschein,", "tokens": ["Blitzt", "der", "Ta\u00b7ler", "im", "Son\u00b7nen\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Blitzt dem Kind in die Augen hinein,", "tokens": ["Blitzt", "dem", "Kind", "in", "die", "Au\u00b7gen", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "\u00dcber die Wangen rollen die Tr\u00e4nen.", "tokens": ["\u00dc\u00b7ber", "die", "Wan\u00b7gen", "rol\u00b7len", "die", "Tr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Mutter zieht gar ein ernst Gesicht:", "tokens": ["Mut\u00b7ter", "zieht", "gar", "ein", "ernst", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Vor dem Taler, Schatz, f\u00fcrchte dich nicht;", "tokens": ["Vor", "dem", "Ta\u00b7ler", ",", "Schatz", ",", "f\u00fcrch\u00b7te", "dich", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+---+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Nach dem Taler sollst du dich sehnen.", "tokens": ["Nach", "dem", "Ta\u00b7ler", "sollst", "du", "dich", "seh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Sieh, mein Herzblatt, auf Gottes Welt", "tokens": ["Sieh", ",", "mein", "Herz\u00b7blatt", ",", "auf", "Got\u00b7tes", "Welt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "APPR", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "F\u00fcr uns Menschen gibt's nichts ohne Geld,", "tokens": ["F\u00fcr", "uns", "Men\u00b7schen", "gibt's", "nichts", "oh\u00b7ne", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "VVFIN", "PIS", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "H\u00e4tt ich dich, Herzblatt, auch nicht bekommen.", "tokens": ["H\u00e4tt", "ich", "dich", ",", "Herz\u00b7blatt", ",", "auch", "nicht", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "NN", "$,", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Bist noch so unschuldig, noch so klein,", "tokens": ["Bist", "noch", "so", "un\u00b7schul\u00b7dig", ",", "noch", "so", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "$,", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Willst doch t\u00e4glich gef\u00fcttert sein,", "tokens": ["Willst", "doch", "t\u00e4g\u00b7lich", "ge\u00b7f\u00fct\u00b7tert", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADJD", "VVPP", "VAINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Hast es mir selbst aus der Tasche genommen.", "tokens": ["Hast", "es", "mir", "selbst", "aus", "der", "Ta\u00b7sche", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.3": {"line.1": {"text": "Darfst nicht weinen, bist all mein Gl\u00fcck;", "tokens": ["Darfst", "nicht", "wei\u00b7nen", ",", "bist", "all", "mein", "Gl\u00fcck", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKNEG", "VVINF", "$,", "VAFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Gibst mir's tausendf\u00e4ltig zur\u00fcck.", "tokens": ["Gibst", "mir's", "tau\u00b7send\u00b7f\u00e4l\u00b7tig", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJD", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Sieh, die goldene Sonne dort oben,", "tokens": ["Sieh", ",", "die", "gol\u00b7de\u00b7ne", "Son\u00b7ne", "dort", "o\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "ADV", "ADV", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Brennt sie dir gleich deine Guckaugen wund,", "tokens": ["Brennt", "sie", "dir", "gleich", "dei\u00b7ne", "Guc\u00b7kau\u00b7gen", "wund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.5": {"text": "N\u00e4hrt und beh\u00fctet den Erdenrund,", "tokens": ["N\u00e4hrt", "und", "be\u00b7h\u00fc\u00b7tet", "den", "Er\u00b7den\u00b7rund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "Da\u00df alle Kreaturen sie loben.", "tokens": ["Da\u00df", "al\u00b7le", "Kre\u00b7a\u00b7tu\u00b7ren", "sie", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Nach der Sonne in goldiger Pracht", "tokens": ["Nach", "der", "Son\u00b7ne", "in", "gol\u00b7di\u00b7ger", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Haben die Menschen ihr Geld gemacht;", "tokens": ["Ha\u00b7ben", "die", "Men\u00b7schen", "ihr", "Geld", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Ohne das Geld mu\u00df man elend sterben.", "tokens": ["Oh\u00b7ne", "das", "Geld", "mu\u00df", "man", "e\u00b7lend", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Sonne ist Gl\u00fcck und Gl\u00fcck ist Geld;", "tokens": ["Son\u00b7ne", "ist", "Gl\u00fcck", "und", "Gl\u00fcck", "ist", "Geld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "KON", "NN", "VAFIN", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Wem es nicht schon in die Wiege f\u00e4llt,", "tokens": ["Wem", "es", "nicht", "schon", "in", "die", "Wie\u00b7ge", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Der mu\u00df es m\u00fchevoll sich erwerben.", "tokens": ["Der", "mu\u00df", "es", "m\u00fc\u00b7he\u00b7voll", "sich", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Sieh, mein Herzblatt, den gr\u00fcnen Wald,", "tokens": ["Sieh", ",", "mein", "Herz\u00b7blatt", ",", "den", "gr\u00fc\u00b7nen", "Wald", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Drin der V\u00f6gel Gezwitscher erschallt;", "tokens": ["Drin", "der", "V\u00f6\u00b7gel", "Ge\u00b7zwit\u00b7scher", "er\u00b7schallt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Wie das so lieblich ist anzuschauen!", "tokens": ["Wie", "das", "so", "lieb\u00b7lich", "ist", "an\u00b7zu\u00b7schau\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ADV", "ADJD", "VAFIN", "VVIZU", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hast du kein Geld f\u00fcr das morgige Brot,", "tokens": ["Hast", "du", "kein", "Geld", "f\u00fcr", "das", "mor\u00b7gi\u00b7ge", "Brot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "---+--+--+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dir sind all die V\u00f6gelein tot,", "tokens": ["Dir", "sind", "all", "die", "V\u00f6\u00b7ge\u00b7lein", "tot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Und der Wald ist ein schrecklich Grauen!", "tokens": ["Und", "der", "Wald", "ist", "ein", "schreck\u00b7lich", "Grau\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Geld ist Sch\u00f6nheit! Mit recht viel Geld", "tokens": ["Geld", "ist", "Sch\u00f6n\u00b7heit", "!", "Mit", "recht", "viel", "Geld"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "NN", "$.", "APPR", "ADJD", "PIAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nimmst du den Mann, der dir wohlgef\u00e4llt,", "tokens": ["Nimmst", "du", "den", "Mann", ",", "der", "dir", "wohl\u00b7ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Keinen H\u00e4\u00dflichen, keinen Alten.", "tokens": ["Kei\u00b7nen", "H\u00e4\u00df\u00b7li\u00b7chen", ",", "kei\u00b7nen", "Al\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sieh, der Reichen H\u00e4nde, wie wei\u00df!", "tokens": ["Sieh", ",", "der", "Rei\u00b7chen", "H\u00e4n\u00b7de", ",", "wie", "wei\u00df", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "NN", "$,", "PWAV", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wissen nichts von Frost und von Schwei\u00df;", "tokens": ["Wis\u00b7sen", "nichts", "von", "Frost", "und", "von", "Schwei\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Haben keine Schwielen noch Falten.", "tokens": ["Ha\u00b7ben", "kei\u00b7ne", "Schwie\u00b7len", "noch", "Fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADV", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Bei uns Armen ist eins mal sch\u00f6n,", "tokens": ["Bei", "uns", "Ar\u00b7men", "ist", "eins", "mal", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "VAFIN", "PIS", "ADV", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Aber nur im Vor\u00fcbergehn;", "tokens": ["A\u00b7ber", "nur", "im", "Vor\u00b7\u00fc\u00b7ber\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Morgen schon ist zerrupft sein Gefieder.", "tokens": ["Mor\u00b7gen", "schon", "ist", "zer\u00b7rupft", "sein", "Ge\u00b7fie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "VVPP", "PPOSAT", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Oder die Sch\u00f6nheit wird ihm zu Geld;", "tokens": ["O\u00b7der", "die", "Sch\u00f6n\u00b7heit", "wird", "ihm", "zu", "Geld", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "APPR", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Kommt es hinauf in die gro\u00dfe Welt,", "tokens": ["Kommt", "es", "hin\u00b7auf", "in", "die", "gro\u00b7\u00dfe", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "Steigt es nicht leicht mehr zu uns hernieder.", "tokens": ["Steigt", "es", "nicht", "leicht", "mehr", "zu", "uns", "her\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADJD", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Kind, hab acht auf wahren Gewinn:", "tokens": ["Kind", ",", "hab", "acht", "auf", "wah\u00b7ren", "Ge\u00b7winn", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "CARD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Geld ist Freiheit, ist Edelsinn,", "tokens": ["Geld", "ist", "Frei\u00b7heit", ",", "ist", "E\u00b7del\u00b7sinn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,", "VAFIN", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Menschenw\u00fcrde und Seelenfrieden.", "tokens": ["Men\u00b7schen\u00b7w\u00fcr\u00b7de", "und", "See\u00b7len\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Alles kehrt sich zum goldenen Licht,", "tokens": ["Al\u00b7les", "kehrt", "sich", "zum", "gol\u00b7de\u00b7nen", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Warum sollen wir Menschen es nicht?", "tokens": ["Wa\u00b7rum", "sol\u00b7len", "wir", "Men\u00b7schen", "es", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "NN", "PPER", "PTKNEG", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Dir, mein Kind, sei das Gl\u00fcck beschieden.", "tokens": ["Dir", ",", "mein", "Kind", ",", "sei", "das", "Gl\u00fcck", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}}}}