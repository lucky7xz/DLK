{"dta.poem.9301": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das andere lied.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Gehab dich wohl mein kind/ es ist doch nun geschehn/", "tokens": ["Ge\u00b7hab", "dich", "wohl", "mein", "kind", "/", "es", "ist", "doch", "nun", "ge\u00b7schehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "$(", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df wir einander nicht so leichtlich wieder sehn:", "tokens": ["Da\u00df", "wir", "ein\u00b7an\u00b7der", "nicht", "so", "leicht\u00b7lich", "wie\u00b7der", "sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich mu\u00df so schleinig fort da ich am besten sp\u00fcre/", "tokens": ["Ich", "mu\u00df", "so", "schlei\u00b7nig", "fort", "da", "ich", "am", "bes\u00b7ten", "sp\u00fc\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PTKVZ", "KOUS", "PPER", "PTKA", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie gro\u00df die freude sey/ die ich durch dich verliehre.", "tokens": ["Wie", "gro\u00df", "die", "freu\u00b7de", "sey", "/", "die", "ich", "durch", "dich", "ver\u00b7lieh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VAFIN", "$(", "PRELS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "2. Die zeit ist viel zu kurtz da\u00df ich beschreiben kan/", "tokens": ["Die", "zeit", "ist", "viel", "zu", "kurtz", "da\u00df", "ich", "be\u00b7schrei\u00b7ben", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "KOUS", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie weh mir allbereit die enderung gethan/", "tokens": ["Wie", "weh", "mir", "all\u00b7be\u00b7reit", "die", "en\u00b7de\u00b7rung", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wie von hertzen gern ich hier verbleiben wolte/", "tokens": ["Und", "wie", "von", "hert\u00b7zen", "gern", "ich", "hier", "ver\u00b7blei\u00b7ben", "wol\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "NN", "ADV", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn ich des gl\u00fcckes schlu\u00df zur\u00fccke treiben solte.", "tokens": ["Wenn", "ich", "des", "gl\u00fc\u00b7ckes", "schlu\u00df", "zu\u00b7r\u00fc\u00b7cke", "trei\u00b7ben", "sol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "3. Ich habe deine gunst vortrefflich hochgesch\u00e4tzt/", "tokens": ["Ich", "ha\u00b7be", "dei\u00b7ne", "gunst", "vor\u00b7treff\u00b7lich", "hoch\u00b7ge\u00b7sch\u00e4tzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drum gieb mir auch den trost nunmehr zu guter letzt", "tokens": ["Drum", "gieb", "mir", "auch", "den", "trost", "nun\u00b7mehr", "zu", "gu\u00b7ter", "letzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "APPR", "ADJA", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und la\u00df mich nur gewi\u00df versicherung bekommen", "tokens": ["Und", "la\u00df", "mich", "nur", "ge\u00b7wi\u00df", "ver\u00b7si\u00b7che\u00b7rung", "be\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "ADV", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du habest alles thun am besten aufgenommen.", "tokens": ["Du", "ha\u00b7best", "al\u00b7les", "thun", "am", "bes\u00b7ten", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "VVINF", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "4. Mein kind/ es mag wol seyn da\u00df ich zu k\u00fchne bin/", "tokens": ["Mein", "kind", "/", "es", "mag", "wol", "seyn", "da\u00df", "ich", "zu", "k\u00fch\u00b7ne", "bin", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPER", "VMFIN", "ADV", "VAINF", "KOUS", "PPER", "PTKA", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jedoch verla\u00df ich mich auff deinen guten sinn/", "tokens": ["Je\u00b7doch", "ver\u00b7la\u00df", "ich", "mich", "auff", "dei\u00b7nen", "gu\u00b7ten", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der hat mir allezeit die zuversicht gelassen/", "tokens": ["Der", "hat", "mir", "al\u00b7le\u00b7zeit", "die", "zu\u00b7ver\u00b7sicht", "ge\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ART", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als kontestu mich nicht in meiner einfalt hassen", "tokens": ["Als", "kon\u00b7tes\u00b7tu", "mich", "nicht", "in", "mei\u00b7ner", "ein\u00b7falt", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "PPER", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "5. Ach h\u00e4tt ich nur die zeit noch besser angewendt/", "tokens": ["Ach", "h\u00e4tt", "ich", "nur", "die", "zeit", "noch", "bes\u00b7ser", "an\u00b7ge\u00b7wendt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und h\u00e4t ich deinen sinn ein bi\u00dfgen eh erkennt/", "tokens": ["Und", "h\u00e4t", "ich", "dei\u00b7nen", "sinn", "ein", "bi\u00df\u00b7gen", "eh", "er\u00b7kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So w\u00fcrdestu vielleicht mit be\u00dferm grunde wissen/", "tokens": ["So", "w\u00fcr\u00b7des\u00b7tu", "viel\u00b7leicht", "mit", "be\u00b7\u00dferm", "grun\u00b7de", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df mir die worte recht aus meinem hertzen flissen.", "tokens": ["Da\u00df", "mir", "die", "wor\u00b7te", "recht", "aus", "mei\u00b7nem", "hert\u00b7zen", "flis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "6. Ich sehe dirs wol an/ du traust in allen nicht/ (spricht.", "tokens": ["Ich", "se\u00b7he", "dirs", "wol", "an", "/", "du", "traust", "in", "al\u00b7len", "nicht", "/", "(", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "PTKVZ", "$(", "PPER", "VVFIN", "APPR", "PIS", "PTKNEG", "$(", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Wenn gleich mein from\u0303er mund von treu und freundschafft", "tokens": ["Wenn", "gleich", "mein", "from\u0303er", "mund", "von", "treu", "und", "freund\u00b7schafft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "APPR", "ADJD", "KON", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Das machts ich h\u00e4tte noch ein jahr verzieyen sollen/", "tokens": ["Das", "machts", "ich", "h\u00e4t\u00b7te", "noch", "ein", "jahr", "ver\u00b7zie\u00b7yen", "sol\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VAFIN", "ADV", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So h\u00e4tten wir gewi\u00df bekanter werden wollen.", "tokens": ["So", "h\u00e4t\u00b7ten", "wir", "ge\u00b7wi\u00df", "be\u00b7kan\u00b7ter", "wer\u00b7den", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "7. Inzwischen weil die zeit mit mir ein ende macht/", "tokens": ["I\u00b7nzwi\u00b7schen", "weil", "die", "zeit", "mit", "mir", "ein", "en\u00b7de", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPR", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So bring ich nun betr\u00fcbt die letzte gute nacht/", "tokens": ["So", "bring", "ich", "nun", "be\u00b7tr\u00fcbt", "die", "letz\u00b7te", "gu\u00b7te", "nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der himmel decke dich mit segen au\u00df der h\u00f6he", "tokens": ["Der", "him\u00b7mel", "de\u00b7cke", "dich", "mit", "se\u00b7gen", "au\u00df", "der", "h\u00f6\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df alles weil du lebst/ nach deinem wunsche gehe.", "tokens": ["Da\u00df", "al\u00b7les", "weil", "du", "lebst", "/", "nach", "dei\u00b7nem", "wun\u00b7sche", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOUS", "PPER", "VVFIN", "$(", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "8. Nur schaue mich mein kind abwesend g\u00fctig an/", "tokens": ["Nur", "schau\u00b7e", "mich", "mein", "kind", "ab\u00b7we\u00b7send", "g\u00fc\u00b7tig", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich in freud und leid von dir erfahren kan/", "tokens": ["Da\u00df", "ich", "in", "freud", "und", "leid", "von", "dir", "er\u00b7fah\u00b7ren", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "KON", "ADJD", "APPR", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob ich mich freuen sol/ ob ich mich sol bekr\u00fcben?", "tokens": ["Ob", "ich", "mich", "freu\u00b7en", "sol", "/", "ob", "ich", "mich", "sol", "be\u00b7kr\u00b7\u00fc\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$(", "KOUS", "PPER", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Also wil ich dein gl\u00fcck mehr als mich selber lieben", "tokens": ["Al\u00b7so", "wil", "ich", "dein", "gl\u00fcck", "mehr", "als", "mich", "sel\u00b7ber", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "ADV", "KOUS", "PPER", "ADV", "VVINF"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "9. Hiermit zu guter nacht/ nur la\u00df mir willig zu", "tokens": ["Hier\u00b7mit", "zu", "gu\u00b7ter", "nacht", "/", "nur", "la\u00df", "mir", "wil\u00b7lig", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "$(", "ADV", "VVIMP", "PPER", "ADJD", "PTKZU"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df ich mein letztes wort in diesem liede thu/", "tokens": ["Da\u00df", "ich", "mein", "letz\u00b7tes", "wort", "in", "die\u00b7sem", "lie\u00b7de", "thu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die thr\u00e4nen m\u00f6chten sonst aus meinen augen brechen/", "tokens": ["Die", "thr\u00e4\u00b7nen", "m\u00f6ch\u00b7ten", "sonst", "aus", "mei\u00b7nen", "au\u00b7gen", "bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und solches w\u00fcrde mir manch kl\u00fcgling \u00fcbel sprechen.", "tokens": ["Und", "sol\u00b7ches", "w\u00fcr\u00b7de", "mir", "manch", "kl\u00fcg\u00b7ling", "\u00fc\u00b7bel", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "PIAT", "VVFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "10. Drum sprech ich kurtz und gut/ mein kind gehab dich", "tokens": ["Drum", "sprech", "ich", "kurtz", "und", "gut", "/", "mein", "kind", "ge\u00b7hab", "dich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$(", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bedencke was ich nun mit dir verlassen sol/ ", "tokens": ["Be\u00b7den\u00b7cke", "was", "ich", "nun", "mit", "dir", "ver\u00b7las\u00b7sen", "sol", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "PPER", "ADV", "APPR", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil ich meine pflicht in worten nicht erweise/", "tokens": ["Und", "weil", "ich", "mei\u00b7ne", "pflicht", "in", "wor\u00b7ten", "nicht", "er\u00b7wei\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "APPR", "NN", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So gieb mir liebstes kind/ ein blickgen auf die reise.", "tokens": ["So", "gieb", "mir", "liebs\u00b7tes", "kind", "/", "ein", "blick\u00b7gen", "auf", "die", "rei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADJA", "NN", "$(", "ART", "ADJA", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}