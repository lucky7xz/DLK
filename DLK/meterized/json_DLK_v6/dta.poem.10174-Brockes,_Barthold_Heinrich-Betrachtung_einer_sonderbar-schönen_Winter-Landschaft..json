{"dta.poem.10174": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Betrachtung einer sonderbar-sch\u00f6nen  \n Winter-Landschaft.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wie j\u00fcngst ein tieffer Schnee gefallen,", "tokens": ["Wie", "j\u00fcngst", "ein", "tief\u00b7fer", "Schnee", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und gleich ein Regen drauf; bald aber wieder\u00fcm", "tokens": ["Und", "gleich", "ein", "Re\u00b7gen", "drauf", ";", "bald", "a\u00b7ber", "wie\u00b7de\u00b7r\u00fcm"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "PTKVZ", "$.", "ADV", "ADV", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein schneller Frost entstand; erstarrt\u2019 vor dessen Grimm", "tokens": ["Ein", "schnel\u00b7ler", "Frost", "ent\u00b7stand", ";", "er\u00b7starrt'", "vor", "des\u00b7sen", "Grimm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "VVFIN", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Schnee, der eben schmoltz. Da schien nun wie Cry-", "tokens": ["Der", "Schnee", ",", "der", "e\u00b7ben", "schmoltz", ".", "Da", "schien", "nun", "wie", "Cry"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADJD", "$.", "ADV", "VVFIN", "ADV", "KOKOM", "TRUNC"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Der B\u00e4ume glatte Schaar,", "tokens": ["Der", "B\u00e4u\u00b7me", "glat\u00b7te", "Schaar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Die fast im Augenblick als wie beharnischt war.", "tokens": ["Die", "fast", "im", "Au\u00b7gen\u00b7blick", "als", "wie", "be\u00b7har\u00b7nischt", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "KOUS", "KOKOM", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es wurden Wunder-schnell so gross-als kleine Sprossen,", "tokens": ["Es", "wur\u00b7den", "Wun\u00b7der\u00b7schnell", "so", "gross\u00b7als", "klei\u00b7ne", "Spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Von einem halb bereits erstarrten Ra\u00df, beflossen,", "tokens": ["Von", "ei\u00b7nem", "halb", "be\u00b7reits", "er\u00b7starr\u00b7ten", "Ra\u00df", ",", "be\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADV", "ADJA", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und rings\u00fcm eingefasst und eingeschlossen.", "tokens": ["Und", "ring\u00b7s\u00fcm", "ein\u00b7ge\u00b7fasst", "und", "ein\u00b7ge\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sie waren gantz mit klarem Eis bedecket:", "tokens": ["Sie", "wa\u00b7ren", "gantz", "mit", "kla\u00b7rem", "Eis", "be\u00b7de\u00b7cket", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Das allerkleinste Zweiglein stecket", "tokens": ["Das", "al\u00b7ler\u00b7kleins\u00b7te", "Zwei\u00b7glein", "ste\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "In einer Eis-Crystallnen Stangen,", "tokens": ["In", "ei\u00b7ner", "Eis\u00b7Cry\u00b7stall\u00b7nen", "Stan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Die sieben mahl so dick, als wie es selbst. Daher", "tokens": ["Die", "sie\u00b7ben", "mahl", "so", "dick", ",", "als", "wie", "es", "selbst", ".", "Da\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "CARD", "ADV", "ADV", "ADJD", "$,", "KOUS", "PWAV", "PPER", "ADV", "$.", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Aeste denn, dieweil das Eis so schwer,", "tokens": ["Die", "A\u00b7es\u00b7te", "denn", ",", "die\u00b7weil", "das", "Eis", "so", "schwer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KOUS", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Gebogen all\u2019 herunter hangen.", "tokens": ["Ge\u00b7bo\u00b7gen", "all'", "her\u00b7un\u00b7ter", "han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Wodurch der B\u00e4ume Heer", "tokens": ["Wo\u00b7durch", "der", "B\u00e4u\u00b7me", "Heer"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Den Palmen an Figur, an Glantz den Leuchter-Cronen", "tokens": ["Den", "Pal\u00b7men", "an", "Fi\u00b7gur", ",", "an", "Glantz", "den", "Leuch\u00b7ter\u00b7Cro\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Von reinem Berg-Crystall, die hell polirt sind, glich.", "tokens": ["Von", "rei\u00b7nem", "Ber\u00b7gCry\u00b7stall", ",", "die", "hell", "po\u00b7lirt", "sind", ",", "glich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVPP", "VAFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die gantze Landschaft sah daher verwunderlich,", "tokens": ["Die", "gant\u00b7ze", "Land\u00b7schaft", "sah", "da\u00b7her", "ver\u00b7wun\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PAV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hell, pr\u00e4chtig, herrlich aus. Zumahl", "tokens": ["Hell", ",", "pr\u00e4ch\u00b7tig", ",", "herr\u00b7lich", "aus", ".", "Zu\u00b7mahl"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "PTKVZ", "$.", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Wie bey dem Untergang der niedre Sonnen-Strahl", "tokens": ["Wie", "bey", "dem", "Un\u00b7ter\u00b7gang", "der", "nied\u00b7re", "Son\u00b7nen\u00b7Strahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In, durch, und an die klare Gl\u00e4tte fiel.", "tokens": ["In", ",", "durch", ",", "und", "an", "die", "kla\u00b7re", "Gl\u00e4t\u00b7te", "fiel", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "APPR", "$,", "KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Es ist fast auf der Welt kein sch\u00f6ner Augen-Ziel.", "tokens": ["Es", "ist", "fast", "auf", "der", "Welt", "kein", "sch\u00f6\u00b7ner", "Au\u00b7gen\u00b7Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Glantz, den K\u00f6nig\u2019 oder Kaiser", "tokens": ["Der", "Glantz", ",", "den", "K\u00f6\u00b7nig'", "o\u00b7der", "Kai\u00b7ser"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "An Kostbarkeiten zeigen k\u00f6nnen;", "tokens": ["An", "Kost\u00b7bar\u00b7kei\u00b7ten", "zei\u00b7gen", "k\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind nichts bey diesem Glantz zu rechnen, nicht zu nennen.", "tokens": ["Sind", "nichts", "bey", "die\u00b7sem", "Glantz", "zu", "rech\u00b7nen", ",", "nicht", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "PDAT", "NN", "PTKZU", "VVINF", "$,", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Wald von Berg-Crystall voll Diamantner Reiser", "tokens": ["Ein", "Wald", "von", "Ber\u00b7gCry\u00b7stall", "voll", "Di\u00b7a\u00b7mant\u00b7ner", "Rei\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sind \u00fcberall zur Schau gestellt.", "tokens": ["Sind", "\u00fc\u00b7be\u00b7rall", "zur", "Schau", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Dresdnisch gr\u00fcn Gew\u00f6lb war ietzt die gantze Welt:", "tokens": ["Ein", "Dresd\u00b7nisch", "gr\u00fcn", "Ge\u00b7w\u00f6lb", "war", "ietzt", "die", "gant\u00b7ze", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weil nichts als spielende Briljanten,", "tokens": ["Weil", "nichts", "als", "spie\u00b7len\u00b7de", "Bril\u00b7jan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Als sch\u00fctternde geschliffne Diamanten,", "tokens": ["Als", "sch\u00fct\u00b7tern\u00b7de", "ge\u00b7schliff\u00b7ne", "Di\u00b7a\u00b7man\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "So weit man sah, zu sehn.", "tokens": ["So", "weit", "man", "sah", ",", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich muste hier iedoch der Menschen Meinung lachen,", "tokens": ["Ich", "mus\u00b7te", "hier", "ie\u00b7doch", "der", "Men\u00b7schen", "Mei\u00b7nung", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die so viel Prahlerey von Edelsteinen machen.", "tokens": ["Die", "so", "viel", "Prah\u00b7le\u00b7rey", "von", "E\u00b7del\u00b7stei\u00b7nen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie leicht kann, dacht ich, die Natur", "tokens": ["Wie", "leicht", "kann", ",", "dacht", "ich", ",", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "ADJD", "VMFIN", "$,", "VVFIN", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Juwelen \u00fcberall bereiten!", "tokens": ["Ju\u00b7we\u00b7len", "\u00fc\u00b7be\u00b7rall", "be\u00b7rei\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die H\u00e4rte fehlet ja dem Eise nur,", "tokens": ["Die", "H\u00e4r\u00b7te", "feh\u00b7let", "ja", "dem", "Ei\u00b7se", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So hat es alle Kostbarkeiten,", "tokens": ["So", "hat", "es", "al\u00b7le", "Kost\u00b7bar\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Pracht, Schimmer, Wasser, Feur und Schein,", "tokens": ["Pracht", ",", "Schim\u00b7mer", ",", "Was\u00b7ser", ",", "Feur", "und", "Schein", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und alle rare Seltenheiten,", "tokens": ["Und", "al\u00b7le", "ra\u00b7re", "Sel\u00b7ten\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die im so hoch gesch\u00e4tzten Demant seyn.", "tokens": ["Die", "im", "so", "hoch", "ge\u00b7sch\u00e4tz\u00b7ten", "De\u00b7mant", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "ADV", "ADJD", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Man stell sich einen Saal, voll Leuchter an der Wand", "tokens": ["Man", "stell", "sich", "ei\u00b7nen", "Saal", ",", "voll", "Leuch\u00b7ter", "an", "der", "Wand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "PRF", "ART", "NN", "$,", "ADJD", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von oben gantz herab, von allerhand", "tokens": ["Von", "o\u00b7ben", "gantz", "her\u00b7ab", ",", "von", "al\u00b7ler\u00b7hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADV", "ADV", "ADV", "$,", "APPR", "PIAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Bald rund-, bald eckigten Corallen", "tokens": ["Bald", "run\u00b7d", ",", "bald", "ec\u00b7kig\u00b7ten", "Co\u00b7ral\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "TRUNC", "$,", "ADV", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von klaren Berg-Crystallen,", "tokens": ["Von", "kla\u00b7ren", "Ber\u00b7gCry\u00b7stal\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Viel tausend helle Kertzen blitzen)", "tokens": ["Viel", "tau\u00b7send", "hel\u00b7le", "Kert\u00b7zen", "blit\u00b7zen", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Einst in Gedancken vor; so wird der bunte Schein", "tokens": ["Einst", "in", "Ge\u00b7dan\u00b7cken", "vor", ";", "so", "wird", "der", "bun\u00b7te", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "PTKVZ", "$.", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch schwach, bey diesem Gl\u00e4ntzen, seyn,", "tokens": ["Doch", "schwach", ",", "bey", "die\u00b7sem", "Gl\u00e4nt\u00b7zen", ",", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "PDAT", "NN", "$,", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das auf der Erd\u2019 ietzt allgemein.", "tokens": ["Das", "auf", "der", "Erd'", "ietzt", "all\u00b7ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da alle B\u00e4ume, alle H\u00fcgel,", "tokens": ["Da", "al\u00b7le", "B\u00e4u\u00b7me", ",", "al\u00b7le", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wie Leuchter-Cronen, helle Spiegel,", "tokens": ["Wie", "Leuch\u00b7ter\u00b7Cro\u00b7nen", ",", "hel\u00b7le", "Spie\u00b7gel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die selbst der Sonnen Wunder-Strahl", "tokens": ["Die", "selbst", "der", "Son\u00b7nen", "Wun\u00b7der\u00b7Strahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "An allen Orten trifft, bemahlt, durchdringet, schm\u00fccket,", "tokens": ["An", "al\u00b7len", "Or\u00b7ten", "trifft", ",", "be\u00b7mahlt", ",", "durch\u00b7drin\u00b7get", ",", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Jm ungemessnen Erden-Saal,", "tokens": ["Jm", "un\u00b7ge\u00b7mess\u00b7nen", "Er\u00b7den\u00b7Saal", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "In einem hellen Glantz und Schein", "tokens": ["In", "ei\u00b7nem", "hel\u00b7len", "Glantz", "und", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Erstaunlich anzusehen seyn.", "tokens": ["Er\u00b7staun\u00b7lich", "an\u00b7zu\u00b7se\u00b7hen", "seyn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVIZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Es wird mein Auge fast entz\u00fccket,", "tokens": ["Es", "wird", "mein", "Au\u00b7ge", "fast", "ent\u00b7z\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Da ich zur selben Zeit, im Garten, die Allee", "tokens": ["Da", "ich", "zur", "sel\u00b7ben", "Zeit", ",", "im", "Gar\u00b7ten", ",", "die", "Al\u00b7lee"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "$,", "APPRART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Auf gleiche Weise,", "tokens": ["Auf", "glei\u00b7che", "Wei\u00b7se", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Durch den so schnell geschmoltznen Schnee,", "tokens": ["Durch", "den", "so", "schnell", "ge\u00b7schmoltz\u00b7nen", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "In einem hell bestrahlten Eise,", "tokens": ["In", "ei\u00b7nem", "hell", "be\u00b7strahl\u00b7ten", "Ei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Nicht schimmern, feurig funckeln seh.", "tokens": ["Nicht", "schim\u00b7mern", ",", "feu\u00b7rig", "fun\u00b7ckeln", "seh", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sie war nicht anders anzuschauen,", "tokens": ["Sie", "war", "nicht", "an\u00b7ders", "an\u00b7zu\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als wie ein Weg, den man, im Bergwerck, aus Juwelen", "tokens": ["Als", "wie", "ein", "Weg", ",", "den", "man", ",", "im", "Berg\u00b7werck", ",", "aus", "Ju\u00b7we\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "PRELS", "PIS", "$,", "APPRART", "NN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und Diamanten ausgehauen.", "tokens": ["Und", "Di\u00b7a\u00b7man\u00b7ten", "aus\u00b7ge\u00b7hau\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn man durch fliessenden geschmoltzenen Crystall", "tokens": ["Wenn", "man", "durch", "flies\u00b7sen\u00b7den", "ge\u00b7schmolt\u00b7ze\u00b7nen", "Crys\u00b7tall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die B\u00e4ume gantz gezogen h\u00e4tte;", "tokens": ["Die", "B\u00e4u\u00b7me", "gantz", "ge\u00b7zo\u00b7gen", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So k\u00f6nnten sie in einer hellern Gl\u00e4tte,", "tokens": ["So", "k\u00f6nn\u00b7ten", "sie", "in", "ei\u00b7ner", "hel\u00b7lern", "Gl\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Als wie sie damahls \u00fcberall,", "tokens": ["Als", "wie", "sie", "da\u00b7mahls", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Unm\u00f6glich funckeln, blitzen, gl\u00e4ntzen.", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "fun\u00b7ckeln", ",", "blit\u00b7zen", ",", "gl\u00e4nt\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Mein Leser, glaube nicht, da\u00df mein erzehlen", "tokens": ["Mein", "Le\u00b7ser", ",", "glau\u00b7be", "nicht", ",", "da\u00df", "mein", "er\u00b7zeh\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PTKNEG", "$,", "KOUS", "PPOSAT", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu weit sey ausgedehnt. Es ist wahrhaftig wahr.", "tokens": ["Zu", "weit", "sey", "aus\u00b7ge\u00b7dehnt", ".", "Es", "ist", "wahr\u00b7haf\u00b7tig", "wahr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "VVPP", "$.", "PPER", "VAFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und bin ich nicht geschickt,", "tokens": ["Und", "bin", "ich", "nicht", "ge\u00b7schickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df es, durch meinen Kiel, hoch, pr\u00e4chtig, \u00e4hnlich, klar", "tokens": ["Da\u00df", "es", ",", "durch", "mei\u00b7nen", "Kiel", ",", "hoch", ",", "pr\u00e4ch\u00b7tig", ",", "\u00e4hn\u00b7lich", ",", "klar"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und sch\u00f6n genug wird ausgedr\u00fcckt.", "tokens": ["Und", "sch\u00f6n", "ge\u00b7nug", "wird", "aus\u00b7ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch hab ich auch den Frost so gar ausnehmend sch\u00f6n,", "tokens": ["Doch", "hab", "ich", "auch", "den", "Frost", "so", "gar", "aus\u00b7neh\u00b7mend", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nur blo\u00df ein einzigs mahl, gesehn.", "tokens": ["Nur", "blo\u00df", "ein", "ein\u00b7zigs", "mahl", ",", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADV", "ADV", "$,", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.8": {"text": "Jedoch mu\u00df ich dabey gestehn:", "tokens": ["Je\u00b7doch", "mu\u00df", "ich", "da\u00b7bey", "ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df alle Sch\u00f6nheit doch ein Etwas, welches wild,", "tokens": ["Da\u00df", "al\u00b7le", "Sch\u00f6n\u00b7heit", "doch", "ein", "Et\u00b7was", ",", "wel\u00b7ches", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "ART", "ADV", "$,", "PRELS", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und rauh, und f\u00fcrchterlich, zugleich uns zeigte.", "tokens": ["Und", "rauh", ",", "und", "f\u00fcrch\u00b7ter\u00b7lich", ",", "zu\u00b7gleich", "uns", "zeig\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KON", "ADJD", "$,", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Denn da ein ieder Baum sich gantz herabw\u00e4rts beugte,", "tokens": ["Denn", "da", "ein", "ie\u00b7der", "Baum", "sich", "gantz", "her\u00b7ab\u00b7w\u00e4rts", "beug\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "PIAT", "NN", "PRF", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "War Weg und Steg versperrt. Hier\u00fcber fiel mir ein:", "tokens": ["War", "Weg", "und", "Steg", "ver\u00b7sperrt", ".", "Hier\u00b7\u00fc\u00b7ber", "fiel", "mir", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "VVFIN", "$.", "PAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie mu\u00df doch dem zu muthe seyn,", "tokens": ["Wie", "mu\u00df", "doch", "dem", "zu", "mu\u00b7the", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "ART", "PTKZU", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Der ietzt durch W\u00e4lder reisen mu\u00df?", "tokens": ["Der", "ietzt", "durch", "W\u00e4l\u00b7der", "rei\u00b7sen", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ich stellte mir", "tokens": ["Ich", "stell\u00b7te", "mir"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.16": {"text": "Davon viel gr\u00e4\u00dfliches und sehr gef\u00e4hrlichs f\u00fcr.", "tokens": ["Da\u00b7von", "viel", "gr\u00e4\u00df\u00b7li\u00b7ches", "und", "sehr", "ge\u00b7f\u00e4hr\u00b7lichs", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "ADJA", "KON", "ADV", "ADJA", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Doch hast du bald darauf, gelehrter Clodius,", "tokens": ["Doch", "hast", "du", "bald", "da\u00b7rauf", ",", "ge\u00b7lehr\u00b7ter", "Clo\u00b7dius", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PAV", "$,", "ADJA", "NE", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.18": {"text": "Den eben, \u00fcber mein Verhoffen,", "tokens": ["Den", "e\u00b7ben", ",", "\u00fc\u00b7ber", "mein", "Ver\u00b7hof\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Die\u00df Ungemach betroffen,", "tokens": ["Die\u00df", "Un\u00b7ge\u00b7mach", "be\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "Es mir weit schrecklicher, als ich mir, vorgestellt.", "tokens": ["Es", "mir", "weit", "schreck\u00b7li\u00b7cher", ",", "als", "ich", "mir", ",", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "PPER", "ADJD", "ADJD", "$,", "KOUS", "PPER", "PPER", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Kurtz: wircklich war, zu dieser Zeit, die Welt", "tokens": ["Kurtz", ":", "wir\u00b7ck\u00b7lich", "war", ",", "zu", "die\u00b7ser", "Zeit", ",", "die", "Welt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "$.", "ADJD", "VAFIN", "$,", "APPR", "PDAT", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Mit Sch\u00f6nheit und Gefahr, mit Lust und Last erf\u00fcllt.", "tokens": ["Mit", "Sch\u00f6n\u00b7heit", "und", "Ge\u00b7fahr", ",", "mit", "Lust", "und", "Last", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie war ein lieblich Schrecken-Bild.", "tokens": ["Sie", "war", "ein", "lieb\u00b7lich", "Schre\u00b7cken\u00b7Bild", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entsetzlich angenehm, erschrecklich sch\u00f6n", "tokens": ["Ent\u00b7setz\u00b7lich", "an\u00b7ge\u00b7nehm", ",", "er\u00b7schreck\u00b7lich", "sch\u00f6n"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "ADJD", "$,", "ADJD", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Des Eises sch\u00f6ner Glantz, das, durch die schwehre La", "tokens": ["Des", "Ei\u00b7ses", "sch\u00f6\u00b7ner", "Glantz", ",", "das", ",", "durch", "die", "schweh\u00b7re", "La"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PDS", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So manchen Ast", "tokens": ["So", "man\u00b7chen", "Ast"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "So sehr beschwehrt\u2019, und abw\u00e4rts beugte,", "tokens": ["So", "sehr", "be\u00b7schwehrt'", ",", "und", "ab\u00b7w\u00e4rts", "beug\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ja viele gar zerbrach, zerknickte,", "tokens": ["Ja", "vie\u00b7le", "gar", "zer\u00b7brach", ",", "zer\u00b7knick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "PIS", "ADV", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und manchen gantzen Baum so gar zur Erden dr\u00fcckte,", "tokens": ["Und", "man\u00b7chen", "gant\u00b7zen", "Baum", "so", "gar", "zur", "Er\u00b7den", "dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "War mir nicht nur ein Beyspiel mancher Sch\u00f6nen,", "tokens": ["War", "mir", "nicht", "nur", "ein", "Bey\u00b7spiel", "man\u00b7cher", "Sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die offt durch eigner Sch\u00f6nheit Pracht", "tokens": ["Die", "offt", "durch", "eig\u00b7ner", "Sch\u00f6n\u00b7heit", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zu Ungl\u00fcck k\u00f6mmt, und wird zu Fall gebracht:", "tokens": ["Zu", "Un\u00b7gl\u00fcck", "k\u00f6mmt", ",", "und", "wird", "zu", "Fall", "ge\u00b7bracht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "KON", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Es lie\u00df zugleich die\u00df lieblich rauhe Wesen,", "tokens": ["Es", "lie\u00df", "zu\u00b7gleich", "die\u00df", "lieb\u00b7lich", "rau\u00b7he", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PDS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Vom Zustand unsrer Welt, mir eine Lehre lesen:", "tokens": ["Vom", "Zu\u00b7stand", "uns\u00b7rer", "Welt", ",", "mir", "ei\u00b7ne", "Leh\u00b7re", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$,", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wie in so sch\u00f6nem Frost sich Pein und Schein vereine", "tokens": ["Wie", "in", "so", "sch\u00f6\u00b7nem", "Frost", "sich", "Pein", "und", "Schein", "ver\u00b7ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ADV", "ADJA", "NN", "PRF", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und unser Aug\u2019 erschrecket und erfrischt;", "tokens": ["Und", "un\u00b7ser", "Aug'", "er\u00b7schre\u00b7cket", "und", "er\u00b7frischt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So ist mit Gutem auch das B\u00f6se stets vermischt.", "tokens": ["So", "ist", "mit", "Gu\u00b7tem", "auch", "das", "B\u00f6\u00b7se", "stets", "ver\u00b7mischt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Daher, was jener sagt, die Wahrheit, wie es scheinet:", "tokens": ["Da\u00b7her", ",", "was", "je\u00b7ner", "sagt", ",", "die", "Wahr\u00b7heit", ",", "wie", "es", "schei\u00b7net", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PWS", "PDS", "VVFIN", "$,", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Vergeht nun gleich des Winters sch\u00f6ner Schimmer", "tokens": ["Ver\u00b7geht", "nun", "gleich", "des", "Win\u00b7ters", "sch\u00f6\u00b7ner", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Viel eh noch, als die Unbequemlichkeit;", "tokens": ["Viel", "eh", "noch", ",", "als", "die", "Un\u00b7be\u00b7quem\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ADV", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So w\u00e4hrt doch auch der scharffe Frost nicht immer.", "tokens": ["So", "w\u00e4hrt", "doch", "auch", "der", "scharf\u00b7fe", "Frost", "nicht", "im\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Es jagt ihn, sammt dem kalten Rord", "tokens": ["Es", "jagt", "ihn", ",", "sammt", "dem", "kal\u00b7ten", "Rord"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu rechter Zeit der frohe Fr\u00fchling fort.", "tokens": ["Zu", "rech\u00b7ter", "Zeit", "der", "fro\u00b7he", "Fr\u00fch\u00b7ling", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Dar\u00fcm verzweifle nicht, wenn rauhe Winde wehn,", "tokens": ["Da\u00b7r\u00fcm", "ver\u00b7zweif\u00b7le", "nicht", ",", "wenn", "rau\u00b7he", "Win\u00b7de", "wehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PTKNEG", "$,", "KOUS", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch sey auch nicht zu stoltz, wenn alles still und sch\u00f6n!", "tokens": ["Doch", "sey", "auch", "nicht", "zu", "stoltz", ",", "wenn", "al\u00b7les", "still", "und", "sch\u00f6n", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "PTKA", "ADJD", "$,", "KOUS", "PIS", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vielmehr gedenck, sowol im Sturm, als in der Stille:", "tokens": ["Viel\u00b7mehr", "ge\u00b7denck", ",", "so\u00b7wol", "im", "Sturm", ",", "als", "in", "der", "Stil\u00b7le", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPRART", "NN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "La\u00df dich den Glantz zum Trost, den Frost zur Demuth brin-", "tokens": ["La\u00df", "dich", "den", "Glantz", "zum", "Trost", ",", "den", "Frost", "zur", "De\u00b7muth", "brin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und dencke: ", "tokens": ["Und", "den\u00b7cke", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}}}}