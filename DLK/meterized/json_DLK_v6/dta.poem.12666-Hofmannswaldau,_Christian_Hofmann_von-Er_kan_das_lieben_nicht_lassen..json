{"dta.poem.12666": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Er kan das lieben nicht lassen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein hertze hat der freyheit gold verlohren,", "tokens": ["Mein", "hert\u00b7ze", "hat", "der", "frey\u00b7heit", "gold", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich mu\u00df, wie vor, der liebe sclave seyn,", "tokens": ["Ich", "mu\u00df", ",", "wie", "vor", ",", "der", "lie\u00b7be", "scla\u00b7ve", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PWAV", "PTKVZ", "$,", "ART", "ADJA", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum, da\u00df mein mund die dienstbarkeit verschworen,", "tokens": ["Kaum", ",", "da\u00df", "mein", "mund", "die", "dienst\u00b7bar\u00b7keit", "ver\u00b7schwo\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So rei\u00dft ein blick den schwachen vorsatz ein;", "tokens": ["So", "rei\u00dft", "ein", "blick", "den", "schwa\u00b7chen", "vor\u00b7satz", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Verh\u00e4ngni\u00df, gl\u00fcck und zeit, ihr meister aller sachen,", "tokens": ["Ver\u00b7h\u00e4ng\u00b7ni\u00df", ",", "gl\u00fcck", "und", "zeit", ",", "ihr", "meis\u00b7ter", "al\u00b7ler", "sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "KON", "NN", "$,", "PPOSAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sagt, was wird endlich doch aus mir die liebe machen?", "tokens": ["Sagt", ",", "was", "wird", "end\u00b7lich", "doch", "aus", "mir", "die", "lie\u00b7be", "ma\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "VAFIN", "ADV", "ADV", "APPR", "PPER", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ein fisch, der sich vom angel lo\u00dfgerissen,", "tokens": ["Ein", "fisch", ",", "der", "sich", "vom", "an\u00b7gel", "lo\u00df\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "PRELS", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Eilt nicht so bald dem falschen k\u00f6der nach;", "tokens": ["Eilt", "nicht", "so", "bald", "dem", "fal\u00b7schen", "k\u00f6\u00b7der", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein schiffmann wird den ort zu meiden wissen,", "tokens": ["Ein", "schiff\u00b7mann", "wird", "den", "ort", "zu", "mei\u00b7den", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Allwo er mast und seegel nechst zerbrach:", "tokens": ["All\u00b7wo", "er", "mast", "und", "see\u00b7gel", "nechst", "zer\u00b7brach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nur ich armseeligster bleib itzt an Seyllen hangen,", "tokens": ["Nur", "ich", "arm\u00b7see\u00b7ligs\u00b7ter", "bleib", "itzt", "an", "Seyl\u00b7len", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJA", "VVFIN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "Ob gleich mein liebes-schiff Charybden kaum entgangen.", "tokens": ["Ob", "gleich", "mein", "lie\u00b7bes\u00b7schiff", "Cha\u00b7ryb\u00b7den", "kaum", "ent\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jedoch, wer kan die hand zur\u00fccke ziehen,", "tokens": ["Je\u00b7doch", ",", "wer", "kan", "die", "hand", "zu\u00b7r\u00fc\u00b7cke", "zie\u00b7hen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VMFIN", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn sch\u00f6nheit uns beut ihren nectar an?", "tokens": ["Wenn", "sch\u00f6n\u00b7heit", "uns", "beut", "ih\u00b7ren", "nec\u00b7tar", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der schwache mensch mu\u00df sich umsonst bem\u00fchen,", "tokens": ["Der", "schwa\u00b7che", "mensch", "mu\u00df", "sich", "um\u00b7sonst", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Weil niemand hier, als engel, leben kan.", "tokens": ["Weil", "nie\u00b7mand", "hier", ",", "als", "en\u00b7gel", ",", "le\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "$,", "KOUS", "NN", "$,", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der mund mag noch so viel von zucht und keuschheit sprechen;", "tokens": ["Der", "mund", "mag", "noch", "so", "viel", "von", "zucht", "und", "keuschheit", "spre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-++-", "measure": "unknown.measure.hexa"}, "line.6": {"text": "Ein sch\u00f6nes auge kan ihm bald den hochmuth brechen.", "tokens": ["Ein", "sch\u00f6\u00b7nes", "au\u00b7ge", "kan", "ihm", "bald", "den", "hoch\u00b7muth", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Lie\u00df Davids hand nicht harff und psalter liegen,", "tokens": ["Lie\u00df", "Da\u00b7vids", "hand", "nicht", "harff", "und", "psal\u00b7ter", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VVFIN", "PTKNEG", "ADJD", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Als Bathseba sein hertz gesetzt in brand?", "tokens": ["Als", "Bath\u00b7se\u00b7ba", "sein", "hertz", "ge\u00b7setzt", "in", "brand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPOSAT", "NN", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und Simsons faust verlernete zu siegen,", "tokens": ["Und", "Sim\u00b7sons", "faust", "ver\u00b7ler\u00b7ne\u00b7te", "zu", "sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als ihn ein weib mit ihren stricken band;", "tokens": ["Als", "ihn", "ein", "weib", "mit", "ih\u00b7ren", "stri\u00b7cken", "band", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Selbst Salomonis witz und klugheit gieng verlohren,", "tokens": ["Selbst", "Sa\u00b7lo\u00b7mo\u00b7nis", "witz", "und", "klug\u00b7heit", "gieng", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "KON", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die weiber-liebe schrieb ihn in die zahl der thoren.", "tokens": ["Die", "wei\u00b7ber\u00b7lie\u00b7be", "schrieb", "ihn", "in", "die", "zahl", "der", "tho\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Kan sch\u00f6nheit nun so s\u00fc\u00dfen neetar schencken,", "tokens": ["Kan", "sch\u00f6n\u00b7heit", "nun", "so", "s\u00fc\u00b7\u00dfen", "nee\u00b7tar", "schen\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der f\u00fcrsten st\u00fcrtzt und helden taumeln lehrt:", "tokens": ["Der", "f\u00fcrs\u00b7ten", "st\u00fcrtzt", "und", "hel\u00b7den", "tau\u00b7meln", "lehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KON", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was wunder? wenn mit ihren zauber-tr\u00e4ncken,", "tokens": ["Was", "wun\u00b7der", "?", "wenn", "mit", "ih\u00b7ren", "zau\u00b7ber\u00b7tr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "KOUS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie meinen geist itz und aufs neu beth\u00f6rt.", "tokens": ["Sie", "mei\u00b7nen", "geist", "itz", "und", "aufs", "neu", "be\u00b7th\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "NE", "KON", "APPRART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich wag es noch einmal und fehl ich auch noch heute;", "tokens": ["Ich", "wag", "es", "noch", "ein\u00b7mal", "und", "fehl", "ich", "auch", "noch", "heu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "KON", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So ist mein fehler doch ein fehler gro\u00dfer leute.", "tokens": ["So", "ist", "mein", "feh\u00b7ler", "doch", "ein", "feh\u00b7ler", "gro\u00b7\u00dfer", "leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}