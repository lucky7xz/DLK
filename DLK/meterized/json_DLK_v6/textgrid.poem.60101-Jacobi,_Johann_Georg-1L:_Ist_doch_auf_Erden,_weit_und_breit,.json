{"textgrid.poem.60101": {"metadata": {"author": {"name": "Jacobi, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ist doch auf Erden, weit und breit,", "genre": "verse", "period": "N.A.", "pub_year": 1777, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ist doch auf Erden, weit und breit,", "tokens": ["Ist", "doch", "auf", "Er\u00b7den", ",", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wenig Recht und Billigkeit,", "tokens": ["So", "we\u00b7nig", "Recht", "und", "Bil\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df auch der allerbeste Mann", "tokens": ["Da\u00df", "auch", "der", "al\u00b7ler\u00b7bes\u00b7te", "Mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Unschuld oft betr\u00fcben kann!", "tokens": ["Die", "Un\u00b7schuld", "oft", "be\u00b7tr\u00fc\u00b7ben", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da klagen Sie uns M\u00e4dchen an,", "tokens": ["Da", "kla\u00b7gen", "Sie", "uns", "M\u00e4d\u00b7chen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als setzten wir ins Werk der Nadel", "tokens": ["Als", "setz\u00b7ten", "wir", "ins", "Werk", "der", "Na\u00b7del"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das h\u00f6chste Lob, den h\u00f6chsten Tadel;", "tokens": ["Das", "h\u00f6chs\u00b7te", "Lob", ",", "den", "h\u00f6chs\u00b7ten", "Ta\u00b7del", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und was den Leumond \u00e4rger macht,", "tokens": ["Und", "was", "den", "Leu\u00b7mond", "\u00e4r\u00b7ger", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Dadurch des Hauses Nutz und Ehren,", "tokens": ["Da\u00b7durch", "des", "Hau\u00b7ses", "Nutz", "und", "Eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wie unsre M\u00fctter, zu vermehren;", "tokens": ["Wie", "uns\u00b7re", "M\u00fct\u00b7ter", ",", "zu", "ver\u00b7meh\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Als lebten wir vom Zeitvertrieb,", "tokens": ["Als", "leb\u00b7ten", "wir", "vom", "Zeit\u00b7ver\u00b7trieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "In jeder Woch' auf unsern Leib", "tokens": ["In", "je\u00b7der", "Wo\u00b7ch'", "auf", "un\u00b7sern", "Leib"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Ein neues P\u00f6\u00dfchen hinzut\u00e4ndeln,", "tokens": ["Ein", "neu\u00b7es", "P\u00f6\u00df\u00b7chen", "hin\u00b7zu\u00b7t\u00e4n\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und spr\u00e4chen, sonder Ueberdru\u00df,", "tokens": ["Und", "spr\u00e4\u00b7chen", ",", "son\u00b7der", "Ue\u00b7berd\u00b7ru\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Davon, wie ein Politicus", "tokens": ["Da\u00b7von", ",", "wie", "ein", "Po\u00b7li\u00b7ti\u00b7cus"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PAV", "$,", "PWAV", "ART", "NN"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Von seinen Kriegs- und Friedensh\u00e4ndeln;", "tokens": ["Von", "sei\u00b7nen", "Kriegs", "und", "Frie\u00b7dens\u00b7h\u00e4n\u00b7deln", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Als w\u00e4re das, was Kinder froh", "tokens": ["Als", "w\u00e4\u00b7re", "das", ",", "was", "Kin\u00b7der", "froh"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PDS", "$,", "PWS", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Und gl\u00fccklich macht, uns nur willkommen ...", "tokens": ["Und", "gl\u00fcck\u00b7lich", "macht", ",", "uns", "nur", "will\u00b7kom\u00b7men", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$,", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Doch g\u00e4b' es hundert M\u00e4dchen so \u2013", "tokens": ["Doch", "g\u00e4b'", "es", "hun\u00b7dert", "M\u00e4d\u00b7chen", "so", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "CARD", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Wir beyde blieben ausgenommen.", "tokens": ["Wir", "bey\u00b7de", "blie\u00b7ben", "aus\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es bannt die feine Sitte zwar", "tokens": ["Es", "bannt", "die", "fei\u00b7ne", "Sit\u00b7te", "zwar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Spindel und den Rahmen gar;", "tokens": ["Die", "Spin\u00b7del", "und", "den", "Rah\u00b7men", "gar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein St\u00fcck wird mehr von uns gewebt,", "tokens": ["Kein", "St\u00fcck", "wird", "mehr", "von", "uns", "ge\u00b7webt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Das k\u00fcnftig bey den Erben lebt.", "tokens": ["Das", "k\u00fcnf\u00b7tig", "bey", "den", "Er\u00b7ben", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch macht den Zierrath unsrer Kleider", "tokens": ["Auch", "macht", "den", "Zier\u00b7rath", "uns\u00b7rer", "Klei\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die allerneuste Mode leider", "tokens": ["Die", "al\u00b7ler\u00b7neus\u00b7te", "Mo\u00b7de", "lei\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So spinnenm\u00e4\u00dfig zart und d\u00fcnn,", "tokens": ["So", "spin\u00b7nen\u00b7m\u00e4\u00b7\u00dfig", "zart", "und", "d\u00fcnn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie unsrer M\u00e4nner Flattersinn;", "tokens": ["Wie", "uns\u00b7rer", "M\u00e4n\u00b7ner", "Flat\u00b7ter\u00b7sinn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da gehn die ersten Wochen hin;", "tokens": ["Da", "gehn", "die", "ers\u00b7ten", "Wo\u00b7chen", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Weg ist der Staat! ihn nutzt ein Jude", "tokens": ["Weg", "ist", "der", "Staat", "!", "ihn", "nutzt", "ein", "Ju\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN", "$.", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Noch kaum in seiner Tr\u00f6delbude;", "tokens": ["Noch", "kaum", "in", "sei\u00b7ner", "Tr\u00f6\u00b7del\u00b7bu\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Geschweige denn die Enkelinn.", "tokens": ["Ge\u00b7schwei\u00b7ge", "denn", "die", "En\u00b7ke\u00b7linn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Wer aber darf an Sch\u00fcrz' und B\u00e4ndern,", "tokens": ["Wer", "a\u00b7ber", "darf", "an", "Sch\u00fcrz'", "und", "B\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "An Hut und Locken etwas \u00e4ndern?", "tokens": ["An", "Hut", "und", "Lo\u00b7cken", "et\u00b7was", "\u00e4n\u00b7dern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Um mit den Meisten fortzuschlendern,", "tokens": ["Um", "mit", "den", "Meis\u00b7ten", "fort\u00b7zu\u00b7schlen\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Bed\u00fcrfen wir zu jeder Nath,", "tokens": ["Be\u00b7d\u00fcr\u00b7fen", "wir", "zu", "je\u00b7der", "Nath", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Zu jeder Schleife guten Rath;", "tokens": ["Zu", "je\u00b7der", "Schlei\u00b7fe", "gu\u00b7ten", "Rath", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Gern aber lassen wir uns st\u00f6ren,", "tokens": ["Gern", "a\u00b7ber", "las\u00b7sen", "wir", "uns", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Um etwas Kl\u00fcgres anzuh\u00f6ren.", "tokens": ["Um", "et\u00b7was", "Kl\u00fcg\u00b7res", "an\u00b7zu\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Will uns ein Biedermann belehren,", "tokens": ["Will", "uns", "ein", "Bie\u00b7der\u00b7mann", "be\u00b7leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Er ist uns theurer, glauben Sie's!", "tokens": ["Er", "ist", "uns", "theu\u00b7rer", ",", "glau\u00b7ben", "Sie's", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "$,", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Als irgend einer, dem Paris", "tokens": ["Als", "ir\u00b7gend", "ei\u00b7ner", ",", "dem", "Pa\u00b7ris"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "$,", "ART", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die letzten Mode-Puppen wies.", "tokens": ["Die", "letz\u00b7ten", "Mo\u00b7de\u00b7Pup\u00b7pen", "wies", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "So d\u00fcnken wir, frisirt als Igel,", "tokens": ["So", "d\u00fcn\u00b7ken", "wir", ",", "fri\u00b7sirt", "als", "I\u00b7gel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVPP", "KOKOM", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.25": {"text": "Uns bey dem gl\u00e4nzendsten Besuch", "tokens": ["Uns", "bey", "dem", "gl\u00e4n\u00b7zends\u00b7ten", "Be\u00b7such"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.26": {"text": "Nicht mehr, als unterm H\u00fclletuch", "tokens": ["Nicht", "mehr", ",", "als", "un\u00b7term", "H\u00fcl\u00b7le\u00b7tuch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "$,", "KOUS", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Bey vorgeschobnem Kammerriegel,", "tokens": ["Bey", "vor\u00b7ge\u00b7schob\u00b7nem", "Kam\u00b7mer\u00b7rie\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und gucken seltner in den Spiegel", "tokens": ["Und", "gu\u00b7cken", "selt\u00b7ner", "in", "den", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Vielleicht, als in ein gutes Buch.", "tokens": ["Viel\u00b7leicht", ",", "als", "in", "ein", "gu\u00b7tes", "Buch", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Gilt's eine Wette, lieber Rector?", "tokens": ["Gilt's", "ei\u00b7ne", "Wet\u00b7te", ",", "lie\u00b7ber", "Rec\u00b7tor", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Es sind Achill, Uly\u00df und Hector,", "tokens": ["Es", "sind", "A\u00b7chill", ",", "U\u00b7ly\u00df", "und", "Hec\u00b7tor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "NE", "KON", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.32": {"text": "Sammt Troja, der ber\u00fchmten Stadt", "tokens": ["Sammt", "Tro\u00b7ja", ",", "der", "be\u00b7r\u00fchm\u00b7ten", "Stadt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Uns so bekannt, wie Goliath", "tokens": ["Uns", "so", "be\u00b7kannt", ",", "wie", "Go\u00b7li\u00b7ath"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "ADJD", "$,", "PWAV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Und David in der Bilder-Bibel.", "tokens": ["Und", "Da\u00b7vid", "in", "der", "Bil\u00b7der\u00b7Bi\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wenn aber \u2013 und wer kann es \u00fcbel", "tokens": ["Wenn", "a\u00b7ber", "\u2013", "und", "wer", "kann", "es", "\u00fc\u00b7bel"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "$(", "KON", "PWS", "VMFIN", "PPER", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Uns deuten? \u2013 wenn zum \u00f6ftern Sie,", "tokens": ["Uns", "deu\u00b7ten", "?", "\u2013", "wenn", "zum", "\u00f6f\u00b7tern", "Sie", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "$(", "KOUS", "APPRART", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Ihrer Etymologie", "tokens": ["Mit", "Ih\u00b7rer", "E\u00b7ty\u00b7mo\u00b7lo\u00b7gie"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Langerweil' uns zu versteinern,", "tokens": ["Vor", "Lan\u00b7ger\u00b7weil'", "uns", "zu", "ver\u00b7stei\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sammt unserm Bruder hochgelahrt,", "tokens": ["Sammt", "un\u00b7serm", "Bru\u00b7der", "hoch\u00b7ge\u00b7lahrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht scheuend unsre Gegenwart,", "tokens": ["Nicht", "scheu\u00b7end", "uns\u00b7re", "Ge\u00b7gen\u00b7wart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Aus Griechen, W\u00e4lschen und Lateinern,", "tokens": ["Aus", "Grie\u00b7chen", ",", "W\u00e4l\u00b7schen", "und", "La\u00b7tei\u00b7nern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Wort in ", "tokens": ["Ein", "Wort", "in"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "APPR"], "meter": "+--", "measure": "dactylic.init"}, "line.9": {"text": "So lang betrachten um und um,", "tokens": ["So", "lang", "be\u00b7trach\u00b7ten", "um", "und", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Es messen in die L\u00e4ng' und Quer',", "tokens": ["Es", "mes\u00b7sen", "in", "die", "L\u00e4ng'", "und", "Quer'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Bis sie errathen ungef\u00e4hr,", "tokens": ["Bis", "sie", "er\u00b7ra\u00b7then", "un\u00b7ge\u00b7f\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wann's in die Welt kam, und woher;", "tokens": ["Wann's", "in", "die", "Welt", "kam", ",", "und", "wo\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Zuweilen dr\u00fcber eine Fehde", "tokens": ["Zu\u00b7wei\u00b7len", "dr\u00fc\u00b7ber", "ei\u00b7ne", "Feh\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PAV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Beginnen, gleich als ob die Rede", "tokens": ["Be\u00b7gin\u00b7nen", ",", "gleich", "als", "ob", "die", "Re\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "KOKOM", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Vom Stammbaum unsers F\u00fcrsten w\u00e4r' \u2013", "tokens": ["Vom", "Stamm\u00b7baum", "un\u00b7sers", "F\u00fcrs\u00b7ten", "w\u00e4r'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "O dann, gewi\u00df durchs Ihre Schuld,", "tokens": ["O", "dann", ",", "ge\u00b7wi\u00df", "durchs", "Ih\u00b7re", "Schuld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$,", "ADV", "APPRART", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Zerrei\u00dft uns endlich die Geduld;", "tokens": ["Zer\u00b7rei\u00dft", "uns", "end\u00b7lich", "die", "Ge\u00b7duld", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Denn w\u00e4hrend Sie ein einzig Wort", "tokens": ["Denn", "w\u00e4h\u00b7rend", "Sie", "ein", "ein\u00b7zig", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "So, nach Gefallen, radebrechen,", "tokens": ["So", ",", "nach", "Ge\u00b7fal\u00b7len", ",", "ra\u00b7de\u00b7bre\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "K\u00f6nnt' unser eine \u2013 welch ein Mord! \u2013", "tokens": ["K\u00f6nnt'", "un\u00b7ser", "ei\u00b7ne", "\u2013", "welch", "ein", "Mord", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPOSAT", "ART", "$(", "PWAT", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wohl ihrer viele tausend sprechen.", "tokens": ["Wohl", "ih\u00b7rer", "vie\u00b7le", "tau\u00b7send", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "PIAT", "CARD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wir aber denken uns zu r\u00e4chen.", "tokens": ["Wir", "a\u00b7ber", "den\u00b7ken", "uns", "zu", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist erst der lange Winter aus,", "tokens": ["Ist", "erst", "der", "lan\u00b7ge", "Win\u00b7ter", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Sie begehren einen Strau\u00df,", "tokens": ["Und", "Sie", "be\u00b7geh\u00b7ren", "ei\u00b7nen", "Strau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da sollen Sie von jeder Art", "tokens": ["Da", "sol\u00b7len", "Sie", "von", "je\u00b7der", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Fr\u00fchlingsblumen, die wir pfl\u00fccken,", "tokens": ["Der", "Fr\u00fch\u00b7lings\u00b7blu\u00b7men", ",", "die", "wir", "pfl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Erz\u00e4hlen, ehe wir uns b\u00fccken,", "tokens": ["Er\u00b7z\u00e4h\u00b7len", ",", "e\u00b7he", "wir", "uns", "b\u00fc\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wie sie ges\u00e4't, gepflanzet ward,", "tokens": ["Wie", "sie", "ge\u00b7s\u00e4't", ",", "ge\u00b7pflan\u00b7zet", "ward", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "$,", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und wie sich in den Keimem zart", "tokens": ["Und", "wie", "sich", "in", "den", "Kei\u00b7mem", "zart"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PRF", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Bl\u00e4tter bildeten und schieden. \u2013", "tokens": ["Die", "Bl\u00e4t\u00b7ter", "bil\u00b7de\u00b7ten", "und", "schie\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wenn uns der Himmel nur bewahrt,", "tokens": ["Wenn", "uns", "der", "Him\u00b7mel", "nur", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Da\u00df wir nicht eher noch erm\u00fcden,", "tokens": ["Da\u00df", "wir", "nicht", "e\u00b7her", "noch", "er\u00b7m\u00fc\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Als Sie mit Ihrem kalten Blut!", "tokens": ["Als", "Sie", "mit", "Ih\u00b7rem", "kal\u00b7ten", "Blut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Denn, lieber Rector, kurz und gut!", "tokens": ["Denn", ",", "lie\u00b7ber", "Rec\u00b7tor", ",", "kurz", "und", "gut", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Dem M\u00e4dchen ist es nicht gegeben,", "tokens": ["Dem", "M\u00e4d\u00b7chen", "ist", "es", "nicht", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da\u00df stundenlang, mit festem Muth,", "tokens": ["Da\u00df", "stun\u00b7den\u00b7lang", ",", "mit", "fes\u00b7tem", "Muth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Sein Geist auf Einem Dinge ruht.", "tokens": ["Sein", "Geist", "auf", "Ei\u00b7nem", "Din\u00b7ge", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Wir ahnden, sehn, genie\u00dfen, schweben,", "tokens": ["Wir", "ahn\u00b7den", ",", "sehn", ",", "ge\u00b7nie\u00b7\u00dfen", ",", "schwe\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Nach Art der Honigtr\u00e4gerinn,", "tokens": ["Nach", "Art", "der", "Ho\u00b7nig\u00b7tr\u00e4\u00b7ge\u00b7rinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Um etwas Andres zu erstreben.", "tokens": ["Um", "et\u00b7was", "And\u00b7res", "zu", "er\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "So will's Natur: Ein leichter Sinn", "tokens": ["So", "will's", "Na\u00b7tur", ":", "Ein", "leich\u00b7ter", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wird uns zum k\u00f6stlichen Gewinn;", "tokens": ["Wird", "uns", "zum", "k\u00f6st\u00b7li\u00b7chen", "Ge\u00b7winn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Er l\u00e4\u00dft in dieses Alltagsleben", "tokens": ["Er", "l\u00e4\u00dft", "in", "die\u00b7ses", "All\u00b7tags\u00b7le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Uns frohe Zwischenspiele weben;", "tokens": ["Uns", "fro\u00b7he", "Zwi\u00b7schen\u00b7spie\u00b7le", "we\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Mit ihm verl\u00f6ren wir zugleich", "tokens": ["Mit", "ihm", "ver\u00b7l\u00f6\u00b7ren", "wir", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Den Reiz des Neuen, der die Liebe", "tokens": ["Den", "Reiz", "des", "Neu\u00b7en", ",", "der", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Des Mannes einzig n\u00e4hrt: Wo bliebe", "tokens": ["Des", "Man\u00b7nes", "ein\u00b7zig", "n\u00e4hrt", ":", "Wo", "blie\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$.", "PWAV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Dann unser ganzes K\u00f6nigreich?", "tokens": ["Dann", "un\u00b7ser", "gan\u00b7zes", "K\u00f6\u00b7nig\u00b7reich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}