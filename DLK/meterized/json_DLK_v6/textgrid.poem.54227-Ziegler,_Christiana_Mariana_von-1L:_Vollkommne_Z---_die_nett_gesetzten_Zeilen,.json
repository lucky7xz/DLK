{"textgrid.poem.54227": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vollkommne Z--- die nett gesetzten Zeilen,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vollkommne Z--- die nett gesetzten Zeilen,", "tokens": ["Voll\u00b7komm\u00b7ne", "Z\u00b7", "die", "nett", "ge\u00b7setz\u00b7ten", "Zei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "TRUNC", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "meter.parsing.error", "measure": "measure.parsing.error"}, "line.2": {"text": "So mir mein lieber Freund und Vetter \u00fcberbracht,", "tokens": ["So", "mir", "mein", "lie\u00b7ber", "Freund", "und", "Vet\u00b7ter", "\u00fc\u00b7berb\u00b7racht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPOSAT", "ADJA", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erregen Sinn und Hand, da\u00df sie zur Antwort eilen,", "tokens": ["Er\u00b7re\u00b7gen", "Sinn", "und", "Hand", ",", "da\u00df", "sie", "zur", "Ant\u00b7wort", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und kaum besinn ich mich, so ist sie vollgemacht.", "tokens": ["Und", "kaum", "be\u00b7sinn", "ich", "mich", ",", "so", "ist", "sie", "voll\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch fehlet Geist und Feur und sonst geschicktes Wesen,", "tokens": ["Doch", "feh\u00b7let", "Geist", "und", "Feur", "und", "sonst", "ge\u00b7schick\u00b7tes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So blo\u00df zu dieser Kunst und s\u00fcssen Spiel geh\u00f6rt,", "tokens": ["So", "blo\u00df", "zu", "die\u00b7ser", "Kunst", "und", "s\u00fcs\u00b7sen", "Spiel", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PDAT", "NN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da die von Z--- weit kl\u00fcgre Schrifft gelesen,", "tokens": ["Da", "die", "von", "Z\u00b7", "weit", "kl\u00fcg\u00b7re", "Schrifft", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "TRUNC", "ADJD", "ADJA", "NN", "VVPP", "$,"], "meter": "meter.parsing.error", "measure": "measure.parsing.error"}, "line.8": {"text": "Als das, womit mein Kiel das reine Blat versehrt.", "tokens": ["Als", "das", ",", "wo\u00b7mit", "mein", "Kiel", "das", "rei\u00b7ne", "Blat", "ver\u00b7sehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PWAV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun aber l\u00e4sset mich das Alter nicht erjagen,", "tokens": ["Nun", "a\u00b7ber", "l\u00e4s\u00b7set", "mich", "das", "Al\u00b7ter", "nicht", "er\u00b7ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was meiner Jugend Lentz nicht l\u00e4ngsten hat gethan,", "tokens": ["Was", "mei\u00b7ner", "Ju\u00b7gend", "Lentz", "nicht", "l\u00e4ngs\u00b7ten", "hat", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "NE", "PTKNEG", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So mu\u00df ich mich betr\u00fcbt beym Helicon verklagen,", "tokens": ["So", "mu\u00df", "ich", "mich", "be\u00b7tr\u00fcbt", "beym", "He\u00b7li\u00b7con", "ver\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVPP", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und bitte, sieh den Brief, nicht meine Fehler, an.", "tokens": ["Und", "bit\u00b7te", ",", "sieh", "den", "Brief", ",", "nicht", "mei\u00b7ne", "Feh\u00b7ler", ",", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "VVIMP", "ART", "NN", "$,", "PTKNEG", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hingegen freu ich mich, da\u00df du an mich gedenckest,", "tokens": ["Hin\u00b7ge\u00b7gen", "freu", "ich", "mich", ",", "da\u00df", "du", "an", "mich", "ge\u00b7den\u00b7ckest", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+++-+-", "measure": "iambic.septa.invert"}, "line.14": {"text": "Ich nenne deine Lieb, als das was mich erg\u00f6tzt.", "tokens": ["Ich", "nen\u00b7ne", "dei\u00b7ne", "Lieb", ",", "als", "das", "was", "mich", "er\u00b7g\u00f6tzt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KOUS", "PDS", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Weil du zu gleicher Zeit mir Hertz und Zuschrifft schenckest,", "tokens": ["Weil", "du", "zu", "glei\u00b7cher", "Zeit", "mir", "Hertz", "und", "Zu\u00b7schrifft", "schen\u00b7ckest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "PPER", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Empfind ich, was mich auch schon ausser mich gesetzt.", "tokens": ["Emp\u00b7find", "ich", ",", "was", "mich", "auch", "schon", "aus\u00b7ser", "mich", "ge\u00b7setzt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "PWS", "PPER", "ADV", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Auch solt ich m\u00f6glichstens dein seltnes Lob erh\u00f6hen;", "tokens": ["Auch", "solt", "ich", "m\u00f6g\u00b7lichs\u00b7tens", "dein", "selt\u00b7nes", "Lob", "er\u00b7h\u00f6\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch meine F\u00e4higkeit ist hierzu nicht geschickt.", "tokens": ["Doch", "mei\u00b7ne", "F\u00e4\u00b7hig\u00b7keit", "ist", "hier\u00b7zu", "nicht", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PAV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So kan ich nicht bey dir als zehnte Muse stehen,", "tokens": ["So", "kan", "ich", "nicht", "bey", "dir", "als", "zehn\u00b7te", "Mu\u00b7se", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "APPR", "PPER", "KOUS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Es bleibt mir gegen dich so Geist als Leib geb\u00fcckt.", "tokens": ["Es", "bleibt", "mir", "ge\u00b7gen", "dich", "so", "Geist", "als", "Leib", "ge\u00b7b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPER", "ADV", "NN", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Mein Vetter sagte mir, was deinen Ruhm vermehrte,", "tokens": ["Mein", "Vet\u00b7ter", "sag\u00b7te", "mir", ",", "was", "dei\u00b7nen", "Ruhm", "ver\u00b7mehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,", "PRELS", "PPOSAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und dich vollkommner macht, sey sch\u00f6n seyn und galant.", "tokens": ["Und", "dich", "voll\u00b7komm\u00b7ner", "macht", ",", "sey", "sch\u00f6n", "seyn", "und", "ga\u00b7lant", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "VVFIN", "$,", "VAFIN", "ADJD", "VAINF", "KON", "ADJD", "$."], "meter": "-+-+-+-++-+-", "measure": "unknown.measure.hexa"}, "line.23": {"text": "Er merckte, wie vergn\u00fcgt ich solchen Lobspruch h\u00f6rte,", "tokens": ["Er", "merck\u00b7te", ",", "wie", "ver\u00b7gn\u00fcgt", "ich", "sol\u00b7chen", "Lob\u00b7spruch", "h\u00f6r\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Sie ist, so fuhr er fort, der klugen Welt bekannt.", "tokens": ["Sie", "ist", ",", "so", "fuhr", "er", "fort", ",", "der", "klu\u00b7gen", "Welt", "be\u00b7kannt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Doch mu\u00df ich bey dem Schlu\u00df der Bitte nicht vergessen,", "tokens": ["Doch", "mu\u00df", "ich", "bey", "dem", "Schlu\u00df", "der", "Bit\u00b7te", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Dem ding ich deine Huld als mein Verlangen ein,", "tokens": ["Dem", "ding", "ich", "dei\u00b7ne", "Huld", "als", "mein", "Ver\u00b7lan\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PPOSAT", "NN", "KOKOM", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Von mir nimm diesen Brief in Sylben abgemessen,", "tokens": ["Von", "mir", "nimm", "die\u00b7sen", "Brief", "in", "Syl\u00b7ben", "ab\u00b7ge\u00b7mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Zum Zeugni\u00df, da\u00df ich stets von Hertzen werde seyn", "tokens": ["Zum", "Zeug\u00b7ni\u00df", ",", "da\u00df", "ich", "stets", "von", "Hert\u00b7zen", "wer\u00b7de", "seyn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "ADV", "APPR", "NN", "VAFIN", "PPOSAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}