{"textgrid.poem.62923": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Esel trat als Supplicant", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Esel trat als Supplicant", "tokens": ["Der", "E\u00b7sel", "trat", "als", "Sup\u00b7pli\u00b7cant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum L\u00f6wen. Sir, darf ich es wagen,", "tokens": ["Zum", "L\u00f6\u00b7wen", ".", "Sir", ",", "darf", "ich", "es", "wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "NN", "$,", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sprach er, ein Wort dir vorzutragen?", "tokens": ["Sprach", "er", ",", "ein", "Wort", "dir", "vor\u00b7zu\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ART", "NN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Polizey in jedem Land", "tokens": ["Die", "Po\u00b7li\u00b7zey", "in", "je\u00b7dem", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat M\u00e4nner von Talent ernannt,", "tokens": ["Hat", "M\u00e4n\u00b7ner", "von", "Ta\u00b7lent", "er\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Des Nachts die Stunden anzusagen:", "tokens": ["Des", "Nachts", "die", "Stun\u00b7den", "an\u00b7zu\u00b7sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nun wissen Berge, Thal und Wald,", "tokens": ["Nun", "wis\u00b7sen", "Ber\u00b7ge", ",", "Thal", "und", "Wald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie m\u00e4chtig meine T\u00f6ne schallen,", "tokens": ["Wie", "m\u00e4ch\u00b7tig", "mei\u00b7ne", "T\u00f6\u00b7ne", "schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Drum bitt ich, Sir, la\u00df dir gefallen", "tokens": ["Drum", "bitt", "ich", ",", "Sir", ",", "la\u00df", "dir", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "$,", "NN", "$,", "VVIMP", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Mit einem m\u00e4\u00dfigen Gehalt", "tokens": ["Mit", "ei\u00b7nem", "m\u00e4\u00b7\u00dfi\u00b7gen", "Ge\u00b7halt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Von Rocken, Haber oder Kleyen", "tokens": ["Von", "Ro\u00b7cken", ",", "Ha\u00b7ber", "o\u00b7der", "Kle\u00b7yen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Das W\u00e4chteramt mir zu verleihen.", "tokens": ["Das", "W\u00e4ch\u00b7ter\u00b7amt", "mir", "zu", "ver\u00b7lei\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Er senkt das Ohr und schweigt. Alsbald", "tokens": ["Er", "senkt", "das", "Ohr", "und", "schweigt", ".", "Als\u00b7bald"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wird seine Bitte placidieret;", "tokens": ["Wird", "sei\u00b7ne", "Bit\u00b7te", "pla\u00b7ci\u00b7die\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Der Esel wird durch Stab und Horn", "tokens": ["Der", "E\u00b7sel", "wird", "durch", "Stab", "und", "Horn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Zum Stundenrufer investieret,", "tokens": ["Zum", "Stun\u00b7den\u00b7ru\u00b7fer", "in\u00b7ves\u00b7tie\u00b7ret", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Und ein Gehalt von Heidekorn", "tokens": ["Und", "ein", "Ge\u00b7halt", "von", "Hei\u00b7de\u00b7korn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Wird ihm in Gnaden assignieret.", "tokens": ["Wird", "ihm", "in", "Gna\u00b7den", "as\u00b7sig\u00b7nie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Die Nacht bricht ein. Wie Boreas", "tokens": ["Die", "Nacht", "bricht", "ein", ".", "Wie", "Bo\u00b7re\u00b7as"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$.", "PWAV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ruft er: ihr Herren, la\u00dft euch sagen ...", "tokens": ["Ruft", "er", ":", "ihr", "Her\u00b7ren", ",", "la\u00dft", "euch", "sa\u00b7gen", "..."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPOSAT", "NN", "$,", "VVIMP", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Dem Hof gefiel der neue Spa\u00df;", "tokens": ["Dem", "Hof", "ge\u00b7fiel", "der", "neu\u00b7e", "Spa\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Doch, als der Seiger Eins geschlagen", "tokens": ["Doch", ",", "als", "der", "Sei\u00b7ger", "Eins", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Und er noch rief, da fieng der Chan", "tokens": ["Und", "er", "noch", "rief", ",", "da", "fi\u00b7eng", "der", "Chan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "Den Schreyer zu verw\u00fcnschen an;", "tokens": ["Den", "Schre\u00b7yer", "zu", "ver\u00b7w\u00fcn\u00b7schen", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Und Luna gieng noch nicht zur Neige,", "tokens": ["Und", "Lu\u00b7na", "gieng", "noch", "nicht", "zur", "Nei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ADV", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "So bot er durch ein Windspiel ihn", "tokens": ["So", "bot", "er", "durch", "ein", "Wind\u00b7spiel", "ihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Auf seine Burg. Das Thier erschien.", "tokens": ["Auf", "sei\u00b7ne", "Burg", ".", "Das", "Thier", "er\u00b7schien", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Geh, fri\u00df dein Korn daheim und schweige.", "tokens": ["Geh", ",", "fri\u00df", "dein", "Korn", "da\u00b7heim", "und", "schwei\u00b7ge", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "PPOSAT", "NN", "ADV", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "So sprach der F\u00fcrst und lie\u00df ihn ziehn;", "tokens": ["So", "sprach", "der", "F\u00fcrst", "und", "lie\u00df", "ihn", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Und so entstanden in dem Staate", "tokens": ["Und", "so", "ent\u00b7stan\u00b7den", "in", "dem", "Staa\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Die fetten Hofkanonikate", "tokens": ["Die", "fet\u00b7ten", "Hof\u00b7ka\u00b7no\u00b7ni\u00b7ka\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "F\u00fcr Eseln, die auf Polstern ruhn,", "tokens": ["F\u00fcr", "E\u00b7seln", ",", "die", "auf", "Pols\u00b7tern", "ruhn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Und Sold beziehn um nichts zu thun.", "tokens": ["Und", "Sold", "be\u00b7ziehn", "um", "nichts", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}