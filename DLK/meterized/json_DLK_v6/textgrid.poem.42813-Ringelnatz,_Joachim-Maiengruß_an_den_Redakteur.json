{"textgrid.poem.42813": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Maiengru\u00df an den Redakteur", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fr\u00fchlingszartes Wohlbehagen", "tokens": ["Fr\u00fch\u00b7lings\u00b7zar\u00b7tes", "Wohl\u00b7be\u00b7ha\u00b7gen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwellt erfrorne Poesie.", "tokens": ["Schwellt", "er\u00b7fror\u00b7ne", "Poe\u00b7sie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Maiberauscht im Speisewagen", "tokens": ["Mai\u00b7be\u00b7rauscht", "im", "Spei\u00b7se\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ballt sich etwas wie Genie.", "tokens": ["Ballt", "sich", "et\u00b7was", "wie", "Ge\u00b7nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIS", "KOKOM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Weil Berlin voraus in Sicht ist", "tokens": ["Weil", "Ber\u00b7lin", "vo\u00b7raus", "in", "Sicht", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "PTKVZ", "APPR", "NN", "VAFIN"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Und die Sonne mich bestrahlt.", "tokens": ["Und", "die", "Son\u00b7ne", "mich", "be\u00b7strahlt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und je l\u00e4nger ein Gedicht ist,", "tokens": ["Und", "je", "l\u00e4n\u00b7ger", "ein", "Ge\u00b7dicht", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ART", "NN", "VAFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Desto besser wird's bezahlt.", "tokens": ["Des\u00b7to", "bes\u00b7ser", "wird's", "be\u00b7zahlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Darum: Hundertzweiundneunzig", "tokens": ["Da\u00b7rum", ":", "Hun\u00b7dert\u00b7zwei\u00b7und\u00b7neun\u00b7zig"], "token_info": ["word", "punct", "word"], "pos": ["PAV", "$.", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tausend und f\u00fcnfhundertzwei", "tokens": ["Tau\u00b7send", "und", "f\u00fcnf\u00b7hun\u00b7dert\u00b7zwei"], "token_info": ["word", "word", "word"], "pos": ["CARD", "KON", "CARD"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Oder noch mehr Leute freun sich.", "tokens": ["O\u00b7der", "noch", "mehr", "Leu\u00b7te", "freun", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VVFIN", "PRF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn der Winter ist vorbei.", "tokens": ["Denn", "der", "Win\u00b7ter", "ist", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Elf Millionen zweimal hundert", "tokens": ["Elf", "Mil\u00b7lion\u00b7en", "zwei\u00b7mal", "hun\u00b7dert"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tausend siebenhundertzehn", "tokens": ["Tau\u00b7send", "sie\u00b7ben\u00b7hun\u00b7dert\u00b7zehn"], "token_info": ["word", "word"], "pos": ["CARD", "CARD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Menschen sind etwas verwundert,", "tokens": ["Men\u00b7schen", "sind", "et\u00b7was", "ver\u00b7wun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIS", "VVFIN", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Weil kein Maik\u00e4fer zu sehn.", "tokens": ["Weil", "kein", "Mai\u00b7k\u00e4\u00b7fer", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Sechs Billionen zw\u00f6lf Milliarden \u2013", "tokens": ["Sechs", "Bil\u00b7li\u00b7o\u00b7nen", "zw\u00f6lf", "Mil\u00b7li\u00b7ar\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "CARD", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sch\u00e4tzungsweise \u2013 fragen sich:", "tokens": ["Sch\u00e4t\u00b7zungs\u00b7wei\u00b7se", "\u2013", "fra\u00b7gen", "sich", ":"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo steckt Maximilian Harden.", "tokens": ["Wo", "steckt", "Ma\u00b7xi\u00b7mi\u00b7li\u00b7an", "Har\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nun, verflucht, was k\u00fcmmert's mich.", "tokens": ["Nun", ",", "ver\u00b7flucht", ",", "was", "k\u00fcm\u00b7mert's", "mich", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVPP", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Vier Trillionen neun Billionen", "tokens": ["Vier", "Tril\u00b7li\u00b7o\u00b7nen", "neun", "Bil\u00b7li\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "CARD", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zirka siebenhundertelf", "tokens": ["Zir\u00b7ka", "sie\u00b7ben\u00b7hun\u00b7der\u00b7telf"], "token_info": ["word", "word"], "pos": ["NE", "CARD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Milliarden f\u00fcnf Millionen", "tokens": ["Mil\u00b7li\u00b7ar\u00b7den", "f\u00fcnf", "Mil\u00b7lion\u00b7en"], "token_info": ["word", "word", "word"], "pos": ["NN", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Achtzehntausend hundertzw\u00f6lf \u2013 \u2013", "tokens": ["Acht\u00b7zehn\u00b7tau\u00b7send", "hun\u00b7dert\u00b7zw\u00f6lf", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["CARD", "CARD", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und ich k\u00f6nnte das erweitern", "tokens": ["Und", "ich", "k\u00f6nn\u00b7te", "das", "er\u00b7wei\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PDS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bis in die Unendlichkeit,", "tokens": ["Bis", "in", "die", "Un\u00b7end\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Doch ein Dichter tritt den heitern", "tokens": ["Doch", "ein", "Dich\u00b7ter", "tritt", "den", "hei\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fr\u00fchlingszarten Mai nicht breit.", "tokens": ["Fr\u00fch\u00b7lings\u00b7zar\u00b7ten", "Mai", "nicht", "breit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sondern trinkt, sich selbst beschr\u00e4nkend,", "tokens": ["Son\u00b7dern", "trinkt", ",", "sich", "selbst", "be\u00b7schr\u00e4n\u00b7kend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Maienbowle, Maienkraut,", "tokens": ["Mai\u00b7en\u00b7bow\u00b7le", ",", "Mai\u00b7en\u00b7kraut", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seines Redakteurs gedenkend,", "tokens": ["Sei\u00b7nes", "Re\u00b7dak\u00b7teurs", "ge\u00b7den\u00b7kend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dem er voll und ganz vertraut.", "tokens": ["Dem", "er", "voll", "und", "ganz", "ver\u00b7traut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}