{"textgrid.poem.33018": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1. Sylvester", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Komm, vergi\u00df einmal all die Geschichten", "tokens": ["Komm", ",", "ver\u00b7gi\u00df", "ein\u00b7mal", "all", "die", "Ge\u00b7schich\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVIMP", "ADV", "PIAT", "ART", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "komm und begrab einmal all den Kram!", "tokens": ["komm", "und", "be\u00b7grab", "ein\u00b7mal", "all", "den", "Kram", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "ADV", "PIAT", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "es sind ja doch nur Lumpereien,", "tokens": ["es", "sind", "ja", "doch", "nur", "Lum\u00b7pe\u00b7rei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die einem nur das Herz zerqu\u00e4len,", "tokens": ["die", "ei\u00b7nem", "nur", "das", "Herz", "zer\u00b7qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die einen nur m\u00fcde machen und lahm!", "tokens": ["die", "ei\u00b7nen", "nur", "m\u00fc\u00b7de", "ma\u00b7chen", "und", "lahm", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "ADJD", "VVINF", "KON", "PTKVZ", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Die Menschen sind so, ich wei\u00df es wohl:", "tokens": ["Die", "Men\u00b7schen", "sind", "so", ",", "ich", "wei\u00df", "es", "wohl", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "statt fr\u00f6hlich und guter Dinge zu sein,", "tokens": ["statt", "fr\u00f6h\u00b7lich", "und", "gu\u00b7ter", "Din\u00b7ge", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJA", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "vern\u00f6rgeln sie sich die sch\u00f6nsten Stunden", "tokens": ["ver\u00b7n\u00f6r\u00b7geln", "sie", "sich", "die", "sch\u00f6ns\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "mit kindisch t\u00f6richten Hetzerein.", "tokens": ["mit", "kin\u00b7disch", "t\u00f6\u00b7rich\u00b7ten", "Het\u00b7ze\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie m\u00f6chten es selbst nicht, wenn man fr\u00e4gt ...", "tokens": ["Sie", "m\u00f6ch\u00b7ten", "es", "selbst", "nicht", ",", "wenn", "man", "fr\u00e4gt", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "PIS", "VVFIN", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "sie sehnen sich, harmloser sein zu d\u00fcrfen,", "tokens": ["sie", "seh\u00b7nen", "sich", ",", "harm\u00b7lo\u00b7ser", "sein", "zu", "d\u00fcr\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "ADJD", "VAINF", "PTKZU", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "sie nennen es Unrecht, Schande und Hohn", "tokens": ["sie", "nen\u00b7nen", "es", "Un\u00b7recht", ",", "Schan\u00b7de", "und", "Hohn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "NN", "KON", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "und m\u00f6chten heraus aus all dem Gez\u00e4nke ...", "tokens": ["und", "m\u00f6ch\u00b7ten", "he\u00b7raus", "aus", "all", "dem", "Ge\u00b7z\u00e4n\u00b7ke", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PIAT", "ART", "NN", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "und kommen doch nicht los davon ...", "tokens": ["und", "kom\u00b7men", "doch", "nicht", "los", "da\u00b7von", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "ADJD", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "und wenn man so zusieht, wie sie allm\u00e4hlich", "tokens": ["und", "wenn", "man", "so", "zu\u00b7sieht", ",", "wie", "sie", "all\u00b7m\u00e4h\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ADV", "VVFIN", "$,", "PWAV", "PPER", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "mutloser werden, tr\u00fcber und tr\u00fcber ...", "tokens": ["mut\u00b7lo\u00b7ser", "wer\u00b7den", ",", "tr\u00fc\u00b7ber", "und", "tr\u00fc\u00b7ber", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$,", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Mein Gott, man k\u00f6nnte weinen dr\u00fcber!", "tokens": ["Mein", "Gott", ",", "man", "k\u00f6nn\u00b7te", "wei\u00b7nen", "dr\u00fc\u00b7ber", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PIS", "VMFIN", "VVINF", "PAV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Lebt mit mehr Freude! ach, ich m\u00f6cht's", "tokens": ["Lebt", "mit", "mehr", "Freu\u00b7de", "!", "ach", ",", "ich", "m\u00f6cht's"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$.", "XY", "$,", "PPER", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gro\u00df wie die Sonne an den Himmel schreiben,", "tokens": ["gro\u00df", "wie", "die", "Son\u00b7ne", "an", "den", "Him\u00b7mel", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "da\u00df es wie Feuer in die Herzen loht ...", "tokens": ["da\u00df", "es", "wie", "Feu\u00b7er", "in", "die", "Her\u00b7zen", "loht", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "lebt mit mehr Freude und ohne die Not", "tokens": ["lebt", "mit", "mehr", "Freu\u00b7de", "und", "oh\u00b7ne", "die", "Not"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "KON", "APPR", "ART", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.5": {"text": "und ohne den Ha\u00df und ohne den Neid,", "tokens": ["und", "oh\u00b7ne", "den", "Ha\u00df", "und", "oh\u00b7ne", "den", "Neid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "an den ihr das halbe Leben verpa\u00dft ...", "tokens": ["an", "den", "ihr", "das", "hal\u00b7be", "Le\u00b7ben", "ver\u00b7pa\u00dft", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "macht's euch zu Lust und nicht zu Last!", "tokens": ["macht's", "euch", "zu", "Lust", "und", "nicht", "zu", "Last", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "PTKNEG", "APPR", "NE", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.8": {"text": "lebt mit mehr Freude,", "tokens": ["lebt", "mit", "mehr", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.9": {"text": "lebt mit mehr Rast!", "tokens": ["lebt", "mit", "mehr", "Rast", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}}}}