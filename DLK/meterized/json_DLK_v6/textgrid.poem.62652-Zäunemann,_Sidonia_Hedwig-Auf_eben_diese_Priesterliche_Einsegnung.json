{"textgrid.poem.62652": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Auf eben diese Priesterliche Einsegnung", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als Rom und Griechenland in seinem Flor noch war,", "tokens": ["Als", "Rom", "und", "Grie\u00b7chen\u00b7land", "in", "sei\u00b7nem", "Flor", "noch", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "KON", "NE", "APPR", "PPOSAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So hatte hier das Gl\u00fcck sein Feuer und Altar.", "tokens": ["So", "hat\u00b7te", "hier", "das", "Gl\u00fcck", "sein", "Feu\u00b7er", "und", "Al\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein Tempel wurde leer, man hat auf denen Knien,", "tokens": ["Kein", "Tem\u00b7pel", "wur\u00b7de", "leer", ",", "man", "hat", "auf", "de\u00b7nen", "Kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "$,", "PIS", "VAFIN", "APPR", "PRELS", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das Gl\u00fcck um seine Gunst und Beystand angeschrien.", "tokens": ["Das", "Gl\u00fcck", "um", "sei\u00b7ne", "Gunst", "und", "Beys\u00b7tand", "an\u00b7ge\u00b7schri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Die Tempel sind verheert; allein der G\u00f6tze nicht,", "tokens": ["Die", "Tem\u00b7pel", "sind", "ver\u00b7heert", ";", "al\u00b7lein", "der", "G\u00f6t\u00b7ze", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "ADV", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er hat sich anderswo viel Tempel aufgericht.", "tokens": ["Er", "hat", "sich", "an\u00b7ders\u00b7wo", "viel", "Tem\u00b7pel", "auf\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein Dienst geht durch die Welt, man sieht den gr\u00f6sten Haufen,", "tokens": ["Sein", "Dienst", "geht", "durch", "die", "Welt", ",", "man", "sieht", "den", "gr\u00f6s\u00b7ten", "Hau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "PIS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit heiser Andachts-Glut zu diesen G\u00f6tzen laufen.", "tokens": ["Mit", "hei\u00b7ser", "An\u00b7dachts\u00b7Glut", "zu", "die\u00b7sen", "G\u00f6t\u00b7zen", "lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es schmeichelt sich das Gl\u00fcck, da\u00df mans so hoch verehrt,", "tokens": ["Es", "schmei\u00b7chelt", "sich", "das", "Gl\u00fcck", ",", "da\u00df", "mans", "so", "hoch", "ver\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,", "KOUS", "PIS", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da es doch seine T\u00fcck so oft hervor gekehrt.", "tokens": ["Da", "es", "doch", "sei\u00b7ne", "T\u00fcck", "so", "oft", "her\u00b7vor", "ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "ADV", "ADV", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Durchsucht der Zeiten Lauf, ich wei\u00df, ihr werdet lesen,", "tokens": ["Durch\u00b7sucht", "der", "Zei\u00b7ten", "Lauf", ",", "ich", "wei\u00df", ",", "ihr", "wer\u00b7det", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "$,", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das Gl\u00fcck sey nur allein im Wechsel treu gewesen.", "tokens": ["Das", "Gl\u00fcck", "sey", "nur", "al\u00b7lein", "im", "Wech\u00b7sel", "treu", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "APPRART", "NN", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es lockt so angenehm, und scherzt wie Delila;", "tokens": ["Es", "lockt", "so", "an\u00b7ge\u00b7nehm", ",", "und", "scherzt", "wie", "De\u00b7li\u00b7la", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$,", "KON", "VVFIN", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Doch eh man sichs versieht, so ist der Ernst schon da,", "tokens": ["Doch", "eh", "man", "sichs", "ver\u00b7sieht", ",", "so", "ist", "der", "Ernst", "schon", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PIS", "VVFIN", "$,", "ADV", "VAFIN", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der unsern Fall bestellt. Forscht mehr, ihr werdet sehen,", "tokens": ["Der", "un\u00b7sern", "Fall", "be\u00b7stellt", ".", "Forscht", "mehr", ",", "ihr", "wer\u00b7det", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$.", "NN", "ADV", "$,", "PPER", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Es pflege nur das Gl\u00fcck mit Falschheit umzugehen:", "tokens": ["Es", "pfle\u00b7ge", "nur", "das", "Gl\u00fcck", "mit", "Falschheit", "um\u00b7zu\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Denn oft nimts einem was, und wei\u00dfts auch bald hinweg.", "tokens": ["Denn", "oft", "nimts", "ei\u00b7nem", "was", ",", "und", "wei\u00dfts", "auch", "bald", "hin\u00b7weg", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "PWS", "$,", "KON", "VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Es hat nebst diesem auch die Grausamkeit zum Zweck,", "tokens": ["Es", "hat", "nebst", "die\u00b7sem", "auch", "die", "Grau\u00b7sam\u00b7keit", "zum", "Zweck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PDAT", "ADV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Da\u00df es kein Bitten h\u00f6rt. Ulysses stopft die Ohren,", "tokens": ["Da\u00df", "es", "kein", "Bit\u00b7ten", "h\u00f6rt", ".", "U\u00b7lys\u00b7ses", "stopft", "die", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$.", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Vor den Sirenen zu. Das Gl\u00fcck hat auch geschworen,", "tokens": ["Vor", "den", "Si\u00b7re\u00b7nen", "zu", ".", "Das", "Gl\u00fcck", "hat", "auch", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es sey von gleicher Art. Es h\u00f6rt auf kein Geschrey,", "tokens": ["Es", "sey", "von", "glei\u00b7cher", "Art", ".", "Es", "h\u00f6rt", "auf", "kein", "Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Es streicht, es flieht, es geht vor unserm Wunsch vorbey;", "tokens": ["Es", "streicht", ",", "es", "flieht", ",", "es", "geht", "vor", "un\u00b7serm", "Wunsch", "vor\u00b7bey", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Es ist auch ungerecht, verkehrt und blind zu nennen,", "tokens": ["Es", "ist", "auch", "un\u00b7ge\u00b7recht", ",", "ver\u00b7kehrt", "und", "blind", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "VVPP", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Diejengen, welche nichts von den Verdiensten kennen;", "tokens": ["Die\u00b7jen\u00b7gen", ",", "wel\u00b7che", "nichts", "von", "den", "Ver\u00b7diens\u00b7ten", "ken\u00b7nen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die Tugend nicht gesehn; die Klugheit nie geliebt;", "tokens": ["Die", "Tu\u00b7gend", "nicht", "ge\u00b7sehn", ";", "die", "Klug\u00b7heit", "nie", "ge\u00b7liebt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$.", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die sind es, welchen oft das Gl\u00fcck das beste giebt!", "tokens": ["Die", "sind", "es", ",", "wel\u00b7chen", "oft", "das", "Gl\u00fcck", "das", "bes\u00b7te", "giebt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$,", "PWAT", "ADV", "ART", "NN", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wie manche schwarze That und unerlaubt Beginnen", "tokens": ["Wie", "man\u00b7che", "schwar\u00b7ze", "That", "und", "un\u00b7er\u00b7laubt", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "KON", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Mu\u00df noch darzu vom Gl\u00fcck die Huld und Gunst gewinnen!", "tokens": ["Mu\u00df", "noch", "dar\u00b7zu", "vom", "Gl\u00fcck", "die", "Huld", "und", "Gunst", "ge\u00b7win\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PAV", "APPRART", "NN", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ja Kayser Sigismund, du hast es auch geglaubt,", "tokens": ["Ja", "Kay\u00b7ser", "Si\u00b7gis\u00b7mund", ",", "du", "hast", "es", "auch", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "NE", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df denen W\u00fcrdigsten das Gl\u00fcck die Gaben raubt;", "tokens": ["Da\u00df", "de\u00b7nen", "W\u00fcr\u00b7digs\u00b7ten", "das", "Gl\u00fcck", "die", "Ga\u00b7ben", "raubt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "VVFIN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "Du hasts nicht nur geglaubt; du hasts auch einst bewiesen,", "tokens": ["Du", "hasts", "nicht", "nur", "ge\u00b7glaubt", ";", "du", "hasts", "auch", "einst", "be\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "VVPP", "$.", "PPER", "VAFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wor\u00fcber denn dein Knecht lie\u00df heise Thr\u00e4nen fliessen.", "tokens": ["Wo\u00b7r\u00fc\u00b7ber", "denn", "dein", "Knecht", "lie\u00df", "hei\u00b7se", "Thr\u00e4\u00b7nen", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PPOSAT", "NN", "VVFIN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Der weise Salomon hegt selbst auch diesen Wahn,", "tokens": ["Der", "wei\u00b7se", "Sa\u00b7lo\u00b7mon", "hegt", "selbst", "auch", "die\u00b7sen", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der Fortgang unsers Werks k\u00e4m meist aufs Gl\u00fccke an.", "tokens": ["Der", "Fort\u00b7gang", "un\u00b7sers", "Werks", "k\u00e4m", "meist", "aufs", "Gl\u00fc\u00b7cke", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Allein was suchet man das Gl\u00fccke zu besch\u00e4men,", "tokens": ["Al\u00b7lein", "was", "su\u00b7chet", "man", "das", "Gl\u00fc\u00b7cke", "zu", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als wisse es das Recht nicht wohl in acht zu nehmen?", "tokens": ["Als", "wis\u00b7se", "es", "das", "Recht", "nicht", "wohl", "in", "acht", "zu", "neh\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "ADV", "APPR", "CARD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die\u00df ist zu viel gesagt! Man hat ja oft versp\u00fchrt,", "tokens": ["Die\u00df", "ist", "zu", "viel", "ge\u00b7sagt", "!", "Man", "hat", "ja", "oft", "ver\u00b7sp\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKA", "PIS", "VVPP", "$.", "PIS", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df es die Tugenden mit seinen Gaben ziert.", "tokens": ["Da\u00df", "es", "die", "Tu\u00b7gen\u00b7den", "mit", "sei\u00b7nen", "Ga\u00b7ben", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier kommt die Demuth auf, dort wird die Treu belohnet,", "tokens": ["Hier", "kommt", "die", "De\u00b7muth", "auf", ",", "dort", "wird", "die", "Treu", "be\u00b7loh\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "VAFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So, da\u00df sie nun nicht mehr in Staub und Asche wohnet.", "tokens": ["So", ",", "da\u00df", "sie", "nun", "nicht", "mehr", "in", "Staub", "und", "A\u00b7sche", "woh\u00b7net", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es sieget die Gedult, die man vorher gedr\u00fcckt;", "tokens": ["Es", "sie\u00b7get", "die", "Ge\u00b7dult", ",", "die", "man", "vor\u00b7her", "ge\u00b7dr\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Keuschheit triumphirt und wird nach Wunsch geschm\u00fcckt;", "tokens": ["Die", "Keuschheit", "tri\u00b7um\u00b7phirt", "und", "wird", "nach", "Wunsch", "ge\u00b7schm\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "KON", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Die Tapferkeit bekommt den Lohn, der ihr geh\u00f6ret;", "tokens": ["Die", "Tap\u00b7fer\u00b7keit", "be\u00b7kommt", "den", "Lohn", ",", "der", "ihr", "ge\u00b7h\u00f6\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Es wird die Fr\u00f6mmigkeit durch Amt und Stand geehret,", "tokens": ["Es", "wird", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "durch", "Amt", "und", "Stand", "ge\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und \u00fcber die gesetzt, die denen Lastern hold.", "tokens": ["Und", "\u00fc\u00b7ber", "die", "ge\u00b7setzt", ",", "die", "de\u00b7nen", "Las\u00b7tern", "hold", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "VVPP", "$,", "PRELS", "PDS", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der Weisheit lohnet sie durch Ehre, Macht und Gold;", "tokens": ["Der", "Weis\u00b7heit", "loh\u00b7net", "sie", "durch", "Eh\u00b7re", ",", "Macht", "und", "Gold", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Klugheit wird ger\u00fchmt, und der Verstand empfindet,", "tokens": ["Die", "Klug\u00b7heit", "wird", "ge\u00b7r\u00fchmt", ",", "und", "der", "Ver\u00b7stand", "emp\u00b7fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df man um seinen Freund die Lorber-Kr\u00e4nze windet;", "tokens": ["Da\u00df", "man", "um", "sei\u00b7nen", "Freund", "die", "Lor\u00b7ber\u00b7Kr\u00e4n\u00b7ze", "win\u00b7det", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Flei\u00df wird angesehn, sein Schwei\u00df erh\u00e4lt den Lohn,", "tokens": ["Der", "Flei\u00df", "wird", "an\u00b7ge\u00b7sehn", ",", "sein", "Schwei\u00df", "er\u00b7h\u00e4lt", "den", "Lohn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und die Geschicklichkeit tr\u00e4gt auch ihr Theil davon.", "tokens": ["Und", "die", "Ge\u00b7schick\u00b7lich\u00b7keit", "tr\u00e4gt", "auch", "ihr", "Theil", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Es kan der heutge Tag hiervon ein Zeugni\u00df geben.", "tokens": ["Es", "kan", "der", "heut\u00b7ge", "Tag", "hier\u00b7von", "ein", "Zeug\u00b7ni\u00df", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "PAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Tugend \u00fcbergab; die Fr\u00f6mmigkeit geliebt;", "tokens": ["Der", "Tu\u00b7gend", "\u00fc\u00b7berg\u00b7ab", ";", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "ge\u00b7liebt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Lehrer hoch geehrt; die Eltern nie betr\u00fcbt;", "tokens": ["Die", "Leh\u00b7rer", "hoch", "ge\u00b7ehrt", ";", "die", "El\u00b7tern", "nie", "be\u00b7tr\u00fcbt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$.", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dein Hochmuth widerstrebt. Die Redlichkeit und G\u00fcte,", "tokens": ["Dein", "Hoch\u00b7muth", "wi\u00b7der\u00b7strebt", ".", "Die", "Red\u00b7lich\u00b7keit", "und", "G\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$.", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Regierte seine Brust, und wohnte im Gem\u00fcthe.", "tokens": ["Re\u00b7gier\u00b7te", "sei\u00b7ne", "Brust", ",", "und", "wohn\u00b7te", "im", "Ge\u00b7m\u00fc\u00b7the", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er gieng der Weisheit nach, bis da\u00df Er sie bekam,", "tokens": ["Er", "gieng", "der", "Weis\u00b7heit", "nach", ",", "bis", "da\u00df", "Er", "sie", "be\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und sie durch seinen Flei\u00df bey Ihm die Wohnung nahm.", "tokens": ["Und", "sie", "durch", "sei\u00b7nen", "Flei\u00df", "bey", "Ihm", "die", "Woh\u00b7nung", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Es hat Eusebie sich \u00fcber Ihn gefreuet,", "tokens": ["Es", "hat", "Eu\u00b7se\u00b7bie", "sich", "\u00fc\u00b7ber", "Ihn", "ge\u00b7freu\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "So, da\u00df sie Ihn nunmehr zu Ihrem Priester weyhet.", "tokens": ["So", ",", "da\u00df", "sie", "Ihn", "nun\u00b7mehr", "zu", "Ih\u00b7rem", "Pries\u00b7ter", "wey\u00b7het", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zum Priester! warlich ja! wer h\u00e4tt es jetzt gemeint?", "tokens": ["Zum", "Pries\u00b7ter", "!", "war\u00b7lich", "ja", "!", "wer", "h\u00e4tt", "es", "jetzt", "ge\u00b7meint", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ADV", "ADV", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wer h\u00e4tte das gedacht? Mein ", "tokens": ["Wer", "h\u00e4t\u00b7te", "das", "ge\u00b7dacht", "?", "Mein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VAFIN", "PDS", "VVPP", "$.", "PPOSAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Ja! ja! dir hat das Gl\u00fcck, durch deiner Tugend Proben", "tokens": ["Ja", "!", "ja", "!", "dir", "hat", "das", "Gl\u00fcck", ",", "durch", "dei\u00b7ner", "Tu\u00b7gend", "Pro\u00b7ben"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "PTKANT", "$.", "PPER", "VAFIN", "ART", "NN", "$,", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Den edlen Hirten-Stab und Kanzel aufgehoben.", "tokens": ["Den", "ed\u00b7len", "Hir\u00b7ten\u00b7Stab", "und", "Kan\u00b7zel", "auf\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Welt hat den Gebrauch; es ist so eingef\u00fchrt,", "tokens": ["Die", "Welt", "hat", "den", "Ge\u00b7brauch", ";", "es", "ist", "so", "ein\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn man im Allmanach ein Namens-Fest versp\u00fchrt,", "tokens": ["Wenn", "man", "im", "All\u00b7ma\u00b7nach", "ein", "Na\u00b7mens\u00b7Fest", "ver\u00b7sp\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das unsern Freund betrift, den wir von Herzen lieben,", "tokens": ["Das", "un\u00b7sern", "Freund", "be\u00b7trift", ",", "den", "wir", "von", "Her\u00b7zen", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So sucht man sich so gleich in Lust und Wunsch zu \u00fcben.", "tokens": ["So", "sucht", "man", "sich", "so", "gleich", "in", "Lust", "und", "Wunsch", "zu", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ADV", "ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man geht noch weiter fort, man leget nach der Treu", "tokens": ["Man", "geht", "noch", "wei\u00b7ter", "fort", ",", "man", "le\u00b7get", "nach", "der", "Treu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "PTKVZ", "$,", "PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Freundschaft ein Geschenk zum Namens-Tage bey.", "tokens": ["Und", "Freund\u00b7schaft", "ein", "Ge\u00b7schenk", "zum", "Na\u00b7mens\u00b7Ta\u00b7ge", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was gab denn dir das Gl\u00fcck zu deinen", "tokens": ["Was", "gab", "denn", "dir", "das", "Gl\u00fcck", "zu", "dei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "KON", "PPER", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Gewi\u00df es schenkte dir das Liebste und das Beste.", "tokens": ["Ge\u00b7wi\u00df", "es", "schenk\u00b7te", "dir", "das", "Liebs\u00b7te", "und", "das", "Bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zwar hat es mehr der Herr, der Wind und Wellen dr\u00e4ut,", "tokens": ["Zwar", "hat", "es", "mehr", "der", "Herr", ",", "der", "Wind", "und", "Wel\u00b7len", "dr\u00e4ut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und der dem Donner ruft, und auch dem Blitz gebeut,", "tokens": ["Und", "der", "dem", "Don\u00b7ner", "ruft", ",", "und", "auch", "dem", "Blitz", "ge\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVFIN", "$,", "KON", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Als wie das Gl\u00fcck gethan: Derselbe gab dem Gl\u00fccke", "tokens": ["Als", "wie", "das", "Gl\u00fcck", "ge\u00b7than", ":", "Der\u00b7sel\u00b7be", "gab", "dem", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "KOKOM", "ART", "NN", "VVPP", "$.", "PDS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den Wink, damit es dir was angenehmes schicke.", "tokens": ["Den", "Wink", ",", "da\u00b7mit", "es", "dir", "was", "an\u00b7ge\u00b7neh\u00b7mes", "schi\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PPER", "PIS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was wars? die Prob-Sermon. So must du ja gestehn,", "tokens": ["Was", "wars", "?", "die", "Prob\u00b7Ser\u00b7mon", ".", "So", "must", "du", "ja", "ge\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$.", "ART", "NN", "$.", "ADV", "VMFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Es habe dich das Gl\u00fcck mit L\u00e4cheln angesehn.", "tokens": ["Es", "ha\u00b7be", "dich", "das", "Gl\u00fcck", "mit", "L\u00e4\u00b7cheln", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nun seh ich ", "tokens": ["Nun", "seh", "ich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Und deiner Eltern Lust, im heilgen Priester-Kleide,", "tokens": ["Und", "dei\u00b7ner", "El\u00b7tern", "Lust", ",", "im", "heil\u00b7gen", "Pries\u00b7ter\u00b7Klei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vor Gottes Altar stehn, man h\u00e4lt dir jetzt die Zier,", "tokens": ["Vor", "Got\u00b7tes", "Al\u00b7tar", "stehn", ",", "man", "h\u00e4lt", "dir", "jetzt", "die", "Zier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVINF", "$,", "PIS", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wie die schuldge Pflicht der Kirchen-Diener f\u00fcr.", "tokens": ["So", "wie", "die", "schuld\u00b7ge", "Pflicht", "der", "Kir\u00b7chen\u00b7Die\u00b7ner", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich seh die Aeltesten, wie sie den Priester-Seegen,", "tokens": ["Ich", "seh", "die", "A\u00b7el\u00b7tes\u00b7ten", ",", "wie", "sie", "den", "Pries\u00b7ter\u00b7See\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "$,"], "meter": "-+--+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Und H\u00e4nde nach Gebrauch der Kirche auf dich legen.", "tokens": ["Und", "H\u00e4n\u00b7de", "nach", "Ge\u00b7brauch", "der", "Kir\u00b7che", "auf", "dich", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Von Jugend auf geliebt, wie wir so br\u00fcderlich", "tokens": ["Von", "Ju\u00b7gend", "auf", "ge\u00b7liebt", ",", "wie", "wir", "so", "br\u00fc\u00b7der\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "VVPP", "$,", "PWAV", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Uns jederzeit bezeugt. Hast du vergn\u00fcgte Stunden", "tokens": ["Uns", "je\u00b7der\u00b7zeit", "be\u00b7zeugt", ".", "Hast", "du", "ver\u00b7gn\u00fcg\u00b7te", "Stun\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "$.", "VAFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erblickt, gesehn, erlebt, so hab ich Lust empfunden.", "tokens": ["Er\u00b7blickt", ",", "ge\u00b7sehn", ",", "er\u00b7lebt", ",", "so", "hab", "ich", "Lust", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "$,", "ADV", "VAFIN", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Drum kans nicht anders seyn, es regt sich auch mein Geist,", "tokens": ["Drum", "kans", "nicht", "an\u00b7ders", "seyn", ",", "es", "regt", "sich", "auch", "mein", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PTKNEG", "ADV", "VAINF", "$,", "PPER", "VVFIN", "PRF", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da man dich einen Knecht und Diener Gottes heist.", "tokens": ["Da", "man", "dich", "ei\u00b7nen", "Knecht", "und", "Die\u00b7ner", "Got\u00b7tes", "heist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ART", "NN", "KON", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich freue mich mit dir; doch w\u00fcnsch ich auch darneben:", "tokens": ["Ich", "freu\u00b7e", "mich", "mit", "dir", ";", "doch", "w\u00fcnsch", "ich", "auch", "dar\u00b7ne\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "$.", "ADV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Dein Erz-Hirt wolle dir den Geist Johannis geben.", "tokens": ["Dein", "Er\u00b7zHirt", "wol\u00b7le", "dir", "den", "Geist", "Jo\u00b7han\u00b7nis", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "ART", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dein Eifer komme ihm, so wie der Nahme bey;", "tokens": ["Dein", "Ei\u00b7fer", "kom\u00b7me", "ihm", ",", "so", "wie", "der", "Nah\u00b7me", "bey", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,", "ADV", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In Strafen schone nicht, und rede auch so frey,", "tokens": ["In", "Stra\u00b7fen", "scho\u00b7ne", "nicht", ",", "und", "re\u00b7de", "auch", "so", "frey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKNEG", "$,", "KON", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie dieser hat gethan. Zeig auch mit deinem Finger", "tokens": ["Wie", "die\u00b7ser", "hat", "ge\u00b7than", ".", "Zeig", "auch", "mit", "dei\u00b7nem", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PDS", "VAFIN", "VVPP", "$.", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Auf das erw\u00fcrgte Lamm, wie dieser heilge J\u00fcnger.", "tokens": ["Auf", "das", "er\u00b7w\u00fcrg\u00b7te", "Lamm", ",", "wie", "die\u00b7ser", "heil\u00b7ge", "J\u00fcn\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PWAV", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}