{"textgrid.poem.38068": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Die l\u00f6bliche Gesellschaft Moselsar", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die l\u00f6bliche Gesellschaft zwischen Rhein", "tokens": ["Die", "l\u00f6b\u00b7li\u00b7che", "Ge\u00b7sell\u00b7schaft", "zwi\u00b7schen", "Rhein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und der Mosel allzeit r\u00fcstig seyn,", "tokens": ["Und", "der", "Mo\u00b7sel", "all\u00b7zeit", "r\u00fcs\u00b7tig", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADJD", "VAINF", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Nach Unfall sie nicht fragen,", "tokens": ["Nach", "Un\u00b7fall", "sie", "nicht", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Terich (Land) hin und her,", "tokens": ["Das", "Te\u00b7rich", "(", "Land", ")", "hin", "und", "her", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "$(", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Langes durch und die quer,", "tokens": ["Lan\u00b7ges", "durch", "und", "die", "quer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "KON", "ART", "NN", "$,"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Zu Fu\u00df und Pferd durchjagen,", "tokens": ["Zu", "Fu\u00df", "und", "Pferd", "durch\u00b7ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Frisch sie es wagen,", "tokens": ["Frisch", "sie", "es", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Kein Scheuen tragen.", "tokens": ["Kein", "Scheu\u00b7en", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Ueber hohe Berg, durch tiefe Thal,", "tokens": ["Ue\u00b7ber", "ho\u00b7he", "Berg", ",", "durch", "tie\u00b7fe", "Thal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Fallen sie oftmals ein wie der Strahl,", "tokens": ["Fal\u00b7len", "sie", "oft\u00b7mals", "ein", "wie", "der", "Strahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PTKVZ", "KOKOM", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "All Weg ohn Weg sie finden,", "tokens": ["All", "Weg", "ohn", "Weg", "sie", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu d\u00fcstrer Nachteszeit", "tokens": ["Zu", "d\u00fcst\u00b7rer", "Nach\u00b7tes\u00b7zeit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Wann schlunen (schlafen) ander Leut,", "tokens": ["Wann", "schlu\u00b7nen", "(", "schla\u00b7fen", ")", "an\u00b7der", "Leut", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "$(", "VVINF", "$(", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie alles fein aufbinden,", "tokens": ["Sie", "al\u00b7les", "fein", "auf\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ohn Licht anz\u00fcnden,", "tokens": ["Ohn", "Licht", "an\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Bleibt nichts dahinten.", "tokens": ["Bleibt", "nichts", "da\u00b7hin\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Laffel, der wei\u00df gar fein auszusehn,", "tokens": ["Laf\u00b7fel", ",", "der", "wei\u00df", "gar", "fein", "aus\u00b7zu\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "VVFIN", "ADV", "ADJD", "VVIZU", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wo irgend in einem Gfar Klebis (Pferd) stehn,", "tokens": ["Wo", "ir\u00b7gend", "in", "ei\u00b7nem", "Gfar", "Kle\u00b7bis", "(", "Pferd", ")", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "ART", "NN", "NE", "$(", "NN", "$(", "VVINF", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wanns w\u00e4r auf zwanzig Meilen,", "tokens": ["Wanns", "w\u00e4r", "auf", "zwan\u00b7zig", "Mei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Beym hellen Mondenschein,", "tokens": ["Beym", "hel\u00b7len", "Mon\u00b7den\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die Gleicher (Mitgesell) ins gemein,", "tokens": ["Die", "Glei\u00b7cher", "(", "Mit\u00b7ge\u00b7sell", ")", "ins", "ge\u00b7mein", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "$(", "APPRART", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "In einer kurzen Weilen", "tokens": ["In", "ei\u00b7ner", "kur\u00b7zen", "Wei\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sie \u00fcbereilen,", "tokens": ["Sie", "\u00fc\u00b7be\u00b7rei\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und redlich theilen.", "tokens": ["Und", "red\u00b7lich", "thei\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Battrawitz, der alcht (geht) zur Hinterth\u00fcr hinein,", "tokens": ["Bat\u00b7tra\u00b7witz", ",", "der", "alcht", "(", "geht", ")", "zur", "Hin\u00b7tert\u00b7h\u00fcr", "hin\u00b7ein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$(", "VVFIN", "$(", "APPRART", "NN", "PTKVZ", "$,"], "meter": "+----+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Bobowitz sazt sich hinter ein Haufen Stein,", "tokens": ["Bo\u00b7bo\u00b7witz", "sazt", "sich", "hin\u00b7ter", "ein", "Hau\u00b7fen", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Mit den andern Gesellen,", "tokens": ["Mit", "den", "an\u00b7dern", "Ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Den Quien (Hund) ruft er klug,", "tokens": ["Den", "Qui\u00b7en", "(", "Hund", ")", "ruft", "er", "klug", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und brockt ihm Lehm (Brodt) gnug,", "tokens": ["Und", "brockt", "ihm", "Lehm", "(", "Brodt", ")", "gnug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "$(", "NN", "$(", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Da\u00df sie nicht sollen bellen,", "tokens": ["Da\u00df", "sie", "nicht", "sol\u00b7len", "bel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.7": {"text": "Bis aus den St\u00e4llen", "tokens": ["Bis", "aus", "den", "St\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Die Klebis schnellen.", "tokens": ["Die", "Kle\u00b7bis", "schnel\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Wann sie nun haben die Hautzen Ro\u00df,", "tokens": ["Wann", "sie", "nun", "ha\u00b7ben", "die", "Haut\u00b7zen", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So reiten sie nach dem neuen Schlo\u00df:", "tokens": ["So", "rei\u00b7ten", "sie", "nach", "dem", "neu\u00b7en", "Schlo\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist jemand der will kaufen?", "tokens": ["Ist", "je\u00b7mand", "der", "will", "kau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Putzjakala", "tokens": ["Der", "Putz\u00b7ja\u00b7ka\u00b7la"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Ist m\u00fcd und liegt da,", "tokens": ["Ist", "m\u00fcd", "und", "liegt", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Weil er sich lahm gelaufen,", "tokens": ["Weil", "er", "sich", "lahm", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Schier nicht kann schnaufen,", "tokens": ["Schier", "nicht", "kann", "schnau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Drum will er saufen.", "tokens": ["Drum", "will", "er", "sau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Herr Wirth: Nun so la\u00df uns lustig seyn,", "tokens": ["Herr", "Wirth", ":", "Nun", "so", "la\u00df", "uns", "lus\u00b7tig", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ADV", "ADV", "VVIMP", "PPER", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Lang mir den Glestrich (Glas) vom besten Wein,", "tokens": ["Lang", "mir", "den", "Glest\u00b7rich", "(", "Glas", ")", "vom", "bes\u00b7ten", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "$(", "NN", "$(", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Um Doulme\u00df (Pfennig) darfst nicht sorgen;", "tokens": ["Um", "Doul\u00b7me\u00df", "(", "Pfen\u00b7nig", ")", "darfst", "nicht", "sor\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$(", "NN", "$(", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein halbe gute Nacht", "tokens": ["Ein", "hal\u00b7be", "gu\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Uns all zu Sontzen (Edelleuten) macht,", "tokens": ["Uns", "all", "zu", "Sont\u00b7zen", "(", "E\u00b7del\u00b7leu\u00b7ten", ")", "macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "PIAT", "APPR", "NN", "$(", "NN", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Du kannst uns ja bis morgen", "tokens": ["Du", "kannst", "uns", "ja", "bis", "mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Die Irtin (Zeche) borgen,", "tokens": ["Die", "Ir\u00b7tin", "(", "Ze\u00b7che", ")", "bor\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "NN", "$(", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Der Hautz (Bauer) mu\u00df sorgen.", "tokens": ["Der", "Hautz", "(", "Bau\u00b7er", ")", "mu\u00df", "sor\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "NE", "$(", "VMFIN", "VVINF", "$."], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Ist das nicht wunderlich Gesind,", "tokens": ["Ist", "das", "nicht", "wun\u00b7der\u00b7lich", "Ge\u00b7sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df der Hautz sein Schuh mit Weiden bindt,", "tokens": ["Da\u00df", "der", "Hautz", "sein", "Schuh", "mit", "Wei\u00b7den", "bindt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und da die Zech mu\u00df zahlen,", "tokens": ["Und", "da", "die", "Zech", "mu\u00df", "zah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So lang er hat ein Kuh,", "tokens": ["So", "lang", "er", "hat", "ein", "Kuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die Klebis auch dazu,", "tokens": ["Die", "Kle\u00b7bis", "auch", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Die Rappen mit den Fahlen,", "tokens": ["Die", "Rap\u00b7pen", "mit", "den", "Fah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wir allzumalen", "tokens": ["Wir", "all\u00b7zu\u00b7ma\u00b7len"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Durch Giel (Mund) vermalen.", "tokens": ["Durch", "Giel", "(", "Mund", ")", "ver\u00b7ma\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "$(", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}