{"dta.poem.18993": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Von jhrer Sch\u00f6nheit Wundern-  \n St\u00e4nde.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Seind es haar oder garn das krau\u00dflecht/ reine", "tokens": ["Seind", "es", "haar", "o\u00b7der", "garn", "das", "krau\u00df\u00b7lecht", "/", "rei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADV", "ART", "NN", "$(", "ADJA"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "gold/", "tokens": ["gold", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Nach dessen purem schatz die G\u00f6tter ein verlangen?", "tokens": ["Nach", "des\u00b7sen", "pu\u00b7rem", "schatz", "die", "G\u00f6t\u00b7ter", "ein", "ver\u00b7lan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "ART", "NN", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach! Es seind zarte haar/ meiner lieb wehrter sold:", "tokens": ["Ach", "!", "Es", "seind", "zar\u00b7te", "haar", "/", "mei\u00b7ner", "lieb", "wehr\u00b7ter", "sold", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VAFIN", "ADJA", "NN", "$(", "PPOSAT", "ADJD", "NN", "ADJD", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Nein. Es seind starcke garn/ da sich die sehle\u0304 fangen.", "tokens": ["Nein", ".", "Es", "seind", "star\u00b7cke", "garn", "/", "da", "sich", "die", "sehl\u0113", "fan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "ADJA", "NN", "$(", "KOUS", "PRF", "ART", "ADV", "VVFIN", "$."], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Ein gestirn oder stirn ist dan das helfenbein/", "tokens": ["Ein", "ge\u00b7stirn", "o\u00b7der", "stirn", "ist", "dan", "das", "hel\u00b7fen\u00b7bein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Darauff sich Mayestet/ wei\u00df heit vnd zucht erfrewet?", "tokens": ["Dar\u00b7auff", "sich", "Ma\u00b7ye\u00b7stet", "/", "wei\u00df", "heit", "vnd", "zucht", "er\u00b7fre\u00b7wet", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "NE", "$(", "VVFIN", "NE", "KON", "NN", "VVFIN", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es ist ein glatte stirn/ die hofnung meiner pein:", "tokens": ["Es", "ist", "ein", "glat\u00b7te", "stirn", "/", "die", "hof\u00b7nung", "mei\u00b7ner", "pein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nein. Es ist ein gestirn/ das die freche betr\u00f6wet.", "tokens": ["Nein", ".", "Es", "ist", "ein", "ge\u00b7stirn", "/", "das", "die", "fre\u00b7che", "be\u00b7tr\u00f6\u00b7wet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "ART", "NN", "$(", "PRELS", "ART", "ADJA", "VVFIN", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Seind es blick oder plitz der schnell vnd helle glantz/", "tokens": ["Seind", "es", "blick", "o\u00b7der", "plitz", "der", "schnell", "vnd", "hel\u00b7le", "glantz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "VVIMP", "ART", "ADJD", "KON", "ADJA", "NN", "$("], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Darab wir vns zugleich ents\u00f6tzen vnd erg\u00f6tzen?", "tokens": ["Da\u00b7rab", "wir", "vns", "zu\u00b7gleich", "ent\u00b7s\u00f6t\u00b7zen", "vnd", "er\u00b7g\u00f6t\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach! Es seind s\u00fcsse blick au\u00df Amors starcker schantz:", "tokens": ["Ach", "!", "Es", "seind", "s\u00fcs\u00b7se", "blick", "au\u00df", "A\u00b7mors", "star\u00b7cker", "schantz", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PPER", "VAFIN", "ADJA", "NN", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nein. Es seind scharpfe plitz/ so die hertzen verl\u00f6tzen.", "tokens": ["Nein", ".", "Es", "seind", "scharp\u00b7fe", "plitz", "/", "so", "die", "hert\u00b7zen", "ver\u00b7l\u00f6t\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VAFIN", "VVFIN", "NE", "$(", "ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Ist ein brust oder blust der zwirig-b\u00f6bend thron/", "tokens": ["Ist", "ein", "brust", "o\u00b7der", "blust", "der", "zwi\u00b7rig\u00b7b\u00f6\u00b7bend", "thron", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "VVFIN", "ART", "CARD", "NN", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Darauff die Charites den Liebelein liebkosen?", "tokens": ["Dar\u00b7auff", "die", "Cha\u00b7ri\u00b7tes", "den", "Lie\u00b7be\u00b7lein", "lieb\u00b7ko\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ist ein v\u00f6ste brust/ da wohnet all mein wohn:", "tokens": ["Es", "ist", "ein", "v\u00f6s\u00b7te", "brust", "/", "da", "woh\u00b7net", "all", "mein", "wohn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "ADV", "VVFIN", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es ist ein edle blust von erdb\u00f6r-gilg-vnd-rosen.", "tokens": ["Es", "ist", "ein", "ed\u00b7le", "blust", "von", "erd\u00b7b\u00f6r\u00b7gil\u00b7g\u00b7vn\u00b7dro\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+----", "measure": "unknown.measure.penta"}}, "stanza.5": {"line.1": {"text": "Ist ein hand oder band der f\u00fcnffgezincket ast/", "tokens": ["Ist", "ein", "hand", "o\u00b7der", "band", "der", "f\u00fcnff\u00b7ge\u00b7zin\u00b7cket", "ast", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "VVFIN", "ART", "VVFIN", "ADV", "$("], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Dessen schneeweisser pracht das aug vnd hertz ver-", "tokens": ["Des\u00b7sen", "schnee\u00b7weis\u00b7ser", "pracht", "das", "aug", "vnd", "hertz", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "ART", "NN", "KON", "NN", "TRUNC"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "blindet.", "tokens": ["blin\u00b7det", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Es ist ein zarte hand/ erleuchtend der Lieb last:", "tokens": ["Es", "ist", "ein", "zar\u00b7te", "hand", "/", "er\u00b7leuch\u00b7tend", "der", "Lieb", "last", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "VVPP", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--++", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Es ist ein hartes band/ das die Freyheit verbindet.", "tokens": ["Es", "ist", "ein", "har\u00b7tes", "band", "/", "das", "die", "Frey\u00b7heit", "ver\u00b7bin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "VVFIN", "$(", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Wie seelig bin ich doch/ O haar/ stirn/ blick/ brust/", "tokens": ["Wie", "see\u00b7lig", "bin", "ich", "doch", "/", "O", "haar", "/", "stirn", "/", "blick", "/", "brust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$(", "NE", "NN", "$(", "VVINF", "$(", "VVIMP", "$(", "VVFIN", "$("], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.2": {"text": "hand/", "tokens": ["hand", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "So k\u00f6stlich/ freindlich/ klar/ anmuhtig vnd beglicket!", "tokens": ["So", "k\u00f6st\u00b7lich", "/", "freind\u00b7lich", "/", "klar", "/", "an\u00b7muh\u00b7tig", "vnd", "be\u00b7gli\u00b7cket", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ich durch solches garn/ gestirn/ plitz/ blust vnd", "tokens": ["Da\u00df", "ich", "durch", "sol\u00b7ches", "garn", "/", "ge\u00b7stirn", "/", "plitz", "/", "blust", "vnd"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "NN", "$(", "VVPP", "$(", "NE", "$(", "VVFIN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "band/", "tokens": ["band", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Gefangen bin/ freyh/ wund/ erquicket vnd verstricket!", "tokens": ["Ge\u00b7fan\u00b7gen", "bin", "/", "freyh", "/", "wund", "/", "er\u00b7quic\u00b7ket", "vnd", "ver\u00b7stri\u00b7cket", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$(", "ADJD", "$(", "ADJD", "$(", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}