{"textgrid.poem.64800": {"metadata": {"author": {"name": "K\u00e4stner, Abraham Gotthelf", "birth": "N.A.", "death": "N.A."}, "title": "7. Der Nutzen der sch\u00f6nen Wissenschaften beym Vortrage philosophischer Lehren", "genre": "verse", "period": "N.A.", "pub_year": 1742, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Freund, dir sind Recht und Brauch vom alten Rom bekannt,", "tokens": ["Freund", ",", "dir", "sind", "Recht", "und", "Brauch", "vom", "al\u00b7ten", "Rom", "be\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "NN", "KON", "NN", "APPRART", "ADJA", "NE", "ADJD", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Doch kein gelehrter Stolz verschm\u00e4ht dein Vaterland;", "tokens": ["Doch", "kein", "ge\u00b7lehr\u00b7ter", "Stolz", "ver\u00b7schm\u00e4ht", "dein", "Va\u00b7ter\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein Eifer ist bem\u00fcht mit Mustern und mit Lehren", "tokens": ["Dein", "Ei\u00b7fer", "ist", "be\u00b7m\u00fcht", "mit", "Mus\u00b7tern", "und", "mit", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Ruhm Germanien's, der Sprache Glanz zu mehren:", "tokens": ["Den", "Ruhm", "Ger\u00b7ma\u00b7ni\u00b7en's", ",", "der", "Spra\u00b7che", "Glanz", "zu", "meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bald, wenn ein muntrer Vers, der deinen Einfall ziert,", "tokens": ["Bald", ",", "wenn", "ein", "mun\u00b7trer", "Vers", ",", "der", "dei\u00b7nen", "Ein\u00b7fall", "ziert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das Ohr durch Harmonie, durch Witz das Herze r\u00fchrt;", "tokens": ["Das", "Ohr", "durch", "Har\u00b7mo\u00b7nie", ",", "durch", "Witz", "das", "Her\u00b7ze", "r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bald, wenn der freye Geist zwar nicht die Sylben z\u00e4hlet,", "tokens": ["Bald", ",", "wenn", "der", "frey\u00b7e", "Geist", "zwar", "nicht", "die", "Syl\u00b7ben", "z\u00e4h\u00b7let", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "ADJA", "NN", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch Wort und Redensart voll Reiz und Nachdruck w\u00e4hlet.", "tokens": ["Doch", "Wort", "und", "Re\u00b7den\u00b7sart", "voll", "Reiz", "und", "Nach\u00b7druck", "w\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ADJD", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "O Freund, ist nicht der Flei\u00df, der Witz und Sch\u00f6nheit sch\u00e4tzt,", "tokens": ["O", "Freund", ",", "ist", "nicht", "der", "Flei\u00df", ",", "der", "Witz", "und", "Sch\u00f6n\u00b7heit", "sch\u00e4tzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "VAFIN", "PTKNEG", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf's h\u00f6chste Zeitvertreib, der ohne Frucht erg\u00f6tzt?", "tokens": ["Auf's", "h\u00f6chs\u00b7te", "Zeit\u00b7ver\u00b7treib", ",", "der", "oh\u00b7ne", "Frucht", "er\u00b7g\u00f6tzt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PRELS", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Kraft, die Grund und Schlu\u00df erkannter Wahrheit geben,", "tokens": ["Die", "Kraft", ",", "die", "Grund", "und", "Schlu\u00df", "er\u00b7kann\u00b7ter", "Wahr\u00b7heit", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Braucht die wohl Putz und Kunst, sich erstlich zu beleben?", "tokens": ["Braucht", "die", "wohl", "Putz", "und", "Kunst", ",", "sich", "erst\u00b7lich", "zu", "be\u00b7le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "NN", "KON", "NN", "$,", "PRF", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So glaubt vielleicht ein Geist, der nur f\u00fcr sich gelehrt,", "tokens": ["So", "glaubt", "viel\u00b7leicht", "ein", "Geist", ",", "der", "nur", "f\u00fcr", "sich", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nie Wahrheit und Vernunft durch Unterrichten mehrt,", "tokens": ["Nie", "Wahr\u00b7heit", "und", "Ver\u00b7nunft", "durch", "Un\u00b7ter\u00b7rich\u00b7ten", "mehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vergn\u00fcgt, wofern nur er, den Schwierigkeit entz\u00fcndet,", "tokens": ["Ver\u00b7gn\u00fcgt", ",", "wo\u00b7fern", "nur", "er", ",", "den", "Schwie\u00b7rig\u00b7keit", "ent\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ADV", "PPER", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch unbewegten Flei\u00df den tiefsten Satz ergr\u00fcndet,", "tokens": ["Durch", "un\u00b7be\u00b7weg\u00b7ten", "Flei\u00df", "den", "tiefs\u00b7ten", "Satz", "er\u00b7gr\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er lerne, wie man sich zum schw\u00e4chern Geiste senkt,", "tokens": ["Er", "ler\u00b7ne", ",", "wie", "man", "sich", "zum", "schw\u00e4\u00b7chern", "Geis\u00b7te", "senkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PIS", "PRF", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der nicht so scharf, wie wir, auch nicht so eifrig denkt.", "tokens": ["Der", "nicht", "so", "scharf", ",", "wie", "wir", ",", "auch", "nicht", "so", "eif\u00b7rig", "denkt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ADJD", "$,", "PWAV", "PPER", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vergebens wird man dem, die Wahrheit vorzutragen,", "tokens": ["Ver\u00b7ge\u00b7bens", "wird", "man", "dem", ",", "die", "Wahr\u00b7heit", "vor\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ART", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In unzertrennter Reih', nur trockne Schl\u00fcsse sagen,", "tokens": ["In", "un\u00b7zer\u00b7trenn\u00b7ter", "Reih'", ",", "nur", "trock\u00b7ne", "Schl\u00fcs\u00b7se", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zeigt nicht des Lehrers Witz, was er begreifen soll,", "tokens": ["Zeigt", "nicht", "des", "Leh\u00b7rers", "Witz", ",", "was", "er", "be\u00b7grei\u00b7fen", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "NN", "NN", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ihm leicht f\u00fcr den Verstand, dem Sinne reizungsvoll;", "tokens": ["Ihm", "leicht", "f\u00fcr", "den", "Ver\u00b7stand", ",", "dem", "Sin\u00b7ne", "rei\u00b7zungs\u00b7voll", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$,", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Kann muntrer Vortrag nicht die Schl\u00e4frigkeit erheitern,", "tokens": ["Kann", "mun\u00b7trer", "Vor\u00b7trag", "nicht", "die", "Schl\u00e4f\u00b7rig\u00b7keit", "er\u00b7hei\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Oft Ausdruck mancher Art nur einen Satz erl\u00e4utern;", "tokens": ["Oft", "Aus\u00b7druck", "man\u00b7cher", "Art", "nur", "ei\u00b7nen", "Satz", "er\u00b7l\u00e4u\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PIAT", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.13": {"text": "Macht Beyspiel, Aehnlichkeit, was eine Rede schm\u00fcckt,", "tokens": ["Macht", "Bey\u00b7spiel", ",", "A\u00b7ehn\u00b7lich\u00b7keit", ",", "was", "ei\u00b7ne", "Re\u00b7de", "schm\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Nicht, da\u00df Beweis und Satz sich st\u00e4rker in ihn dr\u00fcckt.", "tokens": ["Nicht", ",", "da\u00df", "Be\u00b7weis", "und", "Satz", "sich", "st\u00e4r\u00b7ker", "in", "ihn", "dr\u00fcckt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "KOUS", "NN", "KON", "NN", "PRF", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So l\u00e4\u00dft uns ", "tokens": ["So", "l\u00e4\u00dft", "uns"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Auch wenn er Weisen schreibt, mit Rednerkunst empfinden.", "tokens": ["Auch", "wenn", "er", "Wei\u00b7sen", "schreibt", ",", "mit", "Red\u00b7ner\u00b7kunst", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "NN", "VVFIN", "$,", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als Redner ist er gro\u00df, weil ihn die Weisheit st\u00e4rkt,", "tokens": ["Als", "Red\u00b7ner", "ist", "er", "gro\u00df", ",", "weil", "ihn", "die", "Weis\u00b7heit", "st\u00e4rkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als Weiser schreibt er sch\u00f6n, weil man den Redner merkt.", "tokens": ["Als", "Wei\u00b7ser", "schreibt", "er", "sch\u00f6n", ",", "weil", "man", "den", "Red\u00b7ner", "merkt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor ihm mag noch die Schaar von ungelehrten Weisen", "tokens": ["Vor", "ihm", "mag", "noch", "die", "Schaar", "von", "un\u00b7ge\u00b7lehr\u00b7ten", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VMFIN", "ADV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "Die trockne Barbarey als tief und gr\u00fcndlich preisen.", "tokens": ["Die", "trock\u00b7ne", "Bar\u00b7ba\u00b7rey", "als", "tief", "und", "gr\u00fcnd\u00b7lich", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KOKOM", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das hei\u00dft nicht gr\u00fcndlich seyn, da\u00df man die Sprache kr\u00e4nkt,", "tokens": ["Das", "hei\u00dft", "nicht", "gr\u00fcnd\u00b7lich", "seyn", ",", "da\u00df", "man", "die", "Spra\u00b7che", "kr\u00e4nkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ADJD", "VAINF", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Neu und barbarisch spricht, gemein und dunkel denkt,", "tokens": ["Neu", "und", "bar\u00b7ba\u00b7risch", "spricht", ",", "ge\u00b7mein", "und", "dun\u00b7kel", "denkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVFIN", "$,", "ADJD", "KON", "ADJD", "VVFIN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Im Schreiben Satz an Satz mit Syllogismen bindet,", "tokens": ["Im", "Schrei\u00b7ben", "Satz", "an", "Satz", "mit", "Syl\u00b7lo\u00b7gis\u00b7men", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "APPR", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Denken falschen Schlu\u00df auf falsche S\u00e4tze gr\u00fcndet.", "tokens": ["Im", "Den\u00b7ken", "fal\u00b7schen", "Schlu\u00df", "auf", "fal\u00b7sche", "S\u00e4t\u00b7ze", "gr\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Soll stets der Criticus des Weisen Schreibart schm\u00e4hn?", "tokens": ["Soll", "stets", "der", "Cri\u00b7ti\u00b7cus", "des", "Wei\u00b7sen", "Schrei\u00b7bart", "schm\u00e4hn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer scharf und richtig denkt, der sprech' auch rein und sch\u00f6n,", "tokens": ["Wer", "scharf", "und", "rich\u00b7tig", "denkt", ",", "der", "sprech'", "auch", "rein", "und", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "ADJD", "VVFIN", "$,", "PRELS", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df er im Ausdruck sich so wie im Denken \u00fcbet,", "tokens": ["Da\u00df", "er", "im", "Aus\u00b7druck", "sich", "so", "wie", "im", "Den\u00b7ken", "\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PRF", "ADV", "KOKOM", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Kunst der Redner kennt, den Geist der Dichter liebet,", "tokens": ["Die", "Kunst", "der", "Red\u00b7ner", "kennt", ",", "den", "Geist", "der", "Dich\u00b7ter", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und dennoch nicht dabey, von Munterkeit verf\u00fchrt,", "tokens": ["Und", "den\u00b7noch", "nicht", "da\u00b7bey", ",", "von", "Mun\u00b7ter\u00b7keit", "ver\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "PAV", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ganz den Verstand vergi\u00dft, wenn er die Sinne r\u00fchrt,", "tokens": ["Ganz", "den", "Ver\u00b7stand", "ver\u00b7gi\u00dft", ",", "wenn", "er", "die", "Sin\u00b7ne", "r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "F\u00fcr strenge Gr\u00fcndlichkeit mit Witze spielend pranget,", "tokens": ["F\u00fcr", "stren\u00b7ge", "Gr\u00fcnd\u00b7lich\u00b7keit", "mit", "Wit\u00b7ze", "spie\u00b7lend", "pran\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und uns ein Gleichni\u00df giebt, wenn man Beweis verlanget.", "tokens": ["Und", "uns", "ein", "Gleich\u00b7ni\u00df", "giebt", ",", "wenn", "man", "Be\u00b7weis", "ver\u00b7lan\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVFIN", "$,", "KOUS", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein pr\u00e4chtiger Palast sey seiner Lehrart gleich,", "tokens": ["Ein", "pr\u00e4ch\u00b7ti\u00b7ger", "Pa\u00b7last", "sey", "sei\u00b7ner", "Le\u00b7hrart", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Befestigt durch Vernunft, durch Witz an Anmuth reich.", "tokens": ["Be\u00b7fes\u00b7tigt", "durch", "Ver\u00b7nunft", ",", "durch", "Witz", "an", "An\u00b7muth", "reich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,", "APPR", "NN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Am meisten sey er da auf Reiz und Schmuck beflissen,", "tokens": ["Am", "meis\u00b7ten", "sey", "er", "da", "auf", "Reiz", "und", "Schmuck", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "VAFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Befiehlt sein Unterricht zu thun und nicht zu wissen.", "tokens": ["Be\u00b7fiehlt", "sein", "Un\u00b7ter\u00b7richt", "zu", "thun", "und", "nicht", "zu", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "KON", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vergebens, da\u00df er nur den trocknen Satz gebeut", "tokens": ["Ver\u00b7ge\u00b7bens", ",", "da\u00df", "er", "nur", "den", "trock\u00b7nen", "Satz", "ge\u00b7beut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ewig wiederholt: ", "tokens": ["Und", "e\u00b7wig", "wie\u00b7der\u00b7holt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "In Rechten ungelehrt, unwissend in Geschichten,", "tokens": ["In", "Rech\u00b7ten", "un\u00b7ge\u00b7lehrt", ",", "un\u00b7wis\u00b7send", "in", "Ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mag er vom ", "tokens": ["Mag", "er", "vom"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPER", "APPRART"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Der Tugend Reiz vergeht, wenn uns sein ernster Geist", "tokens": ["Der", "Tu\u00b7gend", "Reiz", "ver\u00b7geht", ",", "wenn", "uns", "sein", "erns\u00b7ter", "Geist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein metaphysisch Bild von ihrer Sch\u00f6nheit weist.", "tokens": ["Ein", "me\u00b7ta\u00b7phy\u00b7sisch", "Bild", "von", "ih\u00b7rer", "Sch\u00f6n\u00b7heit", "weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.7": {"line.1": {"text": "Der Dichtkunst altes Recht ist, von der Tugend spielen;", "tokens": ["Der", "Dicht\u00b7kunst", "al\u00b7tes", "Recht", "ist", ",", "von", "der", "Tu\u00b7gend", "spie\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "$,", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Menschen lehrte sie l\u00e4ngst seine Pflichten f\u00fchlen,", "tokens": ["Den", "Men\u00b7schen", "lehr\u00b7te", "sie", "l\u00e4ngst", "sei\u00b7ne", "Pflich\u00b7ten", "f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.3": {"text": "Eh' ein Gelehrter noch mit Arbeit ohne Frucht", "tokens": ["Eh'", "ein", "Ge\u00b7lehr\u00b7ter", "noch", "mit", "Ar\u00b7beit", "oh\u00b7ne", "Frucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vom Rechte der Natur den ersten Satz gesucht,", "tokens": ["Vom", "Rech\u00b7te", "der", "Na\u00b7tur", "den", "ers\u00b7ten", "Satz", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durch Schl\u00fcsse kann das Kind nicht gut und b\u00f6ses trennen;", "tokens": ["Durch", "Schl\u00fcs\u00b7se", "kann", "das", "Kind", "nicht", "gut", "und", "b\u00f6\u00b7ses", "tren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "ART", "NN", "PTKNEG", "ADJD", "KON", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es wird den Unterschied in ihrer Fabel kennen.", "tokens": ["Es", "wird", "den", "Un\u00b7ter\u00b7schied", "in", "ih\u00b7rer", "Fa\u00b7bel", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie zwingt uns, da\u00df man selbst der eignen Thorheit lacht,", "tokens": ["Sie", "zwingt", "uns", ",", "da\u00df", "man", "selbst", "der", "eig\u00b7nen", "Thor\u00b7heit", "lacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PIS", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und lehrt den B\u00fcrger fliehn, was Helden elend macht.", "tokens": ["Und", "lehrt", "den", "B\u00fcr\u00b7ger", "fliehn", ",", "was", "Hel\u00b7den", "e\u00b7lend", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVINF", "$,", "PWS", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O da\u00df doch \u00f6fters Der, den ihre Gluth beseelet,", "tokens": ["O", "da\u00df", "doch", "\u00f6f\u00b7ters", "Der", ",", "den", "ih\u00b7re", "Gluth", "be\u00b7see\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "ADV", "ADV", "ART", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Laster falschen Reiz zum Gegenstande w\u00e4hlet!", "tokens": ["Der", "Las\u00b7ter", "fal\u00b7schen", "Reiz", "zum", "Ge\u00b7gen\u00b7stan\u00b7de", "w\u00e4h\u00b7let", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Und wenn die Redekunst der St\u00e4dte Freyheit sch\u00fctzt,", "tokens": ["Und", "wenn", "die", "Re\u00b7de\u00b7kunst", "der", "St\u00e4d\u00b7te", "Frey\u00b7heit", "sch\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Auf ", "tokens": ["Auf"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Bleibt ihr der Vorzug noch, da\u00df sie manch Volk regieret,", "tokens": ["Bleibt", "ihr", "der", "Vor\u00b7zug", "noch", ",", "da\u00df", "sie", "manch", "Volk", "re\u00b7gie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn heil'ger Wahrheit Kraft durch sie die Herzen r\u00fchret.", "tokens": ["Wenn", "heil'\u00b7ger", "Wahr\u00b7heit", "Kraft", "durch", "sie", "die", "Her\u00b7zen", "r\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "APPR", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Freund, gl\u00fccklich, wer von dir, was die Natur uns lehrt,", "tokens": ["Freund", ",", "gl\u00fcck\u00b7lich", ",", "wer", "von", "dir", ",", "was", "die", "Na\u00b7tur", "uns", "lehrt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "PWS", "APPR", "PPER", "$,", "PRELS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie voller Gr\u00fcndlichkeit, so voller Anmuth h\u00f6rt.", "tokens": ["Wie", "vol\u00b7ler", "Gr\u00fcnd\u00b7lich\u00b7keit", ",", "so", "vol\u00b7ler", "An\u00b7muth", "h\u00f6rt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "$,", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zeuch hin, wo Ueberflu\u00df der Freyheit Flei\u00df begl\u00fccket,", "tokens": ["Zeuch", "hin", ",", "wo", "Ue\u00b7berf\u00b7lu\u00df", "der", "Frey\u00b7heit", "Flei\u00df", "be\u00b7gl\u00fc\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PWAV", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Lust zur Wissenschaft auch Reicher Seelen schm\u00fccket,", "tokens": ["Und", "Lust", "zur", "Wis\u00b7sen\u00b7schaft", "auch", "Rei\u00b7cher", "See\u00b7len", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und lieb' uns, weil uns noch der Trieb, der dich auch f\u00fchrt,", "tokens": ["Und", "lieb'", "uns", ",", "weil", "uns", "noch", "der", "Trieb", ",", "der", "dich", "auch", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "F\u00fcr Deutschlands Redlichkeit und Deutschlands Mundart r\u00fchrt.", "tokens": ["F\u00fcr", "Deutschlands", "Red\u00b7lich\u00b7keit", "und", "Deutschlands", "Mund\u00b7art", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "NE", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}}}}