{"textgrid.poem.37411": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: In Tours, zu Bischof Martins Zeit,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In Tours, zu Bischof Martins Zeit,", "tokens": ["In", "Tours", ",", "zu", "Bi\u00b7schof", "Mar\u00b7tins", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "APPR", "NE", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab's Kr\u00fcppel viel und Bettelleut.", "tokens": ["Gab's", "Kr\u00fcp\u00b7pel", "viel", "und", "Bet\u00b7tel\u00b7leut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Darunter auch ein Ehepaar,", "tokens": ["Da\u00b7run\u00b7ter", "auch", "ein", "E\u00b7he\u00b7paar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was gl\u00fccklich und zufrieden war.", "tokens": ["Was", "gl\u00fcck\u00b7lich", "und", "zu\u00b7frie\u00b7den", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er, sonst gesund, war blind und stumm;", "tokens": ["Er", ",", "sonst", "ge\u00b7sund", ",", "war", "blind", "und", "stumm", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "ADJD", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie sehend, aber lahm und krumm", "tokens": ["Sie", "se\u00b7hend", ",", "a\u00b7ber", "lahm", "und", "krumm"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVPP", "$,", "ADV", "PTKVZ", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "An jedem Glied, bis auf die Zunge", "tokens": ["An", "je\u00b7dem", "Glied", ",", "bis", "auf", "die", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und eine unverletzte Lunge.", "tokens": ["Und", "ei\u00b7ne", "un\u00b7ver\u00b7letz\u00b7te", "Lun\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das pa\u00dfte sch\u00f6n. Sie reitet ihn", "tokens": ["Das", "pa\u00df\u00b7te", "sch\u00f6n", ".", "Sie", "rei\u00b7tet", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJD", "$.", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und, selbstverst\u00e4ndlich, leitet ihn", "tokens": ["Und", ",", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", ",", "lei\u00b7tet", "ihn"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ADJD", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ein geduldig Satteltier,", "tokens": ["Als", "ein", "ge\u00b7dul\u00b7dig", "Sat\u00b7tel\u00b7tier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie obenauf, er unter ihr,", "tokens": ["Sie", "o\u00b7ben\u00b7auf", ",", "er", "un\u00b7ter", "ihr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ganz einfach mit geringer M\u00fch,", "tokens": ["Ganz", "ein\u00b7fach", "mit", "ge\u00b7rin\u00b7ger", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Blo\u00df durch die Worte Hott und H\u00fch,", "tokens": ["Blo\u00df", "durch", "die", "Wor\u00b7te", "Hott", "und", "H\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bald so, bald so, vor allen Dingen", "tokens": ["Bald", "so", ",", "bald", "so", ",", "vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "ADV", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dahin, wo grad die Leute gingen.", "tokens": ["Da\u00b7hin", ",", "wo", "grad", "die", "Leu\u00b7te", "gin\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Fast jeder, der's noch nicht gesehn,", "tokens": ["Fast", "je\u00b7der", ",", "der's", "noch", "nicht", "ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "PRELS", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bleibt unwillk\u00fcrlich stille stehn,", "tokens": ["Bleibt", "un\u00b7will\u00b7k\u00fcr\u00b7lich", "stil\u00b7le", "stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ruft: \u00bbLieber Gott, was ist denn das?\u00ab", "tokens": ["Ruft", ":", "\u00bb", "Lie\u00b7ber", "Gott", ",", "was", "ist", "denn", "das", "?", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "ADJD", "NN", "$,", "PWS", "VAFIN", "ADV", "PDS", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Greift in den Sack, gibt ihnen was", "tokens": ["Greift", "in", "den", "Sack", ",", "gibt", "ih\u00b7nen", "was"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "PWS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und denkt noch lange gern und heiter", "tokens": ["Und", "denkt", "noch", "lan\u00b7ge", "gern", "und", "hei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "KON", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "An dieses Ro\u00df und diesen Reiter.", "tokens": ["An", "die\u00b7ses", "Ro\u00df", "und", "die\u00b7sen", "Rei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So h\u00e4tten denn gewi\u00df die zwei", "tokens": ["So", "h\u00e4t\u00b7ten", "denn", "ge\u00b7wi\u00df", "die", "zwei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ART", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch fortgesetzte Bettelei,", "tokens": ["Durch", "fort\u00b7ge\u00b7setz\u00b7te", "Bet\u00b7te\u00b7lei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vereint in solcherlei Gestalt,", "tokens": ["Ver\u00b7eint", "in", "sol\u00b7cher\u00b7lei", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch ferner ihren Unterhalt,", "tokens": ["Auch", "fer\u00b7ner", "ih\u00b7ren", "Un\u00b7ter\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja, ein Verm\u00f6gen, sich erworben,", "tokens": ["Ja", ",", "ein", "Ver\u00b7m\u00f6\u00b7gen", ",", "sich", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "$,", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "W\u00e4r' Bischof Martin nicht gestorben.", "tokens": ["W\u00e4r'", "Bi\u00b7schof", "Mar\u00b7tin", "nicht", "ge\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Als dieser nun gestorben war,", "tokens": ["Als", "die\u00b7ser", "nun", "ge\u00b7stor\u00b7ben", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Legt man ihn auf die Totenbahr", "tokens": ["Legt", "man", "ihn", "auf", "die", "To\u00b7ten\u00b7bahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und t\u00e4t' ihn unter Weheklagen", "tokens": ["Und", "t\u00e4t'", "ihn", "un\u00b7ter", "We\u00b7he\u00b7kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fein langsam nach dem Dome tragen", "tokens": ["Fein", "lang\u00b7sam", "nach", "dem", "Do\u00b7me", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu seiner wohlverdienten Ruh.", "tokens": ["Zu", "sei\u00b7ner", "wohl\u00b7ver\u00b7dien\u00b7ten", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sieh, ein Wunder trug sich zu.", "tokens": ["Und", "sieh", ",", "ein", "Wun\u00b7der", "trug", "sich", "zu", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ART", "NN", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da, wo der Zug vor\u00fcber kam,", "tokens": ["Da", ",", "wo", "der", "Zug", "vor\u00b7\u00fc\u00b7ber", "kam", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wer irgend blind, wer irgend lahm,", "tokens": ["Wer", "ir\u00b7gend", "blind", ",", "wer", "ir\u00b7gend", "lahm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "$,", "PWS", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der f\u00fchlte sich sogleich genesen,", "tokens": ["Der", "f\u00fchl\u00b7te", "sich", "sog\u00b7leich", "ge\u00b7ne\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Als ob er niemals krank gewesen.", "tokens": ["Als", "ob", "er", "nie\u00b7mals", "krank", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Oh, wie erschrak die lahme Frau!", "tokens": ["Oh", ",", "wie", "er\u00b7schrak", "die", "lah\u00b7me", "Frau", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von weitem schon sah sie's genau,", "tokens": ["Von", "wei\u00b7tem", "schon", "sah", "sie's", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Weil sie hoch oben, wie gewohnt,", "tokens": ["Weil", "sie", "hoch", "o\u00b7ben", ",", "wie", "ge\u00b7wohnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "$,", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf des Gemahles R\u00fccken thront.", "tokens": ["Auf", "des", "Ge\u00b7mah\u00b7les", "R\u00fc\u00b7cken", "thront", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bblauf\u00ab, rief sie, \u00bblaufe schnell von hinnen,", "tokens": ["\u00bb", "lauf", "\u00ab", ",", "rief", "sie", ",", "\u00bb", "lau\u00b7fe", "schnell", "von", "hin\u00b7nen", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "VVFIN", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Damit wir noch beizeit entrinnen.\u00ab", "tokens": ["Da\u00b7mit", "wir", "noch", "bei\u00b7zeit", "ent\u00b7rin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Er l\u00e4uft, er st\u00f6\u00dft an einen Stein,", "tokens": ["Er", "l\u00e4uft", ",", "er", "st\u00f6\u00dft", "an", "ei\u00b7nen", "Stein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er f\u00e4llt und bricht beinah ein Bein.", "tokens": ["Er", "f\u00e4llt", "und", "bricht", "bei\u00b7nah", "ein", "Bein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die Prozession ist auch schon da.", "tokens": ["Die", "Pro\u00b7zes\u00b7si\u00b7on", "ist", "auch", "schon", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sie zieht vorbei. Der Blinde sah,", "tokens": ["Sie", "zieht", "vor\u00b7bei", ".", "Der", "Blin\u00b7de", "sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Lahme, ebenfalls kuriert,", "tokens": ["Die", "Lah\u00b7me", ",", "e\u00b7ben\u00b7falls", "ku\u00b7riert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kann gehn, als wie mit \u00d6l geschmiert,", "tokens": ["Kann", "gehn", ",", "als", "wie", "mit", "\u00d6l", "ge\u00b7schmiert", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "KOUS", "KOKOM", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und beide sind wie neu geboren", "tokens": ["Und", "bei\u00b7de", "sind", "wie", "neu", "ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "KOKOM", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und kratzen sich verdutzt die Ohren.", "tokens": ["Und", "krat\u00b7zen", "sich", "ver\u00b7dutzt", "die", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Jetzt fragt es sich: Was aber nun?", "tokens": ["Jetzt", "fragt", "es", "sich", ":", "Was", "a\u00b7ber", "nun", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$.", "PWS", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer leben will, der mu\u00df was tun.", "tokens": ["Wer", "le\u00b7ben", "will", ",", "der", "mu\u00df", "was", "tun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "VMFIN", "$,", "ART", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn wer kein Geld sein eigen nennt", "tokens": ["Denn", "wer", "kein", "Geld", "sein", "ei\u00b7gen", "nennt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PIAT", "NN", "PPOSAT", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hat zum Betteln kein Talent", "tokens": ["Und", "hat", "zum", "Bet\u00b7teln", "kein", "Ta\u00b7lent"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPRART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und h\u00e4lt zum Stehlen sich zu fein", "tokens": ["Und", "h\u00e4lt", "zum", "Steh\u00b7len", "sich", "zu", "fein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PRF", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und mag auch nicht im Kloster sein,", "tokens": ["Und", "mag", "auch", "nicht", "im", "Klos\u00b7ter", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "PTKNEG", "APPRART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der ist f\u00fcrwahr nicht zu beneiden.", "tokens": ["Der", "ist", "f\u00fcr\u00b7wahr", "nicht", "zu", "be\u00b7nei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das \u00fcberlegten sich die beiden.", "tokens": ["Das", "\u00fc\u00b7ber\u00b7leg\u00b7ten", "sich", "die", "bei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie, sehr begabt, wird eine fesche,", "tokens": ["Sie", ",", "sehr", "be\u00b7gabt", ",", "wird", "ei\u00b7ne", "fe\u00b7sche", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "ADJD", "$,", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gesuchte Pl\u00e4tterin der W\u00e4sche.", "tokens": ["Ge\u00b7such\u00b7te", "Pl\u00e4t\u00b7te\u00b7rin", "der", "W\u00e4\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er, mehr beschr\u00e4nkt, nahm eine Axt", "tokens": ["Er", ",", "mehr", "be\u00b7schr\u00e4nkt", ",", "nahm", "ei\u00b7ne", "Axt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ADV", "VVFIN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und spaltet Kl\u00f6tze, da\u00df es knackst,", "tokens": ["Und", "spal\u00b7tet", "Kl\u00f6t\u00b7ze", ",", "da\u00df", "es", "knackst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von morgens fr\u00fch bis in die Nacht.", "tokens": ["Von", "mor\u00b7gens", "fr\u00fch", "bis", "in", "die", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das hat Sankt Martin gut gemacht.", "tokens": ["Das", "hat", "Sankt", "Mar\u00b7tin", "gut", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVFIN", "NE", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}