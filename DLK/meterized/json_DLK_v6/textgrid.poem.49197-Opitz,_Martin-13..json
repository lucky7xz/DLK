{"textgrid.poem.49197": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "13.", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Derselbe, welcher diese Nacht", "tokens": ["Der\u00b7sel\u00b7be", ",", "wel\u00b7cher", "die\u00b7se", "Nacht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PDAT", "$,", "PRELS", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erst hat sein Leben hingebracht,", "tokens": ["Erst", "hat", "sein", "Le\u00b7ben", "hin\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist eben auch wie die gestorben,", "tokens": ["Ist", "e\u00b7ben", "auch", "wie", "die", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "KOKOM", "ART", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die l\u00e4ngst zuvor verbliechen seyn,", "tokens": ["Die", "l\u00e4ngst", "zu\u00b7vor", "ver\u00b7blie\u00b7chen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und derer Leichnam und Gebein", "tokens": ["Und", "de\u00b7rer", "Leich\u00b7nam", "und", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "NN", "KON", "NN"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Vor tausend Jahren sind verdorben.", "tokens": ["Vor", "tau\u00b7send", "Jah\u00b7ren", "sind", "ver\u00b7dor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Mensch stirbt zeitlich oder spat,", "tokens": ["Der", "Mensch", "stirbt", "zeit\u00b7lich", "o\u00b7der", "spat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So bald er nur gesegnet hat,", "tokens": ["So", "bald", "er", "nur", "ge\u00b7seg\u00b7net", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wird er in den Sand versencket", "tokens": ["So", "wird", "er", "in", "den", "Sand", "ver\u00b7sen\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und legt sich zu der langen Rhu.", "tokens": ["Und", "legt", "sich", "zu", "der", "lan\u00b7gen", "Rhu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wann Ohr und Auge schon ist zu,", "tokens": ["Wann", "Ohr", "und", "Au\u00b7ge", "schon", "ist", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer ist, der an die Welt gedencket?", "tokens": ["Wer", "ist", ",", "der", "an", "die", "Welt", "ge\u00b7den\u00b7cket", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Seele doch allein und blo\u00df", "tokens": ["Die", "See\u00b7le", "doch", "al\u00b7lein", "und", "blo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fleugt, wann sie wird de\u00df C\u00f6rpers lo\u00df,", "tokens": ["Fleugt", ",", "wann", "sie", "wird", "de\u00df", "C\u00f6r\u00b7pers", "lo\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zum Himmel, da sie her gef\u00fchret.", "tokens": ["Zum", "Him\u00b7mel", ",", "da", "sie", "her", "ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "APZR", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was diesen schn\u00f6den Leib betrifft,", "tokens": ["Was", "die\u00b7sen", "schn\u00f6\u00b7den", "Leib", "be\u00b7tr\u00b7ifft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wird nichts an ihm als Stanck und Gifft,", "tokens": ["Wird", "nichts", "an", "ihm", "als", "Stanck", "und", "Gifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "PPER", "KOUS", "NN", "KON", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "Wie sch\u00f6n er vormals war, gesp\u00fchret.", "tokens": ["Wie", "sch\u00f6n", "er", "vor\u00b7mals", "war", ",", "ge\u00b7sp\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "ADV", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Es ist in ihm kein Geist mehr nicht,", "tokens": ["Es", "ist", "in", "ihm", "kein", "Geist", "mehr", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "PIAT", "NN", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Fleisch fellt weg, die Haut verbricht,", "tokens": ["Das", "Fleisch", "fellt", "weg", ",", "die", "Haut", "ver\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein jeglig Haar das mu\u00df verstieben;", "tokens": ["Ein", "jeg\u00b7lig", "Haar", "das", "mu\u00df", "ver\u00b7stie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PDS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, was ich achte mehr zu seyn,", "tokens": ["Und", ",", "was", "ich", "ach\u00b7te", "mehr", "zu", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADJA", "ADV", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Diejenige k\u00f6mpt keinem ein,", "tokens": ["Die\u00b7je\u00b7ni\u00b7ge", "k\u00f6mpt", "kei\u00b7nem", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die er f\u00fcr allem pflag zu lieben.", "tokens": ["Die", "er", "f\u00fcr", "al\u00b7lem", "pflag", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Tod begehrt nichts umb und an;", "tokens": ["Der", "Tod", "be\u00b7gehrt", "nichts", "umb", "und", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "APPR", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drumb, weil ich jetzt noch w\u00fcntschen kan,", "tokens": ["Drumb", ",", "weil", "ich", "jetzt", "noch", "w\u00fcnt\u00b7schen", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wil ich mir nur einig wehlen", "tokens": ["So", "wil", "ich", "mir", "nur", "ei\u00b7nig", "weh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gesunden Leib und rechten Sinn;", "tokens": ["Ge\u00b7sun\u00b7den", "Leib", "und", "rech\u00b7ten", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hernachmals, wann ich kalt schon bin,", "tokens": ["Her\u00b7nach\u00b7mals", ",", "wann", "ich", "kalt", "schon", "bin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADJD", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da will ich Gott den Rest befehlen.", "tokens": ["Da", "will", "ich", "Gott", "den", "Rest", "be\u00b7feh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Homerus, Sappho, Pindarus, Anacreon, Hesiodus", "tokens": ["Ho\u00b7me\u00b7rus", ",", "Sap\u00b7pho", ",", "Pin\u00b7da\u00b7rus", ",", "A\u00b7na\u00b7cre\u00b7on", ",", "He\u00b7sio\u00b7dus"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "NE", "$,", "NE"], "meter": "+--+--+--+-+-+-", "measure": "elegiambus"}, "line.2": {"text": "Und andere sind ohne Sorgen,", "tokens": ["Und", "an\u00b7de\u00b7re", "sind", "oh\u00b7ne", "Sor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man red' jetzt auff sie, was man wil;", "tokens": ["Man", "red'", "jetzt", "auff", "sie", ",", "was", "man", "wil", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "PPER", "$,", "PRELS", "PIS", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So, sagt man nun gleich von mir viel,", "tokens": ["So", ",", "sagt", "man", "nun", "gleich", "von", "mir", "viel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "ADV", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wer wei\u00df, geschieht es \u00fcbermorgen.", "tokens": ["Wer", "wei\u00df", ",", "ge\u00b7schieht", "es", "\u00fc\u00b7ber\u00b7mor\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wo dient das W\u00fcntschen aber zu,", "tokens": ["Wo", "dient", "das", "W\u00fcnt\u00b7schen", "a\u00b7ber", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als das ein Mensch ohn alle Rhu", "tokens": ["Als", "das", "ein", "Mensch", "ohn", "al\u00b7le", "Rhu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "ART", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich Tag und Nacht nur selbst verzehret?", "tokens": ["Sich", "Tag", "und", "Nacht", "nur", "selbst", "ver\u00b7zeh\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "KON", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer w\u00fcndschet, kr\u00e4nckt sich jederzeit;", "tokens": ["Wer", "w\u00fcnd\u00b7schet", ",", "kr\u00e4nckt", "sich", "je\u00b7der\u00b7zeit", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wer todt ist, ist ohn alles Leid.", "tokens": ["Wer", "todt", "ist", ",", "ist", "ohn", "al\u00b7les", "Leid", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "O, wohl dem, der nichts mehr begehret!", "tokens": ["O", ",", "wohl", "dem", ",", "der", "nichts", "mehr", "be\u00b7ge\u00b7hret", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ART", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}}}}}