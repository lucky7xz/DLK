{"textgrid.poem.40229": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Reicher war in Spanien Keiner", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Reicher war in Spanien Keiner", "tokens": ["Rei\u00b7cher", "war", "in", "Spa\u00b7ni\u00b7en", "Kei\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "NE", "NN"], "meter": "+-+----+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "als der Reichste von Sevilla,", "tokens": ["als", "der", "Reichs\u00b7te", "von", "Se\u00b7vil\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "als der reiche Ben Manasse,", "tokens": ["als", "der", "rei\u00b7che", "Ben", "Ma\u00b7nas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aller Juden Stolz und Trost.", "tokens": ["al\u00b7ler", "Ju\u00b7den", "Stolz", "und", "Trost", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Denn schon lange ging ein Murren", "tokens": ["Denn", "schon", "lan\u00b7ge", "ging", "ein", "Mur\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "drohend durch die Christenschaaren", "tokens": ["dro\u00b7hend", "durch", "die", "Chris\u00b7ten\u00b7schaa\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ob der z\u00e4hen Macht des Volkes,", "tokens": ["ob", "der", "z\u00e4\u00b7hen", "Macht", "des", "Vol\u00b7kes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das den Heiland einst erw\u00fcrgt.", "tokens": ["das", "den", "Hei\u00b7land", "einst", "er\u00b7w\u00fcrgt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch das Gold des Ben Manasse", "tokens": ["Doch", "das", "Gold", "des", "Ben", "Ma\u00b7nas\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "gr\u00fc\u00dften selbst die Christen", "tokens": ["gr\u00fc\u00df\u00b7ten", "selbst", "die", "Chris\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und die Priester schwiegen noch.", "tokens": ["Und", "die", "Pries\u00b7ter", "schwie\u00b7gen", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sch\u00f6ner war in Spanien Keine", "tokens": ["Sch\u00f6\u00b7ner", "war", "in", "Spa\u00b7ni\u00b7en", "Kei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "NE", "NE"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "als die Sch\u00f6nste von Sevilla,", "tokens": ["als", "die", "Sch\u00f6ns\u00b7te", "von", "Se\u00b7vil\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "als des gro\u00dfen Juden Tochter,", "tokens": ["als", "des", "gro\u00b7\u00dfen", "Ju\u00b7den", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einz'ge, sch\u00f6ne, Sulamith.", "tokens": ["einz'\u00b7ge", ",", "sch\u00f6\u00b7ne", ",", "Su\u00b7la\u00b7mith", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "$,", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Und die S\u00f6hne ihres Stammes", "tokens": ["Und", "die", "S\u00f6h\u00b7ne", "ih\u00b7res", "Stam\u00b7mes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "kamen weither sie umwerbend,", "tokens": ["ka\u00b7men", "weit\u00b7her", "sie", "um\u00b7wer\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "emsig wie die Bienen schwirren", "tokens": ["em\u00b7sig", "wie", "die", "Bie\u00b7nen", "schwir\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVINF"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "um den Mandelbl\u00fctenbaum.", "tokens": ["um", "den", "Man\u00b7del\u00b7bl\u00fc\u00b7ten\u00b7baum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "denn es liebte sie ein Ritter,", "tokens": ["denn", "es", "lieb\u00b7te", "sie", "ein", "Rit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Don Alvaro de Niebla,", "tokens": ["Don", "Al\u00b7va\u00b7ro", "de", "Nieb\u00b7la", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "denn den Ritter liebte ", "tokens": ["denn", "den", "Rit\u00b7ter", "lieb\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "ach, der fromme stolze Ritter", "tokens": ["ach", ",", "der", "from\u00b7me", "stol\u00b7ze", "Rit\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["XY", "$,", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ha\u00dfte ihres Vaters Glauben", "tokens": ["ha\u00df\u00b7te", "ih\u00b7res", "Va\u00b7ters", "Glau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und verachtete ihr Volk!", "tokens": ["und", "ver\u00b7ach\u00b7te\u00b7te", "ihr", "Volk", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und weil sie so sehr ihn liebte,", "tokens": ["Und", "weil", "sie", "so", "sehr", "ihn", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "und weil Er so sehr sie dr\u00e4ngte,", "tokens": ["und", "weil", "Er", "so", "sehr", "sie", "dr\u00e4ng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nahm sie heimlich ", "tokens": ["nahm", "sie", "heim\u00b7lich"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD"], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "und nun hie\u00df sie Margarita.", "tokens": ["und", "nun", "hie\u00df", "sie", "Mar\u00b7ga\u00b7ri\u00b7ta", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Viel geweihtes Wasser flo\u00df schon", "tokens": ["Viel", "ge\u00b7weih\u00b7tes", "Was\u00b7ser", "flo\u00df", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "damals \u00fcber Judenstirnen;", "tokens": ["da\u00b7mals", "\u00fc\u00b7ber", "Ju\u00b7dens\u00b7tir\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "denn \u2013 die Furcht des Heil'gen Geistes", "tokens": ["denn", "\u2013", "die", "Furcht", "des", "Heil'\u00b7gen", "Geis\u00b7tes"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "tauft hinweg die Menschenfurcht.", "tokens": ["tauft", "hin\u00b7weg", "die", "Men\u00b7schen\u00b7furcht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und die Christen drohten lauter!", "tokens": ["Und", "die", "Chris\u00b7ten", "droh\u00b7ten", "lau\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "nur die F\u00fcrsten schwiegen still noch", "tokens": ["nur", "die", "F\u00fcrs\u00b7ten", "schwie\u00b7gen", "still", "noch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADJD", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "vor dem Gold des Ben Manasse, \u2013", "tokens": ["vor", "dem", "Gold", "des", "Ben", "Ma\u00b7nas\u00b7se", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "doch die Priester murrten schon.", "tokens": ["doch", "die", "Pries\u00b7ter", "murr\u00b7ten", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Er, der greise Jude selber,", "tokens": ["Er", ",", "der", "grei\u00b7se", "Ju\u00b7de", "sel\u00b7ber", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ob auch treu dem Gott der V\u00e4ter,", "tokens": ["ob", "auch", "treu", "dem", "Gott", "der", "V\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "schaute oft voll tiefer Sorge", "tokens": ["schau\u00b7te", "oft", "voll", "tie\u00b7fer", "Sor\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "auf sein liebes, einzig Kind.", "tokens": ["auf", "sein", "lie\u00b7bes", ",", "ein\u00b7zig", "Kind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "$,", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "\u00bbsulamith, mein schutzlos T\u00e4ubchen,", "tokens": ["\u00bb", "su\u00b7la\u00b7mith", ",", "mein", "schutz\u00b7los", "T\u00e4ub\u00b7chen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "PPOSAT", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "willst du einen Mann nicht w\u00e4hlen", "tokens": ["willst", "du", "ei\u00b7nen", "Mann", "nicht", "w\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "aus den S\u00f6hnen deines Stammes,", "tokens": ["aus", "den", "S\u00f6h\u00b7nen", "dei\u00b7nes", "Stam\u00b7mes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der ein sichres Nest dir baut?\u00ab", "tokens": ["der", "ein", "sich\u00b7res", "Nest", "dir", "baut", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ach, mein Vater! nein, mein Vater!", "tokens": ["Ach", ",", "mein", "Va\u00b7ter", "!", "nein", ",", "mein", "Va\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPOSAT", "NN", "$.", "PTKANT", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "frage nicht! Ich kann nicht ", "tokens": ["fra\u00b7ge", "nicht", "!", "Ich", "kann", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "$.", "PPER", "VMFIN", "PTKNEG"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Die ich sah von unserm Stamme.", "tokens": ["Die", "ich", "sah", "von", "un\u00b7serm", "Stam\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Du, mein Vater, bist mein Schutz!", "tokens": ["Du", ",", "mein", "Va\u00b7ter", ",", "bist", "mein", "Schutz", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bbsulamith, mein einzig Kleinod,", "tokens": ["\u00bb", "su\u00b7la\u00b7mith", ",", "mein", "ein\u00b7zig", "Klei\u00b7nod", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "PPOSAT", "ADJD", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "sieh: er ist sehr alt, dein Vater!", "tokens": ["sieh", ":", "er", "ist", "sehr", "alt", ",", "dein", "Va\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wirst du auch allein, verlassen", "tokens": ["Wirst", "du", "auch", "al\u00b7lein", ",", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "$,", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "treu dem Gott der V\u00e4ter sein?!\u00ab", "tokens": ["treu", "dem", "Gott", "der", "V\u00e4\u00b7ter", "sein", "?!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "ART", "NN", "ART", "NN", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "O mein Gott, mein Gott \u2013! Mein Vater,", "tokens": ["O", "mein", "Gott", ",", "mein", "Gott", "\u2013", "!", "Mein", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$(", "$.", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "frage nicht! Ja, ja, ich schw\u00f6re:", "tokens": ["fra\u00b7ge", "nicht", "!", "Ja", ",", "ja", ",", "ich", "schw\u00f6\u00b7re", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$.", "PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "immer treu zu sein dem Glauben,", "tokens": ["im\u00b7mer", "treu", "zu", "sein", "dem", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VAINF", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbo du Leuchte meines Alters,", "tokens": ["\u00bb", "o", "du", "Leuch\u00b7te", "mei\u00b7nes", "Al\u00b7ters", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "o du Morgen meiner Tage,", "tokens": ["o", "du", "Mor\u00b7gen", "mei\u00b7ner", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sulamith, Tau meiner N\u00e4chte,", "tokens": ["Su\u00b7la\u00b7mith", ",", "Tau", "mei\u00b7ner", "N\u00e4ch\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "PPOSAT", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Sulamith, \u2013 ich segne dich!\u00ab", "tokens": ["Su\u00b7la\u00b7mith", ",", "\u2013", "ich", "seg\u00b7ne", "dich", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "$(", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Weinend lag, so oft die Nacht sank,", "tokens": ["Wei\u00b7nend", "lag", ",", "so", "oft", "die", "Nacht", "sank", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weil sie ihren Vater liebte,", "tokens": ["weil", "sie", "ih\u00b7ren", "Va\u00b7ter", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "weil sie ihren Liebsten liebte,", "tokens": ["weil", "sie", "ih\u00b7ren", "Liebs\u00b7ten", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Margarita Sulamith.", "tokens": ["Mar\u00b7ga\u00b7ri\u00b7ta", "Su\u00b7la\u00b7mith", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}}, "stanza.18": {"line.1": {"text": "Und an jedem Abend wollte", "tokens": ["Und", "an", "je\u00b7dem", "A\u00b7bend", "woll\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sie den Ritter bitten, mit ihr", "tokens": ["sie", "den", "Rit\u00b7ter", "bit\u00b7ten", ",", "mit", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ART", "NN", "VVINF", "$,", "APPR", "PPOSAT"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "doch sie schwieg: er war so stolz.", "tokens": ["doch", "sie", "schwieg", ":", "er", "war", "so", "stolz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Und an jedem Morgen wollte", "tokens": ["Und", "an", "je\u00b7dem", "Mor\u00b7gen", "woll\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN", "VMFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles sie dem Vater ", "tokens": ["Al\u00b7les", "sie", "dem", "Va\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "doch sie konnt' ihn nicht betr\u00fcben,", "tokens": ["doch", "sie", "konnt'", "ihn", "nicht", "be\u00b7tr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und sie schwieg: er war so alt.", "tokens": ["und", "sie", "schwieg", ":", "er", "war", "so", "alt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Ja, sie liebte ihren Vater,", "tokens": ["Ja", ",", "sie", "lieb\u00b7te", "ih\u00b7ren", "Va\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "liebte mehr ihn, weil so gut er,", "tokens": ["lieb\u00b7te", "mehr", "ihn", ",", "weil", "so", "gut", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "$,", "KOUS", "ADV", "ADJD", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "mehr ihn, weil so fromm er glaubte,", "tokens": ["mehr", "ihn", ",", "weil", "so", "fromm", "er", "glaub\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "KOUS", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mehr, je mehr sie um ihn log.", "tokens": ["mehr", ",", "je", "mehr", "sie", "um", "ihn", "log", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Ja, sie liebte ihren Ritter,", "tokens": ["Ja", ",", "sie", "lieb\u00b7te", "ih\u00b7ren", "Rit\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "liebte mehr ihn, weil so stolz er,", "tokens": ["lieb\u00b7te", "mehr", "ihn", ",", "weil", "so", "stolz", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "$,", "KOUS", "ADV", "ADJD", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "mehr ihn, weil so hei\u00df er glaubte,", "tokens": ["mehr", "ihn", ",", "weil", "so", "hei\u00df", "er", "glaub\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "KOUS", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mehr, je mehr sie um ihn litt.", "tokens": ["mehr", ",", "je", "mehr", "sie", "um", "ihn", "litt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Liebte ", "tokens": ["Lieb\u00b7te"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "liebte ihn, den Mann am Kreuze,", "tokens": ["lieb\u00b7te", "ihn", ",", "den", "Mann", "am", "Kreu\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "liebt' ihn um sein gro\u00dfes Leiden,", "tokens": ["liebt'", "ihn", "um", "sein", "gro\u00b7\u00dfes", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mehr, je mehr sie selber litt.", "tokens": ["mehr", ",", "je", "mehr", "sie", "sel\u00b7ber", "litt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Aber morgens, aber abends", "tokens": ["A\u00b7ber", "mor\u00b7gens", ",", "a\u00b7ber", "a\u00b7bends"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "$,", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "l\u00e4chelte vor ihrem Vater,", "tokens": ["l\u00e4\u00b7chel\u00b7te", "vor", "ih\u00b7rem", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "l\u00e4chelte vor ihrem Liebsten", "tokens": ["l\u00e4\u00b7chel\u00b7te", "vor", "ih\u00b7rem", "Liebs\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Margarita Sulamith.", "tokens": ["Mar\u00b7ga\u00b7ri\u00b7ta", "Su\u00b7la\u00b7mith", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}}, "stanza.24": {"line.1": {"text": "\u00bbmargarita, meine Sehnsucht,", "tokens": ["\u00bb", "mar\u00b7ga\u00b7ri\u00b7ta", ",", "mei\u00b7ne", "Sehn\u00b7sucht", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "siehst du wol den Mondschein beben", "tokens": ["siehst", "du", "wol", "den", "Mond\u00b7schein", "be\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "um die weichen Wellenbr\u00fcste", "tokens": ["um", "die", "wei\u00b7chen", "Wel\u00b7len\u00b7br\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dort im Guadalquivir?!", "tokens": ["dort", "im", "Gua\u00b7dal\u00b7qui\u00b7vir", "?!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.25": {"line.1": {"text": "Margarita, meine Sehnsucht,", "tokens": ["Mar\u00b7ga\u00b7ri\u00b7ta", ",", "mei\u00b7ne", "Sehn\u00b7sucht", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "siehst du dort den Abendfalter", "tokens": ["siehst", "du", "dort", "den", "A\u00b7bend\u00b7fal\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "taumeln durch die Fliederbl\u00fcte?", "tokens": ["tau\u00b7meln", "durch", "die", "Flie\u00b7der\u00b7bl\u00fc\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Margarita, ", "tokens": ["Mar\u00b7ga\u00b7ri\u00b7ta", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.26": {"line.1": {"text": "Ach, Alvaro! ach, ich seh' ihn", "tokens": ["Ach", ",", "Al\u00b7va\u00b7ro", "!", "ach", ",", "ich", "seh'", "ihn"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "NE", "$.", "XY", "$,", "PPER", "VVFIN", "PPER"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "in ein gro\u00dfes Feuer flattern.", "tokens": ["in", "ein", "gro\u00b7\u00dfes", "Feu\u00b7er", "flat\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, und sieh: der Mond verbirgt sich", "tokens": ["Ach", ",", "und", "sieh", ":", "der", "Mond", "ver\u00b7birgt", "sich"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "VVIMP", "$.", "ART", "NN", "VVFIN", "PRF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hinterm Turm des ", "tokens": ["hin\u00b7term", "Turm", "des"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.27": {"line.1": {"text": "\u00bbmargarita, dort im Dome", "tokens": ["\u00bb", "mar\u00b7ga\u00b7ri\u00b7ta", ",", "dort", "im", "Do\u00b7me"], "token_info": ["punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "NE", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wartet doch der ", "tokens": ["war\u00b7tet", "doch", "der"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADV", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "La\u00df mich nun nicht l\u00e4nger ", "tokens": ["La\u00df", "mich", "nun", "nicht", "l\u00e4n\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Margarita! ", "tokens": ["Mar\u00b7ga\u00b7ri\u00b7ta", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.28": {"line.1": {"text": "Oh, Alvaro \u2013 schone meiner!", "tokens": ["Oh", ",", "Al\u00b7va\u00b7ro", "\u2013", "scho\u00b7ne", "mei\u00b7ner", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "NE", "$(", "VVFIN", "PPOSAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "denk' an meinen alten Vater!", "tokens": ["denk'", "an", "mei\u00b7nen", "al\u00b7ten", "Va\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "la\u00df uns warten \u2013 heimlich \u2013 bis er \u2013", "tokens": ["la\u00df", "uns", "war\u00b7ten", "\u2013", "heim\u00b7lich", "\u2013", "bis", "er", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVINF", "$(", "ADJD", "$(", "KON", "PPER", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bis \u2013 \u2013, und scheu verstummte sie.", "tokens": ["bis", "\u2013", "\u2013", ",", "und", "scheu", "ver\u00b7stumm\u00b7te", "sie", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "$(", "$,", "KON", "ADJD", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "\u00bbsag's nur! bis er ", "tokens": ["\u00bb", "sag's", "nur", "!", "bis", "er"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "ADV", "$.", "KOUS", "PPER"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "stie\u00df er zitternd durch die Z\u00e4hne,", "tokens": ["stie\u00df", "er", "zit\u00b7ternd", "durch", "die", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "st\u00fcrzte wild er aus dem Garten, \u2013", "tokens": ["st\u00fcrz\u00b7te", "wild", "er", "aus", "dem", "Gar\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "APPR", "ART", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und sie wankte bla\u00df ins Haus.", "tokens": ["und", "sie", "wank\u00b7te", "bla\u00df", "ins", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Und es kam auf stillen Sohlen", "tokens": ["Und", "es", "kam", "auf", "stil\u00b7len", "Soh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "durch die Sommerglut geschlichen", "tokens": ["durch", "die", "Som\u00b7mer\u00b7glut", "ge\u00b7schli\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nach Sevilla ein gefr\u00e4\u00dfig", "tokens": ["nach", "Se\u00b7vil\u00b7la", "ein", "ge\u00b7fr\u00e4\u00b7\u00dfig"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "ART", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "katzenhaft Gespenst \u2013 die Pest.", "tokens": ["kat\u00b7zen\u00b7haft", "Ge\u00b7spenst", "\u2013", "die", "Pest", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "NN", "$(", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Auf den Gassen, in den Kammern", "tokens": ["Auf", "den", "Gas\u00b7sen", ",", "in", "den", "Kam\u00b7mern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lag zum Sprunge sie gekauert;", "tokens": ["lag", "zum", "Sprun\u00b7ge", "sie", "ge\u00b7kau\u00b7ert", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und nun leckte sie die F\u00e4nge,", "tokens": ["und", "nun", "leck\u00b7te", "sie", "die", "F\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "reckte sie zum \u00fcppigen Schmaus.", "tokens": ["reck\u00b7te", "sie", "zum", "\u00fcp\u00b7pi\u00b7gen", "Schmaus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.32": {"line.1": {"text": "Ueber tausend tausend Leiber", "tokens": ["Ue\u00b7ber", "tau\u00b7send", "tau\u00b7send", "Lei\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "CARD", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "spannte sie ihr bl\u00e4ulich Tischtuch;", "tokens": ["spann\u00b7te", "sie", "ihr", "bl\u00e4u\u00b7lich", "Tischtuch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und das Mahl mit ihr zu teilen,", "tokens": ["und", "das", "Mahl", "mit", "ihr", "zu", "tei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kam ihr Br\u00e4utigam \u2013 der Tod.", "tokens": ["kam", "ihr", "Br\u00e4u\u00b7ti\u00b7gam", "\u2013", "der", "Tod", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "$(", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Tag und Nacht sie gierig schwelgten;", "tokens": ["Tag", "und", "Nacht", "sie", "gie\u00b7rig", "schwelg\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "rings die Leichenfeuer brannten,", "tokens": ["rings", "die", "Lei\u00b7chen\u00b7feu\u00b7er", "brann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ihres grausen Liebesfestes", "tokens": ["ih\u00b7res", "grau\u00b7sen", "Lie\u00b7bes\u00b7fes\u00b7tes"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hochzeitsfackeln, \u2013 Tag und Nacht.", "tokens": ["Hoch\u00b7zeits\u00b7fa\u00b7ckeln", ",", "\u2013", "Tag", "und", "Nacht", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Und der geile Bund ward fruchtbar:", "tokens": ["Und", "der", "gei\u00b7le", "Bund", "ward", "frucht\u00b7bar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "aus dem Schoo\u00df der Pest gekrochen", "tokens": ["aus", "dem", "Schoo\u00df", "der", "Pest", "ge\u00b7kro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "kam ans Licht ein blindgeboren", "tokens": ["kam", "ans", "Licht", "ein", "blind\u00b7ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "gr\u00e4ulich Vampyrzwillingspaar, \u2013", "tokens": ["gr\u00e4u\u00b7lich", "Vam\u00b7pyr\u00b7zwil\u00b7lings\u00b7paar", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["ADJD", "NN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und es hob sich in die L\u00fcfte,", "tokens": ["und", "es", "hob", "sich", "in", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "hakte sich in alle Ohren,", "tokens": ["hak\u00b7te", "sich", "in", "al\u00b7le", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "kroch durch alle Christenherzen:", "tokens": ["kroch", "durch", "al\u00b7le", "Chris\u00b7ten\u00b7her\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "blinde ", "tokens": ["blin\u00b7de"], "token_info": ["word"], "pos": ["ADJA"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.35": {"line.1": {"text": "Schwirrend durch ganz Spanien flog es, \u2013", "tokens": ["Schwir\u00b7rend", "durch", "ganz", "Spa\u00b7ni\u00b7en", "flog", "es", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "APPR", "ADV", "NE", "VVFIN", "PPER", "$,", "$("], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.2": {"text": "und es zischelten die Priester,", "tokens": ["und", "es", "zi\u00b7schel\u00b7ten", "die", "Pries\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "und es raunten auch die F\u00fcrsten,", "tokens": ["und", "es", "raun\u00b7ten", "auch", "die", "F\u00fcrs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und es knirschte wild das Volk:", "tokens": ["und", "es", "knirschte", "wild", "das", "Volk", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.36": {"line.1": {"text": "Dr\u00fcckt sie tot, die Judennattern!", "tokens": ["Dr\u00fcckt", "sie", "tot", ",", "die", "Ju\u00b7den\u00b7nat\u00b7tern", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sie vergiften uns die Brunnen!", "tokens": ["sie", "ver\u00b7gif\u00b7ten", "uns", "die", "Brun\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die den Heiland einst gekreuzigt,", "tokens": ["Die", "den", "Hei\u00b7land", "einst", "ge\u00b7kreu\u00b7zigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wollen w\u00fcrgen nun auch Uns!", "tokens": ["wol\u00b7len", "w\u00fcr\u00b7gen", "nun", "auch", "Uns", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "ADV", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Gier'ger immer fra\u00df die Pest noch;", "tokens": ["Gier'\u00b7ger", "im\u00b7mer", "fra\u00df", "die", "Pest", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "unter Christen, unter Juden", "tokens": ["un\u00b7ter", "Chris\u00b7ten", ",", "un\u00b7ter", "Ju\u00b7den"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "w\u00fctete ihr gro\u00dfer Hunger;", "tokens": ["w\u00fc\u00b7te\u00b7te", "ihr", "gro\u00b7\u00dfer", "Hun\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "fra\u00df und fra\u00df und ward nicht satt.", "tokens": ["fra\u00df", "und", "fra\u00df", "und", "ward", "nicht", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "KON", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Hielt im Bann den Ha\u00df der Christen,", "tokens": ["Hielt", "im", "Bann", "den", "Ha\u00df", "der", "Chris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hielt im Bann das Gold der Juden;", "tokens": ["hielt", "im", "Bann", "das", "Gold", "der", "Ju\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jeder floh die Hand des Andern,", "tokens": ["Je\u00b7der", "floh", "die", "Hand", "des", "An\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Freund den Freund, und Feind den Feind.", "tokens": ["Freund", "den", "Freund", ",", "und", "Feind", "den", "Feind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "KON", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Kind verschlo\u00df sich vor dem Vater,", "tokens": ["Kind", "ver\u00b7schlo\u00df", "sich", "vor", "dem", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weib verschlo\u00df sich vor dem Manne, \u2013", "tokens": ["Weib", "ver\u00b7schlo\u00df", "sich", "vor", "dem", "Man\u00b7ne", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nur die Leichenknechte karrten", "tokens": ["nur", "die", "Lei\u00b7chen\u00b7knech\u00b7te", "karr\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "beutel\u00fcstern durch die Stadt.", "tokens": ["beu\u00b7te\u00b7l\u00fcs\u00b7tern", "durch", "die", "Stadt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Denn durch alle Schl\u00f6sser langte,", "tokens": ["Denn", "durch", "al\u00b7le", "Schl\u00f6s\u00b7ser", "lang\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "durch die Bretterth\u00fcr der H\u00fctte,", "tokens": ["durch", "die", "Bret\u00b7tert\u00b7h\u00fcr", "der", "H\u00fct\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "durch das Eisenthor der Steinburg,", "tokens": ["durch", "das", "Ei\u00b7sen\u00b7thor", "der", "Stein\u00b7burg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "mit der Krallenfaust die Pest;", "tokens": ["mit", "der", "Kral\u00b7len\u00b7faust", "die", "Pest", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "langte durch die rissige Lehmwand,", "tokens": ["lang\u00b7te", "durch", "die", "ris\u00b7si\u00b7ge", "Lehm\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "langte durch die Marmormauer, \u2013", "tokens": ["lang\u00b7te", "durch", "die", "Mar\u00b7mor\u00b7mau\u00b7er", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und der gro\u00dfe Ben Manasse", "tokens": ["und", "der", "gro\u00b7\u00dfe", "Ben", "Ma\u00b7nas\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "war ", "tokens": ["war"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}}, "stanza.42": {"line.1": {"text": "In dem hohen Prunkgemache", "tokens": ["In", "dem", "ho\u00b7hen", "Prunk\u00b7ge\u00b7ma\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auf den seidnen Polsterpf\u00fchlen", "tokens": ["auf", "den", "seid\u00b7nen", "Pols\u00b7ter\u00b7pf\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "w\u00e4lzte sich in Fieberschauern", "tokens": ["w\u00e4lz\u00b7te", "sich", "in", "Fie\u00b7ber\u00b7schau\u00b7ern"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "einsam Spaniens reichster Mann.", "tokens": ["ein\u00b7sam", "Spa\u00b7ni\u00b7ens", "reichs\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADJA", "NN", "$."], "meter": "+----+-+", "measure": "dactylic.init"}}, "stanza.43": {"line.1": {"text": "Sein Gesinde all verbarg sich,", "tokens": ["Sein", "Ge\u00b7sin\u00b7de", "all", "ver\u00b7barg", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PIAT", "VVFIN", "PRF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "seit den Hauch der Pest es sp\u00fcrte;", "tokens": ["seit", "den", "Hauch", "der", "Pest", "es", "sp\u00fcr\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "seinem Kind befahl er selber,", "tokens": ["sei\u00b7nem", "Kind", "be\u00b7fahl", "er", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "fern zu bleiben seinem Leib.", "tokens": ["fern", "zu", "blei\u00b7ben", "sei\u00b7nem", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Nur der alte treue Asser", "tokens": ["Nur", "der", "al\u00b7te", "treu\u00b7e", "As\u00b7ser"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lugte manchmal durch den Th\u00fcrspalt,", "tokens": ["lug\u00b7te", "manch\u00b7mal", "durch", "den", "Th\u00fcr\u00b7spalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "reichte seinem Herrn an langer", "tokens": ["reich\u00b7te", "sei\u00b7nem", "Herrn", "an", "lan\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stange hastig Wein und Brot.", "tokens": ["Stan\u00b7ge", "has\u00b7tig", "Wein", "und", "Brot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Sieben Tage schon in Qualen", "tokens": ["Sie\u00b7ben", "Ta\u00b7ge", "schon", "in", "Qua\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wand sich einsam Ben Manasse,", "tokens": ["wand", "sich", "ein\u00b7sam", "Ben", "Ma\u00b7nas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sieben Tage schon in Aengsten", "tokens": ["sie\u00b7ben", "Ta\u00b7ge", "schon", "in", "A\u00b7engs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "APPR", "NE"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "um sein einzig, schutzlos Kind.", "tokens": ["um", "sein", "ein\u00b7zig", ",", "schutz\u00b7los", "Kind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJD", "$,", "ADJD", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.46": {"line.1": {"text": "Immer in den wilden Tr\u00e4umen", "tokens": ["Im\u00b7mer", "in", "den", "wil\u00b7den", "Tr\u00e4u\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "sah er in ein gro\u00dfes Feuer", "tokens": ["sah", "er", "in", "ein", "gro\u00b7\u00dfes", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sein gehetztes T\u00e4ubchen flattern", "tokens": ["sein", "ge\u00b7hetz\u00b7tes", "T\u00e4ub\u00b7chen", "flat\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "vor der Wut des Christenvolks.", "tokens": ["vor", "der", "Wut", "des", "Chris\u00b7ten\u00b7volks", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.47": {"line.1": {"text": "Nein, o Qual! das Feuer brannte", "tokens": ["Nein", ",", "o", "Qual", "!", "das", "Feu\u00b7er", "brann\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "FM", "NN", "$.", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in ihm selber! immer wilder!", "tokens": ["in", "ihm", "sel\u00b7ber", "!", "im\u00b7mer", "wil\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$.", "ADV", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "nagte hei\u00df an allen Knochen,", "tokens": ["nag\u00b7te", "hei\u00df", "an", "al\u00b7len", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "z\u00fcngelte schon um sein Herz.", "tokens": ["z\u00fcn\u00b7gel\u00b7te", "schon", "um", "sein", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.48": {"line.1": {"text": "Wehe, wie es zuckend gl\u00fchte \u2013!", "tokens": ["We\u00b7he", ",", "wie", "es", "zu\u00b7ckend", "gl\u00fch\u00b7te", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "VVPP", "VVFIN", "$(", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbwehe, weh! mein ", "tokens": ["\u00bb", "we\u00b7he", ",", "weh", "!", "mein"], "token_info": ["punct", "word", "punct", "word", "punct", "word"], "pos": ["$(", "ADJD", "$,", "PTKVZ", "$.", "PPOSAT"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Herr, Du bist ein Gott der Juden \u2013", "tokens": ["Herr", ",", "Du", "bist", "ein", "Gott", "der", "Ju\u00b7den", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Herr, und bist der Christen Gott!", "tokens": ["Herr", ",", "und", "bist", "der", "Chris\u00b7ten", "Gott", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "Herr, o Herr! du siehst das Herz nur!", "tokens": ["Herr", ",", "o", "Herr", "!", "du", "siehst", "das", "Herz", "nur", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "FM", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr, sie ist mein einzig Kleinod!", "tokens": ["Herr", ",", "sie", "ist", "mein", "ein\u00b7zig", "Klei\u00b7nod", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "PPOSAT", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Herr, mein Gott, verzeihe mir \u2013", "tokens": ["Herr", ",", "mein", "Gott", ",", "ver\u00b7zei\u00b7he", "mir", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Asser, h\u00f6rst du \u2013? Gott, ich sterbe!", "tokens": ["As\u00b7ser", ",", "h\u00f6rst", "du", "\u2013", "?", "Gott", ",", "ich", "ster\u00b7be", "!"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$(", "$.", "NN", "$,", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Asser \u2013 aber nicht herein hier \u2013", "tokens": ["As\u00b7ser", "\u2013", "a\u00b7ber", "nicht", "her\u00b7ein", "hier", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADV", "PTKNEG", "PTKVZ", "ADV", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Asser, \u2013 rufe mir \u2013 mein Kind!\u00ab", "tokens": ["As\u00b7ser", ",", "\u2013", "ru\u00b7fe", "mir", "\u2013", "mein", "Kind", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "$(", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Vor dem hohen Prunkgemache", "tokens": ["Vor", "dem", "ho\u00b7hen", "Prunk\u00b7ge\u00b7ma\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lehnte bleich in wirrem Br\u00fcten,", "tokens": ["lehn\u00b7te", "bleich", "in", "wir\u00b7rem", "Br\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ihres Vaters Tod belauschend,", "tokens": ["ih\u00b7res", "Va\u00b7ters", "Tod", "be\u00b7lau\u00b7schend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Margarita Sulamith.", "tokens": ["Mar\u00b7ga\u00b7ri\u00b7ta", "Su\u00b7la\u00b7mith", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}}, "stanza.52": {"line.1": {"text": "War er nicht sehr alt, ihr Vater?!", "tokens": ["War", "er", "nicht", "sehr", "alt", ",", "ihr", "Va\u00b7ter", "?!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "war sie jung nicht und voll Liebe?!", "tokens": ["war", "sie", "jung", "nicht", "und", "voll", "Lie\u00b7be", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "PTKNEG", "KON", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "war er nicht ein starrer Jude?!", "tokens": ["war", "er", "nicht", "ein", "star\u00b7rer", "Ju\u00b7de", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "war Alvaro nicht ihr Gl\u00fcck?!", "tokens": ["war", "Al\u00b7va\u00b7ro", "nicht", "ihr", "Gl\u00fcck", "?!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Aber Jammer, wie er st\u00f6hnte!", "tokens": ["A\u00b7ber", "Jam\u00b7mer", ",", "wie", "er", "st\u00f6hn\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wie er wimmernd drinnen raste,", "tokens": ["wie", "er", "wim\u00b7mernd", "drin\u00b7nen", "ras\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wie er auf den Knieen rutschte,", "tokens": ["wie", "er", "auf", "den", "Kni\u00b7e\u00b7en", "rutschte", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "r\u00f6chelte zu seinem Gott!", "tokens": ["r\u00f6\u00b7chel\u00b7te", "zu", "sei\u00b7nem", "Gott", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Da: was war das? Heil'ge Jungfrau,", "tokens": ["Da", ":", "was", "war", "das", "?", "Heil'\u00b7ge", "Jung\u00b7frau", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$.", "PWS", "VAFIN", "PDS", "$.", "ADJA", "NN", "$,"], "meter": "--+-+---", "measure": "anapaest.init"}, "line.2": {"text": "Da, wer schrie das: Ja, Jehovah,", "tokens": ["Da", ",", "wer", "schrie", "das", ":", "Ja", ",", "Je\u00b7ho\u00b7vah", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VVFIN", "PDS", "$.", "PTKANT", "$,", "NE", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du bist auch der Christen Gott \u2013!", "tokens": ["Du", "bist", "auch", "der", "Chris\u00b7ten", "Gott", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$(", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.55": {"line.1": {"text": "O mein Heiland, o mein Vater!", "tokens": ["O", "mein", "Hei\u00b7land", ",", "o", "mein", "Va\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "FM", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jesus, \u2013 jetzt ein Winseln \u2013 Kratzen:", "tokens": ["Je\u00b7sus", ",", "\u2013", "jetzt", "ein", "Win\u00b7seln", "\u2013", "Krat\u00b7zen", ":"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "$(", "ADV", "ART", "NN", "$(", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbsulamith, du ", "tokens": ["\u00bb", "su\u00b7la\u00b7mith", ",", "du"], "token_info": ["punct", "word", "punct", "word"], "pos": ["$(", "NE", "$,", "PPER"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Sulamith, vernimmst du mich?", "tokens": ["Su\u00b7la\u00b7mith", ",", "ver\u00b7nimmst", "du", "mich", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Sulamith, die Christen kommen!", "tokens": ["Su\u00b7la\u00b7mith", ",", "die", "Chris\u00b7ten", "kom\u00b7men", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sulamith, mein schutzlos T\u00e4ubchen,", "tokens": ["Su\u00b7la\u00b7mith", ",", "mein", "schutz\u00b7los", "T\u00e4ub\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sulamith \u2013 geh, \u2013 la\u00df dich \u2013 taufen!", "tokens": ["Su\u00b7la\u00b7mith", "\u2013", "geh", ",", "\u2013", "la\u00df", "dich", "\u2013", "tau\u00b7fen", "!"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "VVFIN", "$,", "$(", "VVIMP", "PPER", "$(", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Herr, verzeih mir! r\u00e4che nicht!\u00ab", "tokens": ["Herr", ",", "ver\u00b7zeih", "mir", "!", "r\u00e4\u00b7che", "nicht", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "$.", "VVFIN", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Da ri\u00df taumelnd sie die Th\u00fcr auf,", "tokens": ["Da", "ri\u00df", "tau\u00b7melnd", "sie", "die", "Th\u00fcr", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "fort den alten Diener stie\u00df sie,", "tokens": ["fort", "den", "al\u00b7ten", "Die\u00b7ner", "stie\u00df", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "st\u00fcrzte nieder zu dem Juden:", "tokens": ["st\u00fcrz\u00b7te", "nie\u00b7der", "zu", "dem", "Ju\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00bbvater, Vater, o vergieb!", "tokens": ["\u00bb", "va\u00b7ter", ",", "Va\u00b7ter", ",", "o", "ver\u00b7gieb", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NN", "$,", "NN", "$,", "FM", "FM", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Wenn ich's gleich nicht wert bin, Vater!", "tokens": ["Wenn", "ich's", "gleich", "nicht", "wert", "bin", ",", "Va\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach, er bat so! mein Alvaro!", "tokens": ["Ach", ",", "er", "bat", "so", "!", "mein", "Al\u00b7va\u00b7ro", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "ADV", "$.", "PPOSAT", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Christin ", "tokens": ["Chris\u00b7tin"], "token_info": ["word"], "pos": ["NE"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Vater, da\u00df ich dich betrog!\u00ab", "tokens": ["Va\u00b7ter", ",", "da\u00df", "ich", "dich", "be\u00b7trog", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.59": {"line.1": {"text": "oh Jehovah, Deine Rache! \u2013", "tokens": ["oh", "Je\u00b7ho\u00b7vah", ",", "Dei\u00b7ne", "Ra\u00b7che", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbvater, Vater, meine Thr\u00e4nen!", "tokens": ["\u00bb", "va\u00b7ter", ",", "Va\u00b7ter", ",", "mei\u00b7ne", "Thr\u00e4\u00b7nen", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NN", "$,", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "meine Reue \u2013! ", "tokens": ["mei\u00b7ne", "Reu\u00b7e", "\u2013", "!"], "token_info": ["word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$(", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.60": {"line.1": {"text": "Und in hei\u00dfer Kindesliebe", "tokens": ["Und", "in", "hei\u00b7\u00dfer", "Kin\u00b7des\u00b7lie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weinend mit dem Vater rang sie,", "tokens": ["wei\u00b7nend", "mit", "dem", "Va\u00b7ter", "rang", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "k\u00fc\u00dfte die geballten F\u00e4uste,", "tokens": ["k\u00fc\u00df\u00b7te", "die", "ge\u00b7ball\u00b7ten", "F\u00e4us\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "k\u00fc\u00dfte den verzerrten Mund, \u2013", "tokens": ["k\u00fc\u00df\u00b7te", "den", "ver\u00b7zerr\u00b7ten", "Mund", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.61": {"line.1": {"text": "bis die pestzerfre\u00dfnen Finger", "tokens": ["bis", "die", "pest\u00b7zer\u00b7fre\u00df\u00b7nen", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "segnend um ihr Haupt sich legten,", "tokens": ["seg\u00b7nend", "um", "ihr", "Haupt", "sich", "leg\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "bis er mit den blauen Lippen", "tokens": ["bis", "er", "mit", "den", "blau\u00b7en", "Lip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Segen hauchte \u2013 und verschied.", "tokens": ["Se\u00b7gen", "hauch\u00b7te", "\u2013", "und", "ver\u00b7schied", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$(", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Zu den F\u00fc\u00dfen Don Alvaro's", "tokens": ["Zu", "den", "F\u00fc\u00b7\u00dfen", "Don", "Al\u00b7va\u00b7ro's"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE", "NE"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "kr\u00fcmmte sich der alte Asser:", "tokens": ["kr\u00fcmm\u00b7te", "sich", "der", "al\u00b7te", "As\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbherr! das \u2013 M\u00e4dchen, das Euch liebet,", "tokens": ["\u00bb", "herr", "!", "das", "\u2013", "M\u00e4d\u00b7chen", ",", "das", "Euch", "lie\u00b7bet", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$.", "ART", "$(", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.63": {"line.1": {"text": "Herr, mein Heiland, Margarita \u2013!", "tokens": ["Herr", ",", "mein", "Hei\u00b7land", ",", "Mar\u00b7ga\u00b7ri\u00b7ta", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "NE", "$(", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Doch er schlug nicht; stieren Auges", "tokens": ["Doch", "er", "schlug", "nicht", ";", "stie\u00b7ren", "Au\u00b7ges"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$.", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "schwankte er dem Alten nach.", "tokens": ["schwank\u00b7te", "er", "dem", "Al\u00b7ten", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Dreimal kam und ging die Sonne.", "tokens": ["Drei\u00b7mal", "kam", "und", "ging", "die", "Son\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An dem Lager Margaritas", "tokens": ["An", "dem", "La\u00b7ger", "Mar\u00b7ga\u00b7ri\u00b7tas"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NE"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "kniete schlaflos Don Alvaro.", "tokens": ["knie\u00b7te", "schlaf\u00b7los", "Don", "Al\u00b7va\u00b7ro", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NE", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Dreimal kam und ging der Mond.", "tokens": ["Drei\u00b7mal", "kam", "und", "ging", "der", "Mond", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Wild mit seinem Gotte rang er", "tokens": ["Wild", "mit", "sei\u00b7nem", "Got\u00b7te", "rang", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "um das eine eine Leben,", "tokens": ["um", "das", "ei\u00b7ne", "ei\u00b7ne", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "das er liebte \u2013; furchtbar scholl sein", "tokens": ["das", "er", "lieb\u00b7te", "\u2013", ";", "furcht\u00b7bar", "scholl", "sein"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PRELS", "PPER", "VVFIN", "$(", "$.", "ADJD", "ADJD", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Beten durch die \u00f6de Nacht.", "tokens": ["Be\u00b7ten", "durch", "die", "\u00f6\u00b7de", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.66": {"line.1": {"text": "\u00bboh, Alvaro, bete nichtmehr!", "tokens": ["\u00bb", "oh", ",", "Al\u00b7va\u00b7ro", ",", "be\u00b7te", "nicht\u00b7mehr", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "$,", "NE", "$,", "VVFIN", "PIS", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "k\u00fcsse, k\u00fcsse mich! ich sterbe.\u00ab", "tokens": ["k\u00fcs\u00b7se", ",", "k\u00fcs\u00b7se", "mich", "!", "ich", "ster\u00b7be", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, ", "tokens": ["Nein", ","], "token_info": ["word", "punct"], "pos": ["PTKANT", "$,"], "meter": "+", "measure": "single.up"}}, "stanza.67": {"line.1": {"text": "Fluch ihm, ewig Fluch dem Juden,", "tokens": ["Fluch", "ihm", ",", "e\u00b7wig", "Fluch", "dem", "Ju\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADJD", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der im Tod sein Kind noch w\u00fcrgte!", "tokens": ["der", "im", "Tod", "sein", "Kind", "noch", "w\u00fcrg\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbweh, Alvaro! weh, was thust du!", "tokens": ["\u00bb", "weh", ",", "Al\u00b7va\u00b7ro", "!", "weh", ",", "was", "thust", "du", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NE", "$.", "PTKVZ", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "wehe \u2013!\u00ab und ihr Auge brach.", "tokens": ["we\u00b7he", "\u2013", "!", "\u00ab", "und", "ihr", "Au\u00b7ge", "brach", "."], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "$.", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Tot \u2013? Da fuhr der Wahnsinn in ihn.", "tokens": ["Tot", "\u2013", "?", "Da", "fuhr", "der", "Wahn\u00b7sinn", "in", "ihn", "."], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "$.", "ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbtot? nein, nein, du lebst! du lebst ja!\u00ab", "tokens": ["\u00bb", "tot", "?", "nein", ",", "nein", ",", "du", "lebst", "!", "du", "lebst", "ja", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$.", "PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Br\u00fcnstig ihren Leib umschlo\u00df er,", "tokens": ["Br\u00fcns\u00b7tig", "ih\u00b7ren", "Leib", "um\u00b7schlo\u00df", "er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "pre\u00dfte zu ihr sich ins Bett:", "tokens": ["pre\u00df\u00b7te", "zu", "ihr", "sich", "ins", "Bett", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "\u00bbmargarita, meine Sehnsucht,", "tokens": ["\u00bb", "mar\u00b7ga\u00b7ri\u00b7ta", ",", "mei\u00b7ne", "Sehn\u00b7sucht", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "h\u00f6rst du? k\u00fcsse mich! o sprich doch!", "tokens": ["h\u00f6rst", "du", "?", "k\u00fcs\u00b7se", "mich", "!", "o", "sprich", "doch", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "VVFIN", "PPER", "$.", "FM", "ADV", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "k\u00fcsse, k\u00fcsse mich zu Tode!", "tokens": ["k\u00fcs\u00b7se", ",", "k\u00fcs\u00b7se", "mich", "zu", "To\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Sieben Tage, sieben N\u00e4chte", "tokens": ["Sie\u00b7ben", "Ta\u00b7ge", ",", "sie\u00b7ben", "N\u00e4ch\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hielt den Leichnam er umklammert,", "tokens": ["hielt", "den", "Leich\u00b7nam", "er", "um\u00b7klam\u00b7mert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "kos'te die verwesten Glieder,", "tokens": ["kos'\u00b7te", "die", "ver\u00b7wes\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kos'te den zerfallnen Mund.", "tokens": ["kos'\u00b7te", "den", "zer\u00b7fall\u00b7nen", "Mund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Sieben Tage, sieben N\u00e4chte", "tokens": ["Sie\u00b7ben", "Ta\u00b7ge", ",", "sie\u00b7ben", "N\u00e4ch\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["CARD", "NN", "$,", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "schrie er tobend seinen Gott an,", "tokens": ["schrie", "er", "to\u00b7bend", "sei\u00b7nen", "Gott", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "ihn zu t\u00f6ten; \u2013 grausig gellte", "tokens": ["ihn", "zu", "t\u00f6\u00b7ten", ";", "\u2013", "grau\u00b7sig", "gell\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PPER", "PTKZU", "VVINF", "$.", "$(", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "durch Sevilla sein Gebet.", "tokens": ["durch", "Se\u00b7vil\u00b7la", "sein", "Ge\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "Und dazwischen, gr\u00e4\u00dflich l\u00e4sternd,", "tokens": ["Und", "da\u00b7zwi\u00b7schen", ",", "gr\u00e4\u00df\u00b7lich", "l\u00e4s\u00b7ternd", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "ADJD", "ADJD", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "fluchte er dem toten Juden, \u2013", "tokens": ["fluch\u00b7te", "er", "dem", "to\u00b7ten", "Ju\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "selbst die frechen Leichenknechte", "tokens": ["selbst", "die", "fre\u00b7chen", "Lei\u00b7chen\u00b7knech\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "flohn entsetzt vor seiner Wut.", "tokens": ["flohn", "ent\u00b7setzt", "vor", "sei\u00b7ner", "Wut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.73": {"line.1": {"text": "Bis am achten Tage endlich", "tokens": ["Bis", "am", "ach\u00b7ten", "Ta\u00b7ge", "end\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPRART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "aus der Stadt die Pest ges\u00e4ttigt", "tokens": ["aus", "der", "Stadt", "die", "Pest", "ge\u00b7s\u00e4t\u00b7tigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "mit dem Tod vondannen keuchte.", "tokens": ["mit", "dem", "Tod", "von\u00b7dan\u00b7nen", "keuch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber ", "tokens": ["A\u00b7ber"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.74": {"line.1": {"text": "Vor dem Kruzifix, gesundet,", "tokens": ["Vor", "dem", "Kru\u00b7zi\u00b7fix", ",", "ge\u00b7sun\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lag zum Ersten Mal er wieder;", "tokens": ["lag", "zum", "Ers\u00b7ten", "Mal", "er", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "ADJA", "NN", "PPER", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "aus dem d\u00fcstern Auge lohte", "tokens": ["aus", "dem", "d\u00fcs\u00b7tern", "Au\u00b7ge", "loh\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "himmelauf ein stummer Schwur.", "tokens": ["him\u00b7me\u00b7lauf", "ein", "stum\u00b7mer", "Schwur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "Zehen volle Monde trug er", "tokens": ["Ze\u00b7hen", "vol\u00b7le", "Mon\u00b7de", "trug", "er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NE", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "dann die Martern schwerster Bu\u00dfe,", "tokens": ["dann", "die", "Mar\u00b7tern", "schwers\u00b7ter", "Bu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "gei\u00dfelte die welken Glieder,", "tokens": ["gei\u00b7\u00dfel\u00b7te", "die", "wel\u00b7ken", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "fastete den matten Leib.", "tokens": ["fas\u00b7te\u00b7te", "den", "mat\u00b7ten", "Leib", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.76": {"line.1": {"text": "Bis es m\u00e4hlich stille wurde,", "tokens": ["Bis", "es", "m\u00e4h\u00b7lich", "stil\u00b7le", "wur\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "das verbuhlte wilde Herze;", "tokens": ["das", "ver\u00b7buhl\u00b7te", "wil\u00b7de", "Her\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dann sein Gut den Armen gab er,", "tokens": ["dann", "sein", "Gut", "den", "Ar\u00b7men", "gab", "er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und ging hin und ward ein M\u00f6nch.", "tokens": ["und", "ging", "hin", "und", "ward", "ein", "M\u00f6nch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VAFIN", "ART", "NN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.77": {"line.1": {"text": "Und zog aus auf alle Gassen,", "tokens": ["Und", "zog", "aus", "auf", "al\u00b7le", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "APPR", "PIAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "predigte auf allen Pl\u00e4tzen,", "tokens": ["pre\u00b7dig\u00b7te", "auf", "al\u00b7len", "Pl\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.3": {"text": "predigte in allen Kirchen,", "tokens": ["pre\u00b7dig\u00b7te", "in", "al\u00b7len", "Kir\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "predigte vor jedem Haus, \u2013", "tokens": ["pre\u00b7dig\u00b7te", "vor", "je\u00b7dem", "Haus", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "$,", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.78": {"line.1": {"text": "bis es durch ganz Spanien brauste:", "tokens": ["bis", "es", "durch", "ganz", "Spa\u00b7ni\u00b7en", "braus\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "NE", "VVFIN", "$."], "meter": "+--++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Dr\u00fcckt sie tot, die Judenpestbrut,", "tokens": ["Dr\u00fcckt", "sie", "tot", ",", "die", "Ju\u00b7den\u00b7pest\u00b7brut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "die den Heiland uns gekreuzigt,", "tokens": ["die", "den", "Hei\u00b7land", "uns", "ge\u00b7kreu\u00b7zigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die ein Fluch der Christenheit!", "tokens": ["die", "ein", "Fluch", "der", "Chris\u00b7ten\u00b7heit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "bis die F\u00fcrsten in Gesetzen", "tokens": ["bis", "die", "F\u00fcrs\u00b7ten", "in", "Ge\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "vor den Juden Spanien sch\u00fctzten,", "tokens": ["vor", "den", "Ju\u00b7den", "Spa\u00b7ni\u00b7en", "sch\u00fctz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "--+----+-", "measure": "anapaest.init"}, "line.3": {"text": "bis ihr Blut zum Himmel rauchte,", "tokens": ["bis", "ihr", "Blut", "zum", "Him\u00b7mel", "rauch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bis sie wichen aus dem Reich.", "tokens": ["bis", "sie", "wi\u00b7chen", "aus", "dem", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "Und so reinigte vom Aussatz", "tokens": ["Und", "so", "rei\u00b7nig\u00b7te", "vom", "Aus\u00b7satz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "seine holde Heimaterde,", "tokens": ["sei\u00b7ne", "hol\u00b7de", "Hei\u00b7ma\u00b7ter\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ward ein Retter seines Volkes \u2013", "tokens": ["ward", "ein", "Ret\u00b7ter", "sei\u00b7nes", "Vol\u00b7kes", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.81": {"line.1": {"text": "ward ", "tokens": ["ward"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Spaniens gro\u00dfer Judenhasser,", "tokens": ["Spa\u00b7ni\u00b7ens", "gro\u00b7\u00dfer", "Ju\u00b7den\u00b7has\u00b7ser", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Spaniens erster Judenw\u00fcrger:", "tokens": ["Spa\u00b7ni\u00b7ens", "ers\u00b7ter", "Ju\u00b7den\u00b7w\u00fcr\u00b7ger", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Don Alvaro de Niebla.", "tokens": ["Don", "Al\u00b7va\u00b7ro", "de", "Nieb\u00b7la", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}