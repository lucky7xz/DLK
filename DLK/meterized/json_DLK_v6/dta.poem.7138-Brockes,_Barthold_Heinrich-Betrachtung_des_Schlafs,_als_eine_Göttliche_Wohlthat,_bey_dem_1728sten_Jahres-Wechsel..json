{"dta.poem.7138": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Betrachtung des Schlafs,  \n als  \n eine G\u00f6ttliche Wohlthat,  \n bey dem 1728sten Jahres-Wechsel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1730", "urn": "urn:nbn:de:kobv:b4-20087-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es l\u00e4sset uns, von ihrem leichten Wesen,", "tokens": ["Es", "l\u00e4s\u00b7set", "uns", ",", "von", "ih\u00b7rem", "leich\u00b7ten", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "St. Augustin ein artig Gleichni\u00df lesen:", "tokens": ["St.", "Au\u00b7gus\u00b7tin", "ein", "ar\u00b7tig", "Gleich\u00b7ni\u00df", "le\u00b7sen", ":"], "token_info": ["abbreviation", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie, wenn man einen Wurm, den, wegen vieler F\u00fcsse", "tokens": ["Wie", ",", "wenn", "man", "ei\u00b7nen", "Wurm", ",", "den", ",", "we\u00b7gen", "vie\u00b7ler", "F\u00fcs\u00b7se"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PIS", "ART", "NN", "$,", "ART", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man Tausend-f\u00fcsser nennt,", "tokens": ["Man", "Tau\u00b7sen\u00b7df\u00fcs\u00b7ser", "nennt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "In kleine St\u00fccke theilet;", "tokens": ["In", "klei\u00b7ne", "St\u00fc\u00b7cke", "thei\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Es recht verwunderlich, wie alles l\u00e4ufft und eilet,", "tokens": ["Es", "recht", "ver\u00b7wun\u00b7der\u00b7lich", ",", "wie", "al\u00b7les", "l\u00e4ufft", "und", "ei\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "$,", "PWAV", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie jedes St\u00fcckgen flieht, bald hier, bald dahin rennt,", "tokens": ["Wie", "je\u00b7des", "St\u00fcck\u00b7gen", "flieht", ",", "bald", "hier", ",", "bald", "da\u00b7hin", "rennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVFIN", "$,", "ADV", "ADV", "$,", "ADV", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und doch nicht wei\u00df, wohin. Denn alle sind", "tokens": ["Und", "doch", "nicht", "wei\u00df", ",", "wo\u00b7hin", ".", "Denn", "al\u00b7le", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "VVFIN", "$,", "PWAV", "$.", "KON", "PIS", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Bis auf das erste St\u00fcck, woran der Kopff noch, blind.", "tokens": ["Bis", "auf", "das", "ers\u00b7te", "St\u00fcck", ",", "wo\u00b7ran", "der", "Kopff", "noch", ",", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$,", "PWAV", "ART", "NN", "ADV", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Indessen lauffen sie best\u00e4ndig hin und her,", "tokens": ["In\u00b7des\u00b7sen", "lauf\u00b7fen", "sie", "be\u00b7st\u00e4n\u00b7dig", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Als ob ein jedes St\u00fcck ein gantzes W\u00fcrmgen w\u00e4r:", "tokens": ["Als", "ob", "ein", "je\u00b7des", "St\u00fcck", "ein", "gant\u00b7zes", "W\u00fcrm\u00b7gen", "w\u00e4r", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "PIAT", "NN", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Dort rennet eins auf sechs, hier eins auf sieben F\u00fcssen,", "tokens": ["Dort", "ren\u00b7net", "eins", "auf", "sechs", ",", "hier", "eins", "auf", "sie\u00b7ben", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "CARD", "$,", "ADV", "PIS", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie sie der Zufall gab, und tr\u00e4gt am andern Ort", "tokens": ["Wie", "sie", "der", "Zu\u00b7fall", "gab", ",", "und", "tr\u00e4gt", "am", "an\u00b7dern", "Ort"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Das St\u00fcckgen Leib und Seel, so sein ist, mit sich fort;", "tokens": ["Das", "St\u00fcck\u00b7gen", "Leib", "und", "Seel", ",", "so", "sein", "ist", ",", "mit", "sich", "fort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$,", "ADV", "VAINF", "VAFIN", "$,", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man siehet, sie sich fliehn, sich stossen und mit Hauffen", "tokens": ["Man", "sie\u00b7het", ",", "sie", "sich", "fliehn", ",", "sich", "stos\u00b7sen", "und", "mit", "Hauf\u00b7fen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "PPER", "PRF", "VVINF", "$,", "PRF", "VVINF", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bald an-bald von einander lauffen.", "tokens": ["Bald", "an\u00b7bald", "von", "ein\u00b7an\u00b7der", "lauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Nicht anders gehet es in unsrer Ruh", "tokens": ["Nicht", "an\u00b7ders", "ge\u00b7het", "es", "in", "uns\u00b7rer", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Mit unsern Tr\u00e4umen zu:", "tokens": ["Mit", "un\u00b7sern", "Tr\u00e4u\u00b7men", "zu", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Scheint einer etwan erst manierlich, ordentlich,", "tokens": ["Scheint", "ei\u00b7ner", "et\u00b7wan", "erst", "ma\u00b7nier\u00b7lich", ",", "or\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "ADV", "ADJD", "$,", "ADJD", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.20": {"text": "Gleich bricht er und zertheilet sich", "tokens": ["Gleich", "bricht", "er", "und", "zer\u00b7thei\u00b7let", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "In tausend Grillen, welche fliegen,", "tokens": ["In", "tau\u00b7send", "Gril\u00b7len", ",", "wel\u00b7che", "flie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "PRELS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Sich sencken, sich begegnen, lauffen, stehn,", "tokens": ["Sich", "sen\u00b7cken", ",", "sich", "be\u00b7geg\u00b7nen", ",", "lauf\u00b7fen", ",", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "VVINF", "$,", "PRF", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Verworren durch einander gehn,", "tokens": ["Ver\u00b7wor\u00b7ren", "durch", "ein\u00b7an\u00b7der", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "So, da\u00df nicht zwo geschickt sich wiederum zu f\u00fcgen.", "tokens": ["So", ",", "da\u00df", "nicht", "zwo", "ge\u00b7schickt", "sich", "wie\u00b7de\u00b7rum", "zu", "f\u00fc\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PTKNEG", "CARD", "VVPP", "PRF", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}