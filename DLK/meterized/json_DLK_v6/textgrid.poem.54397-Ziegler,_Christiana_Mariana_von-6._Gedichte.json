{"textgrid.poem.54397": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "6. Gedichte", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist wohl ausgemacht, und mehr als Sonnenklar,", "tokens": ["Es", "ist", "wohl", "aus\u00b7ge\u00b7macht", ",", "und", "mehr", "als", "Son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KON", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sch\u00f6pfer habe nicht ein solches Menschenpaar", "tokens": ["Der", "Sch\u00f6p\u00b7fer", "ha\u00b7be", "nicht", "ein", "sol\u00b7ches", "Men\u00b7schen\u00b7paar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In den so weiten Kreis der grossen Welt gesetzet,", "tokens": ["In", "den", "so", "wei\u00b7ten", "Kreis", "der", "gros\u00b7sen", "Welt", "ge\u00b7set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das sich an allem zwar, doch nicht an sich ergetzet.", "tokens": ["Das", "sich", "an", "al\u00b7lem", "zwar", ",", "doch", "nicht", "an", "sich", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "APPR", "PIS", "ADV", "$,", "ADV", "PTKNEG", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.5": {"text": "Und vor einander sich aus blossem Eigensinn", "tokens": ["Und", "vor", "ein\u00b7an\u00b7der", "sich", "aus", "blos\u00b7sem", "Ei\u00b7gen\u00b7sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PRF", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Verstecket und verkriecht. Sein Zweck gieng wohl dahin,", "tokens": ["Ver\u00b7ste\u00b7cket", "und", "ver\u00b7kriecht", ".", "Sein", "Zweck", "gieng", "wohl", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "ADV", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie sollten beyderseits genaue Freundschaft schliessen,", "tokens": ["Sie", "soll\u00b7ten", "bey\u00b7der\u00b7seits", "ge\u00b7nau\u00b7e", "Freund\u00b7schaft", "schlies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und durch den Umgang sich die Zeit daselbst vers\u00fcssen.", "tokens": ["Und", "durch", "den", "Um\u00b7gang", "sich", "die", "Zeit", "da\u00b7selbst", "ver\u00b7s\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "ART", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Mensch der stets das Licht nach Art der Igel scheut;", "tokens": ["Ein", "Mensch", "der", "stets", "das", "Licht", "nach", "Art", "der", "I\u00b7gel", "scheut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADV", "ART", "NN", "APPR", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den d\u00fcstern Mauren nur sein m\u00fcrrisch Antlitz weyht,", "tokens": ["Den", "d\u00fcs\u00b7tern", "Mau\u00b7ren", "nur", "sein", "m\u00fcr\u00b7risch", "Ant\u00b7litz", "weyht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PPOSAT", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vor allen Menschen flieht, allein und einsam bleibet,", "tokens": ["Vor", "al\u00b7len", "Men\u00b7schen", "flieht", ",", "al\u00b7lein", "und", "ein\u00b7sam", "blei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,", "ADV", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Verdient nicht, da\u00df man ihn zu rechten Menschen schreibet.", "tokens": ["Ver\u00b7di\u00b7ent", "nicht", ",", "da\u00df", "man", "ihn", "zu", "rech\u00b7ten", "Men\u00b7schen", "schrei\u00b7bet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "PIS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Was tr\u00e4gt es in der That uns nicht f\u00fcr Vortheil ein,", "tokens": ["Was", "tr\u00e4gt", "es", "in", "der", "That", "uns", "nicht", "f\u00fcr", "Vor\u00b7theil", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "PPER", "PTKNEG", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wofern man t\u00e4glich kann um seines gleichen seyn?", "tokens": ["Wo\u00b7fern", "man", "t\u00e4g\u00b7lich", "kann", "um", "sei\u00b7nes", "glei\u00b7chen", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VMFIN", "APPR", "PPOSAT", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Umgang ist es blo\u00df, der uns bey unserm Leben", "tokens": ["Der", "Um\u00b7gang", "ist", "es", "blo\u00df", ",", "der", "uns", "bey", "un\u00b7serm", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Diejenige Gestalt und Bildung weis zu geben", "tokens": ["Die\u00b7je\u00b7ni\u00b7ge", "Ge\u00b7stalt", "und", "Bil\u00b7dung", "weis", "zu", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "KON", "NN", "PTKVZ", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die uns zu Menschen macht. Ein toller Sauertopf,", "tokens": ["Die", "uns", "zu", "Men\u00b7schen", "macht", ".", "Ein", "tol\u00b7ler", "Sau\u00b7er\u00b7topf", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVFIN", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der vor den Menschen l\u00e4uft, und seinen schweren Kopf", "tokens": ["Der", "vor", "den", "Men\u00b7schen", "l\u00e4uft", ",", "und", "sei\u00b7nen", "schwe\u00b7ren", "Kopf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "In d\u00fcstre Winkel steckt, mu\u00df, wie wir merklich sp\u00fcren,", "tokens": ["In", "d\u00fcst\u00b7re", "Win\u00b7kel", "steckt", ",", "mu\u00df", ",", "wie", "wir", "merk\u00b7lich", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "VMFIN", "$,", "PWAV", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Von unvern\u00fcnftigen, ja gar von wilden Thieren,", "tokens": ["Von", "un\u00b7ver\u00b7n\u00fcnf\u00b7ti\u00b7gen", ",", "ja", "gar", "von", "wil\u00b7den", "Thie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als die das Tagelicht, woran man sie gebracht,", "tokens": ["Als", "die", "das", "Ta\u00b7ge\u00b7licht", ",", "wo\u00b7ran", "man", "sie", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und unser Zuspruch auch fast halb vern\u00fcnftig macht,", "tokens": ["Und", "un\u00b7ser", "Zu\u00b7spruch", "auch", "fast", "halb", "ver\u00b7n\u00fcnf\u00b7tig", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sich recht besch\u00e4met sehn. Was wird es alles n\u00fctzen,", "tokens": ["Sich", "recht", "be\u00b7sch\u00e4\u00b7met", "sehn", ".", "Was", "wird", "es", "al\u00b7les", "n\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVFIN", "VVINF", "$.", "PWS", "VAFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Wenn wir aus Cedernholz uns Tisch und St\u00fchle schnitzen,", "tokens": ["Wenn", "wir", "aus", "Ce\u00b7dern\u00b7holz", "uns", "Tisch", "und", "St\u00fch\u00b7le", "schnit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Dem Gaumen wohl und sanft durch Leckerspeisen thun,", "tokens": ["Dem", "Gau\u00b7men", "wohl", "und", "sanft", "durch", "Le\u00b7cker\u00b7spei\u00b7sen", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KON", "ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Auf einer Lagerstatt von weichen Federn ruhn,", "tokens": ["Auf", "ei\u00b7ner", "La\u00b7ger\u00b7statt", "von", "wei\u00b7chen", "Fe\u00b7dern", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Und um und neben uns nichts lebendes erblicken,", "tokens": ["Und", "um", "und", "ne\u00b7ben", "uns", "nichts", "le\u00b7ben\u00b7des", "er\u00b7bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "KON", "APPR", "PPER", "PIS", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Das in der Einsamkeit kann unsre Seel erquicken?", "tokens": ["Das", "in", "der", "Ein\u00b7sam\u00b7keit", "kann", "uns\u00b7re", "Seel", "er\u00b7qui\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Jedoch wenn man zugleich bey aller Herrlichkeit,", "tokens": ["Je\u00b7doch", "wenn", "man", "zu\u00b7gleich", "bey", "al\u00b7ler", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Die die Gesellschaft wirkt, den Umgang unsrer Zeit", "tokens": ["Die", "die", "Ge\u00b7sell\u00b7schaft", "wirkt", ",", "den", "Um\u00b7gang", "uns\u00b7rer", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "$,", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "So wie man soll bedenkt, so mu\u00df man auch bekennen,", "tokens": ["So", "wie", "man", "soll", "be\u00b7denkt", ",", "so", "mu\u00df", "man", "auch", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIS", "VMFIN", "VVFIN", "$,", "ADV", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Er sey nur leider mehr als halb verderbt zu nennen.", "tokens": ["Er", "sey", "nur", "lei\u00b7der", "mehr", "als", "halb", "ver\u00b7derbt", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIAT", "KOKOM", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die \u00e4chte Redlichkeit und alte Deutsche Treu,", "tokens": ["Die", "\u00e4ch\u00b7te", "Red\u00b7lich\u00b7keit", "und", "al\u00b7te", "Deut\u00b7sche", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Des Menschen sch\u00f6nster Schmuck, der Tugend Conterfey,", "tokens": ["Des", "Men\u00b7schen", "sch\u00f6ns\u00b7ter", "Schmuck", ",", "der", "Tu\u00b7gend", "Con\u00b7ter\u00b7fey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Die vormals sonder Trug und auch in allen St\u00fccken,", "tokens": ["Die", "vor\u00b7mals", "son\u00b7der", "Trug", "und", "auch", "in", "al\u00b7len", "St\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "KON", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Die B\u00fcrger erster Welt einander liessen blicken,", "tokens": ["Die", "B\u00fcr\u00b7ger", "ers\u00b7ter", "Welt", "ein\u00b7an\u00b7der", "lies\u00b7sen", "bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Hat sich ganz unvermerkt von unserm Erdenkreis,", "tokens": ["Hat", "sich", "ganz", "un\u00b7ver\u00b7merkt", "von", "un\u00b7serm", "Er\u00b7den\u00b7kreis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Nunmehr hinweg gemacht, so, da\u00df man gar nicht weis,", "tokens": ["Nun\u00b7mehr", "hin\u00b7weg", "ge\u00b7macht", ",", "so", ",", "da\u00df", "man", "gar", "nicht", "weis", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APZR", "VVPP", "$,", "ADV", "$,", "KOUS", "PIS", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Wo sie nach ihrer Flucht, die man gar bald entdecket,", "tokens": ["Wo", "sie", "nach", "ih\u00b7rer", "Flucht", ",", "die", "man", "gar", "bald", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "$,", "PRELS", "PIS", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Aus Zorn und Ungeduld sich habe hin verstecket.", "tokens": ["Aus", "Zorn", "und", "Un\u00b7ge\u00b7duld", "sich", "ha\u00b7be", "hin", "ver\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PRF", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Die Welt, betracht ich sie genau, kommt wahrlich mir", "tokens": ["Die", "Welt", ",", "be\u00b7tracht", "ich", "sie", "ge\u00b7nau", ",", "kommt", "wahr\u00b7lich", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "PPER", "ADJD", "$,", "VVFIN", "ADV", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Als ein ohn Unterla\u00df besetzter Schauplatz f\u00fcr,", "tokens": ["Als", "ein", "ohn", "Un\u00b7ter\u00b7la\u00df", "be\u00b7setz\u00b7ter", "Schau\u00b7platz", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "APPR", "NN", "ADJA", "NN", "APPR", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wo man unzehlige sieht aus den Scenen kommen,", "tokens": ["Wo", "man", "un\u00b7zeh\u00b7li\u00b7ge", "sieht", "aus", "den", "Sce\u00b7nen", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJA", "VVFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.44": {"text": "Die dies und jenes sich zu spielen vorgenommen.", "tokens": ["Die", "dies", "und", "je\u00b7nes", "sich", "zu", "spie\u00b7len", "vor\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "KON", "PDS", "PRF", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Sie stellen, ists nicht wahr? oft die Personen vor,", "tokens": ["Sie", "stel\u00b7len", ",", "ists", "nicht", "wahr", "?", "oft", "die", "Per\u00b7so\u00b7nen", "vor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VAFIN", "PTKNEG", "PTKVZ", "$.", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Die sie doch gar nicht sind; ob gleich so Aug als Ohr,", "tokens": ["Die", "sie", "doch", "gar", "nicht", "sind", ";", "ob", "gleich", "so", "Aug", "als", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "PTKNEG", "VAFIN", "$.", "KOUS", "ADV", "ADV", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Durch angenommen Schein, durch Minen und Gederben,", "tokens": ["Durch", "an\u00b7ge\u00b7nom\u00b7men", "Schein", ",", "durch", "Mi\u00b7nen", "und", "Ge\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Tracht, Ansehn und Gestalt dabey betrogen werden.", "tokens": ["Tracht", ",", "An\u00b7sehn", "und", "Ge\u00b7stalt", "da\u00b7bey", "be\u00b7tro\u00b7gen", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "PAV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Die Meisten kleiden sich in falsche Masken ein,", "tokens": ["Die", "Meis\u00b7ten", "klei\u00b7den", "sich", "in", "fal\u00b7sche", "Mas\u00b7ken", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "So oft der Umgang uns befiehlt um sie zu seyn;", "tokens": ["So", "oft", "der", "Um\u00b7gang", "uns", "be\u00b7fiehlt", "um", "sie", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PPER", "VVFIN", "APPR", "PPER", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Kein K\u00fcnstler ist geschickt in seinen sch\u00f6nsten Bildern", "tokens": ["Kein", "K\u00fcnst\u00b7ler", "ist", "ge\u00b7schickt", "in", "sei\u00b7nen", "sch\u00f6ns\u00b7ten", "Bil\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Ein holder Angesicht, als ihres, abzuschildern.", "tokens": ["Ein", "hol\u00b7der", "An\u00b7ge\u00b7sicht", ",", "als", "ih\u00b7res", ",", "ab\u00b7zu\u00b7schil\u00b7dern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "PPOSAT", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ihr Augenpaar, aus dem man sanfte Blicke liest,", "tokens": ["Ihr", "Au\u00b7gen\u00b7paar", ",", "aus", "dem", "man", "sanf\u00b7te", "Bli\u00b7cke", "liest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "APPR", "PRELS", "PIS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Hat sich die Freundlichkeit zum Eigenthum erkiest;", "tokens": ["Hat", "sich", "die", "Freund\u00b7lich\u00b7keit", "zum", "Ei\u00b7gen\u00b7thum", "er\u00b7kiest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Die Stirn ist aufgekl\u00e4rt, erf\u00fcllt mit heitern Stralen,", "tokens": ["Die", "Stirn", "ist", "auf\u00b7ge\u00b7kl\u00e4rt", ",", "er\u00b7f\u00fcllt", "mit", "hei\u00b7tern", "Stra\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Die Wangen mu\u00df vorher die Unschuld \u00fcbermalen;", "tokens": ["Die", "Wan\u00b7gen", "mu\u00df", "vor\u00b7her", "die", "Un\u00b7schuld", "\u00fc\u00b7berm\u00b7a\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Ein \u00e4hnlich Gegenbild der wahren Redlichkeit", "tokens": ["Ein", "\u00e4hn\u00b7lich", "Ge\u00b7gen\u00b7bild", "der", "wah\u00b7ren", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Zeigt sich in jedem Zug; ja es kommt gar so weit", "tokens": ["Zeigt", "sich", "in", "je\u00b7dem", "Zug", ";", "ja", "es", "kommt", "gar", "so", "weit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN", "$.", "ADV", "PPER", "VVFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.59": {"text": "Da\u00df wenn man nach dem Schein das Urtheil f\u00e4llen wollte,", "tokens": ["Da\u00df", "wenn", "man", "nach", "dem", "Schein", "das", "Ur\u00b7theil", "f\u00e4l\u00b7len", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PIS", "APPR", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Man sie f\u00fcr Gratien, f\u00fcr Engel halten sollte.", "tokens": ["Man", "sie", "f\u00fcr", "Gra\u00b7ti\u00b7en", ",", "f\u00fcr", "En\u00b7gel", "hal\u00b7ten", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "APPR", "NE", "$,", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Wie s\u00fcsse klingt der Ton der leisen Sprache nicht?", "tokens": ["Wie", "s\u00fcs\u00b7se", "klingt", "der", "Ton", "der", "lei\u00b7sen", "Spra\u00b7che", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Wie glatt ist jedes Wort, so oft man mit uns spricht?", "tokens": ["Wie", "glatt", "ist", "je\u00b7des", "Wort", ",", "so", "oft", "man", "mit", "uns", "spricht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PIAT", "NN", "$,", "ADV", "ADV", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Das Herze scheint nicht mehr an ihrer Brust zu kleben,", "tokens": ["Das", "Her\u00b7ze", "scheint", "nicht", "mehr", "an", "ih\u00b7rer", "Brust", "zu", "kle\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Man siehet selbiges auf Zung und Lippen schweben.", "tokens": ["Man", "sie\u00b7het", "sel\u00b7bi\u00b7ges", "auf", "Zung", "und", "Lip\u00b7pen", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.65": {"text": "Sie theilen uns sogleich die eine Helfte mit,", "tokens": ["Sie", "thei\u00b7len", "uns", "sog\u00b7leich", "die", "ei\u00b7ne", "Helf\u00b7te", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wenn man das erstemal nur in ihr Zimmer tritt.", "tokens": ["Wenn", "man", "das", "ers\u00b7te\u00b7mal", "nur", "in", "ihr", "Zim\u00b7mer", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Doch wenn wir denen nun die Freunde wollen heissen,", "tokens": ["Doch", "wenn", "wir", "de\u00b7nen", "nun", "die", "Freun\u00b7de", "wol\u00b7len", "heis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "ADV", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Die Larve so sie schm\u00fcckt, von dem Gesichte reissen;", "tokens": ["Die", "Lar\u00b7ve", "so", "sie", "schm\u00fcckt", ",", "von", "dem", "Ge\u00b7sich\u00b7te", "reis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "VVFIN", "$,", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Da sp\u00fchrt man allererst, da\u00df Glanz und falscher Schein", "tokens": ["Da", "sp\u00fchrt", "man", "al\u00b7le\u00b7rerst", ",", "da\u00df", "Glanz", "und", "fal\u00b7scher", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$,", "KOUS", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Dem faulen Holz bey Nacht ganz \u00e4hnlich wolle seyn;", "tokens": ["Dem", "fau\u00b7len", "Holz", "bey", "Nacht", "ganz", "\u00e4hn\u00b7lich", "wol\u00b7le", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "ADV", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Denn ob sich gleich der Schwan mit weissen Federn decket,", "tokens": ["Denn", "ob", "sich", "gleich", "der", "Schwan", "mit", "weis\u00b7sen", "Fe\u00b7dern", "de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PRF", "ADV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "So weis man dennoch wohl was unter ihm verstecket.", "tokens": ["So", "weis", "man", "den\u00b7noch", "wohl", "was", "un\u00b7ter", "ihm", "ver\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PIS", "ADV", "ADV", "PWS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Je freundlicher man uns im Umgang unterh\u00e4lt,", "tokens": ["Je", "freund\u00b7li\u00b7cher", "man", "uns", "im", "Um\u00b7gang", "un\u00b7ter\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Je t\u00fcckischer wird uns ganz heimlich nachgestellt.", "tokens": ["Je", "t\u00fc\u00b7cki\u00b7scher", "wird", "uns", "ganz", "heim\u00b7lich", "nach\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.75": {"text": "Sie l\u00e4cheln jeden an, da doch inde\u00df mit Haufen,", "tokens": ["Sie", "l\u00e4\u00b7cheln", "je\u00b7den", "an", ",", "da", "doch", "in\u00b7de\u00df", "mit", "Hau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PTKVZ", "$,", "KOUS", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Die bittre Galle will vor Unmuth \u00fcberlaufen.", "tokens": ["Die", "bitt\u00b7re", "Gal\u00b7le", "will", "vor", "Un\u00b7muth", "\u00fc\u00b7berl\u00b7au\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Ihr H\u00e4ndedr\u00fccken ist nur eitel Heucheley,", "tokens": ["Ihr", "H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken", "ist", "nur", "ei\u00b7tel", "Heu\u00b7che\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Die Worte klingen sch\u00f6n, das Herze flucht dabey.", "tokens": ["Die", "Wor\u00b7te", "klin\u00b7gen", "sch\u00f6n", ",", "das", "Her\u00b7ze", "flucht", "da\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "PDS", "VVFIN", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Aus dem was sie gesagt, so sch\u00f6n es auch gewesen,", "tokens": ["Aus", "dem", "was", "sie", "ge\u00b7sagt", ",", "so", "sch\u00f6n", "es", "auch", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PWS", "PPER", "VVPP", "$,", "ADV", "ADJD", "PPER", "ADV", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Mu\u00df man das Gegentheil, will man nicht fehlen, lesen.", "tokens": ["Mu\u00df", "man", "das", "Ge\u00b7gen\u00b7theil", ",", "will", "man", "nicht", "feh\u00b7len", ",", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PIS", "ART", "NN", "$,", "VMFIN", "PIS", "PTKNEG", "VVINF", "$,", "VVINF", "$."], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.81": {"text": "Die sch\u00f6nste Wissenschaft nennt man oft leeren Dunst,", "tokens": ["Die", "sch\u00f6ns\u00b7te", "Wis\u00b7sen\u00b7schaft", "nennt", "man", "oft", "lee\u00b7ren", "Dunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.82": {"text": "Nach Art der tollen Welt. Doch die Verstellungskunst", "tokens": ["Nach", "Art", "der", "tol\u00b7len", "Welt", ".", "Doch", "die", "Ver\u00b7stel\u00b7lungs\u00b7kunst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Die heisse nur ein Werk der allergr\u00f6sten Weisen;", "tokens": ["Die", "heis\u00b7se", "nur", "ein", "Werk", "der", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "Wei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Ein jeder will sich hier als einen Meister preisen.", "tokens": ["Ein", "je\u00b7der", "will", "sich", "hier", "als", "ei\u00b7nen", "Meis\u00b7ter", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "PRF", "ADV", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "So h\u00e4\u00dflich und verf\u00e4lscht trifft itzo jedermann", "tokens": ["So", "h\u00e4\u00df\u00b7lich", "und", "ver\u00b7f\u00e4lscht", "trifft", "it\u00b7zo", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVFIN", "ADV", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Die Menschen \u00fcberall in ihrem Umgang an;", "tokens": ["Die", "Men\u00b7schen", "\u00fc\u00b7be\u00b7rall", "in", "ih\u00b7rem", "Um\u00b7gang", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Soll dieses manchem nicht gerechten Anla\u00df geben,", "tokens": ["Soll", "die\u00b7ses", "man\u00b7chem", "nicht", "ge\u00b7rech\u00b7ten", "An\u00b7la\u00df", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "NN", "PTKNEG", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "An seinem Hause stets, den Schnecken gleich, zu kleben?", "tokens": ["An", "sei\u00b7nem", "Hau\u00b7se", "stets", ",", "den", "Schne\u00b7cken", "gleich", ",", "zu", "kle\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "$,", "ART", "NN", "ADV", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Nein; dies reicht noch nicht zu, des Tageslicht zu fliehn,", "tokens": ["Nein", ";", "dies", "reicht", "noch", "nicht", "zu", ",", "des", "Ta\u00b7ges\u00b7licht", "zu", "fliehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PDS", "VVFIN", "ADV", "PTKNEG", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.90": {"text": "Und der Gesellschaft sich deswegen zu entziehn;", "tokens": ["Und", "der", "Ge\u00b7sell\u00b7schaft", "sich", "des\u00b7we\u00b7gen", "zu", "ent\u00b7ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PRF", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wie selten w\u00fcrde der mit Menschen sprechen k\u00f6nnen,", "tokens": ["Wie", "sel\u00b7ten", "w\u00fcr\u00b7de", "der", "mit", "Men\u00b7schen", "spre\u00b7chen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "APPR", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Der wahren Freunden nur den Zuspruch wollte g\u00f6nnen?", "tokens": ["Der", "wah\u00b7ren", "Freun\u00b7den", "nur", "den", "Zu\u00b7spruch", "woll\u00b7te", "g\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Wie man in W\u00e4lder schreyt; so ruft es wieder nach,", "tokens": ["Wie", "man", "in", "W\u00e4l\u00b7der", "schreyt", ";", "so", "ruft", "es", "wie\u00b7der", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Schwatzt dir ein Heuchler vor, sag auch, was dieser sprach,", "tokens": ["Schwatzt", "dir", "ein", "Heuch\u00b7ler", "vor", ",", "sag", "auch", ",", "was", "die\u00b7ser", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "VVFIN", "ADV", "$,", "PWS", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Man mu\u00df des andern List mit Gegenlist ber\u00fccken,", "tokens": ["Man", "mu\u00df", "des", "an\u00b7dern", "List", "mit", "Ge\u00b7gen\u00b7list", "be\u00b7r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und, wenn sich jener neigt, sich zehnmal tiefer b\u00fccken.", "tokens": ["Und", ",", "wenn", "sich", "je\u00b7ner", "neigt", ",", "sich", "zehn\u00b7mal", "tie\u00b7fer", "b\u00fc\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PRF", "PDS", "VVFIN", "$,", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Ein Freund, wo Herz und Mund von gleicher G\u00fcte zeugt,", "tokens": ["Ein", "Freund", ",", "wo", "Herz", "und", "Mund", "von", "glei\u00b7cher", "G\u00fc\u00b7te", "zeugt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Verdienet, da\u00df man ihm sein Lob auch nicht verschweigt;", "tokens": ["Ver\u00b7die\u00b7net", ",", "da\u00df", "man", "ihm", "sein", "Lob", "auch", "nicht", "ver\u00b7schweigt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "PPER", "PPOSAT", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Doch wo die Heucheley die Zunge sucht zu lenken,", "tokens": ["Doch", "wo", "die", "Heu\u00b7che\u00b7ley", "die", "Zun\u00b7ge", "sucht", "zu", "len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Da mu\u00df man wiederum auf solche Sprache denken.", "tokens": ["Da", "mu\u00df", "man", "wie\u00b7de\u00b7rum", "auf", "sol\u00b7che", "Spra\u00b7che", "den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}