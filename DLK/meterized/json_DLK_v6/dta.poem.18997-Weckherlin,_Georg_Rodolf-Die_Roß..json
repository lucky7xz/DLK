{"dta.poem.18997": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Die Ro\u00df.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Kom/ Myrta/ der Lieb wohn vnd wohnung/", "tokens": ["Kom", "/", "Myr\u00b7ta", "/", "der", "Lieb", "wohn", "vnd", "woh\u00b7nung", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NE", "$(", "ART", "NN", "VVFIN", "KON", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Der Sch\u00f6nheit pracht/ der Tugent Cron/", "tokens": ["Der", "Sch\u00f6n\u00b7heit", "pracht", "/", "der", "Tu\u00b7gent", "Cron", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "ART", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnlangst meiner trew werther wohn/", "tokens": ["Vn\u00b7langst", "mei\u00b7ner", "trew", "wert\u00b7her", "wohn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Jetz meiner wehrten trew belohnung:", "tokens": ["Jetz", "mei\u00b7ner", "wehr\u00b7ten", "trew", "be\u00b7loh\u00b7nung", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "VVFIN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kom/ Myrta/ dises fr\u00fclings ruhm/", "tokens": ["Kom", "/", "Myr\u00b7ta", "/", "di\u00b7ses", "fr\u00fc\u00b7lings", "ruhm", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "NE", "$(", "PDAT", "ADJA", "NN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Vnd aller blumen sch\u00f6nste blum/", "tokens": ["Vnd", "al\u00b7ler", "blu\u00b7men", "sch\u00f6ns\u00b7te", "blum", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dich zu mir auff das gr\u00fcn zus\u00f6tzen;", "tokens": ["Dich", "zu", "mir", "auff", "das", "gr\u00fcn", "zu\u00b7s\u00f6t\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "APPR", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df du dich in der blumen zier/", "tokens": ["Da\u00df", "du", "dich", "in", "der", "blu\u00b7men", "zier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df Ich der blumen zier in dir", "tokens": ["Da\u00df", "Ich", "der", "blu\u00b7men", "zier", "in", "dir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Besehend/ wir Vns beed erg\u00f6tzen.", "tokens": ["Be\u00b7se\u00b7hend", "/", "wir", "Vns", "beed", "er\u00b7g\u00f6t\u00b7zen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Weil Amor nu allein zu gegen/", "tokens": ["Weil", "A\u00b7mor", "nu", "al\u00b7lein", "zu", "ge\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ADV", "PTKZU", "APPR", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der stehts durch deine augen Mich/", "tokens": ["Der", "stehts", "durch", "dei\u00b7ne", "au\u00b7gen", "Mich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der stehts durch meine augen Dich", "tokens": ["Der", "stehts", "durch", "mei\u00b7ne", "au\u00b7gen", "Dich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan allein halten vnd bew\u00f6gen:", "tokens": ["Kan", "al\u00b7lein", "hal\u00b7ten", "vnd", "be\u00b7w\u00f6\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So will Ich/ ja so kan ich nicht", "tokens": ["So", "will", "Ich", "/", "ja", "so", "kan", "ich", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "$(", "ADV", "ADV", "VMFIN", "PPER", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wendend mein/ fliehen dein gesicht;", "tokens": ["Wen\u00b7dend", "mein", "/", "flie\u00b7hen", "dein", "ge\u00b7sicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "$(", "VVFIN", "PPOSAT", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Sondern der bl\u00fcmelein zu ehren/", "tokens": ["Son\u00b7dern", "der", "bl\u00fc\u00b7me\u00b7lein", "zu", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Die als stern dises Element", "tokens": ["Die", "als", "stern", "di\u00b7ses", "E\u00b7le\u00b7ment"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KOKOM", "VVFIN", "PDAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Machen ein blumen-firmament/", "tokens": ["Ma\u00b7chen", "ein", "blu\u00b7men\u00b7fir\u00b7ma\u00b7ment", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Begehr ich dein gesang zu h\u00f6ren.", "tokens": ["Be\u00b7gehr", "ich", "dein", "ge\u00b7sang", "zu", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Solt ich zu singen mich bem\u00fchen", "tokens": ["Solt", "ich", "zu", "sin\u00b7gen", "mich", "be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKZU", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von andern/ dan den bl\u00fcmelein/", "tokens": ["Von", "an\u00b7dern", "/", "dan", "den", "bl\u00fc\u00b7me\u00b7lein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$(", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die vnder deiner augen schein", "tokens": ["Die", "vn\u00b7der", "dei\u00b7ner", "au\u00b7gen", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In dir frisch/ vnverwelcklich bl\u00fchen?", "tokens": ["In", "dir", "frisch", "/", "vn\u00b7ver\u00b7welck\u00b7lich", "bl\u00fc\u00b7hen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "$(", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die gilg vnd rosen/ die gewi\u00df", "tokens": ["Die", "gilg", "vnd", "ro\u00b7sen", "/", "die", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "KON", "VVINF", "$(", "ART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein wahres blumen paradi\u00df", "tokens": ["Ein", "wah\u00b7res", "blu\u00b7men", "pa\u00b7ra\u00b7di\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auff deinem leib vns mahlen/ zwingen", "tokens": ["Auff", "dei\u00b7nem", "leib", "vns", "mah\u00b7len", "/", "zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVINF", "$(", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mich auch/ der Natur gunst vnd kunst", "tokens": ["Mich", "auch", "/", "der", "Na\u00b7tur", "gunst", "vnd", "kunst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "$(", "ART", "NN", "NN", "KON", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "In dir betrachtend/ nichts mehr sunst", "tokens": ["In", "dir", "be\u00b7trach\u00b7tend", "/", "nichts", "mehr", "sunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "VVPP", "$(", "PIS", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dan dich der blumen ruhm zu singen.", "tokens": ["Dan", "dich", "der", "blu\u00b7men", "ruhm", "zu", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Vnn\u00f6htig/ Lieb/ ist dein liebkosen/", "tokens": ["Vnn\u00f6h\u00b7tig", "/", "Lieb", "/", "ist", "dein", "lieb\u00b7ko\u00b7sen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "NN", "$(", "VAFIN", "PPOSAT", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil wir nu vnder einem joch;", "tokens": ["Weil", "wir", "nu", "vn\u00b7der", "ei\u00b7nem", "joch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wan ich dir dan lieb/ so sing doch", "tokens": ["Wan", "ich", "dir", "dan", "lieb", "/", "so", "sing", "doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADJD", "$(", "ADV", "VVFIN", "ADV"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.4": {"text": "Jetzund von diesen s\u00fcssen Rosen:", "tokens": ["Je\u00b7tzund", "von", "die\u00b7sen", "s\u00fcs\u00b7sen", "Ro\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sing von den Rosen/ edler schatz/", "tokens": ["Sing", "von", "den", "Ro\u00b7sen", "/", "ed\u00b7ler", "schatz", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$(", "ADJA", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Vnd ich will dich mit einem schmatz", "tokens": ["Vnd", "ich", "will", "dich", "mit", "ei\u00b7nem", "schmatz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "(vnd nicht zuvor) reichlich belohnen:", "tokens": ["(", "vnd", "nicht", "zu\u00b7vor", ")", "reich\u00b7lich", "be\u00b7loh\u00b7nen", ":"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "PTKNEG", "ADV", "$(", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vnd wie lieb du mir auch/ solt du", "tokens": ["Vnd", "wie", "lieb", "du", "mir", "auch", "/", "solt", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "ADJD", "PPER", "PPER", "ADV", "$(", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "(enthaltend deine hand in ruh)", "tokens": ["(", "ent\u00b7hal\u00b7tend", "dei\u00b7ne", "hand", "in", "ruh", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "PPOSAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Jhn vor zu haben/ mir verschonen.", "tokens": ["Jhn", "vor", "zu", "ha\u00b7ben", "/", "mir", "ver\u00b7scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PTKZU", "VAINF", "$(", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "O Rosen/ die kein frost kan t\u00f6dten/", "tokens": ["O", "Ro\u00b7sen", "/", "die", "kein", "frost", "kan", "t\u00f6d\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "ART", "PIAT", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch welche ich widrumb gesund;", "tokens": ["Durch", "wel\u00b7che", "ich", "wid\u00b7rumb", "ge\u00b7sund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Rosen/ die den sch\u00f6nsten mund", "tokens": ["O", "Ro\u00b7sen", "/", "die", "den", "sch\u00f6ns\u00b7ten", "mund"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$(", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wangen/ liebf\u00e4rblich/ ber\u00f6hten;", "tokens": ["Vnd", "wan\u00b7gen", "/", "lieb\u00b7f\u00e4rb\u00b7lich", "/", "be\u00b7r\u00f6h\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$(", "ADJD", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Euch Rosenmund/ vnd allein Euch", "tokens": ["Euch", "Ro\u00b7sen\u00b7mund", "/", "vnd", "al\u00b7lein", "Euch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "NN", "$(", "KON", "ADV", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geb\u00fchret in der Sch\u00f6nheit Reich", "tokens": ["Ge\u00b7b\u00fch\u00b7ret", "in", "der", "Sch\u00f6n\u00b7heit", "Reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Auff der Lieb thron befelch zugeben:", "tokens": ["Auff", "der", "Lieb", "thron", "be\u00b7felch", "zu\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "ADJD", "VVINF", "$."], "meter": "+-++-+-+-", "measure": "unknown.measure.penta"}, "line.8": {"text": "Mir aber Euch/ die jhr gleichlo\u00df/", "tokens": ["Mir", "a\u00b7ber", "Euch", "/", "die", "jhr", "gleic\u00b7hlo\u00df", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vnd aller Rosen sch\u00f6nste Ro\u00df/", "tokens": ["Vnd", "al\u00b7ler", "Ro\u00b7sen", "sch\u00f6ns\u00b7te", "Ro\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dienstlich gehorsamend zu leben.", "tokens": ["Dienst\u00b7lich", "ge\u00b7hor\u00b7sa\u00b7mend", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Wie in dem Himmel/ so auff erden", "tokens": ["Wie", "in", "dem", "Him\u00b7mel", "/", "so", "auff", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "$(", "ADV", "APPR", "NN"], "meter": "+--+--+--", "measure": "dactylic.tri"}, "line.2": {"text": "Kan nichts (dan deine herrlichkeit)", "tokens": ["Kan", "nichts", "(", "dan", "dei\u00b7ne", "herr\u00b7lich\u00b7keit", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "$(", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An sch\u00f6nheit vnd an s\u00fcssigkeit", "tokens": ["An", "sch\u00f6n\u00b7heit", "vnd", "an", "s\u00fcs\u00b7sig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Rosen gleich gefunden werden:", "tokens": ["Der", "Ro\u00b7sen", "gleich", "ge\u00b7fun\u00b7den", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Daher dan/ wan die Fr\u00fclings zeit", "tokens": ["Da\u00b7her", "dan", "/", "wan", "die", "Fr\u00fc\u00b7lings", "zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "$(", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die welt zu der Lieb streit vnd beut", "tokens": ["Die", "welt", "zu", "der", "Lieb", "streit", "vnd", "beut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "NN", "KON", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "Behertzet/ vnd das erdreich zieret/", "tokens": ["Be\u00b7hert\u00b7zet", "/", "vnd", "das", "er\u00b7dreich", "zie\u00b7ret", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KON", "ART", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Erhebet sich die Ro\u00df mit wohn/", "tokens": ["Er\u00b7he\u00b7bet", "sich", "die", "Ro\u00df", "mit", "wohn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Allda/ weil Sie der blumen Cron/", "tokens": ["All\u00b7da", "/", "weil", "Sie", "der", "blu\u00b7men", "Cron", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sie vnder allen triumfieret.", "tokens": ["Sie", "vn\u00b7der", "al\u00b7len", "tri\u00b7um\u00b7fie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Die Morgenr\u00f6htin/ new-geboren/", "tokens": ["Die", "Mor\u00b7gen\u00b7r\u00f6h\u00b7tin", "/", "ne\u00b7wge\u00b7bo\u00b7ren", "/"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$(", "ADJA", "$("], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Der Sonnen kind/ von thr\u00e4nen nassz/", "tokens": ["Der", "Son\u00b7nen", "kind", "/", "von", "thr\u00e4\u00b7nen", "nassz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch schmollend/ bald durch lieb vnd hassz", "tokens": ["Doch", "schmol\u00b7lend", "/", "bald", "durch", "lieb", "vnd", "hassz"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$(", "ADV", "APPR", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von jhr verfolget vnd verloren/", "tokens": ["Von", "jhr", "ver\u00b7fol\u00b7get", "vnd", "ver\u00b7lo\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "KON", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wan sie sich will mit h\u00f6chstem pracht", "tokens": ["Wan", "sie", "sich", "will", "mit", "h\u00f6chs\u00b7tem", "pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "VMFIN", "APPR", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Vnd in der newest sch\u00f6nsten tracht", "tokens": ["Vnd", "in", "der", "ne\u00b7west", "sch\u00f6ns\u00b7ten", "tracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Beklaiden/ mu\u00df sie alle morgen/", "tokens": ["Be\u00b7klai\u00b7den", "/", "mu\u00df", "sie", "al\u00b7le", "mor\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VMFIN", "PPER", "PIS", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sich zu besch\u00f6nen/ zwar ohn scham/", "tokens": ["Sich", "zu", "be\u00b7sch\u00f6\u00b7nen", "/", "zwar", "ohn", "scham", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$(", "ADV", "APPR", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Au\u00df dem lieblichen Rosen-kram", "tokens": ["Au\u00df", "dem", "lieb\u00b7li\u00b7chen", "Ro\u00b7sen\u00b7kram"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "All jhre anstreich-f\u00e4rblein borgen.", "tokens": ["All", "jhre", "an\u00b7streich\u00b7f\u00e4rb\u00b7lein", "bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Dan fr\u00fch al\u00dfbald wir nur erwachen", "tokens": ["Dan", "fr\u00fch", "al\u00df\u00b7bald", "wir", "nur", "er\u00b7wa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOUS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd f\u00fcr dem jungen Sonnenglantz", "tokens": ["Vnd", "f\u00fcr", "dem", "jun\u00b7gen", "Son\u00b7nen\u00b7glantz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die stern vns jhren schein vnd dantz", "tokens": ["Die", "stern", "vns", "jhren", "schein", "vnd", "dantz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Verbergen/ vnd vnsichtbar machen:", "tokens": ["Ver\u00b7ber\u00b7gen", "/", "vnd", "vn\u00b7sicht\u00b7bar", "ma\u00b7chen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "ADJD", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Mit lieblichen pomp vnd geruch", "tokens": ["Mit", "lieb\u00b7li\u00b7chen", "pomp", "vnd", "ge\u00b7ruch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Gleichsam des Blumen-tags anbruch/", "tokens": ["Gleich\u00b7sam", "des", "Blu\u00b7men\u00b7tags", "an\u00b7bruch", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Die Ro\u00df/ den Lufft vnd vns erg\u00f6tzet/", "tokens": ["Die", "Ro\u00df", "/", "den", "Lufft", "vnd", "vns", "er\u00b7g\u00f6t\u00b7zet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "KON", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Vnd vns des himmels frische ehr/", "tokens": ["Vnd", "vns", "des", "him\u00b7mels", "fri\u00b7sche", "ehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als ob sie himmelisch selbs wer/", "tokens": ["Als", "ob", "sie", "him\u00b7me\u00b7lisch", "selbs", "wer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "ADV", "PWS", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit wunder f\u00fcr die augen s\u00f6tzet.", "tokens": ["Mit", "wun\u00b7der", "f\u00fcr", "die", "au\u00b7gen", "s\u00f6t\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der rohte morgen mu\u00df verblaichen", "tokens": ["Der", "roh\u00b7te", "mor\u00b7gen", "mu\u00df", "ver\u00b7blai\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADV", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "(verliebet) ab der Rosen Zier/", "tokens": ["(", "ver\u00b7lie\u00b7bet", ")", "ab", "der", "Ro\u00b7sen", "Zier", "/"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd k\u00fcssend lasset er auff jhr", "tokens": ["Vnd", "k\u00fcs\u00b7send", "las\u00b7set", "er", "auff", "jhr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der s\u00fcssen k\u00fcssen feuchte Zaichen:", "tokens": ["Der", "s\u00fcs\u00b7sen", "k\u00fcs\u00b7sen", "feuch\u00b7te", "Zai\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Verbuhlet auch der Lufft vnd Wind/", "tokens": ["Ver\u00b7buh\u00b7let", "auch", "der", "Lufft", "vnd", "Wind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Durch lieb ", "tokens": ["Durch", "lieb"], "token_info": ["word", "word"], "pos": ["APPR", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Mit jhr offt jhre k\u00fcssz vermischen/", "tokens": ["Mit", "jhr", "offt", "jhre", "k\u00fcssz", "ver\u00b7mi\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Vnd (frech) sich selbs vnd andre auch", "tokens": ["Vnd", "(", "frech", ")", "sich", "selbs", "vnd", "and\u00b7re", "auch"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "ADJD", "$(", "PRF", "ADV", "KON", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit jhrem gleichsam s\u00fcssen rauch", "tokens": ["Mit", "jhrem", "gleich\u00b7sam", "s\u00fcs\u00b7sen", "rauch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Zu mahl erfrewen vnd erfrischen.", "tokens": ["Zu", "mahl", "er\u00b7fre\u00b7wen", "vnd", "er\u00b7fri\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Al\u00dfbald entkn\u00f6pfend Sie auffstehet", "tokens": ["Al\u00df\u00b7bald", "ent\u00b7kn\u00f6p\u00b7fend", "Sie", "auffs\u00b7te\u00b7het"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVPP", "PPER", "VVFIN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Au\u00df jhrem l\u00e4ger gr\u00fcn vnd new/", "tokens": ["Au\u00df", "jhrem", "l\u00e4\u00b7ger", "gr\u00fcn", "vnd", "new", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Al\u00dfbald Sie jmmer frisch vnd frey", "tokens": ["Al\u00df\u00b7bald", "Sie", "jm\u00b7mer", "frisch", "vnd", "frey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als eine kleine Sonn auffgehet:", "tokens": ["Als", "ei\u00b7ne", "klei\u00b7ne", "Sonn", "auff\u00b7ge\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da sihet man sie bald von zorn", "tokens": ["Da", "si\u00b7het", "man", "sie", "bald", "von", "zorn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(besch\u00fctzet zwar von manchem dorn", "tokens": ["(", "be\u00b7sch\u00fct\u00b7zet", "zwar", "von", "man\u00b7chem", "dorn"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So jhre quardy wol zu nennen)", "tokens": ["So", "jhre", "quar\u00b7dy", "wol", "zu", "nen\u00b7nen", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Warnemend da\u00df jhr/ wie dem gold", "tokens": ["War\u00b7ne\u00b7mend", "da\u00df", "jhr", "/", "wie", "dem", "gold"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "KOUS", "PPER", "$(", "KOKOM", "ART", "NN"], "meter": "----+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Schier jederman gef\u00e4hrlich hold/", "tokens": ["Schier", "je\u00b7der\u00b7man", "ge\u00b7f\u00e4hr\u00b7lich", "hold", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Schamroht vnd z\u00fcchtig gleichsam brennen.", "tokens": ["Scham\u00b7roht", "vnd", "z\u00fcch\u00b7tig", "gleich\u00b7sam", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "In jhrem vrsprung war vorzeitten", "tokens": ["In", "jhrem", "vr\u00b7sprung", "war", "vor\u00b7zeit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Ro\u00df so weissz/ da\u00df mit jhr kaum", "tokens": ["Die", "Ro\u00df", "so", "weissz", "/", "da\u00df", "mit", "jhr", "kaum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "$(", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des schnellen wassers frischer schaum", "tokens": ["Des", "schnel\u00b7len", "was\u00b7sers", "fri\u00b7scher", "schaum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch auch des Morgens frost k\u00f6nt streitten;", "tokens": ["Noch", "auch", "des", "Mor\u00b7gens", "frost", "k\u00f6nt", "streit\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADV", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Noch k\u00f6nt des silbers purer schein/", "tokens": ["Noch", "k\u00f6nt", "des", "sil\u00b7bers", "pu\u00b7rer", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Milchrohn/ noch das helfenbein/", "tokens": ["Der", "Milc\u00b7hrohn", "/", "noch", "das", "hel\u00b7fen\u00b7bein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bey jhrer weissin wol bestehen:", "tokens": ["Bey", "jhrer", "weis\u00b7sin", "wol", "be\u00b7ste\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Ja/ weisser war die s\u00fcsse Ro\u00df", "tokens": ["Ja", "/", "weis\u00b7ser", "war", "die", "s\u00fcs\u00b7se", "Ro\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "ADJD", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Dan auff der kalten erden scho\u00df", "tokens": ["Dan", "auff", "der", "kal\u00b7ten", "er\u00b7den", "scho\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der new-gefalne schnee zu sehen.", "tokens": ["Der", "ne\u00b7wge\u00b7fal\u00b7ne", "schnee", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Als aber Venus hie auff erden", "tokens": ["Als", "a\u00b7ber", "Ve\u00b7nus", "hie", "auff", "er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "ADV", "APPR", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Durch jhrer sch\u00f6nheit gegenwart/", "tokens": ["Durch", "jhrer", "sch\u00f6n\u00b7heit", "ge\u00b7gen\u00b7wart", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit jhren br\u00fcstlein zart vnd hart/", "tokens": ["Mit", "jhren", "br\u00fcst\u00b7lein", "zart", "vnd", "hart", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit hertz-entz\u00fcndenden geberden/", "tokens": ["Mit", "hertz\u00b7ent\u00b7z\u00fcn\u00b7den\u00b7den", "ge\u00b7ber\u00b7den", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mit seel-ergr\u00fcndend s\u00fcsser gunst/", "tokens": ["Mit", "seel\u00b7er\u00b7gr\u00fcn\u00b7dend", "s\u00fcs\u00b7ser", "gunst", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit gaist-verblindend gailer kunst/", "tokens": ["Mit", "gaist\u00b7ver\u00b7blin\u00b7dend", "gai\u00b7ler", "kunst", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mit k\u00fcssen Nectar-gleich befeuchtet/", "tokens": ["Mit", "k\u00fcs\u00b7sen", "Nec\u00b7ta\u00b7rgleich", "be\u00b7feuch\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit jhrer augen liebem glantz/", "tokens": ["Mit", "jhrer", "au\u00b7gen", "lie\u00b7bem", "glantz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Mit fr\u00f6lich-m\u00fcdend-jungem dantz", "tokens": ["Mit", "fr\u00f6\u00b7lich\u00b7m\u00fc\u00b7den\u00b7djun\u00b7gem", "dantz"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das volck bereichet vnd erleuchtet:", "tokens": ["Das", "volck", "be\u00b7rei\u00b7chet", "vnd", "er\u00b7leuch\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Da sah man sich die menschen naigen/", "tokens": ["Da", "sah", "man", "sich", "die", "men\u00b7schen", "nai\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "ART", "ADJA", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vnd (lieb zu sein) auff alle wei\u00df", "tokens": ["Vnd", "(", "lieb", "zu", "sein", ")", "auff", "al\u00b7le", "wei\u00df"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$(", "ADJD", "PTKZU", "VAINF", "$(", "APPR", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich freindlich/ h\u00f6flich/ sitsam/ wey\u00df/", "tokens": ["Sich", "freind\u00b7lich", "/", "h\u00f6f\u00b7lich", "/", "sit\u00b7sam", "/", "wey\u00df", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch wacker/ statlich/ k\u00fchn erzaigen:", "tokens": ["Auch", "wa\u00b7cker", "/", "stat\u00b7lich", "/", "k\u00fchn", "er\u00b7zai\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADJD", "$(", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bald sah man dise fro au\u00df lieb/", "tokens": ["Bald", "sah", "man", "di\u00b7se", "fro", "au\u00df", "lieb", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PDAT", "NN", "APPR", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd durch lieb jene kranck vnd tr\u00fceb;", "tokens": ["Vnd", "durch", "lieb", "je\u00b7ne", "kranck", "vnd", "tr\u00fceb", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJD", "PDAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die eine sah man/ jhre schmertzen", "tokens": ["Die", "ei\u00b7ne", "sah", "man", "/", "jhre", "schmert\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PIS", "$(", "PPOSAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Beklagend/ ohn trost/ hofnung/ hail:", "tokens": ["Be\u00b7kla\u00b7gend", "/", "ohn", "trost", "/", "hof\u00b7nung", "/", "hail", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$(", "APPR", "NN", "$(", "NN", "$(", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vnd andre frisch/ kurtzweilig/ gail/", "tokens": ["Vnd", "and\u00b7re", "frisch", "/", "kurt\u00b7zwei\u00b7lig", "/", "gail", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "$(", "ADJD", "$(", "XY", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sich hertzend/ mit einander schertzen.", "tokens": ["Sich", "hert\u00b7zend", "/", "mit", "ein\u00b7an\u00b7der", "schert\u00b7zen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVPP", "$(", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}