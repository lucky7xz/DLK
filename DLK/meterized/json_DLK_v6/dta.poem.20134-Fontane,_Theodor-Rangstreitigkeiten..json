{"dta.poem.20134": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Rangstreitigkeiten.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1851", "urn": "urn:nbn:de:kobv:b4-200905191321", "language": ["de:0.99"], "booktitle": "Fontane, Theodor: Gedichte. Berlin, 1851."}, "poem": {"stanza.1": {"line.1": {"text": "In einem Lumpenkasten", "tokens": ["In", "ei\u00b7nem", "Lum\u00b7pen\u00b7kas\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War gro\u00dfe Rebellion:", "tokens": ["War", "gro\u00b7\u00dfe", "Re\u00b7bel\u00b7lion", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die feinen Lumpen hassten", "tokens": ["Die", "fei\u00b7nen", "Lum\u00b7pen", "hass\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die groben lange schon.", "tokens": ["Die", "gro\u00b7ben", "lan\u00b7ge", "schon", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Fehde th\u00e4t beginnen", "tokens": ["Die", "Feh\u00b7de", "th\u00e4t", "be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein L\u00fcmpchen von Batist,", "tokens": ["Ein", "L\u00fcmp\u00b7chen", "von", "Ba\u00b7tist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil ihm ein St\u00fcck Sacklinnen", "tokens": ["Weil", "ihm", "ein", "St\u00fcck", "Sack\u00b7lin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu nah gekommen ist.", "tokens": ["Zu", "nah", "ge\u00b7kom\u00b7men", "ist", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Sacklinnen aber freilich", "tokens": ["Sack\u00b7lin\u00b7nen", "a\u00b7ber", "frei\u00b7lich"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "War grob wie Sackleinwand,", "tokens": ["War", "grob", "wie", "Sack\u00b7lein\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und hatte wundereilig", "tokens": ["Und", "hat\u00b7te", "wun\u00b7de\u00b7rei\u00b7lig"], "token_info": ["word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Antwort bei der Hand:", "tokens": ["Die", "Ant\u00b7wort", "bei", "der", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u201evon Lady\u2019s oder Schlumpen \u2014", "tokens": ["\u201e", "von", "La\u00b7dy's", "o\u00b7der", "Schlum\u00b7pen"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NE", "KON", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u2019s thut nichts zur Sache hier,", "tokens": ["'s", "thut", "nichts", "zur", "Sa\u00b7che", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du z\u00e4hlst jetzt zu den Lumpen,", "tokens": ["Du", "z\u00e4hlst", "jetzt", "zu", "den", "Lum\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und bist nicht mehr wie wir.\u201c", "tokens": ["Und", "bist", "nicht", "mehr", "wie", "wir", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "KOKOM", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}