{"dta.poem.9190": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  \n Er thut bey der Margaris busse.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Was macht ihr noch/ ihr allerliebsten kinder/", "tokens": ["Was", "macht", "ihr", "noch", "/", "ihr", "al\u00b7ler\u00b7liebs\u00b7ten", "kin\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ach seht doch her/ da k\u00f6mmt ein armer s\u00fcnder/", "tokens": ["Ach", "seht", "doch", "her", "/", "da", "k\u00f6mmt", "ein", "ar\u00b7mer", "s\u00fcn\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "PTKVZ", "$(", "ADV", "VVFIN", "ART", "ADJA", "ADJA", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der hat unl\u00e4ngst sich gar zu viel erk\u00fchnt/", "tokens": ["Der", "hat", "un\u00b7l\u00e4ngst", "sich", "gar", "zu", "viel", "er\u00b7k\u00fchnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "PRF", "ADV", "PTKA", "PIS", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und hat wohl gar den bittern tod verdient.", "tokens": ["Und", "hat", "wohl", "gar", "den", "bit\u00b7tern", "tod", "ver\u00b7dient", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "2. Ach soll ich dran? es ist ja ewig schade/", "tokens": ["Ach", "soll", "ich", "dran", "?", "es", "ist", "ja", "e\u00b7wig", "scha\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VMFIN", "PPER", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es ist geschehn/ ich bitte um genade:", "tokens": ["Es", "ist", "ge\u00b7schehn", "/", "ich", "bit\u00b7te", "um", "ge\u00b7na\u00b7de", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPER", "ADV", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dann meine s\u00fcnd ist mir von hertzen leid/", "tokens": ["Dann", "mei\u00b7ne", "s\u00fcnd", "ist", "mir", "von", "hert\u00b7zen", "leid", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJD", "VAFIN", "PPER", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und hat mich mehr als tausend mahl gereut.", "tokens": ["Und", "hat", "mich", "mehr", "als", "tau\u00b7send", "mahl", "ge\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIAT", "KOKOM", "CARD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "3. Ach schauet doch auf mein bu\u00dffertig hertze/", "tokens": ["Ach", "schau\u00b7et", "doch", "auf", "mein", "bu\u00df\u00b7fer\u00b7tig", "hert\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ob ich sonst gleich trefflich gerne schertze/", "tokens": ["Und", "ob", "ich", "sonst", "gleich", "treff\u00b7lich", "ger\u00b7ne", "schert\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "ADJD", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So mu\u00df ich doch vor dieses mahl gestehn/", "tokens": ["So", "mu\u00df", "ich", "doch", "vor", "die\u00b7ses", "mahl", "ge\u00b7stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "PDAT", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df mir die wort aus meinem hertzen gehn.", "tokens": ["Da\u00df", "mir", "die", "wort", "aus", "mei\u00b7nem", "hert\u00b7zen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "4. Ich bin betr\u00fcbt/ und mu\u00df mich h\u00f6chlich sch\u00e4men/", "tokens": ["Ich", "bin", "be\u00b7tr\u00fcbt", "/", "und", "mu\u00df", "mich", "h\u00f6ch\u00b7lich", "sch\u00e4\u00b7men", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "KON", "VMFIN", "PRF", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und darff mir nicht die k\u00fchnheit selber nehmen/", "tokens": ["Und", "darff", "mir", "nicht", "die", "k\u00fchn\u00b7heit", "sel\u00b7ber", "neh\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df ich bey euch die s\u00fcnd abbitten kan/", "tokens": ["Da\u00df", "ich", "bey", "euch", "die", "s\u00fcnd", "ab\u00b7bit\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ART", "ADJD", "VVINF", "VMFIN", "$("], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Drum nehmt die beicht allhier geschrieben an.", "tokens": ["Drum", "nehmt", "die", "beicht", "all\u00b7hier", "ge\u00b7schrie\u00b7ben", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "ADV", "VVPP", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "5. Ich will f\u00fcrwahr ins k\u00fcnfftig fr\u00f6mmer werden/", "tokens": ["Ich", "will", "f\u00fcr\u00b7wahr", "ins", "k\u00fcnff\u00b7tig", "fr\u00f6m\u00b7mer", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPRART", "ADJD", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich will nicht mehr in reden und geberden/", "tokens": ["Ich", "will", "nicht", "mehr", "in", "re\u00b7den", "und", "ge\u00b7ber\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "APPR", "VVINF", "KON", "VVFIN", "$("], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wann ihr es seht/ ein solches unkraut seyn/", "tokens": ["Wann", "ihr", "es", "seht", "/", "ein", "sol\u00b7ches", "un\u00b7kraut", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "$(", "ART", "PIAT", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mein bart der setzt sich selbst zum b\u00fcrgen ein.", "tokens": ["Mein", "bart", "der", "setzt", "sich", "selbst", "zum", "b\u00fcr\u00b7gen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VVFIN", "PRF", "ADV", "APPRART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "6. Vergesset nur die gar zu grossen s\u00fcnden/", "tokens": ["Ver\u00b7ges\u00b7set", "nur", "die", "gar", "zu", "gros\u00b7sen", "s\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADV", "PTKA", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und lasst mich trost in der vergebung finden/", "tokens": ["Und", "lasst", "mich", "trost", "in", "der", "ver\u00b7ge\u00b7bung", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Steckt sie in sack/ schickt sie ins wasser naus/", "tokens": ["Steckt", "sie", "in", "sack", "/", "schickt", "sie", "ins", "was\u00b7ser", "naus", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "$(", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und last den zorn an mir nicht weiter au\u00df.", "tokens": ["Und", "last", "den", "zorn", "an", "mir", "nicht", "wei\u00b7ter", "au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "7. Also werd ich ein frommes b\u00fcfgen bleiben/", "tokens": ["Al\u00b7so", "werd", "ich", "ein", "from\u00b7mes", "b\u00fcf\u00b7gen", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und werde nicht mehr lose h\u00e4ndel treiben;", "tokens": ["Und", "wer\u00b7de", "nicht", "mehr", "lo\u00b7se", "h\u00e4n\u00b7del", "trei\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Je dennoch ist die s\u00fcnde gar zu gro\u00df/", "tokens": ["Je", "den\u00b7noch", "ist", "die", "s\u00fcn\u00b7de", "gar", "zu", "gro\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "ADJA", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So strafft mich bald/ und last mich k\u00fcnfftig lo\u00df.", "tokens": ["So", "strafft", "mich", "bald", "/", "und", "last", "mich", "k\u00fcnff\u00b7tig", "lo\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}