{"dta.poem.11482": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Als tit. Herr  Professor Buddeus  zu Halle  \n  d. 19 Jun. 1705 Doctor Theologi\u00e6  ernennet  \n wurde, im nahmen einiger seiner  \n haus-pursche.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Die weisheit der vernunfft ist kein geringes licht,", "tokens": ["Die", "weis\u00b7heit", "der", "ver\u00b7nunfft", "ist", "kein", "ge\u00b7rin\u00b7ges", "licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn der begierden dampff nicht ihren schein verdunckelt:", "tokens": ["Wenn", "der", "be\u00b7gier\u00b7den", "dampff", "nicht", "ih\u00b7ren", "schein", "ver\u00b7dun\u00b7ckelt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PTKNEG", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie ist dem monden gleich, der in den n\u00e4chten funckelt,", "tokens": ["Sie", "ist", "dem", "mon\u00b7den", "gleich", ",", "der", "in", "den", "n\u00e4ch\u00b7ten", "fun\u00b7ckelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn keiner wolcken dunst die strahlen unterbricht:", "tokens": ["Wenn", "kei\u00b7ner", "wol\u00b7cken", "dunst", "die", "strah\u00b7len", "un\u00b7ter\u00b7bricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VMFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie lehrt die kleine welt sich durch die gro\u00df\u2019 erbauen,", "tokens": ["Sie", "lehrt", "die", "klei\u00b7ne", "welt", "sich", "durch", "die", "gro\u00df'", "er\u00b7bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und l\u00e4\u00dft den sch\u00f6pffer uns aus den gesch\u00f6pffen schauen.", "tokens": ["Und", "l\u00e4\u00dft", "den", "sch\u00f6pf\u00b7fer", "uns", "aus", "den", "ge\u00b7sch\u00f6pf\u00b7fen", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der mensch w\u00fcrd\u2019 ohne sie kein rechter mensch nicht seyn:", "tokens": ["Der", "mensch", "w\u00fcrd'", "oh\u00b7ne", "sie", "kein", "rech\u00b7ter", "mensch", "nicht", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "PIAT", "ADJA", "NN", "PTKNEG", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie weist ihm, was er ist: Sie giebt ihm sitten-regeln:", "tokens": ["Sie", "weist", "ihm", ",", "was", "er", "ist", ":", "Sie", "giebt", "ihm", "sit\u00b7ten\u00b7re\u00b7geln", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$.", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie ist der see-compa\u00df, nachdem die klugen segeln:", "tokens": ["Sie", "ist", "der", "see\u00b7com\u00b7pa\u00df", ",", "nach\u00b7dem", "die", "klu\u00b7gen", "se\u00b7geln", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KOUS", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie zeigt die strudel an, so uns den schiffbruch dr\u00e4un:", "tokens": ["Sie", "zeigt", "die", "stru\u00b7del", "an", ",", "so", "uns", "den", "schiff\u00b7bruch", "dr\u00e4un", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ADV", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie macht den selbst-betrug, den falschen schein zu nichte,", "tokens": ["Sie", "macht", "den", "selbst\u00b7be\u00b7trug", ",", "den", "fal\u00b7schen", "schein", "zu", "nich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "APPR", "PIS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und zieht der heucheley die larve vom gesichte.", "tokens": ["Und", "zieht", "der", "heu\u00b7che\u00b7ley", "die", "lar\u00b7ve", "vom", "ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADV", "ART", "ADJA", "APPRART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Doch wie des monden glantz noch keinen tag gemacht:", "tokens": ["Doch", "wie", "des", "mon\u00b7den", "glantz", "noch", "kei\u00b7nen", "tag", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sein blasser schimmer auch mehr k\u00e4lt als feuer f\u00fchret;", "tokens": ["Sein", "blas\u00b7ser", "schim\u00b7mer", "auch", "mehr", "k\u00e4lt", "als", "feu\u00b7er", "f\u00fch\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "ADV", "VVFIN", "KOUS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So d\u00e4mpfft der weisheit licht, so die vernunfft gebiehret,", "tokens": ["So", "d\u00e4mpfft", "der", "weis\u00b7heit", "licht", ",", "so", "die", "ver\u00b7nunfft", "ge\u00b7bieh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$,", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie sehr es immer strahlt, doch noch nicht alle nacht.", "tokens": ["Wie", "sehr", "es", "im\u00b7mer", "strahlt", ",", "doch", "noch", "nicht", "al\u00b7le", "nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ADV", "VVFIN", "$,", "ADV", "ADV", "PTKNEG", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es zeiget zwar das grab, in das die seele springet;", "tokens": ["Es", "zei\u00b7get", "zwar", "das", "grab", ",", "in", "das", "die", "see\u00b7le", "sprin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Giebt aber keine krafft, die uns zum leben bringet.", "tokens": ["Giebt", "a\u00b7ber", "kei\u00b7ne", "krafft", ",", "die", "uns", "zum", "le\u00b7ben", "brin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "$,", "PRELS", "PPER", "APPRART", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die sonne bringt allein den klaren tag zur welt;", "tokens": ["Die", "son\u00b7ne", "bringt", "al\u00b7lein", "den", "kla\u00b7ren", "tag", "zur", "welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das wort des H\u00f6chsten kan allein das hertz verkl\u00e4ren.", "tokens": ["Das", "wort", "des", "H\u00f6chs\u00b7ten", "kan", "al\u00b7lein", "das", "hertz", "ver\u00b7kl\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was weder Socrates noch Seneca gew\u00e4hren,", "tokens": ["Was", "we\u00b7der", "So\u00b7cra\u00b7tes", "noch", "Se\u00b7ne\u00b7ca", "ge\u00b7w\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "KON", "NE", "ADV", "NE", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Wird hier durch GOttes mund uns pr\u00e4chtig vorgestellt.", "tokens": ["Wird", "hier", "durch", "Got\u00b7tes", "mund", "uns", "pr\u00e4ch\u00b7tig", "vor\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum d\u00f6rffen wir nicht mehr in labyrinthen schweben,", "tokens": ["Drum", "d\u00f6rf\u00b7fen", "wir", "nicht", "mehr", "in", "la\u00b7by\u00b7rin\u00b7then", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn hier ist GOttes Sohn selbst wahrheit, weg und leben.", "tokens": ["Denn", "hier", "ist", "Got\u00b7tes", "Sohn", "selbst", "wahr\u00b7heit", ",", "weg", "und", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "NN", "ADV", "ADJD", "$,", "ADV", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Du hast, gelehrter Mann! di\u00df besser ausstudirt,", "tokens": ["Du", "hast", ",", "ge\u00b7lehr\u00b7ter", "Mann", "!", "di\u00df", "bes\u00b7ser", "aus\u00b7stu\u00b7dirt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ADJA", "NN", "$.", "PDS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als unsre federn es hier abzubilden wissen:", "tokens": ["Als", "uns\u00b7re", "fe\u00b7dern", "es", "hier", "ab\u00b7zu\u00b7bil\u00b7den", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "ADV", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du hast uns die vernunfft so deutlich abgerissen,", "tokens": ["Du", "hast", "uns", "die", "ver\u00b7nunfft", "so", "deut\u00b7lich", "ab\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihrer weisheit grund so gr\u00fcndlich aufgef\u00fchrt:", "tokens": ["Und", "ih\u00b7rer", "weis\u00b7heit", "grund", "so", "gr\u00fcnd\u00b7lich", "auf\u00b7ge\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df Epictetus selbst die stoltzen segel streichet,", "tokens": ["Da\u00df", "E\u00b7pic\u00b7te\u00b7tus", "selbst", "die", "stolt\u00b7zen", "se\u00b7gel", "strei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Doch wer dich loben soll, mu\u00df ein Buddens seyn;", "tokens": ["Doch", "wer", "dich", "lo\u00b7ben", "soll", ",", "mu\u00df", "ein", "Bud\u00b7dens", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wir wissen unsern kiel nicht so geschickt zu sch\u00e4rffen:", "tokens": ["Wir", "wis\u00b7sen", "un\u00b7sern", "kiel", "nicht", "so", "ge\u00b7schickt", "zu", "sch\u00e4rf\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKNEG", "ADV", "VVPP", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die tugend kan ihr lob am besten selbst entwerffen:", "tokens": ["Die", "tu\u00b7gend", "kan", "ihr", "lob", "am", "bes\u00b7ten", "selbst", "ent\u00b7werf\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPOSAT", "NN", "PTKA", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie darff der blumen nicht, so ihr die Musen streun:", "tokens": ["Sie", "darff", "der", "blu\u00b7men", "nicht", ",", "so", "ihr", "die", "Mu\u00b7sen", "streun", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "$,", "ADV", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das schweigen ist ihr kiel: Die thateu sind die schrifften,", "tokens": ["Das", "schwei\u00b7gen", "ist", "ihr", "kiel", ":", "Die", "tha\u00b7teu", "sind", "die", "schriff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die bey der klugen welt das sch\u00f6nste denckmahl stifften.", "tokens": ["Die", "bey", "der", "klu\u00b7gen", "welt", "das", "sch\u00f6ns\u00b7te", "denck\u00b7mahl", "stiff\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "F\u00fchrt aber die vernunfft uns zu der menschheit an,", "tokens": ["F\u00fchrt", "a\u00b7ber", "die", "ver\u00b7nunfft", "uns", "zu", "der", "menschheit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So wei\u00df uns die Sophie schon h\u00f6her auszur\u00fcsten:", "tokens": ["So", "wei\u00df", "uns", "die", "So\u00b7phie", "schon", "h\u00f6\u00b7her", "aus\u00b7zu\u00b7r\u00fcs\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die himmlische Sophie, so uns zu wahren christen", "tokens": ["Die", "himm\u00b7li\u00b7sche", "So\u00b7phie", ",", "so", "uns", "zu", "wah\u00b7ren", "chris\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "PPER", "PTKZU", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch die genade macht, die alles w\u00fcrcken kan.", "tokens": ["Durch", "die", "ge\u00b7na\u00b7de", "macht", ",", "die", "al\u00b7les", "w\u00fcr\u00b7cken", "kan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn ob wir gleich zu nacht den monden nicht verfluchen;", "tokens": ["Denn", "ob", "wir", "gleich", "zu", "nacht", "den", "mon\u00b7den", "nicht", "ver\u00b7flu\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So m\u00fcssen wir den tag doch bey der sonne suchen.", "tokens": ["So", "m\u00fcs\u00b7sen", "wir", "den", "tag", "doch", "bey", "der", "son\u00b7ne", "su\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Fridriciana wei\u00df, wie du ihn hier gesucht:", "tokens": ["Frid\u00b7ri\u00b7ci\u00b7a\u00b7na", "wei\u00df", ",", "wie", "du", "ihn", "hier", "ge\u00b7sucht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PWAV", "PPER", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie du, ber\u00fchmter Mann! ihn auch vorl\u00e4ngst gefunden:", "tokens": ["Wie", "du", ",", "be\u00b7r\u00fchm\u00b7ter", "Mann", "!", "ihn", "auch", "vor\u00b7l\u00e4ngst", "ge\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "ADJA", "NN", "$.", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum hat sie dir nunmehr den ehren-krantz gewunden,", "tokens": ["Drum", "hat", "sie", "dir", "nun\u00b7mehr", "den", "eh\u00b7ren\u00b7krantz", "ge\u00b7wun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PPER", "ADV", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den du bi\u00dfher verdient. Di\u00df ist der tugend frucht.", "tokens": ["Den", "du", "bi\u00df\u00b7her", "ver\u00b7dient", ".", "Di\u00df", "ist", "der", "tu\u00b7gend", "frucht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "$.", "PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum will das Saal-Athen, so deine grosse gaben", "tokens": ["Drum", "will", "das", "Saa\u00b7lA\u00b7then", ",", "so", "dei\u00b7ne", "gros\u00b7se", "ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "ART", "NN", "$,", "ADV", "PPOSAT", "ADJA", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Uns hier nicht g\u00f6nnen will, dich itzt zum lehrer haben.", "tokens": ["Uns", "hier", "nicht", "g\u00f6n\u00b7nen", "will", ",", "dich", "itzt", "zum", "leh\u00b7rer", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,", "PPER", "ADV", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "In wahrheit dein verlust geht uns recht bitter ein:", "tokens": ["In", "wahr\u00b7heit", "dein", "ver\u00b7lust", "geht", "uns", "recht", "bit\u00b7ter", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wir h\u00f6ren dann nicht mehr die g\u00f6ldnen sitten-lehren.", "tokens": ["Wir", "h\u00f6\u00b7ren", "dann", "nicht", "mehr", "die", "g\u00f6ld\u00b7nen", "sit\u00b7ten\u00b7leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn Jena will von dir die wahre weisheit h\u00f6ren:", "tokens": ["Denn", "Je\u00b7na", "will", "von", "dir", "die", "wah\u00b7re", "weis\u00b7heit", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "APPR", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der eigensinn und wahn umsonst das ende dr\u00e4un.", "tokens": ["Der", "ei\u00b7gen\u00b7sinn", "und", "wahn", "um\u00b7sonst", "das", "en\u00b7de", "dr\u00e4un", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn, solt\u2019 auch sonne, mond und alle welt vergehen;", "tokens": ["Denn", ",", "solt'", "auch", "son\u00b7ne", ",", "mond", "und", "al\u00b7le", "welt", "ver\u00b7ge\u00b7hen", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VMFIN", "ADV", "VVFIN", "$,", "ADJD", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So bleibt doch GOttes wort auf festem fusse stehen.", "tokens": ["So", "bleibt", "doch", "Got\u00b7tes", "wort", "auf", "fes\u00b7tem", "fus\u00b7se", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ehrw\u00fcrdigster Patron! Wir ehron deinen schlu\u00df,", "tokens": ["Ehr\u00b7w\u00fcr\u00b7digs\u00b7ter", "Pat\u00b7ron", "!", "Wir", "eh\u00b7ron", "dei\u00b7nen", "schlu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Weil ihn vernunfft und schrifft nicht auszusetzen wissen:", "tokens": ["Weil", "ihn", "ver\u00b7nunfft", "und", "schrifft", "nicht", "aus\u00b7zu\u00b7set\u00b7zen", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "L\u00e4\u00dft hier dein mund nicht mehr der weisheit str\u00f6me fliessen,", "tokens": ["L\u00e4\u00dft", "hier", "dein", "mund", "nicht", "mehr", "der", "weis\u00b7heit", "str\u00f6\u00b7me", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der weisheit, so der neid selbst weisheit nennen mu\u00df;", "tokens": ["Der", "weis\u00b7heit", ",", "so", "der", "neid", "selbst", "weis\u00b7heit", "nen\u00b7nen", "mu\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So l\u00e4sset deine lieb uns dennoch nichts entbehren.", "tokens": ["So", "l\u00e4s\u00b7set", "dei\u00b7ne", "lieb", "uns", "den\u00b7noch", "nichts", "ent\u00b7beh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJD", "PPER", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn was der mund versagt, das mu\u00df die hand gew\u00e4hren.", "tokens": ["Denn", "was", "der", "mund", "ver\u00b7sagt", ",", "das", "mu\u00df", "die", "hand", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVPP", "$,", "PDS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Was hat nicht schon die welt von dieser hand geschaut?", "tokens": ["Was", "hat", "nicht", "schon", "die", "welt", "von", "die\u00b7ser", "hand", "ge\u00b7schaut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was hat die Cabbala dir nicht vor licht zu dancken?", "tokens": ["Was", "hat", "die", "Cab\u00b7ba\u00b7la", "dir", "nicht", "vor", "licht", "zu", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "PPER", "PTKNEG", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Allein di\u00df kurtze blat fa\u00dft in so engen schrancken", "tokens": ["Al\u00b7lein", "di\u00df", "kurt\u00b7ze", "blat", "fa\u00dft", "in", "so", "en\u00b7gen", "schran\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "ADJA", "NN", "VVFIN", "APPR", "ADV", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die ehren-s\u00e4ulen nicht, so dir dein witz gebaut.", "tokens": ["Die", "eh\u00b7ren\u00b7s\u00e4u\u00b7len", "nicht", ",", "so", "dir", "dein", "witz", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "$,", "ADV", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn deine schrifften sind die r\u00fchmlichsten Colossen,", "tokens": ["Denn", "dei\u00b7ne", "schriff\u00b7ten", "sind", "die", "r\u00fchm\u00b7lichs\u00b7ten", "Co\u00b7los\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.6": {"text": "Dieweil sie die vernunfft, nicht eitler stoltz, gegossen.", "tokens": ["Die\u00b7weil", "sie", "die", "ver\u00b7nunfft", ",", "nicht", "eit\u00b7ler", "stoltz", ",", "ge\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "$,", "PTKNEG", "ADJD", "ADJD", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wohl dir, geehrter Mann! Der H\u00f6chste segne dich!", "tokens": ["Wohl", "dir", ",", "ge\u00b7ehr\u00b7ter", "Mann", "!", "Der", "H\u00f6chs\u00b7te", "seg\u00b7ne", "dich", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADJA", "NN", "$.", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und lasse seinen geist den deinen t\u00e4glich st\u00e4rcken!", "tokens": ["Und", "las\u00b7se", "sei\u00b7nen", "geist", "den", "dei\u00b7nen", "t\u00e4g\u00b7lich", "st\u00e4r\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ART", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lehrst du, wie bi\u00dfher, mit worten und mit wercken:", "tokens": ["So", "lehrst", "du", ",", "wie", "bi\u00df\u00b7her", ",", "mit", "wor\u00b7ten", "und", "mit", "wer\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ADV", "$,", "APPR", "NN", "KON", "APPR", "VVINF", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein solches lehren h\u00e4lt den allerbesten stich.", "tokens": ["Ein", "sol\u00b7ches", "leh\u00b7ren", "h\u00e4lt", "den", "al\u00b7ler\u00b7bes\u00b7ten", "stich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VVFIN", "ART", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und diesen, der mit krafft und nachdruck in den sachen", "tokens": ["Und", "die\u00b7sen", ",", "der", "mit", "krafft", "und", "nach\u00b7druck", "in", "den", "sa\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "$,", "PRELS", "APPR", "NN", "KON", "NN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der weisheit handeln soll, mu\u00df GOtt zum Doctor machen.", "tokens": ["Der", "weis\u00b7heit", "han\u00b7deln", "soll", ",", "mu\u00df", "Gott", "zum", "Doc\u00b7tor", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$,", "VMFIN", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}