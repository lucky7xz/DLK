{"textgrid.poem.36218": {"metadata": {"author": {"name": "Schlegel, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Verh\u00e4ltnisse", "genre": "verse", "period": "N.A.", "pub_year": 1800, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "R\u00fccksichten sind's, die unsern Blick ber\u00fccken;", "tokens": ["R\u00fcck\u00b7sich\u00b7ten", "sin\u00b7d's", ",", "die", "un\u00b7sern", "Blick", "be\u00b7r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In Absicht jede Aussicht gleich erkalten,", "tokens": ["In", "Ab\u00b7sicht", "je\u00b7de", "Aus\u00b7sicht", "gleich", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bis wir, eh' wir uns umgesehn, veralten,", "tokens": ["Bis", "wir", ",", "eh'", "wir", "uns", "um\u00b7ge\u00b7sehn", ",", "ver\u00b7al\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und beugen dann, von Einsicht schwer, den R\u00fccken.", "tokens": ["Und", "beu\u00b7gen", "dann", ",", "von", "Ein\u00b7sicht", "schwer", ",", "den", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "APPR", "NN", "ADJD", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Roh scheint's, der Erde Blumen grade pfl\u00fccken.", "tokens": ["Roh", "scheint's", ",", "der", "Er\u00b7de", "Blu\u00b7men", "gra\u00b7de", "pfl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "ART", "NN", "NN", "ADV", "VVINF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wir m\u00f6chten fein der Schonung Linie halten,", "tokens": ["Wir", "m\u00f6ch\u00b7ten", "fein", "der", "Scho\u00b7nung", "Li\u00b7nie", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Liebe Leben k\u00fcnstlich klug verwalten,", "tokens": ["Der", "Lie\u00b7be", "Le\u00b7ben", "k\u00fcnst\u00b7lich", "klug", "ver\u00b7wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Verst\u00e4ndig und mit Anstand uns erdr\u00fccken.", "tokens": ["Ver\u00b7st\u00e4n\u00b7dig", "und", "mit", "An\u00b7stand", "uns", "er\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wir sollen unbekannte Gr\u00f6\u00dfen w\u00e4hlen,", "tokens": ["Wir", "sol\u00b7len", "un\u00b7be\u00b7kann\u00b7te", "Gr\u00f6\u00b7\u00dfen", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es sind zu wenig Gleichungen gegeben,", "tokens": ["Es", "sind", "zu", "we\u00b7nig", "Glei\u00b7chun\u00b7gen", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Drum hatt' und hat's ein sonderbar Bewendnis;", "tokens": ["Drum", "hatt'", "und", "hat's", "ein", "son\u00b7der\u00b7bar", "Be\u00b7wend\u00b7nis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "KON", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Denn, weil wir endlos rechnen, zweifeln, z\u00e4hlen,", "tokens": ["Denn", ",", "weil", "wir", "end\u00b7los", "rech\u00b7nen", ",", "zwei\u00b7feln", ",", "z\u00e4h\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJD", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wird uns das klare, leichte, freie Leben", "tokens": ["Wird", "uns", "das", "kla\u00b7re", ",", "leich\u00b7te", ",", "frei\u00b7e", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein einzig vielverschlungen Mi\u00dfverst\u00e4ndnis.", "tokens": ["Ein", "ein\u00b7zig", "viel\u00b7ver\u00b7schlun\u00b7gen", "Mi\u00df\u00b7ver\u00b7st\u00e4nd\u00b7nis", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Tapfer verhalte dich stets; so ist dein das beste Verh\u00e4ltnis,", "tokens": ["Tap\u00b7fer", "ver\u00b7hal\u00b7te", "dich", "stets", ";", "so", "ist", "dein", "das", "bes\u00b7te", "Ver\u00b7h\u00e4lt\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "$.", "ADV", "VAFIN", "PPOSAT", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Kannst du gelassen es sehn, wie sich verwickelt das Volk.", "tokens": ["Kannst", "du", "ge\u00b7las\u00b7sen", "es", "sehn", ",", "wie", "sich", "ver\u00b7wi\u00b7ckelt", "das", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVPP", "PPER", "VVINF", "$,", "PWAV", "PRF", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}}}}}