{"dta.poem.10101": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Neue Betrachtung G\u00f6ttlicher Wunder.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Voll Ehr-Furcht hab' ich die\u00df offt bey mir \u00fcberdacht:", "tokens": ["Voll", "Ehr\u00b7Furcht", "hab'", "ich", "die\u00df", "offt", "bey", "mir", "\u00fc\u00b7berd\u00b7acht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VAFIN", "PPER", "PDS", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo auf der Welt, von GOttes Wunder-Macht", "tokens": ["Wo", "auf", "der", "Welt", ",", "von", "Got\u00b7tes", "Wun\u00b7der\u00b7Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "$,", "APPR", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und Weisheit, eine Probe sich,", "tokens": ["Und", "Weis\u00b7heit", ",", "ei\u00b7ne", "Pro\u00b7be", "sich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum nie begriffnen Wunder, zeiget,", "tokens": ["Zum", "nie", "be\u00b7griff\u00b7nen", "Wun\u00b7der", ",", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "ADV", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die allen Witz weit \u00fcbersteiget;", "tokens": ["Die", "al\u00b7len", "Witz", "weit", "\u00fc\u00b7bers\u00b7tei\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So ist es die, wenn man erweget,", "tokens": ["So", "ist", "es", "die", ",", "wenn", "man", "er\u00b7we\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mit geziemender Betrachtung \u00fcberleget,", "tokens": ["Und", "mit", "ge\u00b7zie\u00b7men\u00b7der", "Be\u00b7trach\u00b7tung", "\u00fc\u00b7ber\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie unbegreifflich ordentlich,", "tokens": ["Wie", "un\u00b7be\u00b7greif\u00b7flich", "or\u00b7dent\u00b7lich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In so unordentlich-und wiederw\u00e4rtgen Dingen,", "tokens": ["In", "so", "un\u00b7or\u00b7dent\u00b7lich\u00b7\u00b7und", "wie\u00b7der\u00b7w\u00e4rt\u00b7gen", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Woraus in dieser Unter-Welt", "tokens": ["Wo\u00b7raus", "in", "die\u00b7ser", "Un\u00b7ter\u00b7Welt"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Fast alle Ding\u2019 entstehen und entspringen,", "tokens": ["Fast", "al\u00b7le", "Ding'", "ent\u00b7ste\u00b7hen", "und", "ent\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Doch alles wunderbar vereinet, sich erh\u00e4lt.", "tokens": ["Doch", "al\u00b7les", "wun\u00b7der\u00b7bar", "ver\u00b7ei\u00b7net", ",", "sich", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "VVFIN", "$,", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Aus W\u00e4rm\u2019 und K\u00e4lt\u2019, aus Erd\u2019 und Gluth,", "tokens": ["Aus", "W\u00e4rm'", "und", "K\u00e4lt'", ",", "aus", "Erd'", "und", "Gluth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Licht, aus Dunckelheit, aus Lufft und Fluht,", "tokens": ["Aus", "Licht", ",", "aus", "Dun\u00b7ckel\u00b7heit", ",", "aus", "Lufft", "und", "Fluht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus saur und s\u00fc\u00df, aus tausendfachen S\u00e4fften,", "tokens": ["Aus", "saur", "und", "s\u00fc\u00df", ",", "aus", "tau\u00b7send\u00b7fa\u00b7chen", "S\u00e4ff\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "KON", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Aus Ruh, Beweglichkeit, und tausendfachen Kr\u00e4fften,", "tokens": ["Aus", "Ruh", ",", "Be\u00b7weg\u00b7lich\u00b7keit", ",", "und", "tau\u00b7send\u00b7fa\u00b7chen", "Kr\u00e4ff\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Aus treiben, hemmen, ruhen, eilen,", "tokens": ["Aus", "trei\u00b7ben", ",", "hem\u00b7men", ",", "ru\u00b7hen", ",", "ei\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "VVINF", "$,", "VVFIN", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Aus lauter widerw\u00e4rtgen Theilen", "tokens": ["Aus", "lau\u00b7ter", "wi\u00b7der\u00b7w\u00e4rt\u00b7gen", "Thei\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Bestehet ein harmonisch Gantz.", "tokens": ["Be\u00b7ste\u00b7het", "ein", "har\u00b7mo\u00b7nisch", "Gantz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "O unbegreifflich gross-Anbetungs-w\u00fcrdger GOTT!", "tokens": ["O", "un\u00b7be\u00b7greif\u00b7flich", "gross\u00b7An\u00b7be\u00b7tungs\u00b7w\u00fcrd\u00b7ger", "GoTT", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie herrlich strahlt hieraus der ewgen Weisheit Glantz!", "tokens": ["Wie", "herr\u00b7lich", "strahlt", "hier\u00b7aus", "der", "ew\u00b7gen", "Weis\u00b7heit", "Glantz", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PAV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "O Sch\u00f6pfer aller Ding\u2019, HERR Zebaoth,", "tokens": ["O", "Sch\u00f6p\u00b7fer", "al\u00b7ler", "Ding'", ",", "HeRR", "Ze\u00b7bao\u00b7th", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "PIAT", "NN", "$,", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "O unergr\u00fcndlich weises Wesen,", "tokens": ["O", "un\u00b7er\u00b7gr\u00fcnd\u00b7lich", "wei\u00b7ses", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das ich geoffenbar\u2019t in dieser Mischung seh!", "tokens": ["Das", "ich", "geof\u00b7fen\u00b7ba\u00b7r't", "in", "die\u00b7ser", "Misc\u00b7hung", "seh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVPP", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Was hast Du f\u00fcr Materie", "tokens": ["Was", "hast", "Du", "f\u00fcr", "Ma\u00b7te\u00b7rie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Zum Zeugni\u00df Deiner Macht erlesen!", "tokens": ["Zum", "Zeug\u00b7ni\u00df", "Dei\u00b7ner", "Macht", "er\u00b7le\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was sich verletzen sollt\u2019 und schaden, mu\u00df sich n\u00fctzen;", "tokens": ["Was", "sich", "ver\u00b7let\u00b7zen", "sollt'", "und", "scha\u00b7den", ",", "mu\u00df", "sich", "n\u00fct\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVINF", "VMFIN", "KON", "VVFIN", "$,", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was sich zertr\u00fcmmern m\u00fcst und st\u00fcrtzen, mu\u00df sich st\u00fctzen;", "tokens": ["Was", "sich", "zer\u00b7tr\u00fcm\u00b7mern", "m\u00fcst", "und", "st\u00fcrt\u00b7zen", ",", "mu\u00df", "sich", "st\u00fct\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVINF", "VMFIN", "KON", "VVINF", "$,", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was sich vernichten sollt, zernichtiget sich nicht.", "tokens": ["Was", "sich", "ver\u00b7nich\u00b7ten", "sollt", ",", "zer\u00b7nich\u00b7ti\u00b7get", "sich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVINF", "VMFIN", "$,", "VVFIN", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Aus grosser Ungleichheit entsteht ein Gleich-Gewicht:", "tokens": ["Aus", "gros\u00b7ser", "Un\u00b7gleich\u00b7heit", "ent\u00b7steht", "ein", "Gleich\u00b7Ge\u00b7wicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Aus immerw\u00e4hrndem Krieg\u2019 entsteht ein steter Friede.", "tokens": ["Aus", "im\u00b7mer\u00b7w\u00e4hrn\u00b7dem", "Krieg'", "ent\u00b7steht", "ein", "ste\u00b7ter", "Frie\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ach! w\u00fcrd\u2019 ich doch Zeit Lebens nimmer m\u00fcde,", "tokens": ["Ach", "!", "w\u00fcrd'", "ich", "doch", "Zeit", "Le\u00b7bens", "nim\u00b7mer", "m\u00fc\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ADV", "NN", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von allen Deinen Wunder-Wercken,", "tokens": ["Von", "al\u00b7len", "Dei\u00b7nen", "Wun\u00b7der\u00b7\u00b7Wer\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch die\u00df, als eins der gr\u00f6sten, zu bemercken!", "tokens": ["Doch", "die\u00df", ",", "als", "eins", "der", "gr\u00f6s\u00b7ten", ",", "zu", "be\u00b7mer\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "KOUS", "PIS", "ART", "ADJA", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ach! da\u00df an unsrer Welt, vor allen andern Erden,", "tokens": ["Ach", "!", "da\u00df", "an", "uns\u00b7rer", "Welt", ",", "vor", "al\u00b7len", "an\u00b7dern", "Er\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "KOUS", "APPR", "PPOSAT", "NN", "$,", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die\u00df, als was sonderlichs m\u00f6gt\u2019 angesehn,", "tokens": ["Die\u00df", ",", "als", "was", "son\u00b7der\u00b7lichs", "m\u00f6gt'", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "KOUS", "PIS", "PIS", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und alle Dinge, die in selbigen geschehn,", "tokens": ["Und", "al\u00b7le", "Din\u00b7ge", ",", "die", "in", "sel\u00b7bi\u00b7gen", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als Proben Deiner Macht, o HERR! betrachtet werden!", "tokens": ["Als", "Pro\u00b7ben", "Dei\u00b7ner", "Macht", ",", "o", "HeRR", "!", "be\u00b7trach\u00b7tet", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "$,", "FM", "NN", "$.", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}