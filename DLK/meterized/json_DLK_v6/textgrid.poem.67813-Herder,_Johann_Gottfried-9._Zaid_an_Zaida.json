{"textgrid.poem.67813": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "9. Zaid an Zaida", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sch\u00f6ne Zaida meiner Augen!", "tokens": ["Sch\u00f6\u00b7ne", "Zai\u00b7da", "mei\u00b7ner", "Au\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner Seele sch\u00f6ne Zaida!", "tokens": ["Mei\u00b7ner", "See\u00b7le", "sch\u00f6\u00b7ne", "Zai\u00b7da", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du, die sch\u00f6nste der Mohrinnen,", "tokens": ["Du", ",", "die", "sch\u00f6ns\u00b7te", "der", "Moh\u00b7rin\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vor allen Undankbare.", "tokens": ["Und", "vor", "al\u00b7len", "Un\u00b7dank\u00b7ba\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Du, aus deren sch\u00f6nen Haaren", "tokens": ["Du", ",", "aus", "de\u00b7ren", "sch\u00f6\u00b7nen", "Haa\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.2": {"text": "Amor tausend Neze stricket,", "tokens": ["A\u00b7mor", "tau\u00b7send", "Ne\u00b7ze", "stri\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "CARD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Drinn sich, blind von deinem Anschaun,", "tokens": ["Drinn", "sich", ",", "blind", "von", "dei\u00b7nem", "An\u00b7schaun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tausend freie Seelen fangen!", "tokens": ["Tau\u00b7send", "frei\u00b7e", "See\u00b7len", "fan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Welche Lust empfandst du, Stolze,", "tokens": ["Wel\u00b7che", "Lust", "emp\u00b7fandst", "du", ",", "Stol\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "PPER", "$,", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dich mir also zu ver\u00e4ndern!", "tokens": ["Dich", "mir", "al\u00b7so", "zu", "ver\u00b7\u00e4n\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weist, wie sehr ich dich anbete,", "tokens": ["Weist", ",", "wie", "sehr", "ich", "dich", "an\u00b7be\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "ADV", "PPER", "PRF", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und begegnest mir nun also!", "tokens": ["Und", "be\u00b7geg\u00b7nest", "mir", "nun", "al\u00b7so", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Ach wie \u00fcbel, s\u00fcsse Feindin,", "tokens": ["Ach", "wie", "\u00fc\u00b7bel", ",", "s\u00fcs\u00b7se", "Fein\u00b7din", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADJD", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lohnst du meine treue Liebe!", "tokens": ["Lohnst", "du", "mei\u00b7ne", "treu\u00b7e", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da statt Gegenliebe du mir", "tokens": ["Da", "statt", "Ge\u00b7gen\u00b7lie\u00b7be", "du", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "PPER", "PPER"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Unbestand und Undank giebest.", "tokens": ["Un\u00b7be\u00b7stand", "und", "Un\u00b7dank", "gie\u00b7best", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie so schnell sind sie entflogen", "tokens": ["Wie", "so", "schnell", "sind", "sie", "ent\u00b7flo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADJD", "VAFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deine Worte, deine Schw\u00fcre!", "tokens": ["Dei\u00b7ne", "Wor\u00b7te", ",", "dei\u00b7ne", "Schw\u00fc\u00b7re", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnug, da\u00df es die deine waren,", "tokens": ["Gnug", ",", "da\u00df", "es", "die", "dei\u00b7ne", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ART", "PPOSAT", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nahmen Fl\u00fcgel sie und flogen.", "tokens": ["Nah\u00b7men", "Fl\u00fc\u00b7gel", "sie", "und", "flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PPER", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Denke, wie an jenem Tage", "tokens": ["Den\u00b7ke", ",", "wie", "an", "je\u00b7nem", "Ta\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PWAV", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du mir tausend Liebeszeichen,", "tokens": ["Du", "mir", "tau\u00b7send", "Lie\u00b7bes\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach so zarte Zeichen gabest,", "tokens": ["Ach", "so", "zar\u00b7te", "Zei\u00b7chen", "ga\u00b7best", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df so zart sie welken musten.", "tokens": ["Da\u00df", "so", "zart", "sie", "wel\u00b7ken", "mus\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Denk, o denke, wenn dir, Zaida,", "tokens": ["Denk", ",", "o", "den\u00b7ke", ",", "wenn", "dir", ",", "Zai\u00b7da", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "FM", "VVFIN", "$,", "KOUS", "PPER", "$,", "NE", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Dies Erinnern jezt nicht widert,", "tokens": ["Dies", "E\u00b7rin\u00b7nern", "jezt", "nicht", "wi\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welch Vergn\u00fcgen du empfandest,", "tokens": ["Welch", "Ver\u00b7gn\u00fc\u00b7gen", "du", "emp\u00b7fan\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn ich deinen Pallast umzog.", "tokens": ["Wenn", "ich", "dei\u00b7nen", "Pal\u00b7last", "um\u00b7zog", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Wenn am Tage auf den Punkt schnell", "tokens": ["Wenn", "am", "Ta\u00b7ge", "auf", "den", "Punkt", "schnell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "APPR", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Du hin an das Fenster h\u00fcpftest,", "tokens": ["Du", "hin", "an", "das", "Fens\u00b7ter", "h\u00fcpf\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder Nachts dich auf dem Balkon,", "tokens": ["O\u00b7der", "Nachts", "dich", "auf", "dem", "Bal\u00b7kon", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich am Gitter sprechen liessest.", "tokens": ["Dich", "am", "Git\u00b7ter", "spre\u00b7chen", "lies\u00b7sest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wenn ich ausblieb, oder s\u00e4umte,", "tokens": ["Wenn", "ich", "aus\u00b7blieb", ",", "o\u00b7der", "s\u00e4um\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KON", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Welche Eifersucht dich brannte;", "tokens": ["Wel\u00b7che", "Ei\u00b7fer\u00b7sucht", "dich", "brann\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber nun, wie bist du anders!", "tokens": ["A\u00b7ber", "nun", ",", "wie", "bist", "du", "an\u00b7ders", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "VAFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Heissest mich, an Hof zu gehen.", "tokens": ["Heis\u00b7sest", "mich", ",", "an", "Hof", "zu", "ge\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Heissest mich, dich nie zu sehen,", "tokens": ["Heis\u00b7sest", "mich", ",", "dich", "nie", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nie dir Briefe mehr zu schreiben,", "tokens": ["Nie", "dir", "Brie\u00b7fe", "mehr", "zu", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dir, der einst so lieb sie waren,", "tokens": ["Dir", ",", "der", "einst", "so", "lieb", "sie", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ADV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und nun Unlust dir erregen.", "tokens": ["Und", "nun", "Un\u00b7lust", "dir", "er\u00b7re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ach, o Zaida, deine Liebe,", "tokens": ["Ach", ",", "o", "Zai\u00b7da", ",", "dei\u00b7ne", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "FM", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deine Gunst und s\u00fcssen Worte", "tokens": ["Dei\u00b7ne", "Gunst", "und", "s\u00fcs\u00b7sen", "Wor\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Haben sich mir falsch entdecket,", "tokens": ["Ha\u00b7ben", "sich", "mir", "falsch", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Haben dich mir falsch erwiesen.", "tokens": ["Ha\u00b7ben", "dich", "mir", "falsch", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Kurz, du bist ein Weib, o Zaida,", "tokens": ["Kurz", ",", "du", "bist", "ein", "Weib", ",", "o", "Zai\u00b7da", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "ART", "NN", "$,", "FM", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur geneigt zum Unbestande,", "tokens": ["Nur", "ge\u00b7neigt", "zum", "Un\u00b7be\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Betest an, was dich vergisset,", "tokens": ["Be\u00b7test", "an", ",", "was", "dich", "ver\u00b7gis\u00b7set", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vergiss'st, was dich anbetet.", "tokens": ["Und", "ver\u00b7giss'st", ",", "was", "dich", "an\u00b7be\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "--+--+--", "measure": "anapaest.di.plus"}}, "stanza.13": {"line.1": {"text": "Aber hasse mich, o Zaida,", "tokens": ["A\u00b7ber", "has\u00b7se", "mich", ",", "o", "Zai\u00b7da", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "FM", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir in Nichts zu gleichen, will ich,", "tokens": ["Dir", "in", "Nichts", "zu", "glei\u00b7chen", ",", "will", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "PTKZU", "VVINF", "$,", "VMFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4rest du von hartem Eise,", "tokens": ["W\u00e4\u00b7rest", "du", "von", "har\u00b7tem", "Ei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mehr nur meine Flamme n\u00e4hren,", "tokens": ["Mehr", "nur", "mei\u00b7ne", "Flam\u00b7me", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Will dir deine Untreu lohnen", "tokens": ["Will", "dir", "dei\u00b7ne", "Un\u00b7treu", "loh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit viel tausend Liebes\u00e4ngsten,", "tokens": ["Mit", "viel", "tau\u00b7send", "Lie\u00b7be\u00b7s\u00e4ngs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn, o Zaida, wahre Liebe", "tokens": ["Denn", ",", "o", "Zai\u00b7da", ",", "wah\u00b7re", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "FM", "NE", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird sehr sp\u00e4t nur unbest\u00e4ndig.", "tokens": ["Wird", "sehr", "sp\u00e4t", "nur", "un\u00b7be\u00b7st\u00e4n\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}