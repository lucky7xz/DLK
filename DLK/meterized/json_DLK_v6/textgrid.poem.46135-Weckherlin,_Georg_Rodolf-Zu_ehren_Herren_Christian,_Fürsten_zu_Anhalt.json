{"textgrid.poem.46135": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Zu ehren Herren Christian, F\u00fcrsten zu Anhalt", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dieweil ich sah, da\u00df lehr und kunst,", "tokens": ["Die\u00b7weil", "ich", "sah", ",", "da\u00df", "lehr", "und", "kunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "ADV", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die uns die Musen selbs verkaufen", "tokens": ["die", "uns", "die", "Mu\u00b7sen", "selbs", "ver\u00b7kau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "um flei\u00df, bei allen so umsunst,", "tokens": ["um", "flei\u00df", ",", "bei", "al\u00b7len", "so", "um\u00b7sunst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "PIS", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df man damit m\u00f6cht betlen laufen:", "tokens": ["da\u00df", "man", "da\u00b7mit", "m\u00f6cht", "bet\u00b7len", "lau\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df sie, wie mir ihre lehr", "tokens": ["Und", "da\u00df", "sie", ",", "wie", "mir", "ih\u00b7re", "lehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "$,", "PWAV", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bei fremden freindschaft, lieb und ehr", "tokens": ["bei", "frem\u00b7den", "freind\u00b7schaft", ",", "lieb", "und", "ehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "erworben, hie mich machten hassen:", "tokens": ["er\u00b7wor\u00b7ben", ",", "hie", "mich", "mach\u00b7ten", "has\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "beschlo\u00df ich in der Teutschen sprach", "tokens": ["be\u00b7schlo\u00df", "ich", "in", "der", "Teut\u00b7schen", "sprach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "(der unerfahrnen meinung nach", "tokens": ["(", "der", "un\u00b7er\u00b7fahr\u00b7nen", "mei\u00b7nung", "nach"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "zu grob) zu schreiben abzulassen.", "tokens": ["zu", "grob", ")", "zu", "schrei\u00b7ben", "ab\u00b7zu\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "$(", "PTKZU", "VVINF", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch w\u00e4r es mir nicht eine schand,", "tokens": ["Doch", "w\u00e4r", "es", "mir", "nicht", "ei\u00b7ne", "schand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PPER", "PTKNEG", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wan ich auf dieser meinung bleiben", "tokens": ["wan", "ich", "auf", "die\u00b7ser", "mei\u00b7nung", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PDAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und nicht solt mit getreuer hand", "tokens": ["und", "nicht", "solt", "mit", "ge\u00b7treu\u00b7er", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "von euch ein lobgesang beschreiben?", "tokens": ["von", "euch", "ein", "lob\u00b7ge\u00b7sang", "be\u00b7schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Von euch, prinz, dessen w\u00fcrdigkeit", "tokens": ["Von", "euch", ",", "prinz", ",", "des\u00b7sen", "w\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "$,", "NE", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "vil mehr dan die undankbarkeit", "tokens": ["vil", "mehr", "dan", "die", "un\u00b7dank\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "der argen welt, mein herz entz\u00fcndet:", "tokens": ["der", "ar\u00b7gen", "welt", ",", "mein", "herz", "ent\u00b7z\u00fcn\u00b7det", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "bei dessen tiefen erkantnus", "tokens": ["bei", "des\u00b7sen", "tie\u00b7fen", "er\u00b7kant\u00b7nus"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "kunst und lehr keine hindernus", "tokens": ["kunst", "und", "lehr", "kei\u00b7ne", "hin\u00b7der\u00b7nus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "PIAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.10": {"text": "und keinen schutz die grobheit findet.", "tokens": ["und", "kei\u00b7nen", "schutz", "die", "grob\u00b7heit", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dan ihr, prinz, seid des Teutschlands wohn", "tokens": ["Dan", "ihr", ",", "prinz", ",", "seid", "des", "Teutschlands", "wohn"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "NE", "$,", "VAFIN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "und der gelehrten wolgefallen,", "tokens": ["und", "der", "ge\u00b7lehr\u00b7ten", "wol\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "von welchem, als der kunst patron,", "tokens": ["von", "wel\u00b7chem", ",", "als", "der", "kunst", "pat\u00b7ron", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "$,", "KOUS", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "soll billich meine stim erschallen.", "tokens": ["soll", "bil\u00b7lich", "mei\u00b7ne", "stim", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Euch, euch hat seinem volk zu nutz", "tokens": ["Euch", ",", "euch", "hat", "sei\u00b7nem", "volk", "zu", "nutz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und seinem b\u00f6sen feind zu trutz", "tokens": ["und", "sei\u00b7nem", "b\u00f6\u00b7sen", "feind", "zu", "trutz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "als einen w\u00e4chtern got gegeben,", "tokens": ["als", "ei\u00b7nen", "w\u00e4ch\u00b7tern", "got", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "da\u00df es nach euerm weisen rat,", "tokens": ["da\u00df", "es", "nach", "eu\u00b7erm", "wei\u00b7sen", "rat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "da\u00df es durch eurer weisheit that", "tokens": ["da\u00df", "es", "durch", "eu\u00b7rer", "weis\u00b7heit", "that"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "kan ruhig, still und fr\u00f6lich leben.", "tokens": ["kan", "ru\u00b7hig", ",", "still", "und", "fr\u00f6\u00b7lich", "le\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "$,", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.4": {"line.1": {"text": "Aiax kont durch sein starke hand", "tokens": ["Ai\u00b7ax", "kont", "durch", "sein", "star\u00b7ke", "hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so vil als sunst ein held verrichten,", "tokens": ["so", "vil", "als", "sunst", "ein", "held", "ver\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "zu schlecht war aber sein verstand", "tokens": ["zu", "schlecht", "war", "a\u00b7ber", "sein", "ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKA", "ADJD", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "durch rat ein harte sach zu schlichten:", "tokens": ["durch", "rat", "ein", "har\u00b7te", "sach", "zu", "schlich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Also seid ihr bei weitem nicht,", "tokens": ["Al\u00b7so", "seid", "ihr", "bei", "wei\u00b7tem", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIS", "PTKNEG", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "weil euer sp\u00e4hendes gericht", "tokens": ["weil", "eu\u00b7er", "sp\u00e4\u00b7hen\u00b7des", "ge\u00b7richt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "(darab sich alle frommen freuen)", "tokens": ["(", "da\u00b7rab", "sich", "al\u00b7le", "from\u00b7men", "freu\u00b7en", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "PRF", "PIAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "kan wie Ulysses eure freind", "tokens": ["kan", "wie", "U\u00b7lys\u00b7ses", "eu\u00b7re", "freind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "KOKOM", "NE", "PPOSAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "durch rat erhalten, und die feind", "tokens": ["durch", "rat", "er\u00b7hal\u00b7ten", ",", "und", "die", "feind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "VVFIN", "VVPP", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "wie Aiax mit der that zustreuen.", "tokens": ["wie", "Ai\u00b7ax", "mit", "der", "that", "zu\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "ART", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich kont sehr leichtlich mein gesang", "tokens": ["Ich", "kont", "sehr", "leicht\u00b7lich", "mein", "ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit l\u00f6blichen exempeln zieren,", "tokens": ["mit", "l\u00f6b\u00b7li\u00b7chen", "ex\u00b7em\u00b7peln", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "und eure faust mit klarem klang", "tokens": ["und", "eu\u00b7re", "faust", "mit", "kla\u00b7rem", "klang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wie euers verstands kraft ausf\u00fchren:", "tokens": ["wie", "eu\u00b7ers", "ver\u00b7stands", "kraft", "aus\u00b7f\u00fch\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Wan ihr nicht woltet selbs vilmehr", "tokens": ["Wan", "ihr", "nicht", "wol\u00b7tet", "selbs", "vil\u00b7mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "VMFIN", "ADV", "ADV"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "stets euers namens werte ehr", "tokens": ["stets", "eu\u00b7ers", "na\u00b7mens", "wer\u00b7te", "ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "verdienen, dan erheben h\u00f6ren:", "tokens": ["ver\u00b7die\u00b7nen", ",", "dan", "er\u00b7he\u00b7ben", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und wan nur eines menschen prob", "tokens": ["und", "wan", "nur", "ei\u00b7nes", "men\u00b7schen", "prob"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "mit seinem mund kont euer lob", "tokens": ["mit", "sei\u00b7nem", "mund", "kont", "eu\u00b7er", "lob"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "gleich wie mit seinem geist vermehren.", "tokens": ["gleich", "wie", "mit", "sei\u00b7nem", "geist", "ver\u00b7meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Es weist und weiset ganz Frankreich", "tokens": ["Es", "weist", "und", "wei\u00b7set", "ganz", "Fran\u00b7kreich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(kriegshalb und fridenshalb gepriesen)", "tokens": ["(", "kriegs\u00b7halb", "und", "fri\u00b7dens\u00b7halb", "ge\u00b7prie\u00b7sen", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie dapfer und wie weis ihr euch", "tokens": ["wie", "dap\u00b7fer", "und", "wie", "weis", "ihr", "euch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KON", "PWAV", "ADJD", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in euerm fr\u00fcling gleich erwisen:", "tokens": ["in", "eu\u00b7erm", "fr\u00fc\u00b7ling", "gleich", "er\u00b7wi\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der gro\u00df und gleichlos von Bourbon", "tokens": ["Der", "gro\u00df", "und", "gleich\u00b7los", "von", "Bour\u00b7bon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "ADJD", "APPR", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "der seines namens, bluts und kron", "tokens": ["der", "sei\u00b7nes", "na\u00b7mens", ",", "bluts", "und", "kron"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "wie auch ends halben nachgegangen", "tokens": ["wie", "auch", "ends", "hal\u00b7ben", "nach\u00b7ge\u00b7gan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "dem von Valois, der hat mit lust,", "tokens": ["dem", "von", "Va\u00b7lois", ",", "der", "hat", "mit", "lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "$,", "PRELS", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "und lieb von eurer faust und brust", "tokens": ["und", "lieb", "von", "eu\u00b7rer", "faust", "und", "brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "oft dienst und nutzen gern empfangen.", "tokens": ["oft", "dienst", "und", "nut\u00b7zen", "gern", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und euer w\u00fcrklicher verstand", "tokens": ["Und", "eu\u00b7er", "w\u00fcrk\u00b7li\u00b7cher", "ver\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vil f\u00fcrstlicher werk hat vollendet,", "tokens": ["vil", "f\u00fcrst\u00b7li\u00b7cher", "werk", "hat", "voll\u00b7en\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "insonderheit von dem Teutschland", "tokens": ["in\u00b7son\u00b7der\u00b7heit", "von", "dem", "Teutschland"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "gefahren und leid abgewendet:", "tokens": ["ge\u00b7fah\u00b7ren", "und", "leid", "ab\u00b7ge\u00b7wen\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und eure gr\u00fcndende weisheit", "tokens": ["Und", "eu\u00b7re", "gr\u00fcn\u00b7den\u00b7de", "weis\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "in zwietracht, span und ungleichheit", "tokens": ["in", "zwiet\u00b7racht", ",", "span", "und", "un\u00b7gleich\u00b7heit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "CARD", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "ist billich wert und hoch gehalten;", "tokens": ["ist", "bil\u00b7lich", "wert", "und", "hoch", "ge\u00b7hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "mit zierlichkeit und sattem grund", "tokens": ["mit", "zier\u00b7lich\u00b7keit", "und", "sat\u00b7tem", "grund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "kan euer honigreicher mund", "tokens": ["kan", "eu\u00b7er", "ho\u00b7ni\u00b7grei\u00b7cher", "mund"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "mehr dan des Griechen mund verwalten.", "tokens": ["mehr", "dan", "des", "Grie\u00b7chen", "mund", "ver\u00b7wal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Jedoch da\u00df niemand nu vermein,", "tokens": ["Je\u00b7doch", "da\u00df", "nie\u00b7mand", "nu", "ver\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ich woll in einem lied euch singen,", "tokens": ["ich", "woll", "in", "ei\u00b7nem", "lied", "euch", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und euern namen, dessen schein", "tokens": ["und", "eu\u00b7ern", "na\u00b7men", ",", "des\u00b7sen", "schein"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "klar wie die sonn, hie ganz f\u00fcrbringen;", "tokens": ["klar", "wie", "die", "sonn", ",", "hie", "ganz", "f\u00fcr\u00b7brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So brich ich jetz dem\u00fctig ab", "tokens": ["So", "brich", "ich", "jetz", "de\u00b7m\u00fc\u00b7tig", "ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und bit, ihr wollet dise gab", "tokens": ["und", "bit", ",", "ihr", "wol\u00b7let", "di\u00b7se", "gab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PTKANT", "$,", "PPER", "VMFIN", "PDS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "aufnemen und zumal erwegen,", "tokens": ["auf\u00b7ne\u00b7men", "und", "zu\u00b7mal", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "ich folg der besten maler weis,", "tokens": ["ich", "folg", "der", "bes\u00b7ten", "ma\u00b7ler", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "die f\u00fcr die sonn mit kunst und flei\u00df", "tokens": ["die", "f\u00fcr", "die", "sonn", "mit", "kunst", "und", "flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "allein ein aug zu malen pflegen.", "tokens": ["al\u00b7lein", "ein", "aug", "zu", "ma\u00b7len", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}}}}