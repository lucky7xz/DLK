{"textgrid.poem.48562": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "11. Auf Herren D. Polykarpus Leysers, Superintendentens in Leipzig, seliges Ableben", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zwar, wie hoch wir auch betauren", "tokens": ["Zwar", ",", "wie", "hoch", "wir", "auch", "be\u00b7tau\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "ADJD", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "unsers gro\u00dfen ", "tokens": ["un\u00b7sers", "gro\u00b7\u00dfen"], "token_info": ["word", "word"], "pos": ["PPOSAT", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "doch so w\u00e4re diesem Trauren", "tokens": ["doch", "so", "w\u00e4\u00b7re", "die\u00b7sem", "Trau\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "noch so bald zu helfen ab,", "tokens": ["noch", "so", "bald", "zu", "hel\u00b7fen", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PTKZU", "VVINF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wenn der Tod so hoher Leute", "tokens": ["wenn", "der", "Tod", "so", "ho\u00b7her", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nicht ein derbers Unheil dr\u00e4ute.", "tokens": ["nicht", "ein", "der\u00b7bers", "Un\u00b7heil", "dr\u00e4u\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Gott, der geht mit sich zu Rate", "tokens": ["Gott", ",", "der", "geht", "mit", "sich", "zu", "Ra\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVFIN", "APPR", "PRF", "APPR", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "\u00fcber eine Stadt und Land,", "tokens": ["\u00fc\u00b7ber", "ei\u00b7ne", "Stadt", "und", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "dem er alles Gutes tate,", "tokens": ["dem", "er", "al\u00b7les", "Gu\u00b7tes", "ta\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das doch nicht war angewandt,", "tokens": ["das", "doch", "nicht", "war", "an\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKNEG", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df man aus den strengen Plagen", "tokens": ["da\u00df", "man", "aus", "den", "stren\u00b7gen", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mu\u00df von erster G\u00fcte sagen.", "tokens": ["mu\u00df", "von", "ers\u00b7ter", "G\u00fc\u00b7te", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Er f\u00e4ngt an an seinem Hause,", "tokens": ["Er", "f\u00e4ngt", "an", "an", "sei\u00b7nem", "Hau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "seiner Kirchen schont er nicht,", "tokens": ["sei\u00b7ner", "Kir\u00b7chen", "schont", "er", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "und alsdenn ist keine Pause,", "tokens": ["und", "als\u00b7denn", "ist", "kei\u00b7ne", "Pau\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "bis er Alles fast zerbricht,", "tokens": ["bis", "er", "Al\u00b7les", "fast", "zer\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bis er seinen Grimm vollzogen", "tokens": ["bis", "er", "sei\u00b7nen", "Grimm", "voll\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NE", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "\u00fcber dem, was ihn bewogen.", "tokens": ["\u00fc\u00b7ber", "dem", ",", "was", "ihn", "be\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Er versorget die Gerechten", "tokens": ["Er", "ver\u00b7sor\u00b7get", "die", "Ge\u00b7rech\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und die er vor Andern kennt,", "tokens": ["und", "die", "er", "vor", "An\u00b7dern", "kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PPER", "APPR", "ADJA", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "da\u00df sie uns zu Rechte br\u00e4chten,", "tokens": ["da\u00df", "sie", "uns", "zu", "Rech\u00b7te", "br\u00e4ch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn er sie nicht von uns trennt',", "tokens": ["wenn", "er", "sie", "nicht", "von", "uns", "trennt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--++-+", "measure": "dactylic.init"}, "line.5": {"text": "auf da\u00df er verb\u00fcrter Ma\u00dfen", "tokens": ["auf", "da\u00df", "er", "ver\u00b7b\u00fcr\u00b7ter", "Ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "unverhindert uns kan fassen.", "tokens": ["un\u00b7ver\u00b7hin\u00b7dert", "uns", "kan", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Gleich als wenn ein treuer Hirte", "tokens": ["Gleich", "als", "wenn", "ein", "treu\u00b7er", "Hir\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "in der wilden W\u00fcstenei", "tokens": ["in", "der", "wil\u00b7den", "W\u00fcs\u00b7te\u00b7nei"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "von der Heerde sich verirrte,", "tokens": ["von", "der", "Heer\u00b7de", "sich", "ver\u00b7irr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "das verla\u00dfne Vieh wird scheu,", "tokens": ["das", "ver\u00b7la\u00df\u00b7ne", "Vieh", "wird", "scheu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die best\u00fcrzten L\u00e4mmer laufen", "tokens": ["die", "be\u00b7st\u00fcrz\u00b7ten", "L\u00e4m\u00b7mer", "lau\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "ohne Weiser, ohne Haufen.", "tokens": ["oh\u00b7ne", "Wei\u00b7ser", ",", "oh\u00b7ne", "Hau\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUI", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wenn die teuren M\u00e4nner fallen,", "tokens": ["Wenn", "die", "teu\u00b7ren", "M\u00e4n\u00b7ner", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die uns das gesunde Wort", "tokens": ["die", "uns", "das", "ge\u00b7sun\u00b7de", "Wort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "nach dem Himmel lie\u00dfen schallen,", "tokens": ["nach", "dem", "Him\u00b7mel", "lie\u00b7\u00dfen", "schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da will es mit uns nicht fort;", "tokens": ["da", "will", "es", "mit", "uns", "nicht", "fort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "wir entbrechen aus den Schranken", "tokens": ["wir", "ent\u00b7bre\u00b7chen", "aus", "den", "Schran\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und sind steif in stetem Wanken.", "tokens": ["und", "sind", "steif", "in", "ste\u00b7tem", "Wan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Was f\u00fcr widriges Beginnen", "tokens": ["Was", "f\u00fcr", "wid\u00b7ri\u00b7ges", "Be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "folget' auf des Moses Tod?", "tokens": ["fol\u00b7get'", "auf", "des", "Mo\u00b7ses", "Tod", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Samuel war kaum von hinnen,", "tokens": ["Sa\u00b7muel", "war", "kaum", "von", "hin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "APPR", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Israel verlie\u00dfe Gott.", "tokens": ["Is\u00b7rael", "ver\u00b7lie\u00b7\u00dfe", "Gott", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und man war dem Herrn ergeben,", "tokens": ["Und", "man", "war", "dem", "Herrn", "er\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "weil Jojada war im Leben.", "tokens": ["weil", "Jo\u00b7ja\u00b7da", "war", "im", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VAFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und was ist f\u00fcr Unrat kommen,", "tokens": ["Und", "was", "ist", "f\u00fcr", "Un\u00b7rat", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "seit der hohe ", "tokens": ["seit", "der", "ho\u00b7he"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "unsrer Canzeln lichter Schein?", "tokens": ["uns\u00b7rer", "Can\u00b7zeln", "lich\u00b7ter", "Schein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fcnf Jahr ists, da\u00df er in Frieden", "tokens": ["F\u00fcnf", "Jahr", "ists", ",", "da\u00df", "er", "in", "Frie\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "lebenssatt von uns geschieden.", "tokens": ["le\u00b7bens\u00b7satt", "von", "uns", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Von der Zeit, fast selbtem Tage", "tokens": ["Von", "der", "Zeit", ",", "fast", "selb\u00b7tem", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hebt sich unser Jammer an.", "tokens": ["hebt", "sich", "un\u00b7ser", "Jam\u00b7mer", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mangelts auch an einer Plage,", "tokens": ["Man\u00b7gelts", "auch", "an", "ei\u00b7ner", "Pla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "die uns nicht ist angetan?", "tokens": ["die", "uns", "nicht", "ist", "an\u00b7ge\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Innerhalb so kurzen Jahren", "tokens": ["In\u00b7ner\u00b7halb", "so", "kur\u00b7zen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "haben wir genung erfahren.", "tokens": ["ha\u00b7ben", "wir", "ge\u00b7nung", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Gottes Hand, die b\u00f6se Seuche", "tokens": ["Got\u00b7tes", "Hand", ",", "die", "b\u00f6\u00b7se", "Seu\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hat uns d\u00fcnne satt gemacht,", "tokens": ["hat", "uns", "d\u00fcn\u00b7ne", "satt", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "die Zergliederung im Reiche", "tokens": ["die", "Zer\u00b7glie\u00b7de\u00b7rung", "im", "Rei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nahe nur nicht umbgebracht,", "tokens": ["na\u00b7he", "nur", "nicht", "umb\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "welche noch mit jungem Morgen", "tokens": ["wel\u00b7che", "noch", "mit", "jun\u00b7gem", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRELS", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "uns geb\u00e4ren neue Sorgen.", "tokens": ["uns", "ge\u00b7b\u00e4\u00b7ren", "neu\u00b7e", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Den ver\u00f6deten Gefildern", "tokens": ["Den", "ver\u00b7\u00f6\u00b7de\u00b7ten", "Ge\u00b7fil\u00b7dern"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "mangelt itzt ihr Pflug und Man;", "tokens": ["man\u00b7gelt", "itzt", "ihr", "Pflug", "und", "Man", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "KON", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "G\u00e4rt' und Matten, die verwildern,", "tokens": ["G\u00e4rt'", "und", "Mat\u00b7ten", ",", "die", "ver\u00b7wil\u00b7dern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PRELS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aller Vorrat ist vertan.", "tokens": ["al\u00b7ler", "Vor\u00b7rat", "ist", "ver\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Was wird uns ink\u00fcnftig n\u00e4hren?", "tokens": ["Was", "wird", "uns", "in\u00b7k\u00fcnf\u00b7tig", "n\u00e4h\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Hat man doch kaum itzt zu zehren.", "tokens": ["Hat", "man", "doch", "kaum", "itzt", "zu", "zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Der mit feurigen Gebeten", "tokens": ["Der", "mit", "feu\u00b7ri\u00b7gen", "Ge\u00b7be\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und mit gl\u00fcender Begier", "tokens": ["und", "mit", "gl\u00fcen\u00b7der", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "vor den b\u00f6sen Gott getreten", "tokens": ["vor", "den", "b\u00f6\u00b7sen", "Gott", "ge\u00b7tre\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und uns stets gesprochen f\u00fcr,", "tokens": ["und", "uns", "stets", "ge\u00b7spro\u00b7chen", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "VVPP", "APPR", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "den hat er drumb sterben hei\u00dfen,", "tokens": ["den", "hat", "er", "drumb", "ster\u00b7ben", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "PAV", "VVINF", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "da\u00df er uns kan sch\u00e4rfer schmei\u00dfen.", "tokens": ["da\u00df", "er", "uns", "kan", "sch\u00e4r\u00b7fer", "schmei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "So der Heilige so stirbet,", "tokens": ["So", "der", "Hei\u00b7li\u00b7ge", "so", "stir\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "was hofft ihm ein Eitler wol,", "tokens": ["was", "hofft", "ihm", "ein", "Eit\u00b7ler", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "der in dem stets mehr verdirbet,", "tokens": ["der", "in", "dem", "stets", "mehr", "ver\u00b7dir\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df er nicht verderben soll?", "tokens": ["da\u00df", "er", "nicht", "ver\u00b7der\u00b7ben", "soll", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Soll der S\u00fcnder straflos wallen", "tokens": ["Soll", "der", "S\u00fcn\u00b7der", "straf\u00b7los", "wal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und ein frommer Priester fallen?", "tokens": ["und", "ein", "from\u00b7mer", "Pries\u00b7ter", "fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Vater, euer fr\u00fches Ende", "tokens": ["Va\u00b7ter", ",", "eu\u00b7er", "fr\u00fc\u00b7hes", "En\u00b7de"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "macht, da\u00df wir uns f\u00fcrchten mehr.", "tokens": ["macht", ",", "da\u00df", "wir", "uns", "f\u00fcrch\u00b7ten", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir verkehren Haupt und H\u00e4nde", "tokens": ["Wir", "ver\u00b7keh\u00b7ren", "Haupt", "und", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und tun kl\u00e4glich mehr als sehr,", "tokens": ["und", "tun", "kl\u00e4g\u00b7lich", "mehr", "als", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PIAT", "KOKOM", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sehr, da\u00df ihr uns seid entnommen,", "tokens": ["sehr", ",", "da\u00df", "ihr", "uns", "seid", "ent\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mehr umb das, was drauf mag kommen.", "tokens": ["mehr", "umb", "das", ",", "was", "drauf", "mag", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDS", "$,", "PRELS", "PAV", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}