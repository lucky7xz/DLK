{"textgrid.poem.63389": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Davoser Elegie", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wieder bricht ein Tag mit himbeerrotem Glanz \u00fcber die verschneiten Berge.", "tokens": ["Wie\u00b7der", "bricht", "ein", "Tag", "mit", "him\u00b7beer\u00b7ro\u00b7tem", "Glanz", "\u00fc\u00b7ber", "die", "ver\u00b7schnei\u00b7ten", "Ber\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+--+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Ich wache auf und erschrecke sanft.", "tokens": ["Ich", "wa\u00b7che", "auf", "und", "er\u00b7schre\u00b7cke", "sanft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da bin ich wieder: zur\u00fcckgekehrt aus dem warmen Sarge des Schlafs", "tokens": ["Da", "bin", "ich", "wie\u00b7der", ":", "zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "aus", "dem", "war\u00b7men", "Sar\u00b7ge", "des", "Schlafs"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$.", "VVPP", "APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+--+-+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und mu\u00df schwer atmen, leicht l\u00e4cheln, seufzen, erkennen, sein.", "tokens": ["Und", "mu\u00df", "schwer", "at\u00b7men", ",", "leicht", "l\u00e4\u00b7cheln", ",", "seuf\u00b7zen", ",", "er\u00b7ken\u00b7nen", ",", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$,", "ADJD", "VVFIN", "$,", "VVINF", "$,", "VVINF", "$,", "VAINF", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Die Kuckucksuhr schl\u00e4gt neun.", "tokens": ["Die", "Ku\u00b7ckuck\u00b7suhr", "schl\u00e4gt", "neun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der Teller mit Fr\u00fcchten auf dem Nachtisch hat eine Musikmechanik in sich;", "tokens": ["Der", "Tel\u00b7ler", "mit", "Fr\u00fcch\u00b7ten", "auf", "dem", "Nach\u00b7tisch", "hat", "ei\u00b7ne", "Mu\u00b7sik\u00b7me\u00b7cha\u00b7nik", "in", "sich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "VAFIN", "ART", "NN", "APPR", "PRF", "$."], "meter": "-+--+-+-+--+--+--+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Hebt man ihn auf, spielt er Morgenrot, Morgenrot \u2013", "tokens": ["Hebt", "man", "ihn", "auf", ",", "spielt", "er", "Mor\u00b7gen\u00b7rot", ",", "Mor\u00b7gen\u00b7rot", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKVZ", "$,", "VVFIN", "PPER", "NN", "$,", "NN", "$("], "meter": "+---+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Es wird also Zeit, das Fr\u00fchst\u00fcck herbeizuklingeln.", "tokens": ["Es", "wird", "al\u00b7so", "Zeit", ",", "das", "Fr\u00fch\u00b7st\u00fcck", "her\u00b7bei\u00b7zu\u00b7klin\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Das rothaarige, morgenrothaarige, haarige Dienstm\u00e4dchen erscheint,", "tokens": ["Das", "rot\u00b7haa\u00b7ri\u00b7ge", ",", "mor\u00b7gen\u00b7rot\u00b7haa\u00b7ri\u00b7ge", ",", "haa\u00b7ri\u00b7ge", "Dienst\u00b7m\u00e4d\u00b7chen", "er\u00b7scheint", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+---+--+--+--++--+", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "Anzusehn wie Sankta Barbara, die Schutzheilige der Kanoniere.", "tokens": ["An\u00b7zu\u00b7sehn", "wie", "Sank\u00b7ta", "Bar\u00b7ba\u00b7ra", ",", "die", "Schutz\u00b7hei\u00b7li\u00b7ge", "der", "Ka\u00b7no\u00b7nie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "NE", "NE", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.7": {"text": "Weil sie der erste fr\u00fche Bote Menschheit,", "tokens": ["Weil", "sie", "der", "ers\u00b7te", "fr\u00fc\u00b7he", "Bo\u00b7te", "Menschheit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ist sie mir h\u00f6chlich verha\u00dft.", "tokens": ["Ist", "sie", "mir", "h\u00f6ch\u00b7lich", "ver\u00b7ha\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Es ist eine sch\u00f6ne Frau auf der Welt, die mich (vielleicht) liebt.", "tokens": ["Es", "ist", "ei\u00b7ne", "sch\u00f6\u00b7ne", "Frau", "auf", "der", "Welt", ",", "die", "mich", "(", "viel\u00b7leicht", ")", "liebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "$(", "ADV", "$(", "VVFIN", "$."], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Weil ich nicht sprechen kann, verschweige ich mein Herz.", "tokens": ["Weil", "ich", "nicht", "spre\u00b7chen", "kann", ",", "ver\u00b7schwei\u00b7ge", "ich", "mein", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man soll nicht zu gro\u00dfe Worte und zu gro\u00dfe Tiraden machen.", "tokens": ["Man", "soll", "nicht", "zu", "gro\u00b7\u00dfe", "Wor\u00b7te", "und", "zu", "gro\u00b7\u00dfe", "Ti\u00b7ra\u00b7den", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "PTKZU", "ADJA", "NN", "KON", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+---+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Sie werden leicht \u00fcberheblich.", "tokens": ["Sie", "wer\u00b7den", "leicht", "\u00fc\u00b7ber\u00b7heb\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Kennen den Vater nicht mehr, nicht die Mutter.", "tokens": ["Ken\u00b7nen", "den", "Va\u00b7ter", "nicht", "mehr", ",", "nicht", "die", "Mut\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ADV", "$,", "PTKNEG", "ART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Zum Beispiel Alexander der Gro\u00dfe.", "tokens": ["Zum", "Bei\u00b7spiel", "A\u00b7lex\u00b7an\u00b7der", "der", "Gro\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "ART", "ADJA", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Lassen wir das humanistische Gymnasium.", "tokens": ["Las\u00b7sen", "wir", "das", "hu\u00b7ma\u00b7nis\u00b7ti\u00b7sche", "Gym\u00b7na\u00b7si\u00b7um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.4": {"line.1": {"text": "Ein Vogel zwitschert.", "tokens": ["Ein", "Vo\u00b7gel", "zwit\u00b7schert", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Es wird ein Spatz sein,", "tokens": ["Es", "wird", "ein", "Spatz", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Der auf dem Balkon in den steinharten, gefrorenen Kuchen pickt, den ich gestern stehen lie\u00df.", "tokens": ["Der", "auf", "dem", "Bal\u00b7kon", "in", "den", "stein\u00b7har\u00b7ten", ",", "ge\u00b7fro\u00b7re\u00b7nen", "Ku\u00b7chen", "pickt", ",", "den", "ich", "ge\u00b7stern", "ste\u00b7hen", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+---+--+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Oder sollte es ein Geier sein, der seinen Prometheus sucht?", "tokens": ["O\u00b7der", "soll\u00b7te", "es", "ein", "Gei\u00b7er", "sein", ",", "der", "sei\u00b7nen", "Pro\u00b7me\u00b7theus", "sucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ART", "NN", "VAINF", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.5": {"text": "Wenn ich nach Z\u00fcrich fahre,", "tokens": ["Wenn", "ich", "nach", "Z\u00fc\u00b7rich", "fah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Kaum von den Toten auferstanden und schon wieder hehe.", "tokens": ["Kaum", "von", "den", "To\u00b7ten", "auf\u00b7er\u00b7stan\u00b7den", "und", "schon", "wie\u00b7der", "he\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "KON", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}}, "stanza.5": {"line.1": {"text": "Man modelliert mich, man zeichnet mich,", "tokens": ["Man", "mo\u00b7del\u00b7liert", "mich", ",", "man", "zeich\u00b7net", "mich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PIS", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Man schneidet mich in Holz: Engel mit der Lyra.", "tokens": ["Man", "schnei\u00b7det", "mich", "in", "Holz", ":", "En\u00b7gel", "mit", "der", "Ly\u00b7ra", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "NN", "$.", "NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-++-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Ich werde zurzeit von zwei \u00c4rzten und drei K\u00fcnstlern behandelt.", "tokens": ["Ich", "wer\u00b7de", "zur\u00b7zeit", "von", "zwei", "\u00c4rz\u00b7ten", "und", "drei", "K\u00fcnst\u00b7lern", "be\u00b7han\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "CARD", "NN", "KON", "CARD", "NN", "VVPP", "$."], "meter": "-+--+--+--++--+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Der Bildhauer M. seziert mich ausgezeichnet.", "tokens": ["Der", "Bild\u00b7hau\u00b7er", "M.", "se\u00b7ziert", "mich", "aus\u00b7ge\u00b7zeich\u00b7net", "."], "token_info": ["word", "word", "abbreviation", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "PPER", "VVPP", "$."], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Der Doktor R. hat mich (mit seinem gl\u00fchenden Stahl) fabelhaft getroffen.", "tokens": ["Der", "Dok\u00b7tor", "R.", "hat", "mich", "(", "mit", "sei\u00b7nem", "gl\u00fc\u00b7hen\u00b7den", "Stahl", ")", "fa\u00b7bel\u00b7haft", "ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "abbreviation", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "PPER", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$(", "ADJD", "VVPP", "$."], "meter": "-+--+-+-+--+--+-+-", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "Sind Sie schwach auf der Lunge:", "tokens": ["Sind", "Sie", "schwach", "auf", "der", "Lun\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Kommen Sie, besuchen Sie mich hier oben im Tal des Friedens", "tokens": ["Kom\u00b7men", "Sie", ",", "be\u00b7su\u00b7chen", "Sie", "mich", "hier", "o\u00b7ben", "im", "Tal", "des", "Frie\u00b7dens"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "VVFIN", "PPER", "PRF", "ADV", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+--+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.8": {"text": "(den Prospekt sendet Ihnen der Kurverein auf Wunsch.)!", "tokens": ["(", "den", "Pros\u00b7pekt", "sen\u00b7det", "Ih\u00b7nen", "der", "Kur\u00b7ver\u00b7ein", "auf", "Wunsch", ".", ")", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$.", "$(", "$."], "meter": "-++--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Sie werden zwar auch hier keine Ruhe finden, \u2013", "tokens": ["Sie", "wer\u00b7den", "zwar", "auch", "hier", "kei\u00b7ne", "Ru\u00b7he", "fin\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PIAT", "NN", "VVINF", "$,", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Aber Sie werden Liegekur machen, sich vollfressen,", "tokens": ["A\u00b7ber", "Sie", "wer\u00b7den", "Lie\u00b7ge\u00b7kur", "ma\u00b7chen", ",", "sich", "voll\u00b7fres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "VVINF", "$,", "PRF", "VVPP", "$,"], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Den Kehlkopf ausgebrannt bekommen, liebeln und pokern.", "tokens": ["Den", "Kehl\u00b7kopf", "aus\u00b7ge\u00b7brannt", "be\u00b7kom\u00b7men", ",", "lie\u00b7beln", "und", "po\u00b7kern", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVINF", "$,", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Sie werden einige Jahre l\u00e4nger leben.", "tokens": ["Sie", "wer\u00b7den", "ei\u00b7ni\u00b7ge", "Jah\u00b7re", "l\u00e4n\u00b7ger", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Und wir h\u00e4ngen doch alle am Leben wie die Sch\u00e4cher am Kreuz.", "tokens": ["Und", "wir", "h\u00e4n\u00b7gen", "doch", "al\u00b7le", "am", "Le\u00b7ben", "wie", "die", "Sch\u00e4\u00b7cher", "am", "Kreuz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "PIS", "APPRART", "NN", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "--+--+--+-+-+--+", "measure": "anapaest.tri.plus"}}}}}