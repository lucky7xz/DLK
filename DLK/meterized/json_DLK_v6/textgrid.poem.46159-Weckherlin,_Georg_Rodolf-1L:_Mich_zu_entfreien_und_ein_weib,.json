{"textgrid.poem.46159": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mich zu entfreien und ein weib,", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mich zu entfreien und ein weib,", "tokens": ["Mich", "zu", "ent\u00b7frei\u00b7en", "und", "ein", "weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "ja vil mehr meinen leib, zu freien,", "tokens": ["ja", "vil", "mehr", "mei\u00b7nen", "leib", ",", "zu", "frei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPOSAT", "NN", "$,", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df ihr leib mein, mein leib ihr bleib,", "tokens": ["da\u00df", "ihr", "leib", "mein", ",", "mein", "leib", "ihr", "bleib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPOSAT", "$,", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "da\u00df es mich nicht m\u00f6g widerreuen,", "tokens": ["da\u00df", "es", "mich", "nicht", "m\u00f6g", "wi\u00b7der\u00b7reu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "glaub ich, da\u00df ich vertrauen nicht", "tokens": ["glaub", "ich", ",", "da\u00df", "ich", "ver\u00b7trau\u00b7en", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "solt meines freinds mund noch gesicht:", "tokens": ["solt", "mei\u00b7nes", "freinds", "mund", "noch", "ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "\u00bbzu buhlen und sich selbs zu preisen,", "tokens": ["\u00bb", "zu", "buh\u00b7len", "und", "sich", "selbs", "zu", "prei\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKZU", "VVINF", "KON", "PRF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "kan ein man selbs das best erweisen.\u00ab", "tokens": ["kan", "ein", "man", "selbs", "das", "best", "er\u00b7wei\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "ART", "PIS", "ADV", "ART", "ADJD", "VVINF", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "In meiner wahl nun k\u00fchn und frei", "tokens": ["In", "mei\u00b7ner", "wahl", "nun", "k\u00fchn", "und", "frei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADV", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wolt ich anf\u00e4nglich gleich begehren,", "tokens": ["wolt", "ich", "an\u00b7f\u00e4ng\u00b7lich", "gleich", "be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df solcher eltern kind sie sei,", "tokens": ["da\u00df", "sol\u00b7cher", "el\u00b7tern", "kind", "sie", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die an zucht, freiheit, fromkeit, ehren", "tokens": ["die", "an", "zucht", ",", "frei\u00b7heit", ",", "from\u00b7keit", ",", "eh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "APPR", "NN", "$,", "NN", "$,", "ADJD", "$,", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "noch \u00e4lter, dan ein alt geschlecht;", "tokens": ["noch", "\u00e4l\u00b7ter", ",", "dan", "ein", "alt", "ge\u00b7schlecht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ART", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dan eine sch\u00f6nheit, die nicht schlecht", "tokens": ["dan", "ei\u00b7ne", "sch\u00f6n\u00b7heit", ",", "die", "nicht", "schlecht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "mit einem schlecht und rechten leben", "tokens": ["mit", "ei\u00b7nem", "schlecht", "und", "rech\u00b7ten", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "KON", "ADJA", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "kan das blut selten allein geben.", "tokens": ["kan", "das", "blut", "sel\u00b7ten", "al\u00b7lein", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADJD", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Zwar wei\u00df ich wol, da\u00df gute zweig", "tokens": ["Zwar", "wei\u00df", "ich", "wol", ",", "da\u00df", "gu\u00b7te", "zweig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von alten b\u00e4umen noch aufschie\u00dfen,", "tokens": ["von", "al\u00b7ten", "b\u00e4u\u00b7men", "noch", "auf\u00b7schie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "zu deren lob ich nicht verschweig,", "tokens": ["zu", "de\u00b7ren", "lob", "ich", "nicht", "ver\u00b7schweig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df ihres stammens sie genie\u00dfen,", "tokens": ["da\u00df", "ih\u00b7res", "stam\u00b7mens", "sie", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und darum wert, da\u00df man sie ehr;", "tokens": ["und", "da\u00b7rum", "wert", ",", "da\u00df", "man", "sie", "ehr", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ADJD", "$,", "KOUS", "PIS", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "doch ich vermein auch, da\u00df je mehr", "tokens": ["doch", "ich", "ver\u00b7mein", "auch", ",", "da\u00df", "je", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ADV", "$,", "KOUS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "ein berg sich in die h\u00f6hin strecket,", "tokens": ["ein", "berg", "sich", "in", "die", "h\u00f6\u00b7hin", "stre\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "je b\u00e4lder er mit schnee bedecket.", "tokens": ["je", "b\u00e4l\u00b7der", "er", "mit", "schnee", "be\u00b7de\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Forchtlos nu f\u00fcr der reu zu sein,", "tokens": ["Forcht\u00b7los", "nu", "f\u00fcr", "der", "reu", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ART", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die uns zu spat doch bald erschleichet,", "tokens": ["die", "uns", "zu", "spat", "doch", "bald", "er\u00b7schlei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKZU", "VVFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "soll meine wahl nicht auf den schein,", "tokens": ["soll", "mei\u00b7ne", "wahl", "nicht", "auf", "den", "schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sondern recht n\u00fctzlich sein bereichet.", "tokens": ["son\u00b7dern", "recht", "n\u00fctz\u00b7lich", "sein", "be\u00b7rei\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAINF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "\u00bbwer seine freiheit gibt dahin", "tokens": ["\u00bb", "wer", "sei\u00b7ne", "frei\u00b7heit", "gibt", "da\u00b7hin"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PWS", "PPOSAT", "NN", "VVFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "um stands und um gesichts gewin,", "tokens": ["um", "stands", "und", "um", "ge\u00b7sichts", "ge\u00b7win", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "KON", "APPR", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "der kaufet ein pferd zu prachtieren,", "tokens": ["der", "kau\u00b7fet", "ein", "pferd", "zu", "prach\u00b7tie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "darauf er schimpflich mag verlieren.\u00ab", "tokens": ["da\u00b7rauf", "er", "schimpf\u00b7lich", "mag", "ver\u00b7lie\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "PPER", "ADJD", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Jedoch wolt ich sie an statur", "tokens": ["Je\u00b7doch", "wolt", "ich", "sie", "an", "sta\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und leibs sch\u00f6nheit vollkommen haben", "tokens": ["und", "leibs", "sch\u00f6n\u00b7heit", "voll\u00b7kom\u00b7men", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und da\u00df sie, ganz sch\u00f6n von natur,", "tokens": ["und", "da\u00df", "sie", ",", "ganz", "sch\u00f6n", "von", "na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$,", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "solt aller augen stracks erlaben:", "tokens": ["solt", "al\u00b7ler", "au\u00b7gen", "stracks", "er\u00b7la\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "gleich wie die sonn solt sie sch\u00f6n sein,", "tokens": ["gleich", "wie", "die", "sonn", "solt", "sie", "sch\u00f6n", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df sie mit unbeflecktem schein,", "tokens": ["da\u00df", "sie", "mit", "un\u00b7be\u00b7fleck\u00b7tem", "schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "von allen augen zwar gesehen,", "tokens": ["von", "al\u00b7len", "au\u00b7gen", "zwar", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "m\u00f6g doch nur bei mir nidergehen.", "tokens": ["m\u00f6g", "doch", "nur", "bei", "mir", "ni\u00b7der\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "So darf sie auch nicht sein gelehrt,", "tokens": ["So", "darf", "sie", "auch", "nicht", "sein", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VAINF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vil sprachen darf sie nicht studieren,", "tokens": ["vil", "spra\u00b7chen", "darf", "sie", "nicht", "stu\u00b7die\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "des weibs verstand ist schon gnug wert,", "tokens": ["des", "weibs", "ver\u00b7stand", "ist", "schon", "gnug", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der gnug ist, ihr haus gnug zu zieren.", "tokens": ["der", "gnug", "ist", ",", "ihr", "haus", "gnug", "zu", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "$,", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.5": {"text": "die ein gespr\u00e4ch nur f\u00fcr mich hab,", "tokens": ["die", "ein", "ge\u00b7spr\u00e4ch", "nur", "f\u00fcr", "mich", "hab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "ADV", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "beweisend sie ein gottesgab,", "tokens": ["be\u00b7wei\u00b7send", "sie", "ein", "got\u00b7tes\u00b7gab", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die mehr nicht, dan mein thun und lassen", "tokens": ["die", "mehr", "nicht", ",", "dan", "mein", "thun", "und", "las\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PTKNEG", "$,", "ADV", "PPOSAT", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "thu (als mein spiegel) in sich fassen.", "tokens": ["thu", "(", "als", "mein", "spie\u00b7gel", ")", "in", "sich", "fas\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "PPOSAT", "NN", "$(", "APPR", "PRF", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.7": {"line.1": {"text": "Ich wolt gar nicht, da\u00df sie mit glimpf", "tokens": ["Ich", "wolt", "gar", "nicht", ",", "da\u00df", "sie", "mit", "glimpf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "solt jemand wollen vil vexieren,", "tokens": ["solt", "je\u00b7mand", "wol\u00b7len", "vil", "ve\u00b7xie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "vil weniger mit spot und schimpf", "tokens": ["vil", "we\u00b7ni\u00b7ger", "mit", "spot", "und", "schimpf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "verlachen, zanken und stumpfieren;", "tokens": ["ver\u00b7la\u00b7chen", ",", "zan\u00b7ken", "und", "stump\u00b7fie\u00b7ren", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "verachten soll sie b\u00f6se blick", "tokens": ["ver\u00b7ach\u00b7ten", "soll", "sie", "b\u00f6\u00b7se", "blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "VMFIN", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und schandlicher geberden st\u00fcck", "tokens": ["und", "schand\u00b7li\u00b7cher", "ge\u00b7ber\u00b7den", "st\u00fcck"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.7": {"text": "und b\u00f6se buhler f\u00f6rchten machen", "tokens": ["und", "b\u00f6\u00b7se", "buh\u00b7ler", "f\u00f6rch\u00b7ten", "ma\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ihr f\u00fcr zu bringen b\u00f6se sachen.", "tokens": ["ihr", "f\u00fcr", "zu", "brin\u00b7gen", "b\u00f6\u00b7se", "sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PTKZU", "VVINF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Da\u00df sie niemals ab dem werd rot", "tokens": ["Da\u00df", "sie", "nie\u00b7mals", "ab", "dem", "werd", "rot"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "VAFIN", "ADJD"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "was sie begangen und versaumet;", "tokens": ["was", "sie", "be\u00b7gan\u00b7gen", "und", "ver\u00b7sau\u00b7met", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie sei keusch, ohn schand und spot,", "tokens": ["da\u00df", "sie", "sei", "keusch", ",", "ohn", "schand", "und", "spot", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "$,", "KOUI", "VVFIN", "KON", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "da\u00df ihr nichts b\u00f6ses je getraumet;", "tokens": ["da\u00df", "ihr", "nichts", "b\u00f6\u00b7ses", "je", "ge\u00b7trau\u00b7met", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADJA", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbdan die jungfrau, in deren brust", "tokens": ["\u00bb", "dan", "die", "jung\u00b7frau", ",", "in", "de\u00b7ren", "brust"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "ART", "ADJD", "$,", "APPR", "PRELAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "sich einmal nistet b\u00f6se lust,", "tokens": ["sich", "ein\u00b7mal", "nis\u00b7tet", "b\u00f6\u00b7se", "lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die hat, eh sie thut b\u00f6se thaten,", "tokens": ["die", "hat", ",", "eh", "sie", "thut", "b\u00f6\u00b7se", "tha\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "KOUS", "PPER", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die vestung ihrer zucht verrathen.\u00ab", "tokens": ["die", "ves\u00b7tung", "ih\u00b7rer", "zucht", "ver\u00b7ra\u00b7then", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Stets soll sie mit forcht, scham und ehr,", "tokens": ["Stets", "soll", "sie", "mit", "forcht", ",", "scham", "und", "ehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "VVFIN", "$,", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wan ich sie herze, der lieb pflegen:", "tokens": ["wan", "ich", "sie", "her\u00b7ze", ",", "der", "lieb", "pfle\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVFIN", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "+--+--++-", "measure": "dactylic.di.plus"}, "line.3": {"text": "doch wolt ich, da\u00df sie fruchtbar w\u00e4r,", "tokens": ["doch", "wolt", "ich", ",", "da\u00df", "sie", "frucht\u00b7bar", "w\u00e4r", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mehr namens, dan nur wollusts wegen.", "tokens": ["mehr", "na\u00b7mens", ",", "dan", "nur", "wol\u00b7lusts", "we\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ADV", "ADV", "ADV", "APPR", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbdan die, so in dem werk schamhaft,", "tokens": ["\u00bb", "dan", "die", ",", "so", "in", "dem", "werk", "scham\u00b7haft", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "$,", "ADV", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "hat stets ein neue jungfrauschaft,", "tokens": ["hat", "stets", "ein", "neu\u00b7e", "jung\u00b7frausc\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und die zucht kan die treu erhalten", "tokens": ["und", "die", "zucht", "kan", "die", "treu", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VMFIN", "ART", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und l\u00e4\u00dft den heurat nicht veralten.\u00ab", "tokens": ["und", "l\u00e4\u00dft", "den", "heu\u00b7rat", "nicht", "ver\u00b7al\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "VVFIN", "PTKNEG", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sie soll, wan sie mir gibt die hand", "tokens": ["Sie", "soll", ",", "wan", "sie", "mir", "gibt", "die", "hand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "PWAV", "PPER", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "verlobend sich, in ihr herz graben,", "tokens": ["ver\u00b7lo\u00b7bend", "sich", ",", "in", "ihr", "herz", "gra\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PRF", "$,", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "wie durch des ehstands starkes band", "tokens": ["wie", "durch", "des", "eh\u00b7stands", "star\u00b7kes", "band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "got aus uns beeden eins w\u00f6l haben,", "tokens": ["got", "aus", "uns", "bee\u00b7den", "eins", "w\u00f6l", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "ADJD", "CARD", "NN", "VAFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "und bitten got von herzengrund,", "tokens": ["und", "bit\u00b7ten", "got", "von", "her\u00b7zen\u00b7grund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df wir zugleich in guter stund", "tokens": ["da\u00df", "wir", "zu\u00b7gleich", "in", "gu\u00b7ter", "stund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "(als Aarons steck) beed hie auf erden", "tokens": ["(", "als", "Aa\u00b7rons", "steck", ")", "beed", "hie", "auf", "er\u00b7den"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "NE", "NE", "$(", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "frisch gr\u00fcnen, fruchtbar und d\u00fcrr werden.", "tokens": ["frisch", "gr\u00fc\u00b7nen", ",", "frucht\u00b7bar", "und", "d\u00fcrr", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-++--", "measure": "unknown.measure.tetra"}}}}}