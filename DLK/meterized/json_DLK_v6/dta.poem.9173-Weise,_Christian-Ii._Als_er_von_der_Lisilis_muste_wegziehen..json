{"dta.poem.9173": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n Als er von der Lisilis muste wegziehen.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr m\u00e4dgen von der Pleisse/", "tokens": ["Ihr", "m\u00e4d\u00b7gen", "von", "der", "Pleis\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die ihr mit h\u00f6chstem fleisse", "tokens": ["Die", "ihr", "mit", "h\u00f6chs\u00b7tem", "fleis\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die h\u00f6flichkeit studirt/", "tokens": ["Die", "h\u00f6f\u00b7lich\u00b7keit", "stu\u00b7dirt", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und aller m\u00e4nner hertzen", "tokens": ["Und", "al\u00b7ler", "m\u00e4n\u00b7ner", "hert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Durch euer s\u00fcsses schertzen", "tokens": ["Durch", "eu\u00b7er", "s\u00fcs\u00b7ses", "schert\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als wie gefangen f\u00fchrt.", "tokens": ["Als", "wie", "ge\u00b7fan\u00b7gen", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Ich mu\u00df es zwar gestehen/", "tokens": ["Ich", "mu\u00df", "es", "zwar", "ge\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Jhr k\u00f6nnet sachte gehen", "tokens": ["Ihr", "k\u00f6n\u00b7net", "sach\u00b7te", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und etwas h\u00f6hnisch seyn/", "tokens": ["Und", "et\u00b7was", "h\u00f6h\u00b7nisch", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Doch wenn wir eure wangen", "tokens": ["Doch", "wenn", "wir", "eu\u00b7re", "wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit voller lust empfangen.", "tokens": ["Mit", "vol\u00b7ler", "lust", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Geht alles lieblich ein.", "tokens": ["Geht", "al\u00b7les", "lieb\u00b7lich", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}