{"textgrid.poem.39413": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Florentiner! Florentiner!", "genre": "verse", "period": "N.A.", "pub_year": 1799, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Florentiner! Florentiner!", "tokens": ["Flo\u00b7ren\u00b7ti\u00b7ner", "!", "Flo\u00b7ren\u00b7ti\u00b7ner", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Was mu\u00df euren Sinn verkehren,", "tokens": ["Was", "mu\u00df", "eu\u00b7ren", "Sinn", "ver\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihr eure gro\u00dfen M\u00e4nner", "tokens": ["Da\u00df", "ihr", "eu\u00b7re", "gro\u00b7\u00dfen", "M\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Fremden \u00fcberla\u00dft zu ehren?", "tokens": ["Frem\u00b7den", "\u00fc\u00b7berl\u00b7a\u00dft", "zu", "eh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Dante, welcher g\u00f6ttlich hei\u00dfet,", "tokens": ["Dan\u00b7te", ",", "wel\u00b7cher", "g\u00f6tt\u00b7lich", "hei\u00b7\u00dfet", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Klagt, da\u00df ihn sein Land versto\u00dfe;", "tokens": ["Klagt", ",", "da\u00df", "ihn", "sein", "Land", "ver\u00b7sto\u00b7\u00dfe", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sein verbannter Leib ruht ferne", "tokens": ["Sein", "ver\u00b7bann\u00b7ter", "Leib", "ruht", "fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von der harten Mutter Schoo\u00dfe.", "tokens": ["Von", "der", "har\u00b7ten", "Mut\u00b7ter", "Schoo\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und der alte Leonardo,", "tokens": ["Und", "der", "al\u00b7te", "Le\u00b7o\u00b7nar\u00b7do", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NE", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Weilte bei euch, halb verge\u00dfen,", "tokens": ["Weil\u00b7te", "bei", "euch", ",", "halb", "ver\u00b7ge\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der an euren Kriegesthaten", "tokens": ["Der", "an", "eu\u00b7ren", "Krie\u00b7gest\u00b7ha\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jung des Pinsels Kraft geme\u00dfen.", "tokens": ["Jung", "des", "Pin\u00b7sels", "Kraft", "ge\u00b7me\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Zwar ein Stern, der hoch und herrlich", "tokens": ["Zwar", "ein", "Stern", ",", "der", "hoch", "und", "herr\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An der K\u00fcnste Himmel funkelt,", "tokens": ["An", "der", "K\u00fcns\u00b7te", "Him\u00b7mel", "fun\u00b7kelt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Michel Angel Buonaroti,", "tokens": ["Mi\u00b7chel", "An\u00b7gel", "Buo\u00b7na\u00b7ro\u00b7ti", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hatte seinen Ruhm verdunkelt.", "tokens": ["Hat\u00b7te", "sei\u00b7nen", "Ruhm", "ver\u00b7dun\u00b7kelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Dieser strebt in wildem Trotze", "tokens": ["Die\u00b7ser", "strebt", "in", "wil\u00b7dem", "Trot\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Natur zu unterjochen;", "tokens": ["Die", "Na\u00b7tur", "zu", "un\u00b7ter\u00b7jo\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener bildet, sinnig forschend,", "tokens": ["Je\u00b7ner", "bil\u00b7det", ",", "sin\u00b7nig", "for\u00b7schend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "VVFIN", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was sie leis' ihm ausgesprochen.", "tokens": ["Was", "sie", "leis'", "ihm", "aus\u00b7ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "PPER", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Nicht den Stolzen duldend mu\u00df er", "tokens": ["Nicht", "den", "Stol\u00b7zen", "dul\u00b7dend", "mu\u00df", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ART", "NN", "ADJD", "VMFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch zu fremdem Volk und andern", "tokens": ["Noch", "zu", "frem\u00b7dem", "Volk", "und", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN", "KON", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Menschen, aus Florenz, der sch\u00f6nen,", "tokens": ["Men\u00b7schen", ",", "aus", "Flo\u00b7renz", ",", "der", "sch\u00f6\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "NE", "$,", "ART", "ADJA", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Ein bejahrter Pilger wandern.", "tokens": ["Ein", "be\u00b7jahr\u00b7ter", "Pil\u00b7ger", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ritter Franz, der edle K\u00f6nig,", "tokens": ["Rit\u00b7ter", "Franz", ",", "der", "ed\u00b7le", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rief den weisesten der Mahler,", "tokens": ["Rief", "den", "wei\u00b7ses\u00b7ten", "der", "Mah\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "ART", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Gab ihm Raum nach Lust zu schaffen,", "tokens": ["Gab", "ihm", "Raum", "nach", "Lust", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hoch zu ehren ihn befahl er.", "tokens": ["Hoch", "zu", "eh\u00b7ren", "ihn", "be\u00b7fahl", "er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "PPER", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Zur Vollbringung der Entw\u00fcrfe", "tokens": ["Zur", "Voll\u00b7brin\u00b7gung", "der", "Ent\u00b7w\u00fcr\u00b7fe"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Scheint ihn neuer Muth zu st\u00e4rken;", "tokens": ["Scheint", "ihn", "neu\u00b7er", "Muth", "zu", "st\u00e4r\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber bald h\u00f6rt man ihn klagen", "tokens": ["A\u00b7ber", "bald", "h\u00f6rt", "man", "ihn", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PPER", "VVINF"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Ueber angefangnen Werken:", "tokens": ["Ue\u00b7ber", "an\u00b7ge\u00b7fang\u00b7nen", "Wer\u00b7ken", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sieh, mein Leben ist am Ziele,", "tokens": ["Sieh", ",", "mein", "Le\u00b7ben", "ist", "am", "Zie\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und die Kunst noch kaum begonnen,", "tokens": ["Und", "die", "Kunst", "noch", "kaum", "be\u00b7gon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Haben gleich mir gute Parcen", "tokens": ["Ha\u00b7ben", "gleich", "mir", "gu\u00b7te", "Par\u00b7cen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPER", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Lang den Faden ausgesponnen.", "tokens": ["Lang", "den", "Fa\u00b7den", "aus\u00b7ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Weit in unentdeckte Fernen", "tokens": ["Weit", "in", "un\u00b7ent\u00b7deck\u00b7te", "Fer\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Breiten Klarheit die Gedanken,", "tokens": ["Brei\u00b7ten", "Klar\u00b7heit", "die", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch das N\u00e4chste zu vollenden,", "tokens": ["Doch", "das", "N\u00e4chs\u00b7te", "zu", "voll\u00b7en\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchl' ich meine Hand erkranken.", "tokens": ["F\u00fchl'", "ich", "mei\u00b7ne", "Hand", "er\u00b7kran\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und er mu\u00dfte wider Willen", "tokens": ["Und", "er", "mu\u00df\u00b7te", "wi\u00b7der", "Wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hin sich strecken auf das Lager;", "tokens": ["Hin", "sich", "stre\u00b7cken", "auf", "das", "La\u00b7ger", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcrdig sch\u00f6n in siechem Alter,", "tokens": ["W\u00fcr\u00b7dig", "sch\u00f6n", "in", "sie\u00b7chem", "Al\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00df von Bart und still und hager.", "tokens": ["Wei\u00df", "von", "Bart", "und", "still", "und", "ha\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Als der K\u00f6nig das vernommen,", "tokens": ["Als", "der", "K\u00f6\u00b7nig", "das", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcllt es ihn mit bangen Schmerzen,", "tokens": ["F\u00fcllt", "es", "ihn", "mit", "ban\u00b7gen", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn er hielt ihn wie ein Kleinod", "tokens": ["Denn", "er", "hielt", "ihn", "wie", "ein", "Klei\u00b7nod"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "KOKOM", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seinem Reich und seinem Herzen.", "tokens": ["Sei\u00b7nem", "Reich", "und", "sei\u00b7nem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Eilig wie zu einem Vater,", "tokens": ["Ei\u00b7lig", "wie", "zu", "ei\u00b7nem", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tritt er in des Kranken Zimmer,", "tokens": ["Tritt", "er", "in", "des", "Kran\u00b7ken", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kommen sieht ihn Leonardo", "tokens": ["Kom\u00b7men", "sieht", "ihn", "Le\u00b7o\u00b7nar\u00b7do"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "NE"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit des Augs erloschnem Schimmer.", "tokens": ["Mit", "des", "Augs", "er\u00b7lo\u00b7schnem", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Und er will empor sich richten,", "tokens": ["Und", "er", "will", "em\u00b7por", "sich", "rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seinen jungen Freund zu segnen,", "tokens": ["Sei\u00b7nen", "jun\u00b7gen", "Freund", "zu", "seg\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Dessen Arme, dessen H\u00e4nde", "tokens": ["Des\u00b7sen", "Ar\u00b7me", ",", "des\u00b7sen", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebreich st\u00fctzend ihm begegnen.", "tokens": ["Lieb\u00b7reich", "st\u00fct\u00b7zend", "ihm", "be\u00b7geg\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Heiter l\u00e4chelt noch sein Antlitz,", "tokens": ["Hei\u00b7ter", "l\u00e4\u00b7chelt", "noch", "sein", "Ant\u00b7litz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon erbla\u00dft wie einem Todten:", "tokens": ["Schon", "er\u00b7bla\u00dft", "wie", "ei\u00b7nem", "Tod\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber halb im Mund erstorben", "tokens": ["A\u00b7ber", "halb", "im", "Mund", "ers\u00b7tor\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist der Gru\u00df sein letzter Othem.", "tokens": ["Ist", "der", "Gru\u00df", "sein", "letz\u00b7ter", "O\u00b7them", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Lange harrt der K\u00f6nig schweigend,", "tokens": ["Lan\u00b7ge", "harrt", "der", "K\u00f6\u00b7nig", "schwei\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ob er nicht erwachen werde. \u2013", "tokens": ["Ob", "er", "nicht", "er\u00b7wa\u00b7chen", "wer\u00b7de", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VAFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbruh der kunstbegabten Seele!", "tokens": ["\u00bb", "ruh", "der", "kunst\u00b7be\u00b7gab\u00b7ten", "See\u00b7le", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dem Leib sei leicht die Erde!", "tokens": ["Und", "dem", "Leib", "sei", "leicht", "die", "Er\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Keine Weisheit, keine Tugend", "tokens": ["Kei\u00b7ne", "Weis\u00b7heit", ",", "kei\u00b7ne", "Tu\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kann das herbe Schicksal wenden.", "tokens": ["Kann", "das", "her\u00b7be", "Schick\u00b7sal", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was der Tod ihm st\u00f6rte, wird es", "tokens": ["Was", "der", "Tod", "ihm", "st\u00f6r\u00b7te", ",", "wird", "es"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ART", "NN", "PPER", "VVFIN", "$,", "VAFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Je ein geist'ger Sohn vollenden?", "tokens": ["Je", "ein", "geist'\u00b7ger", "Sohn", "voll\u00b7en\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Darum, weil dies Leben dauert,", "tokens": ["Da\u00b7rum", ",", "weil", "dies", "Le\u00b7ben", "dau\u00b7ert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PDS", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "La\u00dft den Heldentrieb entbrennen.", "tokens": ["La\u00dft", "den", "Hel\u00b7den\u00b7trieb", "ent\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie dein ernster Spruch mich lehrte:", "tokens": ["Wie", "dein", "erns\u00b7ter", "Spruch", "mich", "lehr\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich soll, das will ich k\u00f6nnen!\u00ab", "tokens": ["Was", "ich", "soll", ",", "das", "will", "ich", "k\u00f6n\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "PPER", "VMFIN", "$,", "PDS", "VMFIN", "PPER", "VMFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}