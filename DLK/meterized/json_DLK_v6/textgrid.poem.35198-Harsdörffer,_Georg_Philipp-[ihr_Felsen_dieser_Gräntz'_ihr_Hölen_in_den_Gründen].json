{"textgrid.poem.35198": {"metadata": {"author": {"name": "Harsd\u00f6rffer, Georg Philipp", "birth": "N.A.", "death": "N.A."}, "title": "[ihr Felsen dieser Gr\u00e4ntz'/ ihr H\u00f6len in den Gr\u00fcnden]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Felsen dieser Gr\u00e4ntz'/ ihr H\u00f6len in den Gr\u00fcnd\u0113/", "tokens": ["Ihr", "Fel\u00b7sen", "die\u00b7ser", "Gr\u00e4nt\u00b7z'", "/", "ihr", "H\u00f6\u00b7len", "in", "den", "Gr\u00fcn\u00b7d\u0113", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PDAT", "NN", "$(", "PPOSAT", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihr T\u00e4hler/ du Geb\u00fcsch/ lasst/ was ich suche/ finden.", "tokens": ["Ihr", "T\u00e4h\u00b7ler", "/", "du", "Ge\u00b7b\u00fcsch", "/", "lasst", "/", "was", "ich", "su\u00b7che", "/", "fin\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPER", "NN", "$(", "VVFIN", "$(", "PWS", "PPER", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es liebt ja eure Luft die Luft/ nach der ich sp\u00fcr?", "tokens": ["Es", "liebt", "ja", "eu\u00b7re", "Luft", "die", "Luft", "/", "nach", "der", "ich", "sp\u00fcr", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "ART", "NN", "$(", "APPR", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier hallt ein Gegenhall. Sprich/ Echo bistu hier?", "tokens": ["Hier", "hallt", "ein", "Ge\u00b7gen\u00b7hall", ".", "Sprich", "/", "E\u00b7cho", "bis\u00b7tu", "hier", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "NN", "$(", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Echo. du hier?", "tokens": ["E\u00b7cho", ".", "du", "hier", "?"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "ADV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "Mich h\u00f6rstu wohl/ wohlan/ vernehme was ich sage/", "tokens": ["Mich", "h\u00f6rs\u00b7tu", "wohl", "/", "wo\u00b7hlan", "/", "ver\u00b7neh\u00b7me", "was", "ich", "sa\u00b7ge", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "ADV", "$(", "VVFIN", "PWS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gieb Antwort meinem Wort/ sag aus/was ich dich frage.", "tokens": ["Gieb", "Ant\u00b7wort", "mei\u00b7nem", "Wort", "/", "sag", "aus", "/", "was", "ich", "dich", "fra\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "PPOSAT", "NN", "$(", "VVIMP", "PTKVZ", "$(", "PWS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "E. frage.", "tokens": ["E.", "fra\u00b7ge", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Sag' an/ was zwinget mich von dannen in der Still?", "tokens": ["Sag'", "an", "/", "was", "zwin\u00b7get", "mich", "von", "dan\u00b7nen", "in", "der", "Still", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$(", "PWS", "VVFIN", "PRF", "APPR", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was machet/ da\u00df ich mehr der Orten nicht seyn will?", "tokens": ["Was", "ma\u00b7chet", "/", "da\u00df", "ich", "mehr", "der", "Or\u00b7ten", "nicht", "seyn", "will", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "KOUS", "PPER", "ADV", "ART", "NN", "PTKNEG", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "E. Ein Will.", "tokens": ["E.", "Ein", "Will", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NE", "ART", "NE", "$."], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Ein Will/ das wei\u00df ich vor/ ich hab es selbst vernommen.", "tokens": ["Ein", "Will", "/", "das", "wei\u00df", "ich", "vor", "/", "ich", "hab", "es", "selbst", "ver\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$(", "PDS", "VVFIN", "PPER", "PTKVZ", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wird/ sage/ nach der Hand mir dieser Wechsel frommen?", "tokens": ["Wird", "/", "sa\u00b7ge", "/", "nach", "der", "Hand", "mir", "die\u00b7ser", "Wech\u00b7sel", "from\u00b7men", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "VVFIN", "$(", "APPR", "ART", "NN", "PPER", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "E. frommen.", "tokens": ["E.", "from\u00b7men", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "ADJA", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Wohl/ aber/ wie? durch wen? und wann k\u00f6mt der Genu\u00df?", "tokens": ["Wohl", "/", "a\u00b7ber", "/", "wie", "?", "durch", "wen", "?", "und", "wann", "k\u00f6mt", "der", "Ge\u00b7nu\u00df", "?"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "$(", "PWAV", "$.", "APPR", "PWS", "$.", "KON", "PWAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.11": {"text": "Er mu\u00df nicht ferne seyn/ weil da\u00df ich fort schon mu\u00df.", "tokens": ["Er", "mu\u00df", "nicht", "fer\u00b7ne", "seyn", "/", "weil", "da\u00df", "ich", "fort", "schon", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "VAINF", "$(", "KOUS", "KOUS", "PPER", "PTKVZ", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "E. ohn mu\u00df.", "tokens": ["E.", "ohn", "mu\u00df", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NN", "APPR", "VMFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Ohn Mus/ das frag' ich nicht/ ich mag mich selbst nicht s\u00e4umen.", "tokens": ["Ohn", "Mus", "/", "das", "frag'", "ich", "nicht", "/", "ich", "mag", "mich", "selbst", "nicht", "s\u00e4u\u00b7men", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$(", "PDS", "VVFIN", "PPER", "PTKNEG", "$(", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Was wird/ sag her/ f\u00fcr Gl\u00fckk zu meinem Wunsch sich reimen?", "tokens": ["Was", "wird", "/", "sag", "her", "/", "f\u00fcr", "Gl\u00fckk", "zu", "mei\u00b7nem", "Wunsch", "sich", "rei\u00b7men", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$(", "VVIMP", "PTKVZ", "$(", "APPR", "NN", "APPR", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "E. Reimen.", "tokens": ["E.", "Rei\u00b7men", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.16": {"text": "Was/ Reimen? reime du/ dein Reden reimt sich nicht:", "tokens": ["Was", "/", "Rei\u00b7men", "?", "rei\u00b7me", "du", "/", "dein", "Re\u00b7den", "reimt", "sich", "nicht", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$(", "NN", "$.", "VVFIN", "PPER", "$(", "PPOSAT", "NN", "VVFIN", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ich w\u00fcnsch/ nicht was ich hab/ vielmehr was mir gebricht.", "tokens": ["Ich", "w\u00fcnsch", "/", "nicht", "was", "ich", "hab", "/", "viel\u00b7mehr", "was", "mir", "ge\u00b7bricht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PTKNEG", "PWS", "PPER", "VAFIN", "$(", "ADV", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "E. gebricht.", "tokens": ["E.", "ge\u00b7bricht", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.19": {"text": "Gebricht mir Reimekunst/ was fehlet diesen Zeilen?", "tokens": ["Ge\u00b7bricht", "mir", "Rei\u00b7me\u00b7kunst", "/", "was", "feh\u00b7let", "die\u00b7sen", "Zei\u00b7len", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "$(", "PWS", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Sie sind gesund und gut/ man darf daran nicht heilen.", "tokens": ["Sie", "sind", "ge\u00b7sund", "und", "gut", "/", "man", "darf", "da\u00b7ran", "nicht", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "ADJD", "$(", "PIS", "VMFIN", "PAV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "E. heilen.", "tokens": ["E.", "hei\u00b7len", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.22": {"text": "Was fehlet ihnen dann? Wo hinket ihre Zier?", "tokens": ["Was", "feh\u00b7let", "ih\u00b7nen", "dann", "?", "Wo", "hin\u00b7ket", "ih\u00b7re", "Zier", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PWAV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Im Band: der Dichtungsart: an Kunst: an Wortgeb\u00fcr?", "tokens": ["Im", "Band", ":", "der", "Dich\u00b7tungs\u00b7art", ":", "an", "Kunst", ":", "an", "Wort\u00b7ge\u00b7b\u00fcr", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ART", "NN", "$.", "APPR", "NN", "$.", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "E. Geb\u00fcr.", "tokens": ["E.", "Ge\u00b7b\u00fcr", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.25": {"text": "So meinst du/ da\u00df Geb\u00fcr in allem dem ermangle/", "tokens": ["So", "meinst", "du", "/", "da\u00df", "Ge\u00b7b\u00fcr", "in", "al\u00b7lem", "dem", "er\u00b7mang\u00b7le", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOUS", "NN", "APPR", "PIS", "ART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "An Mangel mangle nicht? Sag/ wo ich b\u00e4ssers angle.", "tokens": ["An", "Man\u00b7gel", "mang\u00b7le", "nicht", "?", "Sag", "/", "wo", "ich", "b\u00e4s\u00b7sers", "ang\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKNEG", "$.", "NN", "$(", "PWAV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "E. angle.", "tokens": ["E.", "ang\u00b7le", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.28": {"text": "So gib den Angel her/ und zeig mir einen Rand/", "tokens": ["So", "gib", "den", "An\u00b7gel", "her", "/", "und", "zeig", "mir", "ei\u00b7nen", "Rand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wo werf' ich dann? vielleicht die Pegnitz ist der Strand?", "tokens": ["Wo", "wer\u00b7f'", "ich", "dann", "?", "viel\u00b7leicht", "die", "Peg\u00b7nitz", "ist", "der", "Strand", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "$.", "ADV", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.30": {"text": "E. der Strand.", "tokens": ["E.", "der", "Strand", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.31": {"text": "Ha/ ha/ du machst es bunt/ so lehren mich die Fische?", "tokens": ["Ha", "/", "ha", "/", "du", "machst", "es", "bunt", "/", "so", "leh\u00b7ren", "mich", "die", "Fi\u00b7sche", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Ihr h\u00f6nt/ ihr R\u00fclzen/ mich/ ihr \u00fcngeh\u00f6ften B\u00fcsche.", "tokens": ["Ihr", "h\u00f6nt", "/", "ihr", "R\u00fcl\u00b7zen", "/", "mich", "/", "ihr", "\u00fcn\u00b7ge\u00b7h\u00f6f\u00b7ten", "B\u00fc\u00b7sche", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPOSAT", "NN", "$(", "PPER", "$(", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "E. B\u00fcsche.", "tokens": ["E.", "B\u00fc\u00b7sche", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.34": {"text": "Nun sollens B\u00fcsche thun/ zuvor der Schuppenschwantz/", "tokens": ["Nun", "sol\u00b7lens", "B\u00fc\u00b7sche", "thun", "/", "zu\u00b7vor", "der", "Schup\u00b7pen\u00b7schwantz", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVINF", "$(", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "So macht sie dann gelehrt ein lauter Sch\u00e4ferdantz.", "tokens": ["So", "macht", "sie", "dann", "ge\u00b7lehrt", "ein", "lau\u00b7ter", "Sch\u00e4\u00b7fer\u00b7dantz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "E. der Dantz.", "tokens": ["E.", "der", "Dantz", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.37": {"text": "Der Dantz/ wie wahr bin ich? du spottst noch immer meiner/", "tokens": ["Der", "Dantz", "/", "wie", "wahr", "bin", "ich", "?", "du", "spottst", "noch", "im\u00b7mer", "mei\u00b7ner", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWAV", "ADJD", "VAFIN", "PPER", "$.", "PPER", "VVFIN", "ADV", "ADV", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wer singt die Lieder vor? ist an der Pegnitz keiner?", "tokens": ["Wer", "singt", "die", "Lie\u00b7der", "vor", "?", "ist", "an", "der", "Peg\u00b7nitz", "kei\u00b7ner", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKVZ", "$.", "VAFIN", "APPR", "ART", "NN", "PIS", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "E. Einer.", "tokens": ["E.", "Ei\u00b7ner", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "PIS", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.40": {"text": "Sih da/ du triffst es schier: Die Pegnitz br\u00fcstet sich/", "tokens": ["Sih", "da", "/", "du", "triffst", "es", "schier", ":", "Die", "Peg\u00b7nitz", "br\u00fcs\u00b7tet", "sich", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$.", "ART", "NN", "VVFIN", "PRF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Weil da\u00df sie Strephon hat. F\u00fcrwar jetzt merk ich dich/", "tokens": ["Weil", "da\u00df", "sie", "Stre\u00b7phon", "hat", ".", "F\u00fcr\u00b7war", "jetzt", "merk", "ich", "dich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "VAFIN", "$.", "ADV", "ADV", "VVFIN", "PPER", "PRF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "E. ich dich.", "tokens": ["E.", "ich", "dich", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NE", "PPER", "PRF", "$."], "meter": "-+", "measure": "iambic.single"}, "line.43": {"text": "So meinstu/ da\u00df ich dort werd Strephons Gonst gewinnen?", "tokens": ["So", "meins\u00b7tu", "/", "da\u00df", "ich", "dort", "werd", "Stre\u00b7phons", "Gonst", "ge\u00b7win\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "KOUS", "PPER", "ADV", "VAFIN", "NE", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "So werd ich sein verm\u00e4ngt dem Chor der Pegnitzinnen?", "tokens": ["So", "werd", "ich", "sein", "ver\u00b7m\u00e4ngt", "dem", "Chor", "der", "Peg\u00b7nit\u00b7zin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VAINF", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "E. sinnen.", "tokens": ["E.", "sin\u00b7nen", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.46": {"text": "Wird aber dieser Tohn gleichg\u00fcltig ihrem seyn?", "tokens": ["Wird", "a\u00b7ber", "die\u00b7ser", "Tohn", "gleich\u00b7g\u00fcl\u00b7tig", "ih\u00b7rem", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "ADJD", "PPOSAT", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Vnd werd ich mit der Zeit anstimmen auch so rein.", "tokens": ["Vnd", "werd", "ich", "mit", "der", "Zeit", "an\u00b7stim\u00b7men", "auch", "so", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "ART", "NN", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "E. so rein.", "tokens": ["E.", "so", "rein", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "$."], "meter": "-+", "measure": "iambic.single"}, "line.49": {"text": "Noch eins: wird mir der Flu\u00df/ die bunten Pegnitz-Heiden/", "tokens": ["Noch", "eins", ":", "wird", "mir", "der", "Flu\u00df", "/", "die", "bun\u00b7ten", "Peg\u00b7nitz\u00b7Hei\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$.", "VAFIN", "PPER", "ART", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Von ihren Blumen was/ zu einem Krantz/ bescheiden?", "tokens": ["Von", "ih\u00b7ren", "Blu\u00b7men", "was", "/", "zu", "ei\u00b7nem", "Krantz", "/", "be\u00b7schei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PWS", "$(", "APPR", "ART", "NN", "$(", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "E. Seiden.", "tokens": ["E.", "Sei\u00b7den", "."], "token_info": ["abbreviation", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.52": {"text": "Die Seid auch zum Geb\u00e4nd", "tokens": ["Die", "Seid", "auch", "zum", "Ge\u00b7b\u00e4nd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.53": {"text": "Ich zieh mit Freuden hin. Wend/ Echo/ dich auch du.", "tokens": ["Ich", "zieh", "mit", "Freu\u00b7den", "hin", ".", "Wend", "/", "E\u00b7cho", "/", "dich", "auch", "du", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$.", "KOUS", "$(", "NN", "$(", "PPER", "ADV", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "E. auch du.", "tokens": ["E.", "auch", "du", "."], "token_info": ["abbreviation", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "$."], "meter": "-+", "measure": "iambic.single"}}}}}