{"dta.poem.11347": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Als herr Johann David Kretschmar  \n ausser seinem vaterland in Leipzig den  \n 20 April 1706 zur erden best\u00e4t-  \n tiget wurde.  \n  G. S.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wei\u00df eine perle nicht den kiesel auszuhalten?", "tokens": ["Wei\u00df", "ei\u00b7ne", "per\u00b7le", "nicht", "den", "kie\u00b7sel", "aus\u00b7zu\u00b7hal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mu\u00df ein kluger kopff viel eher noch erkalten,", "tokens": ["Und", "mu\u00df", "ein", "klu\u00b7ger", "kopff", "viel", "e\u00b7her", "noch", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "ADV", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als ein verwehnter thor, der nichts gelernet hat,", "tokens": ["Als", "ein", "ver\u00b7wehn\u00b7ter", "thor", ",", "der", "nichts", "ge\u00b7ler\u00b7net", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als was ihm Rhenius und irgend der Donat", "tokens": ["Als", "was", "ihm", "Rhe\u00b7ni\u00b7us", "und", "ir\u00b7gend", "der", "Do\u00b7nat"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PWS", "PPER", "NE", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit ruthen eingepauckt? Es ist wohl schwer zu fassen;", "tokens": ["Mit", "ru\u00b7then", "ein\u00b7ge\u00b7pauckt", "?", "Es", "ist", "wohl", "schwer", "zu", "fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "PPER", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein wir m\u00fcssen doch den himmel walten lassen,", "tokens": ["Al\u00b7lein", "wir", "m\u00fcs\u00b7sen", "doch", "den", "him\u00b7mel", "wal\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der weiser ist, als wir. Sonst ist es freylich wahr,", "tokens": ["Der", "wei\u00b7ser", "ist", ",", "als", "wir", ".", "Sonst", "ist", "es", "frey\u00b7lich", "wahr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "$,", "KOUS", "PPER", "$.", "ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df mein erblaster freund was ungemeines war.", "tokens": ["Da\u00df", "mein", "er\u00b7blas\u00b7ter", "freund", "was", "un\u00b7ge\u00b7mei\u00b7nes", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PWS", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie wuste Gryphius nicht seinen witz zn loben?", "tokens": ["Wie", "wus\u00b7te", "Gry\u00b7phius", "nicht", "sei\u00b7nen", "witz", "zn", "lo\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "PTKNEG", "PPOSAT", "NN", "NE", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Fridrieiana kennt und r\u00fchmt noch seine proben:", "tokens": ["Frid\u00b7ri\u00b7ei\u00b7a\u00b7na", "kennt", "und", "r\u00fchmt", "noch", "sei\u00b7ne", "pro\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie uns Cartesius die augen aufgethan:", "tokens": ["Wie", "uns", "Car\u00b7te\u00b7sius", "die", "au\u00b7gen", "auf\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NE", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "Und wie Thomasens muth den alten Schlendrian,", "tokens": ["Und", "wie", "Tho\u00b7ma\u00b7sens", "muth", "den", "al\u00b7ten", "Schlen\u00b7dri\u00b7an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "NN", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Den viele st\u00fcmper uns so kr\u00e4fftig angepriesen,", "tokens": ["Den", "vie\u00b7le", "st\u00fcm\u00b7per", "uns", "so", "kr\u00e4ff\u00b7tig", "an\u00b7ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Nun vollends ausgefegt, und uns die bahn gewiesen,", "tokens": ["Nun", "vol\u00b7lends", "aus\u00b7ge\u00b7fegt", ",", "und", "uns", "die", "bahn", "ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$,", "KON", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "So uns das innerste der sitten-lehr entdeckt,", "tokens": ["So", "uns", "das", "in\u00b7ners\u00b7te", "der", "sit\u00b7ten\u00b7lehr", "ent\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "ADJA", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "So sehr die heucheley auch diesen schatz versteckt;", "tokens": ["So", "sehr", "die", "heu\u00b7che\u00b7ley", "auch", "die\u00b7sen", "schatz", "ver\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADV", "ADV", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was Galil\u00e4us schreibt und Tschirnhaus ausgesonnen:", "tokens": ["Was", "Ga\u00b7li\u00b7l\u00e4us", "schreibt", "und", "Tschirn\u00b7haus", "aus\u00b7ge\u00b7son\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "VVFIN", "KON", "NE", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Was sch\u00f6n und artiges aus Bayles kiel geronnen", "tokens": ["Was", "sch\u00f6n", "und", "ar\u00b7ti\u00b7ges", "aus", "Bay\u00b7les", "kiel", "ge\u00b7ron\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "KON", "ADJA", "APPR", "NE", "NE", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wie Coehorn und Vauban die vestungen gebaut:", "tokens": ["Wie", "Coe\u00b7horn", "und", "Vau\u00b7ban", "die", "ves\u00b7tun\u00b7gen", "ge\u00b7baut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NE", "ART", "NN", "VVPP", "$."], "meter": "-+--++-++--+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Ein Hevel durch ein glas mehr stern im himmel schaut,", "tokens": ["Ein", "He\u00b7vel", "durch", "ein", "glas", "mehr", "stern", "im", "him\u00b7mel", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ADV", "VVFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als keiner vorgesehn: Was Weigels kopff erfunden:", "tokens": ["Als", "kei\u00b7ner", "vor\u00b7ge\u00b7sehn", ":", "Was", "Wei\u00b7gels", "kopff", "er\u00b7fun\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "$.", "PWS", "NE", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Hambergers tieffer sinn in den gelehrten stunden", "tokens": ["Ham\u00b7ber\u00b7gers", "tief\u00b7fer", "sinn", "in", "den", "ge\u00b7lehr\u00b7ten", "stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.23": {"text": "Von der natur erkl\u00e4rt, und die Philosophie", "tokens": ["Von", "der", "na\u00b7tur", "er\u00b7kl\u00e4rt", ",", "und", "die", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "In ihre zirckel fa\u00dft; Di\u00df hat die kluge m\u00fch", "tokens": ["In", "ih\u00b7re", "zir\u00b7ckel", "fa\u00dft", ";", "Di\u00df", "hat", "die", "klu\u00b7ge", "m\u00fch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$.", "PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Des nunmehr seeligen in kurtzer zeit begriffen.", "tokens": ["Des", "nun\u00b7mehr", "see\u00b7li\u00b7gen", "in", "kurt\u00b7zer", "zeit", "be\u00b7grif\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Wann andre voller brunst nach einem dorffe lieffen,", "tokens": ["Wann", "and\u00b7re", "vol\u00b7ler", "brunst", "nach", "ei\u00b7nem", "dorf\u00b7fe", "lief\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wo man verstand und ehr, und geld und zeit verpra\u00dft;", "tokens": ["Wo", "man", "ver\u00b7stand", "und", "ehr", ",", "und", "geld", "und", "zeit", "ver\u00b7pra\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "KON", "NN", "$,", "KON", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "So hattest du, mein freund! ein buch zur hand gefa\u00dft,", "tokens": ["So", "hat\u00b7test", "du", ",", "mein", "freund", "!", "ein", "buch", "zur", "hand", "ge\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$.", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Das nach der wei\u00dfheit schmeckt, und eine strasse zeiget,", "tokens": ["Das", "nach", "der", "wei\u00df\u00b7heit", "schmeckt", ",", "und", "ei\u00b7ne", "stras\u00b7se", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Auf der man in die burg der wahren ehre steiget,", "tokens": ["Auf", "der", "man", "in", "die", "burg", "der", "wah\u00b7ren", "eh\u00b7re", "stei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "In die kein fauler kommt. Dein ruhm ist noch nicht gantz:", "tokens": ["In", "die", "kein", "fau\u00b7ler", "kommt", ".", "Dein", "ruhm", "ist", "noch", "nicht", "gantz", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die Themis windet dir auch einen ehren-krantz.", "tokens": ["Die", "The\u00b7mis", "win\u00b7det", "dir", "auch", "ei\u00b7nen", "eh\u00b7ren\u00b7krantz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Du hast das schwere ", "tokens": ["Du", "hast", "das", "schwe\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.34": {"text": "Als einer, der mit recht den doctor-titul f\u00fchret.", "tokens": ["Als", "ei\u00b7ner", ",", "der", "mit", "recht", "den", "doc\u00b7tor\u00b7ti\u00b7tul", "f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "APPR", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.36": {"text": "Und will vor manchem nichts als eine b\u00fcrde seyn;", "tokens": ["Und", "will", "vor", "man\u00b7chem", "nichts", "als", "ei\u00b7ne", "b\u00fcr\u00b7de", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "PIAT", "PIS", "KOKOM", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Dir war es eine lust, nachdem du Stryckens glossen,", "tokens": ["Dir", "war", "es", "ei\u00b7ne", "lust", ",", "nach\u00b7dem", "du", "Stry\u00b7ckens", "glos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Aus dessen munde nur, was wichtig, kommt geflossen,", "tokens": ["Aus", "des\u00b7sen", "mun\u00b7de", "nur", ",", "was", "wich\u00b7tig", ",", "kommt", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "ADV", "$,", "PRELS", "ADJD", "$,", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Und des Wildvogels witz dir alles klar gemacht;", "tokens": ["Und", "des", "Wild\u00b7vo\u00b7gels", "witz", "dir", "al\u00b7les", "klar", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVIMP", "PPER", "PIS", "ADJD", "VVPP", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.40": {"text": "Denn solcher lichter glantz zerstreuet alle nacht.", "tokens": ["Denn", "sol\u00b7cher", "lich\u00b7ter", "glantz", "zer\u00b7streu\u00b7et", "al\u00b7le", "nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Erweg\u2019 ich noch darzu, was du auf deinen reisen", "tokens": ["Er\u00b7weg'", "ich", "noch", "dar\u00b7zu", ",", "was", "du", "auf", "dei\u00b7nen", "rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "PAV", "$,", "PWS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Vor flei\u00df und witz gebraucht; was find ich nicht zu preisen?", "tokens": ["Vor", "flei\u00df", "und", "witz", "ge\u00b7braucht", ";", "was", "find", "ich", "nicht", "zu", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$.", "PWS", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Doch sag\u2019 ich weiter nichts, als da\u00df du das gethan,", "tokens": ["Doch", "sag'", "ich", "wei\u00b7ter", "nichts", ",", "als", "da\u00df", "du", "das", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "$,", "KOKOM", "KOUS", "PPER", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Was einen in der welt vollkommen machen kan.", "tokens": ["Was", "ei\u00b7nen", "in", "der", "welt", "voll\u00b7kom\u00b7men", "ma\u00b7chen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "APPR", "ART", "NN", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wie solte nun dein tod nicht die verwandten schmertzen?", "tokens": ["Wie", "sol\u00b7te", "nun", "dein", "tod", "nicht", "die", "ver\u00b7wand\u00b7ten", "schmert\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Hoch-edle! dieser schlag dringt auch durch andre hertzen,", "tokens": ["Hoch\u00b7ed\u00b7le", "!", "die\u00b7ser", "schlag", "dringt", "auch", "durch", "and\u00b7re", "hert\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PDAT", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Dieweil er auf einmahl so viel zu grabe tr\u00e4gt.", "tokens": ["Die\u00b7weil", "er", "auf", "ein\u00b7mahl", "so", "viel", "zu", "gra\u00b7be", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Was vor ein herber schmertz hier meine feder regt,", "tokens": ["Was", "vor", "ein", "her\u00b7ber", "schmertz", "hier", "mei\u00b7ne", "fe\u00b7der", "regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADV", "ADJD", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Erweiset diese schrifft, wo nichts in ordnung stehet,", "tokens": ["Er\u00b7wei\u00b7set", "die\u00b7se", "schrifft", ",", "wo", "nichts", "in", "ord\u00b7nung", "ste\u00b7het", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VVFIN", "$,", "PWAV", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Und mancher reim und vers mit schlechten f\u00fcssen gehet;", "tokens": ["Und", "man\u00b7cher", "reim", "und", "vers", "mit", "schlech\u00b7ten", "f\u00fcs\u00b7sen", "ge\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "APPR", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ja, lieff er auch schon gut; so ist mein freund doch hin!", "tokens": ["Ja", ",", "lieff", "er", "auch", "schon", "gut", ";", "so", "ist", "mein", "freund", "doch", "hin", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Ach! auserwehlter freund! ich wei\u00df nicht, wo ich bin;", "tokens": ["Ach", "!", "au\u00b7ser\u00b7wehl\u00b7ter", "freund", "!", "ich", "wei\u00df", "nicht", ",", "wo", "ich", "bin", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADJA", "NN", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Und dennoch soll ich mich zu einem tr\u00f6ster schicken.", "tokens": ["Und", "den\u00b7noch", "soll", "ich", "mich", "zu", "ei\u00b7nem", "tr\u00f6s\u00b7ter", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Zwar, h\u00e4tt ich deinen witz? es solte schon gel\u00fccken;", "tokens": ["Zwar", ",", "h\u00e4tt", "ich", "dei\u00b7nen", "witz", "?", "es", "sol\u00b7te", "schon", "ge\u00b7l\u00fc\u00b7cken", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VAFIN", "PPER", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "So aber fallen mir nur diese w\u00f6rter ein:", "tokens": ["So", "a\u00b7ber", "fal\u00b7len", "mir", "nur", "die\u00b7se", "w\u00f6r\u00b7ter", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Das, was der H\u00f6chste will, mu\u00df gut und heilsam seyn.", "tokens": ["Das", ",", "was", "der", "H\u00f6chs\u00b7te", "will", ",", "mu\u00df", "gut", "und", "heil\u00b7sam", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ART", "NN", "VMFIN", "$,", "VMFIN", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Er dencket nicht, wie wir: Wir schauen auf die jugend,", "tokens": ["Er", "den\u00b7cket", "nicht", ",", "wie", "wir", ":", "Wir", "schau\u00b7en", "auf", "die", "ju\u00b7gend", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und das, was uns gef\u00e4llt; allein die reiffe tugend", "tokens": ["Und", "das", ",", "was", "uns", "ge\u00b7f\u00e4llt", ";", "al\u00b7lein", "die", "reif\u00b7fe", "tu\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PDS", "$,", "PRELS", "PPER", "VVPP", "$.", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Macht auch, was jung ist, alt. Ach augen! weinet nicht,", "tokens": ["Macht", "auch", ",", "was", "jung", "ist", ",", "alt", ".", "Ach", "au\u00b7gen", "!", "wei\u00b7net", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "ADJD", "VAFIN", "$,", "ADJD", "$.", "NN", "NN", "$.", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Da\u00df unser seeliger hier keine dornen bricht:", "tokens": ["Da\u00df", "un\u00b7ser", "see\u00b7li\u00b7ger", "hier", "kei\u00b7ne", "dor\u00b7nen", "bricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "La\u00dft doch die thr\u00e4nen uns wie seinen leib begraben!", "tokens": ["La\u00dft", "doch", "die", "thr\u00e4\u00b7nen", "uns", "wie", "sei\u00b7nen", "leib", "be\u00b7gra\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "PPER", "KOKOM", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Denn was vollkommen ist, das mu\u00df der himmel haben.", "tokens": ["Denn", "was", "voll\u00b7kom\u00b7men", "ist", ",", "das", "mu\u00df", "der", "him\u00b7mel", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJD", "VAFIN", "$,", "PDS", "VMFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}