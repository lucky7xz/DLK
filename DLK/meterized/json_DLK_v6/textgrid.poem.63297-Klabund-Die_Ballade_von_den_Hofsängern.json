{"textgrid.poem.63297": {"metadata": {"author": {"name": "Klabund", "birth": "N.A.", "death": "N.A."}, "title": "Die Ballade von den Hofs\u00e4ngern", "genre": "verse", "period": "N.A.", "pub_year": 1909, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir ziehen dahin von Hof zu Hof.", "tokens": ["Wir", "zie\u00b7hen", "da\u00b7hin", "von", "Hof", "zu", "Hof", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "NN", "APPR", "NE", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Arbeiten? Mensch, wir sind doch nicht dof.", "tokens": ["Ar\u00b7bei\u00b7ten", "?", "Mensch", ",", "wir", "sind", "doch", "nicht", "dof", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "NE", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wir singen nicht sch\u00f6n, aber wir singen laut,", "tokens": ["Wir", "sin\u00b7gen", "nicht", "sch\u00f6n", ",", "a\u00b7ber", "wir", "sin\u00b7gen", "laut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "$,", "KON", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+--+---+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df das Eis in den Dienstm\u00e4dchenherzen taut.", "tokens": ["Da\u00df", "das", "Eis", "in", "den", "Dienst\u00b7m\u00e4d\u00b7chen\u00b7her\u00b7zen", "taut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+--++-+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Jawoll.", "tokens": ["Ja\u00b7woll", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.3": {"line.1": {"text": "Wir haben nur lausige Fetzen an,", "tokens": ["Wir", "ha\u00b7ben", "nur", "lau\u00b7si\u00b7ge", "Fet\u00b7zen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Damit unser Elend man sehen kann.", "tokens": ["Da\u00b7mit", "un\u00b7ser", "E\u00b7lend", "man", "se\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "PIS", "VVINF", "VMFIN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der hat keine Jacke und der kein Hemd,", "tokens": ["Der", "hat", "kei\u00b7ne", "Ja\u00b7cke", "und", "der", "kein", "Hemd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "KON", "ART", "PIAT", "NN", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und dem sind Stiefel und Str\u00fcmpfe fremd.", "tokens": ["Und", "dem", "sind", "Stie\u00b7fel", "und", "Str\u00fcmp\u00b7fe", "fremd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Jawoll.", "tokens": ["Ja\u00b7woll", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Wir kriegen Kleider und Stullen viel,", "tokens": ["Wir", "krie\u00b7gen", "Klei\u00b7der", "und", "Stul\u00b7len", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die verkaufen wir abends im Asyl.", "tokens": ["Die", "ver\u00b7kau\u00b7fen", "wir", "a\u00b7bends", "im", "A\u00b7syl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "--+--++-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ein Schneider lud mitleidig uns zu sich ein,", "tokens": ["Ein", "Schnei\u00b7der", "lud", "mit\u00b7lei\u00b7dig", "uns", "zu", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADJD", "PPER", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Da schlugen wir ihm den Sch\u00e4del ein.", "tokens": ["Da", "schlu\u00b7gen", "wir", "ihm", "den", "Sch\u00e4\u00b7del", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Jawoll.", "tokens": ["Ja\u00b7woll", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Wir singen das Lied vom guten Mond", "tokens": ["Wir", "sin\u00b7gen", "das", "Lied", "vom", "gu\u00b7ten", "Mond"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und sind katholisch, wenn es sich lohnt,", "tokens": ["Und", "sind", "ka\u00b7tho\u00b7lisch", ",", "wenn", "es", "sich", "lohnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Auch singen wir v\u00f6lkisch voll und ganz", "tokens": ["Auch", "sin\u00b7gen", "wir", "v\u00f6l\u00b7ki\u00b7sch", "voll", "und", "ganz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJD", "KON", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "F\u00fcr'n Sechser Heil dir im Siegerkranz.", "tokens": ["F\u00fcr'n", "Sech\u00b7ser", "Heil", "dir", "im", "Sie\u00b7ger\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Jawoll.", "tokens": ["Ja\u00b7woll", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.9": {"line.1": {"text": "Unger, Boeger, Ransick, so hei\u00dfen wir.", "tokens": ["Un\u00b7ger", ",", "Boe\u00b7ger", ",", "Ran\u00b7sick", ",", "so", "hei\u00b7\u00dfen", "wir", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Auf die Gerechtigkeit sch... wir.", "tokens": ["Auf", "die", "Ge\u00b7rech\u00b7tig\u00b7keit", "sch", "...", "wir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$(", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mal mu\u00df ja ein jeder in die Gruft", "tokens": ["Mal", "mu\u00df", "ja", "ein", "je\u00b7der", "in", "die", "Gruft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ADV", "ART", "PIS", "APPR", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und wir, wir baumeln mal in der Luft.", "tokens": ["Und", "wir", ",", "wir", "bau\u00b7meln", "mal", "in", "der", "Luft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Jawoll.", "tokens": ["Ja\u00b7woll", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+", "measure": "iambic.single"}}}}}