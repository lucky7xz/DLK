{"dta.poem.9495": {"metadata": {"author": {"name": "Zesen, Philipp von", "birth": "N.A.", "death": "N.A."}, "title": "Auff H. H. S. Hochzeit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-20684-8", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr Seelen voller brunst/ Jhr hertzen voll von feuer", "tokens": ["Ihr", "See\u00b7len", "vol\u00b7ler", "brunst", "/", "Ihr", "hert\u00b7zen", "voll", "von", "feu\u00b7er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$(", "PPOSAT", "NN", "ADJD", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So Venus angez\u00fcndt Jhr reitzerin der Freyer/", "tokens": ["So", "Ve\u00b7nus", "an\u00b7ge\u00b7z\u00fcndt", "Ihr", "reit\u00b7ze\u00b7rin", "der", "Frey\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "PPOSAT", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "O freundliches geschlecht? ", "tokens": ["O", "freund\u00b7li\u00b7ches", "ge\u00b7schlecht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "O schreckung des gem\u00fcths! ", "tokens": ["O", "schre\u00b7ckung", "des", "ge\u00b7m\u00fcths", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "O ursach zu der lust! wer wolte sich getrauen", "tokens": ["O", "ur\u00b7sach", "zu", "der", "lust", "!", "wer", "wol\u00b7te", "sich", "ge\u00b7trau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "ART", "NN", "$.", "PWS", "VMFIN", "PRF", "VVPP"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Zu schreiben euer thun/ Jhr schn\u00f6desten Junafrauen/", "tokens": ["Zu", "schrei\u00b7ben", "eu\u00b7er", "thun", "/", "Ihr", "schn\u00f6\u00b7des\u00b7ten", "Ju\u00b7na\u00b7frau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "VVINF", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "und wenn Jhm gleich ein Jahr/ ja wol die Ewigkeit", "tokens": ["und", "wenn", "Jhm", "gleich", "ein", "Jahr", "/", "ja", "wol", "die", "E\u00b7wig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "$(", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auch unter dessen wolt gestatten jhre zeit?", "tokens": ["Auch", "un\u00b7ter", "des\u00b7sen", "wolt", "ge\u00b7stat\u00b7ten", "jhre", "zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDS", "VMFIN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "Viel stellen sich/ als wenn sie Gottesf\u00fcrchtig weren/", "tokens": ["Viel", "stel\u00b7len", "sich", "/", "als", "wenn", "sie", "Got\u00b7tes\u00b7f\u00fcrch\u00b7tig", "we\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "$(", "KOKOM", "KOUS", "PPER", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Gehn fleissig zu der Kirch\u2019/ als wenn sie wolten h\u00f6ren/", "tokens": ["Gehn", "fleis\u00b7sig", "zu", "der", "Kirch'", "/", "als", "wenn", "sie", "wol\u00b7ten", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$(", "KOKOM", "KOUS", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch \u00fcmb das h\u00f6ren nicht und bethen nur allein/", "tokens": ["Doch", "\u00fcmb", "das", "h\u00f6\u00b7ren", "nicht", "und", "be\u00b7then", "nur", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PDS", "VVFIN", "PTKNEG", "KON", "VVFIN", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie wollen etwas sehn und auch gesehen seyn.", "tokens": ["Sie", "wol\u00b7len", "et\u00b7was", "sehn", "und", "auch", "ge\u00b7se\u00b7hen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "VVINF", "KON", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sie suchen bilder auff so jhr Gebeth-buch zieren;", "tokens": ["Sie", "su\u00b7chen", "bil\u00b7der", "auff", "so", "jhr", "Ge\u00b7beth\u00b7buch", "zie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Es soll auch manche sich befleissen mit zu f\u00fchren/", "tokens": ["Es", "soll", "auch", "man\u00b7che", "sich", "be\u00b7fleis\u00b7sen", "mit", "zu", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "PRF", "VVPP", "APPR", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wenn sie zur Kirchen geht/ vor Arndes Paradies", "tokens": ["Wenn", "sie", "zur", "Kir\u00b7chen", "geht", "/", "vor", "Arn\u00b7des", "Pa\u00b7ra\u00b7dies"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$(", "APPR", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Deutsche Sch\u00e4fferey und Jhren Amadies.", "tokens": ["Die", "Deut\u00b7sche", "Sch\u00e4f\u00b7fe\u00b7rey", "und", "Ih\u00b7ren", "A\u00b7ma\u00b7dies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "(die Frommen mein\u2019 ich nicht!) wenn sie zu hause", "tokens": ["(", "die", "From\u00b7men", "mein'", "ich", "nicht", "!", ")", "wenn", "sie", "zu", "hau\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "kommen", "tokens": ["kom\u00b7men"], "token_info": ["word"], "pos": ["VVINF"], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "und werden denn gefragt/ was gutes sie vernommen/", "tokens": ["und", "wer\u00b7den", "denn", "ge\u00b7fragt", "/", "was", "gu\u00b7tes", "sie", "ver\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVPP", "$(", "PWS", "ADJA", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Spricht eine der und der jetzt auffgebothen ward", "tokens": ["Spricht", "ei\u00b7ne", "der", "und", "der", "jetzt", "auff\u00b7ge\u00b7bo\u00b7then", "ward"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ART", "KON", "ART", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "zum erst- und andern mal; die ander spricht/ je harrt/", "tokens": ["zum", "er\u00b7st", "und", "an\u00b7dern", "mal", ";", "die", "an\u00b7der", "spricht", "/", "je", "harrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "TRUNC", "KON", "PIS", "ADV", "$.", "ART", "ADJD", "VVFIN", "$(", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.22": {"text": "Ich sah dein Sch\u00e4tzchen auch. Wen\u0303 aber fremde lente", "tokens": ["Ich", "sah", "dein", "Sch\u00e4tz\u00b7chen", "auch", ".", "We\u00f1", "a\u00b7ber", "frem\u00b7de", "len\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$.", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+++-+-+-", "measure": "unknown.measure.septa"}, "line.23": {"text": "Denselben sprechen zu/ und kommen auff die Freyhte/", "tokens": ["Den\u00b7sel\u00b7ben", "spre\u00b7chen", "zu", "/", "und", "kom\u00b7men", "auff", "die", "Freyh\u00b7te", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "PTKZU", "$(", "KON", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Da seyn sie erba", "tokens": ["Da", "seyn", "sie", "er\u00b7ba"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NE"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.25": {"text": "und l\u00e4chlen z\u00fcchtiglich; gar selten geth ein strahl", "tokens": ["und", "l\u00e4ch\u00b7len", "z\u00fcch\u00b7tig\u00b7lich", ";", "gar", "sel\u00b7ten", "ge\u00b7th", "ein", "strahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "$.", "ADV", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Aus jhren Eugelein. Sie machen florne schleyer", "tokens": ["Aus", "jhren", "Eu\u00b7ge\u00b7lein", ".", "Sie", "ma\u00b7chen", "flor\u00b7ne", "schle\u00b7yer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VVINF", "VVFIN", "ADJA"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.27": {"text": "Mitt zin\u0303en h\u00fcbsch verbr\u00e4hmt/ in beyseyn jhrer Freyer/", "tokens": ["Mitt", "zi\u00f1en", "h\u00fcbsch", "ver\u00b7br\u00e4hmt", "/", "in", "bey\u00b7seyn", "jhrer", "Frey\u00b7er", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "VVPP", "$(", "APPR", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.28": {"text": "Sie machen silbern worm un\u0303 winden auf den la", "tokens": ["Sie", "ma\u00b7chen", "sil\u00b7bern", "worm", "u\u00f1", "win\u00b7den", "auf", "den", "la"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "KON", "VVFIN", "APPR", "ART", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ein jedes sonderlich Sie wollen fangen an", "tokens": ["Ein", "je\u00b7des", "son\u00b7der\u00b7lich", "Sie", "wol\u00b7len", "fan\u00b7gen", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJD", "PPER", "VMFIN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Zu schicken sich zur Eh/ und str\u00fccken seidne Hauben", "tokens": ["Zu", "schi\u00b7cken", "sich", "zur", "Eh", "/", "und", "str\u00fc\u00b7cken", "seid\u00b7ne", "Hau\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PRF", "APPRART", "NN", "$(", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Mitt Perlen eingefasst/ im Sommer in der lauben/", "tokens": ["Mitt", "Per\u00b7len", "ein\u00b7ge\u00b7fasst", "/", "im", "Som\u00b7mer", "in", "der", "lau\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$(", "APPRART", "NN", "APPR", "ART", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Jm Winter in der stub\u2019: ists nicht ein thun f\u00fcr sie?", "tokens": ["Jm", "Win\u00b7ter", "in", "der", "stub'", ":", "ists", "nicht", "ein", "thun", "f\u00fcr", "sie", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$.", "VAFIN", "PTKNEG", "PTKVZ", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wer jhnen dis mis g\u00f6nnt/ der darf nicht seyn allhie.", "tokens": ["Wer", "jh\u00b7nen", "dis", "mis", "g\u00f6nnt", "/", "der", "darf", "nicht", "seyn", "all\u00b7hie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PDS", "NE", "VVFIN", "$(", "ART", "VMFIN", "PTKNEG", "VAINF", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Sie nehen bloch-nath aus/ so b\u00e4sser loch-nath hie\u00dfe/", "tokens": ["Sie", "ne\u00b7hen", "bloch\u00b7nath", "aus", "/", "so", "b\u00e4s\u00b7ser", "loch\u00b7nath", "hie\u00b7\u00dfe", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "$(", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Damit die Liljen-haut sichb\u00e4sser schen lie\u00dfe;", "tokens": ["Da\u00b7mit", "die", "Lil\u00b7jen\u00b7haut", "sich\u00b7b\u00e4s\u00b7ser", "schen", "lie\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.36": {"text": "Sie nehen Hertzen aus mit pfeilen/ sch\u00f6ne beum/", "tokens": ["Sie", "ne\u00b7hen", "Hert\u00b7zen", "aus", "mit", "pfei\u00b7len", "/", "sch\u00f6\u00b7ne", "beum", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "APPR", "NN", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Hatzsch-m\u00f6dcl/ K\u00e4lber-z\u00e4hn\u2019/ erbs-l\u00f6cher/ Deut-", "tokens": ["Hatz\u00b7schm\u00f6d\u00b7cl", "/", "K\u00e4l\u00b7ber\u00b7z\u00e4hn'", "/", "erbs\u00b7l\u00f6\u00b7cher", "/", "Deut"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$(", "NN", "$(", "ADJA", "$(", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "schereim'/", "tokens": ["sche\u00b7reim'", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.39": {"text": "Sie machen sch\u00f6ne pfiel/ bereiten sch\u00f6ne betten/", "tokens": ["Sie", "ma\u00b7chen", "sch\u00f6\u00b7ne", "pfiel", "/", "be\u00b7rei\u00b7ten", "sch\u00f6\u00b7ne", "bet\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$(", "ADJA", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Damit sie mit der zeit schon was im vorrath hetten:", "tokens": ["Da\u00b7mit", "sie", "mit", "der", "zeit", "schon", "was", "im", "vor\u00b7rath", "het\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ADV", "PRELS", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Sie nehen hohl-nath aus/ waschblauel/ r\u00e4derlem/", "tokens": ["Sie", "ne\u00b7hen", "hohl\u00b7nath", "aus", "/", "waschblau\u00b7el", "/", "r\u00e4\u00b7der\u00b7lem", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$(", "PWS", "$(", "NE", "$("], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.42": {"text": "Saltz-k\u00f6rbe/ Sonn\u2019 und Mond/ und was es mehr", "tokens": ["Saltz\u00b7k\u00f6r\u00b7be", "/", "Sonn'", "und", "Mond", "/", "und", "was", "es", "mehr"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "NN", "KON", "NN", "$(", "KON", "PWS", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "mag seyn.", "tokens": ["mag", "seyn", "."], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.44": {"text": "Das kl\u00f6ppeln/ jhre lust/ das hatzschen jhre freude/", "tokens": ["Das", "kl\u00f6p\u00b7peln", "/", "jhre", "lust", "/", "das", "hatz\u00b7schen", "jhre", "freu\u00b7de", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "$(", "PPOSAT", "NN", "$(", "PDS", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.45": {"text": "Das str\u00fccken jhre m\u00fch/ das nehen mit der seide", "tokens": ["Das", "str\u00fc\u00b7cken", "jhre", "m\u00fch", "/", "das", "ne\u00b7hen", "mit", "der", "sei\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJD", "$(", "PDS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Bald blan/ bald grau/ bald wei\u00df/ vertreibet jhre zeit/", "tokens": ["Bald", "blan", "/", "bald", "grau", "/", "bald", "wei\u00df", "/", "ver\u00b7trei\u00b7bet", "jhre", "zeit", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "ADV", "ADJD", "$(", "ADV", "VVFIN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.47": {"text": "Der Rehmen wird ber\u00fchmt/ ber\u00fchmt wird weit", "tokens": ["Der", "Reh\u00b7men", "wird", "be\u00b7r\u00fchmt", "/", "be\u00b7r\u00fchmt", "wird", "weit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$(", "ADJD", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "und breit", "tokens": ["und", "breit"], "token_info": ["word", "word"], "pos": ["KON", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.49": {"text": "Das sch\u00f6ne Model-tuch/ So bringen sie die Stunde/", "tokens": ["Das", "sch\u00f6\u00b7ne", "Mo\u00b7del\u00b7tuch", "/", "So", "brin\u00b7gen", "sie", "die", "Stun\u00b7de", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Die s\u00fc\u00dfe Stunde zu/ und machen schlechte kunde", "tokens": ["Die", "s\u00fc\u00b7\u00dfe", "Stun\u00b7de", "zu", "/", "und", "ma\u00b7chen", "schlech\u00b7te", "kun\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "$(", "KON", "VVINF", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Mitt jhrem Buhlen hier: doch stellen sie sich so", "tokens": ["Mitt", "jhrem", "Buh\u00b7len", "hier", ":", "doch", "stel\u00b7len", "sie", "sich", "so"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADV", "$.", "ADV", "VVFIN", "PPER", "PRF", "ADV"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.52": {"text": "Dann wann er gehen will so seyn sie nimmer froh/", "tokens": ["Dann", "wann", "er", "ge\u00b7hen", "will", "so", "seyn", "sie", "nim\u00b7mer", "froh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWAV", "PPER", "VVINF", "VMFIN", "ADV", "VAINF", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Weils nicht von hertzen geht: Sie sprechen zwar Ein", "tokens": ["Weils", "nicht", "von", "hert\u00b7zen", "geht", ":", "Sie", "spre\u00b7chen", "zwar", "Ein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "APPR", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.54": {"text": "Stutzer/", "tokens": ["Stut\u00b7zer", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.55": {"text": "Ein Gassen-treter nur/ und blo\u00dfer Damen-butzer/", "tokens": ["Ein", "Gas\u00b7sen\u00b7tre\u00b7ter", "nur", "/", "und", "blo\u00b7\u00dfer", "Da\u00b7men\u00b7but\u00b7zer", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Was soll ich mit jhm thun; wann er sie zu sich zihn", "tokens": ["Was", "soll", "ich", "mit", "jhm", "thun", ";", "wann", "er", "sie", "zu", "sich", "zihn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "PWAV", "PPER", "PPER", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "und reden will/ spricht sie: Ey macht euch nicht so", "tokens": ["und", "re\u00b7den", "will", "/", "spricht", "sie", ":", "Ey", "macht", "euch", "nicht", "so"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "VMFIN", "$(", "VVFIN", "PPER", "$.", "NN", "VVFIN", "PPER", "PTKNEG", "ADV"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.58": {"text": "gru\u0303n/", "tokens": ["gr\u0169n", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+", "measure": "single.up"}, "line.59": {"text": "Kennt jhr die Ziegen nicht: dis ist ein blo\u00dfes stellen/", "tokens": ["Kennt", "jhr", "die", "Zie\u00b7gen", "nicht", ":", "dis", "ist", "ein", "blo\u00b7\u00dfes", "stel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "$.", "PDS", "VAFIN", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Ein blo\u00dfer blo\u00dfer schein/ das mercken die Gesellen/", "tokens": ["Ein", "blo\u00b7\u00dfer", "blo\u00b7\u00dfer", "schein", "/", "das", "mer\u00b7cken", "die", "Ge\u00b7sel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "PDS", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "und halten wacker an/ bi\u00df sie genommen ein", "tokens": ["und", "hal\u00b7ten", "wa\u00b7cker", "an", "/", "bi\u00df", "sie", "ge\u00b7nom\u00b7men", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PTKVZ", "$(", "KOUS", "PPER", "VVPP", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Durch dienst und stetes lob/ das kluge Jungfreu-", "tokens": ["Durch", "dienst", "und", "ste\u00b7tes", "lob", "/", "das", "klu\u00b7ge", "Jung\u00b7freu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDAT", "KON", "ADJA", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.63": {"text": "lein.", "tokens": ["lein", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-", "measure": "single.down"}, "line.64": {"text": "Wann sie sich denn nun gibt und kundschafft mit jhm", "tokens": ["Wann", "sie", "sich", "denn", "nun", "gibt", "und", "kund\u00b7schafft", "mit", "jhm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADV", "VVFIN", "KON", "NN", "APPR", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.65": {"text": "machet", "tokens": ["ma\u00b7chet"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.66": {"text": "Gef\u00e4llt es beyden wohl/ man\u0303 hertzer/ schertzt un\u0303 lachet/", "tokens": ["Ge\u00b7f\u00e4llt", "es", "bey\u00b7den", "wohl", "/", "ma\u00f1", "hert\u00b7zer", "/", "schertzt", "u\u00f1", "la\u00b7chet", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "ADV", "$(", "NE", "NE", "$(", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Die Euglein streuen aus die s\u00fc\u00dfe Liebes-saat/", "tokens": ["Die", "Eug\u00b7lein", "streu\u00b7en", "aus", "die", "s\u00fc\u00b7\u00dfe", "Lie\u00b7bes\u00b7saat", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Bi\u00df endlich auff sie ziehlt des runden gl\u00fcckes radt/", "tokens": ["Bi\u00df", "end\u00b7lich", "auff", "sie", "ziehlt", "des", "run\u00b7den", "gl\u00fc\u00b7ckes", "radt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Bi\u00df endlich Tyndaris die myrthen-kr\u00e4ntze brin-", "tokens": ["Bi\u00df", "end\u00b7lich", "Tyn\u00b7da\u00b7ris", "die", "myr\u00b7then\u00b7kr\u00e4nt\u00b7ze", "brin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "NE", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "get/", "tokens": ["get", "/"], "token_info": ["word", "punct"], "pos": ["VVPP", "$("], "meter": "-", "measure": "single.down"}, "line.71": {"text": "und jhnen von der licb\u2019 ein s\u00fc\u00dfes liedlein singet/", "tokens": ["und", "jh\u00b7nen", "von", "der", "licb'", "ein", "s\u00fc\u00b7\u00dfes", "lied\u00b7lein", "sin\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Bi\u00df endlich auch Vulcan die Liebes", "tokens": ["Bi\u00df", "end\u00b7lich", "auch", "Vul\u00b7can", "die", "Lie\u00b7bes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "NE", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.73": {"text": "Au\u00df gold von Ophir her/ und selbe bey der nacht", "tokens": ["Au\u00df", "gold", "von", "Op\u00b7hir", "her", "/", "und", "sel\u00b7be", "bey", "der", "nacht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NE", "PTKVZ", "$(", "KON", "ADJA", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Cupido brauchen l\u00e4sst; Als denn l\u00e4sst sie sich sehen/", "tokens": ["Cu\u00b7pi\u00b7do", "brau\u00b7chen", "l\u00e4sst", ";", "Als", "denn", "l\u00e4sst", "sie", "sich", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVFIN", "$.", "KOUS", "ADV", "VVFIN", "PPER", "PRF", "VVINF", "$("], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.75": {"text": "und thut was sonsten nie bey Leuten ist geschehen/", "tokens": ["und", "thut", "was", "sons\u00b7ten", "nie", "bey", "Leu\u00b7ten", "ist", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "VVFIN", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "weil sie nun hett genug/ weil sie den tag erlebt/", "tokens": ["weil", "sie", "nun", "hett", "ge\u00b7nug", "/", "weil", "sie", "den", "tag", "er\u00b7lebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "ADV", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Nach dem sie fort f\u00fcr fort mit schmertzen hatt ge-", "tokens": ["Nach", "dem", "sie", "fort", "f\u00fcr", "fort", "mit", "schmert\u00b7zen", "hatt", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "PTKVZ", "APPR", "PTKVZ", "APPR", "VVINF", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.78": {"text": "strebt.", "tokens": ["strebt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.79": {"text": "Als denn l\u00e4sst sie sich aus und spielet jhrem buhlen", "tokens": ["Als", "denn", "l\u00e4sst", "sie", "sich", "aus", "und", "spie\u00b7let", "jhrem", "buh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.80": {"text": "Auff jhrer Lauten eins in jhrer Liebes-schulen/", "tokens": ["Auff", "jhrer", "Lau\u00b7ten", "eins", "in", "jhrer", "Lie\u00b7bes\u00b7schu\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PIS", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.81": {"text": "Z\u00fcndt an die Liebes-gluth (", "tokens": ["Z\u00fcndt", "an", "die", "Lie\u00b7bes\u00b7gluth", "("], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.82": {"text": "Da\u00df nichts als feuers-brunst daraus entstehen", "tokens": ["Da\u00df", "nichts", "als", "feu\u00b7er\u00b7sbrunst", "da\u00b7raus", "ent\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "KOKOM", "ADJD", "PAV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.83": {"text": "kann/", "tokens": ["kann", "/"], "token_info": ["word", "punct"], "pos": ["VMFIN", "$("], "meter": "+", "measure": "single.up"}, "line.84": {"text": "Wo sie nicht wehrt alsbald und jhre Lieb\u2019 erzeiget", "tokens": ["Wo", "sie", "nicht", "wehrt", "als\u00b7bald", "und", "jhre", "Lieb'", "er\u00b7zei\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PTKNEG", "VVFIN", "ADV", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "+--+-+-++-+-", "measure": "iambic.hexa.invert"}, "line.85": {"text": "Demselben williglich und seine schmertzen beuget", "tokens": ["Dem\u00b7sel\u00b7ben", "wil\u00b7lig\u00b7lich", "und", "sei\u00b7ne", "schmert\u00b7zen", "beu\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "ADJD", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Durch angenehme wort und Anmuth jhrer treu/", "tokens": ["Durch", "an\u00b7ge\u00b7neh\u00b7me", "wort", "und", "An\u00b7muth", "jhrer", "treu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PPOSAT", "ADJD", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.87": {"text": "So \u00fcber jhren Schatz wird alle morgen neu.", "tokens": ["So", "\u00fc\u00b7ber", "jhren", "Schatz", "wird", "al\u00b7le", "mor\u00b7gen", "neu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VAFIN", "PIS", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.88": {"text": "So mu\u00df mann feyren sie/ so kann sich erstlich stellen", "tokens": ["So", "mu\u00df", "mann", "fey\u00b7ren", "sie", "/", "so", "kann", "sich", "erst\u00b7lich", "stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "NN", "VVFIN", "PPER", "$(", "ADV", "VMFIN", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Das kluge Venus-volck/ wie artlich kann es fellen", "tokens": ["Das", "klu\u00b7ge", "Ve\u00b7nus\u00b7volck", "/", "wie", "art\u00b7lich", "kann", "es", "fel\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "PWAV", "ADJD", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Auch wohl den kl\u00fcgesten/ durch solche kunst und", "tokens": ["Auch", "wohl", "den", "kl\u00fc\u00b7ge\u00b7sten", "/", "durch", "sol\u00b7che", "kunst", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADJA", "$(", "APPR", "PIAT", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.91": {"text": "list/", "tokens": ["list", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.92": {"text": "Die jhn von Natur fast eingepflantzet ist.", "tokens": ["Die", "jhn", "von", "Na\u00b7tur", "fast", "ein\u00b7ge\u00b7pflant\u00b7zet", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.93": {"text": "Noch dieses gieng\u2019 auch hi", "tokens": ["Noch", "die\u00b7ses", "gieng'", "auch", "hi"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "ADV", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.94": {"text": "Ob mann sie oftermahls schon etwas solte bitten/", "tokens": ["Ob", "mann", "sie", "of\u00b7ter\u00b7mahls", "schon", "et\u00b7was", "sol\u00b7te", "bit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "ADV", "ADV", "PIS", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Wann sie nur bittens werth/ mit keuschheit seyn be-", "tokens": ["Wann", "sie", "nur", "bit\u00b7tens", "werth", "/", "mit", "keuschheit", "seyn", "be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ADJD", "$(", "APPR", "NN", "PPOSAT", "TRUNC"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.96": {"text": "kleidt/", "tokens": ["kleidt", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+", "measure": "single.up"}, "line.97": {"text": "Mitt tugenden begabt/ begabt mit liebligkeit.", "tokens": ["Mitt", "tu\u00b7gen\u00b7den", "be\u00b7gabt", "/", "be\u00b7gabt", "mit", "lieb\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJD", "$(", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Den\u0303 ostermals geschichts; wen\u0303 sie vom hohen stande/", "tokens": ["De\u00f1", "os\u00b7ter\u00b7mals", "ge\u00b7schichts", ";", "we\u00f1", "sie", "vom", "ho\u00b7hen", "stan\u00b7de", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$.", "KOUS", "PPER", "APPRART", "ADJA", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "So achtet sie dich nicht ist sie die sch\u00f6nst\u2019 im lande/", "tokens": ["So", "ach\u00b7tet", "sie", "dich", "nicht", "ist", "sie", "die", "sch\u00f6nst'", "im", "lan\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKNEG", "VAFIN", "PPER", "ART", "VVFIN", "APPRART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Geht sie spazieren aus; ist sie den\u0303 schwartz und bleich", "tokens": ["Geht", "sie", "spa\u00b7zie\u00b7ren", "aus", ";", "ist", "sie", "de\u00f1", "schwartz", "und", "bleich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVFIN", "PTKVZ", "$.", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.101": {"text": "So gehestu beyseyt ist sie an gutern reich/", "tokens": ["So", "ge\u00b7hes\u00b7tu", "bey\u00b7seyt", "ist", "sie", "an", "gu\u00b7tern", "reich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAFIN", "PPER", "APPR", "ADJA", "ADJD", "$("], "meter": "-+----+--+-+", "measure": "iambic.tetra.relaxed"}, "line.102": {"text": "So will sie Herre seyn: ist sie denn arm gewesen/", "tokens": ["So", "will", "sie", "Her\u00b7re", "seyn", ":", "ist", "sie", "denn", "arm", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VAINF", "$.", "VAFIN", "PPER", "ADV", "ADJD", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Entsteht auch zanck und streit: ist sie auch wohl belesen/", "tokens": ["Ent\u00b7steht", "auch", "zanck", "und", "streit", ":", "ist", "sie", "auch", "wohl", "be\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "KON", "NN", "$.", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "So will sie meister seyn/ ist sie hingegen tumm/", "tokens": ["So", "will", "sie", "meis\u00b7ter", "seyn", "/", "ist", "sie", "hin\u00b7ge\u00b7gen", "tumm", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$(", "VAFIN", "PPER", "ADV", "ADJD", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.105": {"text": "Erhebt sich ha\u00df und netd: ist sie geb\u00fcckt und krum\u0303/", "tokens": ["Er\u00b7hebt", "sich", "ha\u00df", "und", "netd", ":", "ist", "sie", "ge\u00b7b\u00fcckt", "und", "krum\u0303", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "KON", "NE", "$.", "VAFIN", "PPER", "VVPP", "KON", "VVIMP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "So siehstu andern nach: l\u00e4stu sie ausspazieren/", "tokens": ["So", "sieh\u00b7stu", "an\u00b7dern", "nach", ":", "l\u00e4s\u00b7tu", "sie", "aus\u00b7spa\u00b7zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "$.", "VVFIN", "PPER", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "So ist sie dein nicht nur: will sie die Nahrung f\u00fchren", "tokens": ["So", "ist", "sie", "dein", "nicht", "nur", ":", "will", "sie", "die", "Nah\u00b7rung", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "PTKNEG", "ADV", "$.", "VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.108": {"text": "und etwas heu\u00dflich seyn/ so darffstu kemen", "tokens": ["und", "et\u00b7was", "heu\u00df\u00b7lich", "seyn", "/", "so", "darffs\u00b7tu", "ke\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "VAINF", "$(", "ADV", "PAV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.109": {"text": "freund", "tokens": ["freund"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.110": {"text": "Zum truncke laden heim/ sonst wird sie bald dein", "tokens": ["Zum", "trun\u00b7cke", "la\u00b7den", "heim", "/", "sonst", "wird", "sie", "bald", "dein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PTKVZ", "$(", "ADV", "VAFIN", "PPER", "ADV", "PPOSAT"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.111": {"text": "feind", "tokens": ["feind"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.112": {"text": "und keusfet auff dich zu: ist sie denn from\u0303 und z\u00fcchtig/", "tokens": ["und", "keus\u00b7fet", "auff", "dich", "zu", ":", "ist", "sie", "denn", "from\u0303", "und", "z\u00fcch\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$.", "VAFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.113": {"text": "So hatt sie nicht viel geld: ist sie an keuschheit richtig/", "tokens": ["So", "hatt", "sie", "nicht", "viel", "geld", ":", "ist", "sie", "an", "keuschheit", "rich\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "PIAT", "NN", "$.", "VAFIN", "PPER", "APPR", "NN", "ADJD", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.114": {"text": "So ist nicht sch\u00f6nheit da: doch ist die fr\u00f6mmigkeit", "tokens": ["So", "ist", "nicht", "sch\u00f6n\u00b7heit", "da", ":", "doch", "ist", "die", "fr\u00f6m\u00b7mig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PTKNEG", "ADJD", "PTKVZ", "$.", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "und keuschheit vorzuziehn demselben jederzeit.", "tokens": ["und", "keuschheit", "vor\u00b7zu\u00b7ziehn", "dem\u00b7sel\u00b7ben", "je\u00b7der\u00b7zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVIZU", "PDAT", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.116": {"text": "Wann sie nur gut und fromm/ wer fraget nach den", "tokens": ["Wann", "sie", "nur", "gut", "und", "fromm", "/", "wer", "fra\u00b7get", "nach", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "KON", "ADJD", "$(", "PWS", "VVFIN", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.117": {"text": "gaben/", "tokens": ["ga\u00b7ben", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.118": {"text": "Nach sch\u00f6nheit/ gold und pracht: wer kann es alles", "tokens": ["Nach", "sch\u00f6n\u00b7heit", "/", "gold", "und", "pracht", ":", "wer", "kann", "es", "al\u00b7les"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "NN", "KON", "VVFIN", "$.", "PWS", "VMFIN", "PPER", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.119": {"text": "haben", "tokens": ["ha\u00b7ben"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.120": {"text": "Nur freundligkeit und buld erh\u00e4lt das feld bey jhr/", "tokens": ["Nur", "freund\u00b7lig\u00b7keit", "und", "buld", "er\u00b7h\u00e4lt", "das", "feld", "bey", "jhr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "ADJD", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Das ander nichtig bleibt und fl\u00fcchtig f\u00fcr und f\u00fcr.", "tokens": ["Das", "an\u00b7der", "nich\u00b7tig", "bleibt", "und", "fl\u00fcch\u00b7tig", "f\u00fcr", "und", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJD", "VVFIN", "KON", "ADJD", "APPR", "KON", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Dan was ist sch\u00f6nheit wohl/ wann sie zum sch\u00f6nsten", "tokens": ["Dan", "was", "ist", "sch\u00f6n\u00b7heit", "wohl", "/", "wann", "sie", "zum", "sch\u00f6ns\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PWS", "VAFIN", "ADV", "ADV", "$(", "PWAV", "PPER", "APPRART", "ADJA"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.123": {"text": "leuchtet?", "tokens": ["leuch\u00b7tet", "?"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.124": {"text": "Ein angenehmes gifft/ das unser hertz befeuchtet/", "tokens": ["Ein", "an\u00b7ge\u00b7neh\u00b7mes", "gifft", "/", "das", "un\u00b7ser", "hertz", "be\u00b7feuch\u00b7tet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Ein zihender Magnet/ ein Spiegel voller list/", "tokens": ["Ein", "zi\u00b7hen\u00b7der", "Mag\u00b7net", "/", "ein", "Spie\u00b7gel", "vol\u00b7ler", "list", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.126": {"text": "Ein scharffer siraal/ der uns zu f\u00e4llen ist ger\u00fcst.", "tokens": ["Ein", "scharf\u00b7fer", "si\u00b7raal", "/", "der", "uns", "zu", "f\u00e4l\u00b7len", "ist", "ge\u00b7r\u00fcst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "PPER", "PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "++--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.127": {"text": "Ein zunder b\u00f6ser lust/ ein fall und gang zur Hellen/", "tokens": ["Ein", "zun\u00b7der", "b\u00f6\u00b7ser", "lust", "/", "ein", "fall", "und", "gang", "zur", "Hel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$(", "ART", "NN", "KON", "ADJD", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Der hoffarth Kammer-rath/ der \u00fcppigkeit geselle/", "tokens": ["Der", "hof\u00b7farth", "Kam\u00b7mer\u00b7rath", "/", "der", "\u00fcp\u00b7pig\u00b7keit", "ge\u00b7sel\u00b7le", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Ein zwang zur hurerey; ein ursach aller noth/", "tokens": ["Ein", "zwang", "zur", "hu\u00b7re\u00b7rey", ";", "ein", "ur\u00b7sach", "al\u00b7ler", "noth", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "APPRART", "NN", "$.", "ART", "NN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Der Jugend leim und hartz/ ein rechter freuden-todt/", "tokens": ["Der", "Ju\u00b7gend", "leim", "und", "hartz", "/", "ein", "rech\u00b7ter", "freu\u00b7den\u00b7todt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "und was sie alles ist. Mein sinn ist tieff versencket", "tokens": ["und", "was", "sie", "al\u00b7les", "ist", ".", "Mein", "sinn", "ist", "tieff", "ver\u00b7sen\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "PIS", "VAFIN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Das hertz\u2019 erschrickt davor/ in dem es nur bedencket/", "tokens": ["Das", "hertz'", "er\u00b7schrickt", "da\u00b7vor", "/", "in", "dem", "es", "nur", "be\u00b7den\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PAV", "$(", "APPR", "PRELS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Wie hoch die sch\u00f6nheit doch anjetzund ist geacht/", "tokens": ["Wie", "hoch", "die", "sch\u00f6n\u00b7heit", "doch", "an\u00b7jet\u00b7zund", "ist", "ge\u00b7acht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "ADV", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Da tugend/ fr\u00f6mmigkeit und keuschheit wird ver-", "tokens": ["Da", "tu\u00b7gend", "/", "fr\u00f6m\u00b7mig\u00b7keit", "und", "keuschheit", "wird", "ver"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "$(", "NN", "KON", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.135": {"text": "lacht.", "tokens": ["lacht", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.136": {"text": "Wann sch\u00f6nheit oder nur einbildung solcher thete/", "tokens": ["Wann", "sch\u00f6n\u00b7heit", "o\u00b7der", "nur", "ein\u00b7bil\u00b7dung", "sol\u00b7cher", "the\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "ADV", "NN", "PIAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "So hette nie geschaut die sch\u00f6ne morgen-r\u00f6the", "tokens": ["So", "het\u00b7te", "nie", "ge\u00b7schaut", "die", "sch\u00f6\u00b7ne", "mor\u00b7gen\u00b7r\u00f6\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "VVPP", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "unkeusche lieb und lust/ so wer auch nicht so bald/", "tokens": ["un\u00b7keu\u00b7sche", "lieb", "und", "lust", "/", "so", "wer", "auch", "nicht", "so", "bald", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "ADJD", "KON", "VVFIN", "$(", "ADV", "PWS", "ADV", "PTKNEG", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Narcissus abgefleischt/ vor trauren worden kalt.", "tokens": ["Nar\u00b7cis\u00b7sus", "ab\u00b7ge\u00b7fleischt", "/", "vor", "trau\u00b7ren", "wor\u00b7den", "kalt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$(", "APPR", "VVINF", "VAPP", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Dr\u00fcmb sch\u00e4tzt man seelig die so sich der zucht ergeben/", "tokens": ["Dr\u00fcmb", "sch\u00e4tzt", "man", "see\u00b7lig", "die", "so", "sich", "der", "zucht", "er\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ADJD", "ART", "ADV", "PRF", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Seyn from\u0303/ der keuschheit voll in jhrem gantzen leben/", "tokens": ["Seyn", "from\u0303", "/", "der", "keuschheit", "voll", "in", "jhrem", "gant\u00b7zen", "le\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ART", "NN", "ADJD", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.142": {"text": "und achten hochmuth nicht/ noch hoffart/ ehr und", "tokens": ["und", "ach\u00b7ten", "hoch\u00b7muth", "nicht", "/", "noch", "hof\u00b7fart", "/", "ehr", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJA", "NN", "PTKNEG", "$(", "ADV", "VVFIN", "$(", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.143": {"text": "pracht/", "tokens": ["pracht", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.144": {"text": "und seyn auf jhren schmuck und schmincken nicht", "tokens": ["und", "seyn", "auf", "jhren", "schmuck", "und", "schmin\u00b7cken", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PTKNEG"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.145": {"text": "bedacht/", "tokens": ["be\u00b7dacht", "/"], "token_info": ["word", "punct"], "pos": ["VVPP", "$("], "meter": "-+", "measure": "iambic.single"}, "line.146": {"text": "Die werden auch gesucht: dann ehrliche gem\u00fcther", "tokens": ["Die", "wer\u00b7den", "auch", "ge\u00b7sucht", ":", "dann", "ehr\u00b7li\u00b7che", "ge\u00b7m\u00fc\u00b7ther"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$.", "ADV", "ADJA", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Sehn auff das schmincken nicht/ viel minder auff die", "tokens": ["Sehn", "auff", "das", "schmin\u00b7cken", "nicht", "/", "viel", "min\u00b7der", "auff", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PDS", "VVFIN", "PTKNEG", "$(", "ADV", "ADV", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.148": {"text": "g\u00fcter", "tokens": ["g\u00fc\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.149": {"text": "und auff der hoffart glantz; doch wird betrogen auch", "tokens": ["und", "auff", "der", "hof\u00b7fart", "glantz", ";", "doch", "wird", "be\u00b7tro\u00b7gen", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$.", "ADV", "VAFIN", "VVPP", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Manch stiller Mensch/ und kriegt vor klahrheit", "tokens": ["Manch", "stil\u00b7ler", "Mensch", "/", "und", "kriegt", "vor", "klahr\u00b7heit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$(", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.151": {"text": "lauter rauch.", "tokens": ["lau\u00b7ter", "rauch", "."], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.152": {"text": "Jhr aber/ liebsten zwey/ d\u00f6rst Euch nun nicht besorgen/", "tokens": ["Ihr", "a\u00b7ber", "/", "liebs\u00b7ten", "zwey", "/", "d\u00f6rst", "Euch", "nun", "nicht", "be\u00b7sor\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "VVFIN", "CARD", "$(", "ADV", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Stellt solche sachen ein/ un\u0303 schlaftbis an den morgen/", "tokens": ["Stellt", "sol\u00b7che", "sa\u00b7chen", "ein", "/", "u\u00f1", "schlaft\u00b7bis", "an", "den", "mor\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "ART", "$(", "KON", "ADV", "APPR", "ART", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "In stiller/ sanfter Ruh/ Jhr seyd nun Junfer braut", "tokens": ["In", "stil\u00b7ler", "/", "sanf\u00b7ter", "Ruh", "/", "Ihr", "seyd", "nun", "Jun\u00b7fer", "braut"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "$(", "ADJA", "NN", "$(", "PPER", "VAFIN", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Dem/ den Jhr oft begehrt von hertzen anvertraut:", "tokens": ["Dem", "/", "den", "Ihr", "oft", "be\u00b7gehrt", "von", "hert\u00b7zen", "an\u00b7ver\u00b7traut", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "ART", "PPER", "ADV", "VVPP", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "und jhr Herr Breutigam/ habt jetzund eures gleichen/", "tokens": ["und", "jhr", "Herr", "Breu\u00b7ti\u00b7gam", "/", "habt", "je\u00b7tzund", "eu\u00b7res", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "$(", "VAFIN", "ADV", "PPOSAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Denn gleich und gleich pflege sich einander fein zu", "tokens": ["Denn", "gleich", "und", "gleich", "pfle\u00b7ge", "sich", "ein\u00b7an\u00b7der", "fein", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KON", "ADV", "VVFIN", "PRF", "ADV", "ADJD", "PTKZU"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.158": {"text": "weichen/", "tokens": ["wei\u00b7chen", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.159": {"text": "Sie schl\u00e4gt euch g\u00e4ntzlich nach an hertz und an", "tokens": ["Sie", "schl\u00e4gt", "euch", "g\u00e4ntz\u00b7lich", "nach", "an", "hertz", "und", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "APPR", "NN", "KON", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.160": {"text": "gem\u00fcth/", "tokens": ["ge\u00b7m\u00fcth", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "-+", "measure": "iambic.single"}, "line.161": {"text": "Sie ist nicht stoltz und frech/ ja nicht Jhr kleinstes", "tokens": ["Sie", "ist", "nicht", "stoltz", "und", "frech", "/", "ja", "nicht", "Ihr", "kleins\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "KON", "ADJD", "$(", "ADV", "PTKNEG", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.162": {"text": "glied", "tokens": ["glied"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.163": {"text": "Der Hoffart anverwandt: Sie hatt zwar sch\u00f6nheit-", "tokens": ["Der", "Hof\u00b7fart", "an\u00b7ver\u00b7wandt", ":", "Sie", "hatt", "zwar", "sch\u00f6n\u00b7heit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PPER", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.164": {"text": "gaben", "tokens": ["ga\u00b7ben"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.165": {"text": "Doch aber von Natur/ wer wolt es b\u00e4sser haben?", "tokens": ["Doch", "a\u00b7ber", "von", "Na\u00b7tur", "/", "wer", "wolt", "es", "b\u00e4s\u00b7ser", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$(", "PWS", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "Die andern schmincken sich un\u0303 wollen sch\u00f6ner seyn/", "tokens": ["Die", "an\u00b7dern", "schmin\u00b7cken", "sich", "u\u00f1", "wol\u00b7len", "sch\u00f6\u00b7ner", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "NE", "VMFIN", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Sie tadeln die Natur/ und gehn wie pfauen rein.", "tokens": ["Sie", "ta\u00b7deln", "die", "Na\u00b7tur", "/", "und", "gehn", "wie", "pfau\u00b7en", "rein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "KON", "VVINF", "KOKOM", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Sie aber bleibt wie sie Jhr Sch\u00f6pfer hatt formieret/", "tokens": ["Sie", "a\u00b7ber", "bleibt", "wie", "sie", "Ihr", "Sch\u00f6p\u00b7fer", "hatt", "for\u00b7mie\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "KOKOM", "PPER", "PPOSAT", "NN", "VAFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Hat sich mit gummt nicht un\u0303 silber-gl\u00e4th beschmieret/", "tokens": ["Hat", "sich", "mit", "gummt", "nicht", "u\u00f1", "sil\u00b7ber\u00b7gl\u00e4th", "be\u00b7schmie\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "APPR", "VVFIN", "PTKNEG", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.170": {"text": "und ist doch Eure Sch\u00f6nst\u2019 und liebste f\u00fcr und f\u00fcr", "tokens": ["und", "ist", "doch", "Eu\u00b7re", "Sch\u00f6nst'", "und", "liebs\u00b7te", "f\u00fcr", "und", "f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "In dem Sie u\u0303bertrifft die andern an der zier.", "tokens": ["In", "dem", "Sie", "\u0169ber\u00b7trifft", "die", "an\u00b7dern", "an", "der", "zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "ART", "ADJA", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.172": {"text": "Ey nun gehabt Euch wohl: die Nacht will einher bre-", "tokens": ["Ey", "nun", "ge\u00b7habt", "Euch", "wohl", ":", "die", "Nacht", "will", "ein\u00b7her", "bre"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VAPP", "PPER", "ADV", "$.", "ART", "NN", "VMFIN", "PIAT", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "chen/", "tokens": ["chen", "/"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "-", "measure": "single.down"}, "line.174": {"text": "Heut spricht man Jungfer geht/ und morgen wird", "tokens": ["Heut", "spricht", "man", "Jung\u00b7fer", "geht", "/", "und", "mor\u00b7gen", "wird"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "NN", "VVFIN", "$(", "KON", "ADV", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.175": {"text": "mann sprechen/", "tokens": ["mann", "spre\u00b7chen", "/"], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVINF", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.176": {"text": "Willkommen Jungefrau; geht/ geht und steckt", "tokens": ["Will\u00b7kom\u00b7men", "Jun\u00b7ge\u00b7frau", ";", "geht", "/", "geht", "und", "steckt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$.", "VVFIN", "$(", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.177": {"text": "den kohl/", "tokens": ["den", "kohl", "/"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.178": {"text": "Da\u00df er auff Pfingsten trag\u2019: Ey nun gehabt euch", "tokens": ["Da\u00df", "er", "auff", "Pfings\u00b7ten", "trag'", ":", "Ey", "nun", "ge\u00b7habt", "euch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$.", "NN", "ADV", "VAPP", "PPER"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.179": {"text": "wohl!", "tokens": ["wohl", "!"], "token_info": ["word", "punct"], "pos": ["ADV", "$."], "meter": "+", "measure": "single.up"}}}}}