{"textgrid.poem.59703": {"metadata": {"author": {"name": "Arndt, Ernst Moritz", "birth": "N.A.", "death": "N.A."}, "title": "Zu Martin Luthers 300j\u00e4hriger Todesfeier", "genre": "verse", "period": "N.A.", "pub_year": 1814, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr wagt's, die Toten aufzuwecken?", "tokens": ["Ihr", "wagt's", ",", "die", "To\u00b7ten", "auf\u00b7zu\u00b7we\u00b7cken", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O la\u00dft den alten Luther ruhn!", "tokens": ["O", "la\u00dft", "den", "al\u00b7ten", "Lu\u00b7ther", "ruhn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erbebt ihr nicht den blassen Schrecken", "tokens": ["Er\u00b7bebt", "ihr", "nicht", "den", "blas\u00b7sen", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Donnerkinds f\u00fcr euer Tun?", "tokens": ["Des", "Don\u00b7ner\u00b7kinds", "f\u00fcr", "eu\u00b7er", "Tun", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dreihundert Jahr hat er geschlafen \u2013", "tokens": ["Drei\u00b7hun\u00b7dert", "Jahr", "hat", "er", "ge\u00b7schla\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.6": {"text": "Seid ihr die Reinen, Freien, Braven,", "tokens": ["Seid", "ihr", "die", "Rei\u00b7nen", ",", "Frei\u00b7en", ",", "Bra\u00b7ven", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAIMP", "PPER", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die seiner Klinge Blitz bestehn?", "tokens": ["Die", "sei\u00b7ner", "Klin\u00b7ge", "Blitz", "be\u00b7stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Denn Blitz f\u00fchrt seines Wortes Klinge \u2013", "tokens": ["Denn", "Blitz", "f\u00fchrt", "sei\u00b7nes", "Wor\u00b7tes", "Klin\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hui! Turm und Mauer, Wall und Burg!", "tokens": ["Hui", "!", "Turm", "und", "Mau\u00b7er", ",", "Wall", "und", "Burg", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM", "$.", "NN", "KON", "NN", "$,", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hui! Feinster Listen Kettenringe", "tokens": ["Hui", "!", "Feins\u00b7ter", "Lis\u00b7ten", "Ket\u00b7ten\u00b7rin\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["FM", "$.", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er st\u00fcrmt und bricht und haut sie durch. \u2013", "tokens": ["Er", "st\u00fcrmt", "und", "bricht", "und", "haut", "sie", "durch", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch horch'! Wie? Naht sein Waffenklirren?", "tokens": ["Doch", "horch'", "!", "Wie", "?", "Naht", "sein", "Waf\u00b7fenk\u00b7lir\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$.", "PWAV", "$.", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es lispelt nicht wie Taubengirren \u2013", "tokens": ["Es", "lis\u00b7pelt", "nicht", "wie", "Tau\u00b7ben\u00b7gir\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "KOKOM", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "In S\u00e4useln kommt der Donner nicht.", "tokens": ["In", "S\u00e4u\u00b7seln", "kommt", "der", "Don\u00b7ner", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbwie,\u00ab ruft er, \u00bbzaubert aus dem Grabe", "tokens": ["\u00bb", "wie", ",", "\u00ab", "ruft", "er", ",", "\u00bb", "zau\u00b7bert", "aus", "dem", "Gra\u00b7be"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Prophetenstimmen ihr herauf?", "tokens": ["Pro\u00b7phe\u00b7ten\u00b7stim\u00b7men", "ihr", "her\u00b7auf", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4ngst trug ich meiner Arbeit Habe", "tokens": ["L\u00e4ngst", "trug", "ich", "mei\u00b7ner", "Ar\u00b7beit", "Ha\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu meinem Gott und Christ hinauf.", "tokens": ["Zu", "mei\u00b7nem", "Gott", "und", "Christ", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00dft Tote modern bei den Toten!", "tokens": ["La\u00dft", "To\u00b7te", "mo\u00b7dern", "bei", "den", "To\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zu h\u00f6chsten Sternen sendet Boten,", "tokens": ["Zu", "h\u00f6chs\u00b7ten", "Ster\u00b7nen", "sen\u00b7det", "Bo\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da fragt der Zukunft Donnerlaut.", "tokens": ["Da", "fragt", "der", "Zu\u00b7kunft", "Don\u00b7ner\u00b7laut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn Donnerglocken k\u00f6nnt' ich l\u00e4uten,", "tokens": ["Denn", "Don\u00b7ner\u00b7glo\u00b7cken", "k\u00f6nnt'", "ich", "l\u00e4u\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Worob Gesicht und Ohr vergehn,", "tokens": ["Wo\u00b7rob", "Ge\u00b7sicht", "und", "Ohr", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So nahe ferne Zeichen deuten,", "tokens": ["So", "na\u00b7he", "fer\u00b7ne", "Zei\u00b7chen", "deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit solchem Grausen euch durchwehn,", "tokens": ["Mit", "sol\u00b7chem", "Grau\u00b7sen", "euch", "durch\u00b7wehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ihr im Zittern und Verzagen", "tokens": ["Da\u00df", "ihr", "im", "Zit\u00b7tern", "und", "Ver\u00b7za\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mit euren Klagen, euren Fragen", "tokens": ["Mit", "eu\u00b7ren", "Kla\u00b7gen", ",", "eu\u00b7ren", "Fra\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Verstummtet vor dem Schreckenklang.", "tokens": ["Ver\u00b7stumm\u00b7tet", "vor", "dem", "Schre\u00b7cken\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Denn wohl k\u00f6nnt' ich zuerst euch fragen,", "tokens": ["Denn", "wohl", "k\u00f6nnt'", "ich", "zu\u00b7erst", "euch", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ihr das Erbe angewandt,", "tokens": ["Wie", "ihr", "das", "Er\u00b7be", "an\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das einst in Sorgen, K\u00e4mpfen, Plagen", "tokens": ["Das", "einst", "in", "Sor\u00b7gen", ",", "K\u00e4mp\u00b7fen", ",", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PDS", "ADV", "APPR", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich euch errang mit starker Hand,", "tokens": ["Ich", "euch", "er\u00b7rang", "mit", "star\u00b7ker", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Erb' und Recht des tapfern Wortes;", "tokens": ["Das", "Erb'", "und", "Recht", "des", "tap\u00b7fern", "Wor\u00b7tes", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ob ihr des goldnen Freiheitshortes", "tokens": ["Ob", "ihr", "des", "gold\u00b7nen", "Frei\u00b7heits\u00b7hor\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die k\u00fchnen, wachen W\u00e4chter seid;", "tokens": ["Die", "k\u00fch\u00b7nen", ",", "wa\u00b7chen", "W\u00e4ch\u00b7ter", "seid", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ob von Innozenzen und Gregoren,", "tokens": ["Ob", "von", "In\u00b7no\u00b7zen\u00b7zen", "und", "Gre\u00b7go\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von Loyolas Assassinenschwarm,", "tokens": ["Von", "Lo\u00b7yo\u00b7las", "As\u00b7sas\u00b7si\u00b7nen\u00b7schwarm", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Von Rittern von den goldnen Sporen", "tokens": ["Von", "Rit\u00b7tern", "von", "den", "gold\u00b7nen", "Spo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Euch keiner bog den deutschen Arm,", "tokens": ["Euch", "kei\u00b7ner", "bog", "den", "deut\u00b7schen", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ob welschen Schleichern, Sp\u00e4hern, Schranzen", "tokens": ["Ob", "wel\u00b7schen", "Schlei\u00b7chern", ",", "Sp\u00e4\u00b7hern", ",", "Schran\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PWAT", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr hieltet vor die rechten Lanzen", "tokens": ["Ihr", "hiel\u00b7tet", "vor", "die", "rech\u00b7ten", "Lan\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "F\u00fcr Gott und Recht und Vaterland.", "tokens": ["F\u00fcr", "Gott", "und", "Recht", "und", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Denn wohl zum zweiten k\u00f6nnt' ich fragen,", "tokens": ["Denn", "wohl", "zum", "zwei\u00b7ten", "k\u00f6nnt'", "ich", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "ADJA", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ob Menschenwitz und Satanslist", "tokens": ["Ob", "Men\u00b7schen\u00b7witz", "und", "Sa\u00b7tans\u00b7list"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit leersten K\u00fcnsten nicht sich schlagen", "tokens": ["Mit", "leers\u00b7ten", "K\u00fcns\u00b7ten", "nicht", "sich", "schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Um meinen Glauben, meinen Christ,", "tokens": ["Um", "mei\u00b7nen", "Glau\u00b7ben", ",", "mei\u00b7nen", "Christ", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ob ihr in guten, frohen Dingen", "tokens": ["Ob", "ihr", "in", "gu\u00b7ten", ",", "fro\u00b7hen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Noch k\u00f6nnt mit mir von Herzen singen:", "tokens": ["Noch", "k\u00f6nnt", "mit", "mir", "von", "Her\u00b7zen", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u203a", "tokens": ["\u203a"], "token_info": ["punct"], "pos": ["$("]}}, "stanza.8": {"line.1": {"text": "Jawohl zum ersten, zweiten, dritten \u2013", "tokens": ["Ja\u00b7wohl", "zum", "ers\u00b7ten", ",", "zwei\u00b7ten", ",", "drit\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "$,", "VVFIN", "$,", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hauche weg wie Wind die Spreu,", "tokens": ["Ich", "hau\u00b7che", "weg", "wie", "Wind", "die", "Spreu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KOKOM", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was ihr gelitten, was gestritten,", "tokens": ["Was", "ihr", "ge\u00b7lit\u00b7ten", ",", "was", "ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War's nicht um, f\u00fcr und durch die Treu',", "tokens": ["Wa\u00b7r's", "nicht", "um", ",", "f\u00fcr", "und", "durch", "die", "Treu'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "PTKVZ", "$,", "APPR", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Denn fallt ihr hier der scharfen Frage,", "tokens": ["Denn", "fallt", "ihr", "hier", "der", "schar\u00b7fen", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So wird zum M\u00e4rchen gar die Sage,", "tokens": ["So", "wird", "zum", "M\u00e4r\u00b7chen", "gar", "die", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch schon zuviel der strengen Worte,", "tokens": ["Doch", "schon", "zu\u00b7viel", "der", "stren\u00b7gen", "Wor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ziemt der Zorn dem Feste nicht.\u00ab", "tokens": ["Es", "ziemt", "der", "Zorn", "dem", "Fes\u00b7te", "nicht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er schweigt; ausgie\u00dft die Himmelspforte", "tokens": ["Er", "schweigt", ";", "aus\u00b7gie\u00dft", "die", "Him\u00b7mel\u00b7spfor\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den hellsten, vollsten Strom von Licht.", "tokens": ["Den", "hells\u00b7ten", ",", "volls\u00b7ten", "Strom", "von", "Licht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So f\u00e4hrt der alte, tapfre Meister", "tokens": ["So", "f\u00e4hrt", "der", "al\u00b7te", ",", "tapf\u00b7re", "Meis\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In Licht und Blitz ins Reich der Geister", "tokens": ["In", "Licht", "und", "Blitz", "ins", "Reich", "der", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Zu seinem Gott und Christ zur\u00fcck.", "tokens": ["Zu", "sei\u00b7nem", "Gott", "und", "Christ", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}