{"dta.poem.18505": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Der Brillen-Drehbuden- und  \n Stech-Buch-Mann  \n Cupido.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1703", "urn": "urn:nbn:de:kobv:b4-200905199360", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Me\u00dfieurs/ es war mit mir gantz auf die neige kommen/", "tokens": ["Me\u00b7\u00dfie\u00b7urs", "/", "es", "war", "mit", "mir", "gantz", "auf", "die", "nei\u00b7ge", "kom\u00b7men", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VAFIN", "APPR", "PPER", "ADV", "APPR", "ART", "ADJA", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "Die Pohlen hatten mir den vorrath abgenommen/", "tokens": ["Die", "Poh\u00b7len", "hat\u00b7ten", "mir", "den", "vor\u00b7rath", "ab\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verboten mir das land/ da war mein handel aus/", "tokens": ["Ver\u00b7bo\u00b7ten", "mir", "das", "land", "/", "da", "war", "mein", "han\u00b7del", "aus", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$(", "ADV", "VAFIN", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So da\u00df ich wieder kam zu meinen Deutschen raus.", "tokens": ["So", "da\u00df", "ich", "wie\u00b7der", "kam", "zu", "mei\u00b7nen", "Deut\u00b7schen", "raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich zog im lande rum und hatte meine fratzen/", "tokens": ["Ich", "zog", "im", "lan\u00b7de", "rum", "und", "hat\u00b7te", "mei\u00b7ne", "frat\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "KON", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch wenn ich ohngefehr mit einer wolte schwatzen/", "tokens": ["Doch", "wenn", "ich", "ohn\u00b7ge\u00b7fehr", "mit", "ei\u00b7ner", "wol\u00b7te", "schwat\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "APPR", "PIS", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So kr\u00fcmmte sie das maul und sah mich finster an/", "tokens": ["So", "kr\u00fcmm\u00b7te", "sie", "das", "maul", "und", "sah", "mich", "fins\u00b7ter", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als h\u00e4tt ich ihr viel leid und \u00fcberlast gethan/", "tokens": ["Als", "h\u00e4tt", "ich", "ihr", "viel", "leid", "und", "\u00fc\u00b7berl\u00b7ast", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "PPER", "ADV", "ADJD", "KON", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich fing zu l\u00f6flen an/ und war dahin beflissen/", "tokens": ["Ich", "fing", "zu", "l\u00f6f\u00b7len", "an", "/", "und", "war", "da\u00b7hin", "be\u00b7flis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKZU", "VVINF", "PTKVZ", "$(", "KON", "VAFIN", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ob ich durch h\u00f6flichkeit und liebes h\u00e4nde-k\u00fcssen", "tokens": ["Ob", "ich", "durch", "h\u00f6f\u00b7lich\u00b7keit", "und", "lie\u00b7bes", "h\u00e4n\u00b7de\u00b7k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die gunst erzwingen k\u00f6nt/ ich macht ihr treulich kund/", "tokens": ["Die", "gunst", "er\u00b7zwin\u00b7gen", "k\u00f6nt", "/", "ich", "macht", "ihr", "treu\u00b7lich", "kund", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ich sey ihr selave/ knecht/ schulappe/ wasserhund/", "tokens": ["Ich", "sey", "ihr", "se\u00b7la\u00b7ve", "/", "knecht", "/", "schul\u00b7ap\u00b7pe", "/", "was\u00b7ser\u00b7hund", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "$(", "VVFIN", "$(", "VVFIN", "$(", "VVFIN", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Doch alles war umsonst; ich dachte sie zu zwingen/", "tokens": ["Doch", "al\u00b7les", "war", "um\u00b7sonst", ";", "ich", "dach\u00b7te", "sie", "zu", "zwin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und wolte Cavaliers dem sauer-topfe bringen;", "tokens": ["Und", "wol\u00b7te", "Ca\u00b7va\u00b7liers", "dem", "sau\u00b7e\u00b7rtop\u00b7fe", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NE", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Doch stund kein stecken recht/ der war ihr gar zu alt", "tokens": ["Doch", "stund", "kein", "ste\u00b7cken", "recht", "/", "der", "war", "ihr", "gar", "zu", "alt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "VVFIN", "ADJD", "$(", "ART", "VAFIN", "PPER", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und jener allzuklein/ der ander ungestalt/", "tokens": ["Und", "je\u00b7ner", "all\u00b7zu\u00b7klein", "/", "der", "an\u00b7der", "un\u00b7ge\u00b7stalt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "$(", "ART", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die einfalt s\u00e4he dem leibhafftig aus den augen/", "tokens": ["Die", "ein\u00b7falt", "s\u00e4\u00b7he", "dem", "leib\u00b7haff\u00b7tig", "aus", "den", "au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Derwegen k\u00f6nt er nicht zu solchen sachen taugen/", "tokens": ["Der\u00b7we\u00b7gen", "k\u00f6nt", "er", "nicht", "zu", "sol\u00b7chen", "sa\u00b7chen", "tau\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der ginge wie ein artzt/ der h\u00e4tt ein loch im hut/", "tokens": ["Der", "gin\u00b7ge", "wie", "ein", "artzt", "/", "der", "h\u00e4tt", "ein", "loch", "im", "hut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KOKOM", "ART", "NN", "$(", "ART", "VAFIN", "ART", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der w\u00e4re gar ein narr/ es w\u00e4r ihm keine gut/", "tokens": ["Der", "w\u00e4\u00b7re", "gar", "ein", "narr", "/", "es", "w\u00e4r", "ihm", "kei\u00b7ne", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "$(", "PPER", "VAFIN", "PPER", "PIAT", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich lie\u00df die jungfern stehn/ und ging zu junggesellen/", "tokens": ["Ich", "lie\u00df", "die", "jung\u00b7fern", "stehn", "/", "und", "ging", "zu", "jung\u00b7ge\u00b7sel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "VVINF", "$(", "KON", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "In meinung da\u00df sie sich weit anders w\u00fcrden stellen.", "tokens": ["In", "mei\u00b7nung", "da\u00df", "sie", "sich", "weit", "an\u00b7ders", "w\u00fcr\u00b7den", "stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KOUS", "PPER", "PRF", "ADJD", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Da sperrt ich alsobald na\u00df/ maul und ohren auf/", "tokens": ["Da", "sperrt", "ich", "al\u00b7so\u00b7bald", "na\u00df", "/", "maul", "und", "oh\u00b7ren", "auf", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$(", "NE", "KON", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Wie diese gleichfalls auch zum dicksten schm\u00e4lten drauf.", "tokens": ["Wie", "die\u00b7se", "gleich\u00b7falls", "auch", "zum", "dicks\u00b7ten", "schm\u00e4l\u00b7ten", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ADV", "ADV", "APPRART", "ADJA", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Da must sich unter den bald die/ bald jene leiden/", "tokens": ["Da", "must", "sich", "un\u00b7ter", "den", "bald", "die", "/", "bald", "je\u00b7ne", "lei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PRF", "APPR", "ART", "ADV", "ART", "$(", "ADV", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die h\u00e4tte keinen rock und k\u00f6nte sich nicht kleiden/", "tokens": ["Die", "h\u00e4t\u00b7te", "kei\u00b7nen", "rock", "und", "k\u00f6n\u00b7te", "sich", "nicht", "klei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "NN", "KON", "VMFIN", "PRF", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Das w\u00e4r ein alber ding/ die h\u00e4tt ein b\u00f6sen kopf/", "tokens": ["Das", "w\u00e4r", "ein", "al\u00b7ber", "ding", "/", "die", "h\u00e4tt", "ein", "b\u00f6\u00b7sen", "kopf", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$(", "PDS", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Denselben deckten zu die spitzen und der zopf.", "tokens": ["Den\u00b7sel\u00b7ben", "deck\u00b7ten", "zu", "die", "spit\u00b7zen", "und", "der", "zopf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "VVINF", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Die s\u00e4he garstig aus/ die h\u00e4tte gar den schneider/", "tokens": ["Die", "s\u00e4\u00b7he", "gars\u00b7tig", "aus", "/", "die", "h\u00e4t\u00b7te", "gar", "den", "schnei\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "PTKVZ", "$(", "ART", "VAFIN", "ADV", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und jenes gute ding/ das w\u00e4re nun auch leider/", "tokens": ["Und", "je\u00b7nes", "gu\u00b7te", "ding", "/", "das", "w\u00e4\u00b7re", "nun", "auch", "lei\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "$(", "PDS", "VAFIN", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "In etwas gar zu alt: Das waren ihre wort:", "tokens": ["In", "et\u00b7was", "gar", "zu", "alt", ":", "Das", "wa\u00b7ren", "ih\u00b7re", "wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "ADV", "PTKA", "ADJD", "$.", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Da ward ich feuer-roth/ und eilte wieder fort.", "tokens": ["Da", "ward", "ich", "feu\u00b7er\u00b7roth", "/", "und", "eil\u00b7te", "wie\u00b7der", "fort", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$(", "KON", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ich dachte/ was wird doch das werden unterdessen/", "tokens": ["Ich", "dach\u00b7te", "/", "was", "wird", "doch", "das", "wer\u00b7den", "un\u00b7ter\u00b7des\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWS", "VAFIN", "ADV", "PDS", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ich mus bey meiner kunst gar schmale bissen fressen/", "tokens": ["Ich", "mus", "bey", "mei\u00b7ner", "kunst", "gar", "schma\u00b7le", "bis\u00b7sen", "fres\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "ADV", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Das handwerck gieng nicht ab. Doch was die noth nicht kan!", "tokens": ["Das", "hand\u00b7werck", "gieng", "nicht", "ab", ".", "Doch", "was", "die", "noth", "nicht", "kan", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$.", "KON", "PWS", "ART", "NN", "PTKNEG", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Ich gab den handel auf und ward ein brillen-mann.", "tokens": ["Ich", "gab", "den", "han\u00b7del", "auf", "und", "ward", "ein", "bril\u00b7len\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ich m\u00f6chte mich fast selbst zum butter-wecken lachen/", "tokens": ["Ich", "m\u00f6ch\u00b7te", "mich", "fast", "selbst", "zum", "but\u00b7ter\u00b7we\u00b7cken", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Ich spickte meinen kram mit allen sieben sachen/", "tokens": ["Ich", "spick\u00b7te", "mei\u00b7nen", "kram", "mit", "al\u00b7len", "sie\u00b7ben", "sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PIAT", "CARD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Was nur fein n\u00e4rrisch war/ das kaufft ich immer ein/", "tokens": ["Was", "nur", "fein", "n\u00e4r\u00b7risch", "war", "/", "das", "kaufft", "ich", "im\u00b7mer", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "ADJD", "VAFIN", "$(", "PDS", "VVFIN", "PPER", "ADV", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Und machte mich damit in die stadt Leipzig nein/", "tokens": ["Und", "mach\u00b7te", "mich", "da\u00b7mit", "in", "die", "stadt", "Leip\u00b7zig", "nein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "APPR", "ART", "NN", "NE", "PTKANT", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Schnipscherchen/ beutelgen/ fl\u00f6hfallen/ biesem-kn\u00f6pfgen/", "tokens": ["Schnip\u00b7scher\u00b7chen", "/", "beu\u00b7tel\u00b7gen", "/", "fl\u00f6h\u00b7fal\u00b7len", "/", "bie\u00b7sem\u00b7kn\u00f6pf\u00b7gen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "VVINF", "$(", "VVINF", "$(", "NE", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.42": {"text": "Ohrl\u00f6ffel/ becherchen/ und kleine kinder-t\u00f6pfgen/", "tokens": ["Ohr\u00b7l\u00f6f\u00b7fel", "/", "be\u00b7cher\u00b7chen", "/", "und", "klei\u00b7ne", "kin\u00b7der\u00b7t\u00f6pf\u00b7gen", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVINF", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.43": {"text": "Citronen und was mehr/ kamm/ spiegel/ fingerhut/", "tokens": ["Cit\u00b7ro\u00b7nen", "und", "was", "mehr", "/", "kamm", "/", "spie\u00b7gel", "/", "fin\u00b7ger\u00b7hut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "PWS", "ADV", "$(", "VVFIN", "$(", "NE", "$(", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Spiel-karten/ ringelchen/ und ander kaufmanns-gut/", "tokens": ["Spiel\u00b7kar\u00b7ten", "/", "rin\u00b7gel\u00b7chen", "/", "und", "an\u00b7der", "kauf\u00b7manns\u00b7gut", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "$(", "KON", "ADJD", "ADJD", "$("], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.45": {"text": "Das pflegt ich also nun hausieren rum zutragen/", "tokens": ["Das", "pflegt", "ich", "al\u00b7so", "nun", "hau\u00b7sie\u00b7ren", "rum", "zu\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.46": {"text": "Wo liederliche Bursch vielleicht beysammen lagen/", "tokens": ["Wo", "lie\u00b7der\u00b7li\u00b7che", "Bursch", "viel\u00b7leicht", "bey\u00b7sam\u00b7men", "la\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ADV", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Und suchte nur profit/ doch lie\u00df ichs zeitlich stehn/", "tokens": ["Und", "such\u00b7te", "nur", "pro\u00b7fit", "/", "doch", "lie\u00df", "ichs", "zeit\u00b7lich", "stehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$(", "ADV", "VVFIN", "PIS", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Aus ursach: dieser ort war leider b\u00f6\u00df zu gehn.", "tokens": ["Aus", "ur\u00b7sach", ":", "die\u00b7ser", "ort", "war", "lei\u00b7der", "b\u00f6\u00df", "zu", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "PDAT", "NN", "VAFIN", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Es ist ein sch\u00f6ner ort/ von marckt und sch\u00f6nen gassen/", "tokens": ["Es", "ist", "ein", "sch\u00f6\u00b7ner", "ort", "/", "von", "marckt", "und", "sch\u00f6\u00b7nen", "gas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "APPR", "VVFIN", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Man geht sich l\u00e4schicht bald hin und her auf den strassen.", "tokens": ["Man", "geht", "sich", "l\u00e4\u00b7schicht", "bald", "hin", "und", "her", "auf", "den", "stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "VVFIN", "ADV", "PTKVZ", "KON", "ADV", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Und sieht man immerfort nicht vor sich auf den weg/", "tokens": ["Und", "sieht", "man", "im\u00b7mer\u00b7fort", "nicht", "vor", "sich", "auf", "den", "weg", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "PTKNEG", "APPR", "PRF", "APPR", "ART", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "So stolpert man alsbald/ und f\u00e4llt wohl gar in dreck.", "tokens": ["So", "stol\u00b7pert", "man", "als\u00b7bald", "/", "und", "f\u00e4llt", "wohl", "gar", "in", "dreck", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$(", "KON", "VVFIN", "ADV", "ADV", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ich hatte sonsten auch noch auf ein kleines g\u00e4\u00dfgen/", "tokens": ["Ich", "hat\u00b7te", "sons\u00b7ten", "auch", "noch", "auf", "ein", "klei\u00b7nes", "g\u00e4\u00df\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Da mir es n\u00e4rrisch gieng/ ein halb verdecktes h\u00e4\u00dfgen/", "tokens": ["Da", "mir", "es", "n\u00e4r\u00b7risch", "gieng", "/", "ein", "halb", "ver\u00b7deck\u00b7tes", "h\u00e4\u00df\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$(", "ART", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Drum mocht ich l\u00e4nget nicht hausieren r\u00fcmmer gehn/", "tokens": ["Drum", "mocht", "ich", "l\u00e4n\u00b7get", "nicht", "hau\u00b7sie\u00b7ren", "r\u00fcm\u00b7mer", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "VVFIN", "PTKNEG", "VVFIN", "ADV", "VVINF", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.56": {"text": "Und lie\u00df das plunderwerck und lumpen-handel stehn.", "tokens": ["Und", "lie\u00df", "das", "plun\u00b7der\u00b7werck", "und", "lum\u00b7pen\u00b7han\u00b7del", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Ich schlug drehbuden auf/ ich lie\u00df ins geldbuch stechen/", "tokens": ["Ich", "schlug", "dreh\u00b7bu\u00b7den", "auf", "/", "ich", "lie\u00df", "ins", "geld\u00b7buch", "ste\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$(", "PPER", "VVFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und auf dem eisen drehn/ da kamen aus den zechen", "tokens": ["Und", "auf", "dem", "ei\u00b7sen", "drehn", "/", "da", "ka\u00b7men", "aus", "den", "ze\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "VVINF", "$(", "ADV", "VVFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Die bauer-knechte raus/ und satzten bey mir an/", "tokens": ["Die", "bau\u00b7e\u00b7rknech\u00b7te", "raus", "/", "und", "satz\u00b7ten", "bey", "mir", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$(", "KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Ich schrie auch weidlich aus: wer wagts? wie: weiter dran.", "tokens": ["Ich", "schrie", "auch", "weid\u00b7lich", "aus", ":", "wer", "wagts", "?", "wie", ":", "wei\u00b7ter", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "PWS", "VVFIN", "$.", "PWAV", "$.", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Indessen k\u00f6mmt zu mit ein Sch\u00e4fer auch getreten/", "tokens": ["In\u00b7des\u00b7sen", "k\u00f6mmt", "zu", "mit", "ein", "Sch\u00e4\u00b7fer", "auch", "ge\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "APPR", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Nun sah ich alsobald/ da\u00df er nicht wolte beten/", "tokens": ["Nun", "sah", "ich", "al\u00b7so\u00b7bald", "/", "da\u00df", "er", "nicht", "wol\u00b7te", "be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "KOUS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Und hielt ihm f\u00fcr das buch/ da stach er tapffer drein/", "tokens": ["Und", "hielt", "ihm", "f\u00fcr", "das", "buch", "/", "da", "stach", "er", "tapf\u00b7fer", "drein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Es traf ihm aber erst nicht nach belieben ein.", "tokens": ["Es", "traf", "ihm", "a\u00b7ber", "erst", "nicht", "nach", "be\u00b7lie\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "APPR", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Die pfennge giengen weg/ er aber stach darneben/", "tokens": ["Die", "pfenn\u00b7ge", "gien\u00b7gen", "weg", "/", "er", "a\u00b7ber", "stach", "dar\u00b7ne\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "PPER", "ADV", "VVFIN", "PAV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Ich sagte besser dran/ es wird sich alles geben/", "tokens": ["Ich", "sag\u00b7te", "bes\u00b7ser", "dran", "/", "es", "wird", "sich", "al\u00b7les", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PAV", "$(", "PPER", "VAFIN", "PRF", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Da ich kaum ausgeredt/ so sticht er auf ein blat/", "tokens": ["Da", "ich", "kaum", "aus\u00b7ge\u00b7redt", "/", "so", "sticht", "er", "auf", "ein", "blat", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Das ein sch\u00f6n jungfer-bild gemahlet in sich hat.", "tokens": ["Das", "ein", "sch\u00f6n", "jung\u00b7fer\u00b7bild", "ge\u00b7mah\u00b7let", "in", "sich", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJD", "ADJD", "VVPP", "APPR", "PRF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Da drang er auf mich los/ ich wolt es zwar verblettern/", "tokens": ["Da", "drang", "er", "auf", "mich", "los", "/", "ich", "wolt", "es", "zwar", "ver\u00b7blet\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "PTKVZ", "$(", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Er aber lie\u00df nicht ab/ und sprach: ihr schlimmen vettern/", "tokens": ["Er", "a\u00b7ber", "lie\u00df", "nicht", "ab", "/", "und", "sprach", ":", "ihr", "schlim\u00b7men", "vet\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKNEG", "PTKVZ", "$(", "KON", "VVFIN", "$.", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Teuscht ihr die leute so/ ich nehme sonst nichts an/", "tokens": ["Teu\u00b7scht", "ihr", "die", "leu\u00b7te", "so", "/", "ich", "neh\u00b7me", "sonst", "nichts", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$(", "PPER", "VVFIN", "ADV", "PIS", "PTKVZ", "$("], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.72": {"text": "Und solt ich setzen auch mein haab und haare dran.", "tokens": ["Und", "solt", "ich", "set\u00b7zen", "auch", "mein", "ha\u00b7ab", "und", "haa\u00b7re", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.73": {"text": "Drauf must ich endlich doch zur zahlung mich verstehen/", "tokens": ["Drauf", "must", "ich", "end\u00b7lich", "doch", "zur", "zah\u00b7lung", "mich", "ver\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Und mit ihm auf begehr zu feinen m\u00e4dgen gehen/", "tokens": ["Und", "mit", "ihm", "auf", "be\u00b7gehr", "zu", "fei\u00b7nen", "m\u00e4d\u00b7gen", "ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "APPR", "ADJD", "PTKZU", "VVINF", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Indem ich noch so steh und siun in etwas drauf/", "tokens": ["In\u00b7dem", "ich", "noch", "so", "steh", "und", "si\u00b7un", "in", "et\u00b7was", "drauf", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "APPR", "PIS", "PTKVZ", "$("], "meter": "+----+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.76": {"text": "Macht gleich ein jungfer-bild das stuben-fenster auf.", "tokens": ["Macht", "gleich", "ein", "jung\u00b7fer\u00b7bild", "das", "stu\u00b7ben\u00b7fens\u00b7ter", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJD", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Das war mir alsobald umb so viel desto lieber/", "tokens": ["Das", "war", "mir", "al\u00b7so\u00b7bald", "umb", "so", "viel", "des\u00b7to", "lie\u00b7ber", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "APPR", "ADV", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.78": {"text": "Denn meine bude stund dem hause gegen \u00fcber.", "tokens": ["Denn", "mei\u00b7ne", "bu\u00b7de", "stund", "dem", "hau\u00b7se", "ge\u00b7gen", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Ich sprach sie freundlich an/ wie meine g\u00fcte pflegt/", "tokens": ["Ich", "sprach", "sie", "freund\u00b7lich", "an", "/", "wie", "mei\u00b7ne", "g\u00fc\u00b7te", "pflegt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$(", "KOKOM", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Wenn sie ein irdisch hertz in liebes-wahn bewegt/", "tokens": ["Wenn", "sie", "ein", "ir\u00b7disch", "hertz", "in", "lie\u00b7bes\u00b7wahn", "be\u00b7wegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "NN", "APPR", "NE", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Als ich den ersten pfeil nun auf sie zugeschossen/", "tokens": ["Als", "ich", "den", "ers\u00b7ten", "pfeil", "nun", "auf", "sie", "zu\u00b7ge\u00b7schos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "So kannte sie mein wort/ und merckte solche possen/", "tokens": ["So", "kann\u00b7te", "sie", "mein", "wort", "/", "und", "merck\u00b7te", "sol\u00b7che", "pos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PIAT", "NN", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.83": {"text": "Sprach auch gar willig ja/ und lenckte ihren sinn/", "tokens": ["Sprach", "auch", "gar", "wil\u00b7lig", "ja", "/", "und", "lenck\u00b7te", "ih\u00b7ren", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADJD", "ADV", "$(", "KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Auf mein begehren drauf/ zu ihren sch\u00e4fer hin.", "tokens": ["Auf", "mein", "be\u00b7geh\u00b7ren", "drauf", "/", "zu", "ih\u00b7ren", "sch\u00e4\u00b7fer", "hin", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVFIN", "PAV", "$(", "APPR", "PPOSAT", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Doch setzt ich das darzu: Er solt es niemand sagen;", "tokens": ["Doch", "setzt", "ich", "das", "dar\u00b7zu", ":", "Er", "solt", "es", "nie\u00b7mand", "sa\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "PAV", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Da\u00df er auf einen stich die jungfer weg getragen/", "tokens": ["Da\u00df", "er", "auf", "ei\u00b7nen", "stich", "die", "jung\u00b7fer", "weg", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJD", "ART", "ADJA", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Sonst w\u00fcrd ich ander ding nicht einmahl werden lo\u00df/", "tokens": ["Sonst", "w\u00fcrd", "ich", "an\u00b7der", "ding", "nicht", "ein\u00b7mahl", "wer\u00b7den", "lo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVFIN", "PTKNEG", "ADV", "VAINF", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und w\u00e4r um meinen kram der auflauf gar zu gro\u00df.", "tokens": ["Und", "w\u00e4r", "um", "mei\u00b7nen", "kram", "der", "auf\u00b7lauf", "gar", "zu", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "APPR", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Nun immer frisch heran? Wer will noch weiter wagen?", "tokens": ["Nun", "im\u00b7mer", "frisch", "he\u00b7ran", "?", "Wer", "will", "noch", "wei\u00b7ter", "wa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PTKVZ", "$.", "PWS", "VMFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Kommt/ stechet in das buch/ so k\u00f6nt ihr davon tragen/", "tokens": ["Kommt", "/", "ste\u00b7chet", "in", "das", "buch", "/", "so", "k\u00f6nt", "ihr", "da\u00b7von", "tra\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "APPR", "ART", "NN", "$(", "ADV", "VMFIN", "PPER", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Was mehr von solcher art in meinem krahme steht/", "tokens": ["Was", "mehr", "von", "sol\u00b7cher", "art", "in", "mei\u00b7nem", "krah\u00b7me", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Sa! immer frisch gewagt/ eh noch der marck vergeht.", "tokens": ["Sa", "!", "im\u00b7mer", "frisch", "ge\u00b7wagt", "/", "eh", "noch", "der", "marck", "ver\u00b7geht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "ADJD", "VVPP", "$(", "KOUS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}