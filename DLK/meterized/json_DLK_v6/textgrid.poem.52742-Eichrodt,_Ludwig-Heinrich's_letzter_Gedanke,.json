{"textgrid.poem.52742": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Heinrich's letzter Gedanke,", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mich langeweilt das Carroussel,", "tokens": ["Mich", "lan\u00b7ge\u00b7weilt", "das", "Car\u00b7rous\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Freiheit, die Lect\u00fcre;", "tokens": ["Die", "Frei\u00b7heit", ",", "die", "Lec\u00b7t\u00fc\u00b7re", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Lieder murmelreicher Quell", "tokens": ["Der", "Lie\u00b7der", "mur\u00b7mel\u00b7rei\u00b7cher", "Quell"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur Gosse sich verliere!", "tokens": ["Zur", "Gos\u00b7se", "sich", "ver\u00b7lie\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich, des Jahrhunderts Dichterheld,", "tokens": ["Ich", ",", "des", "Jahr\u00b7hun\u00b7derts", "Dich\u00b7ter\u00b7held", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verrufe mein gl\u00e4nzendstes Dictum,", "tokens": ["Ver\u00b7ru\u00b7fe", "mein", "gl\u00e4n\u00b7zends\u00b7tes", "Dic\u00b7tum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich rufe hinaus in die nachtende Welt:", "tokens": ["Ich", "ru\u00b7fe", "hin\u00b7aus", "in", "die", "nach\u00b7ten\u00b7de", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Da steh' ich so ganz, so gar allein,", "tokens": ["Da", "steh'", "ich", "so", "ganz", ",", "so", "gar", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$,", "ADV", "ADV", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und seufz' an dritten Orten,", "tokens": ["Und", "seuf\u00b7z'", "an", "drit\u00b7ten", "Or\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich lebe, das allerbrillanteste Schwein", "tokens": ["Ich", "le\u00b7be", ",", "das", "al\u00b7ler\u00b7bril\u00b7lan\u00b7tes\u00b7te", "Schwein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Aus Epikurs Cohorten.", "tokens": ["Aus", "E\u00b7pi\u00b7kurs", "Co\u00b7hor\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Aufrichtig war ich ein Royalist,", "tokens": ["Auf\u00b7rich\u00b7tig", "war", "ich", "ein", "Ro\u00b7ya\u00b7list", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Iulisonne im Herzen,", "tokens": ["Die", "I\u00b7u\u00b7li\u00b7son\u00b7ne", "im", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-++-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich ende, ein Protestant und Christ,", "tokens": ["Ich", "en\u00b7de", ",", "ein", "Pro\u00b7tes\u00b7tant", "und", "Christ", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit heftigen Judenschmerzen.", "tokens": ["Mit", "hef\u00b7ti\u00b7gen", "Ju\u00b7den\u00b7schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Katholisch zu werden steht mir nah,", "tokens": ["Ka\u00b7tho\u00b7lisch", "zu", "wer\u00b7den", "steht", "mir", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VAINF", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ich war ja ", "tokens": ["Ich", "war", "ja"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Wenn ich Signora knieen sah,", "tokens": ["Wenn", "ich", "Sig\u00b7no\u00b7ra", "kni\u00b7e\u00b7en", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVFIN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Die Taille tiefmelancholisch.", "tokens": ["Die", "Tail\u00b7le", "tief\u00b7me\u00b7lan\u00b7cho\u00b7lisch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die jauchzenden V\u00f6lker an meinem Sarg,", "tokens": ["Die", "jauch\u00b7zen\u00b7den", "V\u00f6l\u00b7ker", "an", "mei\u00b7nem", "Sarg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie brechen in wildes Geheul aus,", "tokens": ["Sie", "bre\u00b7chen", "in", "wil\u00b7des", "Ge\u00b7heul", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Es brechen Laster, tantalisch arg,", "tokens": ["Es", "bre\u00b7chen", "Las\u00b7ter", ",", "tan\u00b7ta\u00b7lisch", "arg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und vorprometheische Gr\u00e4u'l aus.", "tokens": ["Und", "vor\u00b7pro\u00b7me\u00b7thei\u00b7sche", "Gr\u00e4u'l", "aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Es hauchen die Rosen Leichenduft,", "tokens": ["Es", "hau\u00b7chen", "die", "Ro\u00b7sen", "Lei\u00b7chen\u00b7duft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das Kichern verlernen die Veilchen,", "tokens": ["Das", "Ki\u00b7chern", "ver\u00b7ler\u00b7nen", "die", "Veil\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und l\u00fcstern balgen an meiner Gruft", "tokens": ["Und", "l\u00fcs\u00b7tern", "bal\u00b7gen", "an", "mei\u00b7ner", "Gruft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Hexen sich mit den Heil'gen.", "tokens": ["Die", "He\u00b7xen", "sich", "mit", "den", "Heil'\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Die Sonne tr\u00f6pfelt als siedendes Gold", "tokens": ["Die", "Son\u00b7ne", "tr\u00f6p\u00b7felt", "als", "sie\u00b7den\u00b7des", "Gold"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In die Rachen der Pharis\u00e4er,", "tokens": ["In", "die", "Ra\u00b7chen", "der", "Pha\u00b7ri\u00b7s\u00e4\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Der Mond vom Himmel herunterrollt", "tokens": ["Der", "Mond", "vom", "Him\u00b7mel", "her\u00b7un\u00b7ter\u00b7rollt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf den Papst und seine Schw\u00e4her.", "tokens": ["Auf", "den", "Papst", "und", "sei\u00b7ne", "Schw\u00e4\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Das j\u00fcngste Gericht erscheint alsbald", "tokens": ["Das", "j\u00fcngs\u00b7te", "Ge\u00b7richt", "er\u00b7scheint", "als\u00b7bald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit dem liebensw\u00fcrdigen Leviathan,", "tokens": ["Mit", "dem", "lie\u00b7bens\u00b7w\u00fcr\u00b7di\u00b7gen", "Le\u00b7vi\u00b7a\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Und hinter dem Finger der Vorsehung krallt", "tokens": ["Und", "hin\u00b7ter", "dem", "Fin\u00b7ger", "der", "Vor\u00b7se\u00b7hung", "krallt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Seine Teufelsfaust der Satan.", "tokens": ["Sei\u00b7ne", "Teu\u00b7fels\u00b7faust", "der", "Sa\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.10": {"line.1": {"text": "Und doch hat Niemand f\u00fcr soviel Geld", "tokens": ["Und", "doch", "hat", "Nie\u00b7mand", "f\u00fcr", "so\u00b7viel", "Geld"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PIS", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "So feine Lieder gedichtet;", "tokens": ["So", "fei\u00b7ne", "Lie\u00b7der", "ge\u00b7dich\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich habe die Nothdurft der ", "tokens": ["Ich", "ha\u00b7be", "die", "Noth\u00b7durft", "der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch meine Werke verrichtet.", "tokens": ["Durch", "mei\u00b7ne", "Wer\u00b7ke", "ver\u00b7rich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Verleger mein, verzeihe du mir,", "tokens": ["Ver\u00b7le\u00b7ger", "mein", ",", "ver\u00b7zei\u00b7he", "du", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Weil ich jetzt nimmer dich r\u00fchre,", "tokens": ["Weil", "ich", "jetzt", "nim\u00b7mer", "dich", "r\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Bedenke, da\u00df ich ein Laxier", "tokens": ["Be\u00b7den\u00b7ke", ",", "da\u00df", "ich", "ein", "La\u00b7xier"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Statt Versen bei mir f\u00fchre.", "tokens": ["Statt", "Ver\u00b7sen", "bei", "mir", "f\u00fch\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Mein liebes Liebchen, wenn du weinst,", "tokens": ["Mein", "lie\u00b7bes", "Lieb\u00b7chen", ",", "wenn", "du", "weinst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich dich habe vergessen,", "tokens": ["Da\u00df", "ich", "dich", "ha\u00b7be", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Bedenke, da\u00df die Tr\u00fcffeln einst", "tokens": ["Be\u00b7den\u00b7ke", ",", "da\u00df", "die", "Tr\u00fcf\u00b7feln", "einst"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich wundersgern gegessen.", "tokens": ["Ich", "wun\u00b7ders\u00b7gern", "ge\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Mein holdes, angetrautes Weib,", "tokens": ["Mein", "hol\u00b7des", ",", "an\u00b7ge\u00b7trau\u00b7tes", "Weib", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du wirst mir nicht entlaufen,", "tokens": ["Du", "wirst", "mir", "nicht", "ent\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Dein Bett will ich verkaufen.", "tokens": ["Dein", "Bett", "will", "ich", "ver\u00b7kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Mein s\u00fc\u00dfes deutsches Publikum,", "tokens": ["Mein", "s\u00fc\u00b7\u00dfes", "deut\u00b7sches", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Liebster war ich ja immer,", "tokens": ["Dein", "Liebs\u00b7ter", "war", "ich", "ja", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Besorge nur ferner meinen Ruhm,", "tokens": ["Be\u00b7sor\u00b7ge", "nur", "fer\u00b7ner", "mei\u00b7nen", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es f\u00e4llt auf dich der Schimmer.", "tokens": ["Es", "f\u00e4llt", "auf", "dich", "der", "Schim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Jehova mein, erbarme dich,", "tokens": ["Je\u00b7ho\u00b7va", "mein", ",", "er\u00b7bar\u00b7me", "dich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich dich oftmals betr\u00fcbet,", "tokens": ["Da\u00df", "ich", "dich", "oft\u00b7mals", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Du liebest alle Menschen, ich", "tokens": ["Du", "lie\u00b7best", "al\u00b7le", "Men\u00b7schen", ",", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab' jedes Mensch geliebet.", "tokens": ["Hab'", "je\u00b7des", "Mensch", "ge\u00b7lie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Du schufest die Gans mit Vorbedacht,", "tokens": ["Du", "schu\u00b7fest", "die", "Gans", "mit", "Vor\u00b7be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ochs, Esel zu deinem Preise;", "tokens": ["Ochs", ",", "E\u00b7sel", "zu", "dei\u00b7nem", "Prei\u00b7se", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sofern' ich ", "tokens": ["So\u00b7fern'", "ich"], "token_info": ["word", "word"], "pos": ["VVIMP", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Geschah's plagiatorischerweise.", "tokens": ["Ge\u00b7scha\u00b7h's", "pla\u00b7gi\u00b7a\u00b7to\u00b7ri\u00b7scher\u00b7wei\u00b7se", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Nun schwebet mir vor nichts Anderes als", "tokens": ["Nun", "schwe\u00b7bet", "mir", "vor", "nichts", "An\u00b7de\u00b7res", "als"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PIS", "PIS", "KOKOM"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Weltnachtstuhl voll Schwankes,", "tokens": ["Der", "Welt\u00b7nacht\u00b7stuhl", "voll", "Schwan\u00b7kes", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich walle, den Strick um den wei\u00dfen Hals,", "tokens": ["Ich", "wal\u00b7le", ",", "den", "Strick", "um", "den", "wei\u00b7\u00dfen", "Hals", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Zum seligen Strome Ganges.", "tokens": ["Zum", "se\u00b7li\u00b7gen", "Stro\u00b7me", "Gan\u00b7ges", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "NN", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}}, "stanza.18": {"line.1": {"text": "Ich mache dort in der Gegend herum", "tokens": ["Ich", "ma\u00b7che", "dort", "in", "der", "Ge\u00b7gend", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "APZR"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Das Paradies ausfindig", "tokens": ["Das", "Pa\u00b7ra\u00b7dies", "aus\u00b7fin\u00b7dig"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich werde als wie ein Erzengel dumm,", "tokens": ["Ich", "wer\u00b7de", "als", "wie", "ein", "Er\u00b7zen\u00b7gel", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOUS", "KOKOM", "ART", "NN", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie Adam und Eva unm\u00fcndig.", "tokens": ["Wie", "A\u00b7dam", "und", "E\u00b7va", "un\u00b7m\u00fcn\u00b7dig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.19": {"line.1": {"text": "Gazellenaugen glotzen mich an,", "tokens": ["Ga\u00b7zel\u00b7len\u00b7au\u00b7gen", "glot\u00b7zen", "mich", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Die Lotos bekomplimentirt mich,", "tokens": ["Die", "Lo\u00b7tos", "be\u00b7kom\u00b7pli\u00b7men\u00b7tirt", "mich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-++-++--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Den Buckel k\u00fc\u00dft mir ein heiliger Mann,", "tokens": ["Den", "Bu\u00b7ckel", "k\u00fc\u00dft", "mir", "ein", "hei\u00b7li\u00b7ger", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und eine Lady skizzirt mich.", "tokens": ["Und", "ei\u00b7ne", "La\u00b7dy", "skiz\u00b7zirt", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ich h\u00e4nge mich auf am Palmenbaum", "tokens": ["Ich", "h\u00e4n\u00b7ge", "mich", "auf", "am", "Pal\u00b7men\u00b7baum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie Absalon mit den Haaren,", "tokens": ["Wie", "Ab\u00b7sa\u00b7lon", "mit", "den", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Versunken in dattels\u00fc\u00dflieben Traum,", "tokens": ["Ver\u00b7sun\u00b7ken", "in", "dat\u00b7tel\u00b7s\u00fc\u00df\u00b7lie\u00b7ben", "Traum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ankommt mich's, abzufahren.", "tokens": ["An\u00b7kommt", "mich's", ",", "ab\u00b7zu\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Einst, wenn sie nimmer wird drangsalirt", "tokens": ["Einst", ",", "wenn", "sie", "nim\u00b7mer", "wird", "drang\u00b7sa\u00b7lirt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "VAFIN", "VVPP"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Welt, so wett' ich, da\u00df man", "tokens": ["Die", "Welt", ",", "so", "wett'", "ich", ",", "da\u00df", "man"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zu meinem Grabe pilgern wird,", "tokens": ["Zu", "mei\u00b7nem", "Gra\u00b7be", "pil\u00b7gern", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Implicite Tullius Ma\u00dfmann.", "tokens": ["I\u00b7mpli\u00b7ci\u00b7te", "Tul\u00b7li\u00b7us", "Ma\u00df\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}}}}