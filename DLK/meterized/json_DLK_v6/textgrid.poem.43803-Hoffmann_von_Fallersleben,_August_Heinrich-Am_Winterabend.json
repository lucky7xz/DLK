{"textgrid.poem.43803": {"metadata": {"author": {"name": "Hoffmann von Fallersleben, August Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Am Winterabend", "genre": "verse", "period": "N.A.", "pub_year": 1836, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und haben wir uns genug gequ\u00e4lt", "tokens": ["Und", "ha\u00b7ben", "wir", "uns", "ge\u00b7nug", "ge\u00b7qu\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PRF", "ADV", "VVPP"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Rathen, so wird ein M\u00e4rchen erz\u00e4hlt.", "tokens": ["Mit", "Ra\u00b7then", ",", "so", "wird", "ein", "M\u00e4r\u00b7chen", "er\u00b7z\u00e4hlt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Und wer das sch\u00f6nste M\u00e4rchen wei\u00df,", "tokens": ["Und", "wer", "das", "sch\u00f6ns\u00b7te", "M\u00e4r\u00b7chen", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erh\u00e4lt den sch\u00f6nsten Apfel als Preis.", "tokens": ["Er\u00b7h\u00e4lt", "den", "sch\u00f6ns\u00b7ten", "Ap\u00b7fel", "als", "Preis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Da wird gelauscht, und gestaunt und gelacht,", "tokens": ["Da", "wird", "ge\u00b7lauscht", ",", "und", "ge\u00b7staunt", "und", "ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,", "KON", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn's anders kommt als man's sich gedacht.", "tokens": ["Wenn's", "an\u00b7ders", "kommt", "als", "man's", "sich", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "KOUS", "PIS", "PRF", "VVPP", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Und kennen wir in jedem M\u00e4rchen", "tokens": ["Und", "ken\u00b7nen", "wir", "in", "je\u00b7dem", "M\u00e4r\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auch Alles genau bis auf das H\u00e4rchen,", "tokens": ["Auch", "Al\u00b7les", "ge\u00b7nau", "bis", "auf", "das", "H\u00e4r\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADJD", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "So h\u00f6ren wir gern doch jedes an", "tokens": ["So", "h\u00f6\u00b7ren", "wir", "gern", "doch", "je\u00b7des", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PIAT", "APPR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und freuen uns immer von neuem dran.", "tokens": ["Und", "freu\u00b7en", "uns", "im\u00b7mer", "von", "neu\u00b7em", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Dann geht das Erz\u00e4hlen die Reih' herum,", "tokens": ["Dann", "geht", "das", "Er\u00b7z\u00e4h\u00b7len", "die", "Reih'", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wir Anderen lauschen und sind ganz stumm.", "tokens": ["Wir", "An\u00b7de\u00b7ren", "lau\u00b7schen", "und", "sind", "ganz", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "VVINF", "KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Dann wird erz\u00e4hlt vom Hirsedieb,", "tokens": ["Dann", "wird", "er\u00b7z\u00e4hlt", "vom", "Hir\u00b7se\u00b7di\u00b7eb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Was D\u00e4umeling f\u00fcr Kurzweil trieb,", "tokens": ["Was", "D\u00e4u\u00b7me\u00b7ling", "f\u00fcr", "Kurz\u00b7weil", "trieb", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Vom Aschenbr\u00f6del im grauen Rock,", "tokens": ["Vom", "A\u00b7schen\u00b7br\u00f6\u00b7del", "im", "grau\u00b7en", "Rock", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vom pfiffigen Schmid in J\u00fcterbogk,", "tokens": ["Vom", "pfif\u00b7fi\u00b7gen", "Schmid", "in", "J\u00fc\u00b7ter\u00b7bogk", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Von Hans im Gl\u00fcck, von den sieben Raben,", "tokens": ["Von", "Hans", "im", "Gl\u00fcck", ",", "von", "den", "sie\u00b7ben", "Ra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPRART", "NN", "$,", "APPR", "ART", "CARD", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vom Fippchen F\u00e4ppchen, von den sieben Schwaben,", "tokens": ["Vom", "Fipp\u00b7chen", "F\u00e4pp\u00b7chen", ",", "von", "den", "sie\u00b7ben", "Schwa\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ART", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Tischlein deck dich, Esel streck dich, Kn\u00fcppel aus dem Sack,", "tokens": ["Tisc\u00b7hlein", "deck", "dich", ",", "E\u00b7sel", "streck", "dich", ",", "Kn\u00fcp\u00b7pel", "aus", "dem", "Sack", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "PPER", "$,", "NN", "VVFIN", "PPER", "$,", "NN", "APPR", "ART", "NN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Und sonst noch mancher Schnick und Schnack.", "tokens": ["Und", "sonst", "noch", "man\u00b7cher", "Schnick", "und", "Schnack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Nun la\u00dft uns singen allerhand,", "tokens": ["Nun", "la\u00dft", "uns", "sin\u00b7gen", "al\u00b7ler\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch zun\u00e4chst von dem Schlaraffenland!", "tokens": ["Doch", "zu\u00b7n\u00e4chst", "von", "dem", "Schla\u00b7raf\u00b7fen\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}}}}