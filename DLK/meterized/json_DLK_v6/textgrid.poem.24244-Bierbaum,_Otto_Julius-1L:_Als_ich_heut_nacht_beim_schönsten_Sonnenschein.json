{"textgrid.poem.24244": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als ich heut nacht beim sch\u00f6nsten Sonnenschein", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich heut nacht beim sch\u00f6nsten Sonnenschein", "tokens": ["Als", "ich", "heut", "nacht", "beim", "sch\u00f6ns\u00b7ten", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In meinem gro\u00dfen Traumpark promenierte,", "tokens": ["In", "mei\u00b7nem", "gro\u00b7\u00dfen", "Traum\u00b7park", "pro\u00b7me\u00b7nier\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Den Lindenweg entlang, vorbei dem Haus,", "tokens": ["Den", "Lin\u00b7den\u00b7weg", "ent\u00b7lang", ",", "vor\u00b7bei", "dem", "Haus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In dem ich Audienz zu geben pflege,", "tokens": ["In", "dem", "ich", "Au\u00b7di\u00b7enz", "zu", "ge\u00b7ben", "pfle\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wenn meine Freundin mir, die Kaiserin", "tokens": ["Wenn", "mei\u00b7ne", "Freun\u00b7din", "mir", ",", "die", "Kai\u00b7se\u00b7rin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Von Lubidinien, Ambassade schickt,", "tokens": ["Von", "Lu\u00b7bi\u00b7di\u00b7ni\u00b7en", ",", "Am\u00b7bas\u00b7sa\u00b7de", "schickt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Sah ich inmitten der Ranunkelwiese", "tokens": ["Sah", "ich", "in\u00b7mit\u00b7ten", "der", "Ra\u00b7nun\u00b7kel\u00b7wie\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "(der gr\u00fcn und gelbe Glanz ist wunderbar)", "tokens": ["(", "der", "gr\u00fcn", "und", "gel\u00b7be", "Glanz", "ist", "wun\u00b7der\u00b7bar", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJD", "KON", "ADJA", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Gem\u00e4chlich schreitend meinen Freund Herrn Ich.", "tokens": ["Ge\u00b7m\u00e4ch\u00b7lich", "schrei\u00b7tend", "mei\u00b7nen", "Freund", "Herrn", "Ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Durchaus in Wei\u00df gekleidet \u2013 um den Bauch", "tokens": ["Durc\u00b7haus", "in", "Wei\u00df", "ge\u00b7klei\u00b7det", "\u2013", "um", "den", "Bauch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVPP", "$(", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Den breiten schwarzen Seideng\u00fcrtel \u2013 kam", "tokens": ["Den", "brei\u00b7ten", "schwar\u00b7zen", "Sei\u00b7den\u00b7g\u00fcr\u00b7tel", "\u2013", "kam"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "$(", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Mein alter Freund, wie seine Art so ist,", "tokens": ["Mein", "al\u00b7ter", "Freund", ",", "wie", "sei\u00b7ne", "Art", "so", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PWAV", "PPOSAT", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sehr langsam und zuweilen stehen bleibend,", "tokens": ["Sehr", "lang\u00b7sam", "und", "zu\u00b7wei\u00b7len", "ste\u00b7hen", "blei\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Grad auf mich zu, durchaus sich nicht beeilend.", "tokens": ["Grad", "auf", "mich", "zu", ",", "durc\u00b7haus", "sich", "nicht", "be\u00b7ei\u00b7lend", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "$,", "ADV", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Sein breiter Strohsombrero f\u00e4chelte", "tokens": ["Sein", "brei\u00b7ter", "Stroh\u00b7somb\u00b7re\u00b7ro", "f\u00e4\u00b7chel\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Mit schwanken Krempen dem verehrten Haupt,", "tokens": ["Mit", "schwan\u00b7ken", "Krem\u00b7pen", "dem", "ver\u00b7ehr\u00b7ten", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Das f\u00fcr die Hitze nicht geschaffen ward,", "tokens": ["Das", "f\u00fcr", "die", "Hit\u00b7ze", "nicht", "ge\u00b7schaf\u00b7fen", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "PTKNEG", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Erw\u00fcnschte K\u00fchlung um die vollen Backen.", "tokens": ["Er\u00b7w\u00fcnschte", "K\u00fch\u00b7lung", "um", "die", "vol\u00b7len", "Ba\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.19": {"text": "Doch trotzdem hielt mein alter Kamerad", "tokens": ["Doch", "trotz\u00b7dem", "hielt", "mein", "al\u00b7ter", "Ka\u00b7me\u00b7rad"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Noch einen roten seidnen Sonnenschirm", "tokens": ["Noch", "ei\u00b7nen", "ro\u00b7ten", "seid\u00b7nen", "Son\u00b7nen\u00b7schirm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "(t\u00fcrkisch gemustert, riesigsten Formats)", "tokens": ["(", "t\u00fcr\u00b7kisch", "ge\u00b7mus\u00b7tert", ",", "rie\u00b7sigs\u00b7ten", "For\u00b7mats", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVPP", "$,", "ADJA", "NN", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.22": {"text": "Mit seiner Linken sorgsam \u00fcber sich,", "tokens": ["Mit", "sei\u00b7ner", "Lin\u00b7ken", "sorg\u00b7sam", "\u00fc\u00b7ber", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Indes die Rechte den gewohnten Kodak,", "tokens": ["In\u00b7des", "die", "Rech\u00b7te", "den", "ge\u00b7wohn\u00b7ten", "Ko\u00b7dak", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.24": {"text": "Den stets verzeichnenden, behutsam trug.", "tokens": ["Den", "stets", "ver\u00b7zeich\u00b7nen\u00b7den", ",", "be\u00b7hut\u00b7sam", "trug", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Da ich bei Tage nie dem Freund begegne,", "tokens": ["Da", "ich", "bei", "Ta\u00b7ge", "nie", "dem", "Freund", "be\u00b7geg\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Freu ich mich stets, ihn nachts im Park zu sehn,", "tokens": ["Freu", "ich", "mich", "stets", ",", "ihn", "nachts", "im", "Park", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "$,", "PPER", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "In dem zuweilen Sonn und Mond zugleich scheint,", "tokens": ["In", "dem", "zu\u00b7wei\u00b7len", "Sonn", "und", "Mond", "zu\u00b7gleich", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.28": {"text": "Sommer und Winter ist an ", "tokens": ["Som\u00b7mer", "und", "Win\u00b7ter", "ist", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VAFIN", "APPR"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.29": {"text": "Und Zukunft und Vergangenheit sich eint", "tokens": ["Und", "Zu\u00b7kunft", "und", "Ver\u00b7gan\u00b7gen\u00b7heit", "sich", "eint"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "PRF", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Zu einem Heute von besonderem Glanz.", "tokens": ["Zu", "ei\u00b7nem", "Heu\u00b7te", "von", "be\u00b7son\u00b7de\u00b7rem", "Glanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.31": {"text": "Wir sprechen uns dann miteinander aus,", "tokens": ["Wir", "spre\u00b7chen", "uns", "dann", "mi\u00b7tein\u00b7an\u00b7der", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Wie Freunde tun, die sonst entfernt sich sind", "tokens": ["Wie", "Freun\u00b7de", "tun", ",", "die", "sonst", "ent\u00b7fernt", "sich", "sind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "VVINF", "$,", "PRELS", "ADV", "ADJD", "PRF", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "(doch immer nahe im Gef\u00fchl), und stets", "tokens": ["(", "doch", "im\u00b7mer", "na\u00b7he", "im", "Ge\u00b7f\u00fchl", ")", ",", "und", "stets"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["$(", "ADV", "ADV", "ADJD", "APPRART", "NN", "$(", "$,", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Erfahr ich Neues von ihm, das mich wundert.", "tokens": ["Er\u00b7fahr", "ich", "Neu\u00b7es", "von", "ihm", ",", "das", "mich", "wun\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So ging ich denn mit schnellen Schritten ihm", "tokens": ["So", "ging", "ich", "denn", "mit", "schnel\u00b7len", "Schrit\u00b7ten", "ihm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Hand ausstreckend, seine zu ergreifen,", "tokens": ["Die", "Hand", "aus\u00b7stre\u00b7ckend", ",", "sei\u00b7ne", "zu", "er\u00b7grei\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "PPOSAT", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Entgegen, als, pfui Kuckuck, ein Gestank", "tokens": ["Ent\u00b7ge\u00b7gen", ",", "als", ",", "pfui", "Ku\u00b7ckuck", ",", "ein", "Ge\u00b7stank"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "KOUS", "$,", "ITJ", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "H\u00f6chst penetranter Art mich stehen hie\u00df.", "tokens": ["H\u00f6chst", "pe\u00b7ne\u00b7tran\u00b7ter", "Art", "mich", "ste\u00b7hen", "hie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PPER", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Nase klemmend rief ich: \u00bbLieber Freund,", "tokens": ["Die", "Na\u00b7se", "klem\u00b7mend", "rief", "ich", ":", "\u00bb", "Lie\u00b7ber", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "PPER", "$.", "$(", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was f\u00fcr ein scheu\u00dflicher Gestank ist das?", "tokens": ["Was", "f\u00fcr", "ein", "scheu\u00df\u00b7li\u00b7cher", "Ge\u00b7stank", "ist", "das", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN", "VAFIN", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Riechst du ihn nicht? Dann bist du arg verschnupft!", "tokens": ["Riechst", "du", "ihn", "nicht", "?", "Dann", "bist", "du", "arg", "ver\u00b7schnupft", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKNEG", "$.", "ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Schindanger duften lieblicher; es scheint", "tokens": ["Schin\u00b7dan\u00b7ger", "duf\u00b7ten", "lieb\u00b7li\u00b7cher", ";", "es", "scheint"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADJD", "$.", "PPER", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "Von faulen Eiern und verwestem Fleisch", "tokens": ["Von", "fau\u00b7len", "Ei\u00b7ern", "und", "ver\u00b7wes\u00b7tem", "Fleisch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ein f\u00fcrchterlich Gemisch. Bist du vielleicht", "tokens": ["Ein", "f\u00fcrch\u00b7ter\u00b7lich", "Ge\u00b7misch", ".", "Bist", "du", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "$.", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "In was getreten, das von \u00dcbel ist?\u00ab", "tokens": ["In", "was", "ge\u00b7tre\u00b7ten", ",", "das", "von", "\u00dc\u00b7bel", "ist", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PRELS", "VVPP", "$,", "PRELS", "APPR", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da lachte schallend auf mein Freund, wie kaum", "tokens": ["Da", "lach\u00b7te", "schal\u00b7lend", "auf", "mein", "Freund", ",", "wie", "kaum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,", "PWAV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein anderer lachen kann, denn darin hat", "tokens": ["Ein", "an\u00b7de\u00b7rer", "la\u00b7chen", "kann", ",", "denn", "da\u00b7rin", "hat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$,", "KON", "PAV", "VAFIN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Er \u00dcbung. Und er rief: \u00bbDu irrst, du irrst!", "tokens": ["Er", "\u00dc\u00b7bung", ".", "Und", "er", "rief", ":", "\u00bb", "Du", "irrst", ",", "du", "irrst", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$.", "KON", "PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$,", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dies s\u00fc\u00dfe D\u00fcften hab ich mir gekauft", "tokens": ["Dies", "s\u00fc\u00b7\u00dfe", "D\u00fcf\u00b7ten", "hab", "ich", "mir", "ge\u00b7kauft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADJA", "NN", "VAFIN", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "F\u00fcr schweres Geld in einer Menaschrie.", "tokens": ["F\u00fcr", "schwe\u00b7res", "Geld", "in", "ei\u00b7ner", "Me\u00b7nasc\u00b7hrie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Zwei holde Musteliden kauft ich mir,", "tokens": ["Zwei", "hol\u00b7de", "Mus\u00b7te\u00b7li\u00b7den", "kauft", "ich", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Stinktiere hei\u00dft der Laie sie, jedoch", "tokens": ["Stink\u00b7tie\u00b7re", "hei\u00dft", "der", "Lai\u00b7e", "sie", ",", "je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "PPER", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Zoologe Chinqua oder Skunk.", "tokens": ["Der", "Zoo\u00b7lo\u00b7ge", "Chin\u00b7qua", "o\u00b7der", "Skunk", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "KON", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ich f\u00fchre eben zur Dressur sie aus,", "tokens": ["Ich", "f\u00fch\u00b7re", "e\u00b7ben", "zur", "Dres\u00b7sur", "sie", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Da\u00df auf ", "tokens": ["Da\u00df", "auf"], "token_info": ["word", "word"], "pos": ["KOUS", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Verzeih, ich sah dich nicht, sonst h\u00e4tte ich", "tokens": ["Ver\u00b7zeih", ",", "ich", "sah", "dich", "nicht", ",", "sonst", "h\u00e4t\u00b7te", "ich"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "VAFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Nicht eben grade ", "tokens": ["Nicht", "e\u00b7ben", "gra\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "ADV", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "Denn, wenn ein guter Freund mir naht, solln sie", "tokens": ["Denn", ",", "wenn", "ein", "gu\u00b7ter", "Freund", "mir", "naht", ",", "solln", "sie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "ADJA", "NN", "PPER", "VVFIN", "$,", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Nat\u00fcrlich ", "tokens": ["Na\u00b7t\u00fcr\u00b7lich"], "token_info": ["word"], "pos": ["ADV"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.4": {"line.1": {"text": "Dies soll (und wird! verla\u00df dich drauf!) nur dann", "tokens": ["Dies", "soll", "(", "und", "wird", "!", "ver\u00b7la\u00df", "dich", "drauf", "!", ")", "nur", "dann"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PDS", "VMFIN", "$(", "KON", "VAFIN", "$.", "VVIMP", "PPER", "PTKVZ", "$.", "$(", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit Pr\u00e4zision geschehn, begegnet mir", "tokens": ["Mit", "Pr\u00e4\u00b7zi\u00b7si\u00b7on", "ge\u00b7schehn", ",", "be\u00b7geg\u00b7net", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ein Exemplar der b\u00f6sen Spezies", "tokens": ["Ein", "Ex\u00b7emp\u00b7lar", "der", "b\u00f6\u00b7sen", "Spe\u00b7zies"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Homo calumnians, so ein St\u00fcck Vieh,", "tokens": ["Ho\u00b7mo", "ca\u00b7lum\u00b7ni\u00b7ans", ",", "so", "ein", "St\u00fcck", "Vieh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "ADV", "ART", "NN", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Das aus dem ewig l\u00fcgenfeuchten Maul", "tokens": ["Das", "aus", "dem", "e\u00b7wig", "l\u00fc\u00b7gen\u00b7feuch\u00b7ten", "Maul"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Verleumdung stinkt, erlogne Sch\u00e4ndlichkeit", "tokens": ["Ver\u00b7leum\u00b7dung", "stinkt", ",", "er\u00b7log\u00b7ne", "Sch\u00e4nd\u00b7lich\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ausd\u00fcnstet und den guten Namen mir", "tokens": ["Aus\u00b7d\u00fcns\u00b7tet", "und", "den", "gu\u00b7ten", "Na\u00b7men", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "KON", "ART", "ADJA", "NN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit niedertr\u00e4chtgem Klatsch besudelt, oder", "tokens": ["Mit", "nie\u00b7der\u00b7tr\u00e4cht\u00b7gem", "Klatsch", "be\u00b7su\u00b7delt", ",", "o\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ein falscher Freund, der, weil es ihm behagt,", "tokens": ["Ein", "fal\u00b7scher", "Freund", ",", "der", ",", "weil", "es", "ihm", "be\u00b7hagt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Als Alleswisser interessant zu sein,", "tokens": ["Als", "Al\u00b7les\u00b7wis\u00b7ser", "in\u00b7ter\u00b7es\u00b7sant", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Freundschaftlich ihm Vertrautes ausstreut und", "tokens": ["Freund\u00b7schaft\u00b7lich", "ihm", "Ver\u00b7trau\u00b7tes", "aus\u00b7streut", "und"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "NN", "VVPP", "KON"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "Zugleich verh\u00f6hnt, in seinem flachen Sinn", "tokens": ["Zu\u00b7gleich", "ver\u00b7h\u00f6hnt", ",", "in", "sei\u00b7nem", "fla\u00b7chen", "Sinn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "$,", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Gekitzelt, wenn der H\u00f6rer nur geruht,", "tokens": ["Ge\u00b7kit\u00b7zelt", ",", "wenn", "der", "H\u00f6\u00b7rer", "nur", "ge\u00b7ruht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Beifall zu l\u00e4cheln. Stinken solln sie auch,", "tokens": ["Bei\u00b7fall", "zu", "l\u00e4\u00b7cheln", ".", "Stin\u00b7ken", "solln", "sie", "auch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$.", "NN", "VMFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Wenn Neidische in meiner N\u00e4he sind,", "tokens": ["Wenn", "Nei\u00b7di\u00b7sche", "in", "mei\u00b7ner", "N\u00e4\u00b7he", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Von deren blo\u00dfem Atem ringsumher", "tokens": ["Von", "de\u00b7ren", "blo\u00b7\u00dfem", "A\u00b7tem", "rings\u00b7um\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "ADJA", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Die Luft morastig m\u00fcfft, Verkleinerer", "tokens": ["Die", "Luft", "mo\u00b7ras\u00b7tig", "m\u00fcfft", ",", "Ver\u00b7klei\u00b7ne\u00b7rer"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "ADJD", "VMFIN", "$,", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Und darum L\u00fcgner, immerfort bereit,", "tokens": ["Und", "da\u00b7rum", "L\u00fcg\u00b7ner", ",", "im\u00b7mer\u00b7fort", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PAV", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Mit Wenns und Abers leiser Andeutung", "tokens": ["Mit", "Wenns", "und", "A\u00b7bers", "lei\u00b7ser", "An\u00b7deu\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "KON", "NN", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Verdacht zu s\u00e4en. Kurz: Die Niedertracht", "tokens": ["Ver\u00b7dacht", "zu", "s\u00e4\u00b7en", ".", "Kurz", ":", "Die", "Nie\u00b7der\u00b7tracht"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "PTKZU", "VVINF", "$.", "ADJD", "$.", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Will ich vom Leib mir halten durch Gestank.\u00ab", "tokens": ["Will", "ich", "vom", "Leib", "mir", "hal\u00b7ten", "durch", "Ge\u00b7stank", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "So sprach mein Freund und d\u00fcnkte sich sehr klug.", "tokens": ["So", "sprach", "mein", "Freund", "und", "d\u00fcnk\u00b7te", "sich", "sehr", "klug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Ach Gott, so klug! \u2013 Der Gute tat mir leid.", "tokens": ["Ach", "Gott", ",", "so", "klug", "!", "\u2013", "Der", "Gu\u00b7te", "tat", "mir", "leid", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "ADV", "ADJD", "$.", "$(", "ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Und, weil ich nahe ihm verbunden bin", "tokens": ["Und", ",", "weil", "ich", "na\u00b7he", "ihm", "ver\u00b7bun\u00b7den", "bin"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "APPR", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Und es nicht gerne sehe, haut er so", "tokens": ["Und", "es", "nicht", "ger\u00b7ne", "se\u00b7he", ",", "haut", "er", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "PTKNEG", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Mit voller Armauslage in die Leere", "tokens": ["Mit", "vol\u00b7ler", "Ar\u00b7maus\u00b7la\u00b7ge", "in", "die", "Lee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "(wobei man, wie ein jeder Fechter wei\u00df,", "tokens": ["(", "wo\u00b7bei", "man", ",", "wie", "ein", "je\u00b7der", "Fech\u00b7ter", "wei\u00df", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PIS", "$,", "PWAV", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Das Gleichgewicht sehr leicht verlieren kann", "tokens": ["Das", "Gleich\u00b7ge\u00b7wicht", "sehr", "leicht", "ver\u00b7lie\u00b7ren", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.29": {"text": "Und auf die Nase fallen), sagte ich:", "tokens": ["Und", "auf", "die", "Na\u00b7se", "fal\u00b7len", ")", ",", "sag\u00b7te", "ich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$(", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "\u00bbo welch ein Erzkamel du bist, mein Freund!", "tokens": ["\u00bb", "o", "welch", "ein", "Erz\u00b7ka\u00b7mel", "du", "bist", ",", "mein", "Freund", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "PWAT", "ART", "NN", "PPER", "VAFIN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Du legst dein Geld an, wie ein Idiot.", "tokens": ["Du", "legst", "dein", "Geld", "an", ",", "wie", "ein", "I\u00b7diot", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Viel besser, wahrlich, h\u00e4ttest du getan,", "tokens": ["Viel", "bes\u00b7ser", ",", "wahr\u00b7lich", ",", "h\u00e4t\u00b7test", "du", "ge\u00b7tan", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "$,", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.33": {"text": "H\u00e4ttst statt des Stinktierduos du ein Paar \u2013", "tokens": ["H\u00e4ttst", "statt", "des", "Stink\u00b7tier\u00b7du\u00b7os", "du", "ein", "Paar", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "ART", "NN", "$("], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.34": {"text": "Was wei\u00df ich, Metzgerhunde dir gekauft.", "tokens": ["Was", "wei\u00df", "ich", ",", "Metz\u00b7ger\u00b7hun\u00b7de", "dir", "ge\u00b7kauft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Wei\u00dft du denn nicht, da\u00df eben der Gestank", "tokens": ["Wei\u00dft", "du", "denn", "nicht", ",", "da\u00df", "e\u00b7ben", "der", "Ge\u00b7stank"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Das Lebenselement der Schufte ist, die du", "tokens": ["Das", "Le\u00b7ben\u00b7se\u00b7le\u00b7ment", "der", "Schuf\u00b7te", "ist", ",", "die", "du"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Damit nur anziehst, wie der Baldrian", "tokens": ["Da\u00b7mit", "nur", "an\u00b7ziehst", ",", "wie", "der", "Bald\u00b7ri\u00b7an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Die Katzen anzieht? Ist denn das Vernunft,", "tokens": ["Die", "Kat\u00b7zen", "an\u00b7zieht", "?", "Ist", "denn", "das", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Sich mit den St\u00e4nkern durch Gestank ", "tokens": ["Sich", "mit", "den", "St\u00e4n\u00b7kern", "durch", "Ge\u00b7stank"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "APPR", "NN"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Zu machen, sei es auch nicht eigenem?\u00ab", "tokens": ["Zu", "ma\u00b7chen", ",", "sei", "es", "auch", "nicht", "ei\u00b7ge\u00b7nem", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJA", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Da sch\u00e4mte sich mein Freund und ging davon,", "tokens": ["Da", "sch\u00e4m\u00b7te", "sich", "mein", "Freund", "und", "ging", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "KON", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Sonnenschirm geschultert. Seine Skunks", "tokens": ["Den", "Son\u00b7nen\u00b7schirm", "ge\u00b7schul\u00b7tert", ".", "Sei\u00b7ne", "Skunks"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVPP", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Verwandelten sich in zwei Collies, die", "tokens": ["Ver\u00b7wan\u00b7del\u00b7ten", "sich", "in", "zwei", "Col\u00b7lies", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PRF", "APPR", "CARD", "NN", "$,", "PRELS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit edlem Anstand ihn begleiteten.", "tokens": ["Mit", "ed\u00b7lem", "An\u00b7stand", "ihn", "be\u00b7glei\u00b7te\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}