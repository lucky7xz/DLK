{"textgrid.poem.62872": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zween Wanderer mit Kennersmienen,", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zween Wanderer mit Kennersmienen,", "tokens": ["Zween", "Wan\u00b7de\u00b7rer", "mit", "Ken\u00b7ners\u00b7mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie waren aus Burgund und Kent,", "tokens": ["Sie", "wa\u00b7ren", "aus", "Bur\u00b7gund", "und", "Kent", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Begegneten im Orient", "tokens": ["Be\u00b7ge\u00b7gne\u00b7ten", "im", "O\u00b7rient"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich bey Palmiras Prachtruinen.", "tokens": ["Sich", "bey", "Pal\u00b7mi\u00b7ras", "Prach\u00b7tru\u00b7i\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NE", "NE", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Sie sa\u00dfen matt vom langen Gehn", "tokens": ["Sie", "sa\u00b7\u00dfen", "matt", "vom", "lan\u00b7gen", "Gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In einer Ceder breiten Schatten,", "tokens": ["In", "ei\u00b7ner", "Ce\u00b7der", "brei\u00b7ten", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sagten sich, was sie gesehn,", "tokens": ["Und", "sag\u00b7ten", "sich", ",", "was", "sie", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Vielleicht auch nicht gesehen hatten.", "tokens": ["Viel\u00b7leicht", "auch", "nicht", "ge\u00b7se\u00b7hen", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Besonders sprach der Frankensohn", "tokens": ["Be\u00b7son\u00b7ders", "sprach", "der", "Fran\u00b7ken\u00b7sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Viel von bestandnen Abentheuern,", "tokens": ["Viel", "von", "be\u00b7stand\u00b7nen", "A\u00b7bent\u00b7heu\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Von gro\u00df und kleinen Ungeheuern", "tokens": ["Von", "gro\u00df", "und", "klei\u00b7nen", "Un\u00b7ge\u00b7heu\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und endlich vom Cham\u00e4leon.", "tokens": ["Und", "end\u00b7lich", "vom", "Cha\u00b7m\u00e4\u00b7le\u00b7on", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Es ist ein drollichtes Gemische", "tokens": ["Es", "ist", "ein", "drol\u00b7lich\u00b7tes", "Ge\u00b7mi\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Von Fisch und Eidex; dieser gleicht", "tokens": ["Von", "Fisch", "und", "Ei\u00b7dex", ";", "die\u00b7ser", "gleicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$.", "PDS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Sein Kopf und Schwanz, der Leib dem Fische,", "tokens": ["Sein", "Kopf", "und", "Schwanz", ",", "der", "Leib", "dem", "Fi\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und gleichwohl schwimmt es nicht. \u2013 Es kreucht", "tokens": ["Und", "gleich\u00b7wohl", "schwimmt", "es", "nicht", ".", "\u2013", "Es", "kreucht"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Im z\u00f6gernden Galopp der Schnecke,", "tokens": ["Im", "z\u00f6\u00b7gern\u00b7den", "Ga\u00b7lopp", "der", "Schne\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.18": {"text": "Und seine Haut ist himmelblau. \u2013", "tokens": ["Und", "sei\u00b7ne", "Haut", "ist", "him\u00b7mel\u00b7blau", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Halt, Freund, dein Bild ist nicht genau;", "tokens": ["Halt", ",", "Freund", ",", "dein", "Bild", "ist", "nicht", "ge\u00b7nau", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ich fands in einer Myrtenhecke,", "tokens": ["Ich", "fands", "in", "ei\u00b7ner", "Myr\u00b7ten\u00b7he\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Rief Master John, und es war gr\u00fcn. \u2013", "tokens": ["Rief", "Mas\u00b7ter", "John", ",", "und", "es", "war", "gr\u00fcn", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NN", "NE", "$,", "KON", "PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Pardon! ich sahs mit eignen Augen", "tokens": ["Par\u00b7don", "!", "ich", "sahs", "mit", "eig\u00b7nen", "Au\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Den Hauch des Zephyrs in sich saugen,", "tokens": ["Den", "Hauch", "des", "Ze\u00b7phyrs", "in", "sich", "sau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Von dem es lebt, und wette k\u00fchn,", "tokens": ["Von", "dem", "es", "lebt", ",", "und", "wet\u00b7te", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Blau war es, gleich dem Baldachin", "tokens": ["Blau", "war", "es", ",", "gleich", "dem", "Bal\u00b7da\u00b7ch\u00b7in"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "$,", "ADV", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.26": {"text": "Des Himmels, unter dem es speiste. \u2013", "tokens": ["Des", "Him\u00b7mels", ",", "un\u00b7ter", "dem", "es", "speis\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "God damn! Auch ich nahm, wenn ich reiste,", "tokens": ["God", "damn", "!", "Auch", "ich", "nahm", ",", "wenn", "ich", "reis\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM", "FM", "$.", "ADV", "PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.28": {"text": "Die Augen mit: das Thier war gr\u00fcn ...", "tokens": ["Die", "Au\u00b7gen", "mit", ":", "das", "Thier", "war", "gr\u00fcn", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "ART", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Blau! ... Gr\u00fcn! ... Du l\u00fcgst! ... Ein B\u00e4renh\u00e4uter", "tokens": ["Blau", "!", "...", "Gr\u00fcn", "!", "...", "Du", "l\u00fcgst", "!", "...", "Ein", "B\u00e4\u00b7ren\u00b7h\u00e4u\u00b7ter"], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["NN", "$.", "$(", "NN", "$.", "$(", "PPER", "VVFIN", "$.", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Sagt das. Itzt h\u00e4tten sich die Streiter", "tokens": ["Sagt", "das", ".", "Itzt", "h\u00e4t\u00b7ten", "sich", "die", "Strei\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PDS", "$.", "ADV", "VAFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Mit Kn\u00fctteln kreutzlahm demonstriert,", "tokens": ["Mit", "Kn\u00fct\u00b7teln", "kreutz\u00b7lahm", "de\u00b7monst\u00b7riert", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.32": {"text": "H\u00e4tt ihr Geschrey nicht einen dritten,", "tokens": ["H\u00e4tt", "ihr", "Ge\u00b7schrey", "nicht", "ei\u00b7nen", "drit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Ein braunes M\u00f6nchlein hergef\u00fchrt.", "tokens": ["Ein", "brau\u00b7nes", "M\u00f6nch\u00b7lein", "her\u00b7ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Ihr Herrn, wor\u00fcber wird gestritten?", "tokens": ["Ihr", "Herrn", ",", "wo\u00b7r\u00fc\u00b7ber", "wird", "ge\u00b7strit\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "\u00bbfreund, \u00fcber das Cham\u00e4leon,", "tokens": ["\u00bb", "freund", ",", "\u00fc\u00b7ber", "das", "Cha\u00b7m\u00e4\u00b7le\u00b7on", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.36": {"text": "K\u00f6nnt ihr uns seine Farbe sagen?\u00ab", "tokens": ["K\u00f6nnt", "ihr", "uns", "sei\u00b7ne", "Far\u00b7be", "sa\u00b7gen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PRF", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Ja wohl, sprach Vater Simeon,", "tokens": ["Ja", "wohl", ",", "sprach", "Va\u00b7ter", "Si\u00b7me\u00b7on", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "$,", "VVFIN", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Ihr braucht euch darum nicht zu schlagen.", "tokens": ["Ihr", "braucht", "euch", "da\u00b7rum", "nicht", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "\u00bbder Narr behauptet es sey gr\u00fcn;", "tokens": ["\u00bb", "der", "Narr", "be\u00b7haup\u00b7tet", "es", "sey", "gr\u00fcn", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Ich sage blau.\u00ab Wo denkt Ihr hin?", "tokens": ["Ich", "sa\u00b7ge", "blau", ".", "\u00ab", "Wo", "denkt", "Ihr", "hin", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "$(", "PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "La\u00dft eines bessern euch belehren;", "tokens": ["La\u00dft", "ei\u00b7nes", "bes\u00b7sern", "euch", "be\u00b7leh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Braun ist es, braun, das kann ich schw\u00f6ren;", "tokens": ["Braun", "ist", "es", ",", "braun", ",", "das", "kann", "ich", "schw\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$,", "ADJD", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Erst gestern hab ich eins gekauft", "tokens": ["Erst", "ge\u00b7stern", "hab", "ich", "eins", "ge\u00b7kauft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PIS", "VVPP"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.44": {"text": "Und durch mein Glas genau besehen.", "tokens": ["Und", "durch", "mein", "Glas", "ge\u00b7nau", "be\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Die Kempen wollten spottend gehen.", "tokens": ["Die", "Kem\u00b7pen", "woll\u00b7ten", "spot\u00b7tend", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Wenn ihrs nicht sehen wollt, so lauft;", "tokens": ["Wenn", "ihrs", "nicht", "se\u00b7hen", "wollt", ",", "so", "lauft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "VVINF", "VMFIN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Ich hab es hier zum gr\u00f6\u00dften Gl\u00fccke", "tokens": ["Ich", "hab", "es", "hier", "zum", "gr\u00f6\u00df\u00b7ten", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "In meinem Schwei\u00dftuch, sprach der Greis.", "tokens": ["In", "mei\u00b7nem", "Schwei\u00df\u00b7tuch", ",", "sprach", "der", "Greis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "\u00bbweist her!\u00ab Er zog es aus der Ficke.", "tokens": ["\u00bb", "weist", "her", "!", "\u00ab", "Er", "zog", "es", "aus", "der", "Fi\u00b7cke", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.50": {"text": "Und siehe da, das Thier war wei\u00df.", "tokens": ["Und", "sie\u00b7he", "da", ",", "das", "Thier", "war", "wei\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ADV", "$,", "ART", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}