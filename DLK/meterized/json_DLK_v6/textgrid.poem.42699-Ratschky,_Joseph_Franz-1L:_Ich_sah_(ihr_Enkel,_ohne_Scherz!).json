{"textgrid.poem.42699": {"metadata": {"author": {"name": "Ratschky, Joseph Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich sah (ihr Enkel, ohne Scherz!)", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich sah (ihr Enkel, ohne Scherz!)", "tokens": ["Ich", "sah", "(", "ihr", "En\u00b7kel", ",", "oh\u00b7ne", "Scherz", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPOSAT", "NN", "$,", "KOUI", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heut nachts im Traum den Eifrer Merz", "tokens": ["Heut", "nachts", "im", "Traum", "den", "Eif\u00b7rer", "Merz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Predigtstuhl besteigen,", "tokens": ["Den", "Pre\u00b7digt\u00b7stuhl", "be\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sah K\u00fcchennymphen, halb zerdr\u00fcckt", "tokens": ["Sah", "K\u00fc\u00b7chen\u00b7nym\u00b7phen", ",", "halb", "zer\u00b7dr\u00fcckt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "NN", "$,", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Handwerksjungen, unverr\u00fcckt", "tokens": ["Von", "Hand\u00b7werks\u00b7jun\u00b7gen", ",", "un\u00b7ver\u00b7r\u00fcckt"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr Ohr zur Kanzel neigen.", "tokens": ["Ihr", "Ohr", "zur", "Kan\u00b7zel", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Potz Blitz! wie weidlich klopfte nicht", "tokens": ["Potz", "Blitz", "!", "wie", "weid\u00b7lich", "klopf\u00b7te", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$.", "PWAV", "ADJD", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wackre K\u00e4mpfer das Gez\u00fccht", "tokens": ["Der", "wack\u00b7re", "K\u00e4mp\u00b7fer", "das", "Ge\u00b7z\u00fccht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Ketzer auf die Finger!", "tokens": ["Der", "Ket\u00b7zer", "auf", "die", "Fin\u00b7ger", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mir gellen, traun! die Ohren noch:", "tokens": ["Mir", "gel\u00b7len", ",", "traun", "!", "die", "Oh\u00b7ren", "noch", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$,", "VVINF", "$.", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbach, schone, rief ich, schone doch,", "tokens": ["\u00bb", "ach", ",", "scho\u00b7ne", ",", "rief", "ich", ",", "scho\u00b7ne", "doch", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "VVFIN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du tapfrer Schnupftuchschwinger!", "tokens": ["Du", "tapf\u00b7rer", "Schnupf\u00b7tuch\u00b7schwin\u00b7ger", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich will ja glauben, dass die Hand", "tokens": ["Ich", "will", "ja", "glau\u00b7ben", ",", "dass", "die", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Papstes zum gelobten Land,", "tokens": ["Des", "Paps\u00b7tes", "zum", "ge\u00b7lob\u00b7ten", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Milch und Honig fliessen,", "tokens": ["Wo", "Milch", "und", "Ho\u00b7nig", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Schl\u00fcssel hat, um allen Herrn", "tokens": ["Den", "Schl\u00fcs\u00b7sel", "hat", ",", "um", "al\u00b7len", "Herrn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "KOUI", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sektirern und Schismatikern", "tokens": ["Sek\u00b7ti\u00b7rern", "und", "Schis\u00b7ma\u00b7ti\u00b7kern"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Das Pf\u00f6rtchen zu verschliessen;", "tokens": ["Das", "Pf\u00f6rt\u00b7chen", "zu", "ver\u00b7schlies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Will glauben, dass du bibelfest", "tokens": ["Will", "glau\u00b7ben", ",", "dass", "du", "bi\u00b7bel\u00b7fest"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "KOUS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Protestanten Drachennest", "tokens": ["Der", "Pro\u00b7tes\u00b7tan\u00b7ten", "Dra\u00b7chen\u00b7nest"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon halb, wie Spreu, zerst\u00e4ubtest,", "tokens": ["Schon", "halb", ",", "wie", "Spreu", ",", "zer\u00b7st\u00e4ub\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "ADJD", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und manchen armen Pastor schon", "tokens": ["Und", "man\u00b7chen", "ar\u00b7men", "Pas\u00b7tor", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Durch deiner Stimme Donnerton", "tokens": ["Durch", "dei\u00b7ner", "Stim\u00b7me", "Don\u00b7ner\u00b7ton"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf immer \u00fcbert\u00e4ubtest.", "tokens": ["Auf", "im\u00b7mer", "\u00fc\u00b7bert\u00b7\u00e4ub\u00b7test", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du b\u00e4ndigst, grosser Thaumaturg!", "tokens": ["Du", "b\u00e4n\u00b7digst", ",", "gros\u00b7ser", "Thau\u00b7ma\u00b7turg", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Halb Augsburg, Ulm und Regensburg,", "tokens": ["Halb", "Augs\u00b7burg", ",", "Ulm", "und", "Re\u00b7gens\u00b7burg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ja fast das ganze Schwaben,", "tokens": ["Ja", "fast", "das", "gan\u00b7ze", "Schwa\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und keiner von der Ketzerbrut", "tokens": ["Und", "kei\u00b7ner", "von", "der", "Ket\u00b7zer\u00b7brut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vermag mit aller seiner Wuth", "tokens": ["Ver\u00b7mag", "mit", "al\u00b7ler", "sei\u00b7ner", "Wuth"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir je was anzuhaben.", "tokens": ["Dir", "je", "was", "an\u00b7zu\u00b7ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PIS", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Du hautest Luthern, welcher sich", "tokens": ["Du", "hau\u00b7test", "Lu\u00b7thern", ",", "wel\u00b7cher", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$,", "PRELS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Vatikan so freventlich", "tokens": ["Den", "Va\u00b7ti\u00b7kan", "so", "fre\u00b7vent\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu st\u00fcrmen unterstanden,", "tokens": ["Zu", "st\u00fcr\u00b7men", "un\u00b7ter\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und seiner J\u00fcnger Riesenschwarm", "tokens": ["Und", "sei\u00b7ner", "J\u00fcn\u00b7ger", "Rie\u00b7sen\u00b7schwarm"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit deinem orthodoxen Arm", "tokens": ["Mit", "dei\u00b7nem", "or\u00b7tho\u00b7do\u00b7xen", "Arm"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Zwar w\u00e4hnt das b\u00f6se Lutherthum,", "tokens": ["Zwar", "w\u00e4hnt", "das", "b\u00f6\u00b7se", "Lu\u00b7ther\u00b7thum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es st\u00fcnd' um unsrer Kirche Ruhm", "tokens": ["Es", "st\u00fcnd'", "um", "uns\u00b7rer", "Kir\u00b7che", "Ruhm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weit besser, wenn du schwiegest:", "tokens": ["Weit", "bes\u00b7ser", ",", "wenn", "du", "schwie\u00b7gest", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein wer kann in Deutschland nun", "tokens": ["Al\u00b7lein", "wer", "kann", "in", "Deutschland", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWS", "VMFIN", "APPR", "NE", "ADV"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Den Ketzern allen Einhalt thun,", "tokens": ["Den", "Ket\u00b7zern", "al\u00b7len", "Ein\u00b7halt", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn du sie nicht bekriegest?", "tokens": ["Wenn", "du", "sie", "nicht", "be\u00b7krie\u00b7gest", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Dich w\u00fcrde selbst, wenn du den Mund", "tokens": ["Dich", "w\u00fcr\u00b7de", "selbst", ",", "wenn", "du", "den", "Mund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur \u00f6ffnetest, der H\u00f6llenhund", "tokens": ["Nur", "\u00f6ff\u00b7ne\u00b7test", ",", "der", "H\u00f6l\u00b7len\u00b7hund"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht wagen anzublecken,", "tokens": ["Nicht", "wa\u00b7gen", "an\u00b7zu\u00b7ble\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und, wedelnd mit dem krausen Schwanz,", "tokens": ["Und", ",", "we\u00b7delnd", "mit", "dem", "krau\u00b7sen", "Schwanz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KON", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Zehn, o schrecklicher Popanz", "tokens": ["Die", "Zehn", ",", "o", "schreck\u00b7li\u00b7cher", "Po\u00b7panz"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "CARD", "$,", "FM", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Ketzer! sanft dir lecken.\u00ab", "tokens": ["Der", "Ket\u00b7zer", "!", "sanft", "dir", "le\u00b7cken", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$.", "VVFIN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}