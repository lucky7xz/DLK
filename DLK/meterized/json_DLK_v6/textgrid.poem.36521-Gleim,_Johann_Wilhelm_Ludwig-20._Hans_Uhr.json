{"textgrid.poem.36521": {"metadata": {"author": {"name": "Gleim, Johann Wilhelm Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "20. Hans Uhr", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Europas K\u00f6nige herab von ihren Thronen", "tokens": ["Eu\u00b7ro\u00b7pas", "K\u00f6\u00b7ni\u00b7ge", "her\u00b7ab", "von", "ih\u00b7ren", "Thro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Selbst st\u00fcrzen, und die goldnen Kronen", "tokens": ["Selbst", "st\u00fcr\u00b7zen", ",", "und", "die", "gold\u00b7nen", "Kro\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der K\u00f6nige selbst schmelzen, und das Gold", "tokens": ["Der", "K\u00f6\u00b7ni\u00b7ge", "selbst", "schmel\u00b7zen", ",", "und", "das", "Gold"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Selbst nehmen, und mit ihn zehn Barden selbst belohnen,", "tokens": ["Selbst", "neh\u00b7men", ",", "und", "mit", "ihn", "zehn", "Bar\u00b7den", "selbst", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$,", "KON", "APPR", "PPER", "CARD", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das alles hat Hans Uhr, der Kraftmann, selbst gewollt!", "tokens": ["Das", "al\u00b7les", "hat", "Hans", "Uhr", ",", "der", "Kraft\u00b7mann", ",", "selbst", "ge\u00b7wollt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "NE", "NN", "$,", "ART", "NN", "$,", "ADV", "VMPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Als aber das nicht gehen wollte,", "tokens": ["Als", "a\u00b7ber", "das", "nicht", "ge\u00b7hen", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDS", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was that er? Ungek\u00e4mmten Haars,", "tokens": ["Was", "that", "er", "?", "Un\u00b7ge\u00b7k\u00e4mm\u00b7ten", "Haars", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das ihn zum Simson machen sollte,", "tokens": ["Das", "ihn", "zum", "Sim\u00b7son", "ma\u00b7chen", "soll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ging er, am zw\u00f6lften Jenner war's,", "tokens": ["Ging", "er", ",", "am", "zw\u00f6lf\u00b7ten", "Jen\u00b7ner", "wa\u00b7r's", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPRART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Zum Haarbeschneider, und zum Kinn-Beschicker,", "tokens": ["Zum", "Haar\u00b7be\u00b7schnei\u00b7der", ",", "und", "zum", "Kinn\u00b7Be\u00b7schi\u00b7cker", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und kam zur\u00fcck wie ein Adon,", "tokens": ["Und", "kam", "zu\u00b7r\u00fcck", "wie", "ein", "A\u00b7don", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KOKOM", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und ward in Servien des Landmanns Unterdr\u00fccker,", "tokens": ["Und", "ward", "in", "Ser\u00b7vi\u00b7en", "des", "Land\u00b7manns", "Un\u00b7ter\u00b7dr\u00fc\u00b7cker", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NE", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und eines Bassa Schwiegersohn!", "tokens": ["Und", "ei\u00b7nes", "Bas\u00b7sa", "Schwie\u00b7ger\u00b7sohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Sonst nichts? \u2013 Ist's nicht genug f\u00fcr einen Thronbest\u00fcrmer,", "tokens": ["Sonst", "nichts", "?", "\u2013", "Ist's", "nicht", "ge\u00b7nug", "f\u00fcr", "ei\u00b7nen", "Thron\u00b7be\u00b7st\u00fcr\u00b7mer", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$.", "$(", "NE", "PTKNEG", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem's nicht nach seiner Grille geht,", "tokens": ["Dem's", "nicht", "nach", "sei\u00b7ner", "Gril\u00b7le", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und der im Kopfe tr\u00e4gt zehntausend gro\u00dfe W\u00fcrmer,", "tokens": ["Und", "der", "im", "Kop\u00b7fe", "tr\u00e4gt", "zehn\u00b7tau\u00b7send", "gro\u00b7\u00dfe", "W\u00fcr\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPRART", "NN", "VVFIN", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Ungerechtigkeit begeht?", "tokens": ["Und", "Un\u00b7ge\u00b7rech\u00b7tig\u00b7keit", "be\u00b7geht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}