{"textgrid.poem.53856": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Wenn einer eine Reise tut . . .", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die K\u00f6nigin von Rum\u00e4nien", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "von", "Ru\u00b7m\u00e4\u00b7ni\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "war jetzt in Amerika. Da konnten diejenigen", "tokens": ["war", "jetzt", "in", "A\u00b7me\u00b7ri\u00b7ka", ".", "Da", "konn\u00b7ten", "die\u00b7je\u00b7ni\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "NE", "$.", "ADV", "VMFIN", "PDS"], "meter": "+--+--+-+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Seifenh\u00e4ndler, die f\u00fcr das K\u00f6nigliche inklinieren,", "tokens": ["Sei\u00b7fen\u00b7h\u00e4nd\u00b7ler", ",", "die", "f\u00fcr", "das", "K\u00f6\u00b7nig\u00b7li\u00b7che", "in\u00b7kli\u00b7nie\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "eine Majest\u00e4t hofieren \u2013", "tokens": ["ei\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t", "ho\u00b7fie\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "das ist f\u00fcr Gesch\u00e4ft und Gef\u00fchl stets ein Gewinn,", "tokens": ["das", "ist", "f\u00fcr", "Ge\u00b7sch\u00e4ft", "und", "Ge\u00b7f\u00fchl", "stets", "ein", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "KON", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "und \u00fcberhaupt: eine K\u00f6nigin ist eine K\u00f6nigin.", "tokens": ["und", "\u00fc\u00b7ber\u00b7haupt", ":", "ei\u00b7ne", "K\u00f6\u00b7ni\u00b7gin", "ist", "ei\u00b7ne", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}}, "stanza.2": {"line.1": {"text": "Was erz\u00e4hlt denn die K\u00f6nigin von Rum\u00e4nien in Amerika?", "tokens": ["Was", "er\u00b7z\u00e4hlt", "denn", "die", "K\u00f6\u00b7ni\u00b7gin", "von", "Ru\u00b7m\u00e4\u00b7ni\u00b7en", "in", "A\u00b7me\u00b7ri\u00b7ka", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "APPR", "NE", "$."], "meter": "--+--+-+-+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Von ihrer lieben Heimat? von Jassy? vom Horatanz? ja?", "tokens": ["Von", "ih\u00b7rer", "lie\u00b7ben", "Hei\u00b7mat", "?", "von", "Jas\u00b7sy", "?", "vom", "Hor\u00b7a\u00b7tanz", "?", "ja", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "APPR", "NE", "$.", "APPRART", "NN", "$.", "ADV", "$."], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wenn die Amerikaner sie danach fragen,", "tokens": ["Wenn", "die", "A\u00b7me\u00b7ri\u00b7ka\u00b7ner", "sie", "da\u00b7nach", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PAV", "VVINF", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "dann soll sie nur alles, alles sagen \u2013", "tokens": ["dann", "soll", "sie", "nur", "al\u00b7les", ",", "al\u00b7les", "sa\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PIS", "$,", "PIS", "VVINF", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "nur m\u00f6ge sie bei den Empf\u00e4ngen und festlichen Essen", "tokens": ["nur", "m\u00f6\u00b7ge", "sie", "bei", "den", "Emp\u00b7f\u00e4n\u00b7gen", "und", "fest\u00b7li\u00b7chen", "Es\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.6": {"text": "ja nichts vergessen.", "tokens": ["ja", "nichts", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Hat sie erz\u00e4hlt, die Gute, die dr\u00fcben so sehr beliebt,", "tokens": ["Hat", "sie", "er\u00b7z\u00e4hlt", ",", "die", "Gu\u00b7te", ",", "die", "dr\u00fc\u00b7ben", "so", "sehr", "be\u00b7liebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "$,", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "was sich, zum Beispiel, in den rum\u00e4nischen Gef\u00e4ngnissen begibt \u2013?", "tokens": ["was", "sich", ",", "zum", "Bei\u00b7spiel", ",", "in", "den", "ru\u00b7m\u00e4\u00b7ni\u00b7schen", "Ge\u00b7f\u00e4ng\u00b7nis\u00b7sen", "be\u00b7gibt", "\u2013", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "PRF", "$,", "APPRART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "VVFIN", "$(", "$."], "meter": "-+-+-+-+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.4": {"line.1": {"text": "Wie die Leute da n\u00e4chtelang geschlagen werden,", "tokens": ["Wie", "die", "Leu\u00b7te", "da", "n\u00e4ch\u00b7tel\u00b7ang", "ge\u00b7schla\u00b7gen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADJD", "VVPP", "VAINF", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "wie es da kein Recht gibt und keine Beschwerden?", "tokens": ["wie", "es", "da", "kein", "Recht", "gibt", "und", "kei\u00b7ne", "Be\u00b7schwer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIAT", "NN", "VVFIN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und da\u00df gefangene Arbeiter in stehenden S\u00e4rgen krepieren", "tokens": ["Und", "da\u00df", "ge\u00b7fan\u00b7ge\u00b7ne", "Ar\u00b7bei\u00b7ter", "in", "ste\u00b7hen\u00b7den", "S\u00e4r\u00b7gen", "kre\u00b7pie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+---+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "und nichts zu trinken haben, wenn sie nicht grade urinieren?", "tokens": ["und", "nichts", "zu", "trin\u00b7ken", "ha\u00b7ben", ",", "wenn", "sie", "nicht", "gra\u00b7de", "u\u00b7ri\u00b7nie\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PTKZU", "VVINF", "VAFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-++-+-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.5": {"text": "Erz\u00e4hlt das die gute K\u00f6nigin? ja?", "tokens": ["Er\u00b7z\u00e4hlt", "das", "die", "gu\u00b7te", "K\u00f6\u00b7ni\u00b7gin", "?", "ja", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "ADJA", "NN", "$.", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Dr\u00fcben in Amerika \u2013?", "tokens": ["Dr\u00fc\u00b7ben", "in", "A\u00b7me\u00b7ri\u00b7ka", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "NE", "$(", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Und davon, wie jeder, den man f\u00fcr einen Kommunisten h\u00e4lt,", "tokens": ["Und", "da\u00b7von", ",", "wie", "je\u00b7der", ",", "den", "man", "f\u00fcr", "ei\u00b7nen", "Kom\u00b7mu\u00b7nis\u00b7ten", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "PWAV", "PIS", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "nichts mehr gilt in der rum\u00e4nischen Welt?", "tokens": ["nichts", "mehr", "gilt", "in", "der", "ru\u00b7m\u00e4\u00b7ni\u00b7schen", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und da\u00df er vogelfrei ist und gepr\u00fcgelt wird und halbtot geschlagen,", "tokens": ["Und", "da\u00df", "er", "vo\u00b7gel\u00b7frei", "ist", "und", "ge\u00b7pr\u00fc\u00b7gelt", "wird", "und", "halb\u00b7tot", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAFIN", "KON", "VVPP", "VAFIN", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "und da\u00df niemand wagt, die Schinder anzuklagen?", "tokens": ["und", "da\u00df", "nie\u00b7mand", "wagt", ",", "die", "Schin\u00b7der", "an\u00b7zu\u00b7kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Erz\u00e4hlt das die gute K\u00f6nigin? ja?", "tokens": ["Er\u00b7z\u00e4hlt", "das", "die", "gu\u00b7te", "K\u00f6\u00b7ni\u00b7gin", "?", "ja", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "ART", "ADJA", "NN", "$.", "ADV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Dr\u00fcben in Amerika \u2013?", "tokens": ["Dr\u00fc\u00b7ben", "in", "A\u00b7me\u00b7ri\u00b7ka", "\u2013", "?"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "NE", "$(", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.6": {"line.1": {"text": "Und da\u00df bei ihr die Bauern gehalten werden wie Schweine?", "tokens": ["Und", "da\u00df", "bei", "ihr", "die", "Bau\u00b7ern", "ge\u00b7hal\u00b7ten", "wer\u00b7den", "wie", "Schwei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "APPR", "PPER", "ART", "NN", "VVPP", "VAINF", "KOKOM", "NN", "$."], "meter": "-+---+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und da\u00df es bei ihr statt Recht und Gesetz nur die eine", "tokens": ["Und", "da\u00df", "es", "bei", "ihr", "statt", "Recht", "und", "Ge\u00b7setz", "nur", "die", "ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "PPOSAT", "APPR", "NN", "KON", "NN", "ADV", "ART", "ART"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Macht: die Siguranza gibt?", "tokens": ["Macht", ":", "die", "Si\u00b7gu\u00b7ran\u00b7za", "gibt", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wer dar\u00fcber die Wahrheit sagt, der ist nicht beliebt . . .", "tokens": ["Wer", "da\u00b7r\u00fc\u00b7ber", "die", "Wahr\u00b7heit", "sagt", ",", "der", "ist", "nicht", "be\u00b7liebt", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "PAV", "ART", "NN", "VVFIN", "$,", "PRELS", "VAFIN", "PTKNEG", "ADJD", "$.", "$.", "$."], "meter": "-+---+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und da\u00df die Perlen, die an ihr schimmern,", "tokens": ["Und", "da\u00df", "die", "Per\u00b7len", ",", "die", "an", "ihr", "schim\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Tr\u00e4nen von denen sind, die in den S\u00e4rgen wimmern?", "tokens": ["Tr\u00e4\u00b7nen", "von", "de\u00b7nen", "sind", ",", "die", "in", "den", "S\u00e4r\u00b7gen", "wim\u00b7mern", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDS", "VAFIN", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Und da\u00df die Rubinen, die an ihr blitzen,", "tokens": ["Und", "da\u00df", "die", "Ru\u00b7bi\u00b7nen", ",", "die", "an", "ihr", "blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Blutstropfen derer, die in den Erdl\u00f6chern sitzen?", "tokens": ["Bluts\u00b7trop\u00b7fen", "de\u00b7rer", ",", "die", "in", "den", "Erd\u00b7l\u00f6\u00b7chern", "sit\u00b7zen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "++--+-+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Und da\u00df die Polizisten nach eignen Methoden", "tokens": ["Und", "da\u00df", "die", "Po\u00b7li\u00b7zis\u00b7ten", "nach", "eig\u00b7nen", "Me\u00b7tho\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "unbequemen Leuten die Hoden", "tokens": ["un\u00b7be\u00b7que\u00b7men", "Leu\u00b7ten", "die", "Ho\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "abquetschen und Geld, Geld unterschlagen,", "tokens": ["ab\u00b7quet\u00b7schen", "und", "Geld", ",", "Geld", "un\u00b7ter\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVINF", "KON", "NN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "und keine Zeitung darf dar\u00fcber was sagen \u2013?", "tokens": ["und", "kei\u00b7ne", "Zei\u00b7tung", "darf", "da\u00b7r\u00fc\u00b7ber", "was", "sa\u00b7gen", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "VMFIN", "PAV", "PIS", "VVINF", "$(", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Das alles sollte die K\u00f6nigin nicht verfehlen", "tokens": ["Das", "al\u00b7les", "soll\u00b7te", "die", "K\u00f6\u00b7ni\u00b7gin", "nicht", "ver\u00b7feh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "VMFIN", "ART", "NN", "PTKNEG", "VVINF"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "ihren lieben Amerikanern zu erz\u00e4hlen.", "tokens": ["ih\u00b7ren", "lie\u00b7ben", "A\u00b7me\u00b7ri\u00b7ka\u00b7nern", "zu", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Denn das wissen wohl nur die wenigen.", "tokens": ["Denn", "das", "wis\u00b7sen", "wohl", "nur", "die", "we\u00b7ni\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADV", "ART", "PIAT", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und das ist gut. Denn schon in Brooklyn", "tokens": ["Und", "das", "ist", "gut", ".", "Denn", "schon", "in", "Brook\u00b7lyn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "ADJD", "$.", "KON", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "w\u00fcrde sie sonst verdienterma\u00dfen angespien,", "tokens": ["w\u00fcr\u00b7de", "sie", "sonst", "ver\u00b7dien\u00b7ter\u00b7ma\u00b7\u00dfen", "an\u00b7ge\u00b7spi\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVINF", "VVPP", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "die gute K\u00f6nigin von Rum\u00e4nien.", "tokens": ["die", "gu\u00b7te", "K\u00f6\u00b7ni\u00b7gin", "von", "Ru\u00b7m\u00e4\u00b7ni\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}