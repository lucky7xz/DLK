{"textgrid.poem.57914": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie denken Sie \u00fcber das Ehrenforum?", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie denken Sie \u00fcber das Ehrenforum?", "tokens": ["Wie", "den\u00b7ken", "Sie", "\u00fc\u00b7ber", "das", "Eh\u00b7ren\u00b7fo\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das ist eine tadellose Idee.", "tokens": ["Das", "ist", "ei\u00b7ne", "ta\u00b7del\u00b7lo\u00b7se", "I\u00b7dee", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Wir kriegen dann auf dem Schorsenwalle", "tokens": ["Wir", "krie\u00b7gen", "dann", "auf", "dem", "Schor\u00b7sen\u00b7wal\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So eine halbe Siegesallee.", "tokens": ["So", "ei\u00b7ne", "hal\u00b7be", "Sie\u00b7ge\u00b7sal\u00b7lee", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Alle zehn Schritte steht eine Gr\u00f6\u00dfe", "tokens": ["Al\u00b7le", "zehn", "Schrit\u00b7te", "steht", "ei\u00b7ne", "Gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "CARD", "NN", "VVFIN", "ART", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Von dieser oder jener Partei,", "tokens": ["Von", "die\u00b7ser", "o\u00b7der", "je\u00b7ner", "Par\u00b7tei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "KON", "PDAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Welfen und Nationalliberale", "tokens": ["Wel\u00b7fen", "und", "Na\u00b7ti\u00b7o\u00b7nal\u00b7li\u00b7be\u00b7ra\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Bilden dann h\u00fcbsch dort bunte Reih'.", "tokens": ["Bil\u00b7den", "dann", "h\u00fcbsch", "dort", "bun\u00b7te", "Reih'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ADV", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Dazwischen werden dann die Koniferen", "tokens": ["Da\u00b7zwi\u00b7schen", "wer\u00b7den", "dann", "die", "Ko\u00b7ni\u00b7fe\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Aus Kunst und Wissenschaft gesetzt,", "tokens": ["Aus", "Kunst", "und", "Wis\u00b7sen\u00b7schaft", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nat\u00fcrlich in ganz bestimmtem Abstand,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "in", "ganz", "be\u00b7stimm\u00b7tem", "Ab\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df man nirgends die Symmetrie verletzt.", "tokens": ["Da\u00df", "man", "nir\u00b7gends", "die", "Sym\u00b7me\u00b7trie", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Man rechnet so auf St\u00fccke hundert", "tokens": ["Man", "rech\u00b7net", "so", "auf", "St\u00fc\u00b7cke", "hun\u00b7dert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "NN", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vorl\u00e4ufig, schlie\u00dft man die alten mit ein,", "tokens": ["Vor\u00b7l\u00e4u\u00b7fig", ",", "schlie\u00dft", "man", "die", "al\u00b7ten", "mit", "ein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "PIS", "ART", "ADJA", "APPR", "ART", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Bis zum Bundesschie\u00dfen im Sommer", "tokens": ["Bis", "zum", "Bun\u00b7des\u00b7schie\u00b7\u00dfen", "im", "Som\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPRART", "NN", "APPRART", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Soll der ganze Krempel fertig sein.", "tokens": ["Soll", "der", "gan\u00b7ze", "Krem\u00b7pel", "fer\u00b7tig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}