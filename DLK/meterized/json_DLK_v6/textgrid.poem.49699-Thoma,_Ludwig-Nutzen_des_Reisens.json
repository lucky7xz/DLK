{"textgrid.poem.49699": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Nutzen des Reisens", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man soll vom Hause sich entfernen,", "tokens": ["Man", "soll", "vom", "Hau\u00b7se", "sich", "ent\u00b7fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Um in der Fremde neu zu lernen.", "tokens": ["Um", "in", "der", "Frem\u00b7de", "neu", "zu", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit off'nen Augen, frischem Sinn", "tokens": ["Mit", "off'\u00b7nen", "Au\u00b7gen", ",", "fri\u00b7schem", "Sinn"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sch\u00f6pft jeder Reisende Gewinn.", "tokens": ["Sch\u00f6pft", "je\u00b7der", "Rei\u00b7sen\u00b7de", "Ge\u00b7winn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ist dir im Kleinen wie im Gro\u00dfen", "tokens": ["Ist", "dir", "im", "Klei\u00b7nen", "wie", "im", "Gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "KOKOM", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gar manches seltsam aufgesto\u00dfen,", "tokens": ["Gar", "man\u00b7ches", "selt\u00b7sam", "auf\u00b7ge\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beacht es wohl! Veracht es nie!", "tokens": ["Be\u00b7acht", "es", "wohl", "!", "Ver\u00b7acht", "es", "nie", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und suche das \u00bbWarum\u00ab und \u00bbWie\u00ab!", "tokens": ["Und", "su\u00b7che", "das", "\u00bb", "Wa\u00b7rum", "\u00ab", "und", "\u00bb", "Wie", "\u00ab", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "$(", "PWAV", "$(", "KON", "$(", "PWAV", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du gehst ins Land der Italiener.", "tokens": ["Du", "gehst", "ins", "Land", "der", "I\u00b7ta\u00b7li\u00b7e\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da siehst du bald, wie der und jener", "tokens": ["Da", "siehst", "du", "bald", ",", "wie", "der", "und", "je\u00b7ner"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "ART", "KON", "PDS"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Mit L\u00e4cheln an der Ecke steht", "tokens": ["Mit", "L\u00e4\u00b7cheln", "an", "der", "E\u00b7cke", "steht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seine Notdurft hier begeht.", "tokens": ["Und", "sei\u00b7ne", "Not\u00b7durft", "hier", "be\u00b7geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nun also, diese Menschlichkeiten,", "tokens": ["Nun", "al\u00b7so", ",", "die\u00b7se", "Menschlich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PDAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die uns Beschwerden oft bereiten,", "tokens": ["Die", "uns", "Be\u00b7schwer\u00b7den", "oft", "be\u00b7rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der m\u00fchsam unterdr\u00fcckte Drang", "tokens": ["Der", "m\u00fch\u00b7sam", "un\u00b7ter\u00b7dr\u00fcck\u00b7te", "Drang"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vollzieht sich hierorts ohne Zwang.", "tokens": ["Voll\u00b7zieht", "sich", "hier\u00b7orts", "oh\u00b7ne", "Zwang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch dieser Vorgang kann belehren", "tokens": ["Auch", "die\u00b7ser", "Vor\u00b7gang", "kann", "be\u00b7leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und unsern Wissenskreis vermehren,", "tokens": ["Und", "un\u00b7sern", "Wis\u00b7sen\u00b7skreis", "ver\u00b7meh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn man das Typische daran", "tokens": ["Wenn", "man", "das", "Ty\u00b7pi\u00b7sche", "da\u00b7ran"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Klugheit unterscheiden kann.", "tokens": ["Mit", "Klug\u00b7heit", "un\u00b7ter\u00b7schei\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar l\u00e4\u00dft sich die Behauptung wagen:", "tokens": ["Zwar", "l\u00e4\u00dft", "sich", "die", "Be\u00b7haup\u00b7tung", "wa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Art, das Wasser abzuschlagen,", "tokens": ["Die", "Art", ",", "das", "Was\u00b7ser", "ab\u00b7zu\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bleibt immer gleich, und nur das \u00bbWo\u00ab", "tokens": ["Bleibt", "im\u00b7mer", "gleich", ",", "und", "nur", "das", "\u00bb", "Wo", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "$,", "KON", "ADV", "ART", "$(", "PWAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist unterschiedlich, so und so.", "tokens": ["Ist", "un\u00b7ter\u00b7schied\u00b7lich", ",", "so", "und", "so", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Jedoch man urteilt oberfl\u00e4chlich,", "tokens": ["Je\u00b7doch", "man", "ur\u00b7teilt", "o\u00b7berf\u00b7l\u00e4ch\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erachtet man dies nebens\u00e4chlich.", "tokens": ["E\u00b7rach\u00b7tet", "man", "dies", "ne\u00b7ben\u00b7s\u00e4ch\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PDS", "ADJD", "$."], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Denkende sieht die Kultur", "tokens": ["Der", "Den\u00b7ken\u00b7de", "sieht", "die", "Kul\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "In der Befolgung der Natur.", "tokens": ["In", "der", "Be\u00b7fol\u00b7gung", "der", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Ihm ist es auch kulturgeschichtlich;", "tokens": ["Ihm", "ist", "es", "auch", "kul\u00b7tur\u00b7ge\u00b7schicht\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vorgang macht es ihm ersichtlich.", "tokens": ["Der", "Vor\u00b7gang", "macht", "es", "ihm", "er\u00b7sicht\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er wei\u00df jetzt und durchschaut es tief:", "tokens": ["Er", "wei\u00df", "jetzt", "und", "durch\u00b7schaut", "es", "tief", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdas Volk des S\u00fcdens ist naiv.\u00ab", "tokens": ["\u00bb", "das", "Volk", "des", "S\u00fc\u00b7dens", "ist", "naiv", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}