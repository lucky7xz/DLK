{"textgrid.poem.41665": {"metadata": {"author": {"name": "Baudelaire, Charles", "birth": "N.A.", "death": "N.A."}, "title": "1L: Bla\u00df M\u00e4dchen mit dem roten Haar,", "genre": "verse", "period": "N.A.", "pub_year": 1844, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bla\u00df M\u00e4dchen mit dem roten Haar,", "tokens": ["Bla\u00df", "M\u00e4d\u00b7chen", "mit", "dem", "ro\u00b7ten", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Armut werden wir gewahr", "tokens": ["Die", "Ar\u00b7mut", "wer\u00b7den", "wir", "ge\u00b7wahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch all die L\u00f6cher deines Kleids", "tokens": ["Durch", "all", "die", "L\u00f6\u00b7cher", "dei\u00b7nes", "Kleids"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und deinen Reiz.", "tokens": ["Und", "dei\u00b7nen", "Reiz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Dein schmaler K\u00f6rper zeigt f\u00fcr mich,", "tokens": ["Dein", "schma\u00b7ler", "K\u00f6r\u00b7per", "zeigt", "f\u00fcr", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den schwachen, m\u00fcden Dichter, sich,", "tokens": ["Den", "schwa\u00b7chen", ",", "m\u00fc\u00b7den", "Dich\u00b7ter", ",", "sich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Sommersprossen \u00fcberstreut,", "tokens": ["Mit", "Som\u00b7mer\u00b7spros\u00b7sen", "\u00fc\u00b7bers\u00b7treut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Voll S\u00fc\u00dfigkeit.", "tokens": ["Voll", "S\u00fc\u00b7\u00dfig\u00b7keit", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Wie ihre Prunksandalen in", "tokens": ["Wie", "ih\u00b7re", "Prunks\u00b7an\u00b7da\u00b7len", "in"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Romanen eine K\u00f6nigin,", "tokens": ["Ro\u00b7ma\u00b7nen", "ei\u00b7ne", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So zierlich und gewandt tr\u00e4gst du", "tokens": ["So", "zier\u00b7lich", "und", "ge\u00b7wandt", "tr\u00e4gst", "du"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die schweren Schuh.", "tokens": ["Die", "schwe\u00b7ren", "Schuh", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Statt deiner Lumpen m\u00f6ge dir", "tokens": ["Statt", "dei\u00b7ner", "Lum\u00b7pen", "m\u00f6\u00b7ge", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Hofgewand in reicher Zier,", "tokens": ["Ein", "Hof\u00b7ge\u00b7wand", "in", "rei\u00b7cher", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dess' Falten rauschend niedergehn;", "tokens": ["Dess'", "Fal\u00b7ten", "rau\u00b7schend", "nie\u00b7der\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Fu\u00df umwehn.", "tokens": ["Den", "Fu\u00df", "um\u00b7wehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Statt der zerri\u00dfnen Str\u00fcmpfe soll", "tokens": ["Statt", "der", "zer\u00b7ri\u00df\u00b7nen", "Str\u00fcmp\u00b7fe", "soll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Blick des W\u00fcstlings anmutvoll", "tokens": ["Dem", "Blick", "des", "W\u00fcst\u00b7lings", "an\u00b7mut\u00b7voll"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein goldner Dolch an deinem Bein", "tokens": ["Ein", "gold\u00b7ner", "Dolch", "an", "dei\u00b7nem", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Spr\u00fchn lichten Schein;", "tokens": ["Spr\u00fchn", "lich\u00b7ten", "Schein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Da\u00df Schleif und Band, gel\u00f6st, zerkn\u00fcllt,", "tokens": ["Da\u00df", "Schleif", "und", "Band", ",", "ge\u00b7l\u00f6st", ",", "zer\u00b7kn\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr unsre S\u00fcnden froh enth\u00fcllt", "tokens": ["F\u00fcr", "uns\u00b7re", "S\u00fcn\u00b7den", "froh", "ent\u00b7h\u00fcllt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sch\u00f6nen Br\u00fcste heiter Paar,", "tokens": ["Der", "sch\u00f6\u00b7nen", "Br\u00fcs\u00b7te", "hei\u00b7ter", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Augen klar;", "tokens": ["Wie", "Au\u00b7gen", "klar", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Da\u00df deine schlanken Arme, Kind,", "tokens": ["Da\u00df", "dei\u00b7ne", "schlan\u00b7ken", "Ar\u00b7me", ",", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich zu entkleiden willig sind", "tokens": ["Dich", "zu", "ent\u00b7klei\u00b7den", "wil\u00b7lig", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PTKZU", "VVINF", "ADJD", "VAFIN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Und leichter Schlag die Hand verjagt,", "tokens": ["Und", "leich\u00b7ter", "Schlag", "die", "Hand", "ver\u00b7jagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die zuviel wagt.", "tokens": ["Die", "zu\u00b7viel", "wagt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Ein Perlschmuck rein und fehlerlos,", "tokens": ["Ein", "Perl\u00b7schmuck", "rein", "und", "feh\u00b7ler\u00b7los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein z\u00e4rtliches Sonett Belleaus", "tokens": ["Ein", "z\u00e4rt\u00b7li\u00b7ches", "So\u00b7nett", "Bel\u00b7le\u00b7aus"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Bringt der Verehrer Sklavenschar", "tokens": ["Bringt", "der", "Ver\u00b7eh\u00b7rer", "Skla\u00b7ven\u00b7schar"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dir huldgend dar.", "tokens": ["Dir", "huld\u00b7gend", "dar", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Die Helden all der Reimerein,", "tokens": ["Die", "Hel\u00b7den", "all", "der", "Rei\u00b7me\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ihre Erstlinge dir weihn,", "tokens": ["Die", "ih\u00b7re", "Erst\u00b7lin\u00b7ge", "dir", "weihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Bewundern, wie dein leichter Schritt", "tokens": ["Be\u00b7wun\u00b7dern", ",", "wie", "dein", "leich\u00b7ter", "Schritt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Stufen tritt.", "tokens": ["Die", "Stu\u00b7fen", "tritt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Manch Page, der auf Wagnis sann,", "tokens": ["Manch", "Pa\u00b7ge", ",", "der", "auf", "Wag\u00b7nis", "sann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Manch ein Poet und Edelmann,", "tokens": ["Manch", "ein", "Po\u00b7et", "und", "E\u00b7del\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie schicken all ihr Sehnen nach", "tokens": ["Sie", "schi\u00b7cken", "all", "ihr", "Seh\u00b7nen", "nach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "PPOSAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In dein Gemach.", "tokens": ["In", "dein", "Ge\u00b7mach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Es w\u00fcrden auf dem Lager dein", "tokens": ["Es", "w\u00fcr\u00b7den", "auf", "dem", "La\u00b7ger", "dein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mehr K\u00fcss' als K\u00f6nigslilien sein,", "tokens": ["Mehr", "K\u00fcss'", "als", "K\u00f6\u00b7nigs\u00b7li\u00b7li\u00b7en", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "NN", "VAINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Manch Valois machte gerne sich", "tokens": ["Manch", "Va\u00b7lois", "mach\u00b7te", "ger\u00b7ne", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ADV", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Knecht f\u00fcr dich!", "tokens": ["Zum", "Knecht", "f\u00fcr", "dich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Indessen aber bettelnd ziehst", "tokens": ["In\u00b7des\u00b7sen", "a\u00b7ber", "bet\u00b7telnd", "ziehst"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVPP", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch arme Gassen du und siehst", "tokens": ["Durch", "ar\u00b7me", "Gas\u00b7sen", "du", "und", "siehst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PPER", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach dem Ger\u00fcmpel alten Schutts", "tokens": ["Nach", "dem", "Ge\u00b7r\u00fcm\u00b7pel", "al\u00b7ten", "Schutts"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Stra\u00dfenschmutz;", "tokens": ["Im", "Stra\u00b7\u00dfen\u00b7schmutz", ";"], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "Und schielst nach Schmuck hin, vielbegehrt,", "tokens": ["Und", "schielst", "nach", "Schmuck", "hin", ",", "viel\u00b7be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKVZ", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der keine zwanzig Pfennig wert,", "tokens": ["Der", "kei\u00b7ne", "zwan\u00b7zig", "Pfen\u00b7nig", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den ich dir, rechn es mir nicht an,", "tokens": ["Den", "ich", "dir", ",", "rechn", "es", "mir", "nicht", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPER", "$,", "VVFIN", "PPER", "PPER", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht schenken kann.", "tokens": ["Nicht", "schen\u00b7ken", "kann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "So geh denn ohne Prunkgewand,", "tokens": ["So", "geh", "denn", "oh\u00b7ne", "Prunk\u00b7ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Riechwasser, Perlen, Diamant,", "tokens": ["Riech\u00b7was\u00b7ser", ",", "Per\u00b7len", ",", "Di\u00b7a\u00b7mant", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In magrer Nacktheit immerzu,", "tokens": ["In", "mag\u00b7rer", "Nackt\u00b7heit", "im\u00b7mer\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O Sch\u00f6nste du!", "tokens": ["O", "Sch\u00f6ns\u00b7te", "du", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}