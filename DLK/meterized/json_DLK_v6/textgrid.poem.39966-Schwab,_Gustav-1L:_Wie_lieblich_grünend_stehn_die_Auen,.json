{"textgrid.poem.39966": {"metadata": {"author": {"name": "Schwab, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie lieblich gr\u00fcnend stehn die Auen,", "genre": "verse", "period": "N.A.", "pub_year": 1821, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie lieblich gr\u00fcnend stehn die Auen,", "tokens": ["Wie", "lieb\u00b7lich", "gr\u00fc\u00b7nend", "stehn", "die", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch die der Pfad nach Bethlem f\u00fchrt,", "tokens": ["Durch", "die", "der", "Pfad", "nach", "Beth\u00b7lem", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie vollbelaubte H\u00fcgel schauen", "tokens": ["Wie", "voll\u00b7be\u00b7laub\u00b7te", "H\u00fc\u00b7gel", "schau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ins Thal, das keinen Winter sp\u00fcrt.", "tokens": ["Ins", "Thal", ",", "das", "kei\u00b7nen", "Win\u00b7ter", "sp\u00fcrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es wei\u00df nichts von des Hagels Schl\u00e4gen", "tokens": ["Es", "wei\u00df", "nichts", "von", "des", "Ha\u00b7gels", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und bleibt im Sommer unversengt,", "tokens": ["Und", "bleibt", "im", "Som\u00b7mer", "un\u00b7ver\u00b7sengt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es wird zur Zeit der kalten Regen", "tokens": ["Es", "wird", "zur", "Zeit", "der", "kal\u00b7ten", "Re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit warmem Fr\u00fchlingsgu\u00df besprengt.", "tokens": ["Mit", "war\u00b7mem", "Fr\u00fch\u00b7lings\u00b7gu\u00df", "be\u00b7sprengt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Durch solches geht die Winterreise", "tokens": ["Durch", "sol\u00b7ches", "geht", "die", "Win\u00b7ter\u00b7rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der K\u00f6nige mit Lenzesmut;", "tokens": ["Der", "K\u00f6\u00b7ni\u00b7ge", "mit", "Len\u00b7zes\u00b7mut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Sonne sinkt, da gie\u00dft sich leise", "tokens": ["Die", "Son\u00b7ne", "sinkt", ",", "da", "gie\u00dft", "sich", "lei\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch's gr\u00fcne Feld Smaragdenglut.", "tokens": ["Durch's", "gr\u00fc\u00b7ne", "Feld", "Sma\u00b7rag\u00b7deng\u00b7lut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Berge sind von Golde trunken,", "tokens": ["Die", "Ber\u00b7ge", "sind", "von", "Gol\u00b7de", "trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der B\u00e4che Silber leuchtet fern;", "tokens": ["Der", "B\u00e4\u00b7che", "Sil\u00b7ber", "leuch\u00b7tet", "fern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wohl ist die Sonne l\u00e4ngst versunken,", "tokens": ["Wohl", "ist", "die", "Son\u00b7ne", "l\u00e4ngst", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch \u00fcber ihnen geht der Stern.", "tokens": ["Doch", "\u00fc\u00b7ber", "ih\u00b7nen", "geht", "der", "Stern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Heut wandelt er mit ihren Tritten,", "tokens": ["Heut", "wan\u00b7delt", "er", "mit", "ih\u00b7ren", "Trit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er geht so fest, so rasch voran;", "tokens": ["Er", "geht", "so", "fest", ",", "so", "rasch", "vo\u00b7ran", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ja, seine Stralen gleichen Schritten,", "tokens": ["Ja", ",", "sei\u00b7ne", "Stra\u00b7len", "glei\u00b7chen", "Schrit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und lassen Spuren ihrer Bahn.", "tokens": ["Und", "las\u00b7sen", "Spu\u00b7ren", "ih\u00b7rer", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie wenn ein lichter Regenbogen", "tokens": ["Wie", "wenn", "ein", "lich\u00b7ter", "Re\u00b7gen\u00b7bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch's Thal, nicht durch die Wolken geht,", "tokens": ["Durch's", "Thal", ",", "nicht", "durch", "die", "Wol\u00b7ken", "geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So haben sie den Pfad gezogen", "tokens": ["So", "ha\u00b7ben", "sie", "den", "Pfad", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und eine Furche Golds ges\u00e4t.", "tokens": ["Und", "ei\u00b7ne", "Fur\u00b7che", "Golds", "ge\u00b7s\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Dort liegt an eines H\u00fcgels Saume", "tokens": ["Dort", "liegt", "an", "ei\u00b7nes", "H\u00fc\u00b7gels", "Sau\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Gelagert eine Hirtenschar,", "tokens": ["Ge\u00b7la\u00b7gert", "ei\u00b7ne", "Hir\u00b7ten\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erweckt aus ihrem ersten Traume", "tokens": ["Er\u00b7weckt", "aus", "ih\u00b7rem", "ers\u00b7ten", "Trau\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hat sie der Stern so wunderklar.", "tokens": ["Hat", "sie", "der", "Stern", "so", "wun\u00b7der\u00b7klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er deckt mit wei\u00dfen, weichen Lichtern", "tokens": ["Er", "deckt", "mit", "wei\u00b7\u00dfen", ",", "wei\u00b7chen", "Lich\u00b7tern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Schafe schlummernd H\u00e4uflein ganz,", "tokens": ["Der", "Scha\u00b7fe", "schlum\u00b7mernd", "H\u00e4uf\u00b7lein", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und auf den frommen Angesichtern", "tokens": ["Und", "auf", "den", "from\u00b7men", "An\u00b7ge\u00b7sich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der Hirten spiegelt sich sein Glanz.", "tokens": ["Der", "Hir\u00b7ten", "spie\u00b7gelt", "sich", "sein", "Glanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Da kommt der F\u00fcrsten Heer gezogen,", "tokens": ["Da", "kommt", "der", "F\u00fcrs\u00b7ten", "Heer", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Hirten richten sich empor;", "tokens": ["Die", "Hir\u00b7ten", "rich\u00b7ten", "sich", "em\u00b7por", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf fl\u00fccht'gem Ro\u00df herbeigeflogen", "tokens": ["Auf", "fl\u00fccht'\u00b7gem", "Ro\u00df", "her\u00b7bei\u00b7ge\u00b7flo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sprengt an der Tharsisf\u00fcrst, der Mohr:", "tokens": ["Sprengt", "an", "der", "Thar\u00b7sis\u00b7f\u00fcrst", ",", "der", "Mohr", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bberzittert nicht, ihr Hirtenleute!", "tokens": ["\u00bb", "er\u00b7zit\u00b7tert", "nicht", ",", "ihr", "Hir\u00b7ten\u00b7leu\u00b7te", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wir sind kein feindlich Kriegesheer;", "tokens": ["Wir", "sind", "kein", "feind\u00b7lich", "Krie\u00b7ges\u00b7heer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir fallen nicht auf euch nach Beute,", "tokens": ["Wir", "fal\u00b7len", "nicht", "auf", "euch", "nach", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wir werfen nicht nach euch den Speer!\u00ab", "tokens": ["Wir", "wer\u00b7fen", "nicht", "nach", "euch", "den", "Speer", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPER", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ihm tritt ein ernster Greis entgegen,", "tokens": ["Ihm", "tritt", "ein", "erns\u00b7ter", "Greis", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Neigt sich und spricht: \u00bbGewalt'ge Herrn!", "tokens": ["Neigt", "sich", "und", "spricht", ":", "\u00bb", "Ge\u00b7walt'\u00b7ge", "Herrn", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "KON", "VVFIN", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist ein Wunder allerwegen:", "tokens": ["Es", "ist", "ein", "Wun\u00b7der", "al\u00b7ler\u00b7we\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier solches Heer und dort der Stern!", "tokens": ["Hier", "sol\u00b7ches", "Heer", "und", "dort", "der", "Stern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch schreckt uns nicht, was wir gewahren,", "tokens": ["Doch", "schreckt", "uns", "nicht", ",", "was", "wir", "ge\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und blendet dieser Glanz uns nicht,", "tokens": ["Und", "blen\u00b7det", "die\u00b7ser", "Glanz", "uns", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Denn wi\u00dft, wir sahn des Himmels Scharen,", "tokens": ["Denn", "wi\u00dft", ",", "wir", "sahn", "des", "Him\u00b7mels", "Scha\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und schauten mehr denn Sternenlicht.", "tokens": ["Und", "schau\u00b7ten", "mehr", "denn", "Ster\u00b7nen\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wir lagen still bei unsrer Heerde; \u2013", "tokens": ["Wir", "la\u00b7gen", "still", "bei", "uns\u00b7rer", "Heer\u00b7de", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dreizehnmal ward seit dem es Nacht \u2013", "tokens": ["Drei\u00b7zehn\u00b7mal", "ward", "seit", "dem", "es", "Nacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PRELS", "PPER", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da go\u00df sich Klarheit auf die Erde,", "tokens": ["Da", "go\u00df", "sich", "Klar\u00b7heit", "auf", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da wallt' ein Glanz um uns mit Macht,", "tokens": ["Da", "wallt'", "ein", "Glanz", "um", "uns", "mit", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da hatt' im Kleid, aus Licht gewoben,", "tokens": ["Da", "hatt'", "im", "Kleid", ",", "aus", "Licht", "ge\u00b7wo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein J\u00fcngling sich herab gesenkt,", "tokens": ["Ein", "J\u00fcng\u00b7ling", "sich", "her\u00b7ab", "ge\u00b7senkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Hirte d\u00e4ucht' es uns, der droben", "tokens": ["Ein", "Hir\u00b7te", "d\u00e4ucht'", "es", "uns", ",", "der", "dro\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Des Himmels goldne Schafe tr\u00e4nkt.\u00ab", "tokens": ["Des", "Him\u00b7mels", "gold\u00b7ne", "Scha\u00b7fe", "tr\u00e4nkt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Er sprach: \u00bbGetrost! ich bin Verk\u00fcnder", "tokens": ["Er", "sprach", ":", "\u00bb", "Ge\u00b7trost", "!", "ich", "bin", "Ver\u00b7k\u00fcn\u00b7der"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "$.", "PPER", "VAFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Heils, das heut euch widerf\u00e4hrt:", "tokens": ["Des", "Heils", ",", "das", "heut", "euch", "wi\u00b7der\u00b7f\u00e4hrt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Euch ist der Heiland aller S\u00fcnder,", "tokens": ["Euch", "ist", "der", "Hei\u00b7land", "al\u00b7ler", "S\u00fcn\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Christ, in Davids Stadt bescheert.", "tokens": ["Der", "Christ", ",", "in", "Da\u00b7vids", "Stadt", "be\u00b7scheert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bewahrt das Wort von meinen Lippen,", "tokens": ["Be\u00b7wahrt", "das", "Wort", "von", "mei\u00b7nen", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sucht, bis das Zeichen sich erf\u00fcllt:", "tokens": ["Sucht", ",", "bis", "das", "Zei\u00b7chen", "sich", "er\u00b7f\u00fcllt", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr findet dort in einer Krippen", "tokens": ["Ihr", "fin\u00b7det", "dort", "in", "ei\u00b7ner", "Krip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Kind in Windeln eingeh\u00fcllt!\u00ab", "tokens": ["Ein", "Kind", "in", "Win\u00b7deln", "ein\u00b7ge\u00b7h\u00fcllt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Er sprach's, und alsbald war die Menge", "tokens": ["Er", "sprach's", ",", "und", "als\u00b7bald", "war", "die", "Men\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Himmelsscharen um ihn her,", "tokens": ["Der", "Him\u00b7mels\u00b7scha\u00b7ren", "um", "ihn", "her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da rauschten selige Ges\u00e4nge,", "tokens": ["Da", "rauschten", "se\u00b7li\u00b7ge", "Ge\u00b7s\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da wogt' um uns des Lichtes Meer.", "tokens": ["Da", "wogt'", "um", "uns", "des", "Lich\u00b7tes", "Meer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir aber gingen anzubeten,", "tokens": ["Wir", "a\u00b7ber", "gin\u00b7gen", "an\u00b7zu\u00b7be\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wir kennen unsern K\u00f6nig jetzt:", "tokens": ["Wir", "ken\u00b7nen", "un\u00b7sern", "K\u00f6\u00b7nig", "jetzt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Seit hat von Erden-Lust und -N\u00f6ten", "tokens": ["Seit", "hat", "von", "Er\u00b7den\u00b7Lust", "und"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Uns nichts erfreut, uns nichts entsetzt.\u00ab", "tokens": ["Uns", "nichts", "er\u00b7freut", ",", "uns", "nichts", "ent\u00b7setzt", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PIS", "VVFIN", "$,", "PPER", "PIS", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nun wurden K\u00f6n'ge bald und Hirten", "tokens": ["Nun", "wur\u00b7den", "K\u00f6n'\u00b7ge", "bald", "und", "Hir\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In freudigen Gespr\u00e4chen eins,", "tokens": ["In", "freu\u00b7di\u00b7gen", "Ge\u00b7spr\u00e4\u00b7chen", "eins", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Beider Heerden traulich irrten", "tokens": ["Und", "Bei\u00b7der", "Heer\u00b7den", "trau\u00b7lich", "irr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vermengt im Glanz des Sternenscheins.", "tokens": ["Ver\u00b7mengt", "im", "Glanz", "des", "Ster\u00b7nen\u00b7scheins", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da war nicht Jude mehr und Heide,", "tokens": ["Da", "war", "nicht", "Ju\u00b7de", "mehr", "und", "Hei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "NN", "ADV", "KON", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sie waren Beid' ", "tokens": ["Sie", "wa\u00b7ren", "Beid'"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Zu ", "tokens": ["Zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Vom Engel die, und die vom Stern.", "tokens": ["Vom", "En\u00b7gel", "die", ",", "und", "die", "vom", "Stern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "$,", "KON", "ART", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}