{"dta.poem.9143": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "ViII.  \n Als er sich unter fremdes frauenzimmer machen sollte.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Ich will bey meinem m\u00e4dgen bleiben/", "tokens": ["Ich", "will", "bey", "mei\u00b7nem", "m\u00e4d\u00b7gen", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab die brieffe nicht davon/", "tokens": ["Ich", "hab", "die", "brief\u00b7fe", "nicht", "da\u00b7von", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "VVFIN", "PTKNEG", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich mich soll an ein andre reiben/", "tokens": ["Da\u00df", "ich", "mich", "soll", "an", "ein", "and\u00b7re", "rei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "APPR", "ART", "PIS", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Drum geb ich auch kein botenlohn.", "tokens": ["Drum", "geb", "ich", "auch", "kein", "bo\u00b7ten\u00b7lohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und danck es keinem gar zu viel/", "tokens": ["Und", "danck", "es", "kei\u00b7nem", "gar", "zu", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PIS", "ADV", "PTKA", "PIS", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der mich zu andern f\u00fchren will.", "tokens": ["Der", "mich", "zu", "an\u00b7dern", "f\u00fch\u00b7ren", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Ich habe manche liebe stunden", "tokens": ["Ich", "ha\u00b7be", "man\u00b7che", "lie\u00b7be", "stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In leerer hoffnung zugeb\u00fcst/", "tokens": ["In", "lee\u00b7rer", "hoff\u00b7nung", "zu\u00b7ge\u00b7b\u00fcst", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eh ich es in der that befunden", "tokens": ["Eh", "ich", "es", "in", "der", "that", "be\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "VVFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df sie mein m\u00e4dgen worden ist:", "tokens": ["Da\u00df", "sie", "mein", "m\u00e4d\u00b7gen", "wor\u00b7den", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Drum lenck ich auch mein angesicht", "tokens": ["Drum", "lenck", "ich", "auch", "mein", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nunmehr zu keiner andern nicht.", "tokens": ["Nun\u00b7mehr", "zu", "kei\u00b7ner", "an\u00b7dern", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Ich wei\u00df von aussen und von innen", "tokens": ["Ich", "wei\u00df", "von", "aus\u00b7sen", "und", "von", "in\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "VVINF", "KON", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ihr gem\u00fcth im schilde f\u00fchrt/", "tokens": ["Was", "ihr", "ge\u00b7m\u00fcth", "im", "schil\u00b7de", "f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und bin gewi\u00df da\u00df sie die sinnen", "tokens": ["Und", "bin", "ge\u00b7wi\u00df", "da\u00df", "sie", "die", "sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit lauter freundlichkeit regiert/", "tokens": ["Mit", "lau\u00b7ter", "freund\u00b7lich\u00b7keit", "re\u00b7giert", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie ist belieblich/ zart und sch\u00f6n/", "tokens": ["Sie", "ist", "be\u00b7lieb\u00b7lich", "/", "zart", "und", "sch\u00f6n", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$(", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was solt ich dann zur andern gehn.", "tokens": ["Was", "solt", "ich", "dann", "zur", "an\u00b7dern", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Offt hertzt ein fremder eine ziege/", "tokens": ["Offt", "hertzt", "ein", "frem\u00b7der", "ei\u00b7ne", "zie\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sieht sie vor die Venus an/", "tokens": ["Und", "sieht", "sie", "vor", "die", "Ve\u00b7nus", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil er dieselbe nach der gn\u00fcge", "tokens": ["Weil", "er", "die\u00b7sel\u00b7be", "nach", "der", "gn\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDAT", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bald erstlich nicht erkennen kan/", "tokens": ["Bald", "erst\u00b7lich", "nicht", "er\u00b7ken\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und weil ein schleyer und die nacht", "tokens": ["Und", "weil", "ein", "schle\u00b7yer", "und", "die", "nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "ADJA", "KON", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Die schlimmste magd zur jungfer macht.", "tokens": ["Die", "schlimms\u00b7te", "magd", "zur", "jung\u00b7fer", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Und wann ich gleich was sch\u00f6nes k\u00fcsse/", "tokens": ["Und", "wann", "ich", "gleich", "was", "sch\u00f6\u00b7nes", "k\u00fcs\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "PWS", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ist mirs dannoch unbekant/", "tokens": ["So", "ist", "mirs", "dan\u00b7noch", "un\u00b7be\u00b7kant", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach nein/ ich nehme das gewisse/", "tokens": ["Ach", "nein", "/", "ich", "neh\u00b7me", "das", "ge\u00b7wis\u00b7se", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$(", "PPER", "VVFIN", "ART", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und denck/ ein vogel in der hand/", "tokens": ["Und", "denck", "/", "ein", "vo\u00b7gel", "in", "der", "hand", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "$(", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist besser dann ein gantzes dutzt", "tokens": ["Ist", "bes\u00b7ser", "dann", "ein", "gant\u00b7zes", "dutzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das noch in freyen felde stutzt.", "tokens": ["Das", "noch", "in", "frey\u00b7en", "fel\u00b7de", "stutzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Wer sich nun gerne will verhindern", "tokens": ["Wer", "sich", "nun", "ger\u00b7ne", "will", "ver\u00b7hin\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "ADV", "ADV", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der suche seine liebe weit/", "tokens": ["Der", "su\u00b7che", "sei\u00b7ne", "lie\u00b7be", "weit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist doch wahr/ an fremden kindern", "tokens": ["Es", "ist", "doch", "wahr", "/", "an", "frem\u00b7den", "kin\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$(", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verderbt man alle freundlichkeit/", "tokens": ["Ver\u00b7derbt", "man", "al\u00b7le", "freund\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "An fremden hunden wendet man", "tokens": ["An", "frem\u00b7den", "hun\u00b7den", "wen\u00b7det", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die suppen gar vergebens an.", "tokens": ["Die", "sup\u00b7pen", "gar", "ver\u00b7ge\u00b7bens", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Ich bleibe nun wo meine liebe", "tokens": ["Ich", "blei\u00b7be", "nun", "wo", "mei\u00b7ne", "lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PWAV", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sich erstlich hat hervorgethan/", "tokens": ["Sich", "erst\u00b7lich", "hat", "her\u00b7vor\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und da ich endlich keine diebe", "tokens": ["Und", "da", "ich", "end\u00b7lich", "kei\u00b7ne", "die\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu meinem schaden f\u00fcrchten kan.", "tokens": ["Zu", "mei\u00b7nem", "scha\u00b7den", "f\u00fcrch\u00b7ten", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein ander suche was er will/", "tokens": ["Ein", "an\u00b7der", "su\u00b7che", "was", "er", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "PWS", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von meinem m\u00e4dgen halt ich viel.", "tokens": ["Von", "mei\u00b7nem", "m\u00e4d\u00b7gen", "halt", "ich", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}