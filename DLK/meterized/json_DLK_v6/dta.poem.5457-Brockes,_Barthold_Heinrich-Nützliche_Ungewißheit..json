{"dta.poem.5457": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "N\u00fctzliche Ungewi\u00dfheit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nebst andern war ich j\u00fcngst, der alten Weisen Lehren,", "tokens": ["Nebst", "an\u00b7dern", "war", "ich", "j\u00fcngst", ",", "der", "al\u00b7ten", "Wei\u00b7sen", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "ADV", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie sie des weisen ", "tokens": ["Wie", "sie", "des", "wei\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Den man mit Recht die Zierde Hamburgs heist,", "tokens": ["Den", "man", "mit", "Recht", "die", "Zier\u00b7de", "Ham\u00b7burgs", "heist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "NN", "ART", "NN", "NE", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Durch seine Lehrlinge lie\u00df \u00f6ffentlich erkl\u00e4ren,", "tokens": ["Durch", "sei\u00b7ne", "Lehr\u00b7lin\u00b7ge", "lie\u00df", "\u00f6f\u00b7fent\u00b7lich", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Besch\u00e4ftiget gewesen anzuh\u00f6ren.", "tokens": ["Be\u00b7sch\u00e4f\u00b7ti\u00b7get", "ge\u00b7we\u00b7sen", "an\u00b7zu\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VAPP", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wie ich mich nun darauf allein befand;", "tokens": ["Wie", "ich", "mich", "nun", "da\u00b7rauf", "al\u00b7lein", "be\u00b7fand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "PAV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Was ich von ihm geh\u00f6rt, bed\u00e4chtlich \u00fcberlegte,", "tokens": ["Was", "ich", "von", "ihm", "ge\u00b7h\u00f6rt", ",", "be\u00b7d\u00e4cht\u00b7lich", "\u00fc\u00b7ber\u00b7leg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPER", "VVFIN", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und in gelassner Still\u2019 erwegte", "tokens": ["Und", "in", "ge\u00b7lass\u00b7ner", "Still'", "er\u00b7weg\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Die Mannigfaltigkeit der Grillen,", "tokens": ["Die", "Man\u00b7nig\u00b7fal\u00b7tig\u00b7keit", "der", "Gril\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die stets den menschlichen Verstand", "tokens": ["Die", "stets", "den", "menschli\u00b7chen", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "Vor dem erf\u00fcllt, und noch erf\u00fcllen;", "tokens": ["Vor", "dem", "er\u00b7f\u00fcllt", ",", "und", "noch", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVPP", "$,", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Befiel mich eine Traurigkeit,", "tokens": ["Be\u00b7fiel", "mich", "ei\u00b7ne", "Trau\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und drengte die verworrenen Gedancken,", "tokens": ["Und", "dreng\u00b7te", "die", "ver\u00b7wor\u00b7re\u00b7nen", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Mit einer schwartzen Last, aus ihren Schrancken;", "tokens": ["Mit", "ei\u00b7ner", "schwart\u00b7zen", "Last", ",", "aus", "ih\u00b7ren", "Schran\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Ich f\u00fchlt\u2019 ein wahres Hertzeleid.", "tokens": ["Ich", "f\u00fchlt'", "ein", "wah\u00b7res", "Hert\u00b7ze\u00b7leid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Das gantze menschliche Geschlecht", "tokens": ["Das", "gant\u00b7ze", "menschli\u00b7che", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Kam mir bejammerns-wehrt, und recht", "tokens": ["Kam", "mir", "be\u00b7jam\u00b7merns\u00b7wehrt", ",", "und", "recht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "PPER", "VVPP", "$,", "KON", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Erbarmung-w\u00fcrdig f\u00fcr.", "tokens": ["Er\u00b7bar\u00b7mung\u00b7w\u00fcr\u00b7dig", "f\u00fcr", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "APPR", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Wir scheinen nichtes recht zu fassen,", "tokens": ["Wir", "schei\u00b7nen", "nich\u00b7tes", "recht", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Wir scheinen all dem Jrrthum \u00fcberlassen,", "tokens": ["Wir", "schei\u00b7nen", "all", "dem", "Jrr\u00b7thum", "\u00fc\u00b7ber\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Der uns best\u00e4ndig \u00e4fft,", "tokens": ["Der", "uns", "be\u00b7st\u00e4n\u00b7dig", "\u00e4fft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "Da, von den Meynungen, die gantz verschiedlich scheinen,", "tokens": ["Da", ",", "von", "den", "Mey\u00b7nun\u00b7gen", ",", "die", "gantz", "ver\u00b7schied\u00b7lich", "schei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Von welchen von der weisen Schar,", "tokens": ["Von", "wel\u00b7chen", "von", "der", "wei\u00b7sen", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Die H\u00e4lfte, da\u00df sie wahr und klar;", "tokens": ["Die", "H\u00e4lf\u00b7te", ",", "da\u00df", "sie", "wahr", "und", "klar", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Die andre, da\u00df sie falsch und dunckel w\u00e4ren; meynen,", "tokens": ["Die", "and\u00b7re", ",", "da\u00df", "sie", "falsch", "und", "dun\u00b7ckel", "w\u00e4\u00b7ren", ";", "mey\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PIS", "$,", "KOUS", "PPER", "ADJD", "KON", "ADJD", "VAFIN", "$.", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Oft all\u2019, und dennoch keine wahr.", "tokens": ["Oft", "all'", ",", "und", "den\u00b7noch", "kei\u00b7ne", "wahr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "KON", "ADV", "PIAT", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Mir fiel hier\u00fcber ein:", "tokens": ["Mir", "fiel", "hier\u00b7\u00fc\u00b7ber", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Es t\u00e4uscht auch mich vielleicht ein falscher Schein.", "tokens": ["Es", "t\u00e4uscht", "auch", "mich", "viel\u00b7leicht", "ein", "fal\u00b7scher", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich kann ein Ding unm\u00f6glich wahrer halten,", "tokens": ["Ich", "kann", "ein", "Ding", "un\u00b7m\u00f6g\u00b7lich", "wah\u00b7rer", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Als jeder von den Alten", "tokens": ["Als", "je\u00b7der", "von", "den", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Dasjenige, was er geglaubt, f\u00fcr wahr,", "tokens": ["Das\u00b7je\u00b7ni\u00b7ge", ",", "was", "er", "ge\u00b7glaubt", ",", "f\u00fcr", "wahr", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "VVPP", "$,", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr deutlich angesehn und \u00fcberzeuglich klar;", "tokens": ["F\u00fcr", "deut\u00b7lich", "an\u00b7ge\u00b7sehn", "und", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "klar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVPP", "KON", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob sie gleich allesammt geirrt,", "tokens": ["Ob", "sie", "gleich", "al\u00b7le\u00b7sammt", "ge\u00b7irrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sich einander selbst verwirrt.", "tokens": ["Und", "sich", "ein\u00b7an\u00b7der", "selbst", "ver\u00b7wirrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun sind sie weise ja, im hohen Grad, gewesen,", "tokens": ["Nun", "sind", "sie", "wei\u00b7se", "ja", ",", "im", "ho\u00b7hen", "Grad", ",", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "ADV", "$,", "APPRART", "ADJA", "NN", "$,", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wovon wir Proben gnug in ihren Schriften lesen:", "tokens": ["Wo\u00b7von", "wir", "Pro\u00b7ben", "gnug", "in", "ih\u00b7ren", "Schrif\u00b7ten", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was \u00fcberzeugt denn mich, da\u00df ich nicht irren k\u00f6nne,", "tokens": ["Was", "\u00fc\u00b7berz\u00b7eugt", "denn", "mich", ",", "da\u00df", "ich", "nicht", "ir\u00b7ren", "k\u00f6n\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "KON", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und da\u00df ich gleichfals mich nicht von der Wahrheit trenne?", "tokens": ["Und", "da\u00df", "ich", "gleich\u00b7fals", "mich", "nicht", "von", "der", "Wahr\u00b7heit", "tren\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, da\u00df die Nachwelt uns, da\u00df wir in Jrthum stecken,", "tokens": ["Ja", ",", "da\u00df", "die", "Nach\u00b7welt", "uns", ",", "da\u00df", "wir", "in", "Jr\u00b7thum", "ste\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "ART", "NN", "PPER", "$,", "KOUS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie wir der Vorwelt es gezeigt, einst wird entdecken?", "tokens": ["Wie", "wir", "der", "Vor\u00b7welt", "es", "ge\u00b7zeigt", ",", "einst", "wird", "ent\u00b7de\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "PPER", "VVPP", "$,", "ADV", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Zweiffel l\u00f6st sich bald: Wir wissen,", "tokens": ["Der", "Zweif\u00b7fel", "l\u00f6st", "sich", "bald", ":", "Wir", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df unser Wissen nichts, als St\u00fcckwerck sey;", "tokens": ["Da\u00df", "un\u00b7ser", "Wis\u00b7sen", "nichts", ",", "als", "St\u00fcck\u00b7werck", "sey", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PIS", "$,", "KOUS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und wir daher, wie billig ", "tokens": ["Und", "wir", "da\u00b7her", ",", "wie", "bil\u00b7lig"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "PAV", "$,", "PWAV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Nechst diesem steckt hierin noch zweyerley:", "tokens": ["Nechst", "die\u00b7sem", "steckt", "hie\u00b7rin", "noch", "zwey\u00b7er\u00b7ley", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Ungewi\u00dfheit aller Sachen,", "tokens": ["Die", "Un\u00b7ge\u00b7wi\u00df\u00b7heit", "al\u00b7ler", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Besinnen wir uns recht,", "tokens": ["Be\u00b7sin\u00b7nen", "wir", "uns", "recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Soll billig gegen GOtt uns ehrerbietig machen,", "tokens": ["Soll", "bil\u00b7lig", "ge\u00b7gen", "Gott", "uns", "ehr\u00b7er\u00b7bie\u00b7tig", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "APPR", "NN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und voll Vertr\u00e4glichkeit f\u00fcrs menschliche Geschlecht.", "tokens": ["Und", "voll", "Ver\u00b7tr\u00e4g\u00b7lich\u00b7keit", "f\u00fcrs", "menschli\u00b7che", "Ge\u00b7schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Erkennet man, da\u00df man nichts wei\u00df;", "tokens": ["Er\u00b7ken\u00b7net", "man", ",", "da\u00df", "man", "nichts", "wei\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Gereicht es ja zu GOttes Preis,", "tokens": ["Ge\u00b7reicht", "es", "ja", "zu", "Got\u00b7tes", "Preis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil man bey ihm allein die wahre Wei\u00dfheit findet.", "tokens": ["Weil", "man", "bey", "ihm", "al\u00b7lein", "die", "wah\u00b7re", "Wei\u00df\u00b7heit", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.9": {"text": "Das andre, welches auch in der Erk\u00e4nntni\u00df steckt,", "tokens": ["Das", "and\u00b7re", ",", "wel\u00b7ches", "auch", "in", "der", "Er\u00b7k\u00e4nnt\u00b7ni\u00df", "steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ist, da\u00df, da man der Menschen Schw\u00e4ch\u2019 entdeckt;", "tokens": ["Ist", ",", "da\u00df", ",", "da", "man", "der", "Men\u00b7schen", "Schw\u00e4ch'", "ent\u00b7deckt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "$,", "KOUS", "PIS", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Zur N\u00e4chsten-Lieb\u2019 uns der Begriff verbindet:", "tokens": ["Zur", "N\u00e4chs\u00b7ten\u00b7Lieb'", "uns", "der", "Be\u00b7griff", "ver\u00b7bin\u00b7det", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Denn soll mein N\u00e4chster sich mit meiner Schwachheit plagen;", "tokens": ["Denn", "soll", "mein", "N\u00e4chs\u00b7ter", "sich", "mit", "mei\u00b7ner", "Schwach\u00b7heit", "pla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Warum will ich die seine nicht vertragen?", "tokens": ["Wa\u00b7rum", "will", "ich", "die", "sei\u00b7ne", "nicht", "ver\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "PPOSAT", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}