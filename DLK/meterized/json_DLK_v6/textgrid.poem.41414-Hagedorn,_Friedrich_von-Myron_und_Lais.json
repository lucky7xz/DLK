{"textgrid.poem.41414": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Myron und Lais", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der graue Myron hielt um eine Nacht voll K\u00fcsse", "tokens": ["Der", "grau\u00b7e", "My\u00b7ron", "hielt", "um", "ei\u00b7ne", "Nacht", "voll", "K\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bei der geliebten Lais an;", "tokens": ["Bei", "der", "ge\u00b7lieb\u00b7ten", "Lais", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Doch weil sein Seufzen nichts gewann,", "tokens": ["Doch", "weil", "sein", "Seuf\u00b7zen", "nichts", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Errieth er, da\u00df sein Haar den Abscheu wirken m\u00fcsse.", "tokens": ["Er\u00b7rieth", "er", ",", "da\u00df", "sein", "Haar", "den", "Ab\u00b7scheu", "wir\u00b7ken", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Er schw\u00e4rzet sein bereiftes Haubt.", "tokens": ["Er", "schw\u00e4r\u00b7zet", "sein", "be\u00b7reif\u00b7tes", "Haubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein neuer Myron, nach den Haaren,", "tokens": ["Ein", "neu\u00b7er", "My\u00b7ron", ",", "nach", "den", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht nach der Stirne, nach den Jahren,", "tokens": ["Nicht", "nach", "der", "Stir\u00b7ne", ",", "nach", "den", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sucht, was er schon gesucht; doch wird ihm nichts erlaubt.", "tokens": ["Sucht", ",", "was", "er", "schon", "ge\u00b7sucht", ";", "doch", "wird", "ihm", "nichts", "er\u00b7laubt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWS", "PPER", "ADV", "VVPP", "$.", "ADV", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wie schwer sind Weiber zu betr\u00fcgen!", "tokens": ["Wie", "schwer", "sind", "Wei\u00b7ber", "zu", "be\u00b7tr\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr er Lieb' und List vereint,", "tokens": ["So", "sehr", "er", "Lieb'", "und", "List", "ver\u00b7eint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gleich, so ungleich auch er jenem Myron scheint,", "tokens": ["So", "gleich", ",", "so", "un\u00b7gleich", "auch", "er", "je\u00b7nem", "My\u00b7ron", "scheint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "ADJD", "ADV", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Merkt Lais zweifelnd doch das Alter an den Z\u00fcgen.", "tokens": ["Merkt", "Lais", "zwei\u00b7felnd", "doch", "das", "Al\u00b7ter", "an", "den", "Z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "ADJD", "ADV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Allein, im Zweifel selbst sich schalkhaft zu vergn\u00fcgen,", "tokens": ["Al\u00b7lein", ",", "im", "Zwei\u00b7fel", "selbst", "sich", "schalk\u00b7haft", "zu", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "NN", "ADV", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Spricht sie: mein junger Herr! es bleibt bei dem Entschlu\u00df,", "tokens": ["Spricht", "sie", ":", "mein", "jun\u00b7ger", "Herr", "!", "es", "bleibt", "bei", "dem", "Ent\u00b7schlu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPOSAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dergleichen Bitten zu versagen.", "tokens": ["Derg\u00b7lei\u00b7chen", "Bit\u00b7ten", "zu", "ver\u00b7sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich habe, was ich ihm anjetzt verweigern mu\u00df,", "tokens": ["Ich", "ha\u00b7be", ",", "was", "ich", "ihm", "an\u00b7jetzt", "ver\u00b7wei\u00b7gern", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWS", "PPER", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Schon seinem Vater abgeschlagen.", "tokens": ["Schon", "sei\u00b7nem", "Va\u00b7ter", "ab\u00b7ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}