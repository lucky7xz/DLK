{"dta.poem.11377": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Bey der zu Jena dem Herrn  M. L.  Weis-  \n senborn  conferir ten  Adjunctur.  \n E. G.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr, die ihr in der welt mit wei\u00dfheits-tituln prangt,", "tokens": ["Ihr", ",", "die", "ihr", "in", "der", "welt", "mit", "wei\u00df\u00b7heits\u00b7ti\u00b7tuln", "prangt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "APPR", "ART", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und durch gelehrsamkeit auch bey der nach-welt lebet;", "tokens": ["Und", "durch", "ge\u00b7lehr\u00b7sam\u00b7keit", "auch", "bey", "der", "nach\u00b7welt", "le\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Habt den gepriesnen ruhm zwar mit verdienst erlangt:", "tokens": ["Habt", "den", "ge\u00b7pri\u00b7es\u00b7nen", "ruhm", "zwar", "mit", "ver\u00b7dienst", "er\u00b7langt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ADV", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da\u00df ihr den sterblichen geschickte segeln gebet;", "tokens": ["Da\u00df", "ihr", "den", "sterb\u00b7li\u00b7chen", "ge\u00b7schick\u00b7te", "se\u00b7geln", "ge\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein erz\u00f6rnt euch nicht! Man mu\u00df es doch gestehn:", "tokens": ["Al\u00b7lein", "er\u00b7z\u00f6rnt", "euch", "nicht", "!", "Man", "mu\u00df", "es", "doch", "ge\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$.", "PIS", "VMFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es kan ein spr\u00fcchwort offt zehn b\u00fcchern gleiche gehn;", "tokens": ["Es", "kan", "ein", "spr\u00fcch\u00b7wort", "offt", "zehn", "b\u00fc\u00b7chern", "glei\u00b7che", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADV", "ADV", "CARD", "ADJA", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wenn hat wohl ein spruch von euch so eingetroffen,", "tokens": ["Und", "wenn", "hat", "wohl", "ein", "spruch", "von", "euch", "so", "ein\u00b7ge\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "VAFIN", "ADV", "ART", "NN", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als dieser: Da\u00df die welt in meinungen ersoffen.", "tokens": ["Als", "die\u00b7ser", ":", "Da\u00df", "die", "welt", "in", "mei\u00b7nun\u00b7gen", "er\u00b7sof\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "$.", "KOUS", "ART", "NN", "APPR", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wer bey der sonne nicht mit eulen-augen sieht,", "tokens": ["Wer", "bey", "der", "son\u00b7ne", "nicht", "mit", "eu\u00b7len\u00b7au\u00b7gen", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PTKNEG", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kan dieser w\u00f6rter krafft auch von sich selbst erkennen;", "tokens": ["Kan", "die\u00b7ser", "w\u00f6r\u00b7ter", "krafft", "auch", "von", "sich", "selbst", "er\u00b7ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "ADJA", "NN", "ADV", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wem aber eigensinn der sinnen licht entzieht,", "tokens": ["Wem", "a\u00b7ber", "ei\u00b7gen\u00b7sinn", "der", "sin\u00b7nen", "licht", "ent\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem w\u00fcrde man umsonst geborgte fackeln brennen.", "tokens": ["Dem", "w\u00fcr\u00b7de", "man", "um\u00b7sonst", "ge\u00b7borg\u00b7te", "fa\u00b7ckeln", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "ADV", "VVFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Inde\u00df will ja jemand die wahrheit kl\u00e4rer sehn,", "tokens": ["In\u00b7de\u00df", "will", "ja", "je\u00b7mand", "die", "wahr\u00b7heit", "kl\u00e4\u00b7rer", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PIS", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Und denckt, man wolle nur die welt vergebens schm\u00e4hn:", "tokens": ["Und", "denckt", ",", "man", "wol\u00b7le", "nur", "die", "welt", "ver\u00b7ge\u00b7bens", "schm\u00e4hn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PIS", "VMFIN", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der kan zum \u00fcberflu\u00df auf viel gelehrte schauen,", "tokens": ["Der", "kan", "zum", "\u00fc\u00b7berf\u00b7lu\u00df", "auf", "viel", "ge\u00b7lehr\u00b7te", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPRART", "NN", "APPR", "PIAT", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die th\u00fcrm und schl\u00f6sser offt auf wahn und meinung bauen.", "tokens": ["Die", "th\u00fcrm", "und", "schl\u00f6s\u00b7ser", "offt", "auf", "wahn", "und", "mei\u00b7nung", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "ADV", "APPR", "ADJA", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jtzt langt die dinte nicht, es fehlt papier und zeit,", "tokens": ["Jtzt", "langt", "die", "din\u00b7te", "nicht", ",", "es", "fehlt", "pa\u00b7pier", "und", "zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PPER", "VVFIN", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das alte wespen-nest der meinungen zu st\u00f6ren:", "tokens": ["Das", "al\u00b7te", "wes\u00b7pen\u00b7nest", "der", "mei\u00b7nun\u00b7gen", "zu", "st\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "PPOSS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn deun\u2019 des himmels-glantz kohl-schwartze flocken schneyt:", "tokens": ["Wenn", "deun'", "des", "him\u00b7mels\u00b7glantz", "kohl\u00b7schwart\u00b7ze", "flo\u00b7cken", "schneyt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ART", "NN", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und andre affen gern die g\u00e4nse reden h\u00f6ren:", "tokens": ["Und", "and\u00b7re", "af\u00b7fen", "gern", "die", "g\u00e4n\u00b7se", "re\u00b7den", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ART", "ADJA", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja wenn Democritus bey leid und trauren lacht:", "tokens": ["Ja", "wenn", "De\u00b7mo\u00b7cri\u00b7tus", "bey", "leid", "und", "trau\u00b7ren", "lacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "NE", "APPR", "ADJD", "KON", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Leucipp der erden ball zu einer trommel macht:", "tokens": ["Leu\u00b7cipp", "der", "er\u00b7den", "ball", "zu", "ei\u00b7ner", "trom\u00b7mel", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn der Cleanthes sie will statt der kegel brauchen:", "tokens": ["Wenn", "der", "Clean\u00b7thes", "sie", "will", "statt", "der", "ke\u00b7gel", "brau\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "PPER", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.8": {"text": "Und andre sich den kopff in nasse lusst eintauchen.", "tokens": ["Und", "and\u00b7re", "sich", "den", "kopff", "in", "nas\u00b7se", "lusst", "ein\u00b7tau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Di\u00df alles hat bereits das alterthum verdeckt;", "tokens": ["Di\u00df", "al\u00b7les", "hat", "be\u00b7reits", "das", "al\u00b7ter\u00b7thum", "ver\u00b7deckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein man darff nicht erst in jene zeiten lauffen,", "tokens": ["Al\u00b7lein", "man", "darff", "nicht", "erst", "in", "je\u00b7ne", "zei\u00b7ten", "lauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PTKNEG", "ADV", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil man zu unsrer zeit auch grillen ausgeheckt.", "tokens": ["Weil", "man", "zu", "uns\u00b7rer", "zeit", "auch", "gril\u00b7len", "aus\u00b7ge\u00b7heckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPOSAT", "NN", "ADV", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man kan pedanterie noch aller orten kauffen.", "tokens": ["Man", "kan", "pe\u00b7dan\u00b7te\u00b7rie", "noch", "al\u00b7ler", "or\u00b7ten", "kauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVFIN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie wird die stirne nicht in falten eingelegt,", "tokens": ["Wie", "wird", "die", "stir\u00b7ne", "nicht", "in", "fal\u00b7ten", "ein\u00b7ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "PTKNEG", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn ein ertichtes bild auf das gehirne schl\u00e4gt:", "tokens": ["Wenn", "ein", "er\u00b7tich\u00b7tes", "bild", "auf", "das", "ge\u00b7hir\u00b7ne", "schl\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Es strotzt der wei\u00dfheits-sack, und zieht den kopff zur erden,", "tokens": ["Es", "strotzt", "der", "wei\u00df\u00b7heits\u00b7sack", ",", "und", "zieht", "den", "kopff", "zur", "er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als wolte mancher noch zum karrn-gespane werden.", "tokens": ["Als", "wol\u00b7te", "man\u00b7cher", "noch", "zum", "karrn\u00b7ge\u00b7spa\u00b7ne", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PIS", "ADV", "APPRART", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Darbey hefft man den mund mit hundert klammern an,", "tokens": ["Dar\u00b7bey", "hefft", "man", "den", "mund", "mit", "hun\u00b7dert", "klam\u00b7mern", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ART", "NN", "APPR", "CARD", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie die beschwerer thun, wann sie die geister bannen;", "tokens": ["Wie", "die", "be\u00b7schwe\u00b7rer", "thun", ",", "wann", "sie", "die", "geis\u00b7ter", "ban\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "VVINF", "$,", "PWAV", "PPER", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kommt aber eine zeit, da man nicht schweigen kan,", "tokens": ["Kommt", "a\u00b7ber", "ei\u00b7ne", "zeit", ",", "da", "man", "nicht", "schwei\u00b7gen", "kan", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,", "KOUS", "PIS", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So m\u00f6chte man ein pferd vor jede silbe spannen.", "tokens": ["So", "m\u00f6ch\u00b7te", "man", "ein", "pferd", "vor", "je\u00b7de", "sil\u00b7be", "span\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "NN", "APPR", "PIAT", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer f\u00e4llt nunmehr mit mir nicht auch der meinung bey?", "tokens": ["Wer", "f\u00e4llt", "nun\u00b7mehr", "mit", "mir", "nicht", "auch", "der", "mei\u00b7nung", "bey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "APPR", "PPER", "PTKNEG", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df der Pythagoras noch nicht gestorben sey.", "tokens": ["Da\u00df", "der", "Py\u00b7tha\u00b7go\u00b7ras", "noch", "nicht", "ge\u00b7stor\u00b7ben", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NE", "ADV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Ja wenn gelehrte sich vor aller welt verschliessen:", "tokens": ["Ja", "wenn", "ge\u00b7lehr\u00b7te", "sich", "vor", "al\u00b7ler", "welt", "ver\u00b7schlies\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "ADJA", "PRF", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wird Diogeues auch wohl noch leben m\u00fcssen.", "tokens": ["So", "wird", "Dio\u00b7geu\u00b7es", "auch", "wohl", "noch", "le\u00b7ben", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ADV", "ADV", "ADV", "VVINF", "VMINF", "$."], "meter": "---+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Was bildet mancher sich nicht auf den mantel ein!", "tokens": ["Was", "bil\u00b7det", "man\u00b7cher", "sich", "nicht", "auf", "den", "man\u00b7tel", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "PRF", "PTKNEG", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bald will der kragen sich nicht auf die schulter schmiegen:", "tokens": ["Bald", "will", "der", "kra\u00b7gen", "sich", "nicht", "auf", "die", "schul\u00b7ter", "schmie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "PRF", "PTKNEG", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bald fehlet sonsten was: Da mu\u00df man ernsthafft seyn,", "tokens": ["Bald", "feh\u00b7let", "sons\u00b7ten", "was", ":", "Da", "mu\u00df", "man", "ernst\u00b7hafft", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PWS", "$.", "ADV", "VMFIN", "PIS", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als h\u00e4tte man bereits den freyheits-brief zum l\u00fcgen:", "tokens": ["Als", "h\u00e4t\u00b7te", "man", "be\u00b7reits", "den", "frey\u00b7heits\u00b7brief", "zum", "l\u00fc\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PIS", "ADV", "ART", "NN", "APPRART", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dabey wird auch der bart so trotzig aufgesteckt,", "tokens": ["Da\u00b7bey", "wird", "auch", "der", "bart", "so", "trot\u00b7zig", "auf\u00b7ge\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als h\u00e4tten flederm\u00e4u\u00df\u2019 und ratzen da geheckt.", "tokens": ["Als", "h\u00e4t\u00b7ten", "fle\u00b7der\u00b7m\u00e4u\u00df'", "und", "rat\u00b7zen", "da", "ge\u00b7heckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ADJD", "KON", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn sich gelehrte nun so wunderlich geb\u00e4rden,", "tokens": ["Wenn", "sich", "ge\u00b7lehr\u00b7te", "nun", "so", "wun\u00b7der\u00b7lich", "ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "VVFIN", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was wunder? da\u00df sie denn auch zu pedanten werden.", "tokens": ["Was", "wun\u00b7der", "?", "da\u00df", "sie", "denn", "auch", "zu", "pe\u00b7dan\u00b7ten", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "KOUS", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Allein gemach! gemach! man glaubt es doch wohl nicht;", "tokens": ["Al\u00b7lein", "ge\u00b7mach", "!", "ge\u00b7mach", "!", "man", "glaubt", "es", "doch", "wohl", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "ADV", "$.", "PIS", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die welt ist ja nicht gantz in meinungen ersoffen,", "tokens": ["Die", "welt", "ist", "ja", "nicht", "gantz", "in", "mei\u00b7nun\u00b7gen", "er\u00b7sof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKNEG", "ADV", "APPR", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und die gelehrten sind nicht stets so zugericht;", "tokens": ["Und", "die", "ge\u00b7lehr\u00b7ten", "sind", "nicht", "stets", "so", "zu\u00b7ge\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VAFIN", "PTKNEG", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie werden dann und wann wohl kl\u00fcger angetroffen.", "tokens": ["Sie", "wer\u00b7den", "dann", "und", "wann", "wohl", "kl\u00fc\u00b7ger", "an\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KON", "PWAV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Geehrter Weissenborn! dein wei\u00dfheits-brunn quillt klar,", "tokens": ["Ge\u00b7ehr\u00b7ter", "Weis\u00b7sen\u00b7born", "!", "dein", "wei\u00df\u00b7heits\u00b7brunn", "quillt", "klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPOSAT", "ADJA", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und stellt dein ebenbild gewi\u00df gantz anders dar;", "tokens": ["Und", "stellt", "dein", "e\u00b7ben\u00b7bild", "ge\u00b7wi\u00df", "gantz", "an\u00b7ders", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drum wirst du unbeschwert uns dein exempel g\u00f6nnen,", "tokens": ["Drum", "wirst", "du", "un\u00b7be\u00b7schwert", "uns", "dein", "ex\u00b7em\u00b7pel", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADJD", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Damit wir diesen schimpff recht widerlegen k\u00f6nnen.", "tokens": ["Da\u00b7mit", "wir", "die\u00b7sen", "schimpff", "recht", "wi\u00b7der\u00b7le\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Jhr sp\u00f6tter! die ihr gifft aus honig-blumen zieht,", "tokens": ["Ihr", "sp\u00f6t\u00b7ter", "!", "die", "ihr", "gifft", "aus", "ho\u00b7nig\u00b7blu\u00b7men", "zieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "ART", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jhr werdet hier vor euch nichts zu beschmeissen finden;", "tokens": ["Ihr", "wer\u00b7det", "hier", "vor", "euch", "nichts", "zu", "be\u00b7schmeis\u00b7sen", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "PIS", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier ist gelehrsamkeit mit grillen nicht bem\u00fcht:", "tokens": ["Hier", "ist", "ge\u00b7lehr\u00b7sam\u00b7keit", "mit", "gril\u00b7len", "nicht", "be\u00b7m\u00fcht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "APPR", "VVFIN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es l\u00e4st der muntre geist sich keine meinung binden:", "tokens": ["Es", "l\u00e4st", "der", "mun\u00b7tre", "geist", "sich", "kei\u00b7ne", "mei\u00b7nung", "bin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PRF", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das, was der redner kern in mund und schrifften weist:", "tokens": ["Das", ",", "was", "der", "red\u00b7ner", "kern", "in", "mund", "und", "schriff\u00b7ten", "weist", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "ART", "ADJA", "NN", "APPR", "NN", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das ists, was seinen ruhm schon fernen \u00f6rtern prei\u00dft.", "tokens": ["Das", "ists", ",", "was", "sei\u00b7nen", "ruhm", "schon", "fer\u00b7nen", "\u00f6r\u00b7tern", "prei\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja von den Musen selbst hat man den spruch vernommen:", "tokens": ["Ja", "von", "den", "Mu\u00b7sen", "selbst", "hat", "man", "den", "spruch", "ver\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "APPR", "ART", "NN", "ADV", "VAFIN", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gelehrt, beredt und klug ist hier zusammen kommen.", "tokens": ["Ge\u00b7lehrt", ",", "be\u00b7redt", "und", "klug", "ist", "hier", "zu\u00b7sam\u00b7men", "kom\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "KON", "ADJD", "VAFIN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Di\u00df alles hat der schlu\u00df derjenigen bedacht,", "tokens": ["Di\u00df", "al\u00b7les", "hat", "der", "schlu\u00df", "der\u00b7je\u00b7ni\u00b7gen", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "ART", "NN", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die hier mit grund und krafft den bau der wei\u00dfheit st\u00fctzen:", "tokens": ["Die", "hier", "mit", "grund", "und", "krafft", "den", "bau", "der", "wei\u00df\u00b7heit", "st\u00fct\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "KON", "NN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der deiner klarheit schein noch mehr aus licht gebracht,", "tokens": ["Der", "dei\u00b7ner", "klar\u00b7heit", "schein", "noch", "mehr", "aus", "licht", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "ADV", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nachdem er dich itzt heist an ihre seite sitzen.", "tokens": ["Nach\u00b7dem", "er", "dich", "itzt", "heist", "an", "ih\u00b7re", "sei\u00b7te", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie aber dieses nur der erste anblick ist,", "tokens": ["Wie", "a\u00b7ber", "die\u00b7ses", "nur", "der", "ers\u00b7te", "an\u00b7blick", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PDAT", "ADV", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit welchem dich das gl\u00fcck in unserm Jena gr\u00fc\u00dft;", "tokens": ["Mit", "wel\u00b7chem", "dich", "das", "gl\u00fcck", "in", "un\u00b7serm", "Je\u00b7na", "gr\u00fc\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "NN", "APPR", "PPOSAT", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So schreibt der freunde wunsch mit fr\u00f6lichen geb\u00e4rden:", "tokens": ["So", "schreibt", "der", "freun\u00b7de", "wunsch", "mit", "fr\u00f6\u00b7li\u00b7chen", "ge\u00b7b\u00e4r\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dein sch\u00f6nes ebenbild mu\u00df noch bekannter werden.", "tokens": ["Dein", "sch\u00f6\u00b7nes", "e\u00b7ben\u00b7bild", "mu\u00df", "noch", "be\u00b7kann\u00b7ter", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}