{"textgrid.poem.67847": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "19. Gasul und Lindaraja", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch die Strasse zu Sankt Lucar", "tokens": ["Durch", "die", "Stras\u00b7se", "zu", "Sankt", "Lu\u00b7car"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVFIN", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Kommt heran der tapfre Gasul,", "tokens": ["Kommt", "he\u00b7ran", "der", "tapf\u00b7re", "Ga\u00b7sul", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Pr\u00e4chtig, sch\u00f6ngeschm\u00fcckt in weisser,", "tokens": ["Pr\u00e4ch\u00b7tig", ",", "sch\u00f6n\u00b7ge\u00b7schm\u00fcckt", "in", "weis\u00b7ser", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Violett- und gr\u00fcner Farbe.", "tokens": ["Vi\u00b7o\u00b7let\u00b7t", "und", "gr\u00fc\u00b7ner", "Far\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Muthig will er ab jezt reisen", "tokens": ["Mut\u00b7hig", "will", "er", "ab", "jezt", "rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "PTKVZ", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zum Turnierfest, das in Gelves", "tokens": ["Zum", "Tur\u00b7nier\u00b7fest", ",", "das", "in", "Gel\u00b7ves"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Der Alcaide gibt zur Feier,", "tokens": ["Der", "Al\u00b7cai\u00b7de", "gibt", "zur", "Fei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als ein Friedensfest des Landes.", "tokens": ["Als", "ein", "Frie\u00b7dens\u00b7fest", "des", "Lan\u00b7des", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Er liebt eine Benceraja,", "tokens": ["Er", "liebt", "ei\u00b7ne", "Ben\u00b7ce\u00b7ra\u00b7ja", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Ueberbliebne jener Helden,", "tokens": ["Ue\u00b7ber\u00b7blieb\u00b7ne", "je\u00b7ner", "Hel\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die die Zegris und Gomeles", "tokens": ["Die", "die", "Ze\u00b7gris", "und", "Go\u00b7me\u00b7les"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NE", "KON", "NN"], "meter": "---+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Einst verriethen in Granada.", "tokens": ["Einst", "ver\u00b7rie\u00b7then", "in", "Gra\u00b7na\u00b7da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Sie zum Abschied noch zu sprechen,", "tokens": ["Sie", "zum", "Ab\u00b7schied", "noch", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wendet er wohl tausendmale", "tokens": ["Wen\u00b7det", "er", "wohl", "tau\u00b7send\u00b7ma\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf und ab, dringt mit den Augen", "tokens": ["Auf", "und", "ab", ",", "dringt", "mit", "den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "KON", "PTKVZ", "$,", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Durch die gl\u00fccklichlieben W\u00e4nde.", "tokens": ["Durch", "die", "gl\u00fcck\u00b7lich\u00b7lie\u00b7ben", "W\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Endlich, nach der Jahreslangen", "tokens": ["End\u00b7lich", ",", "nach", "der", "Jah\u00b7res\u00b7lan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stunde seiner raschen Hoffnung,", "tokens": ["Stun\u00b7de", "sei\u00b7ner", "ra\u00b7schen", "Hoff\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tritt hervor sie auf den Balcon,", "tokens": ["Tritt", "her\u00b7vor", "sie", "auf", "den", "Bal\u00b7con", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seine lange Stunde k\u00fcrzend.", "tokens": ["Sei\u00b7ne", "lan\u00b7ge", "Stun\u00b7de", "k\u00fcr\u00b7zend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Er h\u00e4lt an sein Ro\u00df, und l\u00e4st es,", "tokens": ["Er", "h\u00e4lt", "an", "sein", "Ro\u00df", ",", "und", "l\u00e4st", "es", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da ihm aufgeht seine Sonne,", "tokens": ["Da", "ihm", "auf\u00b7geht", "sei\u00b7ne", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Niederknien in seinem Namen,", "tokens": ["Nie\u00b7der\u00b7kni\u00b7en", "in", "sei\u00b7nem", "Na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Und vor ihr die Erde k\u00fcssen.", "tokens": ["Und", "vor", "ihr", "die", "Er\u00b7de", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Mit gest\u00f6rter Stimme spricht er:", "tokens": ["Mit", "ge\u00b7st\u00f6r\u00b7ter", "Stim\u00b7me", "spricht", "er", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbsch\u00f6nste, nun kann meiner Reise", "tokens": ["\u00bb", "sch\u00f6ns\u00b7te", ",", "nun", "kann", "mei\u00b7ner", "Rei\u00b7se"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "ADV", "VMFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Trauriges auch nichts begegnen,", "tokens": ["Trau\u00b7ri\u00b7ges", "auch", "nichts", "be\u00b7geg\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ich deinen s\u00fcssen Blick seh.", "tokens": ["Da", "ich", "dei\u00b7nen", "s\u00fcs\u00b7sen", "Blick", "seh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Pflichten nur und Anverwandte", "tokens": ["Pflich\u00b7ten", "nur", "und", "An\u00b7ver\u00b7wand\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ziehn dorthin mich, ohne Seele.", "tokens": ["Ziehn", "dor\u00b7thin", "mich", ",", "oh\u00b7ne", "See\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "$,", "KOUI", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Andenken bleibt zur\u00fcck dir,", "tokens": ["Mein", "An\u00b7den\u00b7ken", "bleibt", "zu\u00b7r\u00fcck", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob du auch an mich noch denkest?", "tokens": ["Ob", "du", "auch", "an", "mich", "noch", "den\u00b7kest", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sch\u00f6nste, gib mir denn ein Denkmaal,", "tokens": ["Sch\u00f6ns\u00b7te", ",", "gib", "mir", "denn", "ein", "Denk\u00b7maal", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht, da\u00df es mich dein erinnre,", "tokens": ["Nicht", ",", "da\u00df", "es", "mich", "dein", "e\u00b7rinn\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "$,", "KOUS", "PPER", "PRF", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur, da\u00df es mit dir mich schm\u00fccke,", "tokens": ["Nur", ",", "da\u00df", "es", "mit", "dir", "mich", "schm\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPR", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00fcze, leit' und mache muthig.\u00ab", "tokens": ["Sch\u00fc\u00b7ze", ",", "leit'", "und", "ma\u00b7che", "mut\u00b7hig", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "KON", "VVFIN", "ADJD", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Aber Lindaraja brennet,", "tokens": ["A\u00b7ber", "Lind\u00b7a\u00b7ra\u00b7ja", "bren\u00b7net", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eifers\u00fcchtig bis zum Tode,", "tokens": ["Ei\u00b7fer\u00b7s\u00fcch\u00b7tig", "bis", "zum", "To\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df in Geres eine Zaida,", "tokens": ["Da\u00df", "in", "Ge\u00b7res", "ei\u00b7ne", "Zai\u00b7da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Neben ihr sie Gasul liebe.", "tokens": ["Ne\u00b7ben", "ihr", "sie", "Ga\u00b7sul", "lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "PPER", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Da\u00df er in den Tod sie liebe,", "tokens": ["Da\u00df", "er", "in", "den", "Tod", "sie", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat erfahren Lindaraja,", "tokens": ["Hat", "er\u00b7fah\u00b7ren", "Lind\u00b7a\u00b7ra\u00b7ja", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und antwortet Gasul also:", "tokens": ["Und", "ant\u00b7wor\u00b7tet", "Ga\u00b7sul", "al\u00b7so", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.12": {"line.1": {"text": "\u00bbwenn sichs im Turnier jezt f\u00fcget,", "tokens": ["\u00bb", "wenn", "sichs", "im", "Tur\u00b7nier", "jezt", "f\u00fc\u00b7get", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "APPRART", "NN", "ADV", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Wie es meine Brust dir w\u00fcnschet", "tokens": ["Wie", "es", "mei\u00b7ne", "Brust", "dir", "w\u00fcn\u00b7schet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die deine es verdienet,", "tokens": ["Und", "die", "dei\u00b7ne", "es", "ver\u00b7die\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So wirst du, so stolz wie immer,", "tokens": ["So", "wirst", "du", ",", "so", "stolz", "wie", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "ADV", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Nach Lucar nicht wiederkehren,", "tokens": ["Nach", "Lu\u00b7car", "nicht", "wie\u00b7der\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht vor Augen, die dich lieben,", "tokens": ["Nicht", "vor", "Au\u00b7gen", ",", "die", "dich", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Noch vor Augen, die dich abscheun.", "tokens": ["Noch", "vor", "Au\u00b7gen", ",", "die", "dich", "ab\u00b7scheun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "PRELS", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ja gefalls dem grossen Alla,", "tokens": ["Ja", "ge\u00b7falls", "dem", "gros\u00b7sen", "Al\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Da\u00df im Spiele deine Feinde", "tokens": ["Da\u00df", "im", "Spie\u00b7le", "dei\u00b7ne", "Fein\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf dich ziehn geheime Lanzen,", "tokens": ["Auf", "dich", "ziehn", "ge\u00b7hei\u00b7me", "Lan\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und du fallest, wie du l\u00fcgest;", "tokens": ["Und", "du", "fal\u00b7lest", ",", "wie", "du", "l\u00fc\u00b7gest", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Und da\u00df, unterm Oberkleide,", "tokens": ["Und", "da\u00df", ",", "un\u00b7term", "O\u00b7berk\u00b7lei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Panzerhemde sie besch\u00fczen,", "tokens": ["Pan\u00b7zer\u00b7hem\u00b7de", "sie", "be\u00b7sch\u00fc\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df, wenn du nach Rache d\u00fcrstest,", "tokens": ["Da\u00df", ",", "wenn", "du", "nach", "Ra\u00b7che", "d\u00fcrs\u00b7test", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Du sie suchst und doch nicht findest,", "tokens": ["Du", "sie", "suchst", "und", "doch", "nicht", "fin\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVFIN", "KON", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Deine Freunde dich verlassen,", "tokens": ["Dei\u00b7ne", "Freun\u00b7de", "dich", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deine Feinde dich zertreten,", "tokens": ["Dei\u00b7ne", "Fein\u00b7de", "dich", "zer\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du auf ihren Schultern ausgehst,", "tokens": ["Du", "auf", "ih\u00b7ren", "Schul\u00b7tern", "aus\u00b7gehst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wie du f\u00fcr die Dame eintratst.", "tokens": ["Wie", "du", "f\u00fcr", "die", "Da\u00b7me", "ein\u00b7tratst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.16": {"line.1": {"text": "Und da\u00df, statt dich zu beweinen,", "tokens": ["Und", "da\u00df", ",", "statt", "dich", "zu", "be\u00b7wei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die du liebst und die du t\u00e4uschest,", "tokens": ["Die", "du", "liebst", "und", "die", "du", "t\u00e4u\u00b7schest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "KON", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Beide dir mit Fl\u00fcchen beistehn,", "tokens": ["Bei\u00b7de", "dir", "mit", "Fl\u00fc\u00b7chen", "bei\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und sich freuen deines Todes.\u00ab", "tokens": ["Und", "sich", "freu\u00b7en", "dei\u00b7nes", "To\u00b7des", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PRF", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Gasul meinet, da\u00df sie scherze,", "tokens": ["Ga\u00b7sul", "mei\u00b7net", ",", "da\u00df", "sie", "scher\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "(wie die Unschuld pflegt zu meinen)", "tokens": ["(", "wie", "die", "Un\u00b7schuld", "pflegt", "zu", "mei\u00b7nen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hebt empor sich in den B\u00fcgeln,", "tokens": ["Hebt", "em\u00b7por", "sich", "in", "den", "B\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre sch\u00f6ne Hand zu langen.", "tokens": ["Ih\u00b7re", "sch\u00f6\u00b7ne", "Hand", "zu", "lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "\u00bbl\u00fcgner, o Sennora, spricht er,", "tokens": ["\u00bb", "l\u00fcg\u00b7ner", ",", "o", "Sen\u00b7no\u00b7ra", ",", "spricht", "er", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "FM", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist der Mohr, der mich verl\u00e4umdet,", "tokens": ["Ist", "der", "Mohr", ",", "der", "mich", "ver\u00b7l\u00e4um\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auf ihn alle diese Fl\u00fcche,", "tokens": ["Auf", "ihn", "al\u00b7le", "die\u00b7se", "Fl\u00fc\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihn zu lohnen, mich zu r\u00e4chen!", "tokens": ["Ihn", "zu", "loh\u00b7nen", ",", "mich", "zu", "r\u00e4\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Meine Seele hasset Zaida,", "tokens": ["Mei\u00b7ne", "See\u00b7le", "has\u00b7set", "Zai\u00b7da", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reuig, da\u00df ich je sie liebte;", "tokens": ["Reu\u00b7ig", ",", "da\u00df", "ich", "je", "sie", "lieb\u00b7te", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fluch auf alle jene Jahre!", "tokens": ["Fluch", "auf", "al\u00b7le", "je\u00b7ne", "Jah\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ich ihr (mein Ungl\u00fcck!) diente.", "tokens": ["Da", "ich", "ihr", "(", "mein", "Un\u00b7gl\u00fcck", "!", ")", "dien\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "$(", "PPOSAT", "NN", "$.", "$(", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Sie hat mich um einen Mohren,", "tokens": ["Sie", "hat", "mich", "um", "ei\u00b7nen", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Reich an armem Gut, verlassen.\u00ab \u2013", "tokens": ["Reich", "an", "ar\u00b7mem", "Gut", ",", "ver\u00b7las\u00b7sen", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,", "VVPP", "$.", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da das Lindaraja h\u00f6ret,", "tokens": ["Da", "das", "Lind\u00b7a\u00b7ra\u00b7ja", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kann sie es nicht l\u00e4nger ausstehn,", "tokens": ["Kann", "sie", "es", "nicht", "l\u00e4n\u00b7ger", "aus\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.21": {"line.1": {"text": "Und in selbem Augenblicke", "tokens": ["Und", "in", "sel\u00b7bem", "Au\u00b7gen\u00b7bli\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommt der Page mit den Rossen,", "tokens": ["Kommt", "der", "Pa\u00b7ge", "mit", "den", "Ros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fchret sie, geschm\u00fcckt mit Federn", "tokens": ["F\u00fch\u00b7ret", "sie", ",", "ge\u00b7schm\u00fcckt", "mit", "Fe\u00b7dern"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVPP", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit anderm Schmuck des Festes;", "tokens": ["Und", "mit", "an\u00b7derm", "Schmuck", "des", "Fes\u00b7tes", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Aber Gasul fa\u00dft die Lanze,", "tokens": ["A\u00b7ber", "Ga\u00b7sul", "fa\u00dft", "die", "Lan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fasset sie mit starker Rechte,", "tokens": ["Fas\u00b7set", "sie", "mit", "star\u00b7ker", "Rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Splittert sie in tausend St\u00fccke", "tokens": ["Split\u00b7tert", "sie", "in", "tau\u00b7send", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gegen die geliebten W\u00e4nde.", "tokens": ["Ge\u00b7gen", "die", "ge\u00b7lieb\u00b7ten", "W\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Und befiehlt, da\u00df seinen Rossen", "tokens": ["Und", "be\u00b7fiehlt", ",", "da\u00df", "sei\u00b7nen", "Ros\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleich der Schmuck gewechselt werde,", "tokens": ["Gleich", "der", "Schmuck", "ge\u00b7wech\u00b7selt", "wer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Statt der gr\u00fcnen Federn falbe,", "tokens": ["Statt", "der", "gr\u00fc\u00b7nen", "Fe\u00b7dern", "fal\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Falb hineinzuziehn nach Gelves.", "tokens": ["Falb", "hin\u00b7ein\u00b7zu\u00b7ziehn", "nach", "Gel\u00b7ves", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}