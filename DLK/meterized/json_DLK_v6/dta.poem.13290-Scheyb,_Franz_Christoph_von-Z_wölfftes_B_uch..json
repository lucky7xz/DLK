{"dta.poem.13290": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "Z w\u00f6lfftes  B uch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jmmittelst wandt er sich nach einem andern Ort;", "tokens": ["Jm\u00b7mit\u00b7telst", "wandt", "er", "sich", "nach", "ei\u00b7nem", "an\u00b7dern", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da wies er wiederum ein Bild und sprach kein Wort.", "tokens": ["Da", "wies", "er", "wie\u00b7de\u00b7rum", "ein", "Bild", "und", "sprach", "kein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "75Ein Kriegs-Heer, welches hin und her und ruckw\u00e4rts streifte,", "tokens": ["Kriegs\u00b7Heer", ",", "wel\u00b7ches", "hin", "und", "her", "und", "ruck\u00b7w\u00e4rts", "streif\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "KON", "PTKVZ", "KON", "ADV", "VVFIN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Hier auseinander lief, dort sich f\u00fcr Schrecken h\u00e4ufte,", "tokens": ["Hier", "aus\u00b7ein\u00b7an\u00b7der", "lief", ",", "dort", "sich", "f\u00fcr", "Schre\u00b7cken", "h\u00e4uf\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "$,", "ADV", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von einem Helden-Schwarm verfolgt, sich immer bog,", "tokens": ["Von", "ei\u00b7nem", "Hel\u00b7den\u00b7Schwarm", "ver\u00b7folgt", ",", "sich", "im\u00b7mer", "bog", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$,", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald vorw\u00e4rts, bald zur\u00fcck, bald nach der Seite zog,", "tokens": ["Bald", "vor\u00b7w\u00e4rts", ",", "bald", "zu\u00b7r\u00fcck", ",", "bald", "nach", "der", "Sei\u00b7te", "zog", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "ADV", "PTKVZ", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verjagten Hirschen gleich an keinem Ort verweilte,", "tokens": ["Ver\u00b7jag\u00b7ten", "Hir\u00b7schen", "gleich", "an", "kei\u00b7nem", "Ort", "ver\u00b7weil\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "80Nur einem Ufer nach, zu sichern Br\u00fccken eilte,", "tokens": ["ei\u00b7nem", "U\u00b7fer", "nach", ",", "zu", "si\u00b7chern", "Br\u00fc\u00b7cken", "eil\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "War, was ich in dem Bild gemahlt, doch lebhaft sah;", "tokens": ["War", ",", "was", "ich", "in", "dem", "Bild", "ge\u00b7mahlt", ",", "doch", "leb\u00b7haft", "sah", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWS", "PPER", "APPR", "ART", "NN", "VVPP", "$,", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Allein ich wu\u00dfte nicht, warum die Flucht geschah.", "tokens": ["Al\u00b7lein", "ich", "wu\u00df\u00b7te", "nicht", ",", "wa\u00b7rum", "die", "Flucht", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wir giengen weiter fort; ich mu\u00dft\u2019 ihn stets begleiten;", "tokens": ["Wir", "gien\u00b7gen", "wei\u00b7ter", "fort", ";", "ich", "mu\u00dft'", "ihn", "stets", "be\u00b7glei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was werden, dacht\u2019 ich oft, die St\u00fccke dann bedeuten?", "tokens": ["Was", "wer\u00b7den", ",", "dacht'", "ich", "oft", ",", "die", "St\u00fc\u00b7cke", "dann", "be\u00b7deu\u00b7ten", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAINF", "$,", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "85Nun blieb er stehn und wies n\u00e4chst an dem K\u00f6nigs-Thron", "tokens": ["blieb", "er", "stehn", "und", "wies", "n\u00e4chst", "an", "dem", "K\u00f6\u00b7nigs\u00b7Thron"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVINF", "KON", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.14": {"text": "Ein ausgeschniztes Bild, das mehr als eine Kron", "tokens": ["Ein", "aus\u00b7ge\u00b7schniz\u00b7tes", "Bild", ",", "das", "mehr", "als", "ei\u00b7ne", "Kron"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PIS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mit Zepter, Helm und Schild, mit Lorber-Reisern schm\u00fcckte.", "tokens": ["Mit", "Zep\u00b7ter", ",", "Helm", "und", "Schild", ",", "mit", "Lor\u00b7ber\u00b7Rei\u00b7sern", "schm\u00fcck\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Als ich dasselbige nur erst von fern erblickte", "tokens": ["Als", "ich", "das\u00b7sel\u00b7bi\u00b7ge", "nur", "erst", "von", "fern", "er\u00b7blick\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "ADV", "ADV", "APPR", "ADJD", "VVFIN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "So sprach ich schon: das ist ja jenes Prinzen-Paar,", "tokens": ["So", "sprach", "ich", "schon", ":", "das", "ist", "ja", "je\u00b7nes", "Prin\u00b7zen\u00b7Paar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$.", "PDS", "VAFIN", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "90Das mit der K\u00f6niginn im Saal anwesend war.", "tokens": ["mit", "der", "K\u00f6\u00b7ni\u00b7ginn", "im", "Saal", "an\u00b7we\u00b7send", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.19": {"text": "Sie schienen Zwillinge, die sich mit Lieb umfangen.", "tokens": ["Sie", "schie\u00b7nen", "Zwil\u00b7lin\u00b7ge", ",", "die", "sich", "mit", "Lieb", "um\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Thalia nezte fast f\u00fcr Anmuth Aug und Wangen.", "tokens": ["Tha\u00b7lia", "nez\u00b7te", "fast", "f\u00fcr", "An\u00b7muth", "Aug", "und", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "NN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.21": {"text": "\u201ewelch unermessner Schaz! O Nachwelt freue dich!\u201e", "tokens": ["\u201e", "welch", "un\u00b7er\u00b7mess\u00b7ner", "Schaz", "!", "O", "Nach\u00b7welt", "freu\u00b7e", "dich", "!", "\u201e"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAT", "ADJA", "NN", "$.", "NE", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Sprach sie, man kennet schon, wie sie sich br\u00fcderlich", "tokens": ["Sprach", "sie", ",", "man", "ken\u00b7net", "schon", ",", "wie", "sie", "sich", "br\u00fc\u00b7der\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "PIS", "VVFIN", "ADV", "$,", "PWAV", "PPER", "PRF", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "95\u201dMit Liebe, Rath und That und Treu verbinden werden;", "tokens": ["\"", "Mit", "Lie\u00b7be", ",", "Rath", "und", "That", "und", "Treu", "ver\u00b7bin\u00b7den", "wer\u00b7den", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u201eder Eine dienet schon dem Andern zum Gef\u00e4rten.", "tokens": ["\u201e", "der", "Ei\u00b7ne", "die\u00b7net", "schon", "dem", "An\u00b7dern", "zum", "Ge\u00b7f\u00e4r\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}