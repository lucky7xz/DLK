{"textgrid.poem.64149": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Des Sultans Gesetz", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbdieses geht nicht!\u00ab sprach in Joppe", "tokens": ["\u00bb", "die\u00b7ses", "geht", "nicht", "!", "\u00ab", "sprach", "in", "Jop\u00b7pe"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "PTKNEG", "$.", "$(", "VVFIN", "APPR", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sultan Selim, der vor kurzem", "tokens": ["Sul\u00b7tan", "Se\u00b7lim", ",", "der", "vor", "kur\u00b7zem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "APPR", "ADJA"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Abgeschlossen auf drei Jahre", "tokens": ["Ab\u00b7ge\u00b7schlos\u00b7sen", "auf", "drei", "Jah\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Waffenstillstand mit den Christen", "tokens": ["Waf\u00b7fen\u00b7still\u00b7stand", "mit", "den", "Chris\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dr\u00fcben in Jerusalem.", "tokens": ["Dr\u00fc\u00b7ben", "in", "Je\u00b7ru\u00b7sa\u00b7lem", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "\u00bbdieses geht nicht, da\u00df die kecken", "tokens": ["\u00bb", "die\u00b7ses", "geht", "nicht", ",", "da\u00df", "die", "ke\u00b7cken"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "PTKNEG", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tempelritter, diese Schlingel,", "tokens": ["Tem\u00b7pel\u00b7rit\u00b7ter", ",", "die\u00b7se", "Schlin\u00b7gel", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tag f\u00fcr Tag gen Joppe reiten", "tokens": ["Tag", "f\u00fcr", "Tag", "gen", "Jop\u00b7pe", "rei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "APPR", "NE", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mir meiner sch\u00f6nsten T\u00fcrken-", "tokens": ["Und", "mir", "mei\u00b7ner", "sch\u00f6ns\u00b7ten", "T\u00fcr\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PPOSAT", "ADJA", "TRUNC"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "M\u00e4dchen Herzen schnappen weg.", "tokens": ["M\u00e4d\u00b7chen", "Her\u00b7zen", "schnap\u00b7pen", "weg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Weil nun solches Herzgeschappen", "tokens": ["Weil", "nun", "sol\u00b7ches", "Herz\u00b7ge\u00b7schap\u00b7pen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Anhebt meist mit Schleierl\u00fcften,", "tokens": ["An\u00b7hebt", "meist", "mit", "Schlei\u00b7er\u00b7l\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So befehl ich: jeden Templer,", "tokens": ["So", "be\u00b7fehl", "ich", ":", "je\u00b7den", "Temp\u00b7ler", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "$.", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welcher eines T\u00fcrkenm\u00e4dchens", "tokens": ["Wel\u00b7cher", "ei\u00b7nes", "T\u00fcr\u00b7ken\u00b7m\u00e4d\u00b7chens"], "token_info": ["word", "word", "word"], "pos": ["PWAT", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Schleier l\u00fcftet, trifft der Tod:", "tokens": ["Schlei\u00b7er", "l\u00fcf\u00b7tet", ",", "trifft", "der", "Tod", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wenn sie nicht statt dessen vorzieht,", "tokens": ["Wenn", "sie", "nicht", "statt", "des\u00b7sen", "vor\u00b7zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "PDS", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nach der Wahl des M\u00e4dchens selber,", "tokens": ["Nach", "der", "Wahl", "des", "M\u00e4d\u00b7chens", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df den frechen \u00dcbelt\u00e4ter", "tokens": ["Da\u00df", "den", "fre\u00b7chen", "\u00dc\u00b7belt\u00b7\u00e4\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Augenblicklich von dem Vater", "tokens": ["Au\u00b7gen\u00b7blick\u00b7lich", "von", "dem", "Va\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie empf\u00e4ngt zum Eh'gemahl.\u00ab", "tokens": ["Sie", "emp\u00b7f\u00e4ngt", "zum", "Eh'\u00b7ge\u00b7mahl", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Dies Gesetz schuf z\u00fcrnend Selim. \u2013", "tokens": ["Dies", "Ge\u00b7setz", "schuf", "z\u00fcr\u00b7nend", "Se\u00b7lim", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "NN", "VVFIN", "ADJD", "NE", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Solches hatte kaum vernommen", "tokens": ["Sol\u00b7ches", "hat\u00b7te", "kaum", "ver\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In Jerusalem Herr Reinhart,", "tokens": ["In", "Je\u00b7ru\u00b7sa\u00b7lem", "Herr", "Rein\u00b7hart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch ein frommer Tempelritter,", "tokens": ["Auch", "ein", "from\u00b7mer", "Tem\u00b7pel\u00b7rit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als er stracks gen Joppe ritt.", "tokens": ["Als", "er", "stracks", "gen", "Jop\u00b7pe", "ritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Fest in seinen langen, wei\u00dfen", "tokens": ["Fest", "in", "sei\u00b7nen", "lan\u00b7gen", ",", "wei\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mantel eingeh\u00fcllt durchschritt er", "tokens": ["Man\u00b7tel", "ein\u00b7ge\u00b7h\u00fcllt", "durch\u00b7schritt", "er"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVPP", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Joppes Stra\u00dfen: herrlich schritt er:", "tokens": ["Jop\u00b7pes", "Stra\u00b7\u00dfen", ":", "herr\u00b7lich", "schritt", "er", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADJD", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tausend T\u00fcrkent\u00f6chter seufzten", "tokens": ["Tau\u00b7send", "T\u00fcr\u00b7ken\u00b7t\u00f6ch\u00b7ter", "seufz\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Durch die L\u00e4den: \u00bbWelch' ein Mann.\u00ab", "tokens": ["Durch", "die", "L\u00e4\u00b7den", ":", "\u00bb", "Welch'", "ein", "Mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$(", "PIAT", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sieh, da wandeln ihm entgegen,", "tokens": ["Sieh", ",", "da", "wan\u00b7deln", "ihm", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tief verh\u00fcllt, zwei T\u00fcrkenm\u00e4dchen:", "tokens": ["Tief", "ver\u00b7h\u00fcllt", ",", "zwei", "T\u00fcr\u00b7ken\u00b7m\u00e4d\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der ungezogne Templer", "tokens": ["Und", "der", "un\u00b7ge\u00b7zog\u00b7ne", "Temp\u00b7ler"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hebt sofort der einen Schleier", "tokens": ["Hebt", "so\u00b7fort", "der", "ei\u00b7nen", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und er ruft: \u00bbSch\u00f6n! Wahrlich, sch\u00f6n!\u00ab", "tokens": ["Und", "er", "ruft", ":", "\u00bb", "Sch\u00f6n", "!", "Wahr\u00b7lich", ",", "sch\u00f6n", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "NE", "$.", "ADV", "$,", "ADJD", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und er zieht sogleich der zweiten", "tokens": ["Und", "er", "zieht", "sog\u00b7leich", "der", "zwei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von dem Antlitz auch den Schleier:", "tokens": ["Von", "dem", "Ant\u00b7litz", "auch", "den", "Schlei\u00b7er", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbtausend Tode will ich sterben\u00ab,", "tokens": ["\u00bb", "tau\u00b7send", "To\u00b7de", "will", "ich", "ster\u00b7ben", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "NN", "VMFIN", "PPER", "VVINF", "$(", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruft er, \u00bbsch\u00f6nstes Weib der Erde \u2013", "tokens": ["Ruft", "er", ",", "\u00bb", "sch\u00f6ns\u00b7tes", "Weib", "der", "Er\u00b7de", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "ADJA", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber einmal k\u00fc\u00df' ich dich.\u00ab", "tokens": ["A\u00b7ber", "ein\u00b7mal", "k\u00fc\u00df'", "ich", "dich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Und er k\u00fc\u00dft sie. \u2013 Und nat\u00fcrlich", "tokens": ["Und", "er", "k\u00fc\u00dft", "sie", ".", "\u2013", "Und", "na\u00b7t\u00fcr\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$.", "$(", "KON", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wird sofort er arretiert auch", "tokens": ["Wird", "so\u00b7fort", "er", "ar\u00b7re\u00b7tiert", "auch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPER", "VVFIN", "ADV"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Von den t\u00fcrkischen Gendarmen \u2013", "tokens": ["Von", "den", "t\u00fcr\u00b7ki\u00b7schen", "Gen\u00b7dar\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das fromme Joppe jubelt:", "tokens": ["Und", "das", "from\u00b7me", "Jop\u00b7pe", "ju\u00b7belt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bbdiesem wird's mal schlecht ergehn!", "tokens": ["\u00bb", "die\u00b7sem", "wird's", "mal", "schlecht", "er\u00b7gehn", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Denn die braven T\u00fcrkenm\u00e4dchen,", "tokens": ["Denn", "die", "bra\u00b7ven", "T\u00fcr\u00b7ken\u00b7m\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die so t\u00f6dlich er gekr\u00e4nkt hat,", "tokens": ["Die", "so", "t\u00f6d\u00b7lich", "er", "ge\u00b7kr\u00e4nkt", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PPER", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Waren \u2013 also m\u00f6g' es jedem", "tokens": ["Wa\u00b7ren", "\u2013", "al\u00b7so", "m\u00f6g'", "es", "je\u00b7dem"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "$(", "ADV", "VMFIN", "PPER", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kecken Schleierl\u00fcfter werden \u2013", "tokens": ["Ke\u00b7cken", "Schlei\u00b7er\u00b7l\u00fcf\u00b7ter", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VAINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sultan Selims T\u00f6chter selbst!\u00ab \u2013", "tokens": ["Sul\u00b7tan", "Se\u00b7lims", "T\u00f6ch\u00b7ter", "selbst", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "NE", "NN", "ADV", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Vor dem Sultan stand der Ritter:", "tokens": ["Vor", "dem", "Sul\u00b7tan", "stand", "der", "Rit\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es sprach die eine Tochter", "tokens": ["Und", "es", "sprach", "die", "ei\u00b7ne", "Toch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u2013 Schwarze Brau'n zog sie zusammen", "tokens": ["\u2013", "Schwar\u00b7ze", "Brau'n", "zog", "sie", "zu\u00b7sam\u00b7men"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und es war die \u00e4lt're Tochter,", "tokens": ["Und", "es", "war", "die", "\u00e4lt'\u00b7re", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Die der Frevler ", "tokens": ["Die", "der", "Frev\u00b7ler"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}}, "stanza.12": {"line.1": {"text": "\u00bbvater, Todes soll er sterben", "tokens": ["\u00bb", "va\u00b7ter", ",", "To\u00b7des", "soll", "er", "ster\u00b7ben"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "$,", "NN", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nach dem ersten Paragraphen", "tokens": ["Nach", "dem", "ers\u00b7ten", "Pa\u00b7ra\u00b7gra\u00b7phen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Deiner Satzung: \u2013 ich verlang' es!\u00ab", "tokens": ["Dei\u00b7ner", "Sat\u00b7zung", ":", "\u2013", "ich", "ver\u00b7lang'", "es", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$.", "$(", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Sultan, turbannickend,", "tokens": ["Und", "der", "Sul\u00b7tan", ",", "tur\u00b7ban\u00b7ni\u00b7ckend", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprach: \u00bbGestrenge Tochter, ja!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Ge\u00b7stren\u00b7ge", "Toch\u00b7ter", ",", "ja", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "NN", "NN", "$,", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Doch da sprach die j\u00fcng're Tochter,", "tokens": ["Doch", "da", "sprach", "die", "j\u00fcng'\u00b7re", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u2013 Blondgelockt, sie, die er k\u00fc\u00dfte: \u2013", "tokens": ["\u2013", "Blond\u00b7ge\u00b7lockt", ",", "sie", ",", "die", "er", "k\u00fc\u00df\u00b7te", ":", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "PPER", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bblieber Vater, ich verlange", "tokens": ["\u00bb", "lie\u00b7ber", "Va\u00b7ter", ",", "ich", "ver\u00b7lan\u00b7ge"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ADV", "NN", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Diesen jungen Staatsverbrecher", "tokens": ["Die\u00b7sen", "jun\u00b7gen", "Staats\u00b7ver\u00b7bre\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Nach Gesetz zum Eh'gemahl.", "tokens": ["Nach", "Ge\u00b7setz", "zum", "Eh'\u00b7ge\u00b7mahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Denn ich bin ein T\u00fcrkenm\u00e4dchen", "tokens": ["Denn", "ich", "bin", "ein", "T\u00fcr\u00b7ken\u00b7m\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ein Templer ist der Ritter", "tokens": ["Und", "ein", "Temp\u00b7ler", "ist", "der", "Rit\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er hat \u2013 ich kann's beweisen \u2013", "tokens": ["Und", "er", "hat", "\u2013", "ich", "kann's", "be\u00b7wei\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$(", "PPER", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meinen Schleier hoch gel\u00fcftet", "tokens": ["Mei\u00b7nen", "Schlei\u00b7er", "hoch", "ge\u00b7l\u00fcf\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und dein zweiter Paragraph\u00ab \u2013", "tokens": ["Und", "dein", "zwei\u00b7ter", "Pa\u00b7ra\u00b7gra\u00b7ph", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$(", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "\u00bbschweig und nimm ihn!\u00ab sprach der Sultan,", "tokens": ["\u00bb", "schweig", "und", "nimm", "ihn", "!", "\u00ab", "sprach", "der", "Sul\u00b7tan", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "KON", "VVIMP", "PPER", "$.", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "\u00bbschwierig ist's, Gesetze machen,", "tokens": ["\u00bb", "schwie\u00b7rig", "ist's", ",", "Ge\u00b7set\u00b7ze", "ma\u00b7chen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schwerer noch ist's, M\u00e4dchen h\u00fcten: \u2013", "tokens": ["Schwe\u00b7rer", "noch", "ist's", ",", "M\u00e4d\u00b7chen", "h\u00fc\u00b7ten", ":", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "VAFIN", "$,", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00fcss' mich, Goldgelock, mein Liebling,", "tokens": ["K\u00fcss'", "mich", ",", "Gold\u00b7ge\u00b7lock", ",", "mein", "Lieb\u00b7ling", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Heute noch soll Hochzeit sein.\u00ab", "tokens": ["Heu\u00b7te", "noch", "soll", "Hoch\u00b7zeit", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}