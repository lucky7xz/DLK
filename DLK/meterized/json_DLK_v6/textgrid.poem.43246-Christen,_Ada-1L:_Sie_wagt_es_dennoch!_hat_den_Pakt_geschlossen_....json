{"textgrid.poem.43246": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sie wagt es dennoch! hat den Pakt geschlossen ...", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie wagt es dennoch! hat den Pakt geschlossen ...", "tokens": ["Sie", "wagt", "es", "den\u00b7noch", "!", "hat", "den", "Pakt", "ge\u00b7schlos\u00b7sen", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich lie\u00df sie keine grimmen Eide schw\u00f6ren,", "tokens": ["Ich", "lie\u00df", "sie", "kei\u00b7ne", "grim\u00b7men", "Ei\u00b7de", "schw\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das alte Lied nur will ich manchmal h\u00f6ren", "tokens": ["Das", "al\u00b7te", "Lied", "nur", "will", "ich", "manch\u00b7mal", "h\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und neue k\u00fcmmerliche Weiberglossen.", "tokens": ["Und", "neu\u00b7e", "k\u00fcm\u00b7mer\u00b7li\u00b7che", "Wei\u00b7berg\u00b7los\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Will h\u00f6ren, was ihr Welt und Menschen galten;", "tokens": ["Will", "h\u00f6\u00b7ren", ",", "was", "ihr", "Welt", "und", "Men\u00b7schen", "gal\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PRELS", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Will sehen, wie in guterfundnen Z\u00fcgen", "tokens": ["Will", "se\u00b7hen", ",", "wie", "in", "gut\u00b7er\u00b7fund\u00b7nen", "Z\u00fc\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Als Wahrheit wiederspiegeln sich die L\u00fcgen,", "tokens": ["Als", "Wahr\u00b7heit", "wie\u00b7der\u00b7spie\u00b7geln", "sich", "die", "L\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die ihr Gehirnlein rasch wei\u00df zu gestalten.", "tokens": ["Die", "ihr", "Ge\u00b7hirn\u00b7lein", "rasch", "wei\u00df", "zu", "ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Nicht Thorheit, T\u00e4uschung, feige Herzenss\u00fcnden", "tokens": ["Nicht", "Thor\u00b7heit", ",", "T\u00e4u\u00b7schung", ",", "fei\u00b7ge", "Her\u00b7zens\u00b7s\u00fcn\u00b7den"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PTKNEG", "NN", "$,", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verm\u00f6gen mich so bald von ihr zu trennen;", "tokens": ["Ver\u00b7m\u00f6\u00b7gen", "mich", "so", "bald", "von", "ihr", "zu", "tren\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vielleicht lehrt sie mich Weiberart erkennen,", "tokens": ["Viel\u00b7leicht", "lehrt", "sie", "mich", "Wei\u00b7be\u00b7rart", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Keiner noch vermochte zu ergr\u00fcnden.", "tokens": ["Die", "Kei\u00b7ner", "noch", "ver\u00b7moch\u00b7te", "zu", "er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich bin ein Thor ... denn einer Th\u00f6rin Mund,", "tokens": ["Ich", "bin", "ein", "Thor", "...", "denn", "ei\u00b7ner", "Th\u00f6\u00b7rin", "Mund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "KON", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die schier zu schwach zum Guten wie zum B\u00f6sen,", "tokens": ["Die", "schier", "zu", "schwach", "zum", "Gu\u00b7ten", "wie", "zum", "B\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PTKA", "ADJD", "APPRART", "NN", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Soll mir das unheilvollste R\u00e4thsel l\u00f6sen?", "tokens": ["Soll", "mir", "das", "un\u00b7heil\u00b7volls\u00b7te", "R\u00e4th\u00b7sel", "l\u00f6\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Was that sie mir seit langen Monden kund?", "tokens": ["Was", "that", "sie", "mir", "seit", "lan\u00b7gen", "Mon\u00b7den", "kund", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Nicht einen einzig' neuen Zug der Frau,", "tokens": ["Nicht", "ei\u00b7nen", "ein\u00b7zig'", "neu\u00b7en", "Zug", "der", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "PIAT", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nichts konnte ich aus ihrem Lachen lesen,", "tokens": ["Nichts", "konn\u00b7te", "ich", "aus", "ih\u00b7rem", "La\u00b7chen", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Aus ihren Thr\u00e4nen, ihrem Flimmerwesen,", "tokens": ["Aus", "ih\u00b7ren", "Thr\u00e4\u00b7nen", ",", "ih\u00b7rem", "Flim\u00b7mer\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das sich oft abd\u00e4mpft bis zum tr\u00fcbsten Grau ...", "tokens": ["Das", "sich", "oft", "ab\u00b7d\u00e4mpft", "bis", "zum", "tr\u00fcbs\u00b7ten", "Grau", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADV", "VVFIN", "APPR", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wenn ich nur w\u00fc\u00dfte, warum \u00e4ngstlich-fest", "tokens": ["Wenn", "ich", "nur", "w\u00fc\u00df\u00b7te", ",", "wa\u00b7rum", "\u00e4ngst\u00b7lich\u00b7fest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Oft ihre H\u00e4nde meinen Arm umklammern,", "tokens": ["Oft", "ih\u00b7re", "H\u00e4n\u00b7de", "mei\u00b7nen", "Arm", "um\u00b7klam\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Verst\u00e4nde ich der Augen scheues Jammern,", "tokens": ["Ver\u00b7st\u00e4n\u00b7de", "ich", "der", "Au\u00b7gen", "scheu\u00b7es", "Jam\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das halbe Wort, das schwer sich deuten l\u00e4\u00dft!", "tokens": ["Das", "hal\u00b7be", "Wort", ",", "das", "schwer", "sich", "deu\u00b7ten", "l\u00e4\u00dft", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADJD", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Seltsames Weib ... das sch\u00fcchtern, ungeliebt,", "tokens": ["Selt\u00b7sa\u00b7mes", "Weib", "...", "das", "sch\u00fcch\u00b7tern", ",", "un\u00b7ge\u00b7liebt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$(", "PDS", "VVINF", "$,", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Halbwachend nur hin durch die Welt geschritten", "tokens": ["Halb\u00b7wa\u00b7chend", "nur", "hin", "durch", "die", "Welt", "ge\u00b7schrit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADV", "ADV", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wie im Traume jedes Leid erlitten,", "tokens": ["Und", "wie", "im", "Trau\u00b7me", "je\u00b7des", "Leid", "er\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPRART", "NN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das die Verlassenheit dem Weibe giebt.", "tokens": ["Das", "die", "Ver\u00b7las\u00b7sen\u00b7heit", "dem", "Wei\u00b7be", "giebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ein Bl\u00e4ttchen gab sie mir mit stummer Hast", "tokens": ["Ein", "Bl\u00e4tt\u00b7chen", "gab", "sie", "mir", "mit", "stum\u00b7mer", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Als Antwort auf die wohlbedachte Frage:", "tokens": ["Als", "Ant\u00b7wort", "auf", "die", "wohl\u00b7be\u00b7dach\u00b7te", "Fra\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ob Langeweile sie nicht l\u00e4ngst schon plage,", "tokens": ["Ob", "Lan\u00b7ge\u00b7wei\u00b7le", "sie", "nicht", "l\u00e4ngst", "schon", "pla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "PTKNEG", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ob ich ihr nicht ein unwillkommner Gast.", "tokens": ["Ob", "ich", "ihr", "nicht", "ein", "un\u00b7will\u00b7komm\u00b7ner", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Sie sch\u00fcttelt mit der Feder fort die Last", "tokens": ["Sie", "sch\u00fct\u00b7telt", "mit", "der", "Fe\u00b7der", "fort", "die", "Last"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und wimmert redlich um vergangne Tage.", "tokens": ["Und", "wim\u00b7mert", "red\u00b7lich", "um", "ver\u00b7gang\u00b7ne", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich wei\u00df, es endet tragisch mit der Klage:", "tokens": ["Ich", "wei\u00df", ",", "es", "en\u00b7det", "tra\u00b7gisch", "mit", "der", "Kla\u00b7ge", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbdas Leben ist mir bitterlich verha\u00dft!\u00ab", "tokens": ["\u00bb", "das", "Le\u00b7ben", "ist", "mir", "bit\u00b7ter\u00b7lich", "ver\u00b7ha\u00dft", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}