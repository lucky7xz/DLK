{"dta.poem.9192": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n Auff einen falschen Freund.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Du sch\u00e4ndliche kr\u00f6te/ nun hast du den gifft", "tokens": ["Du", "sch\u00e4nd\u00b7li\u00b7che", "kr\u00f6\u00b7te", "/", "nun", "hast", "du", "den", "gifft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$(", "ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "An meiner unschuld ausgelassen/", "tokens": ["An", "mei\u00b7ner", "un\u00b7schuld", "aus\u00b7ge\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du drache/ dein gifftiges hauchen betrifft", "tokens": ["Du", "dra\u00b7che", "/", "dein", "giff\u00b7ti\u00b7ges", "hau\u00b7chen", "be\u00b7tr\u00b7ifft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Mein leben unverdienter massen/", "tokens": ["Mein", "le\u00b7ben", "un\u00b7ver\u00b7dien\u00b7ter", "mas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bleib daheim/ es hat nicht noth/", "tokens": ["Doch", "bleib", "da\u00b7heim", "/", "es", "hat", "nicht", "noth", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$(", "PPER", "VAFIN", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein solch basilisk der sieh\u2019t mich nicht todt.", "tokens": ["Ein", "solch", "ba\u00b7si\u00b7lisk", "der", "sieh't", "mich", "nicht", "todt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "VVFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "2. Du fleischerner teuffel/ du wanderst herumb/", "tokens": ["Du", "flei\u00b7scher\u00b7ner", "teuf\u00b7fel", "/", "du", "wan\u00b7derst", "he\u00b7rumb", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$(", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "-+--+-+++-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Als wie ein l\u00f6w in finstern p\u00fcschen/", "tokens": ["Als", "wie", "ein", "l\u00f6w", "in", "fins\u00b7tern", "p\u00fc\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NE", "APPR", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und siehest dich hinten und fornen wohl um/", "tokens": ["Und", "sie\u00b7hest", "dich", "hin\u00b7ten", "und", "for\u00b7nen", "wohl", "um", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "ADV", "APPR", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Ob du was schw\u00e4chers kanst erwischen!", "tokens": ["Ob", "du", "was", "schw\u00e4\u00b7chers", "kanst", "er\u00b7wi\u00b7schen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADJA", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch lauff nur fort du wildes thier/", "tokens": ["Doch", "lauff", "nur", "fort", "du", "wil\u00b7des", "thier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ADV", "PTKVZ", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein muthiger Hercules streitet bey mir.", "tokens": ["Ein", "mut\u00b7hi\u00b7ger", "Her\u00b7cu\u00b7les", "strei\u00b7tet", "bey", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "3. Du hungriger wolfs-zahn/ ach wolst du nicht gern", "tokens": ["Du", "hung\u00b7ri\u00b7ger", "wolfs\u00b7zahn", "/", "ach", "wolst", "du", "nicht", "gern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$(", "XY", "VMFIN", "PPER", "PTKNEG", "ADV"], "meter": "-+--+-+++-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mich armes schaf zu todte beissen?", "tokens": ["Mich", "ar\u00b7mes", "schaf", "zu", "tod\u00b7te", "beis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So lauschet ein listiger habicht von fern", "tokens": ["So", "lau\u00b7schet", "ein", "lis\u00b7ti\u00b7ger", "ha\u00b7bicht", "von", "fern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJD"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wann er die taube will zerreissen/", "tokens": ["Wann", "er", "die", "tau\u00b7be", "will", "zer\u00b7reis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So schnappet ein r\u00e4ubischer hecht", "tokens": ["So", "schnap\u00b7pet", "ein", "r\u00e4u\u00b7bi\u00b7scher", "hecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Und jaget wol selber sein eignes geschlecht.", "tokens": ["Und", "ja\u00b7get", "wol", "sel\u00b7ber", "sein", "eig\u00b7nes", "ge\u00b7schlecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PPOSAT", "ADJA", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.4": {"line.1": {"text": "4. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "An das verhalten meiner jugend?", "tokens": ["An", "das", "ver\u00b7hal\u00b7ten", "mei\u00b7ner", "ju\u00b7gend", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du eyfriges l\u00fcgen-maul wirst du nicht roth/", "tokens": ["Du", "ey\u00b7fri\u00b7ges", "l\u00fc\u00b7gen\u00b7maul", "wirst", "du", "nicht", "roth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$("], "meter": "-++-+-+-+-+", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Indem du meine reine tugend", "tokens": ["In\u00b7dem", "du", "mei\u00b7ne", "rei\u00b7ne", "tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu lauter grossen lastern machst/", "tokens": ["Zu", "lau\u00b7ter", "gros\u00b7sen", "las\u00b7tern", "machst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und meine gedancken so h\u00f6hnisch verlachst?", "tokens": ["Und", "mei\u00b7ne", "ge\u00b7dan\u00b7cken", "so", "h\u00f6h\u00b7nisch", "ver\u00b7lachst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.5": {"line.1": {"text": "5. Du diebische katze/ was leckst du mich doch/", "tokens": ["Du", "die\u00b7bi\u00b7sche", "kat\u00b7ze", "/", "was", "leckst", "du", "mich", "doch", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "VVFIN", "$(", "PWS", "VVFIN", "PPER", "PRF", "ADV", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Wann du mich willst von hinden kratzen?", "tokens": ["Wann", "du", "mich", "willst", "von", "hin\u00b7den", "krat\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VMFIN", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du spitzige zunge/ was willstu mir noch", "tokens": ["Du", "spit\u00b7zi\u00b7ge", "zun\u00b7ge", "/", "was", "will\u00b7stu", "mir", "noch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$(", "PWS", "VMFIN", "PPER", "ADV"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Von guter gunst und freundschafft schwatzen:", "tokens": ["Von", "gu\u00b7ter", "gunst", "und", "freund\u00b7schafft", "schwat\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Du meinst/ ich sol ins netze gehn", "tokens": ["Du", "meinst", "/", "ich", "sol", "ins", "net\u00b7ze", "gehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "$(", "PPER", "VMFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum singst du so lieblich und pfeiffest so sch\u00f6n.", "tokens": ["Drum", "singst", "du", "so", "lieb\u00b7lich", "und", "pfeif\u00b7fest", "so", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ADJD", "KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.6": {"line.1": {"text": "6. Du T\u00fcrcke/ du Heyde/ bedenckst du dich nicht/", "tokens": ["Du", "T\u00fcr\u00b7cke", "/", "du", "Hey\u00b7de", "/", "be\u00b7denckst", "du", "dich", "nicht", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$(", "PPER", "NE", "$(", "VVFIN", "PPER", "PRF", "PTKNEG", "$("], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Du unmensch/ hast du kein gewissen/", "tokens": ["Du", "un\u00b7mensch", "/", "hast", "du", "kein", "ge\u00b7wis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$(", "VAFIN", "PPER", "PIAT", "VAPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Des himmels gerechtigkeit eiffert und spricht:", "tokens": ["Des", "him\u00b7mels", "ge\u00b7rech\u00b7tig\u00b7keit", "eif\u00b7fert", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "KON", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Verflucht sey! der sich so beflissen/", "tokens": ["Ver\u00b7flucht", "sey", "!", "der", "sich", "so", "be\u00b7flis\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$.", "PRELS", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er den nechsten der ihn liebt/", "tokens": ["Da\u00df", "er", "den", "nechs\u00b7ten", "der", "ihn", "liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "ART", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit tausend betr\u00fcglichen h\u00e4nden betr\u00fcbt.", "tokens": ["Mit", "tau\u00b7send", "be\u00b7tr\u00fcg\u00b7li\u00b7chen", "h\u00e4n\u00b7den", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "7. Doch schwerme nur besser du rasender hund/", "tokens": ["Doch", "schwer\u00b7me", "nur", "bes\u00b7ser", "du", "ra\u00b7sen\u00b7der", "hund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "PPER", "ADJA", "NN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Bi\u00df mir und aller welt zuwieder;", "tokens": ["Bi\u00df", "mir", "und", "al\u00b7ler", "welt", "zu\u00b7wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bleibe doch immer am leibe gesund/", "tokens": ["Ich", "blei\u00b7be", "doch", "im\u00b7mer", "am", "lei\u00b7be", "ge\u00b7sund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "VVPP", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Du aber schl\u00e4gst dich selber nieder/", "tokens": ["Du", "a\u00b7ber", "schl\u00e4gst", "dich", "sel\u00b7ber", "nie\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein hund der sich so sehr bewegt/", "tokens": ["Ein", "hund", "der", "sich", "so", "sehr", "be\u00b7wegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PRF", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat selten neun tage zur\u00fccke gelegt.", "tokens": ["Hat", "sel\u00b7ten", "neun", "ta\u00b7ge", "zu\u00b7r\u00fc\u00b7cke", "ge\u00b7legt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "CARD", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "8. Ich habe noch keinen bekannten gesehn/", "tokens": ["Ich", "ha\u00b7be", "noch", "kei\u00b7nen", "be\u00b7kann\u00b7ten", "ge\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "VVPP", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Dem du von hertzen g\u00fcnstig w\u00e4rest:", "tokens": ["Dem", "du", "von", "hert\u00b7zen", "g\u00fcns\u00b7tig", "w\u00e4\u00b7rest", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Drum la\u00df ich es endlich gedultig geschehen/", "tokens": ["Drum", "la\u00df", "ich", "es", "end\u00b7lich", "ge\u00b7dul\u00b7tig", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.4": {"text": "Da\u00df du mich hier und da versehrest.", "tokens": ["Da\u00df", "du", "mich", "hier", "und", "da", "ver\u00b7seh\u00b7rest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Vielleicht kompt noch die liebe zeit/", "tokens": ["Viel\u00b7leicht", "kompt", "noch", "die", "lie\u00b7be", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df mancher sein eiffriges w\u00fcten bereut.", "tokens": ["Da\u00df", "man\u00b7cher", "sein", "eif\u00b7fri\u00b7ges", "w\u00fc\u00b7ten", "be\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "PPOSAT", "ADJA", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}}}}