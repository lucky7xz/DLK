{"textgrid.poem.41418": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Paulus Purganti und Agnese", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "War nicht der Arzt Purganti zu beklagen?", "tokens": ["War", "nicht", "der", "Arzt", "Pur\u00b7gan\u00b7ti", "zu", "be\u00b7kla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er hatt' in seinen alten Tagen", "tokens": ["Er", "hatt'", "in", "sei\u00b7nen", "al\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein schwaches Haubt, und einen schw\u00e4chern Leib,", "tokens": ["Ein", "schwa\u00b7ches", "Haubt", ",", "und", "ei\u00b7nen", "schw\u00e4\u00b7chern", "Leib", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Auch \u00fcberdie\u00df, zum Zuwachs seiner Plagen,", "tokens": ["Auch", "\u00fc\u00b7ber\u00b7die\u00df", ",", "zum", "Zu\u00b7wachs", "sei\u00b7ner", "Pla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein junges Weib.", "tokens": ["Ein", "jun\u00b7ges", "Weib", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Sie hie\u00df Agnes, und war ein Bild der Zucht;", "tokens": ["Sie", "hie\u00df", "Ag\u00b7nes", ",", "und", "war", "ein", "Bild", "der", "Zucht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$,", "KON", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Es macht ihr gro\u00dfer Ruhm, des frommen Wandels Frucht,", "tokens": ["Es", "macht", "ihr", "gro\u00b7\u00dfer", "Ruhm", ",", "des", "from\u00b7men", "Wan\u00b7dels", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das ganze Kirchspiel stolz. Man sprach in langer Zeit", "tokens": ["Das", "gan\u00b7ze", "Kirch\u00b7spiel", "stolz", ".", "Man", "sprach", "in", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "$.", "PIS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bei jeder W\u00f6chnerin, bewundernd ohne Neid,", "tokens": ["Bei", "je\u00b7der", "W\u00f6ch\u00b7ne\u00b7rin", ",", "be\u00b7wun\u00b7dernd", "oh\u00b7ne", "Neid", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur von Agnesens Ehrbarkeit.", "tokens": ["Nur", "von", "Ag\u00b7ne\u00b7sens", "Ehr\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Auf ihrem B\u00fccherschrank stand niemals ein Roman,", "tokens": ["Auf", "ih\u00b7rem", "B\u00fc\u00b7cher\u00b7schrank", "stand", "nie\u00b7mals", "ein", "Ro\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Doch wol ein Quirsfeld, Kern, Schmuck, Albrecht, Wudrian.", "tokens": ["Doch", "wol", "ein", "Quirs\u00b7feld", ",", "Kern", ",", "Schmuck", ",", "Al\u00b7brecht", ",", "Wud\u00b7ri\u00b7an", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "NN", "$,", "NN", "$,", "NE", "$,", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie war insonderheit der Oper feind gewesen,", "tokens": ["Sie", "war", "in\u00b7son\u00b7der\u00b7heit", "der", "O\u00b7per", "feind", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und hatte, wie, vor ihr, fast niemand sonst gethan,", "tokens": ["Und", "hat\u00b7te", ",", "wie", ",", "vor", "ihr", ",", "fast", "nie\u00b7mand", "sonst", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "PWAV", "$,", "APPR", "PPER", "$,", "ADV", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Cubach dreimal durchgelesen.", "tokens": ["Den", "Cu\u00b7bach", "drei\u00b7mal", "durch\u00b7ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Asmodi selbst verlor das Herz,", "tokens": ["As\u00b7mo\u00b7di", "selbst", "ver\u00b7lor", "das", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die starke Gl\u00e4ubige durch List zu \u00fcberwinden,", "tokens": ["Die", "star\u00b7ke", "Gl\u00e4u\u00b7bi\u00b7ge", "durch", "List", "zu", "\u00fc\u00b7berw\u00b7in\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Denn sie verfluchte wilden Scherz,", "tokens": ["Denn", "sie", "ver\u00b7fluch\u00b7te", "wil\u00b7den", "Scherz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und trotzte gar den Schwachheits\u00fcnden.", "tokens": ["Und", "trotz\u00b7te", "gar", "den", "Schwach\u00b7hei\u00b7ts\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Oft ward von ihr, die Andacht zu entz\u00fcnden,", "tokens": ["Oft", "ward", "von", "ihr", ",", "die", "An\u00b7dacht", "zu", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Ein geistlicher Choral auf dem Clavier gespielt,", "tokens": ["Ein", "geist\u00b7li\u00b7cher", "Cho\u00b7ral", "auf", "dem", "Cla\u00b7vier", "ge\u00b7spielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Und, wie man mir entdeckt, dem Spiegel zugeschielt,", "tokens": ["Und", ",", "wie", "man", "mir", "ent\u00b7deckt", ",", "dem", "Spie\u00b7gel", "zu\u00b7ge\u00b7schielt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PIS", "PPER", "VVPP", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nur ihr Gesicht aufmerksam zu betrachten,", "tokens": ["Nur", "ihr", "Ge\u00b7sicht", "auf\u00b7merk\u00b7sam", "zu", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Um jeden Theil davon gro\u00dfm\u00fcthig zu verachten.", "tokens": ["Um", "je\u00b7den", "Theil", "da\u00b7von", "gro\u00df\u00b7m\u00fct\u00b7hig", "zu", "ver\u00b7ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PIAT", "NN", "PAV", "ADJD", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Allein, sie war ganz heimlich von der Art,", "tokens": ["Al\u00b7lein", ",", "sie", "war", "ganz", "heim\u00b7lich", "von", "der", "Art", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die keusche Reden gern mit Liebeswerken paart.", "tokens": ["Die", "keu\u00b7sche", "Re\u00b7den", "gern", "mit", "Lie\u00b7bes\u00b7wer\u00b7ken", "paart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den ird'schen Trieb der L\u00fcsternheit,", "tokens": ["Den", "ird'\u00b7schen", "Trieb", "der", "L\u00fcs\u00b7tern\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ents\u00fcndigte des Eh'stands Schuldigkeit,", "tokens": ["Ent\u00b7s\u00fcn\u00b7dig\u00b7te", "des", "Eh'\u00b7stands", "Schul\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und einer tugendhaften Brust", "tokens": ["Und", "ei\u00b7ner", "tu\u00b7gend\u00b7haf\u00b7ten", "Brust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird immer jede Pflicht zur Lust.", "tokens": ["Wird", "im\u00b7mer", "je\u00b7de", "Pflicht", "zur", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Agnese, das getreue Weib,", "tokens": ["Ag\u00b7ne\u00b7se", ",", "das", "ge\u00b7treu\u00b7e", "Weib", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Verpflegt des theuren Gatten Leib,", "tokens": ["Ver\u00b7pflegt", "des", "theu\u00b7ren", "Gat\u00b7ten", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie wei\u00df ihm von gesunden Speisen", "tokens": ["Sie", "wei\u00df", "ihm", "von", "ge\u00b7sun\u00b7den", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die trefflichsten stets anzupreisen;", "tokens": ["Die", "treff\u00b7lichs\u00b7ten", "stets", "an\u00b7zu\u00b7prei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "VVIZU", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Was aber schw\u00e4chet oder zehrt,", "tokens": ["Was", "a\u00b7ber", "schw\u00e4\u00b7chet", "o\u00b7der", "zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wird ihm mit vielem Recht verwehrt,", "tokens": ["Wird", "ihm", "mit", "vie\u00b7lem", "Recht", "ver\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sie w\u00e4rmt und w\u00fcrzt des Mannes Wein,", "tokens": ["Sie", "w\u00e4rmt", "und", "w\u00fcrzt", "des", "Man\u00b7nes", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und schneidet ihm die Bissen klein,", "tokens": ["Und", "schnei\u00b7det", "ihm", "die", "Bis\u00b7sen", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Legt Mark und Nieren reichlich vor,", "tokens": ["Legt", "Mark", "und", "Nie\u00b7ren", "reich\u00b7lich", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dr\u00fcckt seine Hand, zupft ihn an's Ohr,", "tokens": ["Dr\u00fcckt", "sei\u00b7ne", "Hand", ",", "zupft", "ihn", "an's", "Ohr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Um durch dergleichen Schmeicheleien", "tokens": ["Um", "durch", "derg\u00b7lei\u00b7chen", "Schmei\u00b7che\u00b7lei\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "APPR", "PIS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Den alten Paulus zu erfreuen.", "tokens": ["Den", "al\u00b7ten", "Pau\u00b7lus", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Dankbarkeit ist eine schwere Last:", "tokens": ["Die", "Dank\u00b7bar\u00b7keit", "ist", "ei\u00b7ne", "schwe\u00b7re", "Last", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu vieles Z\u00e4rtlichthun wird endlich auch verha\u00dft.", "tokens": ["Zu", "vie\u00b7les", "Z\u00e4rt\u00b7licht\u00b7hun", "wird", "end\u00b7lich", "auch", "ver\u00b7ha\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVINF", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Alte fand sein Sch\u00e4tzchen zu gesch\u00e4ftig,", "tokens": ["Der", "Al\u00b7te", "fand", "sein", "Sch\u00e4tz\u00b7chen", "zu", "ge\u00b7sch\u00e4f\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und ihre Liebe viel zu heftig.", "tokens": ["Und", "ih\u00b7re", "Lie\u00b7be", "viel", "zu", "hef\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er suchte bald in allen diesen Werken", "tokens": ["Er", "such\u00b7te", "bald", "in", "al\u00b7len", "die\u00b7sen", "Wer\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PIAT", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mehr Eigennutz, als Neigung zu bemerken.", "tokens": ["Mehr", "Ei\u00b7gen\u00b7nutz", ",", "als", "Nei\u00b7gung", "zu", "be\u00b7mer\u00b7ken", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "KOUS", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den tauben Ottern gleich, wann ihr Beschw\u00f6rer spricht,", "tokens": ["Den", "tau\u00b7ben", "Ot\u00b7tern", "gleich", ",", "wann", "ihr", "Be\u00b7schw\u00f6\u00b7rer", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,", "PWAV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "H\u00f6rt er die s\u00fc\u00dfen Worte nicht;", "tokens": ["H\u00f6rt", "er", "die", "s\u00fc\u00b7\u00dfen", "Wor\u00b7te", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Name: Sch\u00e4tzchen, Engel, Leben,", "tokens": ["Der", "Na\u00b7me", ":", "Sch\u00e4tz\u00b7chen", ",", "En\u00b7gel", ",", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "$,", "NE", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wird ihm zwar oft, doch stets umsonst, gegeben.", "tokens": ["Wird", "ihm", "zwar", "oft", ",", "doch", "stets", "um\u00b7sonst", ",", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "$,", "ADV", "ADV", "ADV", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "So oft, als mitten in der Nacht", "tokens": ["So", "oft", ",", "als", "mit\u00b7ten", "in", "der", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Purganti schnarcht, Agnese wacht,", "tokens": ["Pur\u00b7gan\u00b7ti", "schnarcht", ",", "Ag\u00b7ne\u00b7se", "wacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "NE", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Und, durch ein falsch' Gespenst geschrecket,", "tokens": ["Und", ",", "durch", "ein", "falsch'", "Ge\u00b7spenst", "ge\u00b7schre\u00b7cket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich zum Gemahl, so nah' als m\u00f6glich, strecket,", "tokens": ["Sich", "zum", "Ge\u00b7mahl", ",", "so", "nah'", "als", "m\u00f6g\u00b7lich", ",", "stre\u00b7cket", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "$,", "ADV", "ADJD", "KOKOM", "ADJD", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und durch ein M\u00e4ulchen ihn erwecket,", "tokens": ["Und", "durch", "ein", "M\u00e4ul\u00b7chen", "ihn", "er\u00b7we\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gibt diese Dreistigkeit ihm neues Ungemach;", "tokens": ["Gibt", "die\u00b7se", "Dreis\u00b7tig\u00b7keit", "ihm", "neu\u00b7es", "Un\u00b7ge\u00b7mach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er sinnt den Gegenmitteln nach,", "tokens": ["Er", "sinnt", "den", "Ge\u00b7gen\u00b7mit\u00b7teln", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Um dem zu weibischen Bezeigen", "tokens": ["Um", "dem", "zu", "wei\u00b7bi\u00b7schen", "Be\u00b7zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "In Zukunft bestens vorzubeugen.", "tokens": ["In", "Zu\u00b7kunft", "bes\u00b7tens", "vor\u00b7zu\u00b7beu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Durch Macht und Widerstand? Ach nein!", "tokens": ["Durch", "Macht", "und", "Wi\u00b7der\u00b7stand", "?", "Ach", "nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$.", "NN", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was konnt' ihm hierzu Muth verleihn?", "tokens": ["Was", "konnt'", "ihm", "hier\u00b7zu", "Muth", "ver\u00b7leihn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PAV", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er krieget, wie der Fabius,", "tokens": ["Er", "krie\u00b7get", ",", "wie", "der", "Fa\u00b7bi\u00b7us", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der durch Verzug gewinnen mu\u00df.", "tokens": ["Der", "durch", "Ver\u00b7zug", "ge\u00b7win\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was soll man von dem Ritter sagen,", "tokens": ["Was", "soll", "man", "von", "dem", "Rit\u00b7ter", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der weder fliehen darf, noch schlagen,", "tokens": ["Der", "we\u00b7der", "flie\u00b7hen", "darf", ",", "noch", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "KON", "VVINF", "VMFIN", "$,", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der, wann der Schranken offen steht,", "tokens": ["Der", ",", "wann", "der", "Schran\u00b7ken", "of\u00b7fen", "steht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht k\u00e4mpft, auch nicht um Gnade fleht?", "tokens": ["Nicht", "k\u00e4mpft", ",", "auch", "nicht", "um", "Gna\u00b7de", "fleht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,", "ADV", "PTKNEG", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wo die Gewalt unbrauchbar ist,", "tokens": ["Wo", "die", "Ge\u00b7walt", "un\u00b7brauch\u00b7bar", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedient' ein Weiser sich der List.", "tokens": ["Be\u00b7dient'", "ein", "Wei\u00b7ser", "sich", "der", "List", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Arzt, der seinen Gegner scheut,", "tokens": ["Der", "Arzt", ",", "der", "sei\u00b7nen", "Geg\u00b7ner", "scheut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kirrt ihn durch falsche Freundlichkeit,", "tokens": ["Kirrt", "ihn", "durch", "fal\u00b7sche", "Freund\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und er erwiedert oft der Frauen Morgenku\u00df", "tokens": ["Und", "er", "er\u00b7wie\u00b7dert", "oft", "der", "Frau\u00b7en", "Mor\u00b7gen\u00b7ku\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ganz liebreich, sonder Ueberdru\u00df.", "tokens": ["Ganz", "lieb\u00b7reich", ",", "son\u00b7der", "Ue\u00b7berd\u00b7ru\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Drauf fragt er: Was ist dir geschehn?", "tokens": ["Drauf", "fragt", "er", ":", "Was", "ist", "dir", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$.", "PWS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du pflegst ja frischer auszusehn.", "tokens": ["Du", "pflegst", "ja", "fri\u00b7scher", "aus\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sie mu\u00df ihm ihre Rechte reichen:", "tokens": ["Sie", "mu\u00df", "ihm", "ih\u00b7re", "Rech\u00b7te", "rei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Hier sind, spricht er, gar schlimme Zeichen:", "tokens": ["Hier", "sind", ",", "spricht", "er", ",", "gar", "schlim\u00b7me", "Zei\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "VVFIN", "PPER", "$,", "ADV", "ADJA", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Ein Puls, der viel zu heftig schl\u00e4gt.", "tokens": ["Ein", "Puls", ",", "der", "viel", "zu", "hef\u00b7tig", "schl\u00e4gt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "PTKA", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Noch mehr! ein Auge voller Glut,", "tokens": ["Noch", "mehr", "!", "ein", "Au\u00b7ge", "vol\u00b7ler", "Glut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Und eine hei\u00dfe Brust, die sich zu sehr bewegt!", "tokens": ["Und", "ei\u00b7ne", "hei\u00b7\u00dfe", "Brust", ",", "die", "sich", "zu", "sehr", "be\u00b7wegt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "PRF", "APPR", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die\u00df, sonderlich die Brust, die nimmer ruht!", "tokens": ["Die\u00df", ",", "son\u00b7der\u00b7lich", "die", "Brust", ",", "die", "nim\u00b7mer", "ruht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "ADJD", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Bezeugt ein wallendes, ein angestecktes Blut,", "tokens": ["Be\u00b7zeugt", "ein", "wal\u00b7len\u00b7des", ",", "ein", "an\u00b7ge\u00b7steck\u00b7tes", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Das einen schnellen Tod hervorzubringen pflegt.", "tokens": ["Das", "ei\u00b7nen", "schnel\u00b7len", "Tod", "her\u00b7vor\u00b7zu\u00b7brin\u00b7gen", "pflegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So urtheilt Musitan. Der Brunnen scheint hier gut,", "tokens": ["So", "ur\u00b7theilt", "Mu\u00b7si\u00b7tan", ".", "Der", "Brun\u00b7nen", "scheint", "hier", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$.", "ART", "NN", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Spaer sonderlich, der rechte Wunder thut ...", "tokens": ["Der", "Spaer", "son\u00b7der\u00b7lich", ",", "der", "rech\u00b7te", "Wun\u00b7der", "thut", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.19": {"text": "Der Spaer? Eben der! Kurz, es gedeiht zum Schlu\u00df,", "tokens": ["Der", "Spaer", "?", "E\u00b7ben", "der", "!", "Kurz", ",", "es", "ge\u00b7deiht", "zum", "Schlu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADV", "ART", "$.", "ADJD", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.20": {"text": "Da\u00df Agnes unges\u00e4umt den Brunnen brauchen mu\u00df.", "tokens": ["Da\u00df", "Ag\u00b7nes", "un\u00b7ge\u00b7s\u00e4umt", "den", "Brun\u00b7nen", "brau\u00b7chen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADJD", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Doch fehlte sehr des Doctors Wissenschaft:", "tokens": ["Doch", "fehl\u00b7te", "sehr", "des", "Doc\u00b7tors", "Wis\u00b7sen\u00b7schaft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Unkr\u00e4ftig ist allhier der Wasser Wunderkraft.", "tokens": ["Un\u00b7kr\u00e4f\u00b7tig", "ist", "all\u00b7hier", "der", "Was\u00b7ser", "Wun\u00b7der\u00b7kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die in der Heilungskunst gewandt,", "tokens": ["Die", "in", "der", "Hei\u00b7lungs\u00b7kunst", "ge\u00b7wandt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind andrer Meinung, als Purgant,", "tokens": ["Sind", "an\u00b7drer", "Mei\u00b7nung", ",", "als", "Pur\u00b7gant", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$,", "KOUS", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und vom Galen zum Sternenkalb", "tokens": ["Und", "vom", "Ga\u00b7len", "zum", "Ster\u00b7nen\u00b7kalb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPRART", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Lehrt jeder Arzt, dies Mittel hilft nicht halb:", "tokens": ["Lehrt", "je\u00b7der", "Arzt", ",", "dies", "Mit\u00b7tel", "hilft", "nicht", "halb", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PDS", "NN", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Zumal, wann solch ein brennend Gift", "tokens": ["Zu\u00b7mal", ",", "wann", "solch", "ein", "bren\u00b7nend", "Gift"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "PIAT", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Des K\u00f6rpers edle Theile trifft,", "tokens": ["Des", "K\u00f6r\u00b7pers", "ed\u00b7le", "Thei\u00b7le", "trifft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und mit dem Kreislauf vom Gebl\u00fct'", "tokens": ["Und", "mit", "dem", "Kreis\u00b7lauf", "vom", "Ge\u00b7bl\u00fct'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Allm\u00e4hlich sich um's Herze zieht.", "tokens": ["All\u00b7m\u00e4h\u00b7lich", "sich", "um's", "Her\u00b7ze", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "NE", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Agnese trinkt und leert mit Widerwillen", "tokens": ["Ag\u00b7ne\u00b7se", "trinkt", "und", "leert", "mit", "Wi\u00b7der\u00b7wil\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "APPR", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Zw\u00f6lf Flaschen aus, bedient sich auch der Pillen.", "tokens": ["Zw\u00f6lf", "Fla\u00b7schen", "aus", ",", "be\u00b7dient", "sich", "auch", "der", "Pil\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PTKVZ", "$,", "VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Allein umsonst: nichts kann die Krankheit stillen.", "tokens": ["Al\u00b7lein", "um\u00b7sonst", ":", "nichts", "kann", "die", "Krank\u00b7heit", "stil\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "PIS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Es meldet sich der erste Brand,", "tokens": ["Es", "mel\u00b7det", "sich", "der", "ers\u00b7te", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wie zuvor, in Brust und Hand.", "tokens": ["So", "wie", "zu\u00b7vor", ",", "in", "Brust", "und", "Hand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie \u00e4chzt und seufzt ohn' Unterla\u00df,", "tokens": ["Sie", "\u00e4chzt", "und", "seufzt", "ohn'", "Un\u00b7ter\u00b7la\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und sagt, ihr fehlt sie wei\u00df nicht was,", "tokens": ["Und", "sagt", ",", "ihr", "fehlt", "sie", "wei\u00df", "nicht", "was", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "VVFIN", "PTKNEG", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und k\u00f6mmt zum Eh'herrn oft gerannt,", "tokens": ["Und", "k\u00f6mmt", "zum", "Eh'\u00b7herrn", "oft", "ge\u00b7rannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Lechzt, klaget, flehet, girrt, und sieht ihn sehnend an.", "tokens": ["Lechzt", ",", "kla\u00b7get", ",", "fle\u00b7het", ",", "girrt", ",", "und", "sieht", "ihn", "seh\u00b7nend", "an", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dies h\u00e4tte mich ger\u00fchrt; doch r\u00fchrt' es nicht den Mann,", "tokens": ["Dies", "h\u00e4t\u00b7te", "mich", "ge\u00b7r\u00fchrt", ";", "doch", "r\u00fchrt'", "es", "nicht", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVPP", "$.", "ADV", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der ist kaum ihres Flehns gew\u00e4rtig,", "tokens": ["Der", "ist", "kaum", "ih\u00b7res", "Flehns", "ge\u00b7w\u00e4r\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "So h\u00e4lt er zum voraus sich mit der Ausflucht fertig.", "tokens": ["So", "h\u00e4lt", "er", "zum", "vo\u00b7raus", "sich", "mit", "der", "Aus\u00b7flucht", "fer\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADV", "PRF", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Anstatt der th\u00e4t'gen Lieb' und Huld,", "tokens": ["An\u00b7statt", "der", "th\u00e4t'\u00b7gen", "Lieb'", "und", "Huld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Spricht er zu ihr nur von Geduld,", "tokens": ["Spricht", "er", "zu", "ihr", "nur", "von", "Ge\u00b7duld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Von Selbstverl\u00e4ugnung und Beschwerden,", "tokens": ["Von", "Selbst\u00b7ver\u00b7l\u00e4ug\u00b7nung", "und", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wann Leib und Fleisch gepr\u00fcfet werden,", "tokens": ["Wann", "Leib", "und", "Fleisch", "ge\u00b7pr\u00fc\u00b7fet", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und wie, seit Evens N\u00e4scherei,", "tokens": ["Und", "wie", ",", "seit", "E\u00b7vens", "N\u00e4\u00b7sche\u00b7rei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Weiber Erbtheil Leiden sei;", "tokens": ["Der", "Wei\u00b7ber", "E\u00b7rbtheil", "Lei\u00b7den", "sei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df die Entz\u00fcndung, die sie f\u00fchlt,", "tokens": ["Da\u00df", "die", "Ent\u00b7z\u00fcn\u00b7dung", ",", "die", "sie", "f\u00fchlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sich durch kein m\u00fcrrisch Winseln k\u00fchlt;", "tokens": ["Sich", "durch", "kein", "m\u00fcr\u00b7risch", "Win\u00b7seln", "k\u00fchlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIAT", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sie m\u00fcsse nur der Ruhe pflegen,", "tokens": ["Sie", "m\u00fcs\u00b7se", "nur", "der", "Ru\u00b7he", "pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die Augen schlie\u00dfen, sich nicht regen,", "tokens": ["Die", "Au\u00b7gen", "schlie\u00b7\u00dfen", ",", "sich", "nicht", "re\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PRF", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Sich immer auf die Seite legen,", "tokens": ["Sich", "im\u00b7mer", "auf", "die", "Sei\u00b7te", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und ihre Kniee nicht bewegen.", "tokens": ["Und", "ih\u00b7re", "Kni\u00b7ee", "nicht", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Doch ende bald, Thalia, den Gesang:", "tokens": ["Doch", "en\u00b7de", "bald", ",", "Tha\u00b7lia", ",", "den", "Ge\u00b7sang", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$,", "NE", "$,", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Kein M\u00e4rchen schickt sich gar zu lang.", "tokens": ["Kein", "M\u00e4r\u00b7chen", "schickt", "sich", "gar", "zu", "lang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Je mehr Purganti spricht, und lehrt,", "tokens": ["Je", "mehr", "Pur\u00b7gan\u00b7ti", "spricht", ",", "und", "lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,", "KON", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Je minder wird sein Weib bekehrt.", "tokens": ["Je", "min\u00b7der", "wird", "sein", "Weib", "be\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Fieber \u00e4u\u00dfert sich bald wieder,", "tokens": ["Ihr", "Fie\u00b7ber", "\u00e4u\u00b7\u00dfert", "sich", "bald", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie schl\u00e4gt die Augen z\u00fcchtig nieder,", "tokens": ["Sie", "schl\u00e4gt", "die", "Au\u00b7gen", "z\u00fcch\u00b7tig", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und lispelt: Schatz, ich wollte wol ...", "tokens": ["Und", "lis\u00b7pelt", ":", "Schatz", ",", "ich", "woll\u00b7te", "wol", "..."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "$,", "PPER", "VMFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was willst du? ruft er eifersvoll,", "tokens": ["Was", "willst", "du", "?", "ruft", "er", "ei\u00b7fers\u00b7voll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "$.", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Beim Brunnentrinken? Bist du toll?", "tokens": ["Beim", "Brun\u00b7nen\u00b7trin\u00b7ken", "?", "Bist", "du", "toll", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du willst: du willst; doch ist gewi\u00df", "tokens": ["Du", "willst", ":", "du", "willst", ";", "doch", "ist", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$.", "PPER", "VMFIN", "$.", "ADV", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kein Gift dir sch\u00e4dlicher, als dies.", "tokens": ["Kein", "Gift", "dir", "sch\u00e4d\u00b7li\u00b7cher", ",", "als", "dies", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "ADJD", "$,", "KOUS", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ach! ach! wann werden doch auf Erden", "tokens": ["Ach", "!", "ach", "!", "wann", "wer\u00b7den", "doch", "auf", "Er\u00b7den"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "XY", "$.", "PWAV", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die Weiber einmal kl\u00fcger werden?", "tokens": ["Die", "Wei\u00b7ber", "ein\u00b7mal", "kl\u00fc\u00b7ger", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ich werd' es thun; doch magst du wissen,", "tokens": ["Ich", "werd'", "es", "thun", ";", "doch", "magst", "du", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$.", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Du wirst vor morgen sterben m\u00fcssen.", "tokens": ["Du", "wirst", "vor", "mor\u00b7gen", "ster\u00b7ben", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Was du mir sagst, mein Herz, ist wahr,", "tokens": ["Was", "du", "mir", "sagst", ",", "mein", "Herz", ",", "ist", "wahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "$,", "PPOSAT", "NN", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch ich erkenne die Gefahr.", "tokens": ["Auch", "ich", "er\u00b7ken\u00b7ne", "die", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, was ist dies schn\u00f6de Leben,", "tokens": ["Al\u00b7lein", ",", "was", "ist", "dies", "schn\u00f6\u00b7de", "Le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PDS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die kurze Wallfahrt? M\u00fche, Pein.", "tokens": ["Die", "kur\u00b7ze", "Wall\u00b7fahrt", "?", "M\u00fc\u00b7he", ",", "Pein", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mu\u00df ich nicht immer fertig sein,", "tokens": ["Mu\u00df", "ich", "nicht", "im\u00b7mer", "fer\u00b7tig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr dich, mein Kind, es aufzugeben?", "tokens": ["F\u00fcr", "dich", ",", "mein", "Kind", ",", "es", "auf\u00b7zu\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Den Tod mu\u00df nur ein Weltkind scheun;", "tokens": ["Den", "Tod", "mu\u00df", "nur", "ein", "Welt\u00b7kind", "scheun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich aber will, du sollst es sehn,", "tokens": ["Ich", "a\u00b7ber", "will", ",", "du", "sollst", "es", "sehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihm l\u00e4chelnd jetzt entgegen gehn.", "tokens": ["Ihm", "l\u00e4\u00b7chelnd", "jetzt", "ent\u00b7ge\u00b7gen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADV", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Purganti stutzt, erwiedert zwar mit K\u00fcssen;", "tokens": ["Pur\u00b7gan\u00b7ti", "stutzt", ",", "er\u00b7wie\u00b7dert", "zwar", "mit", "K\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jedoch den Mord verbietet sein Gewissen.", "tokens": ["Je\u00b7doch", "den", "Mord", "ver\u00b7bie\u00b7tet", "sein", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er selbst wird kurz darauf ihr durch den Tod entrissen.", "tokens": ["Er", "selbst", "wird", "kurz", "da\u00b7rauf", "ihr", "durch", "den", "Tod", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADJD", "PAV", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seht, wie bei h\u00f6chster Noth der Himmel Trost ertheilt!", "tokens": ["Seht", ",", "wie", "bei", "h\u00f6chs\u00b7ter", "Noth", "der", "Him\u00b7mel", "Trost", "er\u00b7theilt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "APPR", "ADJA", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die fromme Wittwe traurt, freit wieder, wird geheilt.", "tokens": ["Die", "from\u00b7me", "Witt\u00b7we", "traurt", ",", "freit", "wie\u00b7der", ",", "wird", "ge\u00b7heilt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ADV", "ADV", "$,", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}