{"textgrid.poem.54002": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Das Gesetz", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mann und Frau und Frau und Mann \u2013", "tokens": ["Mann", "und", "Frau", "und", "Frau", "und", "Mann", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "KON", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wohnungsnot und Herzensnot", "tokens": ["Woh\u00b7nungs\u00b7not", "und", "Her\u00b7zens\u00b7not"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "machen manche Ehe tot.", "tokens": ["ma\u00b7chen", "man\u00b7che", "E\u00b7he", "tot", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Warum", "tokens": ["Wa\u00b7rum"], "token_info": ["word"], "pos": ["PWAV"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "l\u00e4\u00dft man sich denn nicht scheiden?", "tokens": ["l\u00e4\u00dft", "man", "sich", "denn", "nicht", "schei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "'s fehlt an Geld \u2013 und der Schmutz und der Schmutz . . .", "tokens": ["'s", "fehlt", "an", "Geld", "\u2013", "und", "der", "Schmutz", "und", "der", "Schmutz", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$(", "KON", "ART", "NN", "KON", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und so zerrinnt das Leben beiden \u2013", "tokens": ["Und", "so", "zer\u00b7rinnt", "das", "Le\u00b7ben", "bei\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PIAT", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "so wie sie, sind hunderttausend ohne Schutz . . .", "tokens": ["so", "wie", "sie", ",", "sind", "hun\u00b7dert\u00b7tau\u00b7send", "oh\u00b7ne", "Schutz", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "KOKOM", "PPER", "$,", "VAFIN", "ADJD", "APPR", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.3": {"line.1": {"text": "Und unterdes \u2013", "tokens": ["Und", "un\u00b7ter\u00b7des", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJA", "$("], "meter": "-+--", "measure": "dactylic.init"}, "line.2": {"text": "da sitzen sie im Reichstagshaus", "tokens": ["da", "sit\u00b7zen", "sie", "im", "Reichs\u00b7tags\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und knobeln sich neue Gesetze aus;", "tokens": ["und", "kno\u00b7beln", "sich", "neu\u00b7e", "Ge\u00b7set\u00b7ze", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "ein gutes f\u00fcr Scheidung ist nicht dabei \u2013", "tokens": ["ein", "gu\u00b7tes", "f\u00fcr", "Schei\u00b7dung", "ist", "nicht", "da\u00b7bei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "NN", "VAFIN", "PTKNEG", "PAV", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "H\u00f6rt ihr den Schrei? H\u00f6rt ihr den Schrei?", "tokens": ["H\u00f6rt", "ihr", "den", "Schrei", "?", "H\u00f6rt", "ihr", "den", "Schrei", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "H\u00f6rt ihr den Schrei?", "tokens": ["H\u00f6rt", "ihr", "den", "Schrei", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Paragraph 5, Ziffer 4, Absatz 3.", "tokens": ["Pa\u00b7ra\u00b7gra\u00b7ph", "5", ",", "Zif\u00b7fer", "4", ",", "Ab\u00b7satz", "3."], "token_info": ["word", "number", "punct", "word", "number", "punct", "word", "ordinal"], "pos": ["NN", "CARD", "$,", "NN", "CARD", "$,", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00bbh\u00f6r mal, Willy \u2013 jetzt ists aus!", "tokens": ["\u00bb", "h\u00f6r", "mal", ",", "Wil\u00b7ly", "\u2013", "jetzt", "ists", "aus", "!"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "NE", "$(", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Noch ein f\u00fcnftes Kind hat keinen Platz im Haus!\u00ab", "tokens": ["Noch", "ein", "f\u00fcnf\u00b7tes", "Kind", "hat", "kei\u00b7nen", "Platz", "im", "Haus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "PIAT", "NN", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "\u00bbheul nicht, Liese, das hat keinen Sinn . . .", "tokens": ["\u00bb", "heul", "nicht", ",", "Lie\u00b7se", ",", "das", "hat", "kei\u00b7nen", "Sinn", ".", ".", "."], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADV", "PTKNEG", "$,", "NN", "$,", "PDS", "VAFIN", "PIAT", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "hier hast du ne Adresse \u2013 geh mal hin!\u00ab", "tokens": ["hier", "hast", "du", "ne", "Ad\u00b7res\u00b7se", "\u2013", "geh", "mal", "hin", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "$(", "VVFIN", "ADV", "PTKVZ", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Die Olsch, die macht das im Tarife \u2013", "tokens": ["Die", "Ol\u00b7sch", ",", "die", "macht", "das", "im", "Ta\u00b7ri\u00b7fe", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ART", "APPRART", "NN", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "aber schlecht \u2013 und die Frau geht ein.", "tokens": ["a\u00b7ber", "schlecht", "\u2013", "und", "die", "Frau", "geht", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Dann setzt es anonyme Briefe,", "tokens": ["Dann", "setzt", "es", "an\u00b7o\u00b7ny\u00b7me", "Brie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und vier Kinder sind nun ganz allein . . .", "tokens": ["und", "vier", "Kin\u00b7der", "sind", "nun", "ganz", "al\u00b7lein", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "ADV", "ADV", "ADV", "$.", "$.", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}}, "stanza.6": {"line.1": {"text": "Und unterdes \u2013", "tokens": ["Und", "un\u00b7ter\u00b7des", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJA", "$("], "meter": "-+--", "measure": "dactylic.init"}, "line.2": {"text": "da sitzen sie im Reichstagshaus", "tokens": ["da", "sit\u00b7zen", "sie", "im", "Reichs\u00b7tags\u00b7haus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und knobeln sich neue Gesetze aus \u2013", "tokens": ["und", "kno\u00b7beln", "sich", "neu\u00b7e", "Ge\u00b7set\u00b7ze", "aus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "F\u00fcr manche ist die Frau eine Milchmeierei \u2013", "tokens": ["F\u00fcr", "man\u00b7che", "ist", "die", "Frau", "ei\u00b7ne", "Milch\u00b7mei\u00b7e\u00b7rei", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "H\u00f6rt ihr den Schrei? H\u00f6rt ihr den Schrei?", "tokens": ["H\u00f6rt", "ihr", "den", "Schrei", "?", "H\u00f6rt", "ihr", "den", "Schrei", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "H\u00f6rt ihr den Schrei?", "tokens": ["H\u00f6rt", "ihr", "den", "Schrei", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Paragraph 5, Ziffer 4, Absatz 3.", "tokens": ["Pa\u00b7ra\u00b7gra\u00b7ph", "5", ",", "Zif\u00b7fer", "4", ",", "Ab\u00b7satz", "3."], "token_info": ["word", "number", "punct", "word", "number", "punct", "word", "ordinal"], "pos": ["NN", "CARD", "$,", "NN", "CARD", "$,", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Kleiner Dieb, der wird geh\u00e4ngt \u2013", "tokens": ["Klei\u00b7ner", "Dieb", ",", "der", "wird", "ge\u00b7h\u00e4ngt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "gro\u00dfer Verbrecher kriegt noch was geschenkt.", "tokens": ["gro\u00b7\u00dfer", "Ver\u00b7bre\u00b7cher", "kriegt", "noch", "was", "ge\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "PIS", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wer da ausbrennt Kriegessaat \u2013", "tokens": ["Wer", "da", "aus\u00b7brennt", "Krie\u00b7ges\u00b7saat", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "das nennt der Richter Landesverrat.", "tokens": ["das", "nennt", "der", "Rich\u00b7ter", "Lan\u00b7des\u00b7ver\u00b7rat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Zehntausend warten ungeduldig", "tokens": ["Zehn\u00b7tau\u00b7send", "war\u00b7ten", "un\u00b7ge\u00b7dul\u00b7dig"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "VAFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in den Zellen, geduckt wie ein Tier . . .", "tokens": ["in", "den", "Zel\u00b7len", ",", "ge\u00b7duckt", "wie", "ein", "Tier", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVPP", "KOKOM", "ART", "NN", "$.", "$.", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Die sind vorm Paragraphen schuldig", "tokens": ["Die", "sind", "vorm", "Pa\u00b7ra\u00b7gra\u00b7phen", "schul\u00b7dig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u2013 aber Menschen, Menschen wie wir! \u2013", "tokens": ["\u2013", "a\u00b7ber", "Men\u00b7schen", ",", "Men\u00b7schen", "wie", "wir", "!", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "NN", "$,", "NN", "KOKOM", "PPER", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Wach auf, wach auf, Barmherzigkeit!", "tokens": ["Wach", "auf", ",", "wach", "auf", ",", "Barm\u00b7her\u00b7zig\u00b7keit", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "ADJD", "PTKVZ", "$,", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein neuer Ton \u2013 eine neue Zeit!", "tokens": ["Ein", "neu\u00b7er", "Ton", "\u2013", "ei\u00b7ne", "neu\u00b7e", "Zeit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Recht und Recht sind immer zweierlei . . .", "tokens": ["Recht", "und", "Recht", "sind", "im\u00b7mer", "zwei\u00b7er\u00b7lei", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADV", "CARD", "$.", "$.", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "H\u00f6rt ihr den Schrei? H\u00f6rt ihr den Schrei?", "tokens": ["H\u00f6rt", "ihr", "den", "Schrei", "?", "H\u00f6rt", "ihr", "den", "Schrei", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "H\u00f6rt ihr den Schrei?", "tokens": ["H\u00f6rt", "ihr", "den", "Schrei", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Macht euch frei!", "tokens": ["Macht", "euch", "frei", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Macht euch frei!", "tokens": ["Macht", "euch", "frei", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Macht euch frei!", "tokens": ["Macht", "euch", "frei", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}