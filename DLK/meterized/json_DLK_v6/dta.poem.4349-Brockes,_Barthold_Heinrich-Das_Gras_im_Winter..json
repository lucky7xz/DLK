{"dta.poem.4349": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das Gras im Winter.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "An dem erhabnen Wall und neuen Vestungs-Werken,", "tokens": ["An", "dem", "er\u00b7hab\u00b7nen", "Wall", "und", "neu\u00b7en", "Ves\u00b7tungs\u00b7Wer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die, so wie es der Brauch, von Rasen aufgef\u00fchrt,", "tokens": ["Die", ",", "so", "wie", "es", "der", "Brauch", ",", "von", "Ra\u00b7sen", "auf\u00b7ge\u00b7f\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "KOKOM", "PPER", "ART", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "hab ich recht deutlich k\u00f6nnen merken,", "tokens": ["hab", "ich", "recht", "deut\u00b7lich", "k\u00f6n\u00b7nen", "mer\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Sie sich der Erden Kraft, auch selbst im Winter, r\u00fchrt.", "tokens": ["Sie", "sich", "der", "Er\u00b7den", "Kraft", ",", "auch", "selbst", "im", "Win\u00b7ter", ",", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "PRF", "ART", "NN", "NN", "$,", "ADV", "ADV", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "ich konnte ganz bequehm, und ohne mich zu b\u00fccken,", "tokens": ["ich", "konn\u00b7te", "ganz", "be\u00b7quehm", ",", "und", "oh\u00b7ne", "mich", "zu", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "$,", "KON", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "im Stehen, mit geraden Blicken,", "tokens": ["im", "Ste\u00b7hen", ",", "mit", "ge\u00b7ra\u00b7den", "Bli\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "in dem gesenkten Werk an Flanken und Cortinen,", "tokens": ["in", "dem", "ge\u00b7senk\u00b7ten", "Werk", "an", "Flan\u00b7ken", "und", "Cor\u00b7ti\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "auch in dem \u00f6fters noch beschneiten Gr\u00fcnen,", "tokens": ["auch", "in", "dem", "\u00f6f\u00b7ters", "noch", "be\u00b7schnei\u00b7ten", "Gr\u00fc\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.9": {"text": "doch hie und da bereits des Grases Wachsthum sehn.", "tokens": ["doch", "hie", "und", "da", "be\u00b7reits", "des", "Gra\u00b7ses", "Wach\u00b7sthum", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bewundernd sah ich es recht wunderbar entstehn.", "tokens": ["Be\u00b7wun\u00b7dernd", "sah", "ich", "es", "recht", "wun\u00b7der\u00b7bar", "ent\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "im Februario sah ich schon hie und dort", "tokens": ["im", "Feb\u00b7ru\u00b7a\u00b7rio", "sah", "ich", "schon", "hie", "und", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "von jungen Kr\u00e4utern zarte Sprossen,", "tokens": ["von", "jun\u00b7gen", "Kr\u00e4u\u00b7tern", "zar\u00b7te", "Spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "sind nahe bey, an einem andern Ort,", "tokens": ["sind", "na\u00b7he", "bey", ",", "an", "ei\u00b7nem", "an\u00b7dern", "Ort", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PTKVZ", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "kam kleiner Klee gemach hervorgeschossen.", "tokens": ["kam", "klei\u00b7ner", "Klee", "ge\u00b7mach", "her\u00b7vor\u00b7ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Oft sah ich durch ein kleines Ritzgen,", "tokens": ["Oft", "sah", "ich", "durch", "ein", "klei\u00b7nes", "Ritz\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "das kaum zu sehen war,", "tokens": ["das", "kaum", "zu", "se\u00b7hen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "in neu- gebohren Grases-Spitzgen,", "tokens": ["in", "neu", "ge\u00b7boh\u00b7ren", "Gra\u00b7ses\u00b7Spitz\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "So zart, als wie ein gr\u00fcnes Haar,", "tokens": ["So", "zart", ",", "als", "wie", "ein", "gr\u00fc\u00b7nes", "Haar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Sich sanft erheben, brechen, dringen.", "tokens": ["Sich", "sanft", "er\u00b7he\u00b7ben", ",", "bre\u00b7chen", ",", "drin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Es kamen diese Spitzgen mir,", "tokens": ["Es", "ka\u00b7men", "die\u00b7se", "Spitz\u00b7gen", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Zumahl sie mehrentheils gedoppelt waren, f\u00fcr,", "tokens": ["Zu\u00b7mahl", "sie", "meh\u00b7ren\u00b7theils", "ge\u00b7dop\u00b7pelt", "wa\u00b7ren", ",", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,", "APPR", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "als we&#241; das Kraut und Gras, nach Art der klugen Schnecken,", "tokens": ["als", "we", "&#241;", "das", "Kraut", "und", "Gras", ",", "nach", "Art", "der", "klu\u00b7gen", "Schne\u00b7cken", ","], "token_info": ["word", "word", "XML_entity", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$(", "ART", "NN", "KON", "NN", "$,", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "zwey kleine H\u00f6rnerchen in ihnen von sich strecken,", "tokens": ["zwey", "klei\u00b7ne", "H\u00f6r\u00b7ner\u00b7chen", "in", "ih\u00b7nen", "von", "sich", "stre\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "APPR", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "rum, obs schon f\u00fcr sie sicher, zu entdecken.", "tokens": ["rum", ",", "obs", "schon", "f\u00fcr", "sie", "si\u00b7cher", ",", "zu", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADV", "APPR", "PPER", "ADJD", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Indem ich hier vergn\u00fcget steh,", "tokens": ["In\u00b7dem", "ich", "hier", "ver\u00b7gn\u00fc\u00b7get", "steh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und spitzes Gras fast wachsen seh;", "tokens": ["und", "spit\u00b7zes", "Gras", "fast", "wach\u00b7sen", "seh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "U&#868;brblick ich, voller Freude, zwischen", "tokens": ["U", "&#868;", "brblick", "ich", ",", "vol\u00b7ler", "Freu\u00b7de", ",", "zwi\u00b7schen"], "token_info": ["word", "XML_entity", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["XY", "$(", "VVIMP", "PPER", "$,", "ADJA", "NN", "$,", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "verschiednen spitzen Grases B\u00fcschen", "tokens": ["ver\u00b7schied\u00b7nen", "spit\u00b7zen", "Gra\u00b7ses", "B\u00fc\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "auch rund belaubten jungen Klee.", "tokens": ["auch", "rund", "be\u00b7laub\u00b7ten", "jun\u00b7gen", "Klee", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die s\u00fcsse Bildung reizte mich,", "tokens": ["Die", "s\u00fcs\u00b7se", "Bil\u00b7dung", "reiz\u00b7te", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf seine Form\u2019, wenn er entsteht, zu achten,", "tokens": ["Auf", "sei\u00b7ne", "Form'", ",", "wenn", "er", "ent\u00b7steht", ",", "zu", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und recht, auf welche Art er sich", "tokens": ["Und", "recht", ",", "auf", "wel\u00b7che", "Art", "er", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "APPR", "PWAT", "NN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus seiner Mutter Schoo\u00df erhebet, zu betrachten.", "tokens": ["Aus", "sei\u00b7ner", "Mut\u00b7ter", "Schoo\u00df", "er\u00b7he\u00b7bet", ",", "zu", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da ich denn, mit Verwundrung, fand,", "tokens": ["Da", "ich", "denn", ",", "mit", "Ver\u00b7wund\u00b7rung", ",", "fand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df jedes Blatt sich in der Mitte bieget,", "tokens": ["Da\u00df", "je\u00b7des", "Blatt", "sich", "in", "der", "Mit\u00b7te", "bie\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und so verschr\u00e4nkt zusammenf\u00fcget,", "tokens": ["Und", "so", "ver\u00b7schr\u00e4nkt", "zu\u00b7sam\u00b7men\u00b7f\u00fc\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df alle drey kaum breiter als der Stiel.", "tokens": ["Da\u00df", "al\u00b7le", "drey", "kaum", "brei\u00b7ter", "als", "der", "Stiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "CARD", "ADV", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Wodurch mir denn zugleich, woher", "tokens": ["Wo\u00b7durch", "mir", "denn", "zu\u00b7gleich", ",", "wo\u00b7her"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "ADV", "ADV", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Strich in aller Bl\u00e4tter Mitten,", "tokens": ["Ein", "Strich", "in", "al\u00b7ler", "Bl\u00e4t\u00b7ter", "Mit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Als w\u00e4r er eingekerbt und gleichsam eingeschnitlen,", "tokens": ["Als", "w\u00e4r", "er", "ein\u00b7ge\u00b7kerbt", "und", "gleich\u00b7sam", "ein\u00b7ge\u00b7schnit\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "VVPP", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Jm Klee sich immer zeigt, mir in die Augen fiel,", "tokens": ["Jm", "Klee", "sich", "im\u00b7mer", "zeigt", ",", "mir", "in", "die", "Au\u00b7gen", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "ADV", "VVFIN", "$,", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und da\u00df es nicht von ungefehr.", "tokens": ["Und", "da\u00df", "es", "nicht", "von", "un\u00b7ge\u00b7fehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "APPR", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Ich ward hiebey noch mehr gewahr,", "tokens": ["Ich", "ward", "hie\u00b7bey", "noch", "mehr", "ge\u00b7wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So ich vorhero nicht beachtet,", "tokens": ["So", "ich", "vor\u00b7he\u00b7ro", "nicht", "be\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "Ob ich gleich \u00f6fters Gras betrachtet,", "tokens": ["Ob", "ich", "gleich", "\u00f6f\u00b7ters", "Gras", "be\u00b7trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Da\u00df solch ein tiefer Strich so gar", "tokens": ["Da\u00df", "solch", "ein", "tie\u00b7fer", "Strich", "so", "gar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "ART", "ADJA", "NN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "In jedem Spierchen Gras sich zeiget,", "tokens": ["In", "je\u00b7dem", "Spier\u00b7chen", "Gras", "sich", "zei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Weil jedes Spierchen Gras, um besser durchzubrechen,", "tokens": ["Weil", "je\u00b7des", "Spier\u00b7chen", "Gras", ",", "um", "bes\u00b7ser", "durch\u00b7zu\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "$,", "KOUI", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und durch die Erde sich zu stechen,", "tokens": ["Und", "durch", "die", "Er\u00b7de", "sich", "zu", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Gefaltet aus dem Boden steiget.", "tokens": ["Ge\u00b7fal\u00b7tet", "aus", "dem", "Bo\u00b7den", "stei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Daher, wenn es nachher sich weiter treibt,", "tokens": ["Da\u00b7her", ",", "wenn", "es", "nach\u00b7her", "sich", "wei\u00b7ter", "treibt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "ADV", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Der Strich doch allezeit darinn verbleibt.", "tokens": ["Der", "Strich", "doch", "al\u00b7le\u00b7zeit", "da\u00b7rinn", "ver\u00b7bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wie ich neulich die Betrachtung von der Erden Schmuck,", "tokens": ["Wie", "ich", "neu\u00b7lich", "die", "Be\u00b7trach\u00b7tung", "von", "der", "Er\u00b7den", "Schmuck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "dem Grase,", "tokens": ["dem", "Gra\u00b7se", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Da ich selbst im Grase sa\u00df, auch die andern, \u00fcberlase;", "tokens": ["Da", "ich", "selbst", "im", "Gra\u00b7se", "sa\u00df", ",", "auch", "die", "an\u00b7dern", ",", "\u00fc\u00b7ber\u00b7la\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,", "ADV", "ART", "ADJA", "$,", "VVFIN", "$."], "meter": "--+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Fand ich zwar, da\u00df von demselben was verhandelt, doch", "tokens": ["Fand", "ich", "zwar", ",", "da\u00df", "von", "dem\u00b7sel\u00b7ben", "was", "ver\u00b7han\u00b7delt", ",", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "APPR", "PDAT", "PWS", "VVFIN", "$,", "ADV"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "dabey,", "tokens": ["da\u00b7bey", ","], "token_info": ["word", "punct"], "pos": ["PAV", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Da\u00df in diesem Wunder-Kraut mehr noch zu bewundern sey.", "tokens": ["Da\u00df", "in", "die\u00b7sem", "Wun\u00b7der\u00b7Kraut", "mehr", "noch", "zu", "be\u00b7wun\u00b7dern", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PDAT", "NN", "ADV", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.5": {"line.1": {"text": "Wie es angenehm bebl\u00fchmet, wie die Farbe gr\u00fcn und", "tokens": ["Wie", "es", "an\u00b7ge\u00b7nehm", "be\u00b7bl\u00fch\u00b7met", ",", "wie", "die", "Far\u00b7be", "gr\u00fcn", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADJD", "VVFIN", "$,", "PWAV", "ART", "NN", "ADJD", "KON"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "sch\u00f6n,", "tokens": ["sch\u00f6n", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Wie es Vieh und Thiere n\u00e4hre, haben wir, mit Lust,", "tokens": ["Wie", "es", "Vieh", "und", "Thie\u00b7re", "n\u00e4h\u00b7re", ",", "ha\u00b7ben", "wir", ",", "mit", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "KON", "NN", "VVFIN", "$,", "VAFIN", "PPER", "$,", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "gesehn.", "tokens": ["ge\u00b7sehn", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Aber, da\u00df es wunderbarlich nicht nur Milch und Fleisch", "tokens": ["A\u00b7ber", ",", "da\u00df", "es", "wun\u00b7der\u00b7bar\u00b7lich", "nicht", "nur", "Milch", "und", "Fleisch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "PPER", "ADJD", "PTKNEG", "ADV", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.6": {"text": "uns zolle,", "tokens": ["uns", "zol\u00b7le", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Sondern Kleider, Str\u00fcmpf\u2019 und Schuh\u2019, da es gar in", "tokens": ["Son\u00b7dern", "Klei\u00b7der", ",", "Str\u00fcmpf'", "und", "Schuh'", ",", "da", "es", "gar", "in"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "$,", "KOUS", "PPER", "ADV", "APPR"], "meter": "+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.8": {"text": "Leder, Wolle,", "tokens": ["Le\u00b7der", ",", "Wol\u00b7le", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Horn und Federn sich verwandelt; dieses hatt\u2019 ich nicht", "tokens": ["Horn", "und", "Fe\u00b7dern", "sich", "ver\u00b7wan\u00b7delt", ";", "die\u00b7ses", "hatt'", "ich", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "PRF", "VVPP", "$.", "PDS", "VAFIN", "PPER", "PTKNEG"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.10": {"text": "bedacht,", "tokens": ["be\u00b7dacht", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.11": {"text": "Sondern nur desselben Sch\u00f6nheit, Bildung, Farbe, Glanz", "tokens": ["Son\u00b7dern", "nur", "des\u00b7sel\u00b7ben", "Sch\u00f6n\u00b7heit", ",", "Bil\u00b7dung", ",", "Far\u00b7be", ",", "Glanz"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["KON", "ADV", "PDAT", "NN", "$,", "NN", "$,", "NN", "$,", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.12": {"text": "und Pracht.", "tokens": ["und", "Pracht", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.6": {"line.1": {"text": "La\u00df uns denn, geliebter Leser, die\u00df ein wenig \u00fcberdenken!", "tokens": ["La\u00df", "uns", "denn", ",", "ge\u00b7lieb\u00b7ter", "Le\u00b7ser", ",", "die\u00df", "ein", "we\u00b7nig", "\u00fc\u00b7ber\u00b7den\u00b7ken", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "ADJA", "NN", "$,", "PDS", "ART", "PIS", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "La\u00df uns unsers Geistes Kraft auf des Nutzens Menge", "tokens": ["La\u00df", "uns", "un\u00b7sers", "Geis\u00b7tes", "Kraft", "auf", "des", "Nut\u00b7zens", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "NN", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "lenken,", "tokens": ["len\u00b7ken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Die ein liebreich- weises Wesen in so kleinen Platz zu", "tokens": ["Die", "ein", "lieb\u00b7reich", "wei\u00b7ses", "We\u00b7sen", "in", "so", "klei\u00b7nen", "Platz", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "TRUNC", "ADJA", "NN", "APPR", "ADV", "ADJA", "NN", "PTKZU"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.5": {"text": "schr\u00e4nken,", "tokens": ["schr\u00e4n\u00b7ken", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "In ein so ver\u00e4chtlich Kraut die Beschaffenheit zu senken,", "tokens": ["In", "ein", "so", "ver\u00b7\u00e4cht\u00b7lich", "Kraut", "die", "Be\u00b7schaf\u00b7fen\u00b7heit", "zu", "sen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJD", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Voller Huld, entschlossen hat, wof\u00fcr man Jhn billig", "tokens": ["Vol\u00b7ler", "Huld", ",", "ent\u00b7schlos\u00b7sen", "hat", ",", "wo\u00b7f\u00fcr", "man", "Jhn", "bil\u00b7lig"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVPP", "VAFIN", "$,", "PWAV", "PIS", "PPER", "ADJD"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.8": {"text": "ehret.", "tokens": ["eh\u00b7ret", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "Da es sich in alles fast, was uns kleidet, was uns n\u00e4hret,", "tokens": ["Da", "es", "sich", "in", "al\u00b7les", "fast", ",", "was", "uns", "klei\u00b7det", ",", "was", "uns", "n\u00e4h\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PIS", "ADV", "$,", "PRELS", "PPER", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.10": {"text": "Und Bequehmlichkeit verschafft, recht verwunderlich ver-", "tokens": ["Und", "Be\u00b7quehm\u00b7lich\u00b7keit", "ver\u00b7schafft", ",", "recht", "ver\u00b7wun\u00b7der\u00b7lich", "ver"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VVPP", "$,", "ADV", "ADJD", "TRUNC"], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "kehret.", "tokens": ["keh\u00b7ret", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "Sollt\u2019 ein Baum an einem Ort etwan anzutreffen seyn,", "tokens": ["Sollt'", "ein", "Baum", "an", "ei\u00b7nem", "Ort", "et\u00b7wan", "an\u00b7zu\u00b7tref\u00b7fen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "APPR", "ART", "NN", "ADV", "VVIZU", "VAINF", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Der so viele, so verschiedne, und so n\u00f6htge Fr\u00fcchte br\u00e4chte;", "tokens": ["Der", "so", "vie\u00b7le", ",", "so", "ver\u00b7schied\u00b7ne", ",", "und", "so", "n\u00f6ht\u00b7ge", "Fr\u00fcch\u00b7te", "br\u00e4ch\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "$,", "ADV", "ADJA", "$,", "KON", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "So eracht\u2019 ich, da\u00df man es als ein Wunderwerk bed\u00e4chte.", "tokens": ["So", "er\u00b7acht'", "ich", ",", "da\u00df", "man", "es", "als", "ein", "Wun\u00b7der\u00b7werk", "be\u00b7d\u00e4ch\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "PPER", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Alles aber tr\u00e4gt nicht nur unser liebes Gras allein,", "tokens": ["Al\u00b7les", "a\u00b7ber", "tr\u00e4gt", "nicht", "nur", "un\u00b7ser", "lie\u00b7bes", "Gras", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVFIN", "PTKNEG", "ADV", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.5": {"text": "Sondern es ist nicht zu z\u00e4hlen, wie von ungez\u00e4hlten", "tokens": ["Son\u00b7dern", "es", "ist", "nicht", "zu", "z\u00e4h\u00b7len", ",", "wie", "von", "un\u00b7ge\u00b7z\u00e4hl\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,", "PWAV", "APPR", "ADJA"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.6": {"text": "Dingen,", "tokens": ["Din\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Allen Thieren, allen Menschen, G\u00fcter aus dem Gras", "tokens": ["Al\u00b7len", "Thie\u00b7ren", ",", "al\u00b7len", "Men\u00b7schen", ",", "G\u00fc\u00b7ter", "aus", "dem", "Gras"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.8": {"text": "entspringen.", "tokens": ["ent\u00b7sprin\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.8": {"line.1": {"text": "La\u00dft uns k\u00fcnftig denn, wenn wir Gras auf unsern Wie-", "tokens": ["La\u00dft", "uns", "k\u00fcnf\u00b7tig", "denn", ",", "wenn", "wir", "Gras", "auf", "un\u00b7sern", "Wie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADJD", "KON", "$,", "KOUS", "PPER", "NN", "APPR", "PPOSAT", "TRUNC"], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "sen sehn,", "tokens": ["sen", "sehn", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Nicht allein, wie es so lieblich, gl\u00e4nzend, zierlich, bunt und", "tokens": ["Nicht", "al\u00b7lein", ",", "wie", "es", "so", "lieb\u00b7lich", ",", "gl\u00e4n\u00b7zend", ",", "zier\u00b7lich", ",", "bunt", "und"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["PTKNEG", "ADV", "$,", "PWAV", "PPER", "ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "sch\u00f6n,", "tokens": ["sch\u00f6n", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Mit erfreutem Blick, betrachten, sondern GOtt darinn", "tokens": ["Mit", "er\u00b7freu\u00b7tem", "Blick", ",", "be\u00b7trach\u00b7ten", ",", "son\u00b7dern", "Gott", "da\u00b7rinn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "VVFIN", "$,", "KON", "NN", "PAV"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.6": {"text": "erkennen,", "tokens": ["er\u00b7ken\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Der uns ungez\u00e4hlte G\u00fcter in dem Grase wollen g\u00f6nnen!", "tokens": ["Der", "uns", "un\u00b7ge\u00b7z\u00e4hl\u00b7te", "G\u00fc\u00b7ter", "in", "dem", "Gra\u00b7se", "wol\u00b7len", "g\u00f6n\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJA", "NN", "APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Der in diese Segens-Pflanze Selbst Sich gleichsam sicht-", "tokens": ["Der", "in", "die\u00b7se", "Se\u00b7gens\u00b7Pflan\u00b7ze", "Selbst", "Sich", "gleich\u00b7sam", "sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PDAT", "NN", "ADV", "PRF", "ADJD", "TRUNC"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.9": {"text": "bar macht,", "tokens": ["bar", "macht", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.10": {"text": "Und in diesem Wunder-Kraut,", "tokens": ["Und", "in", "die\u00b7sem", "Wun\u00b7der\u00b7Kraut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Welches Er, ohn\u2019 unser Zuthun, giebt und gleichsam Selber", "tokens": ["Wel\u00b7ches", "Er", ",", "ohn'", "un\u00b7ser", "Zu\u00b7thun", ",", "giebt", "und", "gleich\u00b7sam", "Sel\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "$,", "KOUI", "PPOSAT", "NN", "$,", "VVFIN", "KON", "ADJD", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.12": {"text": "baut,", "tokens": ["baut", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.13": {"text": "Eine solche Weis\u2019 erdacht,", "tokens": ["Ei\u00b7ne", "sol\u00b7che", "Weis'", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "Und in seine zarte Fiebern eine Wohlfahrts-Quell\u2019 gesen-", "tokens": ["Und", "in", "sei\u00b7ne", "zar\u00b7te", "Fie\u00b7bern", "ei\u00b7ne", "Wohl\u00b7fahrts\u00b7Quell'", "ge\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "TRUNC"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.15": {"text": "ket,", "tokens": ["ket", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.16": {"text": "Wodurch Er dem ganzen Thier-Reich Leben und Erhaltung", "tokens": ["Wo\u00b7durch", "Er", "dem", "gan\u00b7zen", "Thier\u00b7Reich", "Le\u00b7ben", "und", "Er\u00b7hal\u00b7tung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.17": {"text": "schenket.", "tokens": ["schen\u00b7ket", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.9": {"line.1": {"text": "Schenke, wunderbarer GOtt, denn auch uns Bedacht,", "tokens": ["Schen\u00b7ke", ",", "wun\u00b7der\u00b7ba\u00b7rer", "Gott", ",", "denn", "auch", "uns", "Be\u00b7dacht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "KON", "ADV", "PPER", "NN", "$,"], "meter": "+-+-+-+-++-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Erkenntni\u00df!", "tokens": ["Er\u00b7kennt\u00b7ni\u00df", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Sende Selbst in unsre Seelen Ueberlegung und Verst\u00e4nd-", "tokens": ["Sen\u00b7de", "Selbst", "in", "uns\u00b7re", "See\u00b7len", "Ue\u00b7ber\u00b7le\u00b7gung", "und", "Ver\u00b7st\u00e4n\u00b7d"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "NN", "KON", "TRUNC"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "ni\u00df,", "tokens": ["ni\u00df", ","], "token_info": ["word", "punct"], "pos": ["PTKANT", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Dank, Erkenntlichkeit, Bewundrung! La\u00df uns nimmer", "tokens": ["Dank", ",", "Er\u00b7kennt\u00b7lich\u00b7keit", ",", "Be\u00b7wund\u00b7rung", "!", "La\u00df", "uns", "nim\u00b7mer"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$.", "VVIMP", "PPER", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "m\u00fcde werden", "tokens": ["m\u00fc\u00b7de", "wer\u00b7den"], "token_info": ["word", "word"], "pos": ["ADJD", "VAINF"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "In den uns von Dir gezeigten Wunder-Werken dieser", "tokens": ["In", "den", "uns", "von", "Dir", "ge\u00b7zeig\u00b7ten", "Wun\u00b7der\u00b7Wer\u00b7ken", "die\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PPER", "APPR", "PPER", "ADJA", "NN", "PDAT"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.8": {"text": "Erden,", "tokens": ["Er\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "In den herrlichen Gesch\u00f6pfen, die so n\u00fctzlich, die so sch\u00f6n,", "tokens": ["In", "den", "herr\u00b7li\u00b7chen", "Ge\u00b7sch\u00f6p\u00b7fen", ",", "die", "so", "n\u00fctz\u00b7lich", ",", "die", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ADJD", "$,", "PRELS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.10": {"text": "Dich allein, in froher Andacht, als die Urquell\u2019 anzu-", "tokens": ["Dich", "al\u00b7lein", ",", "in", "fro\u00b7her", "An\u00b7dacht", ",", "als", "die", "Ur\u00b7quell'", "an\u00b7zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "$,", "APPR", "ADJA", "NN", "$,", "KOUS", "ART", "NN", "TRUNC"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.11": {"text": "sehn!", "tokens": ["sehn", "!"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+", "measure": "single.up"}, "line.12": {"text": "La\u00df uns, in verg\u00f6nnter Lust, durch der C\u00f6rper Bau ge-", "tokens": ["La\u00df", "uns", ",", "in", "ver\u00b7g\u00f6nn\u00b7ter", "Lust", ",", "durch", "der", "C\u00f6r\u00b7per", "Bau", "ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "TRUNC"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.13": {"text": "r\u00fchrt,", "tokens": ["r\u00fchrt", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+", "measure": "single.up"}, "line.14": {"text": "Zu derselben grossen Meister, blo\u00df allein zu Dir gef\u00fchrt,", "tokens": ["Zu", "der\u00b7sel\u00b7ben", "gros\u00b7sen", "Meis\u00b7ter", ",", "blo\u00df", "al\u00b7lein", "zu", "Dir", "ge\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "ADV", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.10": {"line.1": {"text": "Und, absonderlich beym Grase, uns, mit frohem Ernst,", "tokens": ["Und", ",", "ab\u00b7son\u00b7der\u00b7lich", "beym", "Gra\u00b7se", ",", "uns", ",", "mit", "fro\u00b7hem", "Ernst", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "APPRART", "NN", "$,", "PPER", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "bestreben,", "tokens": ["be\u00b7stre\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Jm Gesch\u00f6pf Dich, seinen Sch\u00f6pfer, recht von Herzen zu", "tokens": ["Jm", "Ge\u00b7sch\u00f6pf", "Dich", ",", "sei\u00b7nen", "Sch\u00f6p\u00b7fer", ",", "recht", "von", "Her\u00b7zen", "zu"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PPER", "$,", "PPOSAT", "NN", "$,", "ADJD", "APPR", "NN", "PTKZU"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.4": {"text": "erheben,", "tokens": ["er\u00b7he\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Dir, nach aller M\u00f6glichkeit, Ehre, Preis und Dank zu", "tokens": ["Dir", ",", "nach", "al\u00b7ler", "M\u00f6g\u00b7lich\u00b7keit", ",", "Eh\u00b7re", ",", "Preis", "und", "Dank", "zu"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "APPR", "PIAT", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "PTKZU"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.6": {"text": "geben,", "tokens": ["ge\u00b7ben", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Und, aus kindlichem Vertrauen, wie Du es verlangst, zu", "tokens": ["Und", ",", "aus", "kind\u00b7li\u00b7chem", "Ver\u00b7trau\u00b7en", ",", "wie", "Du", "es", "ver\u00b7langst", ",", "zu"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "$,", "APPR", "ADJA", "NN", "$,", "PWAV", "PPER", "PPER", "VVFIN", "$,", "APPR"], "meter": "--+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "leben.", "tokens": ["le\u00b7ben", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}}}}