{"dta.poem.3799": {"metadata": {"author": {"name": "Spindler, Christian Gotthold", "birth": "N.A.", "death": "N.A."}, "title": "Die Liebe zu Allerley,  \n oder ein Quodlibet.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1745", "urn": "urn:nbn:de:kobv:b4-20581-9", "language": ["de:0.99"], "booktitle": "Spindler, Christian Gotthold: Unschuldige Jugend-Fr\u00fcchte. Leipzig, 1745."}, "poem": {"stanza.1": {"line.1": {"text": "Herr Schwager, du verlangst von mir", "tokens": ["Herr", "Schwa\u00b7ger", ",", "du", "ver\u00b7langst", "von", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "PPER", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Voritzt ein Allerley zu lesen:", "tokens": ["Vo\u00b7ritzt", "ein", "Al\u00b7ler\u00b7ley", "zu", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcnff Jahre bist du schon nicht hier", "tokens": ["F\u00fcnff", "Jah\u00b7re", "bist", "du", "schon", "nicht", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In unserm alten Ort gewesen.", "tokens": ["In", "un\u00b7serm", "al\u00b7ten", "Ort", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wohlan, ich folge meiner Pflicht,", "tokens": ["Wo\u00b7hlan", ",", "ich", "fol\u00b7ge", "mei\u00b7ner", "Pflicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und thu dirs zu Gefallen,", "tokens": ["Und", "thu", "dirs", "zu", "Ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ich wei\u00df schon, du verschm\u00e4hest nicht", "tokens": ["Ich", "wei\u00df", "schon", ",", "du", "ver\u00b7schm\u00e4\u00b7hest", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mein Allerley von allen.", "tokens": ["Mein", "Al\u00b7ler\u00b7ley", "von", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Herr Bruder, ach bedencke doch", "tokens": ["Herr", "Bru\u00b7der", ",", "ach", "be\u00b7den\u00b7cke", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NN", "$,", "ITJ", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die alte Marcipille,", "tokens": ["Die", "al\u00b7te", "Mar\u00b7ci\u00b7pil\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das alte Fell lebt immer noch,", "tokens": ["Das", "al\u00b7te", "Fell", "lebt", "im\u00b7mer", "noch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und kuppelt in der Stille.", "tokens": ["Und", "kup\u00b7pelt", "in", "der", "Stil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ist das nicht eine grosse Noth,", "tokens": ["Ist", "das", "nicht", "ei\u00b7ne", "gros\u00b7se", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Geh doch, du alter Sch\u00e4cker,", "tokens": ["Geh", "doch", ",", "du", "al\u00b7ter", "Sch\u00e4\u00b7cker", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Es heist: i\u00df fein viel Zucker-Brod,", "tokens": ["Es", "heist", ":", "i\u00df", "fein", "viel", "Zu\u00b7cke\u00b7rBrod", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADV", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und lauf zum Apothecker.", "tokens": ["Und", "lauf", "zum", "A\u00b7pot\u00b7hec\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da schickt mich meine Schwester her", "tokens": ["Da", "schickt", "mich", "mei\u00b7ne", "Schwes\u00b7ter", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit einem guten Tage,", "tokens": ["Mit", "ei\u00b7nem", "gu\u00b7ten", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das arme Kind hinckt itzo sehr,", "tokens": ["Das", "ar\u00b7me", "Kind", "hinckt", "it\u00b7zo", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ist ja eine Plage.", "tokens": ["Das", "ist", "ja", "ei\u00b7ne", "Pla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Seyd aber auch nicht theuer,", "tokens": ["Seyd", "a\u00b7ber", "auch", "nicht", "theu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADV", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Es brennt dem armen Ding das Hertz", "tokens": ["Es", "brennt", "dem", "ar\u00b7men", "Ding", "das", "Hertz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als wie pur lauter Feuer.", "tokens": ["Als", "wie", "pur", "lau\u00b7ter", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ADJD", "PIAT", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Ey, liebe Jungfer, o! mit Gunst,", "tokens": ["Ey", ",", "lie\u00b7be", "Jung\u00b7fer", ",", "o", "!", "mit", "Gunst", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "FM", "$.", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jhr solt es schon erfahren,", "tokens": ["Ihr", "solt", "es", "schon", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich will mit meiner grossen Kunst", "tokens": ["Ich", "will", "mit", "mei\u00b7ner", "gros\u00b7sen", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht das geringste spahren.", "tokens": ["Nicht", "das", "ge\u00b7rings\u00b7te", "spah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Hier habt ihr eine Portion", "tokens": ["Hier", "habt", "ihr", "ei\u00b7ne", "Por\u00b7ti\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von neun und achtzig Pillen,", "tokens": ["Von", "neun", "und", "acht\u00b7zig", "Pil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "KON", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da, Jungfer, die ", "tokens": ["Da", ",", "Jung\u00b7fer", ",", "die"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["ADV", "$,", "NE", "$,", "PRELS"], "meter": "-+--", "measure": "dactylic.init"}, "line.8": {"text": "Das wird den Schmertzen stillen.", "tokens": ["Das", "wird", "den", "Schmert\u00b7zen", "stil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Bey uns sieht es gar windig aus,", "tokens": ["Bey", "uns", "sieht", "es", "gar", "win\u00b7dig", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Man geht nicht mehr zum Biere.", "tokens": ["Man", "geht", "nicht", "mehr", "zum", "Bie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sonst kam man von dem guten Schmaus", "tokens": ["Sonst", "kam", "man", "von", "dem", "gu\u00b7ten", "Schmaus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht eher als um Viere.", "tokens": ["Nicht", "e\u00b7her", "als", "um", "Vie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch, wenn es uns am Besten fehlt,", "tokens": ["Doch", ",", "wenn", "es", "uns", "am", "Bes\u00b7ten", "fehlt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So mangeln auch die H\u00fcner.", "tokens": ["So", "man\u00b7geln", "auch", "die", "H\u00fc\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wie steht es um das liebe Geld?", "tokens": ["Wie", "steht", "es", "um", "das", "lie\u00b7be", "Geld", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mein Herr, ich bin sein Diener.", "tokens": ["Mein", "Herr", ",", "ich", "bin", "sein", "Die\u00b7ner", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ach lieber Herr! ach lieber Herr!", "tokens": ["Ach", "lie\u00b7ber", "Herr", "!", "ach", "lie\u00b7ber", "Herr", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "NN", "$.", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo bleibt doch unser Bote?", "tokens": ["Wo", "bleibt", "doch", "un\u00b7ser", "Bo\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "O! wenn er schon gekommen w\u00e4r,", "tokens": ["O", "!", "wenn", "er", "schon", "ge\u00b7kom\u00b7men", "w\u00e4r", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst gr\u00e4m ich mich zu Tode.", "tokens": ["Sonst", "gr\u00e4m", "ich", "mich", "zu", "To\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es heisset: mach nunmehr ", "tokens": ["Es", "heis\u00b7set", ":", "mach", "nun\u00b7mehr"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Da hilfft kein langes Kratzen,", "tokens": ["Da", "hilfft", "kein", "lan\u00b7ges", "Krat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der Bote bringet alles mit,", "tokens": ["Der", "Bo\u00b7te", "brin\u00b7get", "al\u00b7les", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Zumahl ein S\u00e4ckgen Batzen.", "tokens": ["Zu\u00b7mahl", "ein", "S\u00e4ck\u00b7gen", "Bat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Katze l\u00e4\u00dft das Naschen nicht,", "tokens": ["Die", "Kat\u00b7ze", "l\u00e4\u00dft", "das", "Na\u00b7schen", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gleichwie der Hund das Bellen.", "tokens": ["Gleich\u00b7wie", "der", "Hund", "das", "Bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Monsieur, hier ist ein Inselt-Licht.", "tokens": ["Mon\u00b7si\u00b7eur", ",", "hier", "ist", "ein", "In\u00b7sel\u00b7tLicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM", "$,", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wer wird sich so verstellen?", "tokens": ["Wer", "wird", "sich", "so", "ver\u00b7stel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Zumahl bey Menuween.", "tokens": ["Zu\u00b7mahl", "bey", "Me\u00b7nu\u00b7we\u00b7en", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Geh nur, du garstig b\u00f6ses Ding,", "tokens": ["Geh", "nur", ",", "du", "gars\u00b7tig", "b\u00f6\u00b7ses", "Ding", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich kan dich nicht ersehen.", "tokens": ["Ich", "kan", "dich", "nicht", "er\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Der Dachs im Loche beist den Hund,", "tokens": ["Der", "Dachs", "im", "Lo\u00b7che", "beist", "den", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab es nechst gelesen.", "tokens": ["Ich", "hab", "es", "nechst", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ey kleiner, halte dich recht rund,", "tokens": ["Ey", "klei\u00b7ner", ",", "hal\u00b7te", "dich", "recht", "rund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mach kein grosses Wesen.", "tokens": ["Und", "mach", "kein", "gros\u00b7ses", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das Ding geht so ohnm\u00f6glich an,", "tokens": ["Das", "Ding", "geht", "so", "ohn\u00b7m\u00f6g\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wer kan denn alles riechen?", "tokens": ["Wer", "kan", "denn", "al\u00b7les", "rie\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Nechst hat mir auch des Nachbars Hahn", "tokens": ["Nechst", "hat", "mir", "auch", "des", "Nach\u00b7bars", "Hahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mein H\u00fcner-Haus bestiegen.", "tokens": ["Mein", "H\u00fc\u00b7ner\u00b7Haus", "be\u00b7stie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ein alter Mann, ein junges Weib", "tokens": ["Ein", "al\u00b7ter", "Mann", ",", "ein", "jun\u00b7ges", "Weib"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind l\u00e4cherliche Dinge.", "tokens": ["Sind", "l\u00e4\u00b7cher\u00b7li\u00b7che", "Din\u00b7ge", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Fluchs, Junge, siehe her und schreib,", "tokens": ["Fluchs", ",", "Jun\u00b7ge", ",", "sie\u00b7he", "her", "und", "schreib", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVIMP", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df ichs zu Stande bringe.", "tokens": ["Da\u00df", "ichs", "zu", "Stan\u00b7de", "brin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ey sage doch, was heist denn das?", "tokens": ["Ey", "sa\u00b7ge", "doch", ",", "was", "heist", "denn", "das", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "$,", "PWS", "VVFIN", "KON", "PDS", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wo mu\u00df Herr Einfalt stecken?", "tokens": ["Wo", "mu\u00df", "Herr", "Ein\u00b7falt", "ste\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dort steht er bey dem Syrup-Fa\u00df,", "tokens": ["Dort", "steht", "er", "bey", "dem", "Sy\u00b7rup\u00b7Fa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und wird den Deckel lecken.", "tokens": ["Und", "wird", "den", "De\u00b7ckel", "le\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "En quaeso, ergo itaque,", "tokens": ["En", "qua\u00b7e\u00b7so", ",", "er\u00b7go", "i\u00b7ta\u00b7que", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$,", "FM.la", "FM.la", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So sange der Schulmeister.", "tokens": ["So", "san\u00b7ge", "der", "Schul\u00b7meis\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Quid agunt nostrae Foeminae?", "tokens": ["Quid", "a\u00b7gunt", "nost\u00b7rae", "Fo\u00b7e\u00b7mi\u00b7nae", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sie pr\u00fcfen eure Geister.", "tokens": ["Sie", "pr\u00fc\u00b7fen", "eu\u00b7re", "Geis\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ach heuer ists gantz wohl bestellt,", "tokens": ["Ach", "heu\u00b7er", "ists", "gantz", "wohl", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Haber giebt viel K\u00f6rner.", "tokens": ["Der", "Ha\u00b7ber", "giebt", "viel", "K\u00f6r\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Was machen Weiber in der Welt?", "tokens": ["Was", "ma\u00b7chen", "Wei\u00b7ber", "in", "der", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Responsio: Viel H\u00f6rner.", "tokens": ["Res\u00b7pon\u00b7sio", ":", "Viel", "H\u00f6r\u00b7ner", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Nechst sagte Frau Pomponia:", "tokens": ["Nechst", "sag\u00b7te", "Frau", "Pom\u00b7po\u00b7nia", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Schatz! ich werd balde sterben,", "tokens": ["Schatz", "!", "ich", "werd", "bal\u00b7de", "ster\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich mercke nun, mein End ist da,", "tokens": ["Ich", "mer\u00b7cke", "nun", ",", "mein", "End", "ist", "da", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun solst du alles erben.", "tokens": ["Nun", "solst", "du", "al\u00b7les", "er\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Schatz! sprach er, sterbe lieber jung,", "tokens": ["Schatz", "!", "sprach", "er", ",", "ster\u00b7be", "lie\u00b7ber", "jung", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "$,", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich will dich gl\u00fccklich preisen,", "tokens": ["Ich", "will", "dich", "gl\u00fcck\u00b7lich", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Denn, weist du deine Besserung,", "tokens": ["Denn", ",", "weist", "du", "dei\u00b7ne", "Bes\u00b7se\u00b7rung", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.8": {"text": "So magst du morgen reisen.", "tokens": ["So", "magst", "du", "mor\u00b7gen", "rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Ich wolte gerne bald f\u00fcrwahr", "tokens": ["Ich", "wol\u00b7te", "ger\u00b7ne", "bald", "f\u00fcr\u00b7wahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Sch\u00e4tzgen auch besuchen;", "tokens": ["Mein", "Sch\u00e4tz\u00b7gen", "auch", "be\u00b7su\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein die Gelder sind zu rar,", "tokens": ["Al\u00b7lein", "die", "Gel\u00b7der", "sind", "zu", "rar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Wie wird die Mutter fluchen!", "tokens": ["Wie", "wird", "die", "Mut\u00b7ter", "flu\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ach wohl, du gut und armes Kind,", "tokens": ["Ach", "wohl", ",", "du", "gut", "und", "ar\u00b7mes", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$,", "PPER", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich bin dir zwar gewogen,", "tokens": ["Ich", "bin", "dir", "zwar", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Allein wenn sich das Ende findt,", "tokens": ["Al\u00b7lein", "wenn", "sich", "das", "En\u00b7de", "findt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So bist du doch betrogen.", "tokens": ["So", "bist", "du", "doch", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "So wird er gar erschlagen.", "tokens": ["So", "wird", "er", "gar", "er\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und unsre vorge junge Magd", "tokens": ["Und", "uns\u00b7re", "vor\u00b7ge", "jun\u00b7ge", "Magd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird den ", "tokens": ["Wird", "den"], "token_info": ["word", "word"], "pos": ["VAFIN", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Wer wird wohl k\u00fcnfftig den ", "tokens": ["Wer", "wird", "wohl", "k\u00fcnff\u00b7tig", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADJD", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Vor einen Achter kauffen,", "tokens": ["Vor", "ei\u00b7nen", "Ach\u00b7ter", "kauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das thut dem Beutel gar zu weh,", "tokens": ["Das", "thut", "dem", "Beu\u00b7tel", "gar", "zu", "weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So mu\u00df man Raster sauffen.", "tokens": ["So", "mu\u00df", "man", "Ras\u00b7ter", "sauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Zu Neudorff ist ein junges Bild,", "tokens": ["Zu", "Neu\u00b7dorff", "ist", "ein", "jun\u00b7ges", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jhr k\u00f6nnt sie fast errathen,", "tokens": ["Ihr", "k\u00f6nnt", "sie", "fast", "er\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dieselbe ist sehr frech und wild,", "tokens": ["Die\u00b7sel\u00b7be", "ist", "sehr", "frech", "und", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00e4lt es mit Soldaten.", "tokens": ["Und", "h\u00e4lt", "es", "mit", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mein Kind! ich hab es selbst gesehn,", "tokens": ["Mein", "Kind", "!", "ich", "hab", "es", "selbst", "ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nunmehro vor acht Wochen,", "tokens": ["Nun\u00b7meh\u00b7ro", "vor", "acht", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Die liebe Mutter wird sie sch\u00f6n", "tokens": ["Die", "lie\u00b7be", "Mut\u00b7ter", "wird", "sie", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und nach der Kunst auspochen.", "tokens": ["Und", "nach", "der", "Kunst", "aus\u00b7po\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Was will der arme ", "tokens": ["Was", "will", "der", "ar\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Ist das ", "tokens": ["Ist", "das"], "token_info": ["word", "word"], "pos": ["VAFIN", "PDS"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Da ich nun auch ", "tokens": ["Da", "ich", "nun", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Was will der arme Herre?", "tokens": ["Was", "will", "der", "ar\u00b7me", "Her\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich bin vor ihn zu ", "tokens": ["Ich", "bin", "vor", "ihn", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "PTKZU"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Das walte doch der Himmel.", "tokens": ["Das", "wal\u00b7te", "doch", "der", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Der Hammer giebet harte St\u00f6\u00df.", "tokens": ["Der", "Ham\u00b7mer", "gie\u00b7bet", "har\u00b7te", "St\u00f6\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Geh nur, du Bauer-Limmel.", "tokens": ["Geh", "nur", ",", "du", "Bau\u00b7e\u00b7rLim\u00b7mel", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADV", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Wenn du zu Frauenzimmer gehst,", "tokens": ["Wenn", "du", "zu", "Frau\u00b7en\u00b7zim\u00b7mer", "gehst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sey doch nicht so verzumpen;", "tokens": ["Sey", "doch", "nicht", "so", "ver\u00b7zum\u00b7pen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn wenn du gar zu h\u00f6ckrigt stehst,", "tokens": ["Denn", "wenn", "du", "gar", "zu", "h\u00f6ck\u00b7rigt", "stehst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So kriegst du einen Stumpen.", "tokens": ["So", "kriegst", "du", "ei\u00b7nen", "Stum\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wohlan, so mache dich beliebt,", "tokens": ["Wo\u00b7hlan", ",", "so", "ma\u00b7che", "dich", "be\u00b7liebt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und thue gleich ein T\u00e4ntzgen.", "tokens": ["Und", "thue", "gleich", "ein", "T\u00e4ntz\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Sieh nur, wie steht hier so betr\u00fcbt", "tokens": ["Sieh", "nur", ",", "wie", "steht", "hier", "so", "be\u00b7tr\u00fcbt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "$,", "PWAV", "VVFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.17": {"line.1": {"text": "Wie es nun also bey uns geht,", "tokens": ["Wie", "es", "nun", "al\u00b7so", "bey", "uns", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das siehst du nun itzunder.", "tokens": ["Das", "siehst", "du", "nun", "it\u00b7zun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Herr Schwager, dieses Quodlibet", "tokens": ["Herr", "Schwa\u00b7ger", ",", "die\u00b7ses", "Quod\u00b7li\u00b7bet"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zeigt dir den gantzen Plunder.", "tokens": ["Zeigt", "dir", "den", "gant\u00b7zen", "Plun\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und scheint dir es nicht wahr zu seyn,", "tokens": ["Und", "scheint", "dir", "es", "nicht", "wahr", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "PTKNEG", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So komm auf unsre H\u00f6hen,", "tokens": ["So", "komm", "auf", "uns\u00b7re", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Mein Allerley trifft richtig ein,", "tokens": ["Mein", "Al\u00b7ler\u00b7ley", "trifft", "rich\u00b7tig", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du wirst es deutlich sehen.", "tokens": ["Du", "wirst", "es", "deut\u00b7lich", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}