{"textgrid.poem.50191": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "23. Eytelkeit der weltlichen L\u00fcst' und Ehre", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dass eine ", "tokens": ["Dass", "ei\u00b7ne"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Und mich ein ", "tokens": ["Und", "mich", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Ich ", "tokens": ["Ich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Als aber ich erwacht', und nach den sanfften Zeichen", "tokens": ["Als", "a\u00b7ber", "ich", "er\u00b7wacht'", ",", "und", "nach", "den", "sanff\u00b7ten", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "VVFIN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Auch den ", "tokens": ["Auch", "den"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Durch mein ", "tokens": ["Durch", "mein"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Da war so wenig hier zu ", "tokens": ["Da", "war", "so", "we\u00b7nig", "hier", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADV", "APPR"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Als wenn, was ", "tokens": ["Als", "wenn", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "KOUS", "$,", "PWS"], "meter": "+-+", "measure": "trochaic.di"}}}}}