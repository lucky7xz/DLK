{"dta.poem.3118": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "163.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Was ist Verneinung wol im Denken und im Wort?", "tokens": ["Was", "ist", "Ver\u00b7nei\u00b7nung", "wol", "im", "Den\u00b7ken", "und", "im", "Wort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NN", "ADV", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bejahung nur, die r\u00fcckt von dem zu jenem fort.", "tokens": ["Be\u00b7ja\u00b7hung", "nur", ",", "die", "r\u00fcckt", "von", "dem", "zu", "je\u00b7nem", "fort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRELS", "VVFIN", "APPR", "ART", "APPR", "PDAT", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Dies Weiterr\u00fccken selbst erscheinet dreierlei,", "tokens": ["Dies", "Wei\u00b7ter\u00b7r\u00fc\u00b7cken", "selbst", "er\u00b7schei\u00b7net", "drei\u00b7er\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch leicht erkennest du: im Grund ist eins das drei.", "tokens": ["Doch", "leicht", "er\u00b7ken\u00b7nest", "du", ":", "im", "Grund", "ist", "eins", "das", "drei", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$.", "APPRART", "NN", "VAFIN", "PIS", "ART", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Das Gehn wird zum Vergehn, das Schlagen zum Erschlagen;", "tokens": ["Das", "Gehn", "wird", "zum", "Ver\u00b7gehn", ",", "das", "Schla\u00b7gen", "zum", "Er\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Aufhebt sich jede Kraft, zu ihrem Ziel getragen.", "tokens": ["Auf\u00b7hebt", "sich", "je\u00b7de", "Kraft", ",", "zu", "ih\u00b7rem", "Ziel", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PIAT", "NN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Von dem du jetzo sagst: es ist, sagst du: es war,", "tokens": ["Von", "dem", "du", "jet\u00b7zo", "sagst", ":", "es", "ist", ",", "sagst", "du", ":", "es", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "$.", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "$.", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Im n\u00e4chsten Nu; das Seyn stellt sich als Nichtseyn dar.", "tokens": ["Im", "n\u00e4chs\u00b7ten", "Nu", ";", "das", "Seyn", "stellt", "sich", "als", "Nich\u00b7tseyn", "dar", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "$.", "ART", "NN", "VVFIN", "PRF", "KOUS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Worauf du denkend siehst, das wird von dir empfunden", "tokens": ["Wo\u00b7rauf", "du", "den\u00b7kend", "siehst", ",", "das", "wird", "von", "dir", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "VVPP", "VVFIN", "$,", "PDS", "VAFIN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als etwas; siehst du weg, zum Nichts ist es geschwunden.", "tokens": ["Als", "et\u00b7was", ";", "siehst", "du", "weg", ",", "zum", "Nichts", "ist", "es", "ge\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$.", "VVFIN", "PPER", "PTKVZ", "$,", "APPRART", "PIS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Im R\u00fccken also durch die Zeit und durch den Ort,", "tokens": ["Im", "R\u00fc\u00b7cken", "al\u00b7so", "durch", "die", "Zeit", "und", "durch", "den", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und durch Gedanken, r\u00fcckt zum Tod das Leben fort.", "tokens": ["Und", "durch", "Ge\u00b7dan\u00b7ken", ",", "r\u00fcckt", "zum", "Tod", "das", "Le\u00b7ben", "fort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "VVFIN", "APPRART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "In dieser R\u00fccksicht nur wird dir zum Nein das Ja", "tokens": ["In", "die\u00b7ser", "R\u00fcck\u00b7sicht", "nur", "wird", "dir", "zum", "Nein", "das", "Ja"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ADV", "VAFIN", "PPER", "APPRART", "NN", "ART", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Nicht f\u00fcr sich selbst ists nicht, f\u00fcr dich nur ists nicht da.", "tokens": ["Nicht", "f\u00fcr", "sich", "selbst", "ists", "nicht", ",", "f\u00fcr", "dich", "nur", "ists", "nicht", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PRF", "ADV", "VAFIN", "PTKNEG", "$,", "APPR", "PPER", "ADV", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}