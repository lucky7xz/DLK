{"textgrid.poem.35158": {"metadata": {"author": {"name": "May, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Vorw\u00e4rts!", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer geht mit mir? Ich bleibe nicht!", "tokens": ["Wer", "geht", "mit", "mir", "?", "Ich", "blei\u00b7be", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Warum soll ich noch l\u00e4nger warten?", "tokens": ["Wa\u00b7rum", "soll", "ich", "noch", "l\u00e4n\u00b7ger", "war\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich lege ferner kein Gewicht", "tokens": ["Ich", "le\u00b7ge", "fer\u00b7ner", "kein", "Ge\u00b7wicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Dinge, die bisher mich narrten.", "tokens": ["Auf", "Din\u00b7ge", ",", "die", "bis\u00b7her", "mich", "narr\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wozu in aller Welt der Streit,", "tokens": ["Wo\u00b7zu", "in", "al\u00b7ler", "Welt", "der", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das fieberhafte Vorw\u00e4rtseilen,", "tokens": ["Das", "fie\u00b7ber\u00b7haf\u00b7te", "Vor\u00b7w\u00e4rt\u00b7sei\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn man dabei doch weit und breit", "tokens": ["Wenn", "man", "da\u00b7bei", "doch", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PAV", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nur um sich schl\u00e4gt mit Vorurtheilen!", "tokens": ["Nur", "um", "sich", "schl\u00e4gt", "mit", "Vor\u00b7urt\u00b7hei\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PRF", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Welch eine Welt liegt rings umher:", "tokens": ["Welch", "ei\u00b7ne", "Welt", "liegt", "rings", "um\u00b7her", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohin ich schau, nur Fragezeichen!", "tokens": ["Wo\u00b7hin", "ich", "schau", ",", "nur", "Fra\u00b7ge\u00b7zei\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKVZ", "$,", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist denn die Antwort gar so schwer?", "tokens": ["Ist", "denn", "die", "Ant\u00b7wort", "gar", "so", "schwer", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nat\u00fcrlich, schwerer als das Schweigen!", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", ",", "schwe\u00b7rer", "als", "das", "Schwei\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man denkt, man f\u00fchlt, man ahnt Etwas", "tokens": ["Man", "denkt", ",", "man", "f\u00fchlt", ",", "man", "ahnt", "Et\u00b7was"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch wagt man nicht, es laut zu sagen.", "tokens": ["Doch", "wagt", "man", "nicht", ",", "es", "laut", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKNEG", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Es droht der Spott; es droht der Ha\u00df,", "tokens": ["Es", "droht", "der", "Spott", ";", "es", "droht", "der", "Ha\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und das verursacht Unbehagen.", "tokens": ["Und", "das", "ver\u00b7ur\u00b7sacht", "Un\u00b7be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Man wei\u00df ein wunderbares Land", "tokens": ["Man", "wei\u00df", "ein", "wun\u00b7der\u00b7ba\u00b7res", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jenseits der Fragezeichen liegen,", "tokens": ["Jen\u00b7seits", "der", "Fra\u00b7ge\u00b7zei\u00b7chen", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch der verst\u00e4ndige Verstand", "tokens": ["Doch", "der", "ver\u00b7st\u00e4n\u00b7di\u00b7ge", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Versteht es nicht, sich zu besiegen.", "tokens": ["Ver\u00b7steht", "es", "nicht", ",", "sich", "zu", "be\u00b7sie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es \u00e4ngstigt ihn das \u00bbleere Nichts\u00ab,", "tokens": ["Es", "\u00e4ngs\u00b7tigt", "ihn", "das", "\u00bb", "lee\u00b7re", "Nichts", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "$(", "ADJA", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das zwischen hier und dort sich breitet", "tokens": ["Das", "zwi\u00b7schen", "hier", "und", "dort", "sich", "brei\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "KON", "ADV", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und ihm \u00bbdas ganze Reich des Lichts\u00ab", "tokens": ["Und", "ihm", "\u00bb", "das", "gan\u00b7ze", "Reich", "des", "Lichts", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und \u00bbseine Seligkeit\u00ab verleidet.", "tokens": ["Und", "\u00bb", "sei\u00b7ne", "Se\u00b7lig\u00b7keit", "\u00ab", "ver\u00b7lei\u00b7det", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$(", "PPOSAT", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und doch, wie ist dies Nichts belebt,", "tokens": ["Und", "doch", ",", "wie", "ist", "dies", "Nichts", "be\u00b7lebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "VAFIN", "PDS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Genau, genau wie unsre Erde!", "tokens": ["Ge\u00b7nau", ",", "ge\u00b7nau", "wie", "uns\u00b7re", "Er\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und wie ist dieses Nichts bestrebt,", "tokens": ["Und", "wie", "ist", "die\u00b7ses", "Nichts", "be\u00b7strebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df es ein Etwas f\u00fcr uns werde!", "tokens": ["Da\u00df", "es", "ein", "Et\u00b7was", "f\u00fcr", "uns", "wer\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADV", "APPR", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Jedoch in Vorurtheilen blind,", "tokens": ["Je\u00b7doch", "in", "Vor\u00b7urt\u00b7hei\u00b7len", "blind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verm\u00f6gen wir nicht, es zu sehen,", "tokens": ["Ver\u00b7m\u00f6\u00b7gen", "wir", "nicht", ",", "es", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und bleiben wir so, wie wir sind,", "tokens": ["Und", "blei\u00b7ben", "wir", "so", ",", "wie", "wir", "sind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kanns durch ein Wunder nur geschehen.", "tokens": ["Kanns", "durch", "ein", "Wun\u00b7der", "nur", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wer geht mit mir? Ich bleibe nicht!", "tokens": ["Wer", "geht", "mit", "mir", "?", "Ich", "blei\u00b7be", "nicht", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "$.", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich will nun endlich vorw\u00e4rtsschreiten.", "tokens": ["Ich", "will", "nun", "end\u00b7lich", "vor\u00b7w\u00e4rts\u00b7schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wem es dazu an Muth gebricht,", "tokens": ["Wem", "es", "da\u00b7zu", "an", "Muth", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der bleib; er ist nicht zu beneiden.", "tokens": ["Der", "bleib", ";", "er", "ist", "nicht", "zu", "be\u00b7nei\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Des Glaubens Schuhe zieh ich an;", "tokens": ["Des", "Glau\u00b7bens", "Schu\u00b7he", "zieh", "ich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Hoffnung g\u00fcrtet mir die Lenden,", "tokens": ["Die", "Hoff\u00b7nung", "g\u00fcr\u00b7tet", "mir", "die", "Len\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und was nicht ich vollbringen kann,", "tokens": ["Und", "was", "nicht", "ich", "voll\u00b7brin\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das wird ein Anderer vollenden!", "tokens": ["Das", "wird", "ein", "An\u00b7de\u00b7rer", "voll\u00b7en\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}