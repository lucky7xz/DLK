{"textgrid.poem.53071": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Hippocrene liegt gewis", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hippocrene liegt gewis", "tokens": ["Hip\u00b7po\u00b7cre\u00b7ne", "liegt", "ge\u00b7wis"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch jetzt in des Winters Banden,", "tokens": ["Auch", "jetzt", "in", "des", "Win\u00b7ters", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "Vnd mein klarer Castalis", "tokens": ["Vnd", "mein", "kla\u00b7rer", "Cas\u00b7ta\u00b7lis"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist mir durch den Frost bestanden,", "tokens": ["Ist", "mir", "durch", "den", "Frost", "be\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df mein Singen vnd mein Spiel", "tokens": ["Da\u00df", "mein", "Sin\u00b7gen", "vnd", "mein", "Spiel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gantz mir nicht gerahten wil.", "tokens": ["Gantz", "mir", "nicht", "ge\u00b7rah\u00b7ten", "wil", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Meiner leichten Adern gang", "tokens": ["Mei\u00b7ner", "leich\u00b7ten", "A\u00b7dern", "gang"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist mit strengem Schnee verwehet,", "tokens": ["Ist", "mit", "stren\u00b7gem", "Schnee", "ver\u00b7we\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df Ihr, Musen, solchen Zwang", "tokens": ["Da\u00df", "Ihr", ",", "Mu\u00b7sen", ",", "sol\u00b7chen", "Zwang"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jetzt in meinen Reimen sehet,", "tokens": ["Jetzt", "in", "mei\u00b7nen", "Rei\u00b7men", "se\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd ich nicht so gut vnd wol", "tokens": ["Vnd", "ich", "nicht", "so", "gut", "vnd", "wol"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PTKNEG", "ADV", "ADJD", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schreibe, wie ich schreiben sol.", "tokens": ["Schrei\u00b7be", ",", "wie", "ich", "schrei\u00b7ben", "sol", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Br\u00e4utlein, der ich schuldig bin", "tokens": ["Br\u00e4ut\u00b7lein", ",", "der", "ich", "schul\u00b7dig", "bin"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "PPER", "ADJD", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Di\u00df dein Braut-Fest zu besingen,", "tokens": ["Di\u00df", "dein", "Braut\u00b7Fest", "zu", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Mercke, wie ich meinen Sinn", "tokens": ["Mer\u00b7cke", ",", "wie", "ich", "mei\u00b7nen", "Sinn"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jetzt mu\u00df in die Reime zwingen,", "tokens": ["Jetzt", "mu\u00df", "in", "die", "Rei\u00b7me", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Mi\u00df es mir nicht also zu,", "tokens": ["Mi\u00df", "es", "mir", "nicht", "al\u00b7so", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "PTKNEG", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich es au\u00df Tr\u00e4gheit thue.", "tokens": ["Da\u00df", "ich", "es", "au\u00df", "Tr\u00e4g\u00b7heit", "thue", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.4": {"line.1": {"text": "Du, Pobunden, wolttest mir", "tokens": ["Du", ",", "Po\u00b7bun\u00b7den", ",", "wolt\u00b7test", "mir"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "PWAV", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel Rhue vnd Zeit nicht g\u00f6nnen", "tokens": ["So", "viel", "Rhue", "vnd", "Zeit", "nicht", "g\u00f6n\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich etwas nur bey dir", "tokens": ["Da\u00df", "ich", "et\u00b7was", "nur", "bey", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hett' in Reime fassen k\u00f6nnen,", "tokens": ["Hett'", "in", "Rei\u00b7me", "fas\u00b7sen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Pillkop vnd Karwaiten sind", "tokens": ["Pill\u00b7kop", "vnd", "Kar\u00b7wai\u00b7ten", "sind"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VAFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wo mir alle Kunst zerrinnt.", "tokens": ["Wo", "mir", "al\u00b7le", "Kunst", "zer\u00b7rinnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "F\u00fcr der gr\u00fcnen B\u00e4ume Pracht", "tokens": ["F\u00fcr", "der", "gr\u00fc\u00b7nen", "B\u00e4u\u00b7me", "Pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd den sch\u00f6nen Sand-Gebirgen", "tokens": ["Vnd", "den", "sch\u00f6\u00b7nen", "San\u00b7dGe\u00b7bir\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sieht man wie der W\u00f6lffe Schlacht", "tokens": ["Sieht", "man", "wie", "der", "W\u00f6lf\u00b7fe", "Schlacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "KOKOM", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "N\u00e4chtlich sucht das Vieh zu w\u00fcrgen,", "tokens": ["N\u00e4cht\u00b7lich", "sucht", "das", "Vieh", "zu", "w\u00fcr\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Frost vnd Schnee vnd wilder Nort", "tokens": ["Frost", "vnd", "Schnee", "vnd", "wil\u00b7der", "Nort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sind jetzt Wirth' an diesem Ort.", "tokens": ["Sind", "jetzt", "Wir\u00b7th'", "an", "die\u00b7sem", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "M\u00fcmmel, sagt ich, wird es sein,", "tokens": ["M\u00fcm\u00b7mel", ",", "sagt", "ich", ",", "wird", "es", "sein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So dich noch wird singen lassen", "tokens": ["So", "dich", "noch", "wird", "sin\u00b7gen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "VAFIN", "VVINF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie du pflagest, aber nein,", "tokens": ["Wie", "du", "pfla\u00b7gest", ",", "a\u00b7ber", "nein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "ADV", "PTKANT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier auch wei\u00df ich nichts zu fassen,", "tokens": ["Hier", "auch", "wei\u00df", "ich", "nichts", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Welches ewren Hochzeit-Tag", "tokens": ["Wel\u00b7ches", "ew\u00b7ren", "Hoch\u00b7zeit\u00b7Tag"], "token_info": ["word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie geb\u00fchret ehren mag.", "tokens": ["Wie", "ge\u00b7b\u00fch\u00b7ret", "eh\u00b7ren", "mag."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["PWAV", "VVPP", "VVFIN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Drumb begeht nur diese Zeit", "tokens": ["Drumb", "be\u00b7geht", "nur", "die\u00b7se", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ohne meiner Harffen Seiten", "tokens": ["Oh\u00b7ne", "mei\u00b7ner", "Harf\u00b7fen", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In gew\u00fcnschter Fr\u00f6lichkeit.", "tokens": ["In", "ge\u00b7w\u00fcnschter", "Fr\u00f6\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Gl\u00fcck vnd Segen wird euch leiten:", "tokens": ["Gl\u00fcck", "vnd", "Se\u00b7gen", "wird", "euch", "lei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gl\u00fcck, wodurch die Haabe bl\u00fcht,", "tokens": ["Gl\u00fcck", ",", "wo\u00b7durch", "die", "Haa\u00b7be", "bl\u00fcht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Segen, der auff Kinder sieht.", "tokens": ["Se\u00b7gen", ",", "der", "auff", "Kin\u00b7der", "sieht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}