{"textgrid.poem.40575": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der Graf kehrt heim vom Festturnei,", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Graf kehrt heim vom Festturnei,", "tokens": ["Der", "Graf", "kehrt", "heim", "vom", "Fest\u00b7tur\u00b7nei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da wallt an ihm sein Knecht vorbei.", "tokens": ["Da", "wallt", "an", "ihm", "sein", "Knecht", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Hallo, woher des Wegs, sag' an!", "tokens": ["Hal\u00b7lo", ",", "wo\u00b7her", "des", "Wegs", ",", "sag'", "an", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wohin, mein Knecht, geht deine Bahn?", "tokens": ["Wo\u00b7hin", ",", "mein", "Knecht", ",", "geht", "dei\u00b7ne", "Bahn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbich wandle, da\u00df der Leib gedeih',", "tokens": ["\u00bb", "ich", "wand\u00b7le", ",", "da\u00df", "der", "Leib", "ge\u00b7deih'", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Wohnhaus such' ich mir nebenbei.\u00ab", "tokens": ["Ein", "Wohn\u00b7haus", "such'", "ich", "mir", "ne\u00b7ben\u00b7bei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Ein Wohnhaus? Nun, sprich grad' heraus,", "tokens": ["Ein", "Wohn\u00b7haus", "?", "Nun", ",", "sprich", "grad'", "he\u00b7raus", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADV", "$,", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was ist geschehn bei uns zu Haus?", "tokens": ["Was", "ist", "ge\u00b7schehn", "bei", "uns", "zu", "Haus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "VVPP", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbnichts Sonderlich's! Nur todeswund", "tokens": ["\u00bb", "nichts", "Son\u00b7der\u00b7lich's", "!", "Nur", "to\u00b7des\u00b7wund"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PIS", "PIS", "$.", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Liegt euer kleiner wei\u00dfer Hund.\u00ab", "tokens": ["Liegt", "eu\u00b7er", "klei\u00b7ner", "wei\u00b7\u00dfer", "Hund", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Mein treues H\u00fcndchen todeswund!", "tokens": ["Mein", "treu\u00b7es", "H\u00fcnd\u00b7chen", "to\u00b7des\u00b7wund", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprich, wie begab sich's mit dem Hund?", "tokens": ["Sprich", ",", "wie", "be\u00b7gab", "sich's", "mit", "dem", "Hund", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "PWAV", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbim Schreck eu'r Leibro\u00df auf ihn sprang,", "tokens": ["\u00bb", "im", "Schreck", "eu'r", "Lei\u00b7bro\u00df", "auf", "ihn", "sprang", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drauf lief's in den Strom, der es verschlang.\u00ab", "tokens": ["Drauf", "lie\u00b7f's", "in", "den", "Strom", ",", "der", "es", "ver\u00b7schlang", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Mein sch\u00f6nes Ro\u00df, des Stalles Zier!", "tokens": ["Mein", "sch\u00f6\u00b7nes", "Ro\u00df", ",", "des", "Stal\u00b7les", "Zier", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wovon erschrak das arme Thier?", "tokens": ["Wo\u00b7von", "er\u00b7schrak", "das", "ar\u00b7me", "Thier", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbbesinn ich recht mich, erschrak's davon,", "tokens": ["\u00bb", "be\u00b7sinn", "ich", "recht", "mich", ",", "er\u00b7schrak's", "da\u00b7von", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADJD", "PPER", "$,", "PIS", "PAV", "$,"], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Als von dem Fenster st\u00fcrzt' eu'r Sohn.\u00ab", "tokens": ["Als", "von", "dem", "Fens\u00b7ter", "st\u00fcrzt'", "eu'r", "Sohn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Mein Sohn? Doch blieb er unverletzt?", "tokens": ["Mein", "Sohn", "?", "Doch", "blieb", "er", "un\u00b7ver\u00b7letzt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl pflegt mein s\u00fc\u00dfes Weib ihn jetzt?", "tokens": ["Wohl", "pflegt", "mein", "s\u00fc\u00b7\u00dfes", "Weib", "ihn", "jetzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbdie Gr\u00e4fin r\u00fchrte stracks der Schlag,", "tokens": ["\u00bb", "die", "Gr\u00e4\u00b7fin", "r\u00fchr\u00b7te", "stracks", "der", "Schlag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als vor ihr des Herrleins Leichnam lag.\u00ab", "tokens": ["Als", "vor", "ihr", "des", "Herr\u00b7leins", "Leich\u00b7nam", "lag", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ART", "NN", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Warum bei solchem Jammer und Graus,", "tokens": ["Wa\u00b7rum", "bei", "sol\u00b7chem", "Jam\u00b7mer", "und", "Graus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Du Schlingel, h\u00fctest du nicht das Haus?", "tokens": ["Du", "Schlin\u00b7gel", ",", "h\u00fc\u00b7test", "du", "nicht", "das", "Haus", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "\u00bbdas Haus? Ei, welches meint ihr wohl?", "tokens": ["\u00bb", "das", "Haus", "?", "Ei", ",", "wel\u00b7ches", "meint", "ihr", "wohl", "?"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$.", "NN", "$,", "PRELS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das eure liegt in Asch' und Kohl'!", "tokens": ["Das", "eu\u00b7re", "liegt", "in", "Asch'", "und", "Kohl'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "VVFIN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Die Leichenfrau schlief ein an der Bahr',", "tokens": ["Die", "Lei\u00b7chen\u00b7frau", "schlief", "ein", "an", "der", "Bahr'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und Feuer fing ihr Kleid und Haar.", "tokens": ["Und", "Feu\u00b7er", "fing", "ihr", "Kleid", "und", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und Schlo\u00df und Stall verlodert' im Wind,", "tokens": ["Und", "Schlo\u00df", "und", "Stall", "ver\u00b7lo\u00b7dert'", "im", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Dazu das ganze Hausgesind!", "tokens": ["Da\u00b7zu", "das", "gan\u00b7ze", "Haus\u00b7ge\u00b7sind", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Nur mich hat das Schicksal aufgespart,", "tokens": ["Nur", "mich", "hat", "das", "Schick\u00b7sal", "auf\u00b7ge\u00b7spart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Euch's vorzubringen auf gute Art.\u00ab", "tokens": ["Euch's", "vor\u00b7zu\u00b7brin\u00b7gen", "auf", "gu\u00b7te", "Art", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}