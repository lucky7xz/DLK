{"textgrid.poem.64127": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Gotenzug", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gebt Raum, ihr V\u00f6lker, unserm Schritt:", "tokens": ["Gebt", "Raum", ",", "ihr", "V\u00f6l\u00b7ker", ",", "un\u00b7serm", "Schritt", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind die letzten Goten!", "tokens": ["Wir", "sind", "die", "letz\u00b7ten", "Go\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir tragen keine Sch\u00e4tze mit: \u2013", "tokens": ["Wir", "tra\u00b7gen", "kei\u00b7ne", "Sch\u00e4t\u00b7ze", "mit", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir tragen einen Toten.", "tokens": ["Wir", "tra\u00b7gen", "ei\u00b7nen", "To\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Mit Schild an Schild und Speer an Speer", "tokens": ["Mit", "Schild", "an", "Schild", "und", "Speer", "an", "Speer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir ziehn nach Nordlands Winden,", "tokens": ["Wir", "ziehn", "nach", "Nord\u00b7lands", "Win\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bis wir im fernsten grauen Meer", "tokens": ["Bis", "wir", "im", "ferns\u00b7ten", "grau\u00b7en", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Insel Thule finden.", "tokens": ["Die", "In\u00b7sel", "Thu\u00b7le", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Das soll der Treue Insel sein:", "tokens": ["Das", "soll", "der", "Treu\u00b7e", "In\u00b7sel", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "NN", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Dort gilt noch Eid und Ehre:", "tokens": ["Dort", "gilt", "noch", "Eid", "und", "Eh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dort senken wir den K\u00f6nig ein", "tokens": ["Dort", "sen\u00b7ken", "wir", "den", "K\u00f6\u00b7nig", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Im Sarg der Eichenspeere.", "tokens": ["Im", "Sarg", "der", "Ei\u00b7chen\u00b7spee\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wir kommen her \u2013 gebt Raum dem Schritt! \u2013", "tokens": ["Wir", "kom\u00b7men", "her", "\u2013", "gebt", "Raum", "dem", "Schritt", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$(", "VVFIN", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Romas falschen Toren:", "tokens": ["Aus", "Ro\u00b7mas", "fal\u00b7schen", "To\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir tragen nur den K\u00f6nig mit: \u2013", "tokens": ["Wir", "tra\u00b7gen", "nur", "den", "K\u00f6\u00b7nig", "mit", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Krone ging verloren.", "tokens": ["Die", "Kro\u00b7ne", "ging", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}