{"textgrid.poem.63845": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "S\u00fcndenregister", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Stets nahm ich dich in Schutz und bliebe", "tokens": ["Stets", "nahm", "ich", "dich", "in", "Schutz", "und", "blie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Anwalt gegen eine Welt,", "tokens": ["Dein", "An\u00b7walt", "ge\u00b7gen", "ei\u00b7ne", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du Volk Italiens, das ich liebe,", "tokens": ["Du", "Volk", "I\u00b7ta\u00b7li\u00b7ens", ",", "das", "ich", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "NE", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So manches mir an dir mi\u00dff\u00e4llt.", "tokens": ["So", "man\u00b7ches", "mir", "an", "dir", "mi\u00df\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch unter uns und ohne Zeugen", "tokens": ["Doch", "un\u00b7ter", "uns", "und", "oh\u00b7ne", "Zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nehm' ich ein Blatt nicht vor den Mund", "tokens": ["Nehm'", "ich", "ein", "Blatt", "nicht", "vor", "den", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kann als Freund dir nicht verschweigen:", "tokens": ["Und", "kann", "als", "Freund", "dir", "nicht", "ver\u00b7schwei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "KOUS", "NN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sie tadeln dich nicht ohne Grund.", "tokens": ["Sie", "ta\u00b7deln", "dich", "nicht", "oh\u00b7ne", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Das s\u00fc\u00dfe Nichtstun \u2013 deinen Kindern", "tokens": ["Das", "s\u00fc\u00b7\u00dfe", "Nichts\u00b7tun", "\u2013", "dei\u00b7nen", "Kin\u00b7dern"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verwehrt's die liebe Sonne nicht,", "tokens": ["Ver\u00b7wehrt's", "die", "lie\u00b7be", "Son\u00b7ne", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und fremde Reisende zu pl\u00fcndern,", "tokens": ["Und", "frem\u00b7de", "Rei\u00b7sen\u00b7de", "zu", "pl\u00fcn\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Scheint jedem Gastwirt Ehrenpflicht.", "tokens": ["Scheint", "je\u00b7dem", "Gast\u00b7wirt", "Eh\u00b7ren\u00b7pflicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Man schilt auch, da\u00df du ohn' Err\u00f6ten", "tokens": ["Man", "schilt", "auch", ",", "da\u00df", "du", "ohn'", "Er\u00b7r\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In schmutz'gen Mauerh\u00f6hlen wohnst,", "tokens": ["In", "schmutz'\u00b7gen", "Mau\u00b7er\u00b7h\u00f6h\u00b7len", "wohnst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die kleinen V\u00f6gel liebst zu t\u00f6ten,", "tokens": ["Die", "klei\u00b7nen", "V\u00f6\u00b7gel", "liebst", "zu", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch das Ungeziefer schonst;", "tokens": ["Je\u00b7doch", "das", "Un\u00b7ge\u00b7zie\u00b7fer", "schonst", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und da\u00df man selbst den Angestellten", "tokens": ["Und", "da\u00df", "man", "selbst", "den", "An\u00b7ge\u00b7stell\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vergolden mag die hohle Hand \u2013", "tokens": ["Ver\u00b7gol\u00b7den", "mag", "die", "hoh\u00b7le", "Hand", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun, dies und andres noch, nicht selten", "tokens": ["Nun", ",", "dies", "und", "and\u00b7res", "noch", ",", "nicht", "sel\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "PDS", "KON", "PIS", "ADV", "$,", "PTKNEG", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Trifft man's wohl auch in anderm Land.", "tokens": ["Trifft", "man's", "wohl", "auch", "in", "an\u00b7derm", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "APPR", "PIS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch Schlimmres noch: Brigantenhorden", "tokens": ["Doch", "Schlimm\u00b7res", "noch", ":", "Bri\u00b7gan\u00b7ten\u00b7hor\u00b7den"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "NN", "ADV", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "In deiner Berge wildem Scho\u00df,", "tokens": ["In", "dei\u00b7ner", "Ber\u00b7ge", "wil\u00b7dem", "Scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vendetta, die, zur Pflicht geworden,", "tokens": ["Ven\u00b7det\u00b7ta", ",", "die", ",", "zur", "Pflicht", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "$,", "APPRART", "NN", "VAPP", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Geschlechter mordet gnadelos,", "tokens": ["Ge\u00b7schlech\u00b7ter", "mor\u00b7det", "gna\u00b7de\u00b7los", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der W\u00e4lder gr\u00e4uliche Verw\u00fcstung,", "tokens": ["Der", "W\u00e4l\u00b7der", "gr\u00e4u\u00b7li\u00b7che", "Ver\u00b7w\u00fcs\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Camorra, die das \u00c4rgste wagt,", "tokens": ["Ca\u00b7mor\u00b7ra", ",", "die", "das", "\u00c4rgs\u00b7te", "wagt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wes in sittlicher Entr\u00fcstung", "tokens": ["Und", "wes", "in", "sitt\u00b7li\u00b7cher", "Ent\u00b7r\u00fcs\u00b7tung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dich gutes Volk man sonst verklagt:", "tokens": ["Dich", "gu\u00b7tes", "Volk", "man", "sonst", "ver\u00b7klagt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Das alles d\u00fcnkt dir sehr verzeihlich,", "tokens": ["Das", "al\u00b7les", "d\u00fcnkt", "dir", "sehr", "ver\u00b7zeih\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was Hohn Europens Sitte spricht,", "tokens": ["Was", "Hohn", "Eu\u00b7ro\u00b7pens", "Sit\u00b7te", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nur eine seltne Tugend freilich", "tokens": ["Nur", "ei\u00b7ne", "selt\u00b7ne", "Tu\u00b7gend", "frei\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Macht Vieles gut: du heuchelst nicht.", "tokens": ["Macht", "Vie\u00b7les", "gut", ":", "du", "heu\u00b7chelst", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADJD", "$.", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Auch ich, so sehr ich dir gewogen,", "tokens": ["Auch", "ich", ",", "so", "sehr", "ich", "dir", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "ADV", "ADV", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bin nicht f\u00fcr deine Fehler blind.", "tokens": ["Bin", "nicht", "f\u00fcr", "dei\u00b7ne", "Feh\u00b7ler", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wei\u00df, du wurdest schlecht erzogen,", "tokens": ["Ich", "wei\u00df", ",", "du", "wur\u00b7dest", "schlecht", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So bliebst du stets ein gro\u00dfes Kind.", "tokens": ["So", "bliebst", "du", "stets", "ein", "gro\u00b7\u00dfes", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Unarten, die in deinem Blute", "tokens": ["Un\u00b7ar\u00b7ten", ",", "die", "in", "dei\u00b7nem", "Blu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verderblich nisteten bis heut,", "tokens": ["Ver\u00b7derb\u00b7lich", "nis\u00b7te\u00b7ten", "bis", "heut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie wurden nicht mit scharfer Rute", "tokens": ["Sie", "wur\u00b7den", "nicht", "mit", "schar\u00b7fer", "Ru\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von deinen Zwingherrn ausgebl\u00e4ut.", "tokens": ["Von", "dei\u00b7nen", "Zwing\u00b7herrn", "aus\u00b7ge\u00b7bl\u00e4ut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Sie knechteten dich manch Jahrhundert,", "tokens": ["Sie", "knech\u00b7te\u00b7ten", "dich", "manch", "Jahr\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit schlauer Priesterschaft im Bund,", "tokens": ["Mit", "schlau\u00b7er", "Pries\u00b7ter\u00b7schaft", "im", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df billig ", "tokens": ["Da\u00df", "bil\u00b7lig"], "token_info": ["word", "word"], "pos": ["KOUS", "ADJD"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wie unverw\u00fcstlich du gesund.", "tokens": ["Wie", "un\u00b7ver\u00b7w\u00fcst\u00b7lich", "du", "ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Gewi\u00df, dir w\u00e4re hoch vonn\u00f6ten", "tokens": ["Ge\u00b7wi\u00df", ",", "dir", "w\u00e4\u00b7re", "hoch", "von\u00b7n\u00f6\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein deutscher Unteroffizier,", "tokens": ["Ein", "deut\u00b7scher", "Un\u00b7ter\u00b7of\u00b7fi\u00b7zier", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "W\u00fcrd' auch sein Drill so manches t\u00f6ten,", "tokens": ["W\u00fcrd'", "auch", "sein", "Drill", "so", "man\u00b7ches", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VAINF", "VMFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was liebensw\u00fcrdig ist an dir.", "tokens": ["Was", "lie\u00b7bens\u00b7w\u00fcr\u00b7dig", "ist", "an", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Doch da man endlich aus Ruinen", "tokens": ["Doch", "da", "man", "end\u00b7lich", "aus", "Ru\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Verj\u00e4hrten Wust beiseite r\u00e4umt,", "tokens": ["Ver\u00b7j\u00e4hr\u00b7ten", "Wust", "bei\u00b7sei\u00b7te", "r\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So malerisch er lang erschienen,", "tokens": ["So", "ma\u00b7le\u00b7risch", "er", "lang", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So wundersam man drin getr\u00e4umt;", "tokens": ["So", "wun\u00b7der\u00b7sam", "man", "drin", "ge\u00b7tr\u00e4umt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Da selbst in Roms verfallne Gassen", "tokens": ["Da", "selbst", "in", "Roms", "ver\u00b7fall\u00b7ne", "Gas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Licht man einen Weg gebahnt,", "tokens": ["Dem", "Licht", "man", "ei\u00b7nen", "Weg", "ge\u00b7bahnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob auch erhabne Tr\u00fcmmermassen", "tokens": ["Ob", "auch", "er\u00b7hab\u00b7ne", "Tr\u00fcm\u00b7mer\u00b7mas\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An ferne gro\u00dfe Zeit gemahnt,", "tokens": ["An", "fer\u00b7ne", "gro\u00b7\u00dfe", "Zeit", "ge\u00b7mahnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVPP", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.15": {"line.1": {"text": "So w\u00fcnsch' ich, da\u00df du, neu erstanden", "tokens": ["So", "w\u00fcn\u00b7sch'", "ich", ",", "da\u00df", "du", ",", "neu", "er\u00b7stan\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "$,", "ADJD", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Aus langem Schlummer, dich befreist", "tokens": ["Aus", "lan\u00b7gem", "Schlum\u00b7mer", ",", "dich", "be\u00b7freist"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von den jahrtausendalten Banden,", "tokens": ["Von", "den", "jahr\u00b7tau\u00b7sen\u00b7dal\u00b7ten", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dir umschn\u00fcrten Seel' und Geist;", "tokens": ["Die", "dir", "um\u00b7schn\u00fcr\u00b7ten", "Seel'", "und", "Geist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Da\u00df du, was nie zuvor du lerntest,", "tokens": ["Da\u00df", "du", ",", "was", "nie", "zu\u00b7vor", "du", "lern\u00b7test", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADV", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dich selber nimmst in strenge Zucht", "tokens": ["Dich", "sel\u00b7ber", "nimmst", "in", "stren\u00b7ge", "Zucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und vollgereift nun endlich erntest", "tokens": ["Und", "voll\u00b7ge\u00b7reift", "nun", "end\u00b7lich", "ern\u00b7test"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "All deiner edlen Gaben Frucht.", "tokens": ["All", "dei\u00b7ner", "ed\u00b7len", "Ga\u00b7ben", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Dann wirst du deine Rache nehmen", "tokens": ["Dann", "wirst", "du", "dei\u00b7ne", "Ra\u00b7che", "neh\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und, die dich h\u00f6hnten d\u00fcnkelhaft", "tokens": ["Und", ",", "die", "dich", "h\u00f6hn\u00b7ten", "d\u00fcn\u00b7kel\u00b7haft"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PRELS", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als \u00bbLand der Toten\u00ab, stolz besch\u00e4men", "tokens": ["Als", "\u00bb", "Land", "der", "To\u00b7ten", "\u00ab", ",", "stolz", "be\u00b7sch\u00e4\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KOUS", "$(", "NN", "ART", "NN", "$(", "$,", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Taten freud'ger Lebenskraft.", "tokens": ["Durch", "Ta\u00b7ten", "freu\u00b7d'\u00b7ger", "Le\u00b7bens\u00b7kraft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}