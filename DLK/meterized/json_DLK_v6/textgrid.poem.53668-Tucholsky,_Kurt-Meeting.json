{"textgrid.poem.53668": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Meeting", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das ist nun so.", "tokens": ["Das", "ist", "nun", "so", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Je freier und je nackter,", "tokens": ["Je", "frei\u00b7er", "und", "je", "nack\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "je mehr enth\u00fcllt das Herz sich. Offen liegt", "tokens": ["je", "mehr", "ent\u00b7h\u00fcllt", "das", "Herz", "sich", ".", "Of\u00b7fen", "liegt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PRF", "$.", "NN", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "beim Boxen und beim Lieben der Charakter", "tokens": ["beim", "Bo\u00b7xen", "und", "beim", "Lie\u00b7ben", "der", "Cha\u00b7rak\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "des Partners, der dich h\u00fcllenlos besiegt.", "tokens": ["des", "Part\u00b7ners", ",", "der", "dich", "h\u00fcl\u00b7len\u00b7los", "be\u00b7siegt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Trainer schreien. \u00bbZeit!\u00ab Ihr streckt die H\u00e4nde.", "tokens": ["Die", "Trai\u00b7ner", "schrei\u00b7en", ".", "\u00bb", "Zeit", "!", "\u00ab", "Ihr", "streckt", "die", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihr seid ein Kn\u00e4ul. Ein Wille. Ein Duett.", "tokens": ["Ihr", "seid", "ein", "Kn\u00e4ul", ".", "Ein", "Wil\u00b7le", ".", "Ein", "Du\u00b7ett", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "ART", "NN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die strengen Regeln treibens bis zum Ende", "tokens": ["Die", "stren\u00b7gen", "Re\u00b7geln", "trei\u00b7bens", "bis", "zum", "En\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "beim Boxen, liebe Frau, und auch im Bett.", "tokens": ["beim", "Bo\u00b7xen", ",", "lie\u00b7be", "Frau", ",", "und", "auch", "im", "Bett", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADJA", "NN", "$,", "KON", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Wie sch\u00f6n zu k\u00e4mpfen und sich zu umfassen.", "tokens": ["Wie", "sch\u00f6n", "zu", "k\u00e4mp\u00b7fen", "und", "sich", "zu", "um\u00b7fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PTKZU", "VVINF", "KON", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da noch ein Druck und da ein Untergriff.", "tokens": ["Da", "noch", "ein", "Druck", "und", "da", "ein", "Un\u00b7ter\u00b7griff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und dann bet\u00e4ubt sich leise treiben lassen . . .", "tokens": ["Und", "dann", "be\u00b7t\u00e4ubt", "sich", "lei\u00b7se", "trei\u00b7ben", "las\u00b7sen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADJD", "VVINF", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Richter gibt den ersten Pausenpfiff.", "tokens": ["Der", "Rich\u00b7ter", "gibt", "den", "ers\u00b7ten", "Pau\u00b7sen\u00b7pfiff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Der n\u00e4chste Gang. So gib, du, gib dein Letztes.", "tokens": ["Der", "n\u00e4chs\u00b7te", "Gang", ".", "So", "gib", ",", "du", ",", "gib", "dein", "Letz\u00b7tes", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADV", "VVIMP", "$,", "PPER", "$,", "VVIMP", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich f\u00fchle lebensnahe, glatte Haut . . .", "tokens": ["Ich", "f\u00fch\u00b7le", "le\u00b7bens\u00b7na\u00b7he", ",", "glat\u00b7te", "Haut", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "$,", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus Tiefen springt dein Herzblut, und dann netzt es", "tokens": ["Aus", "Tie\u00b7fen", "springt", "dein", "Herz\u00b7blut", ",", "und", "dann", "netzt", "es"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$,", "KON", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "mich weich \u2013 wie bist du mir vertraut!", "tokens": ["mich", "weich", "\u2013", "wie", "bist", "du", "mir", "ver\u00b7traut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$(", "KOKOM", "VAFIN", "PPER", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wo bist du, Welt?", "tokens": ["Wo", "bist", "du", ",", "Welt", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "$,", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Die Erde soll versinken.", "tokens": ["Die", "Er\u00b7de", "soll", "ver\u00b7sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es h\u00fcllt der Kampf uns, tief bewu\u00dftlos, ein.", "tokens": ["Es", "h\u00fcllt", "der", "Kampf", "uns", ",", "tief", "be\u00b7wu\u00dft\u00b7los", ",", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "$,", "ADJD", "ADJD", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und meine trocknen Lippen wollen trinken.", "tokens": ["Und", "mei\u00b7ne", "trock\u00b7nen", "Lip\u00b7pen", "wol\u00b7len", "trin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich hasse dich. Doch du mu\u00dft bei mir sein.", "tokens": ["Ich", "has\u00b7se", "dich", ".", "Doch", "du", "mu\u00dft", "bei", "mir", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "KON", "PPER", "VMFIN", "APPR", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Die Gruppe l\u00f6st sich.", "tokens": ["Die", "Grup\u00b7pe", "l\u00f6st", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Und die Trainer wettern.", "tokens": ["Und", "die", "Trai\u00b7ner", "wet\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Der Richter winkt. Das Publikum kann gehn.", "tokens": ["Der", "Rich\u00b7ter", "winkt", ".", "Das", "Pub\u00b7li\u00b7kum", "kann", "gehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und morgen stehts in allen gro\u00dfen Bl\u00e4ttern:", "tokens": ["Und", "mor\u00b7gen", "stehts", "in", "al\u00b7len", "gro\u00b7\u00dfen", "Bl\u00e4t\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "\u00bbjolanthe/Tiger \u2013", "tokens": ["\u00bb", "jo\u00b7lan\u00b7the", "/", "Ti\u00b7ger", "\u2013"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "NE", "$(", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ausgang: 10 zu 10.\u00ab", "tokens": ["Aus\u00b7gang", ":", "10", "zu", "10.", "\u00ab"], "token_info": ["word", "punct", "number", "word", "ordinal", "punct"], "pos": ["NN", "$.", "CARD", "APPR", "ADJA", "$("], "meter": "+-+", "measure": "trochaic.di"}}}}}