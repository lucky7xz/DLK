{"textgrid.poem.55819": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Das Buch vom m\u00f6nchischen Leben", "genre": "verse", "period": "N.A.", "pub_year": 1899, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da neigt sich die Stunde und r\u00fchrt mich an", "tokens": ["Da", "neigt", "sich", "die", "Stun\u00b7de", "und", "r\u00fchrt", "mich", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "mit klarem, metallenem Schlag:", "tokens": ["mit", "kla\u00b7rem", ",", "me\u00b7tal\u00b7le\u00b7nem", "Schlag", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "mir zittern die Sinne. Ich f\u00fchle: ich kann \u2013", "tokens": ["mir", "zit\u00b7tern", "die", "Sin\u00b7ne", ".", "Ich", "f\u00fch\u00b7le", ":", "ich", "kann", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "$.", "PPER", "VMFIN", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "und ich fasse den plastischen Tag.", "tokens": ["und", "ich", "fas\u00b7se", "den", "plas\u00b7ti\u00b7schen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Nichts war noch vollendet, eh ich es erschaut,", "tokens": ["Nichts", "war", "noch", "voll\u00b7en\u00b7det", ",", "eh", "ich", "es", "er\u00b7schaut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "VVPP", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "ein jedes Werden stand still.", "tokens": ["ein", "je\u00b7des", "Wer\u00b7den", "stand", "still", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Meine Blicke sind reif, und wie eine Braut", "tokens": ["Mei\u00b7ne", "Bli\u00b7cke", "sind", "reif", ",", "und", "wie", "ei\u00b7ne", "Braut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KON", "PWAV", "ART", "NN"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "kommt jedem das Ding, das er will.", "tokens": ["kommt", "je\u00b7dem", "das", "Ding", ",", "das", "er", "will", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "$,", "PRELS", "PPER", "VMFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Nichts ist mir zu klein und ich lieb es trotzdem", "tokens": ["Nichts", "ist", "mir", "zu", "klein", "und", "ich", "lieb", "es", "trotz\u00b7dem"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "PTKA", "ADJD", "KON", "PPER", "ADJD", "PPER", "PAV"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "und mal es auf Goldgrund und gro\u00df,", "tokens": ["und", "mal", "es", "auf", "Gold\u00b7grund", "und", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "APPR", "NN", "KON", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "und halte es hoch, und ich wei\u00df nicht wem", "tokens": ["und", "hal\u00b7te", "es", "hoch", ",", "und", "ich", "wei\u00df", "nicht", "wem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$,", "KON", "PPER", "VVFIN", "PTKNEG", "PWS"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "l\u00f6st es die Seele los ...", "tokens": ["l\u00f6st", "es", "die", "See\u00b7le", "los", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.4": {"line.1": {"text": "Ich lebe mein Leben in wachsenden Ringen,", "tokens": ["Ich", "le\u00b7be", "mein", "Le\u00b7ben", "in", "wach\u00b7sen\u00b7den", "Rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "die sich \u00fcber die Dinge ziehn.", "tokens": ["die", "sich", "\u00fc\u00b7ber", "die", "Din\u00b7ge", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ich werde den letzten vielleicht nicht vollbringen,", "tokens": ["Ich", "wer\u00b7de", "den", "letz\u00b7ten", "viel\u00b7leicht", "nicht", "voll\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "aber versuchen will ich ihn.", "tokens": ["a\u00b7ber", "ver\u00b7su\u00b7chen", "will", "ich", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPER", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Ich kreise um Gott, um den uralten Turm,", "tokens": ["Ich", "krei\u00b7se", "um", "Gott", ",", "um", "den", "ur\u00b7al\u00b7ten", "Turm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "KOUI", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "und ich kreise jahrtausendelang;", "tokens": ["und", "ich", "krei\u00b7se", "jahr\u00b7tau\u00b7sen\u00b7de\u00b7lang", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "und ich wei\u00df noch nicht: bin ich ein Falke, ein Sturm", "tokens": ["und", "ich", "wei\u00df", "noch", "nicht", ":", "bin", "ich", "ein", "Fal\u00b7ke", ",", "ein", "Sturm"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "PTKNEG", "$.", "VAFIN", "PPER", "ART", "NN", "$,", "ART", "NN"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "oder ein gro\u00dfer Gesang.", "tokens": ["o\u00b7der", "ein", "gro\u00b7\u00dfer", "Ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.6": {"line.1": {"text": "Ich habe viele Br\u00fcder in Sutanen", "tokens": ["Ich", "ha\u00b7be", "vie\u00b7le", "Br\u00fc\u00b7der", "in", "Su\u00b7ta\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "im S\u00fcden, wo in Kl\u00f6stern Lorbeer steht.", "tokens": ["im", "S\u00fc\u00b7den", ",", "wo", "in", "Kl\u00f6s\u00b7tern", "Lor\u00b7beer", "steht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PWAV", "APPR", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich wei\u00df, wie menschlich sie Madonnen planen,", "tokens": ["Ich", "wei\u00df", ",", "wie", "menschlich", "sie", "Ma\u00b7don\u00b7nen", "pla\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADJD", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und tr\u00e4ume oft von jungen Tizianen,", "tokens": ["und", "tr\u00e4u\u00b7me", "oft", "von", "jun\u00b7gen", "Ti\u00b7zi\u00b7a\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "durch die der Gott in Gluten geht.", "tokens": ["durch", "die", "der", "Gott", "in", "Glu\u00b7ten", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch wie ich mich auch in mich selber neige:", "tokens": ["Doch", "wie", "ich", "mich", "auch", "in", "mich", "sel\u00b7ber", "nei\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PRF", "ADV", "APPR", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "von hundert Wurzeln, welche schweigsam trinken.", "tokens": ["von", "hun\u00b7dert", "Wur\u00b7zeln", ",", "wel\u00b7che", "schweig\u00b7sam", "trin\u00b7ken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "PRELS", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nur, da\u00df ich mich aus ", "tokens": ["Nur", ",", "da\u00df", "ich", "mich", "aus"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "mehr wei\u00df ich nicht, weil alle meine Zweige", "tokens": ["mehr", "wei\u00df", "ich", "nicht", ",", "weil", "al\u00b7le", "mei\u00b7ne", "Zwei\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "tief unten ruhn und nur im Winde winken.", "tokens": ["tief", "un\u00b7ten", "ruhn", "und", "nur", "im", "Win\u00b7de", "win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVINF", "KON", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wir d\u00fcrfen dich nicht eigenm\u00e4chtig malen,", "tokens": ["Wir", "d\u00fcr\u00b7fen", "dich", "nicht", "ei\u00b7gen\u00b7m\u00e4ch\u00b7tig", "ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "du D\u00e4mmernde, aus der der Morgen stieg.", "tokens": ["du", "D\u00e4m\u00b7mern\u00b7de", ",", "aus", "der", "der", "Mor\u00b7gen", "stieg", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Wir holen aus den alten Farbenschalen", "tokens": ["Wir", "ho\u00b7len", "aus", "den", "al\u00b7ten", "Far\u00b7ben\u00b7scha\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die gleichen Striche und die gleichen Strahlen,", "tokens": ["die", "glei\u00b7chen", "Stri\u00b7che", "und", "die", "glei\u00b7chen", "Strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "mit denen dich der Heilige verschwieg.", "tokens": ["mit", "de\u00b7nen", "dich", "der", "Hei\u00b7li\u00b7ge", "ver\u00b7schwieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Wir bauen Bilder vor dir auf wie W\u00e4nde;", "tokens": ["Wir", "bau\u00b7en", "Bil\u00b7der", "vor", "dir", "auf", "wie", "W\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "PPER", "PTKVZ", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "so da\u00df schon tausend Mauern um dich stehn.", "tokens": ["so", "da\u00df", "schon", "tau\u00b7send", "Mau\u00b7ern", "um", "dich", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ADV", "CARD", "NN", "APPR", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Denn dich verh\u00fcllen unsre frommen H\u00e4nde,", "tokens": ["Denn", "dich", "ver\u00b7h\u00fcl\u00b7len", "uns\u00b7re", "from\u00b7men", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sooft dich unsre Herzen offen sehn.", "tokens": ["sooft", "dich", "uns\u00b7re", "Her\u00b7zen", "of\u00b7fen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Ich liebe meines Wesens Dunkelstunden,", "tokens": ["Ich", "lie\u00b7be", "mei\u00b7nes", "We\u00b7sens", "Dun\u00b7kel\u00b7stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "in welchen meine Sinne sich vertiefen;", "tokens": ["in", "wel\u00b7chen", "mei\u00b7ne", "Sin\u00b7ne", "sich", "ver\u00b7tie\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "in ihnen hab ich, wie in alten Briefen,", "tokens": ["in", "ih\u00b7nen", "hab", "ich", ",", "wie", "in", "al\u00b7ten", "Brie\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "$,", "PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "mein t\u00e4glich Leben schon gelebt gefunden", "tokens": ["mein", "t\u00e4g\u00b7lich", "Le\u00b7ben", "schon", "ge\u00b7lebt", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "ADV", "VVPP", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und wie Legende weit und \u00fcberwunden.", "tokens": ["und", "wie", "Le\u00b7gen\u00b7de", "weit", "und", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "ADJD", "KON", "VVPP", "$."], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Aus ihnen kommt mir Wissen, da\u00df ich Raum", "tokens": ["Aus", "ih\u00b7nen", "kommt", "mir", "Wis\u00b7sen", ",", "da\u00df", "ich", "Raum"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "NN", "$,", "KOUS", "PPER", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "zu einem zweiten zeitlos breiten Leben habe.", "tokens": ["zu", "ei\u00b7nem", "zwei\u00b7ten", "zeit\u00b7los", "brei\u00b7ten", "Le\u00b7ben", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJD", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Und manchmal bin ich wie der Baum,", "tokens": ["Und", "manch\u00b7mal", "bin", "ich", "wie", "der", "Baum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der, reif und rauschend, \u00fcber einem Grabe", "tokens": ["der", ",", "reif", "und", "rau\u00b7schend", ",", "\u00fc\u00b7ber", "ei\u00b7nem", "Gra\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "$,", "ADJD", "KON", "ADJD", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "(um den sich seine warmen Wurzeln dr\u00e4ngen)", "tokens": ["(", "um", "den", "sich", "sei\u00b7ne", "war\u00b7men", "Wur\u00b7zeln", "dr\u00e4n\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PRELS", "PRF", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "verlor in Traurigkeiten und Ges\u00e4ngen.", "tokens": ["ver\u00b7lor", "in", "Trau\u00b7rig\u00b7kei\u00b7ten", "und", "Ge\u00b7s\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Du, Nachbar Gott, wenn ich dich manchesmal", "tokens": ["Du", ",", "Nach\u00b7bar", "Gott", ",", "wenn", "ich", "dich", "man\u00b7ches\u00b7mal"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "NN", "$,", "KOUS", "PPER", "PRF", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "in langer Nacht mit hartem Klopfen st\u00f6re, \u2013", "tokens": ["in", "lan\u00b7ger", "Nacht", "mit", "har\u00b7tem", "Klop\u00b7fen", "st\u00f6\u00b7re", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "so ists, weil ich dich selten atmen h\u00f6re", "tokens": ["so", "ists", ",", "weil", "ich", "dich", "sel\u00b7ten", "at\u00b7men", "h\u00f6\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "$,", "KOUS", "PPER", "PRF", "ADJD", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und wei\u00df: Du bist allein im Saal.", "tokens": ["und", "wei\u00df", ":", "Du", "bist", "al\u00b7lein", "im", "Saal", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wenn du etwas brauchst, ist keiner da,", "tokens": ["Und", "wenn", "du", "et\u00b7was", "brauchst", ",", "ist", "kei\u00b7ner", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "VVFIN", "$,", "VAFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "um deinem Tasten einen Trank zu reichen:", "tokens": ["um", "dei\u00b7nem", "Tas\u00b7ten", "ei\u00b7nen", "Trank", "zu", "rei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ich horche immer. Gieb ein kleines Zeichen.", "tokens": ["Ich", "hor\u00b7che", "im\u00b7mer", ".", "Gieb", "ein", "klei\u00b7nes", "Zei\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "VVIMP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich bin ganz nah.", "tokens": ["Ich", "bin", "ganz", "nah", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "Nur eine schmale Wand ist zwischen uns,", "tokens": ["Nur", "ei\u00b7ne", "schma\u00b7le", "Wand", "ist", "zwi\u00b7schen", "uns", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VAFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "durch Zufall; denn es k\u00f6nnte sein:", "tokens": ["durch", "Zu\u00b7fall", ";", "denn", "es", "k\u00f6nn\u00b7te", "sein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "KON", "PPER", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein Rufen deines oder meines Munds \u2013", "tokens": ["ein", "Ru\u00b7fen", "dei\u00b7nes", "o\u00b7der", "mei\u00b7nes", "Munds", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und sie bricht ein", "tokens": ["und", "sie", "bricht", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "ganz ohne L\u00e4rm und Laut.", "tokens": ["ganz", "oh\u00b7ne", "L\u00e4rm", "und", "Laut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Aus deinen Bildern ist sie aufgebaut.", "tokens": ["Aus", "dei\u00b7nen", "Bil\u00b7dern", "ist", "sie", "auf\u00b7ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Und deine Bilder stehn vor dir wie Namen.", "tokens": ["Und", "dei\u00b7ne", "Bil\u00b7der", "stehn", "vor", "dir", "wie", "Na\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "PPER", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wenn einmal das Licht in mir entbrennt,", "tokens": ["Und", "wenn", "ein\u00b7mal", "das", "Licht", "in", "mir", "ent\u00b7brennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "mit welchem meine Tiefe dich erkennt,", "tokens": ["mit", "wel\u00b7chem", "mei\u00b7ne", "Tie\u00b7fe", "dich", "er\u00b7kennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "vergeudet sichs als Glanz auf ihren Rahmen.", "tokens": ["ver\u00b7geu\u00b7det", "sichs", "als", "Glanz", "auf", "ih\u00b7ren", "Rah\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Und meine Sinne, welche schnell erlahmen,", "tokens": ["Und", "mei\u00b7ne", "Sin\u00b7ne", ",", "wel\u00b7che", "schnell", "er\u00b7lah\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "sind ohne Heimat und von dir getrennt.", "tokens": ["sind", "oh\u00b7ne", "Hei\u00b7mat", "und", "von", "dir", "ge\u00b7trennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "KON", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Wenn es nur einmal so ganz stille w\u00e4re.", "tokens": ["Wenn", "es", "nur", "ein\u00b7mal", "so", "ganz", "stil\u00b7le", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADV", "ADV", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn das Zuf\u00e4llige und Ungef\u00e4hre", "tokens": ["Wenn", "das", "Zu\u00b7f\u00e4l\u00b7li\u00b7ge", "und", "Un\u00b7ge\u00b7f\u00e4h\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "verstummte und das nachbarliche Lachen,", "tokens": ["ver\u00b7stumm\u00b7te", "und", "das", "nach\u00b7bar\u00b7li\u00b7che", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "wenn das Ger\u00e4usch, das meine Sinne machen,", "tokens": ["wenn", "das", "Ge\u00b7r\u00e4usch", ",", "das", "mei\u00b7ne", "Sin\u00b7ne", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "mich nicht so sehr verhinderte am Wachen \u2013:", "tokens": ["mich", "nicht", "so", "sehr", "ver\u00b7hin\u00b7der\u00b7te", "am", "Wa\u00b7chen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "VVFIN", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Dann k\u00f6nnte ich in einem tausendfachen", "tokens": ["Dann", "k\u00f6nn\u00b7te", "ich", "in", "ei\u00b7nem", "tau\u00b7send\u00b7fa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gedanken bis an deinen Rand dich denken", "tokens": ["Ge\u00b7dan\u00b7ken", "bis", "an", "dei\u00b7nen", "Rand", "dich", "den\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und dich besitzen (nur ein L\u00e4cheln lang),", "tokens": ["und", "dich", "be\u00b7sit\u00b7zen", "(", "nur", "ein", "L\u00e4\u00b7cheln", "lang", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$(", "ADV", "ART", "NN", "ADJD", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "um dich an alles Leben zu verschenken", "tokens": ["um", "dich", "an", "al\u00b7les", "Le\u00b7ben", "zu", "ver\u00b7schen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PRF", "APPR", "PIAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wie einen Dank.", "tokens": ["wie", "ei\u00b7nen", "Dank", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.20": {"line.1": {"text": "Ich lebe grad, da das Jahrhundert geht.", "tokens": ["Ich", "le\u00b7be", "grad", ",", "da", "das", "Jahr\u00b7hun\u00b7dert", "geht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Man f\u00fchlt den Wind von einem gro\u00dfen Blatt,", "tokens": ["Man", "f\u00fchlt", "den", "Wind", "von", "ei\u00b7nem", "gro\u00b7\u00dfen", "Blatt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "das Gott und du und ich beschrieben hat", "tokens": ["das", "Gott", "und", "du", "und", "ich", "be\u00b7schrie\u00b7ben", "hat"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PPER", "KON", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und das sich hoch in fremden H\u00e4nden dreht.", "tokens": ["und", "das", "sich", "hoch", "in", "frem\u00b7den", "H\u00e4n\u00b7den", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PRF", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Man f\u00fchlt den Glanz von einer neuen Seite,", "tokens": ["Man", "f\u00fchlt", "den", "Glanz", "von", "ei\u00b7ner", "neu\u00b7en", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "auf der noch Alles werden kann.", "tokens": ["auf", "der", "noch", "Al\u00b7les", "wer\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIS", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Die stillen Kr\u00e4fte pr\u00fcfen ihre Breite", "tokens": ["Die", "stil\u00b7len", "Kr\u00e4f\u00b7te", "pr\u00fc\u00b7fen", "ih\u00b7re", "Brei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und sehn einander dunkel an.", "tokens": ["und", "sehn", "ein\u00b7an\u00b7der", "dun\u00b7kel", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Ich lese es heraus aus deinem Wort,", "tokens": ["Ich", "le\u00b7se", "es", "he\u00b7raus", "aus", "dei\u00b7nem", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus der Geschichte der Geb\u00e4rden,", "tokens": ["aus", "der", "Ge\u00b7schich\u00b7te", "der", "Ge\u00b7b\u00e4r\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mit welchen deine H\u00e4nde um das Werden", "tokens": ["mit", "wel\u00b7chen", "dei\u00b7ne", "H\u00e4n\u00b7de", "um", "das", "Wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sich r\u00fcndeten, begrenzend, warm und weise.", "tokens": ["sich", "r\u00fcn\u00b7de\u00b7ten", ",", "be\u00b7gren\u00b7zend", ",", "warm", "und", "wei\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "VVPP", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Du sagtest ", "tokens": ["Du", "sag\u00b7test"], "token_info": ["word", "word"], "pos": ["PPER", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "und wiederholtest immer wieder: ", "tokens": ["und", "wie\u00b7der\u00b7hol\u00b7test", "im\u00b7mer", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch vor dem ersten Tode kam der Mord.", "tokens": ["Doch", "vor", "dem", "ers\u00b7ten", "To\u00b7de", "kam", "der", "Mord", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Da ging ein Ri\u00df durch deine reifen Kreise", "tokens": ["Da", "ging", "ein", "Ri\u00df", "durch", "dei\u00b7ne", "rei\u00b7fen", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und ging ein Schrein", "tokens": ["und", "ging", "ein", "Schrein"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "und ri\u00df die Stimmen fort,", "tokens": ["und", "ri\u00df", "die", "Stim\u00b7men", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "die eben erst sich sammelten", "tokens": ["die", "e\u00b7ben", "erst", "sich", "sam\u00b7mel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "PRF", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "um dich zu sagen,", "tokens": ["um", "dich", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "um dich zu tragen", "tokens": ["um", "dich", "zu", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "alles Abgrunds Br\u00fccke \u2013", "tokens": ["al\u00b7les", "Ab\u00b7grunds", "Br\u00fc\u00b7cke", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Und was sie seither stammelten,", "tokens": ["Und", "was", "sie", "sei\u00b7ther", "stam\u00b7mel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "sind St\u00fccke", "tokens": ["sind", "St\u00fc\u00b7cke"], "token_info": ["word", "word"], "pos": ["VAFIN", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "deines alten Namens.", "tokens": ["dei\u00b7nes", "al\u00b7ten", "Na\u00b7mens", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.25": {"line.1": {"text": "Ich bin nicht. Der Bruder hat mir was getan,", "tokens": ["Ich", "bin", "nicht", ".", "Der", "Bru\u00b7der", "hat", "mir", "was", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "$.", "ART", "NN", "VAFIN", "PPER", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "was meine Augen nicht sahn.", "tokens": ["was", "mei\u00b7ne", "Au\u00b7gen", "nicht", "sahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Er hat mir das Licht verh\u00e4ngt.", "tokens": ["Er", "hat", "mir", "das", "Licht", "ver\u00b7h\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er hat mein Gesicht verdr\u00e4ngt", "tokens": ["Er", "hat", "mein", "Ge\u00b7sicht", "ver\u00b7dr\u00e4ngt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "mit seinem Gesicht.", "tokens": ["mit", "sei\u00b7nem", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Er ist jetzt allein.", "tokens": ["Er", "ist", "jetzt", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Ich denke, er mu\u00df noch sein.", "tokens": ["Ich", "den\u00b7ke", ",", "er", "mu\u00df", "noch", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "ADV", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Denn ihm tut niemand, wie er mir getan.", "tokens": ["Denn", "ihm", "tut", "nie\u00b7mand", ",", "wie", "er", "mir", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$,", "PWAV", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Es gingen alle meine Bahn,", "tokens": ["Es", "gin\u00b7gen", "al\u00b7le", "mei\u00b7ne", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "kommen alle vor seinen Zorn,", "tokens": ["kom\u00b7men", "al\u00b7le", "vor", "sei\u00b7nen", "Zorn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.11": {"text": "gehen alle an ihm verloren.", "tokens": ["ge\u00b7hen", "al\u00b7le", "an", "ihm", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.26": {"line.1": {"text": "Ich glaube, mein gro\u00dfer Bruder wacht", "tokens": ["Ich", "glau\u00b7be", ",", "mein", "gro\u00b7\u00dfer", "Bru\u00b7der", "wacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "wie ein Gericht.", "tokens": ["wie", "ein", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "An mich hat die Nacht gedacht;", "tokens": ["An", "mich", "hat", "die", "Nacht", "ge\u00b7dacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "an ihn nicht.", "tokens": ["an", "ihn", "nicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.27": {"line.1": {"text": "Du Dunkelheit, aus der ich stamme,", "tokens": ["Du", "Dun\u00b7kel\u00b7heit", ",", "aus", "der", "ich", "stam\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ich liebe dich mehr als die Flamme,", "tokens": ["ich", "lie\u00b7be", "dich", "mehr", "als", "die", "Flam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "welche die Welt begrenzt,", "tokens": ["wel\u00b7che", "die", "Welt", "be\u00b7grenzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRELS", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "indem sie gl\u00e4nzt", "tokens": ["in\u00b7dem", "sie", "gl\u00e4nzt"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "f\u00fcr irgend einen Kreis,", "tokens": ["f\u00fcr", "ir\u00b7gend", "ei\u00b7nen", "Kreis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "aus dem heraus kein Wesen von ihr wei\u00df.", "tokens": ["aus", "dem", "he\u00b7raus", "kein", "We\u00b7sen", "von", "ihr", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Aber die Dunkelheit h\u00e4lt alles an sich:", "tokens": ["A\u00b7ber", "die", "Dun\u00b7kel\u00b7heit", "h\u00e4lt", "al\u00b7les", "an", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIS", "APPR", "PRF", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Gestalten und Flammen, Tiere und mich,", "tokens": ["Ge\u00b7stal\u00b7ten", "und", "Flam\u00b7men", ",", "Tie\u00b7re", "und", "mich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "ADJA", "KON", "PPER", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "wie sie's errafft,", "tokens": ["wie", "sie's", "er\u00b7rafft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Menschen und M\u00e4chte \u2013", "tokens": ["Men\u00b7schen", "und", "M\u00e4ch\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.29": {"line.1": {"text": "Und es kann sein: eine gro\u00dfe Kraft", "tokens": ["Und", "es", "kann", "sein", ":", "ei\u00b7ne", "gro\u00b7\u00dfe", "Kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "VAINF", "$.", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "r\u00fchrt sich in meiner Nachbarschaft.", "tokens": ["r\u00fchrt", "sich", "in", "mei\u00b7ner", "Nach\u00b7bar\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.30": {"line.1": {"text": "Ich glaube an N\u00e4chte.", "tokens": ["Ich", "glau\u00b7be", "an", "N\u00e4ch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.31": {"line.1": {"text": "Ich glaube an Alles noch nie Gesagte.", "tokens": ["Ich", "glau\u00b7be", "an", "Al\u00b7les", "noch", "nie", "Ge\u00b7sag\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "ADV", "ADV", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ich will meine fr\u00f6mmsten Gef\u00fchle befrein.", "tokens": ["Ich", "will", "mei\u00b7ne", "fr\u00f6mms\u00b7ten", "Ge\u00b7f\u00fch\u00b7le", "be\u00b7fr\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Was noch keiner zu wollen wagte,", "tokens": ["Was", "noch", "kei\u00b7ner", "zu", "wol\u00b7len", "wag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIS", "PTKZU", "VMINF", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "wird mir einmal unwillk\u00fcrlich sein.", "tokens": ["wird", "mir", "ein\u00b7mal", "un\u00b7will\u00b7k\u00fcr\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.32": {"line.1": {"text": "Ist das vermessen, mein Gott, vergieb.", "tokens": ["Ist", "das", "ver\u00b7mes\u00b7sen", ",", "mein", "Gott", ",", "ver\u00b7gieb", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PDS", "VVINF", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Aber ich will dir damit nur sagen:", "tokens": ["A\u00b7ber", "ich", "will", "dir", "da\u00b7mit", "nur", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PAV", "ADV", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Meine beste Kraft soll sein wie ein Trieb,", "tokens": ["Mei\u00b7ne", "bes\u00b7te", "Kraft", "soll", "sein", "wie", "ein", "Trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "VAINF", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "so ohne Z\u00fcrnen und ohne Zagen;", "tokens": ["so", "oh\u00b7ne", "Z\u00fcr\u00b7nen", "und", "oh\u00b7ne", "Za\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "so haben dich ja die Kinder lieb.", "tokens": ["so", "ha\u00b7ben", "dich", "ja", "die", "Kin\u00b7der", "lieb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "Mit diesem Hinfluten, mit diesem M\u00fcnden", "tokens": ["Mit", "die\u00b7sem", "Hin\u00b7flu\u00b7ten", ",", "mit", "die\u00b7sem", "M\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "in breiten Armen ins offene Meer,", "tokens": ["in", "brei\u00b7ten", "Ar\u00b7men", "ins", "of\u00b7fe\u00b7ne", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "mit dieser wachsenden Wiederkehr", "tokens": ["mit", "die\u00b7ser", "wach\u00b7sen\u00b7den", "Wie\u00b7der\u00b7kehr"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "will ich dich bekennen, will ich dich verk\u00fcnden", "tokens": ["will", "ich", "dich", "be\u00b7ken\u00b7nen", ",", "will", "ich", "dich", "ver\u00b7k\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$,", "VMFIN", "PPER", "PRF", "VVINF"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "wie keiner vorher.", "tokens": ["wie", "kei\u00b7ner", "vor\u00b7her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.34": {"line.1": {"text": "Und ist das Hoffahrt, so la\u00df mich hoff\u00e4hrtig sein", "tokens": ["Und", "ist", "das", "Hof\u00b7fahrt", ",", "so", "la\u00df", "mich", "hof\u00b7f\u00e4hr\u00b7tig", "sein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "$,", "ADV", "VVIMP", "PPER", "ADJD", "VAINF"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "f\u00fcr mein Gebet,", "tokens": ["f\u00fcr", "mein", "Ge\u00b7bet", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+--", "measure": "dactylic.init"}, "line.3": {"text": "das so ernst und allein", "tokens": ["das", "so", "ernst", "und", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "ADJD", "KON", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "vor deiner wolkigen Stirne steht.", "tokens": ["vor", "dei\u00b7ner", "wol\u00b7ki\u00b7gen", "Stir\u00b7ne", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.35": {"line.1": {"text": "Ich bin auf der Welt zu allein und doch nicht allein genug,", "tokens": ["Ich", "bin", "auf", "der", "Welt", "zu", "al\u00b7lein", "und", "doch", "nicht", "al\u00b7lein", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "ADV", "KON", "ADV", "PTKNEG", "ADV", "ADV", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "um jede Stunde zu weihn.", "tokens": ["um", "je\u00b7de", "Stun\u00b7de", "zu", "weihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich bin auf der Welt zu gering und doch nicht klein genug,", "tokens": ["Ich", "bin", "auf", "der", "Welt", "zu", "ge\u00b7ring", "und", "doch", "nicht", "klein", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PTKA", "ADJD", "KON", "ADV", "PTKNEG", "ADJD", "ADV", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "um vor dir zu sein wie ein Ding,", "tokens": ["um", "vor", "dir", "zu", "sein", "wie", "ein", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "PPER", "PTKZU", "VAINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "dunkel und klug.", "tokens": ["dun\u00b7kel", "und", "klug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Ich will meinen Willen und will meinen Willen begleiten", "tokens": ["Ich", "will", "mei\u00b7nen", "Wil\u00b7len", "und", "will", "mei\u00b7nen", "Wil\u00b7len", "be\u00b7glei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "KON", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "+---+-+-+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "die Wege zur Tat;", "tokens": ["die", "We\u00b7ge", "zur", "Tat", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "und will in stillen, irgendwie z\u00f6gernden Zeiten,", "tokens": ["und", "will", "in", "stil\u00b7len", ",", "ir\u00b7gend\u00b7wie", "z\u00f6\u00b7gern\u00b7den", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ADJA", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "wenn etwas naht,", "tokens": ["wenn", "et\u00b7was", "naht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "unter den Wissenden sein", "tokens": ["un\u00b7ter", "den", "Wis\u00b7sen\u00b7den", "sein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.11": {"text": "oder allein.", "tokens": ["o\u00b7der", "al\u00b7lein", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.12": {"text": "Ich will dich immer spiegeln in ganzer Gestalt,", "tokens": ["Ich", "will", "dich", "im\u00b7mer", "spie\u00b7geln", "in", "gan\u00b7zer", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "und will niemals blind sein oder zu alt", "tokens": ["und", "will", "nie\u00b7mals", "blind", "sein", "o\u00b7der", "zu", "alt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "ADJD", "VAINF", "KON", "PTKA", "ADJD"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "um dein schweres schwankendes Bild zu halten.", "tokens": ["um", "dein", "schwe\u00b7res", "schwan\u00b7ken\u00b7des", "Bild", "zu", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Ich will mich entfalten.", "tokens": ["Ich", "will", "mich", "ent\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.16": {"text": "Nirgends will ich gebogen bleiben,", "tokens": ["Nir\u00b7gends", "will", "ich", "ge\u00b7bo\u00b7gen", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVPP", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.17": {"text": "denn dort bin ich gelogen, wo ich gebogen bin.", "tokens": ["denn", "dort", "bin", "ich", "ge\u00b7lo\u00b7gen", ",", "wo", "ich", "ge\u00b7bo\u00b7gen", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "VVPP", "$,", "PWAV", "PPER", "VVPP", "VAFIN", "$."], "meter": "-++--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Und ich will meinen Sinn", "tokens": ["Und", "ich", "will", "mei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "wahr vor dir. Ich will mich beschreiben", "tokens": ["wahr", "vor", "dir", ".", "Ich", "will", "mich", "be\u00b7schrei\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPER", "$.", "PPER", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "wie ein Bild das ich sah,", "tokens": ["wie", "ein", "Bild", "das", "ich", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "PPER", "VVFIN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.21": {"text": "lange und nah,", "tokens": ["lan\u00b7ge", "und", "nah", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADJD", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.22": {"text": "wie ein Wort, das ich begriff,", "tokens": ["wie", "ein", "Wort", ",", "das", "ich", "be\u00b7griff", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.23": {"text": "wie meinen t\u00e4glichen Krug,", "tokens": ["wie", "mei\u00b7nen", "t\u00e4g\u00b7li\u00b7chen", "Krug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.24": {"text": "wie meiner Mutter Gesicht,", "tokens": ["wie", "mei\u00b7ner", "Mut\u00b7ter", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.25": {"text": "wie ein Schiff,", "tokens": ["wie", "ein", "Schiff", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.26": {"text": "das mich trug", "tokens": ["das", "mich", "trug"], "token_info": ["word", "word", "word"], "pos": ["ART", "PPER", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.27": {"text": "durch den t\u00f6dlichsten Sturm.", "tokens": ["durch", "den", "t\u00f6d\u00b7lichs\u00b7ten", "Sturm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.36": {"line.1": {"text": "Du siehst, ich will viel.", "tokens": ["Du", "siehst", ",", "ich", "will", "viel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Vielleicht will ich Alles:", "tokens": ["Viel\u00b7leicht", "will", "ich", "Al\u00b7les", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "$."], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.3": {"text": "das Dunkel jedes unendlichen Falles", "tokens": ["das", "Dun\u00b7kel", "je\u00b7des", "un\u00b7end\u00b7li\u00b7chen", "Fal\u00b7les"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und jedes Steigens lichtzitterndes Spiel.", "tokens": ["und", "je\u00b7des", "Stei\u00b7gens", "licht\u00b7zit\u00b7tern\u00b7des", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.37": {"line.1": {"text": "Es leben so viele und wollen nichts,", "tokens": ["Es", "le\u00b7ben", "so", "vie\u00b7le", "und", "wol\u00b7len", "nichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "KON", "VMFIN", "PIS", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "und sind durch ihres leichten Gerichts", "tokens": ["und", "sind", "durch", "ih\u00b7res", "leich\u00b7ten", "Ge\u00b7richts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "glatte Gef\u00fchle gef\u00fcrstet.", "tokens": ["glat\u00b7te", "Ge\u00b7f\u00fch\u00b7le", "ge\u00b7f\u00fcrs\u00b7tet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.38": {"line.1": {"text": "Aber du freust dich jedes Gesichts,", "tokens": ["A\u00b7ber", "du", "freust", "dich", "je\u00b7des", "Ge\u00b7sichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "das dient und d\u00fcrstet.", "tokens": ["das", "dient", "und", "d\u00fcrs\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.39": {"line.1": {"text": "Du freust dich Aller, die dich gebrauchen", "tokens": ["Du", "freust", "dich", "Al\u00b7ler", ",", "die", "dich", "ge\u00b7brau\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "PRELS", "PRF", "VVINF"], "meter": "-+----+-+-", "measure": "dactylic.init"}, "line.2": {"text": "wie ein Ger\u00e4t.", "tokens": ["wie", "ein", "Ge\u00b7r\u00e4t", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.40": {"line.1": {"text": "Noch bist du nicht kalt, und es ist nicht zu sp\u00e4t,", "tokens": ["Noch", "bist", "du", "nicht", "kalt", ",", "und", "es", "ist", "nicht", "zu", "sp\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "KON", "PPER", "VAFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "in deine werdenden Tiefen zu tauchen,", "tokens": ["in", "dei\u00b7ne", "wer\u00b7den\u00b7den", "Tie\u00b7fen", "zu", "tau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "wo sich das Leben ruhig verr\u00e4t.", "tokens": ["wo", "sich", "das", "Le\u00b7ben", "ru\u00b7hig", "ver\u00b7r\u00e4t", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.41": {"line.1": {"text": "Wir bauen an dir mit zitternden H\u00e4nden", "tokens": ["Wir", "bau\u00b7en", "an", "dir", "mit", "zit\u00b7tern\u00b7den", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und wir t\u00fcrmen Atom auf Atom.", "tokens": ["und", "wir", "t\u00fcr\u00b7men", "A\u00b7tom", "auf", "A\u00b7tom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJA", "NN", "APPR", "NE", "$."], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Aber wer kann dich vollenden,", "tokens": ["A\u00b7ber", "wer", "kann", "dich", "voll\u00b7en\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VMFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "du Dom.", "tokens": ["du", "Dom", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.42": {"line.1": {"text": "Was ist Rom?", "tokens": ["Was", "ist", "Rom", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Es zerf\u00e4llt.", "tokens": ["Es", "zer\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Was ist die Welt?", "tokens": ["Was", "ist", "die", "Welt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sie wird zerschlagen", "tokens": ["Sie", "wird", "zer\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "eh deine T\u00fcrme Kuppeln tragen,", "tokens": ["eh", "dei\u00b7ne", "T\u00fcr\u00b7me", "Kup\u00b7peln", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "eh aus Meilen von Mosaik", "tokens": ["eh", "aus", "Mei\u00b7len", "von", "Mo\u00b7saik"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "deine strahlende Stirne stieg.", "tokens": ["dei\u00b7ne", "strah\u00b7len\u00b7de", "Stir\u00b7ne", "stieg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.43": {"line.1": {"text": "Aber manchmal im Traum", "tokens": ["A\u00b7ber", "manch\u00b7mal", "im", "Traum"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "kann ich deinen Raum", "tokens": ["kann", "ich", "dei\u00b7nen", "Raum"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "\u00fcberschaun,", "tokens": ["\u00fc\u00b7bersc\u00b7haun", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.4": {"text": "tief vom Beginne", "tokens": ["tief", "vom", "Be\u00b7gin\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "APPRART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "bis zu des Daches goldenem Grate.", "tokens": ["bis", "zu", "des", "Da\u00b7ches", "gol\u00b7de\u00b7nem", "Gra\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.44": {"line.1": {"text": "Und ich seh: meine Sinne", "tokens": ["Und", "ich", "seh", ":", "mei\u00b7ne", "Sin\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "bilden und baun", "tokens": ["bil\u00b7den", "und", "baun"], "token_info": ["word", "word", "word"], "pos": ["VVINF", "KON", "VVINF"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "die letzten Zierate.", "tokens": ["die", "letz\u00b7ten", "Zie\u00b7ra\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Daraus, da\u00df Einer dich einmal gewollt hat,", "tokens": ["Da\u00b7raus", ",", "da\u00df", "Ei\u00b7ner", "dich", "ein\u00b7mal", "ge\u00b7wollt", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PIS", "PPER", "ADV", "VMPP", "VAFIN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "wei\u00df ich, da\u00df wir dich wollen d\u00fcrfen.", "tokens": ["wei\u00df", "ich", ",", "da\u00df", "wir", "dich", "wol\u00b7len", "d\u00fcr\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn wir auch alle Tiefen verw\u00fcrfen:", "tokens": ["Wenn", "wir", "auch", "al\u00b7le", "Tie\u00b7fen", "ver\u00b7w\u00fcr\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "wenn ein Gebirge Gold hat", "tokens": ["wenn", "ein", "Ge\u00b7bir\u00b7ge", "Gold", "hat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "und keiner mehr es ergraben mag,", "tokens": ["und", "kei\u00b7ner", "mehr", "es", "er\u00b7gra\u00b7ben", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "tr\u00e4gt es einmal der Flu\u00df zutag,", "tokens": ["tr\u00e4gt", "es", "ein\u00b7mal", "der", "Flu\u00df", "zu\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "der in die Stille der Steine greift,", "tokens": ["der", "in", "die", "Stil\u00b7le", "der", "Stei\u00b7ne", "greift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "der vollen.", "tokens": ["der", "vol\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "ADJA", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.46": {"line.1": {"text": "Auch wenn wir nicht wollen:", "tokens": ["Auch", "wenn", "wir", "nicht", "wol\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.47": {"line.1": {"text": "Wer seines Lebens viele Widersinne", "tokens": ["Wer", "sei\u00b7nes", "Le\u00b7bens", "vie\u00b7le", "Wi\u00b7der\u00b7sin\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "vers\u00f6hnt und dankbar in ein Sinnbild fa\u00dft,", "tokens": ["ver\u00b7s\u00f6hnt", "und", "dank\u00b7bar", "in", "ein", "Sinn\u00b7bild", "fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der dr\u00e4ngt", "tokens": ["der", "dr\u00e4ngt"], "token_info": ["word", "word"], "pos": ["ART", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "die L\u00e4rmenden aus dem Palast,", "tokens": ["die", "L\u00e4r\u00b7men\u00b7den", "aus", "dem", "Pa\u00b7last", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "wird ", "tokens": ["wird"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "den er an sanften Abenden empf\u00e4ngt.", "tokens": ["den", "er", "an", "sanf\u00b7ten", "A\u00b7ben\u00b7den", "emp\u00b7f\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Du bist der Zweite seiner Einsamkeit,", "tokens": ["Du", "bist", "der", "Zwei\u00b7te", "sei\u00b7ner", "Ein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die ruhige Mitte seinen Monologen;", "tokens": ["die", "ru\u00b7hi\u00b7ge", "Mit\u00b7te", "sei\u00b7nen", "Mo\u00b7no\u00b7lo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "und jeder Kreis, um dich gezogen,", "tokens": ["und", "je\u00b7der", "Kreis", ",", "um", "dich", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "KOUI", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "spannt ihm den Zirkel aus der Zeit.", "tokens": ["spannt", "ihm", "den", "Zir\u00b7kel", "aus", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.49": {"line.1": {"text": "Was irren meine H\u00e4nde in den Pinseln?", "tokens": ["Was", "ir\u00b7ren", "mei\u00b7ne", "H\u00e4n\u00b7de", "in", "den", "Pin\u00b7seln", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn ich dich ", "tokens": ["Wenn", "ich", "dich"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "PRF"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.50": {"line.1": {"text": "Ich ", "tokens": ["Ich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "beginnst du z\u00f6gernd, wie mit vielen Inseln,", "tokens": ["be\u00b7ginnst", "du", "z\u00f6\u00b7gernd", ",", "wie", "mit", "vie\u00b7len", "In\u00b7seln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "$,", "PWAV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und deinen Augen, welche niemals blinseln,", "tokens": ["und", "dei\u00b7nen", "Au\u00b7gen", ",", "wel\u00b7che", "nie\u00b7mals", "blin\u00b7seln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "bin ich der Raum.", "tokens": ["bin", "ich", "der", "Raum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.51": {"line.1": {"text": "Du bist nichtmehr inmitten deines Glanzes,", "tokens": ["Du", "bist", "nicht\u00b7mehr", "in\u00b7mit\u00b7ten", "dei\u00b7nes", "Glan\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wo alle Linien des Engeltanzes", "tokens": ["wo", "al\u00b7le", "Li\u00b7ni\u00b7en", "des", "En\u00b7gel\u00b7tan\u00b7zes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die Fernen dir verbrauchen wie Musik, \u2013", "tokens": ["die", "Fer\u00b7nen", "dir", "ver\u00b7brau\u00b7chen", "wie", "Mu\u00b7sik", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "PPER", "VVINF", "KOKOM", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "du wohnst in deinem allerletzten Haus.", "tokens": ["du", "wohnst", "in", "dei\u00b7nem", "al\u00b7ler\u00b7letz\u00b7ten", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Dein ganzer Himmel horcht in mich hinaus,", "tokens": ["Dein", "gan\u00b7zer", "Him\u00b7mel", "horcht", "in", "mich", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "PRF", "APZR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "weil ich mich sinnend dir verschwieg.", "tokens": ["weil", "ich", "mich", "sin\u00b7nend", "dir", "ver\u00b7schwieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Ich bin, du \u00c4ngstlicher. H\u00f6rst du mich nicht", "tokens": ["Ich", "bin", ",", "du", "\u00c4ngst\u00b7li\u00b7cher", ".", "H\u00f6rst", "du", "mich", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PPER", "NN", "$.", "VVFIN", "PPER", "PRF", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit allen meinen Sinnen an dir branden?", "tokens": ["mit", "al\u00b7len", "mei\u00b7nen", "Sin\u00b7nen", "an", "dir", "bran\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Meine Gef\u00fchle, welche Fl\u00fcgel fanden,", "tokens": ["Mei\u00b7ne", "Ge\u00b7f\u00fch\u00b7le", ",", "wel\u00b7che", "Fl\u00fc\u00b7gel", "fan\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAT", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "umkreisen wei\u00df dein Angesicht.", "tokens": ["um\u00b7krei\u00b7sen", "wei\u00df", "dein", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVINF", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Siehst du nicht meine Seele, wie sie dicht", "tokens": ["Siehst", "du", "nicht", "mei\u00b7ne", "See\u00b7le", ",", "wie", "sie", "dicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$,", "PWAV", "PPER", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "vor dir in einem Kleid aus Stille steht?", "tokens": ["vor", "dir", "in", "ei\u00b7nem", "Kleid", "aus", "Stil\u00b7le", "steht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Reift nicht mein mailiches Gebet", "tokens": ["Reift", "nicht", "mein", "mai\u00b7li\u00b7ches", "Ge\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.8": {"text": "an deinem Blicke wie an einem Baum?", "tokens": ["an", "dei\u00b7nem", "Bli\u00b7cke", "wie", "an", "ei\u00b7nem", "Baum", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Wenn du der Tr\u00e4umer bist, bin ich dein Traum.", "tokens": ["Wenn", "du", "der", "Tr\u00e4u\u00b7mer", "bist", ",", "bin", "ich", "dein", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$,", "VAFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch wenn du wachen willst, bin ich dein Wille", "tokens": ["Doch", "wenn", "du", "wa\u00b7chen", "willst", ",", "bin", "ich", "dein", "Wil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "VAFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und werde m\u00e4chtig aller Herrlichkeit", "tokens": ["und", "wer\u00b7de", "m\u00e4ch\u00b7tig", "al\u00b7ler", "Herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und r\u00fcnde mich wie eine Sternenstille", "tokens": ["und", "r\u00fcn\u00b7de", "mich", "wie", "ei\u00b7ne", "Ster\u00b7nen\u00b7stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "\u00fcber der wunderlichen Stadt der Zeit.", "tokens": ["\u00fc\u00b7ber", "der", "wun\u00b7der\u00b7li\u00b7chen", "Stadt", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.54": {"line.1": {"text": "Mein Leben ist nicht diese steile Stunde,", "tokens": ["Mein", "Le\u00b7ben", "ist", "nicht", "die\u00b7se", "stei\u00b7le", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "darin du mich so eilen siehst.", "tokens": ["da\u00b7rin", "du", "mich", "so", "ei\u00b7len", "siehst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin ein Baum vor meinem Hintergrunde,", "tokens": ["Ich", "bin", "ein", "Baum", "vor", "mei\u00b7nem", "Hin\u00b7ter\u00b7grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ich bin nur einer meiner vielen Munde", "tokens": ["ich", "bin", "nur", "ei\u00b7ner", "mei\u00b7ner", "vie\u00b7len", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "PPOSAT", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und jener, welcher sich am fr\u00fchsten schlie\u00dft.", "tokens": ["und", "je\u00b7ner", ",", "wel\u00b7cher", "sich", "am", "fr\u00fchs\u00b7ten", "schlie\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "PRF", "APPRART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Ich bin die Ruhe zwischen zweien T\u00f6nen,", "tokens": ["Ich", "bin", "die", "Ru\u00b7he", "zwi\u00b7schen", "zwei\u00b7en", "T\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die sich nur schlecht aneinander gew\u00f6hnen:", "tokens": ["die", "sich", "nur", "schlecht", "an\u00b7ein\u00b7an\u00b7der", "ge\u00b7w\u00f6h\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "ADV", "ADJD", "ADV", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "denn der Ton Tod will sich erh\u00f6hn \u2013", "tokens": ["denn", "der", "Ton", "Tod", "will", "sich", "er\u00b7h\u00f6hn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VMFIN", "PRF", "VVINF", "$("], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}}, "stanza.56": {"line.1": {"text": "Aber im dunklen Intervall vers\u00f6hnen", "tokens": ["A\u00b7ber", "im", "dunk\u00b7len", "In\u00b7ter\u00b7vall", "ver\u00b7s\u00f6h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "sich beide zitternd.", "tokens": ["sich", "bei\u00b7de", "zit\u00b7ternd", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "PIS", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Und das Lied bleibt sch\u00f6n.", "tokens": ["Und", "das", "Lied", "bleibt", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Wenn ich gewachsen w\u00e4re irgendwo,", "tokens": ["Wenn", "ich", "ge\u00b7wach\u00b7sen", "w\u00e4\u00b7re", "ir\u00b7gend\u00b7wo", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wo leichtere Tage sind und schlanke Stunden,", "tokens": ["wo", "leich\u00b7te\u00b7re", "Ta\u00b7ge", "sind", "und", "schlan\u00b7ke", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VAFIN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "ich h\u00e4tte dir ein gro\u00dfes Fest erfunden,", "tokens": ["ich", "h\u00e4t\u00b7te", "dir", "ein", "gro\u00b7\u00dfes", "Fest", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und meine H\u00e4nde hielten dich nicht so,", "tokens": ["und", "mei\u00b7ne", "H\u00e4n\u00b7de", "hiel\u00b7ten", "dich", "nicht", "so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "wie sie dich manchmal halten, bang und hart.", "tokens": ["wie", "sie", "dich", "manch\u00b7mal", "hal\u00b7ten", ",", "bang", "und", "hart", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "VVINF", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.58": {"line.1": {"text": "Dort h\u00e4tte ich gewagt, dich zu vergeuden,", "tokens": ["Dort", "h\u00e4t\u00b7te", "ich", "ge\u00b7wagt", ",", "dich", "zu", "ver\u00b7geu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "du grenzenlose Gegenwart.", "tokens": ["du", "gren\u00b7zen\u00b7lo\u00b7se", "Ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie einen Ball", "tokens": ["Wie", "ei\u00b7nen", "Ball"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "h\u00e4tt ich dich in alle wogenden Freuden", "tokens": ["h\u00e4tt", "ich", "dich", "in", "al\u00b7le", "wo\u00b7gen\u00b7den", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "hineingeschleudert, da\u00df einer dich finge", "tokens": ["hin\u00b7ein\u00b7ge\u00b7schleu\u00b7dert", ",", "da\u00df", "ei\u00b7ner", "dich", "fin\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "PIS", "PPER", "VVFIN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "und deinem Fall", "tokens": ["und", "dei\u00b7nem", "Fall"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "mit hohen H\u00e4nden entgegenspringe,", "tokens": ["mit", "ho\u00b7hen", "H\u00e4n\u00b7den", "ent\u00b7ge\u00b7gen\u00b7sprin\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "du Ding der Dinge.", "tokens": ["du", "Ding", "der", "Din\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.59": {"line.1": {"text": "Ich h\u00e4tte dich wie eine Klinge", "tokens": ["Ich", "h\u00e4t\u00b7te", "dich", "wie", "ei\u00b7ne", "Klin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "blitzen lassen.", "tokens": ["blit\u00b7zen", "las\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Vom goldensten Ringe", "tokens": ["Vom", "gol\u00b7dens\u00b7ten", "Rin\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "lie\u00df ich dein Feuer umfassen,", "tokens": ["lie\u00df", "ich", "dein", "Feu\u00b7er", "um\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "und er m\u00fc\u00dfte mirs halten", "tokens": ["und", "er", "m\u00fc\u00df\u00b7te", "mirs", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "NE", "VVINF"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "\u00fcber die wei\u00dfeste Hand.", "tokens": ["\u00fc\u00b7ber", "die", "wei\u00b7\u00dfes\u00b7te", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.60": {"line.1": {"text": "Gemalt h\u00e4tt ich dich: nicht an die Wand,", "tokens": ["Ge\u00b7malt", "h\u00e4tt", "ich", "dich", ":", "nicht", "an", "die", "Wand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PRF", "$.", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "an den Himmel selber von Rand zu Rand,", "tokens": ["an", "den", "Him\u00b7mel", "sel\u00b7ber", "von", "Rand", "zu", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "APPR", "NN", "APPR", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "und h\u00e4tt dich gebildet, wie ein Gigant", "tokens": ["und", "h\u00e4tt", "dich", "ge\u00b7bil\u00b7det", ",", "wie", "ein", "Gi\u00b7gant"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "VVPP", "$,", "PWAV", "ART", "NN"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "dich bilden w\u00fcrde: als Berg, als Brand,", "tokens": ["dich", "bil\u00b7den", "w\u00fcr\u00b7de", ":", "als", "Berg", ",", "als", "Brand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VAFIN", "$.", "KOUS", "NN", "$,", "KOUS", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "als Samum, wachsend aus W\u00fcstensand \u2013", "tokens": ["als", "Sa\u00b7mum", ",", "wach\u00b7send", "aus", "W\u00fcs\u00b7ten\u00b7sand", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "ADJD", "APPR", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "oder", "tokens": ["o\u00b7der"], "token_info": ["word"], "pos": ["KON"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "es kann auch sein: ich fand", "tokens": ["es", "kann", "auch", "sein", ":", "ich", "fand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "VAINF", "$.", "PPER", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "dich einmal ...", "tokens": ["dich", "ein\u00b7mal", "..."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "ADV", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Meine Freunde sind weit,", "tokens": ["Mei\u00b7ne", "Freun\u00b7de", "sind", "weit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "ich h\u00f6re kaum noch ihr Lachen schallen;", "tokens": ["ich", "h\u00f6\u00b7re", "kaum", "noch", "ihr", "La\u00b7chen", "schal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "und du: du bist aus dem Nest gefallen,", "tokens": ["und", "du", ":", "du", "bist", "aus", "dem", "Nest", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$.", "PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.12": {"text": "bist ein junger Vogel mit gelben Krallen", "tokens": ["bist", "ein", "jun\u00b7ger", "Vo\u00b7gel", "mit", "gel\u00b7ben", "Kral\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "und gro\u00dfen Augen und tust mir leid.", "tokens": ["und", "gro\u00b7\u00dfen", "Au\u00b7gen", "und", "tust", "mir", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "(meine Hand ist dir viel zu breit.)", "tokens": ["(", "mei\u00b7ne", "Hand", "ist", "dir", "viel", "zu", "breit", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.15": {"text": "Und ich heb mit dem Finger vom Quell einen Tropfen", "tokens": ["Und", "ich", "heb", "mit", "dem", "Fin\u00b7ger", "vom", "Quell", "ei\u00b7nen", "Trop\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "ART", "NN"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.16": {"text": "und lausche, ob du ihn lechzend langst,", "tokens": ["und", "lau\u00b7sche", ",", "ob", "du", "ihn", "lech\u00b7zend", "langst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "$,", "KOUS", "PPER", "PPER", "ADJD", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "und ich f\u00fchle dein Herz und meines klopfen", "tokens": ["und", "ich", "f\u00fch\u00b7le", "dein", "Herz", "und", "mei\u00b7nes", "klop\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.18": {"text": "und beide aus Angst.", "tokens": ["und", "bei\u00b7de", "aus", "Angst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.61": {"line.1": {"text": "Ich finde dich in allen diesen Dingen,", "tokens": ["Ich", "fin\u00b7de", "dich", "in", "al\u00b7len", "die\u00b7sen", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "denen ich gut und wie ein Bruder bin;", "tokens": ["de\u00b7nen", "ich", "gut", "und", "wie", "ein", "Bru\u00b7der", "bin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADJD", "KON", "PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "als Samen sonnst du dich in den geringen", "tokens": ["als", "Sa\u00b7men", "sonnst", "du", "dich", "in", "den", "ge\u00b7rin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VMFIN", "PPER", "PRF", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und in den gro\u00dfen giebst du gro\u00df dich hin.", "tokens": ["und", "in", "den", "gro\u00b7\u00dfen", "giebst", "du", "gro\u00df", "dich", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "VVFIN", "PPER", "ADJD", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.62": {"line.1": {"text": "Das ist das wundersame Spiel der Kr\u00e4fte,", "tokens": ["Das", "ist", "das", "wun\u00b7der\u00b7sa\u00b7me", "Spiel", "der", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df sie so dienend durch die Dinge gehn:", "tokens": ["da\u00df", "sie", "so", "die\u00b7nend", "durch", "die", "Din\u00b7ge", "gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "in Wurzeln wachsend, schwindend in die Sch\u00e4fte", "tokens": ["in", "Wur\u00b7zeln", "wach\u00b7send", ",", "schwin\u00b7dend", "in", "die", "Sch\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$,", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und in den Wipfeln wie ein Auferstehn.", "tokens": ["und", "in", "den", "Wip\u00b7feln", "wie", "ein", "Auf\u00b7er\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.63": {"line.1": {"text": "Ich verrinne, ich verrinne", "tokens": ["Ich", "ver\u00b7rin\u00b7ne", ",", "ich", "ver\u00b7rin\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wie Sand, der durch Finger rinnt.", "tokens": ["wie", "Sand", ",", "der", "durch", "Fin\u00b7ger", "rinnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ich habe auf einmal so viele Sinne,", "tokens": ["Ich", "ha\u00b7be", "auf", "ein\u00b7mal", "so", "vie\u00b7le", "Sin\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die alle anders durstig sind.", "tokens": ["die", "al\u00b7le", "an\u00b7ders", "durs\u00b7tig", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich f\u00fchle mich an hundert Stellen", "tokens": ["Ich", "f\u00fch\u00b7le", "mich", "an", "hun\u00b7dert", "Stel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "schwellen und schmerzen.", "tokens": ["schwel\u00b7len", "und", "schmer\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Aber am meisten mitten im Herzen.", "tokens": ["A\u00b7ber", "am", "meis\u00b7ten", "mit\u00b7ten", "im", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "PIS", "ADV", "APPRART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.64": {"line.1": {"text": "Ich m\u00f6chte sterben. La\u00df mich allein.", "tokens": ["Ich", "m\u00f6ch\u00b7te", "ster\u00b7ben", ".", "La\u00df", "mich", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$.", "VVIMP", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich glaube, es wird mir gelingen,", "tokens": ["Ich", "glau\u00b7be", ",", "es", "wird", "mir", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "so bange zu sein,", "tokens": ["so", "ban\u00b7ge", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "da\u00df mir die Pulse zerspringen.", "tokens": ["da\u00df", "mir", "die", "Pul\u00b7se", "zer\u00b7sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.65": {"line.1": {"text": "Sieh, Gott, es kommt ein Neuer an dir bauen,", "tokens": ["Sieh", ",", "Gott", ",", "es", "kommt", "ein", "Neu\u00b7er", "an", "dir", "bau\u00b7en", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der gestern noch ein Knabe war; von Frauen", "tokens": ["der", "ge\u00b7stern", "noch", "ein", "Kna\u00b7be", "war", ";", "von", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "VAFIN", "$.", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "sind seine H\u00e4nde noch zusammgef\u00fcgt", "tokens": ["sind", "sei\u00b7ne", "H\u00e4n\u00b7de", "noch", "zu\u00b7samm\u00b7ge\u00b7f\u00fcgt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "zu einem Falten, welches halb schon l\u00fcgt.", "tokens": ["zu", "ei\u00b7nem", "Fal\u00b7ten", ",", "wel\u00b7ches", "halb", "schon", "l\u00fcgt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Denn seine Rechte will schon von der Linken,", "tokens": ["Denn", "sei\u00b7ne", "Rech\u00b7te", "will", "schon", "von", "der", "Lin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "um sich zu wehren oder um zu winken", "tokens": ["um", "sich", "zu", "weh\u00b7ren", "o\u00b7der", "um", "zu", "win\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PRF", "PTKZU", "VVINF", "KON", "KOUI", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und um am Arm allein zu sein.", "tokens": ["und", "um", "am", "Arm", "al\u00b7lein", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "APPRART", "NN", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Noch gestern war die Stirne wie ein Stein", "tokens": ["Noch", "ge\u00b7stern", "war", "die", "Stir\u00b7ne", "wie", "ein", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "KOKOM", "ART", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "im Bach, ger\u00fcndet von den Tagen,", "tokens": ["im", "Bach", ",", "ge\u00b7r\u00fcn\u00b7det", "von", "den", "Ta\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die nichts bedeuten als ein Wellenschlagen", "tokens": ["die", "nichts", "be\u00b7deu\u00b7ten", "als", "ein", "Wel\u00b7len\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVINF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und nichts verlangen, als ein Bild zu tragen", "tokens": ["und", "nichts", "ver\u00b7lan\u00b7gen", ",", "als", "ein", "Bild", "zu", "tra\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVINF", "$,", "KOUS", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "von Himmeln, die der Zufall dr\u00fcber h\u00e4ngt;", "tokens": ["von", "Him\u00b7meln", ",", "die", "der", "Zu\u00b7fall", "dr\u00fc\u00b7ber", "h\u00e4ngt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ART", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "heut dr\u00e4ngt", "tokens": ["heut", "dr\u00e4ngt"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "auf ihr sich eine Weltgeschichte", "tokens": ["auf", "ihr", "sich", "ei\u00b7ne", "Welt\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PRF", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "vor einem unerbittlichen Gerichte,", "tokens": ["vor", "ei\u00b7nem", "un\u00b7er\u00b7bitt\u00b7li\u00b7chen", "Ge\u00b7rich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und sie versinkt in seinem Urteilsspruch.", "tokens": ["und", "sie", "ver\u00b7sinkt", "in", "sei\u00b7nem", "Ur\u00b7teils\u00b7spruch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.67": {"line.1": {"text": "Raum wird auf einem neuen Angesichte.", "tokens": ["Raum", "wird", "auf", "ei\u00b7nem", "neu\u00b7en", "An\u00b7ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es war kein Licht vor diesem Lichte,", "tokens": ["Es", "war", "kein", "Licht", "vor", "die\u00b7sem", "Lich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und, wie noch nie, beginnt dein Buch.", "tokens": ["und", ",", "wie", "noch", "nie", ",", "be\u00b7ginnt", "dein", "Buch", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADV", "ADV", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Ich liebe dich, du sanftestes Gesetz,", "tokens": ["Ich", "lie\u00b7be", "dich", ",", "du", "sanf\u00b7tes\u00b7tes", "Ge\u00b7setz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "an dem wir reiften, da wir mit ihm rangen;", "tokens": ["an", "dem", "wir", "reif\u00b7ten", ",", "da", "wir", "mit", "ihm", "ran\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "du gro\u00dfes Heimweh, das wir nicht bezwangen,", "tokens": ["du", "gro\u00b7\u00dfes", "Heim\u00b7weh", ",", "das", "wir", "nicht", "be\u00b7zwan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "du Wald, aus dem wir nie hinausgegangen,", "tokens": ["du", "Wald", ",", "aus", "dem", "wir", "nie", "hin\u00b7aus\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "du Lied, das wir mit jedem Schweigen sangen,", "tokens": ["du", "Lied", ",", "das", "wir", "mit", "je\u00b7dem", "Schwei\u00b7gen", "san\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "du dunkles Netz,", "tokens": ["du", "dunk\u00b7les", "Netz", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "darin sich fl\u00fcchtend die Gef\u00fchle fangen.", "tokens": ["da\u00b7rin", "sich", "fl\u00fcch\u00b7tend", "die", "Ge\u00b7f\u00fch\u00b7le", "fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.69": {"line.1": {"text": "Du hast dich so unendlich gro\u00df begonnen", "tokens": ["Du", "hast", "dich", "so", "un\u00b7end\u00b7lich", "gro\u00df", "be\u00b7gon\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "an jenem Tage, da du uns begannst, \u2013", "tokens": ["an", "je\u00b7nem", "Ta\u00b7ge", ",", "da", "du", "uns", "be\u00b7gannst", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wir sind so gereift in deinen Sonnen,", "tokens": ["und", "wir", "sind", "so", "ge\u00b7reift", "in", "dei\u00b7nen", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "so breit geworden und so tief gepflanzt,", "tokens": ["so", "breit", "ge\u00b7wor\u00b7den", "und", "so", "tief", "ge\u00b7pflanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAPP", "KON", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "da\u00df du in Menschen, Engeln und Madonnen", "tokens": ["da\u00df", "du", "in", "Men\u00b7schen", ",", "En\u00b7geln", "und", "Ma\u00b7don\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "dich ruhend jetzt vollenden kannst.", "tokens": ["dich", "ru\u00b7hend", "jetzt", "voll\u00b7en\u00b7den", "kannst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "La\u00df deine Hand am Hang der Himmel ruhn", "tokens": ["La\u00df", "dei\u00b7ne", "Hand", "am", "Hang", "der", "Him\u00b7mel", "ruhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN", "APPRART", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und dulde stumm, was wir dir dunkel tun.", "tokens": ["und", "dul\u00b7de", "stumm", ",", "was", "wir", "dir", "dun\u00b7kel", "tun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "PRELS", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.71": {"line.1": {"text": "Werkleute sind wir: Knappen, J\u00fcnger, Meister,", "tokens": ["Wer\u00b7kleu\u00b7te", "sind", "wir", ":", "Knap\u00b7pen", ",", "J\u00fcn\u00b7ger", ",", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$.", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und bauen dich, du hohes Mittelschiff.", "tokens": ["und", "bau\u00b7en", "dich", ",", "du", "ho\u00b7hes", "Mit\u00b7tel\u00b7schiff", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und manchmal kommt ein ernster Hergereister,", "tokens": ["Und", "manch\u00b7mal", "kommt", "ein", "erns\u00b7ter", "Her\u00b7ge\u00b7reis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "geht wie ein Glanz durch unsre hundert Geister", "tokens": ["geht", "wie", "ein", "Glanz", "durch", "uns\u00b7re", "hun\u00b7dert", "Geis\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "APPR", "PPOSAT", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und zeigt uns zitternd einen neuen Griff.", "tokens": ["und", "zeigt", "uns", "zit\u00b7ternd", "ei\u00b7nen", "neu\u00b7en", "Griff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.72": {"line.1": {"text": "Wir steigen in die wiegenden Ger\u00fcste,", "tokens": ["Wir", "stei\u00b7gen", "in", "die", "wie\u00b7gen\u00b7den", "Ge\u00b7r\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "in unsern H\u00e4nden h\u00e4ngt der Hammer schwer,", "tokens": ["in", "un\u00b7sern", "H\u00e4n\u00b7den", "h\u00e4ngt", "der", "Ham\u00b7mer", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "bis eine Stunde uns die Stirnen k\u00fc\u00dfte,", "tokens": ["bis", "ei\u00b7ne", "Stun\u00b7de", "uns", "die", "Stir\u00b7nen", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die strahlend und als ob sie Alles w\u00fc\u00dfte", "tokens": ["die", "strah\u00b7lend", "und", "als", "ob", "sie", "Al\u00b7les", "w\u00fc\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "KOKOM", "KOUS", "PPER", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "von dir kommt, wie der Wind vom Meer.", "tokens": ["von", "dir", "kommt", ",", "wie", "der", "Wind", "vom", "Meer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Dann ist ein Hallen von dem vielen H\u00e4mmern", "tokens": ["Dann", "ist", "ein", "Hal\u00b7len", "von", "dem", "vie\u00b7len", "H\u00e4m\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und durch die Berge geht es Sto\u00df um Sto\u00df.", "tokens": ["und", "durch", "die", "Ber\u00b7ge", "geht", "es", "Sto\u00df", "um", "Sto\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Erst wenn es dunkelt lassen wir dich los:", "tokens": ["Erst", "wenn", "es", "dun\u00b7kelt", "las\u00b7sen", "wir", "dich", "los", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN", "PPER", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und deine kommenden Konturen d\u00e4mmern.", "tokens": ["Und", "dei\u00b7ne", "kom\u00b7men\u00b7den", "Kon\u00b7tu\u00b7ren", "d\u00e4m\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.74": {"line.1": {"text": "Gott, du bist gro\u00df.", "tokens": ["Gott", ",", "du", "bist", "gro\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.75": {"line.1": {"text": "Du bist so gro\u00df, da\u00df ich schon nicht mehr bin,", "tokens": ["Du", "bist", "so", "gro\u00df", ",", "da\u00df", "ich", "schon", "nicht", "mehr", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wenn ich mich nur in deine N\u00e4he stelle.", "tokens": ["wenn", "ich", "mich", "nur", "in", "dei\u00b7ne", "N\u00e4\u00b7he", "stel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du bist so dunkel; meine kleine Helle", "tokens": ["Du", "bist", "so", "dun\u00b7kel", ";", "mei\u00b7ne", "klei\u00b7ne", "Hel\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "an deinem Saum hat keinen Sinn.", "tokens": ["an", "dei\u00b7nem", "Saum", "hat", "kei\u00b7nen", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein Wille geht wie eine Welle", "tokens": ["Dein", "Wil\u00b7le", "geht", "wie", "ei\u00b7ne", "Wel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und jeder Tag ertrinkt darin.", "tokens": ["und", "je\u00b7der", "Tag", "er\u00b7trinkt", "da\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Nur meine Sehnsucht ragt dir bis ans Kinn", "tokens": ["Nur", "mei\u00b7ne", "Sehn\u00b7sucht", "ragt", "dir", "bis", "ans", "Kinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und steht vor dir wie aller Engel gr\u00f6\u00dfter:", "tokens": ["und", "steht", "vor", "dir", "wie", "al\u00b7ler", "En\u00b7gel", "gr\u00f6\u00df\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "KOKOM", "PIAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ein fremder, bleicher und noch unerl\u00f6ster,", "tokens": ["ein", "frem\u00b7der", ",", "blei\u00b7cher", "und", "noch", "un\u00b7er\u00b7l\u00f6s\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und h\u00e4lt dir seine Fl\u00fcgel hin.", "tokens": ["und", "h\u00e4lt", "dir", "sei\u00b7ne", "Fl\u00fc\u00b7gel", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Er will nicht mehr den uferlosen Flug,", "tokens": ["Er", "will", "nicht", "mehr", "den", "u\u00b7fer\u00b7lo\u00b7sen", "Flug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "an dem die Monde bla\u00df vor\u00fcberschwammen,", "tokens": ["an", "dem", "die", "Mon\u00b7de", "bla\u00df", "vor\u00b7\u00fc\u00b7bersc\u00b7hwam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NE", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und von den Welten wei\u00df er l\u00e4ngst genug.", "tokens": ["und", "von", "den", "Wel\u00b7ten", "wei\u00df", "er", "l\u00e4ngst", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mit seinen Fl\u00fcgeln will er wie mit Flammen", "tokens": ["Mit", "sei\u00b7nen", "Fl\u00fc\u00b7geln", "will", "er", "wie", "mit", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "vor deinem schattigen Gesichte stehn", "tokens": ["vor", "dei\u00b7nem", "schat\u00b7ti\u00b7gen", "Ge\u00b7sich\u00b7te", "stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und will bei ihrem wei\u00dfen Scheine sehn,", "tokens": ["und", "will", "bei", "ih\u00b7rem", "wei\u00b7\u00dfen", "Schei\u00b7ne", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "ob deine grauen Brauen ihn verdammen.", "tokens": ["ob", "dei\u00b7ne", "grau\u00b7en", "Brau\u00b7en", "ihn", "ver\u00b7dam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.78": {"line.1": {"text": "So viele Engel suchen dich im Lichte", "tokens": ["So", "vie\u00b7le", "En\u00b7gel", "su\u00b7chen", "dich", "im", "Lich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und sto\u00dfen mit den Stirnen nach den Sternen", "tokens": ["und", "sto\u00b7\u00dfen", "mit", "den", "Stir\u00b7nen", "nach", "den", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und wollen dich aus jedem Glanze lernen.", "tokens": ["und", "wol\u00b7len", "dich", "aus", "je\u00b7dem", "Glan\u00b7ze", "ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mir aber ist, sooft ich von dir dichte,", "tokens": ["Mir", "a\u00b7ber", "ist", ",", "sooft", "ich", "von", "dir", "dich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "$,", "VVFIN", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "da\u00df sie mit abgewendetem Gesichte", "tokens": ["da\u00df", "sie", "mit", "ab\u00b7ge\u00b7wen\u00b7de\u00b7tem", "Ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "von deines Mantels Falten sich entfernen.", "tokens": ["von", "dei\u00b7nes", "Man\u00b7tels", "Fal\u00b7ten", "sich", "ent\u00b7fer\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.79": {"line.1": {"text": "Denn du warst selber nur ein Gast des Golds.", "tokens": ["Denn", "du", "warst", "sel\u00b7ber", "nur", "ein", "Gast", "des", "Golds", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nur einer Zeit zuliebe, die dich flehte", "tokens": ["Nur", "ei\u00b7ner", "Zeit", "zu\u00b7lie\u00b7be", ",", "die", "dich", "fleh\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "in ihre klaren marmornen Gebete,", "tokens": ["in", "ih\u00b7re", "kla\u00b7ren", "mar\u00b7mor\u00b7nen", "Ge\u00b7be\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "erschienst du wie der K\u00f6nig der Komete,", "tokens": ["er\u00b7schienst", "du", "wie", "der", "K\u00f6\u00b7nig", "der", "Ko\u00b7me\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auf deiner Stirne Strahlenstr\u00f6me stolz.", "tokens": ["auf", "dei\u00b7ner", "Stir\u00b7ne", "Strah\u00b7len\u00b7str\u00f6\u00b7me", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.80": {"line.1": {"text": "Du kehrtest heim, da jene Zeit zerschmolz.", "tokens": ["Du", "kehr\u00b7test", "heim", ",", "da", "je\u00b7ne", "Zeit", "zer\u00b7schmolz", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.81": {"line.1": {"text": "Ganz dunkel ist dein Mund, von dem ich wehte,", "tokens": ["Ganz", "dun\u00b7kel", "ist", "dein", "Mund", ",", "von", "dem", "ich", "weh\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und deine H\u00e4nde sind von Ebenholz.", "tokens": ["und", "dei\u00b7ne", "H\u00e4n\u00b7de", "sind", "von", "E\u00b7ben\u00b7holz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.82": {"line.1": {"text": "Das waren Tage Michelangelo's,", "tokens": ["Das", "wa\u00b7ren", "Ta\u00b7ge", "Mi\u00b7che\u00b7lan\u00b7ge\u00b7lo's", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "von denen ich in fremden B\u00fcchern las.", "tokens": ["von", "de\u00b7nen", "ich", "in", "frem\u00b7den", "B\u00fc\u00b7chern", "las", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das war der Mann, der \u00fcber einem Ma\u00df,", "tokens": ["Das", "war", "der", "Mann", ",", "der", "\u00fc\u00b7ber", "ei\u00b7nem", "Ma\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "gigantengro\u00df,", "tokens": ["gi\u00b7gan\u00b7ten\u00b7gro\u00df", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "die Unerme\u00dflichkeit verga\u00df.", "tokens": ["die", "Un\u00b7er\u00b7me\u00df\u00b7lich\u00b7keit", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Das war der Mann, der immer wiederkehrt,", "tokens": ["Das", "war", "der", "Mann", ",", "der", "im\u00b7mer", "wie\u00b7der\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wenn eine Zeit noch einmal ihren Wert,", "tokens": ["wenn", "ei\u00b7ne", "Zeit", "noch", "ein\u00b7mal", "ih\u00b7ren", "Wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "da sie sich enden will, zusammenfa\u00dft.", "tokens": ["da", "sie", "sich", "en\u00b7den", "will", ",", "zu\u00b7sam\u00b7men\u00b7fa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da hebt noch einer ihre ganze Last", "tokens": ["Da", "hebt", "noch", "ei\u00b7ner", "ih\u00b7re", "gan\u00b7ze", "Last"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und wirft sie in den Abgrund seiner Brust.", "tokens": ["und", "wirft", "sie", "in", "den", "Ab\u00b7grund", "sei\u00b7ner", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die vor ihm hatten Leid und Lust;", "tokens": ["Die", "vor", "ihm", "hat\u00b7ten", "Leid", "und", "Lust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "er aber f\u00fchlt nur noch des Lebens Masse", "tokens": ["er", "a\u00b7ber", "f\u00fchlt", "nur", "noch", "des", "Le\u00b7bens", "Mas\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und da\u00df er Alles wie ", "tokens": ["und", "da\u00df", "er", "Al\u00b7les", "wie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PIS", "KOKOM"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "nur Gott bleibt \u00fcber seinem Willen weit:", "tokens": ["nur", "Gott", "bleibt", "\u00fc\u00b7ber", "sei\u00b7nem", "Wil\u00b7len", "weit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "da liebt er ihn mit seinem hohen Hasse", "tokens": ["da", "liebt", "er", "ihn", "mit", "sei\u00b7nem", "ho\u00b7hen", "Has\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "f\u00fcr diese Unerreichbarkeit.", "tokens": ["f\u00fcr", "die\u00b7se", "Un\u00b7er\u00b7reich\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Der Ast vom Baume Gott, der \u00fcber Italien reicht,", "tokens": ["Der", "Ast", "vom", "Bau\u00b7me", "Gott", ",", "der", "\u00fc\u00b7ber", "I\u00b7ta\u00b7li\u00b7en", "reicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "NN", "$,", "PRELS", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Er h\u00e4tte vielleicht", "tokens": ["Er", "h\u00e4t\u00b7te", "viel\u00b7leicht"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "sich schon gerne, mit Fr\u00fcchten gef\u00fcllt, verfr\u00fcht,", "tokens": ["sich", "schon", "ger\u00b7ne", ",", "mit", "Fr\u00fcch\u00b7ten", "ge\u00b7f\u00fcllt", ",", "ver\u00b7fr\u00fcht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PRF", "ADV", "ADV", "$,", "APPR", "NN", "VVPP", "$,", "VVFIN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "doch er wurde mitten im Bl\u00fchen m\u00fcd,", "tokens": ["doch", "er", "wur\u00b7de", "mit\u00b7ten", "im", "Bl\u00fc\u00b7hen", "m\u00fcd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "und er wird keine Fr\u00fcchte haben.", "tokens": ["und", "er", "wird", "kei\u00b7ne", "Fr\u00fcch\u00b7te", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.85": {"line.1": {"text": "Nur der Fr\u00fchling Gottes war dort,", "tokens": ["Nur", "der", "Fr\u00fch\u00b7ling", "Got\u00b7tes", "war", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "nur sein Sohn, das Wort,", "tokens": ["nur", "sein", "Sohn", ",", "das", "Wort", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "vollendete sich.", "tokens": ["voll\u00b7en\u00b7de\u00b7te", "sich", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PRF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Es wendete sich", "tokens": ["Es", "wen\u00b7de\u00b7te", "sich"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "alle Kraft zu dem strahlenden Knaben.", "tokens": ["al\u00b7le", "Kraft", "zu", "dem", "strah\u00b7len\u00b7den", "Kna\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Alle kamen mit Gaben", "tokens": ["Al\u00b7le", "ka\u00b7men", "mit", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "zu ihm;", "tokens": ["zu", "ihm", ";"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "PPER", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.8": {"text": "alle sangen wie Cherubim", "tokens": ["al\u00b7le", "san\u00b7gen", "wie", "Che\u00b7ru\u00b7bim"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "KOKOM", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.9": {"text": "seinen Preis.", "tokens": ["sei\u00b7nen", "Preis", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.86": {"line.1": {"text": "Und er duftete leis", "tokens": ["Und", "er", "duf\u00b7te\u00b7te", "leis"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADJD"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "als Rose der Rosen.", "tokens": ["als", "Ro\u00b7se", "der", "Ro\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Er war ein Kreis", "tokens": ["Er", "war", "ein", "Kreis"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "um die Heimatlosen.", "tokens": ["um", "die", "Hei\u00b7mat\u00b7lo\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Er ging in M\u00e4nteln und Metamorphosen", "tokens": ["Er", "ging", "in", "M\u00e4n\u00b7teln", "und", "Me\u00b7ta\u00b7mor\u00b7pho\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "durch alle steigenden Stimmen der Zeit.", "tokens": ["durch", "al\u00b7le", "stei\u00b7gen\u00b7den", "Stim\u00b7men", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.87": {"line.1": {"text": "Da ward auch die zur Frucht Erweckte,", "tokens": ["Da", "ward", "auch", "die", "zur", "Frucht", "Er\u00b7weck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die sch\u00fcchterne und sch\u00f6nerschreckte,", "tokens": ["die", "sch\u00fcch\u00b7ter\u00b7ne", "und", "sch\u00f6\u00b7ner\u00b7schreck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die heimgesuchte Magd geliebt.", "tokens": ["die", "heim\u00b7ge\u00b7such\u00b7te", "Magd", "ge\u00b7liebt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Bl\u00fchende, die Unentdeckte,", "tokens": ["Die", "Bl\u00fc\u00b7hen\u00b7de", ",", "die", "Un\u00b7ent\u00b7deck\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "in der es hundert Wege giebt.", "tokens": ["in", "der", "es", "hun\u00b7dert", "We\u00b7ge", "giebt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Da lie\u00dfen sie sie gehn und schweben", "tokens": ["Da", "lie\u00b7\u00dfen", "sie", "sie", "gehn", "und", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVINF", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und treiben mit dem jungen Jahr;", "tokens": ["und", "trei\u00b7ben", "mit", "dem", "jun\u00b7gen", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ihr dienendes Marien-Leben", "tokens": ["ihr", "die\u00b7nen\u00b7des", "Ma\u00b7ri\u00b7en\u00b7Le\u00b7ben"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ward k\u00f6niglich und wunderbar.", "tokens": ["ward", "k\u00f6\u00b7nig\u00b7lich", "und", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie feiert\u00e4gliches Gel\u00e4ute", "tokens": ["Wie", "fei\u00b7er\u00b7t\u00e4g\u00b7li\u00b7ches", "Ge\u00b7l\u00e4u\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ging es durch alle H\u00e4user gro\u00df;", "tokens": ["ging", "es", "durch", "al\u00b7le", "H\u00e4u\u00b7ser", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und die einst m\u00e4dchenhaft Zerstreute", "tokens": ["und", "die", "einst", "m\u00e4d\u00b7chen\u00b7haft", "Zer\u00b7streu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "war so versenkt in ihren Schoo\u00df", "tokens": ["war", "so", "ver\u00b7senkt", "in", "ih\u00b7ren", "Schoo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "und so erf\u00fcllt von jenem Einen", "tokens": ["und", "so", "er\u00b7f\u00fcllt", "von", "je\u00b7nem", "Ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "APPR", "PDAT", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und so f\u00fcr Tausende genug,", "tokens": ["und", "so", "f\u00fcr", "Tau\u00b7sen\u00b7de", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "da\u00df alles schien, sie zu bescheinen,", "tokens": ["da\u00df", "al\u00b7les", "schien", ",", "sie", "zu", "be\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "die wie ein Weinberg war und trug.", "tokens": ["die", "wie", "ein", "Wein\u00b7berg", "war", "und", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "VAFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.89": {"line.1": {"text": "Aber als h\u00e4tte die Last der Fruchtgeh\u00e4nge", "tokens": ["A\u00b7ber", "als", "h\u00e4t\u00b7te", "die", "Last", "der", "Frucht\u00b7ge\u00b7h\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOKOM", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "und der Verfall der S\u00e4ulen und Bogeng\u00e4nge", "tokens": ["und", "der", "Ver\u00b7fall", "der", "S\u00e4u\u00b7len", "und", "Bo\u00b7gen\u00b7g\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "und der Abgesang der Ges\u00e4nge", "tokens": ["und", "der", "Ab\u00b7ge\u00b7sang", "der", "Ge\u00b7s\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "sie beschwert,", "tokens": ["sie", "be\u00b7schwert", ","], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVPP", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "hat die Jungfrau sich in anderen Stunden,", "tokens": ["hat", "die", "Jung\u00b7frau", "sich", "in", "an\u00b7de\u00b7ren", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+---+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "wie von Gr\u00f6\u00dferem noch unentbunden,", "tokens": ["wie", "von", "Gr\u00f6\u00b7\u00dfe\u00b7rem", "noch", "un\u00b7ent\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NE", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "kommenden Wunden", "tokens": ["kom\u00b7men\u00b7den", "Wun\u00b7den"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "zugekehrt.", "tokens": ["zu\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.90": {"line.1": {"text": "Ihre H\u00e4nde, die sich lautlos l\u00f6sten,", "tokens": ["Ih\u00b7re", "H\u00e4n\u00b7de", ",", "die", "sich", "laut\u00b7los", "l\u00f6s\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "liegen leer.", "tokens": ["lie\u00b7gen", "leer", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Wehe, sie gebar noch nicht den Gr\u00f6\u00dften.", "tokens": ["We\u00b7he", ",", "sie", "ge\u00b7bar", "noch", "nicht", "den", "Gr\u00f6\u00df\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADJD", "ADV", "PTKNEG", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Und die Engel, die nicht tr\u00f6sten,", "tokens": ["Und", "die", "En\u00b7gel", ",", "die", "nicht", "tr\u00f6s\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "stehen fremd und furchtbar um sie her.", "tokens": ["ste\u00b7hen", "fremd", "und", "furcht\u00b7bar", "um", "sie", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.91": {"line.1": {"text": "So hat man sie gemalt; vor allem Einer,", "tokens": ["So", "hat", "man", "sie", "ge\u00b7malt", ";", "vor", "al\u00b7lem", "Ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PPER", "VVPP", "$.", "APPR", "PIS", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der seine Sehnsucht aus der Sonne trug.", "tokens": ["der", "sei\u00b7ne", "Sehn\u00b7sucht", "aus", "der", "Son\u00b7ne", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ihm reifte sie aus allen R\u00e4tseln reiner,", "tokens": ["Ihm", "reif\u00b7te", "sie", "aus", "al\u00b7len", "R\u00e4t\u00b7seln", "rei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PIAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "aber im Leiden immer allgemeiner:", "tokens": ["a\u00b7ber", "im", "Lei\u00b7den", "im\u00b7mer", "all\u00b7ge\u00b7mei\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ADV", "ADJD", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "sein ganzes Leben war er wie ein Weiner,", "tokens": ["sein", "gan\u00b7zes", "Le\u00b7ben", "war", "er", "wie", "ein", "Wei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "dem sich das Weinen in die H\u00e4nde schlug.", "tokens": ["dem", "sich", "das", "Wei\u00b7nen", "in", "die", "H\u00e4n\u00b7de", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.92": {"line.1": {"text": "Er ist der sch\u00f6nste Schleier ihrer Schmerzen,", "tokens": ["Er", "ist", "der", "sch\u00f6ns\u00b7te", "Schlei\u00b7er", "ih\u00b7rer", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der sich an ihre wehen Lippen schmiegt,", "tokens": ["der", "sich", "an", "ih\u00b7re", "we\u00b7hen", "Lip\u00b7pen", "schmiegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sich \u00fcber ihnen fast zum L\u00e4cheln biegt \u2013", "tokens": ["sich", "\u00fc\u00b7ber", "ih\u00b7nen", "fast", "zum", "L\u00e4\u00b7cheln", "biegt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und von dem Licht aus sieben Engelskerzen", "tokens": ["und", "von", "dem", "Licht", "aus", "sie\u00b7ben", "En\u00b7gels\u00b7ker\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wird sein Geheimnis nicht besiegt.", "tokens": ["wird", "sein", "Ge\u00b7heim\u00b7nis", "nicht", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.93": {"line.1": {"text": "Mit einem Ast, der jenem niemals glich,", "tokens": ["Mit", "ei\u00b7nem", "Ast", ",", "der", "je\u00b7nem", "nie\u00b7mals", "glich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PDAT", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wird Gott, der Baum, auch einmal sommerlich", "tokens": ["wird", "Gott", ",", "der", "Baum", ",", "auch", "ein\u00b7mal", "som\u00b7mer\u00b7lich"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "ART", "NN", "$,", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "verk\u00fcndend werden und aus Reife rauschen;", "tokens": ["ver\u00b7k\u00fcn\u00b7dend", "wer\u00b7den", "und", "aus", "Rei\u00b7fe", "rau\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in einem Lande, wo die Menschen lauschen,", "tokens": ["in", "ei\u00b7nem", "Lan\u00b7de", ",", "wo", "die", "Men\u00b7schen", "lau\u00b7schen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wo jeder \u00e4hnlich einsam ist wie ich.", "tokens": ["wo", "je\u00b7der", "\u00e4hn\u00b7lich", "ein\u00b7sam", "ist", "wie", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "ADJD", "VAFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.94": {"line.1": {"text": "Denn nur dem Einsamen wird offenbart,", "tokens": ["Denn", "nur", "dem", "Ein\u00b7sa\u00b7men", "wird", "of\u00b7fen\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und vielen Einsamen der gleichen Art", "tokens": ["und", "vie\u00b7len", "Ein\u00b7sa\u00b7men", "der", "glei\u00b7chen", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wird mehr gegeben als dem schmalen Einen.", "tokens": ["wird", "mehr", "ge\u00b7ge\u00b7ben", "als", "dem", "schma\u00b7len", "Ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn jedem wird ein andrer Gott erscheinen,", "tokens": ["Denn", "je\u00b7dem", "wird", "ein", "an\u00b7drer", "Gott", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "bis sie erkennen, nah am Weinen,", "tokens": ["bis", "sie", "er\u00b7ken\u00b7nen", ",", "nah", "am", "Wei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "da\u00df durch ihr meilenweites Meinen,", "tokens": ["da\u00df", "durch", "ihr", "mei\u00b7len\u00b7wei\u00b7tes", "Mei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "durch ihr Vernehmen und Verneinen,", "tokens": ["durch", "ihr", "Ver\u00b7neh\u00b7men", "und", "Ver\u00b7nei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "verschieden nur in hundert Seinen", "tokens": ["ver\u00b7schie\u00b7den", "nur", "in", "hun\u00b7dert", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.95": {"line.1": {"text": "Das ist das endlichste Gebet,", "tokens": ["Das", "ist", "das", "end\u00b7lichs\u00b7te", "Ge\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "das dann die Sehenden sich sagen:", "tokens": ["das", "dann", "die", "Se\u00b7hen\u00b7den", "sich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wurzel Gott hat Frucht getragen,", "tokens": ["Die", "Wur\u00b7zel", "Gott", "hat", "Frucht", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "geht hin, die Glocken zu zerschlagen;", "tokens": ["geht", "hin", ",", "die", "Glo\u00b7cken", "zu", "zer\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wir kommen zu den stillern Tagen,", "tokens": ["wir", "kom\u00b7men", "zu", "den", "stil\u00b7lern", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "in denen reif die Stunde steht.", "tokens": ["in", "de\u00b7nen", "reif", "die", "Stun\u00b7de", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Wurzel Gott hat Frucht getragen.", "tokens": ["Die", "Wur\u00b7zel", "Gott", "hat", "Frucht", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Seid ernst und seht.", "tokens": ["Seid", "ernst", "und", "seht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.96": {"line.1": {"text": "Ich kann nicht glauben, da\u00df der kleine Tod,", "tokens": ["Ich", "kann", "nicht", "glau\u00b7ben", ",", "da\u00df", "der", "klei\u00b7ne", "Tod", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "dem wir doch t\u00e4glich \u00fcbern Scheitel schauen,", "tokens": ["dem", "wir", "doch", "t\u00e4g\u00b7lich", "\u00fc\u00b7bern", "Schei\u00b7tel", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "uns eine Sorge bleibt und eine Not.", "tokens": ["uns", "ei\u00b7ne", "Sor\u00b7ge", "bleibt", "und", "ei\u00b7ne", "Not", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVFIN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.97": {"line.1": {"text": "Ich kann nicht glauben, da\u00df er ernsthaft droht;", "tokens": ["Ich", "kann", "nicht", "glau\u00b7ben", ",", "da\u00df", "er", "ernst\u00b7haft", "droht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ich lebe noch, ich habe Zeit zu bauen:", "tokens": ["ich", "le\u00b7be", "noch", ",", "ich", "ha\u00b7be", "Zeit", "zu", "bau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mein Blut ist l\u00e4nger als die Rosen rot.", "tokens": ["mein", "Blut", "ist", "l\u00e4n\u00b7ger", "als", "die", "Ro\u00b7sen", "rot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.98": {"line.1": {"text": "Mein Sinn ist tiefer als das witzige Spiel", "tokens": ["Mein", "Sinn", "ist", "tie\u00b7fer", "als", "das", "wit\u00b7zi\u00b7ge", "Spiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "mit unsrer Furcht, darin er sich gef\u00e4llt.", "tokens": ["mit", "uns\u00b7rer", "Furcht", ",", "da\u00b7rin", "er", "sich", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PAV", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin die Welt,", "tokens": ["Ich", "bin", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "aus der er irrend fiel.", "tokens": ["aus", "der", "er", "ir\u00b7rend", "fiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVPP", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.99": {"line.1": {"text": "Wie er", "tokens": ["Wie", "er"], "token_info": ["word", "word"], "pos": ["PWAV", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "kreisende M\u00f6nche wandern so umher;", "tokens": ["krei\u00b7sen\u00b7de", "M\u00f6n\u00b7che", "wan\u00b7dern", "so", "um\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "man f\u00fcrchtet sich vor ihrer Wiederkehr,", "tokens": ["man", "f\u00fcrch\u00b7tet", "sich", "vor", "ih\u00b7rer", "Wie\u00b7der\u00b7kehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "man wei\u00df nicht: ist es jedesmal derselbe,", "tokens": ["man", "wei\u00df", "nicht", ":", "ist", "es", "je\u00b7des\u00b7mal", "der\u00b7sel\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "$.", "VAFIN", "PPER", "ADV", "PDAT", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "sinds zwei, sinds zehn, sinds tausend oder mehr?", "tokens": ["sinds", "zwei", ",", "sinds", "zehn", ",", "sinds", "tau\u00b7send", "o\u00b7der", "mehr", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "CARD", "$,", "VAFIN", "CARD", "$,", "VAFIN", "CARD", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Man kennt nur diese fremde gelbe Hand,", "tokens": ["Man", "kennt", "nur", "die\u00b7se", "frem\u00b7de", "gel\u00b7be", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PDAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "die sich ausstreckt so nackt und nah \u2013", "tokens": ["die", "sich", "aus\u00b7streckt", "so", "nackt", "und", "nah", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.8": {"text": "da da:", "tokens": ["da", "da", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "als k\u00e4m sie aus dem eigenen Gewand.", "tokens": ["als", "k\u00e4m", "sie", "aus", "dem", "ei\u00b7ge\u00b7nen", "Ge\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.100": {"line.1": {"text": "Was wirst du tun, Gott, wenn ich sterbe?", "tokens": ["Was", "wirst", "du", "tun", ",", "Gott", ",", "wenn", "ich", "ster\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVINF", "$,", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin dein Krug (wenn ich zerscherbe?)", "tokens": ["Ich", "bin", "dein", "Krug", "(", "wenn", "ich", "zer\u00b7scher\u00b7be", "?", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin dein Trank (wenn ich verderbe?)", "tokens": ["Ich", "bin", "dein", "Trank", "(", "wenn", "ich", "ver\u00b7der\u00b7be", "?", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$(", "KOUS", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bin dein Gewand und dein Gewerbe,", "tokens": ["Bin", "dein", "Ge\u00b7wand", "und", "dein", "Ge\u00b7wer\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "mit mir verlierst du deinen Sinn.", "tokens": ["mit", "mir", "ver\u00b7lierst", "du", "dei\u00b7nen", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.101": {"line.1": {"text": "Nach mir hast du kein Haus, darin", "tokens": ["Nach", "mir", "hast", "du", "kein", "Haus", ",", "da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "PIAT", "NN", "$,", "PAV"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "dich Worte, nah und warm, begr\u00fc\u00dfen.", "tokens": ["dich", "Wor\u00b7te", ",", "nah", "und", "warm", ",", "be\u00b7gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADJD", "KON", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es f\u00e4llt von deinen m\u00fcden F\u00fc\u00dfen", "tokens": ["Es", "f\u00e4llt", "von", "dei\u00b7nen", "m\u00fc\u00b7den", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Samtsandale, die ich bin.", "tokens": ["die", "Samt\u00b7san\u00b7da\u00b7le", ",", "die", "ich", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.102": {"line.1": {"text": "Dein gro\u00dfer Mantel l\u00e4\u00dft dich los.", "tokens": ["Dein", "gro\u00b7\u00dfer", "Man\u00b7tel", "l\u00e4\u00dft", "dich", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Blick, den ich mit meiner Wange", "tokens": ["Dein", "Blick", ",", "den", "ich", "mit", "mei\u00b7ner", "Wan\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "warm, wie mit einem Pf\u00fchl, empfange,", "tokens": ["warm", ",", "wie", "mit", "ei\u00b7nem", "Pf\u00fchl", ",", "emp\u00b7fan\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "APPR", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "wird kommen, wird mich suchen, lange \u2013", "tokens": ["wird", "kom\u00b7men", ",", "wird", "mich", "su\u00b7chen", ",", "lan\u00b7ge", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "VVINF", "$,", "VAFIN", "PPER", "VVFIN", "$,", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und legt beim Sonnenuntergange", "tokens": ["und", "legt", "beim", "Son\u00b7nen\u00b7un\u00b7ter\u00b7gan\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sich fremden Steinen in den Schoo\u00df.", "tokens": ["sich", "frem\u00b7den", "Stei\u00b7nen", "in", "den", "Schoo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.103": {"line.1": {"text": "Was wirst du tun, Gott? Ich bin bange.", "tokens": ["Was", "wirst", "du", "tun", ",", "Gott", "?", "Ich", "bin", "ban\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVINF", "$,", "NN", "$.", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.104": {"line.1": {"text": "Du bist der raunende Verru\u00dfte,", "tokens": ["Du", "bist", "der", "rau\u00b7nen\u00b7de", "Ver\u00b7ru\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "auf allen \u00d6fen schl\u00e4fst du breit.", "tokens": ["auf", "al\u00b7len", "\u00d6\u00b7fen", "schl\u00e4fst", "du", "breit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Wissen ist nur in der Zeit.", "tokens": ["Das", "Wis\u00b7sen", "ist", "nur", "in", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du bist der dunkle Unbewu\u00dfte", "tokens": ["Du", "bist", "der", "dunk\u00b7le", "Un\u00b7be\u00b7wu\u00df\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "von Ewigkeit zu Ewigkeit.", "tokens": ["von", "E\u00b7wig\u00b7keit", "zu", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du bist der Bittende und Bange,", "tokens": ["Du", "bist", "der", "Bit\u00b7ten\u00b7de", "und", "Ban\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "der aller Dinge Sinn beschwert.", "tokens": ["der", "al\u00b7ler", "Din\u00b7ge", "Sinn", "be\u00b7schwert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du bist die Silbe im Gesange,", "tokens": ["Du", "bist", "die", "Sil\u00b7be", "im", "Ge\u00b7san\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die immer zitternder im Zwange", "tokens": ["die", "im\u00b7mer", "zit\u00b7tern\u00b7der", "im", "Zwan\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "der starken Stimmen wiederkehrt.", "tokens": ["der", "star\u00b7ken", "Stim\u00b7men", "wie\u00b7der\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.105": {"line.1": {"text": "Du hast dich anders nie gelehrt:", "tokens": ["Du", "hast", "dich", "an\u00b7ders", "nie", "ge\u00b7lehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.106": {"line.1": {"text": "Denn du bist nicht der Sch\u00f6numscharte,", "tokens": ["Denn", "du", "bist", "nicht", "der", "Sch\u00f6\u00b7num\u00b7schar\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "um welchen sich der Reichtum reiht.", "tokens": ["um", "wel\u00b7chen", "sich", "der", "Reich\u00b7tum", "reiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist der Schlichte, welcher sparte.", "tokens": ["Du", "bist", "der", "Schlich\u00b7te", ",", "wel\u00b7cher", "spar\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Du bist der Bauer mit dem Barte", "tokens": ["Du", "bist", "der", "Bau\u00b7er", "mit", "dem", "Bar\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "von Ewigkeit zu Ewigkeit.", "tokens": ["von", "E\u00b7wig\u00b7keit", "zu", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.107": {"line.1": {"text": "Du, gestern Knabe, dem die Wirrnis kam:", "tokens": ["Du", ",", "ge\u00b7stern", "Kna\u00b7be", ",", "dem", "die", "Wirr\u00b7nis", "kam", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df sich dein Blut in Blindheit nicht vergeude.", "tokens": ["Da\u00df", "sich", "dein", "Blut", "in", "Blind\u00b7heit", "nicht", "ver\u00b7geu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PPOSAT", "NN", "APPR", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du meinst nicht den Genu\u00df, du meinst die Freude;", "tokens": ["Du", "meinst", "nicht", "den", "Ge\u00b7nu\u00df", ",", "du", "meinst", "die", "Freu\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "ART", "NN", "$,", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "du bist gebildet als ein Br\u00e4utigam,", "tokens": ["du", "bist", "ge\u00b7bil\u00b7det", "als", "ein", "Br\u00e4u\u00b7ti\u00b7gam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KOKOM", "ART", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und deine Braut soll werden: deine Scham.", "tokens": ["und", "dei\u00b7ne", "Braut", "soll", "wer\u00b7den", ":", "dei\u00b7ne", "Scham", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "VAINF", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.108": {"line.1": {"text": "Die gro\u00dfe Lust hat auch nach dir Verlangen,", "tokens": ["Die", "gro\u00b7\u00dfe", "Lust", "hat", "auch", "nach", "dir", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "APPR", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und alle Arme sind auf einmal nackt.", "tokens": ["und", "al\u00b7le", "Ar\u00b7me", "sind", "auf", "ein\u00b7mal", "nackt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "APPR", "ADV", "ADJD", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auf frommen Bildern sind die bleichen Wangen", "tokens": ["Auf", "from\u00b7men", "Bil\u00b7dern", "sind", "die", "blei\u00b7chen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "von fremden Feuern \u00fcberflackt;", "tokens": ["von", "frem\u00b7den", "Feu\u00b7ern", "\u00fc\u00b7ber\u00b7flackt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und deine Sinne sind wie viele Schlangen,", "tokens": ["und", "dei\u00b7ne", "Sin\u00b7ne", "sind", "wie", "vie\u00b7le", "Schlan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "KOKOM", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die, von des Tones Rot umfangen,", "tokens": ["die", ",", "von", "des", "To\u00b7nes", "Rot", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "sich spannen in der Tamburine Takt.", "tokens": ["sich", "span\u00b7nen", "in", "der", "Tam\u00b7bu\u00b7ri\u00b7ne", "Takt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.109": {"line.1": {"text": "Und pl\u00f6tzlich bist du ganz allein gelassen", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "bist", "du", "ganz", "al\u00b7lein", "ge\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "mit deinen H\u00e4nden, die dich hassen \u2013", "tokens": ["mit", "dei\u00b7nen", "H\u00e4n\u00b7den", ",", "die", "dich", "has\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und wenn dein Wille nicht ein Wunder tut:", "tokens": ["und", "wenn", "dein", "Wil\u00b7le", "nicht", "ein", "Wun\u00b7der", "tut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.5": {"text": "Aber da gehen wie durch dunkle Gassen", "tokens": ["A\u00b7ber", "da", "ge\u00b7hen", "wie", "durch", "dunk\u00b7le", "Gas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVINF", "KOKOM", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "von Gott Ger\u00fcchte durch dein dunkles Blut.", "tokens": ["von", "Gott", "Ge\u00b7r\u00fcch\u00b7te", "durch", "dein", "dunk\u00b7les", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.110": {"line.1": {"text": "Dann bete du, wie es dich dieser lehrt,", "tokens": ["Dann", "be\u00b7te", "du", ",", "wie", "es", "dich", "die\u00b7ser", "lehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "PPER", "PRF", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der selber aus der Wirrnis wiederkehrt", "tokens": ["der", "sel\u00b7ber", "aus", "der", "Wirr\u00b7nis", "wie\u00b7der\u00b7kehrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und so, da\u00df er zu heiligen Gestalten,", "tokens": ["und", "so", ",", "da\u00df", "er", "zu", "hei\u00b7li\u00b7gen", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die alle ihres Wesens W\u00fcrde halten,", "tokens": ["die", "al\u00b7le", "ih\u00b7res", "We\u00b7sens", "W\u00fcr\u00b7de", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "in einer Kirche und auf goldnen Smalten", "tokens": ["in", "ei\u00b7ner", "Kir\u00b7che", "und", "auf", "gold\u00b7nen", "Smal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die Sch\u00f6nheit malte, und sie hielt ein Schwert.", "tokens": ["die", "Sch\u00f6n\u00b7heit", "mal\u00b7te", ",", "und", "sie", "hielt", "ein", "Schwert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.111": {"line.1": {"text": "Er lehrt dich sagen:", "tokens": ["Er", "lehrt", "dich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Du mein tiefer Sinn,", "tokens": ["Du", "mein", "tie\u00b7fer", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "vertraue mir, da\u00df ich dich nicht entt\u00e4usche;", "tokens": ["ver\u00b7trau\u00b7e", "mir", ",", "da\u00df", "ich", "dich", "nicht", "ent\u00b7t\u00e4u\u00b7sche", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in meinem Blute sind so viel Ger\u00e4usche,", "tokens": ["in", "mei\u00b7nem", "Blu\u00b7te", "sind", "so", "viel", "Ge\u00b7r\u00e4u\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ich aber wei\u00df, da\u00df ich aus Sehnsucht bin.", "tokens": ["ich", "a\u00b7ber", "wei\u00df", ",", "da\u00df", "ich", "aus", "Sehn\u00b7sucht", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.112": {"line.1": {"text": "Ein gro\u00dfer Ernst bricht \u00fcber mich herein.", "tokens": ["Ein", "gro\u00b7\u00dfer", "Ernst", "bricht", "\u00fc\u00b7ber", "mich", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In seinem Schatten ist das Leben k\u00fchl.", "tokens": ["In", "sei\u00b7nem", "Schat\u00b7ten", "ist", "das", "Le\u00b7ben", "k\u00fchl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin zum erstenmal mit dir allein,", "tokens": ["Ich", "bin", "zum", "ers\u00b7ten\u00b7mal", "mit", "dir", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADV", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "du, mein Gef\u00fchl.", "tokens": ["du", ",", "mein", "Ge\u00b7f\u00fchl", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Du bist so m\u00e4dchenhaft.", "tokens": ["Du", "bist", "so", "m\u00e4d\u00b7chen\u00b7haft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.113": {"line.1": {"text": "Es war ein Weib in meiner Nachbarschaft", "tokens": ["Es", "war", "ein", "Weib", "in", "mei\u00b7ner", "Nach\u00b7bar\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und winkte mir aus welkenden Gew\u00e4ndern.", "tokens": ["und", "wink\u00b7te", "mir", "aus", "wel\u00b7ken\u00b7den", "Ge\u00b7w\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PWAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Du aber sprichst mir von so fernen L\u00e4ndern.", "tokens": ["Du", "a\u00b7ber", "sprichst", "mir", "von", "so", "fer\u00b7nen", "L\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und meine Kraft", "tokens": ["Und", "mei\u00b7ne", "Kraft"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "schaut nach den H\u00fcgelr\u00e4ndern.", "tokens": ["schaut", "nach", "den", "H\u00fc\u00b7gel\u00b7r\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.114": {"line.1": {"text": "Ich habe Hymnen, die ich schweige.", "tokens": ["Ich", "ha\u00b7be", "Hym\u00b7nen", ",", "die", "ich", "schwei\u00b7ge", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es giebt ein Aufgerichtetsein,", "tokens": ["Es", "giebt", "ein", "Auf\u00b7ge\u00b7rich\u00b7te\u00b7tsein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "darin ich meine Sinne neige:", "tokens": ["da\u00b7rin", "ich", "mei\u00b7ne", "Sin\u00b7ne", "nei\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPOSAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "du siehst mich gro\u00df und ich bin klein.", "tokens": ["du", "siehst", "mich", "gro\u00df", "und", "ich", "bin", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du kannst mich dunkel unterscheiden", "tokens": ["Du", "kannst", "mich", "dun\u00b7kel", "un\u00b7ter\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "von jenen Dingen, welche knien;", "tokens": ["von", "je\u00b7nen", "Din\u00b7gen", ",", "wel\u00b7che", "kni\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "sie sind wie Herden und sie weiden,", "tokens": ["sie", "sind", "wie", "Her\u00b7den", "und", "sie", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "NN", "KON", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ich bin der Hirt am Hang der Heiden,", "tokens": ["ich", "bin", "der", "Hirt", "am", "Hang", "der", "Hei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "vor welchem sie zu Abend ziehn.", "tokens": ["vor", "wel\u00b7chem", "sie", "zu", "A\u00b7bend", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dann komm ich hinter ihnen her", "tokens": ["Dann", "komm", "ich", "hin\u00b7ter", "ih\u00b7nen", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "und h\u00f6re dumpf die dunklen Br\u00fccken,", "tokens": ["und", "h\u00f6\u00b7re", "dumpf", "die", "dunk\u00b7len", "Br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "und in dem Rauch von ihren R\u00fccken", "tokens": ["und", "in", "dem", "Rauch", "von", "ih\u00b7ren", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "verbirgt sich meine Wiederkehr.", "tokens": ["ver\u00b7birgt", "sich", "mei\u00b7ne", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.115": {"line.1": {"text": "Gott, wie begreif ich deine Stunde,", "tokens": ["Gott", ",", "wie", "be\u00b7greif", "ich", "dei\u00b7ne", "Stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADJD", "PPER", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "als du, da\u00df sie im Raum sich runde,", "tokens": ["als", "du", ",", "da\u00df", "sie", "im", "Raum", "sich", "run\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUS", "PPER", "APPRART", "NN", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Stimme vor dich hingestellt;", "tokens": ["die", "Stim\u00b7me", "vor", "dich", "hin\u00b7ge\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dir war das Nichts wie eine Wunde,", "tokens": ["dir", "war", "das", "Nichts", "wie", "ei\u00b7ne", "Wun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIS", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da k\u00fchltest du sie mit der Welt.", "tokens": ["da", "k\u00fchl\u00b7test", "du", "sie", "mit", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.116": {"line.1": {"text": "Jetzt heilt es leise unter uns.", "tokens": ["Jetzt", "heilt", "es", "lei\u00b7se", "un\u00b7ter", "uns", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.117": {"line.1": {"text": "Denn die Vergangenheiten tranken", "tokens": ["Denn", "die", "Ver\u00b7gan\u00b7gen\u00b7hei\u00b7ten", "tran\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die vielen Fieber aus dem Kranken,", "tokens": ["die", "vie\u00b7len", "Fie\u00b7ber", "aus", "dem", "Kran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "den ruhigen Puls des Hintergrunds.", "tokens": ["den", "ru\u00b7hi\u00b7gen", "Puls", "des", "Hin\u00b7ter\u00b7grunds", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.118": {"line.1": {"text": "Wir liegen lindernd auf dem Nichts", "tokens": ["Wir", "lie\u00b7gen", "lin\u00b7dernd", "auf", "dem", "Nichts"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und wir verh\u00fcllen alle Risse;", "tokens": ["und", "wir", "ver\u00b7h\u00fcl\u00b7len", "al\u00b7le", "Ris\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du aber w\u00e4chst ins Ungewisse", "tokens": ["du", "a\u00b7ber", "w\u00e4chst", "ins", "Un\u00b7ge\u00b7wis\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "im Schatten deines Angesichts.", "tokens": ["im", "Schat\u00b7ten", "dei\u00b7nes", "An\u00b7ge\u00b7sichts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.119": {"line.1": {"text": "Alle, die ihre H\u00e4nde regen", "tokens": ["Al\u00b7le", ",", "die", "ih\u00b7re", "H\u00e4n\u00b7de", "re\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "PPOSAT", "NN", "ADJA"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "nicht in der Zeit, der armen Stadt,", "tokens": ["nicht", "in", "der", "Zeit", ",", "der", "ar\u00b7men", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "alle, die sie an Leises legen,", "tokens": ["al\u00b7le", ",", "die", "sie", "an", "Lei\u00b7ses", "le\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "an eine Stelle, fern den Wegen,", "tokens": ["an", "ei\u00b7ne", "Stel\u00b7le", ",", "fern", "den", "We\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die kaum noch einen Namen hat, \u2013", "tokens": ["die", "kaum", "noch", "ei\u00b7nen", "Na\u00b7men", "hat", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "VAFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sprechen dich aus, du Alltagssegen.", "tokens": ["spre\u00b7chen", "dich", "aus", ",", "du", "All\u00b7tags\u00b7se\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PPER", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "und sagen sanft auf einem Blatt:", "tokens": ["und", "sa\u00b7gen", "sanft", "auf", "ei\u00b7nem", "Blatt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.120": {"line.1": {"text": "Es giebt im Grunde nur Gebete,", "tokens": ["Es", "giebt", "im", "Grun\u00b7de", "nur", "Ge\u00b7be\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "so sind die H\u00e4nde uns geweiht,", "tokens": ["so", "sind", "die", "H\u00e4n\u00b7de", "uns", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df sie nichts schufen, was nicht flehte;", "tokens": ["da\u00df", "sie", "nichts", "schu\u00b7fen", ",", "was", "nicht", "fleh\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVINF", "$,", "PRELS", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ob einer malte oder m\u00e4hte,", "tokens": ["ob", "ei\u00b7ner", "mal\u00b7te", "o\u00b7der", "m\u00e4h\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "schon aus dem Ringen der Ger\u00e4te", "tokens": ["schon", "aus", "dem", "Rin\u00b7gen", "der", "Ge\u00b7r\u00e4\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "entfaltete sich Fr\u00f6mmigkeit.", "tokens": ["ent\u00b7fal\u00b7te\u00b7te", "sich", "Fr\u00f6m\u00b7mig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.121": {"line.1": {"text": "Die Zeit ist eine vielgestalte.", "tokens": ["Die", "Zeit", "ist", "ei\u00b7ne", "viel\u00b7ge\u00b7stal\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir h\u00f6ren manchmal von der Zeit,", "tokens": ["Wir", "h\u00f6\u00b7ren", "manch\u00b7mal", "von", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und tun das Ewige und Alte;", "tokens": ["und", "tun", "das", "E\u00b7wi\u00b7ge", "und", "Al\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "wir wissen, da\u00df uns Gott umwallte", "tokens": ["wir", "wis\u00b7sen", ",", "da\u00df", "uns", "Gott", "um\u00b7wall\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVINF", "$,", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "gro\u00df wie ein Bart und wie ein Kleid.", "tokens": ["gro\u00df", "wie", "ein", "Bart", "und", "wie", "ein", "Kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wir sind wie Adern im Basalte", "tokens": ["Wir", "sind", "wie", "A\u00b7dern", "im", "Ba\u00b7sal\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KOKOM", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "in Gottes harter Herrlichkeit.", "tokens": ["in", "Got\u00b7tes", "har\u00b7ter", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.122": {"line.1": {"text": "Der Name ist uns wie ein Licht", "tokens": ["Der", "Na\u00b7me", "ist", "uns", "wie", "ein", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hart an die Stirn gestellt.", "tokens": ["hart", "an", "die", "Stirn", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da senkte sich mein Angesicht", "tokens": ["Da", "senk\u00b7te", "sich", "mein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "vor diesem zeitigen Gericht", "tokens": ["vor", "die\u00b7sem", "zei\u00b7ti\u00b7gen", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und sah (von dem es seither spricht)", "tokens": ["und", "sah", "(", "von", "dem", "es", "sei\u00b7ther", "spricht", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "APPR", "PRELS", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "dich, gro\u00dfes dunkelndes Gewicht", "tokens": ["dich", ",", "gro\u00b7\u00dfes", "dun\u00b7keln\u00b7des", "Ge\u00b7wicht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "an mir und an der Welt.", "tokens": ["an", "mir", "und", "an", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.123": {"line.1": {"text": "Du bogst mich langsam aus der Zeit,", "tokens": ["Du", "bogst", "mich", "lang\u00b7sam", "aus", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in die ich schwankend stieg;", "tokens": ["in", "die", "ich", "schwan\u00b7kend", "stieg", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "ich neigte mich nach leisem Streit:", "tokens": ["ich", "neig\u00b7te", "mich", "nach", "lei\u00b7sem", "Streit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "jetzt dauert deine Dunkelheit", "tokens": ["jetzt", "dau\u00b7ert", "dei\u00b7ne", "Dun\u00b7kel\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "um deinen sanften Sieg.", "tokens": ["um", "dei\u00b7nen", "sanf\u00b7ten", "Sieg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.124": {"line.1": {"text": "Jetzt hast du mich und wei\u00dft nicht wen,", "tokens": ["Jetzt", "hast", "du", "mich", "und", "wei\u00dft", "nicht", "wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "KON", "VVFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "denn deine breiten Sinne sehn", "tokens": ["denn", "dei\u00b7ne", "brei\u00b7ten", "Sin\u00b7ne", "sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "nur, da\u00df ich dunkel ward.", "tokens": ["nur", ",", "da\u00df", "ich", "dun\u00b7kel", "ward", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Du h\u00e4ltst mich seltsam zart", "tokens": ["Du", "h\u00e4ltst", "mich", "selt\u00b7sam", "zart"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "und horchst, wie meine H\u00e4nde gehn", "tokens": ["und", "horchst", ",", "wie", "mei\u00b7ne", "H\u00e4n\u00b7de", "gehn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "durch deinen alten Bart.", "tokens": ["durch", "dei\u00b7nen", "al\u00b7ten", "Bart", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.125": {"line.1": {"text": "Dein allererstes Wort war: ", "tokens": ["Dein", "al\u00b7le\u00b7rers\u00b7tes", "Wort", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "da ward die Zeit. Dann schwiegst du lange.", "tokens": ["da", "ward", "die", "Zeit", ".", "Dann", "schwiegst", "du", "lan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dein zweites Wort ward Mensch und bange", "tokens": ["Dein", "zwei\u00b7tes", "Wort", "ward", "Mensch", "und", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(wir dunkeln noch in seinem Klange)", "tokens": ["(", "wir", "dun\u00b7keln", "noch", "in", "sei\u00b7nem", "Klan\u00b7ge", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und wieder sinnt dein Angesicht.", "tokens": ["und", "wie\u00b7der", "sinnt", "dein", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.126": {"line.1": {"text": "Ich aber will dein drittes nicht.", "tokens": ["Ich", "a\u00b7ber", "will", "dein", "drit\u00b7tes", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPOSAT", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.127": {"line.1": {"text": "Ich bete nachts oft: Sei der Stumme,", "tokens": ["Ich", "be\u00b7te", "nachts", "oft", ":", "Sei", "der", "Stum\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der wachsend in Geb\u00e4rden bleibt", "tokens": ["der", "wach\u00b7send", "in", "Ge\u00b7b\u00e4r\u00b7den", "bleibt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und den der Geist im Traume treibt,", "tokens": ["und", "den", "der", "Geist", "im", "Trau\u00b7me", "treibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df er des Schweigens schwere Summe", "tokens": ["da\u00df", "er", "des", "Schwei\u00b7gens", "schwe\u00b7re", "Sum\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "in Stirnen und Gebirge schreibt.", "tokens": ["in", "Stir\u00b7nen", "und", "Ge\u00b7bir\u00b7ge", "schreibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.128": {"line.1": {"text": "Sei du die Zuflucht vor dem Zorne,", "tokens": ["Sei", "du", "die", "Zu\u00b7flucht", "vor", "dem", "Zor\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "der das Unsagbare verstie\u00df.", "tokens": ["der", "das", "Un\u00b7sag\u00b7ba\u00b7re", "ver\u00b7stie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Es wurde Nacht im Paradies:", "tokens": ["Es", "wur\u00b7de", "Nacht", "im", "Pa\u00b7ra\u00b7dies", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sei du der H\u00fcter mit dem Horne,", "tokens": ["sei", "du", "der", "H\u00fc\u00b7ter", "mit", "dem", "Hor\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und man erz\u00e4hlt nur, da\u00df er blies.", "tokens": ["und", "man", "er\u00b7z\u00e4hlt", "nur", ",", "da\u00df", "er", "blies", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.129": {"line.1": {"text": "Du kommst und gehst. Die T\u00fcren fallen", "tokens": ["Du", "kommst", "und", "gehst", ".", "Die", "T\u00fc\u00b7ren", "fal\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "viel sanfter zu, fast ohne Wehn.", "tokens": ["viel", "sanf\u00b7ter", "zu", ",", "fast", "oh\u00b7ne", "Wehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKVZ", "$,", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist der Leiseste von Allen,", "tokens": ["Du", "bist", "der", "Lei\u00b7ses\u00b7te", "von", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die durch die leisen H\u00e4user gehn.", "tokens": ["die", "durch", "die", "lei\u00b7sen", "H\u00e4u\u00b7ser", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.130": {"line.1": {"text": "Man kann sich so an dich gew\u00f6hnen,", "tokens": ["Man", "kann", "sich", "so", "an", "dich", "ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "da\u00df man nicht aus dem Buche schaut,", "tokens": ["da\u00df", "man", "nicht", "aus", "dem", "Bu\u00b7che", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "wenn seine Bilder sich versch\u00f6nen,", "tokens": ["wenn", "sei\u00b7ne", "Bil\u00b7der", "sich", "ver\u00b7sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "von deinem Schatten \u00fcberblaut;", "tokens": ["von", "dei\u00b7nem", "Schat\u00b7ten", "\u00fc\u00b7berb\u00b7laut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "weil dich die Dinge immer t\u00f6nen,", "tokens": ["weil", "dich", "die", "Din\u00b7ge", "im\u00b7mer", "t\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "nur einmal leis und einmal laut.", "tokens": ["nur", "ein\u00b7mal", "leis", "und", "ein\u00b7mal", "laut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.131": {"line.1": {"text": "Oft wenn ich dich in Sinnen sehe,", "tokens": ["Oft", "wenn", "ich", "dich", "in", "Sin\u00b7nen", "se\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "verteilt sich deine Allgestalt:", "tokens": ["ver\u00b7teilt", "sich", "dei\u00b7ne", "All\u00b7ge\u00b7stalt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du gehst wie lauter lichte Rehe", "tokens": ["du", "gehst", "wie", "lau\u00b7ter", "lich\u00b7te", "Re\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und ich bin dunkel und bin Wald.", "tokens": ["und", "ich", "bin", "dun\u00b7kel", "und", "bin", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "KON", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.132": {"line.1": {"text": "Du bist ein Rad, an dem ich stehe:", "tokens": ["Du", "bist", "ein", "Rad", ",", "an", "dem", "ich", "ste\u00b7he", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von deinen vielen dunklen Achsen", "tokens": ["von", "dei\u00b7nen", "vie\u00b7len", "dunk\u00b7len", "Ach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wird immer wieder eine schwer", "tokens": ["wird", "im\u00b7mer", "wie\u00b7der", "ei\u00b7ne", "schwer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und dreht sich n\u00e4her zu mir her,", "tokens": ["und", "dreht", "sich", "n\u00e4\u00b7her", "zu", "mir", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und meine willigen Werke wachsen", "tokens": ["und", "mei\u00b7ne", "wil\u00b7li\u00b7gen", "Wer\u00b7ke", "wach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "von Wiederkehr zu Wiederkehr.", "tokens": ["von", "Wie\u00b7der\u00b7kehr", "zu", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.133": {"line.1": {"text": "Du bist der Tiefste, welcher ragte,", "tokens": ["Du", "bist", "der", "Tiefs\u00b7te", ",", "wel\u00b7cher", "rag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Taucher und der T\u00fcrme Neid.", "tokens": ["der", "Tau\u00b7cher", "und", "der", "T\u00fcr\u00b7me", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du bist der Sanfte, der sich sagte,", "tokens": ["Du", "bist", "der", "Sanf\u00b7te", ",", "der", "sich", "sag\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und doch: wenn dich ein Feiger fragte,", "tokens": ["und", "doch", ":", "wenn", "dich", "ein", "Fei\u00b7ger", "frag\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "so schwelgtest du in Schweigsamkeit.", "tokens": ["so", "schwelg\u00b7test", "du", "in", "Schweig\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.134": {"line.1": {"text": "Du bist der Wald der Widerspr\u00fcche.", "tokens": ["Du", "bist", "der", "Wald", "der", "Wi\u00b7der\u00b7spr\u00fc\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich darf dich wiegen wie ein Kind,", "tokens": ["Ich", "darf", "dich", "wie\u00b7gen", "wie", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und doch vollziehn sich deine Fl\u00fcche,", "tokens": ["und", "doch", "voll\u00b7ziehn", "sich", "dei\u00b7ne", "Fl\u00fc\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die \u00fcber V\u00f6lkern furchtbar sind.", "tokens": ["die", "\u00fc\u00b7ber", "V\u00f6l\u00b7kern", "furcht\u00b7bar", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.135": {"line.1": {"text": "Dir ward das erste Buch geschrieben,", "tokens": ["Dir", "ward", "das", "ers\u00b7te", "Buch", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das erste Bild versuchte dich,", "tokens": ["das", "ers\u00b7te", "Bild", "ver\u00b7such\u00b7te", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du warst im Leiden und im Lieben,", "tokens": ["du", "warst", "im", "Lei\u00b7den", "und", "im", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "KON", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dein Ernst war wie aus Erz getrieben", "tokens": ["dein", "Ernst", "war", "wie", "aus", "Erz", "ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "auf jeder Stirn, die mit den sieben", "tokens": ["auf", "je\u00b7der", "Stirn", ",", "die", "mit", "den", "sie\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "APPR", "ART", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "erf\u00fcllten Tagen dich verglich.", "tokens": ["er\u00b7f\u00fcll\u00b7ten", "Ta\u00b7gen", "dich", "ver\u00b7glich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.136": {"line.1": {"text": "Du gingst in Tausenden verloren,", "tokens": ["Du", "gingst", "in", "Tau\u00b7sen\u00b7den", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und alle Opfer wurden kalt;", "tokens": ["und", "al\u00b7le", "Op\u00b7fer", "wur\u00b7den", "kalt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "bis du in hohen Kirchenchoren", "tokens": ["bis", "du", "in", "ho\u00b7hen", "Kir\u00b7chen\u00b7cho\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dich r\u00fchrtest hinter goldnen Toren;", "tokens": ["dich", "r\u00fchr\u00b7test", "hin\u00b7ter", "gold\u00b7nen", "To\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und eine Bangnis, die geboren,", "tokens": ["und", "ei\u00b7ne", "Bang\u00b7nis", ",", "die", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "umg\u00fcrtete dich mit Gestalt.", "tokens": ["um\u00b7g\u00fcr\u00b7te\u00b7te", "dich", "mit", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.137": {"line.1": {"text": "Ich wei\u00df: Du bist der R\u00e4tselhafte,", "tokens": ["Ich", "wei\u00df", ":", "Du", "bist", "der", "R\u00e4t\u00b7sel\u00b7haf\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "um den die Zeit in Z\u00f6gern stand.", "tokens": ["um", "den", "die", "Zeit", "in", "Z\u00f6\u00b7gern", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O wie so sch\u00f6n ich dich erschaffte", "tokens": ["O", "wie", "so", "sch\u00f6n", "ich", "dich", "er\u00b7schaff\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADV", "ADJD", "PPER", "PRF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in einer Stunde, die mich straffte,", "tokens": ["in", "ei\u00b7ner", "Stun\u00b7de", ",", "die", "mich", "straff\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "in einer Hoffahrt meiner Hand.", "tokens": ["in", "ei\u00b7ner", "Hof\u00b7fahrt", "mei\u00b7ner", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.138": {"line.1": {"text": "Ich zeichnete viel ziere Risse,", "tokens": ["Ich", "zeich\u00b7ne\u00b7te", "viel", "zie\u00b7re", "Ris\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "behorchte alle Hindernisse, \u2013", "tokens": ["be\u00b7horch\u00b7te", "al\u00b7le", "Hin\u00b7der\u00b7nis\u00b7se", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "dann wurden mir die Pl\u00e4ne krank:", "tokens": ["dann", "wur\u00b7den", "mir", "die", "Pl\u00e4\u00b7ne", "krank", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "es wirrten sich wie Dorngerank", "tokens": ["es", "wirr\u00b7ten", "sich", "wie", "Dorn\u00b7ge\u00b7rank"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "KOKOM", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die Linien und die Ovale,", "tokens": ["die", "Li\u00b7ni\u00b7en", "und", "die", "O\u00b7va\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "bis tief in mir mit einem Male", "tokens": ["bis", "tief", "in", "mir", "mit", "ei\u00b7nem", "Ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "aus einem Griff ins Ungewisse", "tokens": ["aus", "ei\u00b7nem", "Griff", "ins", "Un\u00b7ge\u00b7wis\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die frommste aller Formen sprang.", "tokens": ["die", "fromms\u00b7te", "al\u00b7ler", "For\u00b7men", "sprang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.139": {"line.1": {"text": "Ich kann mein Werk nicht \u00fcberschaun", "tokens": ["Ich", "kann", "mein", "Werk", "nicht", "\u00fc\u00b7bersc\u00b7haun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und f\u00fchle doch: es steht vollendet.", "tokens": ["und", "f\u00fch\u00b7le", "doch", ":", "es", "steht", "voll\u00b7en\u00b7det", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Aber, die Augen abgewendet,", "tokens": ["A\u00b7ber", ",", "die", "Au\u00b7gen", "ab\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "will ich es immer wieder baun.", "tokens": ["will", "ich", "es", "im\u00b7mer", "wie\u00b7der", "baun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.140": {"line.1": {"text": "So ist mein Tagwerk, \u00fcber dem", "tokens": ["So", "ist", "mein", "Tag\u00b7werk", ",", "\u00fc\u00b7ber", "dem"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$,", "APPR", "ART"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "mein Schatten liegt wie eine Schale.", "tokens": ["mein", "Schat\u00b7ten", "liegt", "wie", "ei\u00b7ne", "Scha\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und bin ich auch wie Laub und Lehm,", "tokens": ["Und", "bin", "ich", "auch", "wie", "Laub", "und", "Lehm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sooft ich bete oder male", "tokens": ["sooft", "ich", "be\u00b7te", "o\u00b7der", "ma\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ist Sonntag, und ich bin im Tale", "tokens": ["ist", "Sonn\u00b7tag", ",", "und", "ich", "bin", "im", "Ta\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "KON", "PPER", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ein jubelndes Jerusalem.", "tokens": ["ein", "ju\u00b7beln\u00b7des", "Je\u00b7ru\u00b7sa\u00b7lem", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.141": {"line.1": {"text": "Ich bin die stolze Stadt des Herrn", "tokens": ["Ich", "bin", "die", "stol\u00b7ze", "Stadt", "des", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und sage ihn mit hundert Zungen;", "tokens": ["und", "sa\u00b7ge", "ihn", "mit", "hun\u00b7dert", "Zun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "in mir ist Davids Dank verklungen:", "tokens": ["in", "mir", "ist", "Da\u00b7vids", "Dank", "ver\u00b7klun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ich lag in Harfend\u00e4mmerungen", "tokens": ["ich", "lag", "in", "Har\u00b7fen\u00b7d\u00e4m\u00b7me\u00b7run\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und atmete den Abendstern.", "tokens": ["und", "at\u00b7me\u00b7te", "den", "A\u00b7bends\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.142": {"line.1": {"text": "Nach Aufgang gehen meine Gassen.", "tokens": ["Nach", "Auf\u00b7gang", "ge\u00b7hen", "mei\u00b7ne", "Gas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und bin ich lang vom Volk verlassen,", "tokens": ["Und", "bin", "ich", "lang", "vom", "Volk", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "so ists: damit ich gr\u00f6\u00dfer bin.", "tokens": ["so", "ists", ":", "da\u00b7mit", "ich", "gr\u00f6\u00b7\u00dfer", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$.", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich h\u00f6re jeden in mir schreiten", "tokens": ["Ich", "h\u00f6\u00b7re", "je\u00b7den", "in", "mir", "schrei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und breite meine Einsamkeiten", "tokens": ["und", "brei\u00b7te", "mei\u00b7ne", "Ein\u00b7sam\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "von Anbeginn zu Anbeginn.", "tokens": ["von", "An\u00b7be\u00b7ginn", "zu", "An\u00b7be\u00b7ginn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.143": {"line.1": {"text": "Ihr vielen unbest\u00fcrmten St\u00e4dte,", "tokens": ["Ihr", "vie\u00b7len", "un\u00b7be\u00b7st\u00fcrm\u00b7ten", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "habt ihr euch nie den Feind ersehnt?", "tokens": ["habt", "ihr", "euch", "nie", "den", "Feind", "er\u00b7sehnt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O da\u00df er euch belagert h\u00e4tte", "tokens": ["O", "da\u00df", "er", "euch", "be\u00b7la\u00b7gert", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "PPER", "PPER", "VVPP", "VAFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ein langes schwankendes Jahrzehnt.", "tokens": ["ein", "lan\u00b7ges", "schwan\u00b7ken\u00b7des", "Jahr\u00b7zehnt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--++", "measure": "iambic.tetra.relaxed"}}, "stanza.144": {"line.1": {"text": "Bis ihr ihn trostlos und in Trauern,", "tokens": ["Bis", "ihr", "ihn", "trost\u00b7los", "und", "in", "Trau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "ADJD", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "bis da\u00df ihr hungernd ihn ertrugt;", "tokens": ["bis", "da\u00df", "ihr", "hun\u00b7gernd", "ihn", "er\u00b7trugt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "VVPP", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er liegt wie Landschaft vor den Mauern,", "tokens": ["er", "liegt", "wie", "Land\u00b7schaft", "vor", "den", "Mau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "denn also wei\u00df er auszudauern", "tokens": ["denn", "al\u00b7so", "wei\u00df", "er", "aus\u00b7zu\u00b7dau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "um jene, die er heimgesucht.", "tokens": ["um", "je\u00b7ne", ",", "die", "er", "heim\u00b7ge\u00b7sucht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.145": {"line.1": {"text": "Schaut aus vom Rande eurer D\u00e4cher:", "tokens": ["Schaut", "aus", "vom", "Ran\u00b7de", "eu\u00b7rer", "D\u00e4\u00b7cher", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da lagert er und wird nicht matt", "tokens": ["da", "la\u00b7gert", "er", "und", "wird", "nicht", "matt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VAFIN", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und wird nicht weniger und schw\u00e4cher", "tokens": ["und", "wird", "nicht", "we\u00b7ni\u00b7ger", "und", "schw\u00e4\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und schickt nicht Droher und Versprecher", "tokens": ["und", "schickt", "nicht", "Dro\u00b7her", "und", "Ver\u00b7spre\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und \u00dcberreder in die Stadt.", "tokens": ["und", "\u00dc\u00b7berr\u00b7e\u00b7der", "in", "die", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.146": {"line.1": {"text": "Er ist der gro\u00dfe Mauerbrecher,", "tokens": ["Er", "ist", "der", "gro\u00b7\u00dfe", "Mau\u00b7er\u00b7bre\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der eine stumme Arbeit hat.", "tokens": ["der", "ei\u00b7ne", "stum\u00b7me", "Ar\u00b7beit", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.147": {"line.1": {"text": "Ich komme aus meinen Schwingen heim,", "tokens": ["Ich", "kom\u00b7me", "aus", "mei\u00b7nen", "Schwin\u00b7gen", "heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "mit denen ich mich verlor.", "tokens": ["mit", "de\u00b7nen", "ich", "mich", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Ich war Gesang, und Gott, der Reim,", "tokens": ["Ich", "war", "Ge\u00b7sang", ",", "und", "Gott", ",", "der", "Reim", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "KON", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "rauscht noch in meinem Ohr.", "tokens": ["rauscht", "noch", "in", "mei\u00b7nem", "Ohr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.148": {"line.1": {"text": "Ich werde wieder still und schlicht,", "tokens": ["Ich", "wer\u00b7de", "wie\u00b7der", "still", "und", "schlicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und meine Stimme steht;", "tokens": ["und", "mei\u00b7ne", "Stim\u00b7me", "steht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "es senkte sich mein Angesicht", "tokens": ["es", "senk\u00b7te", "sich", "mein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "zu besserem Gebet.", "tokens": ["zu", "bes\u00b7se\u00b7rem", "Ge\u00b7bet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Den andern war ich wie ein Wind,", "tokens": ["Den", "an\u00b7dern", "war", "ich", "wie", "ein", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "da ich sie r\u00fcttelnd rief.", "tokens": ["da", "ich", "sie", "r\u00fct\u00b7telnd", "rief", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Weit war ich, wo die Engel sind,", "tokens": ["Weit", "war", "ich", ",", "wo", "die", "En\u00b7gel", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PWAV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "hoch, wo das Licht in Nichts zerrinnt \u2013", "tokens": ["hoch", ",", "wo", "das", "Licht", "in", "Nichts", "zer\u00b7rinnt", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "APPR", "PIS", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Gott aber dunkelt tief.", "tokens": ["Gott", "a\u00b7ber", "dun\u00b7kelt", "tief", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.149": {"line.1": {"text": "Die Engel sind das letzte Wehn", "tokens": ["Die", "En\u00b7gel", "sind", "das", "letz\u00b7te", "Wehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an seines Wipfels Saum;", "tokens": ["an", "sei\u00b7nes", "Wip\u00b7fels", "Saum", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "da\u00df sie aus seinen \u00c4sten gehn,", "tokens": ["da\u00df", "sie", "aus", "sei\u00b7nen", "\u00c4s\u00b7ten", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ist ihnen wie ein Traum.", "tokens": ["ist", "ih\u00b7nen", "wie", "ein", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sie glauben dort dem Lichte mehr", "tokens": ["Sie", "glau\u00b7ben", "dort", "dem", "Lich\u00b7te", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als Gottes schwarzer Kraft,", "tokens": ["als", "Got\u00b7tes", "schwar\u00b7zer", "Kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "es fl\u00fcchtete sich Lucifer", "tokens": ["es", "fl\u00fcch\u00b7te\u00b7te", "sich", "Lu\u00b7ci\u00b7fer"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "in ihre Nachbarschaft.", "tokens": ["in", "ih\u00b7re", "Nach\u00b7bar\u00b7schaft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.150": {"line.1": {"text": "Er ist der F\u00fcrst im Land des Lichts,", "tokens": ["Er", "ist", "der", "F\u00fcrst", "im", "Land", "des", "Lichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und seine Stirne steht", "tokens": ["und", "sei\u00b7ne", "Stir\u00b7ne", "steht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "so steil am gro\u00dfen Glanz des Nichts,", "tokens": ["so", "steil", "am", "gro\u00b7\u00dfen", "Glanz", "des", "Nichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df er, versengten Angesichts,", "tokens": ["da\u00df", "er", ",", "ver\u00b7seng\u00b7ten", "An\u00b7ge\u00b7sichts", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "nach Finsternissen fleht.", "tokens": ["nach", "Fins\u00b7ter\u00b7nis\u00b7sen", "fleht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Er ist der helle Gott der Zeit,", "tokens": ["Er", "ist", "der", "hel\u00b7le", "Gott", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "zu dem sie laut erwacht,", "tokens": ["zu", "dem", "sie", "laut", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "und weil er oft in Schmerzen schreit", "tokens": ["und", "weil", "er", "oft", "in", "Schmer\u00b7zen", "schreit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "und oft in Schmerzen lacht,", "tokens": ["und", "oft", "in", "Schmer\u00b7zen", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "glaubt sie an seine Seligkeit", "tokens": ["glaubt", "sie", "an", "sei\u00b7ne", "Se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "und hangt an seiner Macht.", "tokens": ["und", "hangt", "an", "sei\u00b7ner", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.151": {"line.1": {"text": "Die Zeit ist wie ein welker Rand", "tokens": ["Die", "Zeit", "ist", "wie", "ein", "wel\u00b7ker", "Rand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an einem Buchenblatt.", "tokens": ["an", "ei\u00b7nem", "Bu\u00b7chen\u00b7blatt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie ist das gl\u00e4nzende Gewand,", "tokens": ["Sie", "ist", "das", "gl\u00e4n\u00b7zen\u00b7de", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "das Gott verworfen hat,", "tokens": ["das", "Gott", "ver\u00b7wor\u00b7fen", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "als Er, der immer Tiefe war,", "tokens": ["als", "Er", ",", "der", "im\u00b7mer", "Tie\u00b7fe", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "erm\u00fcdete des Flugs", "tokens": ["er\u00b7m\u00fc\u00b7de\u00b7te", "des", "Flugs"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "und sich verbarg vor jedem Jahr,", "tokens": ["und", "sich", "ver\u00b7barg", "vor", "je\u00b7dem", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "bis ihm sein wurzelhaftes Haar", "tokens": ["bis", "ihm", "sein", "wur\u00b7zel\u00b7haf\u00b7tes", "Haar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "durch alle Dinge wuchs.", "tokens": ["durch", "al\u00b7le", "Din\u00b7ge", "wuchs", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.152": {"line.1": {"text": "Du wirst nur mit der Tat erfa\u00dft,", "tokens": ["Du", "wirst", "nur", "mit", "der", "Tat", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit H\u00e4nden nur erhellt;", "tokens": ["mit", "H\u00e4n\u00b7den", "nur", "er\u00b7hellt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "ein jeder Sinn ist nur ein Gast", "tokens": ["ein", "je\u00b7der", "Sinn", "ist", "nur", "ein", "Gast"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und sehnt sich aus der Welt.", "tokens": ["und", "sehnt", "sich", "aus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.153": {"line.1": {"text": "Ersonnen ist ein jeder Sinn,", "tokens": ["Er\u00b7son\u00b7nen", "ist", "ein", "je\u00b7der", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "man f\u00fchlt den feinen Saum darin", "tokens": ["man", "f\u00fchlt", "den", "fei\u00b7nen", "Saum", "da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und da\u00df ihn einer spann:", "tokens": ["und", "da\u00df", "ihn", "ei\u00b7ner", "spann", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Du aber kommst und giebst dich hin", "tokens": ["Du", "a\u00b7ber", "kommst", "und", "giebst", "dich", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und f\u00e4llst den Fl\u00fcchtling an.", "tokens": ["und", "f\u00e4llst", "den", "Fl\u00fccht\u00b7ling", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.154": {"line.1": {"text": "Ich will nicht wissen, wo du bist,", "tokens": ["Ich", "will", "nicht", "wis\u00b7sen", ",", "wo", "du", "bist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sprich mir aus \u00fcberall.", "tokens": ["sprich", "mir", "aus", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dein williger Euangelist", "tokens": ["Dein", "wil\u00b7li\u00b7ger", "Eu\u00b7an\u00b7ge\u00b7list"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "verzeichnet alles und vergi\u00dft", "tokens": ["ver\u00b7zeich\u00b7net", "al\u00b7les", "und", "ver\u00b7gi\u00dft"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "zu schauen nach dem Schall.", "tokens": ["zu", "schau\u00b7en", "nach", "dem", "Schall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.155": {"line.1": {"text": "Ich geh doch immer auf dich zu", "tokens": ["Ich", "geh", "doch", "im\u00b7mer", "auf", "dich", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPER", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit meinem ganzen Gehn;", "tokens": ["mit", "mei\u00b7nem", "gan\u00b7zen", "Gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "denn wer bin ich und wer bist du,", "tokens": ["denn", "wer", "bin", "ich", "und", "wer", "bist", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PPER", "KON", "PWS", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenn wir uns nicht verstehn?", "tokens": ["wenn", "wir", "uns", "nicht", "ver\u00b7stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.156": {"line.1": {"text": "Mein Leben hat das gleiche Kleid und Haar", "tokens": ["Mein", "Le\u00b7ben", "hat", "das", "glei\u00b7che", "Kleid", "und", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wie aller alten Zaren Sterbestunde.", "tokens": ["wie", "al\u00b7ler", "al\u00b7ten", "Za\u00b7ren", "Ster\u00b7be\u00b7stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Macht entfremdete nur meinem Munde,", "tokens": ["Die", "Macht", "ent\u00b7frem\u00b7de\u00b7te", "nur", "mei\u00b7nem", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "doch meine Reiche, die ich schweigend runde,", "tokens": ["doch", "mei\u00b7ne", "Rei\u00b7che", ",", "die", "ich", "schwei\u00b7gend", "run\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NE", "$,", "PRELS", "PPER", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "versammeln sich in meinem Hintergrunde", "tokens": ["ver\u00b7sam\u00b7meln", "sich", "in", "mei\u00b7nem", "Hin\u00b7ter\u00b7grun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und meine Sinne sind noch Gossudar.", "tokens": ["und", "mei\u00b7ne", "Sin\u00b7ne", "sind", "noch", "Gos\u00b7su\u00b7dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.157": {"line.1": {"text": "F\u00fcr sie ist beten immer noch: Erbauen,", "tokens": ["F\u00fcr", "sie", "ist", "be\u00b7ten", "im\u00b7mer", "noch", ":", "Er\u00b7bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "VVFIN", "ADV", "ADV", "$.", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "aus allen Ma\u00dfen bauen, da\u00df das Grauen", "tokens": ["aus", "al\u00b7len", "Ma\u00b7\u00dfen", "bau\u00b7en", ",", "da\u00df", "das", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "fast wie die Gr\u00f6\u00dfe wird und sch\u00f6n, \u2013", "tokens": ["fast", "wie", "die", "Gr\u00f6\u00b7\u00dfe", "wird", "und", "sch\u00f6n", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "VAFIN", "KON", "ADJD", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und: jedes Hinknien und Vertrauen", "tokens": ["und", ":", "je\u00b7des", "Hin\u00b7kni\u00b7en", "und", "Ver\u00b7trau\u00b7en"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$.", "PIAT", "NN", "KON", "NN"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "(da\u00df es die andern nicht beschauen)", "tokens": ["(", "da\u00df", "es", "die", "an\u00b7dern", "nicht", "be\u00b7schau\u00b7en", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ART", "ADJA", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "mit vielen goldenen und blauen", "tokens": ["mit", "vie\u00b7len", "gol\u00b7de\u00b7nen", "und", "blau\u00b7en"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und bunten Kuppeln \u00fcberh\u00f6hn.", "tokens": ["und", "bun\u00b7ten", "Kup\u00b7peln", "\u00fc\u00b7berh\u00b7\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.158": {"line.1": {"text": "Denn was sind Kirchen und sind Kl\u00f6ster", "tokens": ["Denn", "was", "sind", "Kir\u00b7chen", "und", "sind", "Kl\u00f6s\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VAFIN", "NN", "KON", "VAFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in ihrem Steigen und Erstehn", "tokens": ["in", "ih\u00b7rem", "Stei\u00b7gen", "und", "Er\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "als Harfen, t\u00f6nende Vertr\u00f6ster,", "tokens": ["als", "Har\u00b7fen", ",", "t\u00f6\u00b7nen\u00b7de", "Ver\u00b7tr\u00f6s\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "durch die die H\u00e4nde Halberl\u00f6ster", "tokens": ["durch", "die", "die", "H\u00e4n\u00b7de", "Hal\u00b7ber\u00b7l\u00f6s\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "vor K\u00f6nigen und Jungfraun gehn.", "tokens": ["vor", "K\u00f6\u00b7ni\u00b7gen", "und", "Jung\u00b7fraun", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.159": {"line.1": {"text": "Und Gott befiehlt mir, da\u00df ich schriebe:", "tokens": ["Und", "Gott", "be\u00b7fiehlt", "mir", ",", "da\u00df", "ich", "schrie\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.160": {"line.1": {"text": "Den K\u00f6nigen sei Grausamkeit.", "tokens": ["Den", "K\u00f6\u00b7ni\u00b7gen", "sei", "Grau\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ist der Engel vor der Liebe,", "tokens": ["Sie", "ist", "der", "En\u00b7gel", "vor", "der", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und ohne diesen Bogen bliebe", "tokens": ["und", "oh\u00b7ne", "die\u00b7sen", "Bo\u00b7gen", "blie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mir keine Br\u00fccke in die Zeit.", "tokens": ["mir", "kei\u00b7ne", "Br\u00fc\u00b7cke", "in", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.161": {"line.1": {"text": "Und Gott befiehlt mir, da\u00df ich male:", "tokens": ["Und", "Gott", "be\u00b7fiehlt", "mir", ",", "da\u00df", "ich", "ma\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.162": {"line.1": {"text": "Die Zeit ist mir mein tiefstes Weh,", "tokens": ["Die", "Zeit", "ist", "mir", "mein", "tiefs\u00b7tes", "Weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so legte ich in ihre Schale:", "tokens": ["so", "leg\u00b7te", "ich", "in", "ih\u00b7re", "Scha\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "das wache Weib, die Wundenmale,", "tokens": ["das", "wa\u00b7che", "Weib", ",", "die", "Wun\u00b7den\u00b7ma\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "den reichen Tod (da\u00df er sie zahle),", "tokens": ["den", "rei\u00b7chen", "Tod", "(", "da\u00df", "er", "sie", "zah\u00b7le", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "KOUS", "PPER", "PPER", "VVFIN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der St\u00e4dte bange Bacchanale,", "tokens": ["der", "St\u00e4d\u00b7te", "ban\u00b7ge", "Bac\u00b7cha\u00b7na\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "den Wahnsinn und die K\u00f6nige.", "tokens": ["den", "Wahn\u00b7sinn", "und", "die", "K\u00f6\u00b7ni\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.163": {"line.1": {"text": "Und Gott befiehlt mir, da\u00df ich baue:", "tokens": ["Und", "Gott", "be\u00b7fiehlt", "mir", ",", "da\u00df", "ich", "bau\u00b7e", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.164": {"line.1": {"text": "Denn K\u00f6nig bin ich von der Zeit.", "tokens": ["Denn", "K\u00f6\u00b7nig", "bin", "ich", "von", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dir aber bin ich nur der graue", "tokens": ["Dir", "a\u00b7ber", "bin", "ich", "nur", "der", "grau\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mitwisser deiner Einsamkeit.", "tokens": ["Mit\u00b7wis\u00b7ser", "dei\u00b7ner", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und bin das Auge mit der Braue ...", "tokens": ["Und", "bin", "das", "Au\u00b7ge", "mit", "der", "Brau\u00b7e", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.165": {"line.1": {"text": "Das \u00fcber meine Schulter schaue", "tokens": ["Das", "\u00fc\u00b7ber", "mei\u00b7ne", "Schul\u00b7ter", "schau\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Ewigkeit zu Ewigkeit.", "tokens": ["von", "E\u00b7wig\u00b7keit", "zu", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.166": {"line.1": {"text": "Es tauchten tausend Theologen", "tokens": ["Es", "tauch\u00b7ten", "tau\u00b7send", "Theo\u00b7lo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "CARD", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "in deines Namens alte Nacht.", "tokens": ["in", "dei\u00b7nes", "Na\u00b7mens", "al\u00b7te", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jungfrauen sind zu dir erwacht,", "tokens": ["Jung\u00b7frau\u00b7en", "sind", "zu", "dir", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und J\u00fcnglinge in Silber zogen", "tokens": ["und", "J\u00fcng\u00b7lin\u00b7ge", "in", "Sil\u00b7ber", "zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "und schimmerten in dir, du Schlacht.", "tokens": ["und", "schim\u00b7mer\u00b7ten", "in", "dir", ",", "du", "Schlacht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.167": {"line.1": {"text": "In deinen langen Bogeng\u00e4ngen", "tokens": ["In", "dei\u00b7nen", "lan\u00b7gen", "Bo\u00b7gen\u00b7g\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "begegneten die Dichter sich", "tokens": ["be\u00b7ge\u00b7gne\u00b7ten", "die", "Dich\u00b7ter", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PRF"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "und waren K\u00f6nige von Kl\u00e4ngen", "tokens": ["und", "wa\u00b7ren", "K\u00f6\u00b7ni\u00b7ge", "von", "Kl\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und mild und tief und meisterlich.", "tokens": ["und", "mild", "und", "tief", "und", "meis\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.168": {"line.1": {"text": "Du bist die sanfte Abendstunde,", "tokens": ["Du", "bist", "die", "sanf\u00b7te", "A\u00b7bends\u00b7tun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die alle Dichter \u00e4hnlich macht;", "tokens": ["die", "al\u00b7le", "Dich\u00b7ter", "\u00e4hn\u00b7lich", "macht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du dr\u00e4ngst dich dunkel in die Munde,", "tokens": ["du", "dr\u00e4ngst", "dich", "dun\u00b7kel", "in", "die", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und im Gef\u00fchl von einem Funde", "tokens": ["und", "im", "Ge\u00b7f\u00fchl", "von", "ei\u00b7nem", "Fun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "umgiebt ein jeder dich mit Pracht.", "tokens": ["um\u00b7giebt", "ein", "je\u00b7der", "dich", "mit", "Pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "PIAT", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.169": {"line.1": {"text": "Dich heben hunderttausend Harfen", "tokens": ["Dich", "he\u00b7ben", "hun\u00b7dert\u00b7tau\u00b7send", "Har\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "CARD", "NN"], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "wie Schwingen aus der Schweigsamkeit.", "tokens": ["wie", "Schwin\u00b7gen", "aus", "der", "Schweig\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und deine alten Winde warfen", "tokens": ["Und", "dei\u00b7ne", "al\u00b7ten", "Win\u00b7de", "war\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zu allen Dingen und Bedarfen", "tokens": ["zu", "al\u00b7len", "Din\u00b7gen", "und", "Be\u00b7dar\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "den Hauch von deiner Herrlichkeit.", "tokens": ["den", "Hauch", "von", "dei\u00b7ner", "Herr\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.170": {"line.1": {"text": "Die Dichter haben dich verstreut", "tokens": ["Die", "Dich\u00b7ter", "ha\u00b7ben", "dich", "ver\u00b7streut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(es ging ein Sturm durch alles Stammeln),", "tokens": ["(", "es", "ging", "ein", "Sturm", "durch", "al\u00b7les", "Stam\u00b7meln", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "APPR", "PIAT", "NN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ich aber will dich wieder sammeln", "tokens": ["ich", "a\u00b7ber", "will", "dich", "wie\u00b7der", "sam\u00b7meln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in dem Gef\u00e4\u00df, das dich erfreut.", "tokens": ["in", "dem", "Ge\u00b7f\u00e4\u00df", ",", "das", "dich", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.171": {"line.1": {"text": "Ich wanderte in vielem Winde;", "tokens": ["Ich", "wan\u00b7der\u00b7te", "in", "vie\u00b7lem", "Win\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da triebst du tausendmal darin.", "tokens": ["da", "triebst", "du", "tau\u00b7send\u00b7mal", "da\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bringe alles was ich finde:", "tokens": ["Ich", "brin\u00b7ge", "al\u00b7les", "was", "ich", "fin\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als Becher brauchte dich der Blinde,", "tokens": ["als", "Be\u00b7cher", "brauch\u00b7te", "dich", "der", "Blin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "sehr tief verbarg dich das Gesinde,", "tokens": ["sehr", "tief", "ver\u00b7barg", "dich", "das", "Ge\u00b7sin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der Bettler aber hielt dich hin;", "tokens": ["der", "Bett\u00b7ler", "a\u00b7ber", "hielt", "dich", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und manchmal war bei einem Kinde", "tokens": ["und", "manch\u00b7mal", "war", "bei", "ei\u00b7nem", "Kin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ein gro\u00dfes St\u00fcck von deinem Sinn.", "tokens": ["ein", "gro\u00b7\u00dfes", "St\u00fcck", "von", "dei\u00b7nem", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.172": {"line.1": {"text": "Du siehst, da\u00df ich ein Sucher bin.", "tokens": ["Du", "siehst", ",", "da\u00df", "ich", "ein", "Su\u00b7cher", "bin", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.173": {"line.1": {"text": "Einer, der hinter seinen H\u00e4nden", "tokens": ["Ei\u00b7ner", ",", "der", "hin\u00b7ter", "sei\u00b7nen", "H\u00e4n\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "verborgen geht und wie ein Hirt;", "tokens": ["ver\u00b7bor\u00b7gen", "geht", "und", "wie", "ein", "Hirt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "(m\u00f6gst du den Blick der ihn beirrt,", "tokens": ["(", "m\u00f6gst", "du", "den", "Blick", "der", "ihn", "be\u00b7irrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "ART", "NN", "ART", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den Blick der Fremden von ihm wenden).", "tokens": ["den", "Blick", "der", "Frem\u00b7den", "von", "ihm", "wen\u00b7den", ")", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPER", "VVINF", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Einer der tr\u00e4umt, dich zu vollenden", "tokens": ["Ei\u00b7ner", "der", "tr\u00e4umt", ",", "dich", "zu", "voll\u00b7en\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "ART", "VVFIN", "$,", "PPER", "PTKZU", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "und: da\u00df er sich vollenden wird.", "tokens": ["und", ":", "da\u00df", "er", "sich", "voll\u00b7en\u00b7den", "wird", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$.", "KOUS", "PPER", "PRF", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.174": {"line.1": {"text": "Selten ist Sonne im Sob\u00f3r.", "tokens": ["Sel\u00b7ten", "ist", "Son\u00b7ne", "im", "Sob\u00f3r", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "APPRART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Die W\u00e4nde wachsen aus Gestalten,", "tokens": ["Die", "W\u00e4n\u00b7de", "wach\u00b7sen", "aus", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und durch die Jungfraun und die Alten", "tokens": ["und", "durch", "die", "Jung\u00b7fraun", "und", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dr\u00e4ngt sich, wie Fl\u00fcgel im Entfalten,", "tokens": ["dr\u00e4ngt", "sich", ",", "wie", "Fl\u00fc\u00b7gel", "im", "Ent\u00b7fal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "PWAV", "NN", "APPRART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "das goldene, das Kaiser-Tor.", "tokens": ["das", "gol\u00b7de\u00b7ne", ",", "das", "Kai\u00b7ser\u00b7Tor", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.175": {"line.1": {"text": "An seinem S\u00e4ulenrand verlor", "tokens": ["An", "sei\u00b7nem", "S\u00e4u\u00b7len\u00b7rand", "ver\u00b7lor"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die Wand sich hinter den Ikonen;", "tokens": ["die", "Wand", "sich", "hin\u00b7ter", "den", "I\u00b7ko\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und, die im stillen Silber wohnen,", "tokens": ["und", ",", "die", "im", "stil\u00b7len", "Sil\u00b7ber", "woh\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Steine, steigen wie ein Chor", "tokens": ["die", "Stei\u00b7ne", ",", "stei\u00b7gen", "wie", "ein", "Chor"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und fallen wieder in die Kronen", "tokens": ["und", "fal\u00b7len", "wie\u00b7der", "in", "die", "Kro\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und schweigen sch\u00f6ner als zuvor.", "tokens": ["und", "schwei\u00b7gen", "sch\u00f6\u00b7ner", "als", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.176": {"line.1": {"text": "Und \u00fcber sie, wie N\u00e4chte blau,", "tokens": ["Und", "\u00fc\u00b7ber", "sie", ",", "wie", "N\u00e4ch\u00b7te", "blau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "$,", "PWAV", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von Angesichte bla\u00df,", "tokens": ["von", "An\u00b7ge\u00b7sich\u00b7te", "bla\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "schwebt, die dich freuete, die Frau:", "tokens": ["schwebt", ",", "die", "dich", "freu\u00b7e\u00b7te", ",", "die", "Frau", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ART", "NN", "$."], "meter": "+--+---+", "measure": "dactylic.di.plus"}, "line.4": {"text": "die Pf\u00f6rtnerin, der Morgentau,", "tokens": ["die", "Pf\u00f6rt\u00b7ne\u00b7rin", ",", "der", "Mor\u00b7gen\u00b7tau", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "die dich umbl\u00fcht wie eine Au", "tokens": ["die", "dich", "um\u00b7bl\u00fcht", "wie", "ei\u00b7ne", "Au"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und ohne Unterla\u00df.", "tokens": ["und", "oh\u00b7ne", "Un\u00b7ter\u00b7la\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.177": {"line.1": {"text": "Die Kuppel ist voll deines Sohns", "tokens": ["Die", "Kup\u00b7pel", "ist", "voll", "dei\u00b7nes", "Sohns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und bindet rund den Bau.", "tokens": ["und", "bin\u00b7det", "rund", "den", "Bau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.178": {"line.1": {"text": "Willst du geruhen deines Throns,", "tokens": ["Willst", "du", "ge\u00b7ru\u00b7hen", "dei\u00b7nes", "Throns", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den ich in Schauern schau.", "tokens": ["den", "ich", "in", "Schau\u00b7ern", "schau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.179": {"line.1": {"text": "Da trat ich als ein Pilger ein", "tokens": ["Da", "trat", "ich", "als", "ein", "Pil\u00b7ger", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und f\u00fchlte voller Qual", "tokens": ["und", "f\u00fchl\u00b7te", "vol\u00b7ler", "Qual"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "an meiner Stirne dich, du Stein.", "tokens": ["an", "mei\u00b7ner", "Stir\u00b7ne", "dich", ",", "du", "Stein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Lichtern, sieben an der Zahl,", "tokens": ["Mit", "Lich\u00b7tern", ",", "sie\u00b7ben", "an", "der", "Zahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "CARD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "umstellte ich dein dunkles Sein", "tokens": ["um\u00b7stell\u00b7te", "ich", "dein", "dunk\u00b7les", "Sein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und sah in jedem Bilde dein", "tokens": ["und", "sah", "in", "je\u00b7dem", "Bil\u00b7de", "dein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "br\u00e4unliches Muttermal.", "tokens": ["br\u00e4un\u00b7li\u00b7ches", "Mut\u00b7ter\u00b7mal", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.180": {"line.1": {"text": "Da stand ich, wo die Bettler stehn,", "tokens": ["Da", "stand", "ich", ",", "wo", "die", "Bett\u00b7ler", "stehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die schlecht und hager sind:", "tokens": ["die", "schlecht", "und", "ha\u00b7ger", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "aus ihrem Auf- und Niederwehn", "tokens": ["aus", "ih\u00b7rem", "Auf", "und", "Nie\u00b7der\u00b7wehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "begriff ich dich, du Wind.", "tokens": ["be\u00b7griff", "ich", "dich", ",", "du", "Wind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PPER", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich sah den Bauer, \u00fcberjahrt,", "tokens": ["Ich", "sah", "den", "Bau\u00b7er", ",", "\u00fc\u00b7ber\u00b7jahrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "b\u00e4rtig wie Joachim,", "tokens": ["b\u00e4r\u00b7tig", "wie", "Joa\u00b7ch\u00b7im", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "und daraus, wie er dunkel ward,", "tokens": ["und", "da\u00b7raus", ",", "wie", "er", "dun\u00b7kel", "ward", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "von lauter \u00c4hnlichen umschart,", "tokens": ["von", "lau\u00b7ter", "\u00c4hn\u00b7li\u00b7chen", "um\u00b7schart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "empfand ich dich wie nie so zart,", "tokens": ["emp\u00b7fand", "ich", "dich", "wie", "nie", "so", "zart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "KOKOM", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "so ohne Wort geoffenbart", "tokens": ["so", "oh\u00b7ne", "Wort", "ge\u00b7of\u00b7fen\u00b7bart"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "in allen und in ihm.", "tokens": ["in", "al\u00b7len", "und", "in", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KON", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.181": {"line.1": {"text": "Du l\u00e4\u00dft der Zeit den Lauf,", "tokens": ["Du", "l\u00e4\u00dft", "der", "Zeit", "den", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "und dir ist niemals Ruh darin:", "tokens": ["und", "dir", "ist", "nie\u00b7mals", "Ruh", "da\u00b7rin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der Bauer findet deinen Sinn", "tokens": ["der", "Bau\u00b7er", "fin\u00b7det", "dei\u00b7nen", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und hebt ihn auf und wirft ihn hin", "tokens": ["und", "hebt", "ihn", "auf", "und", "wirft", "ihn", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und hebt ihn wieder auf.", "tokens": ["und", "hebt", "ihn", "wie\u00b7der", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.182": {"line.1": {"text": "Wie der W\u00e4chter in den Weingel\u00e4nden", "tokens": ["Wie", "der", "W\u00e4ch\u00b7ter", "in", "den", "Wein\u00b7ge\u00b7l\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NE", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "seine H\u00fctte hat und wacht,", "tokens": ["sei\u00b7ne", "H\u00fct\u00b7te", "hat", "und", "wacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "bin ich H\u00fctte, Herr, in deinen H\u00e4nden", "tokens": ["bin", "ich", "H\u00fct\u00b7te", ",", "Herr", ",", "in", "dei\u00b7nen", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "NN", "$,", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "und bin Nacht, o Herr, von deiner Nacht.", "tokens": ["und", "bin", "Nacht", ",", "o", "Herr", ",", "von", "dei\u00b7ner", "Nacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "$,", "FM", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.183": {"line.1": {"text": "Weinberg, Weide, alter Apfelgarten,", "tokens": ["Wein\u00b7berg", ",", "Wei\u00b7de", ",", "al\u00b7ter", "Ap\u00b7fel\u00b7gar\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Acker, der kein Fr\u00fchjahr \u00fcberschl\u00e4gt,", "tokens": ["A\u00b7cker", ",", "der", "kein", "Fr\u00fch\u00b7jahr", "\u00fc\u00b7bersc\u00b7hl\u00e4gt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Feigenbaum, der auch im marmorharten", "tokens": ["Fei\u00b7gen\u00b7baum", ",", "der", "auch", "im", "mar\u00b7mor\u00b7har\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Grunde hundert Fr\u00fcchte tr\u00e4gt:", "tokens": ["Grun\u00b7de", "hun\u00b7dert", "Fr\u00fcch\u00b7te", "tr\u00e4gt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.184": {"line.1": {"text": "Duft geht aus aus deinen runden Zweigen.", "tokens": ["Duft", "geht", "aus", "aus", "dei\u00b7nen", "run\u00b7den", "Zwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und du fragst nicht, ob ich wachsam sei;", "tokens": ["Und", "du", "fragst", "nicht", ",", "ob", "ich", "wach\u00b7sam", "sei", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "furchtlos, aufgel\u00f6st in S\u00e4ften, steigen", "tokens": ["furcht\u00b7los", ",", "auf\u00b7ge\u00b7l\u00f6st", "in", "S\u00e4f\u00b7ten", ",", "stei\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADJD", "$,", "VVFIN", "APPR", "NN", "$,", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "deine Tiefen still an mir vorbei.", "tokens": ["dei\u00b7ne", "Tie\u00b7fen", "still", "an", "mir", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.185": {"line.1": {"text": "Gott spricht zu jedem nur, eh er ihn macht,", "tokens": ["Gott", "spricht", "zu", "je\u00b7dem", "nur", ",", "eh", "er", "ihn", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PIS", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "dann geht er schweigend mit ihm aus der Nacht.", "tokens": ["dann", "geht", "er", "schwei\u00b7gend", "mit", "ihm", "aus", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aber die Worte, eh jeder beginnt,", "tokens": ["A\u00b7ber", "die", "Wor\u00b7te", ",", "eh", "je\u00b7der", "be\u00b7ginnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "diese wolkigen Worte, sind:", "tokens": ["die\u00b7se", "wol\u00b7ki\u00b7gen", "Wor\u00b7te", ",", "sind", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,", "VAFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.186": {"line.1": {"text": "Von deinen Sinnen hinausgesandt,", "tokens": ["Von", "dei\u00b7nen", "Sin\u00b7nen", "hin\u00b7aus\u00b7ge\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "geh bis an deiner Sehnsucht Rand;", "tokens": ["geh", "bis", "an", "dei\u00b7ner", "Sehn\u00b7sucht", "Rand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "gieb mir Gewand.", "tokens": ["gieb", "mir", "Ge\u00b7wand", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.187": {"line.1": {"text": "Hinter den Dingen wachse als Brand,", "tokens": ["Hin\u00b7ter", "den", "Din\u00b7gen", "wach\u00b7se", "als", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "KOUS", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "da\u00df ihre Schatten, ausgespannt,", "tokens": ["da\u00df", "ih\u00b7re", "Schat\u00b7ten", ",", "aus\u00b7ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "immer mich ganz bedecken.", "tokens": ["im\u00b7mer", "mich", "ganz", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.188": {"line.1": {"text": "La\u00df dir Alles geschehn: Sch\u00f6nheit und Schrecken.", "tokens": ["La\u00df", "dir", "Al\u00b7les", "ge\u00b7schehn", ":", "Sch\u00f6n\u00b7heit", "und", "Schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PIS", "VVPP", "$.", "NN", "KON", "NN", "$."], "meter": "+-+---+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Man mu\u00df nur gehn: Kein Gef\u00fchl ist das fernste.", "tokens": ["Man", "mu\u00df", "nur", "gehn", ":", "Kein", "Ge\u00b7f\u00fchl", "ist", "das", "ferns\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "VVINF", "$.", "PIAT", "NN", "VAFIN", "ART", "ADJA", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "La\u00df dich von mir nicht trennen.", "tokens": ["La\u00df", "dich", "von", "mir", "nicht", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nah ist das Land,", "tokens": ["Nah", "ist", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "das sie das Leben nennen.", "tokens": ["das", "sie", "das", "Le\u00b7ben", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.189": {"line.1": {"text": "Du wirst es erkennen", "tokens": ["Du", "wirst", "es", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "an seinem Ernste.", "tokens": ["an", "sei\u00b7nem", "Erns\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.190": {"line.1": {"text": "Gieb mir die Hand.", "tokens": ["Gieb", "mir", "die", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.191": {"line.1": {"text": "Ich war bei den \u00e4ltesten M\u00f6nchen, den Malern und Mythenmeldern,", "tokens": ["Ich", "war", "bei", "den", "\u00e4l\u00b7tes\u00b7ten", "M\u00f6n\u00b7chen", ",", "den", "Ma\u00b7lern", "und", "My\u00b7then\u00b7mel\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+--+-+-", "measure": "amphibrach.penta.plus"}, "line.2": {"text": "die schrieben ruhig Geschichten und zeichneten Runen des Ruhms.", "tokens": ["die", "schrie\u00b7ben", "ru\u00b7hig", "Ge\u00b7schich\u00b7ten", "und", "zeich\u00b7ne\u00b7ten", "Ru\u00b7nen", "des", "Ruhms", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "NN", "KON", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und ich seh dich in meinen Gesichten mit Winden, Wassern und W\u00e4ldern", "tokens": ["Und", "ich", "seh", "dich", "in", "mei\u00b7nen", "Ge\u00b7sich\u00b7ten", "mit", "Win\u00b7den", ",", "Was\u00b7sern", "und", "W\u00e4l\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "rauschend am Rande des Christentums,", "tokens": ["rau\u00b7schend", "am", "Ran\u00b7de", "des", "Chris\u00b7ten\u00b7tums", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "du Land, nicht zu lichten.", "tokens": ["du", "Land", ",", "nicht", "zu", "lich\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.192": {"line.1": {"text": "Ich will dich erz\u00e4hlen, ich will dich beschaun und beschreiben,", "tokens": ["Ich", "will", "dich", "er\u00b7z\u00e4h\u00b7len", ",", "ich", "will", "dich", "be\u00b7schaun", "und", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "$,", "PPER", "VMFIN", "PRF", "VVINF", "KON", "VVPP", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "nicht mit Bol und mit Gold, nur mit Tinte aus Apfelbaumrinden;", "tokens": ["nicht", "mit", "Bol", "und", "mit", "Gold", ",", "nur", "mit", "Tin\u00b7te", "aus", "Ap\u00b7fel\u00b7baum\u00b7rin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NE", "KON", "APPR", "NN", "$,", "ADV", "APPR", "NN", "APPR", "NN", "$."], "meter": "+-+--+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "ich kann auch mit Perlen dich nicht an die Bl\u00e4tter binden,", "tokens": ["ich", "kann", "auch", "mit", "Per\u00b7len", "dich", "nicht", "an", "die", "Bl\u00e4t\u00b7ter", "bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "PPER", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "und das zitterndste Bild, das mir meine Sinne erfinden,", "tokens": ["und", "das", "zit\u00b7ternds\u00b7te", "Bild", ",", "das", "mir", "mei\u00b7ne", "Sin\u00b7ne", "er\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.5": {"text": "du w\u00fcrdest es blind durch dein einfaches Sein \u00fcbertreiben.", "tokens": ["du", "w\u00fcr\u00b7dest", "es", "blind", "durch", "dein", "ein\u00b7fa\u00b7ches", "Sein", "\u00fc\u00b7bert\u00b7rei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.193": {"line.1": {"text": "So will ich die Dinge in dir nur bescheiden und schlichthin benamen,", "tokens": ["So", "will", "ich", "die", "Din\u00b7ge", "in", "dir", "nur", "be\u00b7schei\u00b7den", "und", "schlicht\u00b7hin", "be\u00b7na\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "APPR", "PPER", "ADV", "ADJD", "KON", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "will die K\u00f6nige nennen, die \u00e4ltesten, woher sie kamen,", "tokens": ["will", "die", "K\u00f6\u00b7ni\u00b7ge", "nen\u00b7nen", ",", "die", "\u00e4l\u00b7tes\u00b7ten", ",", "wo\u00b7her", "sie", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVINF", "$,", "ART", "ADJA", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-----+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "und will ihre Taten und Schlachten berichten am Rand meiner Seiten.", "tokens": ["und", "will", "ih\u00b7re", "Ta\u00b7ten", "und", "Schlach\u00b7ten", "be\u00b7rich\u00b7ten", "am", "Rand", "mei\u00b7ner", "Sei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "KON", "NN", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.4": {"text": "Denn du bist der Boden. Dir sind nur wie Sommer die Zeiten,", "tokens": ["Denn", "du", "bist", "der", "Bo\u00b7den", ".", "Dir", "sind", "nur", "wie", "Som\u00b7mer", "die", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ART", "NN", "$.", "PPER", "VAFIN", "ADV", "KOKOM", "NN", "ART", "NN", "$,"], "meter": "--+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "und du denkst an die nahen nicht anders als an die entfernten,", "tokens": ["und", "du", "denkst", "an", "die", "na\u00b7hen", "nicht", "an\u00b7ders", "als", "an", "die", "ent\u00b7fern\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "ADJA", "PTKNEG", "ADV", "KOKOM", "APPR", "ART", "ADJA", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "und ob sie dich tiefer besamen und besser bebauen lernten:", "tokens": ["und", "ob", "sie", "dich", "tie\u00b7fer", "be\u00b7sa\u00b7men", "und", "bes\u00b7ser", "be\u00b7bau\u00b7en", "lern\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADJD", "VVPP", "KON", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+--+--+--+--+-+-", "measure": "amphibrach.penta.plus"}, "line.7": {"text": "du f\u00fchlst dich nur leise ber\u00fchrt von den \u00e4hnlichen Ernten", "tokens": ["du", "f\u00fchlst", "dich", "nur", "lei\u00b7se", "be\u00b7r\u00fchrt", "von", "den", "\u00e4hn\u00b7li\u00b7chen", "Ern\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.8": {"text": "und h\u00f6rst weder S\u00e4er noch Schnitter, die \u00fcber dich schreiten.", "tokens": ["und", "h\u00f6rst", "we\u00b7der", "S\u00e4\u00b7er", "noch", "Schnit\u00b7ter", ",", "die", "\u00fc\u00b7ber", "dich", "schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "NN", "ADV", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}}, "stanza.194": {"line.1": {"text": "Du dunkelnder Grund, geduldig ertr\u00e4gst du die Mauern.", "tokens": ["Du", "dun\u00b7keln\u00b7der", "Grund", ",", "ge\u00b7dul\u00b7dig", "er\u00b7tr\u00e4gst", "du", "die", "Mau\u00b7ern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und vielleicht erlaubst du noch eine Stunde den St\u00e4dten zu dauern", "tokens": ["Und", "viel\u00b7leicht", "er\u00b7laubst", "du", "noch", "ei\u00b7ne", "Stun\u00b7de", "den", "St\u00e4d\u00b7ten", "zu", "dau\u00b7ern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+--+-++-+--+--+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "und gew\u00e4hrst noch zwei Stunden den Kirchen und einsamen Kl\u00f6stern", "tokens": ["und", "ge\u00b7w\u00e4hrst", "noch", "zwei", "Stun\u00b7den", "den", "Kir\u00b7chen", "und", "ein\u00b7sa\u00b7men", "Kl\u00f6s\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "CARD", "NN", "ART", "NN", "KON", "ADJA", "NN"], "meter": "--+--+--+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "und l\u00e4ssest f\u00fcnf Stunden noch M\u00fchsal allen Erl\u00f6stern", "tokens": ["und", "l\u00e4s\u00b7sest", "f\u00fcnf", "Stun\u00b7den", "noch", "M\u00fch\u00b7sal", "al\u00b7len", "Er\u00b7l\u00f6s\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "CARD", "NN", "ADV", "NN", "PIAT", "NN"], "meter": "-+--+--+-+--+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "und siehst noch sieben Stunden das Tagwerk des Bauern \u2013:", "tokens": ["und", "siehst", "noch", "sie\u00b7ben", "Stun\u00b7den", "das", "Tag\u00b7werk", "des", "Bau\u00b7ern", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "CARD", "NN", "ART", "NN", "ART", "NN", "$(", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.195": {"line.1": {"text": "Eh du wieder Wald wirst und Wasser und wachsende Wildnis", "tokens": ["Eh", "du", "wie\u00b7der", "Wald", "wirst", "und", "Was\u00b7ser", "und", "wach\u00b7sen\u00b7de", "Wild\u00b7nis"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.2": {"text": "in der Stunde der unerfa\u00dflichen Angst,", "tokens": ["in", "der", "Stun\u00b7de", "der", "un\u00b7er\u00b7fa\u00df\u00b7li\u00b7chen", "Angst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "da du dein unvollendetes Bildnis", "tokens": ["da", "du", "dein", "un\u00b7voll\u00b7en\u00b7de\u00b7tes", "Bild\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "von allen Dingen zur\u00fcckverlangst.", "tokens": ["von", "al\u00b7len", "Din\u00b7gen", "zu\u00b7r\u00fcck\u00b7ver\u00b7langst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.196": {"line.1": {"text": "Gieb mir noch eine kleine Weile Zeit: ich will die Dinge so wie keiner lieben", "tokens": ["Gieb", "mir", "noch", "ei\u00b7ne", "klei\u00b7ne", "Wei\u00b7le", "Zeit", ":", "ich", "will", "die", "Din\u00b7ge", "so", "wie", "kei\u00b7ner", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "ART", "ADJA", "NN", "NN", "$.", "PPER", "VMFIN", "ART", "NN", "ADV", "KOKOM", "PIS", "VVINF"], "meter": "-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "bis sie dir alle w\u00fcrdig sind und weit.", "tokens": ["bis", "sie", "dir", "al\u00b7le", "w\u00fcr\u00b7dig", "sind", "und", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PIS", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich will nur sieben Tage, sieben", "tokens": ["Ich", "will", "nur", "sie\u00b7ben", "Ta\u00b7ge", ",", "sie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VMFIN", "ADV", "CARD", "NN", "$,", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "auf die sich keiner noch geschrieben,", "tokens": ["auf", "die", "sich", "kei\u00b7ner", "noch", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "sieben Seiten Einsamkeit.", "tokens": ["sie\u00b7ben", "Sei\u00b7ten", "Ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.197": {"line.1": {"text": "Wem du das Buch giebst, welches die umfa\u00dft,", "tokens": ["Wem", "du", "das", "Buch", "giebst", ",", "wel\u00b7ches", "die", "um\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVFIN", "$,", "PRELS", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der wird geb\u00fcckt \u00fcber den Bl\u00e4ttern bleiben.", "tokens": ["der", "wird", "ge\u00b7b\u00fcckt", "\u00fc\u00b7ber", "den", "Bl\u00e4t\u00b7tern", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "VVPP", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Es sei denn, da\u00df du ihn in H\u00e4nden hast,", "tokens": ["Es", "sei", "denn", ",", "da\u00df", "du", "ihn", "in", "H\u00e4n\u00b7den", "hast", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "um selbst zu schreiben.", "tokens": ["um", "selbst", "zu", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.198": {"line.1": {"text": "So bin ich nur als Kind erwacht,", "tokens": ["So", "bin", "ich", "nur", "als", "Kind", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "KOUS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "so sicher im Vertraun", "tokens": ["so", "si\u00b7cher", "im", "Ver\u00b7traun"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "nach jeder Angst und jeder Nacht", "tokens": ["nach", "je\u00b7der", "Angst", "und", "je\u00b7der", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dich wieder anzuschaun.", "tokens": ["dich", "wie\u00b7der", "an\u00b7zu\u00b7schaun", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich wei\u00df, sooft mein Denken mi\u00dft,", "tokens": ["Ich", "wei\u00df", ",", "sooft", "mein", "Den\u00b7ken", "mi\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "wie tief, wie lang, wie weit \u2013 :", "tokens": ["wie", "tief", ",", "wie", "lang", ",", "wie", "weit", "\u2013", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "du aber bist und bist und bist,", "tokens": ["du", "a\u00b7ber", "bist", "und", "bist", "und", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "KON", "VAFIN", "KON", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "umzittert von der Zeit.", "tokens": ["um\u00b7zit\u00b7tert", "von", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.199": {"line.1": {"text": "Mir ist, als w\u00e4r ich jetzt zugleich", "tokens": ["Mir", "ist", ",", "als", "w\u00e4r", "ich", "jetzt", "zu\u00b7gleich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kind, Knab und Mann und mehr.", "tokens": ["Kind", ",", "Knab", "und", "Mann", "und", "mehr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "KON", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich f\u00fchle: nur der Ring ist reich", "tokens": ["Ich", "f\u00fch\u00b7le", ":", "nur", "der", "Ring", "ist", "reich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "durch seine Wiederkehr.", "tokens": ["durch", "sei\u00b7ne", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.200": {"line.1": {"text": "Ich danke dir, du tiefe Kraft,", "tokens": ["Ich", "dan\u00b7ke", "dir", ",", "du", "tie\u00b7fe", "Kraft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "die immer leiser mit mir schafft", "tokens": ["die", "im\u00b7mer", "lei\u00b7ser", "mit", "mir", "schafft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "wie hinter vielen W\u00e4nden;", "tokens": ["wie", "hin\u00b7ter", "vie\u00b7len", "W\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "jetzt ward mir erst der Werktag schlicht", "tokens": ["jetzt", "ward", "mir", "erst", "der", "Werk\u00b7tag", "schlicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und wie ein heiliges Gesicht", "tokens": ["und", "wie", "ein", "hei\u00b7li\u00b7ges", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu meinen dunklen H\u00e4nden.", "tokens": ["zu", "mei\u00b7nen", "dunk\u00b7len", "H\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.201": {"line.1": {"text": "Da\u00df ich nicht war vor einer Weile,", "tokens": ["Da\u00df", "ich", "nicht", "war", "vor", "ei\u00b7ner", "Wei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wei\u00dft du davon? Und du sagst nein.", "tokens": ["wei\u00dft", "du", "da\u00b7von", "?", "Und", "du", "sagst", "nein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "$.", "KON", "PPER", "VVFIN", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da f\u00fchl ich, wenn ich nur nicht eile,", "tokens": ["Da", "f\u00fchl", "ich", ",", "wenn", "ich", "nur", "nicht", "ei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so kann ich nie vergangen sein.", "tokens": ["so", "kann", "ich", "nie", "ver\u00b7gan\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.202": {"line.1": {"text": "Ich bin ja mehr als Traum im Traume.", "tokens": ["Ich", "bin", "ja", "mehr", "als", "Traum", "im", "Trau\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KOUS", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nur was sich sehnt nach einem Saume,", "tokens": ["Nur", "was", "sich", "sehnt", "nach", "ei\u00b7nem", "Sau\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PRELS", "PRF", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ist wie ein Tag und wie ein Ton;", "tokens": ["ist", "wie", "ein", "Tag", "und", "wie", "ein", "Ton", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "NN", "KON", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "es dr\u00e4ngt sich fremd durch deine H\u00e4nde,", "tokens": ["es", "dr\u00e4ngt", "sich", "fremd", "durch", "dei\u00b7ne", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df es die viele Freiheit f\u00e4nde,", "tokens": ["da\u00df", "es", "die", "vie\u00b7le", "Frei\u00b7heit", "f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und traurig lassen sie davon.", "tokens": ["und", "trau\u00b7rig", "las\u00b7sen", "sie", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.203": {"line.1": {"text": "So blieb das Dunkel dir allein,", "tokens": ["So", "blieb", "das", "Dun\u00b7kel", "dir", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und, wachsend in die leere Lichte,", "tokens": ["und", ",", "wach\u00b7send", "in", "die", "lee\u00b7re", "Lich\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "erhob sich eine Weltgeschichte", "tokens": ["er\u00b7hob", "sich", "ei\u00b7ne", "Welt\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "aus immer blinderem Gestein.", "tokens": ["aus", "im\u00b7mer", "blin\u00b7de\u00b7rem", "Ge\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Massen wollen wieder Massen,", "tokens": ["Die", "Mas\u00b7sen", "wol\u00b7len", "wie\u00b7der", "Mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "die Steine sind wie losgelassen", "tokens": ["die", "Stei\u00b7ne", "sind", "wie", "los\u00b7ge\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.204": {"line.1": {"text": "und keiner ist von dir behauen.", "tokens": ["und", "kei\u00b7ner", "ist", "von", "dir", "be\u00b7hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.205": {"line.1": {"text": "Es l\u00e4rmt das Licht im Wipfel deines Baumes", "tokens": ["Es", "l\u00e4rmt", "das", "Licht", "im", "Wip\u00b7fel", "dei\u00b7nes", "Bau\u00b7mes"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und macht dir alle Dinge bunt und eitel,", "tokens": ["und", "macht", "dir", "al\u00b7le", "Din\u00b7ge", "bunt", "und", "ei\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sie finden dich erst wenn der Tag verglomm.", "tokens": ["sie", "fin\u00b7den", "dich", "erst", "wenn", "der", "Tag", "ver\u00b7glomm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die D\u00e4mmerung, die Z\u00e4rtlichkeit des Raumes,", "tokens": ["Die", "D\u00e4m\u00b7me\u00b7rung", ",", "die", "Z\u00e4rt\u00b7lich\u00b7keit", "des", "Rau\u00b7mes", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "legt tausend H\u00e4nde \u00fcber tausend Scheitel,", "tokens": ["legt", "tau\u00b7send", "H\u00e4n\u00b7de", "\u00fc\u00b7ber", "tau\u00b7send", "Schei\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "CARD", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und unter ihnen wird das Fremde fromm.", "tokens": ["und", "un\u00b7ter", "ih\u00b7nen", "wird", "das", "Frem\u00b7de", "fromm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.206": {"line.1": {"text": "Du willst die Welt nicht anders an dich halten", "tokens": ["Du", "willst", "die", "Welt", "nicht", "an\u00b7ders", "an", "dich", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "ADV", "APPR", "PRF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "als so, mit dieser sanftesten Geb\u00e4rde.", "tokens": ["als", "so", ",", "mit", "die\u00b7ser", "sanf\u00b7tes\u00b7ten", "Ge\u00b7b\u00e4r\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Aus ihren Himmeln greifst du dir die Erde", "tokens": ["Aus", "ih\u00b7ren", "Him\u00b7meln", "greifst", "du", "dir", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und f\u00fchlst sie unter deines Mantels Falten.", "tokens": ["und", "f\u00fchlst", "sie", "un\u00b7ter", "dei\u00b7nes", "Man\u00b7tels", "Fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.207": {"line.1": {"text": "Du hast so eine leise Art zu sein.", "tokens": ["Du", "hast", "so", "ei\u00b7ne", "lei\u00b7se", "Art", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und jene, die dir laute Namen weihn,", "tokens": ["Und", "je\u00b7ne", ",", "die", "dir", "lau\u00b7te", "Na\u00b7men", "weihn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "PPER", "VVFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sind schon vergessen deiner Nachbarschaft.", "tokens": ["sind", "schon", "ver\u00b7ges\u00b7sen", "dei\u00b7ner", "Nach\u00b7bar\u00b7schaft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.208": {"line.1": {"text": "Von deinen H\u00e4nden, die sich bergig heben,", "tokens": ["Von", "dei\u00b7nen", "H\u00e4n\u00b7den", ",", "die", "sich", "ber\u00b7gig", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "steigt, unsern Sinnen das Gesetz zu geben,", "tokens": ["steigt", ",", "un\u00b7sern", "Sin\u00b7nen", "das", "Ge\u00b7setz", "zu", "ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mit dunkler Stirne deine stumme Kraft.", "tokens": ["mit", "dunk\u00b7ler", "Stir\u00b7ne", "dei\u00b7ne", "stum\u00b7me", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.209": {"line.1": {"text": "Du Williger, und deine Gnade kam", "tokens": ["Du", "Wil\u00b7li\u00b7ger", ",", "und", "dei\u00b7ne", "Gna\u00b7de", "kam"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "immer in alle \u00e4ltesten Geb\u00e4rden.", "tokens": ["im\u00b7mer", "in", "al\u00b7le", "\u00e4l\u00b7tes\u00b7ten", "Ge\u00b7b\u00e4r\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wenn einer die H\u00e4nde zusammenflicht,", "tokens": ["Wenn", "ei\u00b7ner", "die", "H\u00e4n\u00b7de", "zu\u00b7sam\u00b7men\u00b7flicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "so da\u00df sie zahm", "tokens": ["so", "da\u00df", "sie", "zahm"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "und um ein kleines Dunkel sind \u2013:", "tokens": ["und", "um", "ein", "klei\u00b7nes", "Dun\u00b7kel", "sind", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VAFIN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "auf einmal f\u00fchlt er dich in ihnen werden,", "tokens": ["auf", "ein\u00b7mal", "f\u00fchlt", "er", "dich", "in", "ih\u00b7nen", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PRF", "APPR", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und wie im Winde", "tokens": ["und", "wie", "im", "Win\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOKOM", "APPRART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "senkt sich sein Gesicht", "tokens": ["senkt", "sich", "sein", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PPOSAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "in Scham.", "tokens": ["in", "Scham", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.10": {"text": "Und da versucht er, auf dem Stein zu liegen", "tokens": ["Und", "da", "ver\u00b7sucht", "er", ",", "auf", "dem", "Stein", "zu", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und aufzustehn, wie er bei andern sieht,", "tokens": ["und", "auf\u00b7zu\u00b7stehn", ",", "wie", "er", "bei", "an\u00b7dern", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "PWAV", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "und seine M\u00fche ist, dich einzuwiegen,", "tokens": ["und", "sei\u00b7ne", "M\u00fc\u00b7he", "ist", ",", "dich", "ein\u00b7zu\u00b7wie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "$,", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "aus Angst, da\u00df er dein Wachsein schon verriet.", "tokens": ["aus", "Angst", ",", "da\u00df", "er", "dein", "Wach\u00b7sein", "schon", "ver\u00b7riet", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.210": {"line.1": {"text": "Denn wer dich f\u00fchlt, kann sich mit dir nicht br\u00fcsten;", "tokens": ["Denn", "wer", "dich", "f\u00fchlt", ",", "kann", "sich", "mit", "dir", "nicht", "br\u00fcs\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VMFIN", "PRF", "APPR", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "er ist erschrocken, bang um dich und flieht", "tokens": ["er", "ist", "er\u00b7schro\u00b7cken", ",", "bang", "um", "dich", "und", "flieht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "ADJD", "APPR", "PPER", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "vor allen Fremden, die dich merken m\u00fc\u00dften:", "tokens": ["vor", "al\u00b7len", "Frem\u00b7den", ",", "die", "dich", "mer\u00b7ken", "m\u00fc\u00df\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.211": {"line.1": {"text": "Du bist das Wunder in den W\u00fcsten,", "tokens": ["Du", "bist", "das", "Wun\u00b7der", "in", "den", "W\u00fcs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das Ausgewanderten geschieht.", "tokens": ["das", "Aus\u00b7ge\u00b7wan\u00b7der\u00b7ten", "ge\u00b7schieht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}}, "stanza.212": {"line.1": {"text": "Eine Stunde vom Rande des Tages,", "tokens": ["Ei\u00b7ne", "Stun\u00b7de", "vom", "Ran\u00b7de", "des", "Ta\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "und das Land ist zu allem bereit.", "tokens": ["und", "das", "Land", "ist", "zu", "al\u00b7lem", "be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "PIS", "ADJD", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Was du sehnst, meine Seele, sag es:", "tokens": ["Was", "du", "sehnst", ",", "mei\u00b7ne", "See\u00b7le", ",", "sag", "es", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.213": {"line.1": {"text": "Sei Heide und, Heide, sei weit.", "tokens": ["Sei", "Hei\u00b7de", "und", ",", "Hei\u00b7de", ",", "sei", "weit", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NE", "KON", "$,", "NE", "$,", "VAFIN", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Habe alte, alte Kurgane,", "tokens": ["Ha\u00b7be", "al\u00b7te", ",", "al\u00b7te", "Kur\u00b7ga\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "wachsend und kaumerkannt,", "tokens": ["wach\u00b7send", "und", "kau\u00b7mer\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "wenn es Mond wird \u00fcber das plane", "tokens": ["wenn", "es", "Mond", "wird", "\u00fc\u00b7ber", "das", "pla\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "VAFIN", "APPR", "ART", "ADJA"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "langvergangene Land.", "tokens": ["lang\u00b7ver\u00b7gan\u00b7ge\u00b7ne", "Land", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Gestalte dich, Stille. Gestalte", "tokens": ["Ge\u00b7stal\u00b7te", "dich", ",", "Stil\u00b7le", ".", "Ge\u00b7stal\u00b7te"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "$,", "NN", "$.", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "die Dinge (es ist ihre Kindheit,", "tokens": ["die", "Din\u00b7ge", "(", "es", "ist", "ih\u00b7re", "Kind\u00b7heit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PPER", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "sie werden dir willig sein).", "tokens": ["sie", "wer\u00b7den", "dir", "wil\u00b7lig", "sein", ")", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VAINF", "$(", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Sei Heide, sei Heide, sei Heide,", "tokens": ["Sei", "Hei\u00b7de", ",", "sei", "Hei\u00b7de", ",", "sei", "Hei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NE", "$,", "VAFIN", "NE", "$,", "VAFIN", "NE", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.10": {"text": "dann kommt vielleicht auch der Alte,", "tokens": ["dann", "kommt", "viel\u00b7leicht", "auch", "der", "Al\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "den ich kaum von der Nacht unterscheide,", "tokens": ["den", "ich", "kaum", "von", "der", "Nacht", "un\u00b7ter\u00b7schei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--++-+-", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "und bringt seine riesige Blindheit", "tokens": ["und", "bringt", "sei\u00b7ne", "rie\u00b7si\u00b7ge", "Blind\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "in mein horchendes Haus herein.", "tokens": ["in", "mein", "hor\u00b7chen\u00b7des", "Haus", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.214": {"line.1": {"text": "Ich seh ihn sitzen und sinnen,", "tokens": ["Ich", "seh", "ihn", "sit\u00b7zen", "und", "sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "nicht \u00fcber mich hinaus;", "tokens": ["nicht", "\u00fc\u00b7ber", "mich", "hin\u00b7aus", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "f\u00fcr ihn ist alles innen,", "tokens": ["f\u00fcr", "ihn", "ist", "al\u00b7les", "in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Himmel und Heide und Haus.", "tokens": ["Him\u00b7mel", "und", "Hei\u00b7de", "und", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "KON", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "Nur die Lieder sind ihm verloren,", "tokens": ["Nur", "die", "Lie\u00b7der", "sind", "ihm", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "die er nie mehr beginnt;", "tokens": ["die", "er", "nie", "mehr", "be\u00b7ginnt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "aus vielen tausend Ohren", "tokens": ["aus", "vie\u00b7len", "tau\u00b7send", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "trank sie die Zeit und der Wind;", "tokens": ["trank", "sie", "die", "Zeit", "und", "der", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.9": {"text": "aus den Ohren der Toren.", "tokens": ["aus", "den", "Oh\u00b7ren", "der", "To\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.215": {"line.1": {"text": "Und dennoch: mir geschieht,", "tokens": ["Und", "den\u00b7noch", ":", "mir", "ge\u00b7schieht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "als ob ich ein jedes Lied", "tokens": ["als", "ob", "ich", "ein", "je\u00b7des", "Lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "PPER", "ART", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "tief in mir ihm ersparte.", "tokens": ["tief", "in", "mir", "ihm", "er\u00b7spar\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "PPER", "VVFIN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.216": {"line.1": {"text": "Er schweigt hinterm bebenden Barte,", "tokens": ["Er", "schweigt", "hin\u00b7term", "be\u00b7ben\u00b7den", "Bar\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "er m\u00f6chte sich wiedergewinnen", "tokens": ["er", "m\u00f6ch\u00b7te", "sich", "wie\u00b7der\u00b7ge\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "aus seinen Melodien.", "tokens": ["aus", "sei\u00b7nen", "Me\u00b7lo\u00b7dien", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da komm ich zu seinen Knien:", "tokens": ["Da", "komm", "ich", "zu", "sei\u00b7nen", "Kni\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.217": {"line.1": {"text": "und seine Lieder rinnen", "tokens": ["und", "sei\u00b7ne", "Lie\u00b7der", "rin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "rauschend zur\u00fcck in ihn.", "tokens": ["rau\u00b7schend", "zu\u00b7r\u00fcck", "in", "ihn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "APPR", "PPER", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}}}}