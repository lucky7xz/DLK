{"textgrid.poem.57803": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Frei bin ich, ich bin vogelfrei,", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Frei bin ich, ich bin vogelfrei,", "tokens": ["Frei", "bin", "ich", ",", "ich", "bin", "vo\u00b7gel\u00b7frei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vi va und vogelfrei, ja vogelfrei,", "tokens": ["Vi", "va", "und", "vo\u00b7gel\u00b7frei", ",", "ja", "vo\u00b7gel\u00b7frei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und alles ist mir einerlei,", "tokens": ["Und", "al\u00b7les", "ist", "mir", "ei\u00b7ner\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "I, a und einerlei, ja einerlei;", "tokens": ["I", ",", "a", "und", "ei\u00b7ner\u00b7lei", ",", "ja", "ei\u00b7ner\u00b7lei", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["XY", "$,", "NE", "KON", "PIS", "$,", "ADV", "PIS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich lache, wenn die Sonne scheint", "tokens": ["Ich", "la\u00b7che", ",", "wenn", "die", "Son\u00b7ne", "scheint"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und lache, wenn sie's anders meint,", "tokens": ["Und", "la\u00b7che", ",", "wenn", "sie's", "an\u00b7ders", "meint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und denk mir nichts dabei.", "tokens": ["Und", "denk", "mir", "nichts", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich liebte einst ein M\u00e4gdelein,", "tokens": ["Ich", "lieb\u00b7te", "einst", "ein", "M\u00e4g\u00b7del\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mi, ma und M\u00e4gdelein, ja M\u00e4gdelein,", "tokens": ["Mi", ",", "ma", "und", "M\u00e4g\u00b7del\u00b7ein", ",", "ja", "M\u00e4g\u00b7del\u00b7ein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sprach, ich sollte bei ihr sein,", "tokens": ["Sie", "sprach", ",", "ich", "soll\u00b7te", "bei", "ihr", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "APPR", "PPOSAT", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bi, ba und bei ihr sein, ja bei ihr sein;", "tokens": ["Bi", ",", "ba", "und", "bei", "ihr", "sein", ",", "ja", "bei", "ihr", "sein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "APPR", "PPOSAT", "VAINF", "$,", "ADV", "APPR", "PPOSAT", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch als ich kam beim Sternenlicht,", "tokens": ["Doch", "als", "ich", "kam", "beim", "Ster\u00b7nen\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da hatte sie ihr Fenster dicht,", "tokens": ["Da", "hat\u00b7te", "sie", "ihr", "Fens\u00b7ter", "dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und lie\u00df mich nicht hinein.", "tokens": ["Und", "lie\u00df", "mich", "nicht", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und ist's die Bauerntochter nicht,", "tokens": ["Und", "ist's", "die", "Bau\u00b7ern\u00b7toch\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ti, ta und Tochter nicht, ja Tochter nicht,", "tokens": ["Ti", ",", "ta", "und", "Toch\u00b7ter", "nicht", ",", "ja", "Toch\u00b7ter", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "FM", "KON", "NN", "PTKNEG", "$,", "ADV", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Magd hat auch ein frisch Gesicht,", "tokens": ["Die", "Magd", "hat", "auch", "ein", "frisch", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fri, fra und frisch Gesicht, ja frisch Gesicht;", "tokens": ["Fri", ",", "fra", "und", "frisch", "Ge\u00b7sicht", ",", "ja", "frisch", "Ge\u00b7sicht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "ADJD", "NN", "$,", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und schlaf ich nicht im Federbett,", "tokens": ["Und", "schlaf", "ich", "nicht", "im", "Fe\u00b7der\u00b7bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf Stroh, da liebt sich's auch ganz nett,", "tokens": ["Auf", "Stroh", ",", "da", "liebt", "sich's", "auch", "ganz", "nett", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "VVFIN", "PIS", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das schad't mir weiter nicht.", "tokens": ["Das", "schad't", "mir", "wei\u00b7ter", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}