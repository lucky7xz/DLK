{"dta.poem.11379": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Als Herr J. P.  Artop\u0153us an. 1706 d. 20 Jan.  \n zu Halle  Medic. Doct.  wurde.  \n E. G.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr! die ihr, von dem wahn des p\u00f6bels eingenommen,", "tokens": ["Ihr", "!", "die", "ihr", ",", "von", "dem", "wahn", "des", "p\u00f6\u00b7bels", "ein\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "PRELS", "PPER", "$,", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das werck der medicin als gauckel-possen schm\u00e4ht,", "tokens": ["Das", "werck", "der", "me\u00b7di\u00b7cin", "als", "gau\u00b7ckel\u00b7pos\u00b7sen", "schm\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr habt vorl\u00e4ngsten zwar schon euren text bekommen;", "tokens": ["Ihr", "habt", "vor\u00b7l\u00e4ngs\u00b7ten", "zwar", "schon", "eu\u00b7ren", "text", "be\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedoch, weil ihr noch offt durch staar und h\u00fclsen seht,", "tokens": ["Je\u00b7doch", ",", "weil", "ihr", "noch", "offt", "durch", "staar", "und", "h\u00fcl\u00b7sen", "seht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So will die poesie ohn alles kopff-zerbrechen,", "tokens": ["So", "will", "die", "po\u00b7e\u00b7sie", "ohn", "al\u00b7les", "kopf\u00b7fzer\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Aus lieb euch noch einmahl das fell von augen stechen.", "tokens": ["Aus", "lieb", "euch", "noch", "ein\u00b7mahl", "das", "fell", "von", "au\u00b7gen", "ste\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "PPER", "ADV", "ADV", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gef\u00e4llt euch dieses nicht, so reist es selbst entzwey,", "tokens": ["Ge\u00b7f\u00e4llt", "euch", "die\u00b7ses", "nicht", ",", "so", "reist", "es", "selbst", "ent\u00b7zwey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und sprecht die medicin von eurem schimpffen frey.", "tokens": ["Und", "sprecht", "die", "me\u00b7di\u00b7cin", "von", "eu\u00b7rem", "schimpf\u00b7fen", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der ehrgeitz darff sie nicht zum werck der g\u00f6tter machen?", "tokens": ["Der", "ehr\u00b7geitz", "darff", "sie", "nicht", "zum", "werck", "der", "g\u00f6t\u00b7ter", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "APPRART", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie braucht zu ihrem ruhm nicht abgeschmackten wahn;", "tokens": ["Sie", "braucht", "zu", "ih\u00b7rem", "ruhm", "nicht", "ab\u00b7ge\u00b7schmack\u00b7ten", "wahn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie pfleget selbst den schwarm der alten zu verlachen,", "tokens": ["Sie", "pfle\u00b7get", "selbst", "den", "schwarm", "der", "al\u00b7ten", "zu", "ver\u00b7la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJD", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und liebet einen schlu\u00df, den man beweisen kan.", "tokens": ["Und", "lie\u00b7bet", "ei\u00b7nen", "schlu\u00df", ",", "den", "man", "be\u00b7wei\u00b7sen", "kan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die thiere haben sie vielleicht zuerst getrieben;", "tokens": ["Die", "thie\u00b7re", "ha\u00b7ben", "sie", "viel\u00b7leicht", "zu\u00b7erst", "ge\u00b7trie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein was diesen GOtt in die natur geschrieben,", "tokens": ["Al\u00b7lein", "was", "die\u00b7sen", "Gott", "in", "die", "na\u00b7tur", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PDAT", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das kommt, und wenn es euch auch noch so seltsam w\u00e4r,", "tokens": ["Das", "kommt", ",", "und", "wenn", "es", "euch", "auch", "noch", "so", "selt\u00b7sam", "w\u00e4r", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KON", "KOUS", "PPER", "PPER", "ADV", "ADV", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Aus keinem andern rath, als GOttes wei\u00dfheit, her.", "tokens": ["Aus", "kei\u00b7nem", "an\u00b7dern", "rath", ",", "als", "Got\u00b7tes", "wei\u00df\u00b7heit", ",", "her", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,", "KOUS", "NN", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jhr sprecht: Wie kan denn das ein g\u00f6ttlich wissen heissen,", "tokens": ["Ihr", "sprecht", ":", "Wie", "kan", "denn", "das", "ein", "g\u00f6tt\u00b7lich", "wis\u00b7sen", "heis\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWAV", "VMFIN", "ADV", "ART", "ART", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo ungewi\u00dfheit sich zum grund und regel macht,", "tokens": ["Wo", "un\u00b7ge\u00b7wi\u00df\u00b7heit", "sich", "zum", "grund", "und", "re\u00b7gel", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PRF", "APPRART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wo zehn lehrer sich mit tausend grillen schmeissen,", "tokens": ["Und", "wo", "zehn", "leh\u00b7rer", "sich", "mit", "tau\u00b7send", "gril\u00b7len", "schmeis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "CARD", "NN", "PRF", "APPR", "CARD", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn einer einen wurm von neuem vorgebracht?", "tokens": ["Wenn", "ei\u00b7ner", "ei\u00b7nen", "wurm", "von", "neu\u00b7em", "vor\u00b7ge\u00b7bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein, verzeiht es mir! Die h\u00f6chst gewissen k\u00fcnste", "tokens": ["Al\u00b7lein", ",", "ver\u00b7zeiht", "es", "mir", "!", "Die", "h\u00f6chst", "ge\u00b7wis\u00b7sen", "k\u00fcns\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "PPER", "$.", "ART", "ADV", "ADJA", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sind auch zuweilen nichts als leere meinungs-d\u00fcnste:", "tokens": ["Sind", "auch", "zu\u00b7wei\u00b7len", "nichts", "als", "lee\u00b7re", "mei\u00b7nungs\u00b7d\u00fcns\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zudem so sagt uns doch, wo man bewiesen findt,", "tokens": ["Zu\u00b7dem", "so", "sagt", "uns", "doch", ",", "wo", "man", "be\u00b7wie\u00b7sen", "findt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df andre lehrer frey von allem zweifel sind?", "tokens": ["Da\u00df", "and\u00b7re", "leh\u00b7rer", "frey", "von", "al\u00b7lem", "zwei\u00b7fel", "sind", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "APPR", "PIS", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Erfahrung kan allhier schon gute meister machen,", "tokens": ["Er\u00b7fah\u00b7rung", "kan", "all\u00b7hier", "schon", "gu\u00b7te", "meis\u00b7ter", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "ADV", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wenn vernunfft dabey nicht ausgeschlossen ist;", "tokens": ["Und", "wenn", "ver\u00b7nunfft", "da\u00b7bey", "nicht", "aus\u00b7ge\u00b7schlos\u00b7sen", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "PAV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So findet man durch sie den kern bewehrter sachen,", "tokens": ["So", "fin\u00b7det", "man", "durch", "sie", "den", "kern", "be\u00b7wehr\u00b7ter", "sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PPER", "ART", "ADJA", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch die ein augenblick offt bahr und grab verschliest,", "tokens": ["Durch", "die", "ein", "au\u00b7gen\u00b7blick", "offt", "bahr", "und", "grab", "ver\u00b7schliest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "ADJD", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum, sp\u00f6tter! die ihr wolt dem tod apostel werben,", "tokens": ["Drum", ",", "sp\u00f6t\u00b7ter", "!", "die", "ihr", "wolt", "dem", "tod", "a\u00b7pos\u00b7tel", "wer\u00b7ben", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJD", "$.", "PRELS", "PPER", "VMFIN", "ART", "NN", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Last erstlich euren wurm in dem gehirne sterben:", "tokens": ["Last", "erst\u00b7lich", "eu\u00b7ren", "wurm", "in", "dem", "ge\u00b7hir\u00b7ne", "ster\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn gebt beym Cous euch mit andern fragen an,", "tokens": ["Denn", "gebt", "beym", "Cous", "euch", "mit", "an\u00b7dern", "fra\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPER", "APPR", "PIS", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Ob dieser euch vielleicht mit v\u00f6lckern dienen kan?", "tokens": ["Ob", "die\u00b7ser", "euch", "viel\u00b7leicht", "mit", "v\u00f6l\u00b7ckern", "die\u00b7nen", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "PPER", "ADV", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Zwar wenn Pillificus stets leichen mu\u00df begleiten,", "tokens": ["Zwar", "wenn", "Pil\u00b7li\u00b7fi\u00b7cus", "stets", "lei\u00b7chen", "mu\u00df", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NE", "ADV", "VVINF", "VMFIN", "VVINF", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Und mit der todten-post ein gut verst\u00e4ndni\u00df hat,", "tokens": ["Und", "mit", "der", "tod\u00b7ten\u00b7post", "ein", "gut", "ver\u00b7st\u00e4nd\u00b7ni\u00df", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJD", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So m\u00f6chtet ihr vor ihn wohl ein quartier hereiten;", "tokens": ["So", "m\u00f6ch\u00b7tet", "ihr", "vor", "ihn", "wohl", "ein", "quar\u00b7tier", "he\u00b7rei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein der nahmen macht nicht den gesundheits-rath.", "tokens": ["Al\u00b7lein", "der", "nah\u00b7men", "macht", "nicht", "den", "ge\u00b7sund\u00b7heits\u00b7rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sonst st\u00fcnd ein gr\u00fcner Mops, der wurtzeln graben lernen,", "tokens": ["Sonst", "st\u00fcnd", "ein", "gr\u00fc\u00b7ner", "Mops", ",", "der", "wurt\u00b7zeln", "gra\u00b7ben", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie Aesculapius, vorl\u00e4ngsten bey den sternen;", "tokens": ["Wie", "A\u00b7e\u00b7scu\u00b7la\u00b7pius", ",", "vor\u00b7l\u00e4ngs\u00b7ten", "bey", "den", "ster\u00b7nen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "VVFIN", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schreibt aber ihn die kunst nicht ins register ein,", "tokens": ["Schreibt", "a\u00b7ber", "ihn", "die", "kunst", "nicht", "ins", "re\u00b7gis\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "PTKNEG", "APPRART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So kan er, wie er will, bey euch in diensten seyn.", "tokens": ["So", "kan", "er", ",", "wie", "er", "will", ",", "bey", "euch", "in", "diens\u00b7ten", "seyn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "PWAV", "PPER", "VMFIN", "$,", "APPR", "PPER", "APPR", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Wen der Hippocrates soll zum collegen wehlen,", "tokens": ["Wen", "der", "Hip\u00b7po\u00b7cra\u00b7tes", "soll", "zum", "col\u00b7le\u00b7gen", "weh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VMFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Der mu\u00df zu unsrer zeit aus andern augen sehn:", "tokens": ["Der", "mu\u00df", "zu", "uns\u00b7rer", "zeit", "aus", "an\u00b7dern", "au\u00b7gen", "sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er darff die krancken nicht mit langen fiebern qu\u00e4len.", "tokens": ["Er", "darff", "die", "kran\u00b7cken", "nicht", "mit", "lan\u00b7gen", "fie\u00b7bern", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wenn der herbst gesund, auf b\u00f6se zeiten schm\u00e4hn.", "tokens": ["Und", "wenn", "der", "herbst", "ge\u00b7sund", ",", "auf", "b\u00f6\u00b7se", "zei\u00b7ten", "schm\u00e4hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die krancken werden ihn schon von sich selbsten suchen:", "tokens": ["Die", "kran\u00b7cken", "wer\u00b7den", "ihn", "schon", "von", "sich", "selbs\u00b7ten", "su\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "APPR", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Drum darff er nicht die pest auf st\u00e4dt und l\u00e4nder fluchen;", "tokens": ["Drum", "darff", "er", "nicht", "die", "pest", "auf", "st\u00e4dt", "und", "l\u00e4n\u00b7der", "flu\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PTKNEG", "ART", "NN", "APPR", "ADJD", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und also f\u00e4llt auch hier die bittre schm\u00e4hung hin,", "tokens": ["Und", "al\u00b7so", "f\u00e4llt", "auch", "hier", "die", "bitt\u00b7re", "schm\u00e4\u00b7hung", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df \u00e4rtzte selbst das weh auf ihre krancken ziehn.", "tokens": ["Da\u00df", "\u00e4rtz\u00b7te", "selbst", "das", "weh", "auf", "ih\u00b7re", "kran\u00b7cken", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "ADV", "ART", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Jhr tollen sterblichen! was wolt ihr eure flecken,", "tokens": ["Ihr", "tol\u00b7len", "sterb\u00b7li\u00b7chen", "!", "was", "wolt", "ihr", "eu\u00b7re", "fle\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVINF", "$.", "PWS", "VMFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die geist und leib zugleich ins lazareth gebracht,", "tokens": ["Die", "geist", "und", "leib", "zu\u00b7gleich", "ins", "la\u00b7za\u00b7reth", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch so vergebens hier mit feigen-bl\u00e4ttern decken?", "tokens": ["Doch", "so", "ver\u00b7ge\u00b7bens", "hier", "mit", "fei\u00b7gen\u00b7bl\u00e4t\u00b7tern", "de\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der zorn, der euren kopff zum patienten macht:", "tokens": ["Der", "zorn", ",", "der", "eu\u00b7ren", "kopff", "zum", "pa\u00b7ti\u00b7en\u00b7ten", "macht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der geitz, der mit verdru\u00df nur halbe bissen zehlet:", "tokens": ["Der", "geitz", ",", "der", "mit", "ver\u00b7dru\u00df", "nur", "hal\u00b7be", "bis\u00b7sen", "zeh\u00b7let", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "ADV", "ADJA", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die sinds, durch die ihr euch selbst die gesundheit stehlet;", "tokens": ["Die", "sinds", ",", "durch", "die", "ihr", "euch", "selbst", "die", "ge\u00b7sund\u00b7heit", "steh\u00b7let", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PRELS", "PPER", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wenn der l\u00fcste brand vernunfft nicht l\u00f6schen kan,", "tokens": ["Und", "wenn", "der", "l\u00fcs\u00b7te", "brand", "ver\u00b7nunfft", "nicht", "l\u00f6\u00b7schen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So macht ihr euch ja selbst den \u00e4rtzten unterthau.", "tokens": ["So", "macht", "ihr", "euch", "ja", "selbst", "den", "\u00e4rtz\u00b7ten", "un\u00b7ter\u00b7thau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So \u00e4ndert dann den schlu\u00df, und last die regeln gelten,", "tokens": ["So", "\u00e4n\u00b7dert", "dann", "den", "schlu\u00df", ",", "und", "last", "die", "re\u00b7geln", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,", "KON", "VVFIN", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ihre kunst mit flei\u00df zu eurem nutzen setzt:", "tokens": ["Die", "ih\u00b7re", "kunst", "mit", "flei\u00df", "zu", "eu\u00b7rem", "nut\u00b7zen", "setzt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "H\u00f6rt auf, die gold-tinctur und s\u00fc\u00df essentz zu schelten:", "tokens": ["H\u00f6rt", "auf", ",", "die", "gold\u00b7tinc\u00b7tur", "und", "s\u00fc\u00df", "es\u00b7sentz", "zu", "schel\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "ART", "NN", "KON", "ADJD", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und was man sonsten noch von panaceen sch\u00e4tzt.", "tokens": ["Und", "was", "man", "sons\u00b7ten", "noch", "von", "pa\u00b7na\u00b7ce\u00b7en", "sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ja! wenn die beutel selbst einmahl purgiren m\u00fcssen,", "tokens": ["Ja", "!", "wenn", "die", "beu\u00b7tel", "selbst", "ein\u00b7mahl", "pur\u00b7gi\u00b7ren", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "KOUS", "ART", "NN", "ADV", "ADV", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So last euch nimmermehr das zinse-geld verdriessen:", "tokens": ["So", "last", "euch", "nim\u00b7mer\u00b7mehr", "das", "zin\u00b7se\u00b7geld", "ver\u00b7dries\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn euer schimpff bewegt doch nicht des Sirachs schlu\u00df,", "tokens": ["Denn", "eu\u00b7er", "schimpff", "be\u00b7wegt", "doch", "nicht", "des", "Si\u00b7rachs", "schlu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df man die medicin als g\u00f6ttlich ehren mu\u00df.", "tokens": ["Da\u00df", "man", "die", "me\u00b7di\u00b7cin", "als", "g\u00f6tt\u00b7lich", "eh\u00b7ren", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "PIAT", "KOKOM", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Verzeih, geehrter freund! bey deiner ehren-stunde,", "tokens": ["Ver\u00b7zeih", ",", "ge\u00b7ehr\u00b7ter", "freund", "!", "bey", "dei\u00b7ner", "eh\u00b7ren\u00b7stun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn uns das gegentheil auf dein exempel f\u00fchrt:", "tokens": ["Wenn", "uns", "das", "ge\u00b7gen\u00b7theil", "auf", "dein", "ex\u00b7em\u00b7pel", "f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+--+-+---", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Denn, wenn die wissenschafft aus unsers Wedels munde,", "tokens": ["Denn", ",", "wenn", "die", "wis\u00b7sen\u00b7schafft", "aus", "un\u00b7sers", "We\u00b7dels", "mun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nebst dem, was Seevogt lehrt, und eignes wissen ziert:", "tokens": ["Nebst", "dem", ",", "was", "See\u00b7vogt", "lehrt", ",", "und", "eig\u00b7nes", "wis\u00b7sen", "ziert", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PWS", "NN", "VVFIN", "$,", "KON", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wem Stahl und Hoffmanns hand die doctor-w\u00fcrde g\u00f6nnen,", "tokens": ["Wem", "Stahl", "und", "Hoff\u00b7manns", "hand", "die", "doc\u00b7tor\u00b7w\u00fcr\u00b7de", "g\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der wird die schm\u00e4hungen recht widerlegen k\u00f6nnen.", "tokens": ["Der", "wird", "die", "schm\u00e4\u00b7hun\u00b7gen", "recht", "wi\u00b7der\u00b7le\u00b7gen", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "VVINF", "VMINF", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Indessen w\u00fcnschen wir als freunde noch darbey:", "tokens": ["In\u00b7des\u00b7sen", "w\u00fcn\u00b7schen", "wir", "als", "freun\u00b7de", "noch", "dar\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "NN", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df deine medicin stets ohne tadel sey!", "tokens": ["Da\u00df", "dei\u00b7ne", "me\u00b7di\u00b7cin", "stets", "oh\u00b7ne", "ta\u00b7del", "sey", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}