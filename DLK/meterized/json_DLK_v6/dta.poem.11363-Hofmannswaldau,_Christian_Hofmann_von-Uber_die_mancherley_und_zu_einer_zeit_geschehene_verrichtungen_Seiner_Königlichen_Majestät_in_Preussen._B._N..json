{"dta.poem.11363": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Uber die mancherley und zu einer zeit  \n geschehene verrichtungen Seiner  \n K\u00f6niglichen Majest\u00e4t  \n in Preussen.  \n B. N.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Rom lie\u00df vorzeiten es in b\u00fccher einverleiben,", "tokens": ["Rom", "lie\u00df", "vor\u00b7zei\u00b7ten", "es", "in", "b\u00fc\u00b7cher", "ein\u00b7ver\u00b7lei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVFIN", "PPER", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df C\u00e4sar, wann er la\u00df, auch h\u00f6ren, reden, schreiben,", "tokens": ["Da\u00df", "C\u00e4\u00b7sar", ",", "wann", "er", "la\u00df", ",", "auch", "h\u00f6\u00b7ren", ",", "re\u00b7den", ",", "schrei\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PWAV", "PPER", "PTKVZ", "$,", "ADV", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und also viererley auf einmahl konte thun.", "tokens": ["Und", "al\u00b7so", "vie\u00b7rer\u00b7ley", "auf", "ein\u00b7mahl", "kon\u00b7te", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was ehmahls C\u00e4sar that, thut Preussens K\u00f6nig nun,", "tokens": ["Was", "eh\u00b7mahls", "C\u00e4\u00b7sar", "that", ",", "thut", "Preus\u00b7sens", "K\u00f6\u00b7nig", "nun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NE", "VVFIN", "$,", "VVFIN", "NE", "NE", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer kennt nicht seinen geist und dessen hohe gaben?", "tokens": ["Wer", "kennt", "nicht", "sei\u00b7nen", "geist", "und", "des\u00b7sen", "ho\u00b7he", "ga\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "KON", "PRELAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er lieset, h\u00f6ret, schreibt und redet nicht allein:", "tokens": ["Er", "lie\u00b7set", ",", "h\u00f6\u00b7ret", ",", "schreibt", "und", "re\u00b7det", "nicht", "al\u00b7lein", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er ordnet auch zugleich, wie das und jenes seyn,", "tokens": ["Er", "ord\u00b7net", "auch", "zu\u00b7gleich", ",", "wie", "das", "und", "je\u00b7nes", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PWAV", "PDS", "KON", "PDS", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Was der zum lohne soll, und der zur strafe haben;", "tokens": ["Was", "der", "zum", "loh\u00b7ne", "soll", ",", "und", "der", "zur", "stra\u00b7fe", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "APPRART", "NN", "VMFIN", "$,", "KON", "ART", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Fragt nicht, warum ers thut? Es mangelt ihm an zeit:", "tokens": ["Fragt", "nicht", ",", "wa\u00b7rum", "ers", "thut", "?", "Es", "man\u00b7gelt", "ihm", "an", "zeit", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "PIS", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn was braucht Teutschlands ruh, und was Europens streit", "tokens": ["Denn", "was", "braucht", "Teutschlands", "ruh", ",", "und", "was", "Eu\u00b7ro\u00b7pens", "streit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "NE", "NN", "$,", "KON", "PWS", "NE", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.11": {"text": "F\u00fcr grosse sorgen nicht? Drum mu\u00df er ja wohl eilen,", "tokens": ["F\u00fcr", "gros\u00b7se", "sor\u00b7gen", "nicht", "?", "Drum", "mu\u00df", "er", "ja", "wohl", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "$.", "PAV", "VMFIN", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und das beysammen thun, was andre k\u00f6nnen theilen.", "tokens": ["Und", "das", "bey\u00b7sam\u00b7men", "thun", ",", "was", "and\u00b7re", "k\u00f6n\u00b7nen", "thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVINF", "VVINF", "$,", "PRELS", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Schau aber, Preussen! hier des weisen k\u00f6nigs rath!", "tokens": ["Schau", "a\u00b7ber", ",", "Preus\u00b7sen", "!", "hier", "des", "wei\u00b7sen", "k\u00f6\u00b7nigs", "rath", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "NN", "$.", "ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.14": {"text": "Es war ein C\u00e4sar nur, der solche wunder that.", "tokens": ["Es", "war", "ein", "C\u00e4\u00b7sar", "nur", ",", "der", "sol\u00b7che", "wun\u00b7der", "that", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NE", "ADV", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dein Friedrich that sie nach, und hat ihn \u00fcbertroffen;", "tokens": ["Dein", "Fried\u00b7rich", "that", "sie", "nach", ",", "und", "hat", "ihn", "\u00fc\u00b7ber\u00b7trof\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wie sollen wir in ihm nicht einen k\u00f6nig hoffen?", "tokens": ["Wie", "sol\u00b7len", "wir", "in", "ihm", "nicht", "ei\u00b7nen", "k\u00f6\u00b7nig", "hof\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "APPR", "PPER", "PTKNEG", "ART", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der schlu\u00df bleibt unbewegt:", "tokens": ["Der", "schlu\u00df", "bleibt", "un\u00b7be\u00b7wegt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.18": {"text": "Wer kayser \u00fcbertrifft, die Rom und auch der erden", "tokens": ["Wer", "kay\u00b7ser", "\u00fc\u00b7bert\u00b7rifft", ",", "die", "Rom", "und", "auch", "der", "er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "VVPP", "$,", "PRELS", "NE", "KON", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Durch klugheit und verstand gesetze vorgelegt:", "tokens": ["Durch", "klug\u00b7heit", "und", "ver\u00b7stand", "ge\u00b7set\u00b7ze", "vor\u00b7ge\u00b7legt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Mu\u00df, wo nicht kayser selbst, doch kaysern gleiche werden.", "tokens": ["Mu\u00df", ",", "wo", "nicht", "kay\u00b7ser", "selbst", ",", "doch", "kay\u00b7sern", "glei\u00b7che", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PWAV", "PTKNEG", "ADJD", "ADV", "$,", "ADV", "ADJA", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}