{"textgrid.poem.43869": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer wollte dich nicht englisch preisen,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer wollte dich nicht englisch preisen,", "tokens": ["Wer", "woll\u00b7te", "dich", "nicht", "eng\u00b7lisch", "prei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der so wie ich dein Antliz kennt!", "tokens": ["Der", "so", "wie", "ich", "dein", "Ant\u00b7liz", "kennt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "KOKOM", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du kanst mit allen Blicken weisen,", "tokens": ["Du", "kanst", "mit", "al\u00b7len", "Bli\u00b7cken", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df man dich billig Engel nennt,", "tokens": ["Da\u00df", "man", "dich", "bil\u00b7lig", "En\u00b7gel", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADJD", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Trift dies nur blos noch \u00fcberein,", "tokens": ["Trift", "dies", "nur", "blos", "noch", "\u00fc\u00b7be\u00b7re\u00b7in", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Da\u00df Engel k\u00f6nnen grausam seyn.", "tokens": ["Da\u00df", "En\u00b7gel", "k\u00f6n\u00b7nen", "grau\u00b7sam", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Bedencke nur dein ganzes Wesen,", "tokens": ["Be\u00b7den\u00b7cke", "nur", "dein", "gan\u00b7zes", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist so gar durchaus galant,", "tokens": ["Es", "ist", "so", "gar", "durc\u00b7haus", "ga\u00b7lant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf allen Gliedern kan man lesen:", "tokens": ["Auf", "al\u00b7len", "Glie\u00b7dern", "kan", "man", "le\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dies Bild ist G\u00f6ttern anverwand", "tokens": ["Dies", "Bild", "ist", "G\u00f6t\u00b7tern", "an\u00b7ver\u00b7wand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VAFIN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wie es nicht nat\u00fcrlich ist,", "tokens": ["Und", "wie", "es", "nicht", "na\u00b7t\u00fcr\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PTKNEG", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df du so gar vollkommen bist.", "tokens": ["Da\u00df", "du", "so", "gar", "voll\u00b7kom\u00b7men", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die wundersch\u00f6nen Zauberspiegel,", "tokens": ["Die", "wun\u00b7der\u00b7sch\u00f6\u00b7nen", "Zau\u00b7ber\u00b7spie\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So immer in Bewegung stehn,", "tokens": ["So", "im\u00b7mer", "in", "Be\u00b7we\u00b7gung", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die marmorwei\u00dfen Amorsh\u00fcgel,", "tokens": ["Die", "mar\u00b7mor\u00b7wei\u00b7\u00dfen", "A\u00b7mors\u00b7h\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn sie stets auf- und niedergehn \u2013", "tokens": ["Wenn", "sie", "stets", "auf", "und", "nie\u00b7der\u00b7gehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "TRUNC", "KON", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sagt, wenn der Neid sie selber schaut:", "tokens": ["Sagt", ",", "wenn", "der", "Neid", "sie", "sel\u00b7ber", "schaut", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hier hat mehr als Natur gebaut.", "tokens": ["Hier", "hat", "mehr", "als", "Na\u00b7tur", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "KOKOM", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Denck ich noch an die Tugendsch\u00e4ze,", "tokens": ["Denck", "ich", "noch", "an", "die", "Tu\u00b7gend\u00b7sch\u00e4\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die deine Schwanenbrust umschliest,", "tokens": ["Die", "dei\u00b7ne", "Schwa\u00b7nen\u00b7brust", "um\u00b7schliest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sag ich (doch ist's Dohlgeschw\u00e4ze),", "tokens": ["So", "sag", "ich", "(", "doch", "ist's", "Dohl\u00b7ge\u00b7schw\u00e4\u00b7ze", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "ADV", "VAFIN", "NN", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df du ein Bild der Tugend bist,", "tokens": ["Da\u00df", "du", "ein", "Bild", "der", "Tu\u00b7gend", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und f\u00e4llt mir nur best\u00e4ndig ein,", "tokens": ["Und", "f\u00e4llt", "mir", "nur", "be\u00b7st\u00e4n\u00b7dig", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du m\u00fcstest mehr als menschlich seyn.", "tokens": ["Du", "m\u00fcs\u00b7test", "mehr", "als", "menschlich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "KOKOM", "ADJD", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Ach, aber deine Seltenheiten", "tokens": ["Ach", ",", "a\u00b7ber", "dei\u00b7ne", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind fast wie jenes Paradies,", "tokens": ["Sind", "fast", "wie", "je\u00b7nes", "Pa\u00b7ra\u00b7dies", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KOKOM", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dieweil es zu den Unschuldszeiten", "tokens": ["Die\u00b7weil", "es", "zu", "den", "Un\u00b7schulds\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch alles recht vollkommen wies;", "tokens": ["Noch", "al\u00b7les", "recht", "voll\u00b7kom\u00b7men", "wies", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch dieses, was verbothen war,", "tokens": ["Doch", "die\u00b7ses", ",", "was", "ver\u00b7bo\u00b7then", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$,", "PRELS", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das stellte sich am sch\u00f6nsten dar.", "tokens": ["Das", "stell\u00b7te", "sich", "am", "sch\u00f6ns\u00b7ten", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPRART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Bedencke doch, mein ander Leben,", "tokens": ["Be\u00b7den\u00b7cke", "doch", ",", "mein", "an\u00b7der", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonne giebt dem Mond ihr Licht,", "tokens": ["Die", "Son\u00b7ne", "giebt", "dem", "Mond", "ihr", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er den bla\u00dfen Schein kan geben;", "tokens": ["Da\u00df", "er", "den", "bla\u00b7\u00dfen", "Schein", "kan", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr selbst bl\u00fcht keine Blume nicht;", "tokens": ["Ihr", "selbst", "bl\u00fcht", "kei\u00b7ne", "Blu\u00b7me", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja was uns unser Auge weist,", "tokens": ["Ja", "was", "uns", "un\u00b7ser", "Au\u00b7ge", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist, da\u00df es andern Dienste leist.", "tokens": ["Ist", ",", "da\u00df", "es", "an\u00b7dern", "Diens\u00b7te", "leist", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ist's m\u00f6glich, da\u00df so harte Sinnen", "tokens": ["Ist's", "m\u00f6g\u00b7lich", ",", "da\u00df", "so", "har\u00b7te", "Sin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "$,", "KOUS", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ungemeine Spr\u00f6digkeit", "tokens": ["Und", "un\u00b7ge\u00b7mei\u00b7ne", "Spr\u00f6\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die zarten Glieder hegen k\u00f6nnen,", "tokens": ["Die", "zar\u00b7ten", "Glie\u00b7der", "he\u00b7gen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die mir ein anders prophezeit?", "tokens": ["Die", "mir", "ein", "an\u00b7ders", "pro\u00b7phe\u00b7zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier trift es nicht von Engeln ein,", "tokens": ["Hier", "trift", "es", "nicht", "von", "En\u00b7geln", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df sie dienstbahre Geister seyn.", "tokens": ["Da\u00df", "sie", "dienst\u00b7bah\u00b7re", "Geis\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was zehlt man nicht vor lange Stunden,", "tokens": ["Was", "zehlt", "man", "nicht", "vor", "lan\u00b7ge", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn uns etwas an Gliedern fehlt;", "tokens": ["Wenn", "uns", "et\u00b7was", "an", "Glie\u00b7dern", "fehlt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun dencke, was mein Herz empfunden,", "tokens": ["Nun", "den\u00b7cke", ",", "was", "mein", "Herz", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df noch so gar empfindlich qu\u00e4lt", "tokens": ["Da\u00df", "noch", "so", "gar", "emp\u00b7find\u00b7lich", "qu\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Feuer, so in ihm entbrand,", "tokens": ["Ein", "Feu\u00b7er", ",", "so", "in", "ihm", "ent\u00b7brand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Da dich mein erster Blick gekand.", "tokens": ["Da", "dich", "mein", "ers\u00b7ter", "Blick", "ge\u00b7kand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich will dich \u00fcber alles sch\u00e4zen", "tokens": ["Ich", "will", "dich", "\u00fc\u00b7ber", "al\u00b7les", "sch\u00e4\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und st\u00fcndlich deinen Ruhm erh\u00f6hn.", "tokens": ["Und", "st\u00fcnd\u00b7lich", "dei\u00b7nen", "Ruhm", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird mich noch deine Huld erg\u00f6zen,", "tokens": ["Wird", "mich", "noch", "dei\u00b7ne", "Huld", "er\u00b7g\u00f6\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df wir in gleichen Flammen stehn,", "tokens": ["Da\u00df", "wir", "in", "glei\u00b7chen", "Flam\u00b7men", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So sag ich, wie's die Warheit ist,", "tokens": ["So", "sag", "ich", ",", "wie's", "die", "War\u00b7heit", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df du noch mehr als englisch bist.", "tokens": ["Da\u00df", "du", "noch", "mehr", "als", "eng\u00b7lisch", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "KOKOM", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}