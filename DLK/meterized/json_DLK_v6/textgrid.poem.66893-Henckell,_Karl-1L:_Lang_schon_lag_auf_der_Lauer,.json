{"textgrid.poem.66893": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: Lang schon lag auf der Lauer,", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lang schon lag auf der Lauer,", "tokens": ["Lang", "schon", "lag", "auf", "der", "Lau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Leise sausend,", "tokens": ["Lei\u00b7se", "sau\u00b7send", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Heimlicher Sturm.", "tokens": ["Heim\u00b7li\u00b7cher", "Sturm", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Pl\u00f6tzlich n\u00e4her und n\u00e4her brausend", "tokens": ["Pl\u00f6tz\u00b7lich", "n\u00e4\u00b7her", "und", "n\u00e4\u00b7her", "brau\u00b7send"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "KON", "ADJD", "VVPP"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "\u00dcberf\u00e4llt er die Welt.", "tokens": ["\u00dc\u00b7berf\u00b7\u00e4llt", "er", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Fr\u00fchlingsschauer", "tokens": ["Fr\u00fch\u00b7lings\u00b7schau\u00b7er"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Bringt er dem atemsch\u00f6pfenden Land.", "tokens": ["Bringt", "er", "dem", "a\u00b7tem\u00b7sch\u00f6p\u00b7fen\u00b7den", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Sturm!", "tokens": ["Sturm", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.3": {"line.1": {"text": "Was in verzehrender", "tokens": ["Was", "in", "ver\u00b7zeh\u00b7ren\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["PWS", "APPR", "ADJA"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sehnsucht harrte,", "tokens": ["Sehn\u00b7sucht", "harr\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Schier begraben in schweigender Qual,", "tokens": ["Schier", "be\u00b7gra\u00b7ben", "in", "schwei\u00b7gen\u00b7der", "Qual", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Was die luftspiegelnde", "tokens": ["Was", "die", "luft\u00b7spie\u00b7geln\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Hoffnung narrte,", "tokens": ["Hoff\u00b7nung", "narr\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Mit einem Mal", "tokens": ["Mit", "ei\u00b7nem", "Mal"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Hebt es die H\u00e4upter.", "tokens": ["Hebt", "es", "die", "H\u00e4up\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Und aus der l\u00e4hmenden Stille", "tokens": ["Und", "aus", "der", "l\u00e4h\u00b7men\u00b7den", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Endlich gebrochenem Bann", "tokens": ["End\u00b7lich", "ge\u00b7bro\u00b7che\u00b7nem", "Bann"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Schwillt des Lebens erl\u00f6sender Wille", "tokens": ["Schwillt", "des", "Le\u00b7bens", "er\u00b7l\u00f6\u00b7sen\u00b7der", "Wil\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wieder h\u00f6her", "tokens": ["Wie\u00b7der", "h\u00f6\u00b7her"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Und h\u00f6her an.", "tokens": ["Und", "h\u00f6\u00b7her", "an", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Denn nur H\u00f6rige dulden gelassen,", "tokens": ["Denn", "nur", "H\u00f6\u00b7ri\u00b7ge", "dul\u00b7den", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVINF", "VVPP", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Was des Rechtes W\u00fcrde verh\u00f6hnt,", "tokens": ["Was", "des", "Rech\u00b7tes", "W\u00fcr\u00b7de", "ver\u00b7h\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Freiheitliebende Menschen hassen,", "tokens": ["Frei\u00b7heit\u00b7lie\u00b7ben\u00b7de", "Men\u00b7schen", "has\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Was mit Unbill", "tokens": ["Was", "mit", "Un\u00b7bill"], "token_info": ["word", "word", "word"], "pos": ["PWS", "APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Die Unbill kr\u00f6nt.", "tokens": ["Die", "Un\u00b7bill", "kr\u00f6nt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Seht, ein Sturm", "tokens": ["Seht", ",", "ein", "Sturm"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "ART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Ist langsam gekommen,", "tokens": ["Ist", "lang\u00b7sam", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Jetzo bl\u00e4st er gewaltig ins Horn!", "tokens": ["Jet\u00b7zo", "bl\u00e4st", "er", "ge\u00b7wal\u00b7tig", "ins", "Horn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Wer hinhorchte,", "tokens": ["Wer", "hin\u00b7horch\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,"], "meter": "--+-", "measure": "anapaest.init"}, "line.5": {"text": "Hat l\u00e4ngst ihn vernommen \u2013", "tokens": ["Hat", "l\u00e4ngst", "ihn", "ver\u00b7nom\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "St\u00e4dte ersch\u00fcttert,", "tokens": ["St\u00e4d\u00b7te", "er\u00b7sch\u00fct\u00b7tert", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "L\u00e4nder reinigt sein herrlicher Zorn.", "tokens": ["L\u00e4n\u00b7der", "rei\u00b7nigt", "sein", "herr\u00b7li\u00b7cher", "Zorn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}}}}