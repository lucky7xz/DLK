{"textgrid.poem.35121": {"metadata": {"author": {"name": "May, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Drei Fragen", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sag, wer du bist! Denk aber vorher nach!", "tokens": ["Sag", ",", "wer", "du", "bist", "!", "Denk", "a\u00b7ber", "vor\u00b7her", "nach", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "VAFIN", "$.", "NN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbein Mensch bin ich\u00ab, antwortest du erhaben.", "tokens": ["\u00bb", "ein", "Mensch", "bin", "ich", "\u00ab", ",", "ant\u00b7wor\u00b7test", "du", "er\u00b7ha\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PPER", "$(", "$,", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ein Mensch? Sonst nichts? Und dennoch, dennoch sprach", "tokens": ["Ein", "Mensch", "?", "Sonst", "nichts", "?", "Und", "den\u00b7noch", ",", "den\u00b7noch", "sprach"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "ADV", "PIS", "$.", "KON", "ADV", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Aus dir der Stolz auf dich und deine Gaben.", "tokens": ["Aus", "dir", "der", "Stolz", "auf", "dich", "und", "dei\u00b7ne", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dies letzte Wort berichtet ganz bestimmt", "tokens": ["Dies", "letz\u00b7te", "Wort", "be\u00b7rich\u00b7tet", "ganz", "be\u00b7stimmt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADJA", "NN", "VVFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Nicht von Verdiensten sondern von Geschenken,", "tokens": ["Nicht", "von", "Ver\u00b7diens\u00b7ten", "son\u00b7dern", "von", "Ge\u00b7schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und wer sein ganzes \u00bbSein\u00ab als Gabe nimmt,", "tokens": ["Und", "wer", "sein", "gan\u00b7zes", "\u00bb", "Sein", "\u00ab", "als", "Ga\u00b7be", "nimmt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "ADJA", "$(", "PPOSAT", "$(", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der hat wohl Grund, bescheidener zu denken.", "tokens": ["Der", "hat", "wohl", "Grund", ",", "be\u00b7schei\u00b7de\u00b7ner", "zu", "den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NN", "$,", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.9": {"text": "Und trotzdem meine ich: Blos Mensch ist mir zu klein;", "tokens": ["Und", "trotz\u00b7dem", "mei\u00b7ne", "ich", ":", "Blos", "Mensch", "ist", "mir", "zu", "klein", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "$.", "ADV", "NN", "VAFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ich will weit mehr, ich will viel Gr\u00f6\u00dfres sein.", "tokens": ["Ich", "will", "weit", "mehr", ",", "ich", "will", "viel", "Gr\u00f6\u00df\u00b7res", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "ADV", "$,", "PPER", "VMFIN", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Sag, wo du bist! Du siehst erstaunt mich an", "tokens": ["Sag", ",", "wo", "du", "bist", "!", "Du", "siehst", "er\u00b7staunt", "mich", "an"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "PPER", "VAFIN", "$.", "PPER", "VVFIN", "ADJD", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und sprichst nichts weiter, als \u00bbdoch hier auf Erden!\u00ab", "tokens": ["Und", "sprichst", "nichts", "wei\u00b7ter", ",", "als", "\u00bb", "doch", "hier", "auf", "Er\u00b7den", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PIS", "PTKVZ", "$,", "KOUS", "$(", "ADV", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer sich nicht geistig von ihr trennen kann,", "tokens": ["Wer", "sich", "nicht", "geis\u00b7tig", "von", "ihr", "tren\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "PTKNEG", "ADJD", "APPR", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dem wird dies \u00bbWo\u00ab niemals begreiflich werden.", "tokens": ["Dem", "wird", "dies", "\u00bb", "Wo", "\u00ab", "nie\u00b7mals", "be\u00b7greif\u00b7lich", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PDS", "$(", "PWAV", "$(", "ADV", "ADJD", "VAINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Du bist nicht hier, auch noch nicht wieder dort;", "tokens": ["Du", "bist", "nicht", "hier", ",", "auch", "noch", "nicht", "wie\u00b7der", "dort", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "ADV", "ADV", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Dein \u00bbWo\u00ab liegt dir entr\u00fcckt, ist nicht zu fassen.", "tokens": ["Dein", "\u00bb", "Wo", "\u00ab", "liegt", "dir", "ent\u00b7r\u00fcckt", ",", "ist", "nicht", "zu", "fas\u00b7sen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "$(", "PWAV", "$(", "VVFIN", "PPER", "VVPP", "$,", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Dir fehlt der Halt, der feste, sichre Ort;", "tokens": ["Dir", "fehlt", "der", "Halt", ",", "der", "fes\u00b7te", ",", "sich\u00b7re", "Ort", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Es gab ihn wohl, doch hast du ihn verlassen.", "tokens": ["Es", "gab", "ihn", "wohl", ",", "doch", "hast", "du", "ihn", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "ADV", "VAFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Du h\u00e4ngst arachnengleich im eigenen Gespinnst,", "tokens": ["Du", "h\u00e4ngst", "a\u00b7rach\u00b7nen\u00b7gleich", "im", "ei\u00b7ge\u00b7nen", "Ge\u00b7spinnst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und deine Welt ist, was du dir ersinnst.", "tokens": ["Und", "dei\u00b7ne", "Welt", "ist", ",", "was", "du", "dir", "er\u00b7sinnst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "$,", "PWS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sag, wie du bist! Nat\u00fcrlich bist du gut \u2013", "tokens": ["Sag", ",", "wie", "du", "bist", "!", "Na\u00b7t\u00fcr\u00b7lich", "bist", "du", "gut", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "VAFIN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Fehler sind f\u00fcr Andre nur vorhanden!", "tokens": ["Die", "Feh\u00b7ler", "sind", "f\u00fcr", "And\u00b7re", "nur", "vor\u00b7han\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die deinen aber auch: Sei auf der Hut", "tokens": ["Die", "dei\u00b7nen", "a\u00b7ber", "auch", ":", "Sei", "auf", "der", "Hut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADV", "ADV", "$.", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vor Leuten, die vielleicht dich anders fanden!", "tokens": ["Vor", "Leu\u00b7ten", ",", "die", "viel\u00b7leicht", "dich", "an\u00b7ders", "fan\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Es ist nur Einer gut, nur er allein.", "tokens": ["Es", "ist", "nur", "Ei\u00b7ner", "gut", ",", "nur", "er", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "ADJD", "$,", "ADV", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wer darf an Reinheit sich mit ihm vergleichen?", "tokens": ["Wer", "darf", "an", "Rein\u00b7heit", "sich", "mit", "ihm", "ver\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "APPR", "NN", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und willst du so, wie er es fordert, sein,", "tokens": ["Und", "willst", "du", "so", ",", "wie", "er", "es", "for\u00b7dert", ",", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "PPER", "VVFIN", "$,", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "So kannst du es auch nur durch ihn erreichen.", "tokens": ["So", "kannst", "du", "es", "auch", "nur", "durch", "ihn", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Zerrei\u00df dein Spinnennetz, und werde dir doch klar,", "tokens": ["Zer\u00b7rei\u00df", "dein", "Spin\u00b7nen\u00b7netz", ",", "und", "wer\u00b7de", "dir", "doch", "klar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df jeder Faden nur ein Irrthum war!", "tokens": ["Da\u00df", "je\u00b7der", "Fa\u00b7den", "nur", "ein", "Irr\u00b7thum", "war", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}