{"textgrid.poem.39642": {"metadata": {"author": {"name": "Schlegel, August Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Bogen waren fertig,", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Bogen waren fertig,", "tokens": ["Die", "Bo\u00b7gen", "wa\u00b7ren", "fer\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Drucker des gew\u00e4rtig,", "tokens": ["Der", "Dru\u00b7cker", "des", "ge\u00b7w\u00e4r\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als, just im ersten Schlaf", "tokens": ["Als", ",", "just", "im", "ers\u00b7ten", "Schlaf"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mein Haus das Ungl\u00fcck traf.", "tokens": ["Mein", "Haus", "das", "Un\u00b7gl\u00fcck", "traf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Zwar manches Blatt verbrannte,", "tokens": ["Zwar", "man\u00b7ches", "Blatt", "ver\u00b7brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Doch war es das Bekannte,", "tokens": ["Doch", "war", "es", "das", "Be\u00b7kann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich schrieb's in schnellem Lauf", "tokens": ["Ich", "schrie\u00b7b's", "in", "schnel\u00b7lem", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Aus dem Ged\u00e4chtni\u00df auf.", "tokens": ["Aus", "dem", "Ge\u00b7d\u00e4cht\u00b7ni\u00df", "auf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich war getrost und muthig,", "tokens": ["Ich", "war", "ge\u00b7trost", "und", "mut\u00b7hig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und keine Stunde ruht' ich,", "tokens": ["Und", "kei\u00b7ne", "Stun\u00b7de", "ruht'", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch neues Mi\u00dfgeschick", "tokens": ["Doch", "neu\u00b7es", "Mi\u00df\u00b7ge\u00b7schick"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Umnebelt meinen Blick.", "tokens": ["Um\u00b7ne\u00b7belt", "mei\u00b7nen", "Blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der Wahnwitz der Bourbonen", "tokens": ["Der", "Wahn\u00b7witz", "der", "Bour\u00b7bo\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Entfe\u00dfelt die D\u00e4monen", "tokens": ["Ent\u00b7fe\u00b7\u00dfelt", "die", "D\u00e4\u00b7mo\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Der Revolution,", "tokens": ["Der", "Re\u00b7vo\u00b7lu\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und st\u00fcrzt sie von dem Thron.", "tokens": ["Und", "st\u00fcrzt", "sie", "von", "dem", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Vom Belt bis an die Tiber", "tokens": ["Vom", "Belt", "bis", "an", "die", "Ti\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Grassiert das Freiheitsfieber,", "tokens": ["Gras\u00b7siert", "das", "Frei\u00b7heits\u00b7fie\u00b7ber", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "So da\u00df es mi\u00dflich steht", "tokens": ["So", "da\u00df", "es", "mi\u00df\u00b7lich", "steht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Um F\u00fcrsten-Majest\u00e4t.", "tokens": ["Um", "F\u00fcrs\u00b7ten\u00b7Ma\u00b7je\u00b7st\u00e4t", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUI", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Man sieht des P\u00f6bels Haufen", "tokens": ["Man", "sieht", "des", "P\u00f6\u00b7bels", "Hau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sich mit Soldaten raufen,", "tokens": ["Sich", "mit", "Sol\u00b7da\u00b7ten", "rau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und eh' man um sich schaut,", "tokens": ["Und", "eh'", "man", "um", "sich", "schaut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Verbrennen sie die Mauth.", "tokens": ["Ver\u00b7bren\u00b7nen", "sie", "die", "Mauth", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Menschheit macht sich mausig,", "tokens": ["Die", "Menschheit", "macht", "sich", "mau\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADJD", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Da ist kein Volk so lausig,", "tokens": ["Da", "ist", "kein", "Volk", "so", "lau\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das nicht, vom Wahn verf\u00fchrt,", "tokens": ["Das", "nicht", ",", "vom", "Wahn", "ver\u00b7f\u00fchrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Sich wild rebellisch r\u00fchrt.", "tokens": ["Sich", "wild", "re\u00b7bel\u00b7lisch", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Die Zeit ist gar entsetzlich,", "tokens": ["Die", "Zeit", "ist", "gar", "ent\u00b7setz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Schaden unersetzlich;", "tokens": ["Der", "Scha\u00b7den", "un\u00b7er\u00b7setz\u00b7lich", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hilft nicht der liebe Gott,", "tokens": ["Hilft", "nicht", "der", "lie\u00b7be", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "So sind wir bankerott.", "tokens": ["So", "sind", "wir", "ban\u00b7ke\u00b7rott", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Mich st\u00f6ren die Nationen", "tokens": ["Mich", "st\u00f6\u00b7ren", "die", "Na\u00b7ti\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "In Lucubrationen.", "tokens": ["In", "Lu\u00b7cu\u00b7bra\u00b7ti\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich wei\u00df nicht, wo noch wie,", "tokens": ["Ich", "wei\u00df", "nicht", ",", "wo", "noch", "wie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "ADV", "KOKOM", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Bei dieser Anarchie.", "tokens": ["Bei", "die\u00b7ser", "An\u00b7ar\u00b7chie", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Wie soll ich nun berichten", "tokens": ["Wie", "soll", "ich", "nun", "be\u00b7rich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von R\u00f6mischen Geschichten?", "tokens": ["Von", "R\u00f6\u00b7mi\u00b7schen", "Ge\u00b7schich\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verhagelt ist ja schier", "tokens": ["Ver\u00b7ha\u00b7gelt", "ist", "ja", "schier"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Petersilje mir.", "tokens": ["Die", "Pe\u00b7ter\u00b7sil\u00b7je", "mir", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Wie viel ich auch Excerpte", "tokens": ["Wie", "viel", "ich", "auch", "Ex\u00b7cerp\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PPER", "ADV", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "In's Schreibepult mir kerbte,", "tokens": ["In's", "Schrei\u00b7be\u00b7pult", "mir", "kerb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So seh' ich doch kein Heil", "tokens": ["So", "seh'", "ich", "doch", "kein", "Heil"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "F\u00fcr einen dritten Theil.", "tokens": ["F\u00fcr", "ei\u00b7nen", "drit\u00b7ten", "Theil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Auch fehlt es jetzt an Fragern", "tokens": ["Auch", "fehlt", "es", "jetzt", "an", "Fra\u00b7gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nach R\u00f6mern und Carthagern.", "tokens": ["Nach", "R\u00f6\u00b7mern", "und", "Car\u00b7tha\u00b7gern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Senator und Tribun,", "tokens": ["Se\u00b7na\u00b7tor", "und", "Tri\u00b7bun", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Man l\u00e4\u00dft sie beide ruhn.", "tokens": ["Man", "l\u00e4\u00dft", "sie", "bei\u00b7de", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Doch kommen andre Zeiten,", "tokens": ["Doch", "kom\u00b7men", "and\u00b7re", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "F\u00fcr die will ich's bereiten;", "tokens": ["F\u00fcr", "die", "will", "ich's", "be\u00b7rei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "PIS", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die jetz'ge Barbarei", "tokens": ["Die", "jetz'\u00b7ge", "Bar\u00b7ba\u00b7rei"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Geht wohl einmal vorbei.", "tokens": ["Geht", "wohl", "ein\u00b7mal", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PTKVZ", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.14": {"line.1": {"text": "Im drei\u00dfigsten Jahrhundert", "tokens": ["Im", "drei\u00b7\u00dfigs\u00b7ten", "Jahr\u00b7hun\u00b7dert"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da wird mein Buch bewundert:", "tokens": ["Da", "wird", "mein", "Buch", "be\u00b7wun\u00b7dert", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da findet man den Schatz", "tokens": ["Da", "fin\u00b7det", "man", "den", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "An dem verborgnen Platz.", "tokens": ["An", "dem", "ver\u00b7borg\u00b7nen", "Platz", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}