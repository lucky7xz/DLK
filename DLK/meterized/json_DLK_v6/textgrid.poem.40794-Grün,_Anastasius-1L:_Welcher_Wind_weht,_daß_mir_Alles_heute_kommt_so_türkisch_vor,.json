{"textgrid.poem.40794": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Welcher Wind weht, da\u00df mir Alles heute kommt so t\u00fcrkisch vor,", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Welcher Wind weht, da\u00df mir Alles heute kommt so t\u00fcrkisch vor,", "tokens": ["Wel\u00b7cher", "Wind", "weht", ",", "da\u00df", "mir", "Al\u00b7les", "heu\u00b7te", "kommt", "so", "t\u00fcr\u00b7kisch", "vor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "PIS", "ADV", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df nun als Moschee und Harem ragt Palast und Kirch' empor,", "tokens": ["Da\u00df", "nun", "als", "Mo\u00b7schee", "und", "Ha\u00b7rem", "ragt", "Pa\u00b7last", "und", "Kirch'", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "KOUS", "NN", "KON", "NE", "VVFIN", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "----+-+-+-+-+-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Da\u00df gemeine Weiden, Pappeln, in Cipre\u00df' und Palm' verhext,", "tokens": ["Da\u00df", "ge\u00b7mei\u00b7ne", "Wei\u00b7den", ",", "Pap\u00b7peln", ",", "in", "Ci\u00b7pre\u00df'", "und", "Palm'", "ver\u00b7hext", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$,", "NN", "$,", "APPR", "NE", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+++-+-+", "measure": "unknown.measure.octa.plus"}, "line.4": {"text": "Und zum Weichselrohrkolosse mein Cigarrenst\u00fcmpfchen w\u00e4chst?", "tokens": ["Und", "zum", "Weich\u00b7sel\u00b7rohr\u00b7ko\u00b7los\u00b7se", "mein", "Ci\u00b7gar\u00b7ren\u00b7st\u00fcmpf\u00b7chen", "w\u00e4chst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.2": {"line.1": {"text": "Gl\u00fccklich ist des Marktes Springquell, der fast starb an Wassernoth,", "tokens": ["Gl\u00fcck\u00b7lich", "ist", "des", "Mark\u00b7tes", "Spring\u00b7quell", ",", "der", "fast", "starb", "an", "Was\u00b7ser\u00b7noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Doch jetzt, orientalisch prasselnd, diamantne S\u00fcndfluth droht;", "tokens": ["Doch", "jetzt", ",", "o\u00b7rien\u00b7ta\u00b7lisch", "pras\u00b7selnd", ",", "di\u00b7a\u00b7mant\u00b7ne", "S\u00fcnd\u00b7fluth", "droht", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADJD", "VVPP", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Gl\u00fccklichster doch bist du, Esel, dem Kameel gleich angesehn,", "tokens": ["Gl\u00fcck\u00b7lichs\u00b7ter", "doch", "bist", "du", ",", "E\u00b7sel", ",", "dem", "Ka\u00b7me\u00b7el", "gleich", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PPER", "$,", "NN", "$,", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.4": {"text": "W\u00e4hle frei, ob H\u00f6cker besser oder lange Ohren stehn?", "tokens": ["W\u00e4h\u00b7le", "frei", ",", "ob", "H\u00f6\u00b7cker", "bes\u00b7ser", "o\u00b7der", "lan\u00b7ge", "Oh\u00b7ren", "stehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "KOUS", "NN", "ADJD", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.3": {"line.1": {"text": "In der Marmorwanne streckt sich dort der stolze Renegat,", "tokens": ["In", "der", "Mar\u00b7mor\u00b7wan\u00b7ne", "streckt", "sich", "dort", "der", "stol\u00b7ze", "Re\u00b7ne\u00b7gat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Rosenwasser sprengt ein Diener, andre rings umstehn das Bad,", "tokens": ["Ro\u00b7sen\u00b7was\u00b7ser", "sprengt", "ein", "Die\u00b7ner", ",", "and\u00b7re", "rings", "um\u00b7stehn", "das", "Bad", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "PIS", "ADV", "VVFIN", "ART", "NE", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Wei\u00dfe Linnen, duft'ge Salben haltend, stehn sie tiefverneigt,", "tokens": ["Wei\u00b7\u00dfe", "Lin\u00b7nen", ",", "duft'\u00b7ge", "Sal\u00b7ben", "hal\u00b7tend", ",", "stehn", "sie", "tief\u00b7ver\u00b7neigt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "VVPP", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Harrend stumm, bis ihre Sonne aus des Meeres Becken steigt.", "tokens": ["Har\u00b7rend", "stumm", ",", "bis", "ih\u00b7re", "Son\u00b7ne", "aus", "des", "Mee\u00b7res", "Be\u00b7cken", "steigt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.4": {"line.1": {"text": "Den Gebieter h\u00e4lt Behagen bei der Nymphe lang zur\u00fcck,", "tokens": ["Den", "Ge\u00b7bie\u00b7ter", "h\u00e4lt", "Be\u00b7ha\u00b7gen", "bei", "der", "Nym\u00b7phe", "lang", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "APPR", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Eins nur m\u00fcht ihn: seinen R\u00fccken wegzudrehn dem Dienerblick;", "tokens": ["Eins", "nur", "m\u00fcht", "ihn", ":", "sei\u00b7nen", "R\u00fc\u00b7cken", "weg\u00b7zu\u00b7drehn", "dem", "Die\u00b7ner\u00b7blick", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "PPER", "$.", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Denn ein Mann, der ein gestempelt Eisen trug von ungef\u00e4hr,", "tokens": ["Denn", "ein", "Mann", ",", "der", "ein", "ge\u00b7stem\u00b7pelt", "Ei\u00b7sen", "trug", "von", "un\u00b7ge\u00b7f\u00e4hr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "ART", "VVPP", "NN", "VVFIN", "APPR", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Stie\u00df das gl\u00fch'nde in der Heimat ihm einst drauf von ungef\u00e4hr.", "tokens": ["Stie\u00df", "das", "gl\u00fch'n\u00b7de", "in", "der", "Hei\u00b7mat", "ihm", "einst", "drauf", "von", "un\u00b7ge\u00b7f\u00e4hr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "APPR", "ART", "NN", "PPER", "ADV", "PAV", "APPR", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.5": {"line.1": {"text": "\u00bbdank\u00ab \u2013 so l\u00e4\u00dft er sich vernehmen \u2013 \u00bbsei dir, heil'ger Gott, gesandt,\u2013", "tokens": ["\u00bb", "dank", "\u00ab", "\u2013", "so", "l\u00e4\u00dft", "er", "sich", "ver\u00b7neh\u00b7men", "\u2013", "\u00bb", "sei", "dir", ",", "heil'\u00b7ger", "Gott", ",", "ge\u00b7sandt", ",", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "APPR", "$(", "$(", "ADV", "VVFIN", "PPER", "PRF", "VVINF", "$(", "$(", "VAFIN", "PPER", "$,", "ADJA", "NN", "$,", "VVPP", "$,", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Doch nein, Allah dir! \u2013 denn also schreibst du dich ja hier zu Land;", "tokens": ["Doch", "nein", ",", "Al\u00b7lah", "dir", "!", "\u2013", "denn", "al\u00b7so", "schreibst", "du", "dich", "ja", "hier", "zu", "Land", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "NN", "PPER", "$.", "$(", "KON", "ADV", "VVFIN", "PPER", "PRF", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Bei den Wunden des \u2013 halt inne! Hier hei\u00dft's ja: bei Mahoms Bart!", "tokens": ["Bei", "den", "Wun\u00b7den", "des", "\u2013", "halt", "in\u00b7ne", "!", "Hier", "hei\u00dft's", "ja", ":", "bei", "Ma\u00b7homs", "Bart", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "$(", "VVFIN", "PTKVZ", "$.", "ADV", "VVFIN", "ADV", "$.", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Spr\u00f6de Christenzunge, Alles ist ja doch nur Redensart!", "tokens": ["Spr\u00f6\u00b7de", "Chris\u00b7ten\u00b7zun\u00b7ge", ",", "Al\u00b7les", "ist", "ja", "doch", "nur", "Re\u00b7den\u00b7sart", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PIS", "VAFIN", "ADV", "ADV", "ADV", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.6": {"line.1": {"text": "Heilige Redensart, dir dank' ich Ehren, Macht und Goldgewinn,", "tokens": ["Hei\u00b7li\u00b7ge", "Re\u00b7den\u00b7sart", ",", "dir", "dank'", "ich", "Eh\u00b7ren", ",", "Macht", "und", "Gold\u00b7ge\u00b7winn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VVFIN", "PPER", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+-+-+-+-+", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Da\u00df des gro\u00dfen Wessirs Liebling, Herz und rechte Hand ich bin,", "tokens": ["Da\u00df", "des", "gro\u00b7\u00dfen", "Wes\u00b7sirs", "Lieb\u00b7ling", ",", "Herz", "und", "rech\u00b7te", "Hand", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "NN", "$,", "NN", "KON", "ADJA", "NN", "PPER", "VAFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Da\u00df ich darf, statt heim'schen Sandes, Paradiesesau'n durchtraben,", "tokens": ["Da\u00df", "ich", "darf", ",", "statt", "heim'\u00b7schen", "San\u00b7des", ",", "Pa\u00b7ra\u00b7die\u00b7se\u00b7sau'n", "durch\u00b7tra\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "$,", "KOUI", "ADJA", "NN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Da\u00df mich, statt Teltower R\u00fcbchen, Corfu's Ananasse laben!", "tokens": ["Da\u00df", "mich", ",", "statt", "Tel\u00b7to\u00b7wer", "R\u00fcb\u00b7chen", ",", "Cor\u00b7fu's", "A\u00b7nan\u00b7as\u00b7se", "la\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "KOUI", "NN", "NN", "$,", "NE", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.7": {"line.1": {"text": "Da\u00df ich, Iman meinem Sch\u00fctzer, Recht und Unrecht darf bescheiden,", "tokens": ["Da\u00df", "ich", ",", "I\u00b7man", "mei\u00b7nem", "Sch\u00fct\u00b7zer", ",", "Recht", "und", "Un\u00b7recht", "darf", "be\u00b7schei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "NE", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "So da\u00df wir vom selben Strauche Ruthen oder Kr\u00e4nze schneiden;", "tokens": ["So", "da\u00df", "wir", "vom", "sel\u00b7ben", "Strau\u00b7che", "Ru\u00b7then", "o\u00b7der", "Kr\u00e4n\u00b7ze", "schnei\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "APPRART", "ADJA", "NN", "NE", "KON", "NN", "VVINF", "$."], "meter": "--+-+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Wie dem Ungar treu sein Schafpelz, ist das Recht uns ein Bew\u00e4hrtes,", "tokens": ["Wie", "dem", "Un\u00b7gar", "treu", "sein", "Schaf\u00b7pelz", ",", "ist", "das", "Recht", "uns", "ein", "Be\u00b7w\u00e4hr\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJD", "PPOSAT", "NN", "$,", "VAFIN", "ART", "NN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Rauhes ausw\u00e4rts: K\u00fchlung gibt es, Rauhes einw\u00e4rts: W\u00e4rme n\u00e4hrt es!", "tokens": ["Rau\u00b7hes", "aus\u00b7w\u00e4rts", ":", "K\u00fch\u00b7lung", "gibt", "es", ",", "Rau\u00b7hes", "ein\u00b7w\u00e4rts", ":", "W\u00e4r\u00b7me", "n\u00e4hrt", "es", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$.", "NN", "VVFIN", "PPER", "$,", "NN", "ADV", "$.", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.8": {"line.1": {"text": "Dank dir, da\u00df du mir die Feder und das Messer schliffst gleich scharf,", "tokens": ["Dank", "dir", ",", "da\u00df", "du", "mir", "die", "Fe\u00b7der", "und", "das", "Mes\u00b7ser", "schliffst", "gleich", "scharf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "KON", "ART", "NN", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da\u00df ich mit dem Herrn arbeiten an der Volksbegl\u00fcckung darf,", "tokens": ["Da\u00df", "ich", "mit", "dem", "Herrn", "ar\u00b7bei\u00b7ten", "an", "der", "Volks\u00b7be\u00b7gl\u00fc\u00b7ckung", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Morgens, eh' wir sie beginnen, den durchlaucht'gen Bart rasire,", "tokens": ["Mor\u00b7gens", ",", "eh'", "wir", "sie", "be\u00b7gin\u00b7nen", ",", "den", "durch\u00b7laucht'\u00b7gen", "Bart", "ra\u00b7si\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PPER", "VVINF", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Abends, wenn wir sie vollendet, H\u00fchneraugen operire!", "tokens": ["A\u00b7bends", ",", "wenn", "wir", "sie", "voll\u00b7en\u00b7det", ",", "H\u00fch\u00b7ner\u00b7au\u00b7gen", "o\u00b7pe\u00b7ri\u00b7re", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,", "NN", "VVFIN", "$."], "meter": "+-++--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.9": {"line.1": {"text": "Da\u00df ich im Poetenhaine jeden Steg ihm zeigen kann,", "tokens": ["Da\u00df", "ich", "im", "Poe\u00b7ten\u00b7hai\u00b7ne", "je\u00b7den", "Steg", "ihm", "zei\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PIAT", "NN", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Wie gesprochen und gesungen unser junges Turkistan,", "tokens": ["Wie", "ge\u00b7spro\u00b7chen", "und", "ge\u00b7sun\u00b7gen", "un\u00b7ser", "jun\u00b7ges", "Tur\u00b7kis\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "KON", "VVPP", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Sch\u00f6ne Stellen mit dem Schwarzstift, Schn\u00f6des mit dem R\u00f6thel streichend,", "tokens": ["Sch\u00f6\u00b7ne", "Stel\u00b7len", "mit", "dem", "Schwarz\u00b7stift", ",", "Schn\u00f6\u00b7des", "mit", "dem", "R\u00f6\u00b7thel", "strei\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "$,", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Frevelndem Gedankenvolke schnell die rothe Schnur darreichend.", "tokens": ["Fre\u00b7veln\u00b7dem", "Ge\u00b7dan\u00b7ken\u00b7vol\u00b7ke", "schnell", "die", "ro\u00b7the", "Schnur", "dar\u00b7rei\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.10": {"line.1": {"text": "Ach, wie ist die Volksbegl\u00fcckung der Gesundheit auch gedeihlich!", "tokens": ["Ach", ",", "wie", "ist", "die", "Volks\u00b7be\u00b7gl\u00fc\u00b7ckung", "der", "Ge\u00b7sund\u00b7heit", "auch", "ge\u00b7deih\u00b7lich", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "ART", "NN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Wie seithero Wang' und Waden mir sich runden so erfreulich,", "tokens": ["Wie", "sei\u00b7the\u00b7ro", "Wang'", "und", "Wa\u00b7den", "mir", "sich", "run\u00b7den", "so", "er\u00b7freu\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "KON", "NN", "PPER", "PRF", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Und ein B\u00e4uchlein schon Besitz nimmt von dem Platz, der leer sich fand,", "tokens": ["Und", "ein", "B\u00e4uch\u00b7lein", "schon", "Be\u00b7sitz", "nimmt", "von", "dem", "Platz", ",", "der", "leer", "sich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Gleich dem led'gen Stuhl Sankt Peters, harrend, da\u00df sein Pabst ernannt!\u00ab", "tokens": ["Gleich", "dem", "le\u00b7d'\u00b7gen", "Stuhl", "Sankt", "Pe\u00b7ters", ",", "har\u00b7rend", ",", "da\u00df", "sein", "Pabst", "er\u00b7nannt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "NE", "$,", "VVPP", "$,", "KOUS", "PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.11": {"line.1": {"text": "Pl\u00e4tschernd steigt er aus dem Bade. Ein Rechtgl\u00e4ub'ger, der da harrt,", "tokens": ["Pl\u00e4t\u00b7schernd", "steigt", "er", "aus", "dem", "Ba\u00b7de", ".", "Ein", "Recht\u00b7gl\u00e4ub'\u00b7ger", ",", "der", "da", "harrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Ihn zu salben und zu kleiden, streicht sich stolz den grauen Bart:", "tokens": ["Ihn", "zu", "sal\u00b7ben", "und", "zu", "klei\u00b7den", ",", "streicht", "sich", "stolz", "den", "grau\u00b7en", "Bart", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,", "VVFIN", "PRF", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.3": {"text": "\u00bbpreis dir, Allah, da\u00df geboren diesen Unhold fremdes Land,", "tokens": ["\u00bb", "preis", "dir", ",", "Al\u00b7lah", ",", "da\u00df", "ge\u00b7bo\u00b7ren", "die\u00b7sen", "Un\u00b7hold", "frem\u00b7des", "Land", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "NN", "$,", "KOUS", "VVPP", "PDAT", "NN", "ADJA", "NN", "$,"], "meter": "+--+--+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Und kein Mann zu seinem Amte in ganz Turkistan sich fand!\u00ab", "tokens": ["Und", "kein", "Mann", "zu", "sei\u00b7nem", "Am\u00b7te", "in", "ganz", "Tur\u00b7kis\u00b7tan", "sich", "fand", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPOSAT", "NN", "APPR", "ADV", "NN", "PRF", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}}}}