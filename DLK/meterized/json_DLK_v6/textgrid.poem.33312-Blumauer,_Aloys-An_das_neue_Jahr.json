{"textgrid.poem.33312": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "An das neue Jahr", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Warum, o neues Jahr! soll ich", "tokens": ["Wa\u00b7rum", ",", "o", "neu\u00b7es", "Jahr", "!", "soll", "ich"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$,", "FM", "ADJA", "NN", "$.", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich deiner Ankunft freuen?", "tokens": ["Mich", "dei\u00b7ner", "An\u00b7kunft", "freu\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Man wei\u00df ja niemals, soll man dich", "tokens": ["Man", "wei\u00df", "ja", "nie\u00b7mals", ",", "soll", "man", "dich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "$,", "VMFIN", "PIS", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr w\u00fcnschen, oder scheuen.", "tokens": ["Mehr", "w\u00fcn\u00b7schen", ",", "o\u00b7der", "scheu\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVINF", "$,", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Du trittst, ohn' anzuklopfen, ein,", "tokens": ["Du", "trittst", ",", "ohn'", "an\u00b7zu\u00b7klop\u00b7fen", ",", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "VVIZU", "$,", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und setzest fest dich nieder,", "tokens": ["Und", "set\u00b7zest", "fest", "dich", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und trollst dich, um recht grob zu sein,", "tokens": ["Und", "trollst", "dich", ",", "um", "recht", "grob", "zu", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUI", "ADV", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch ohne Urlaub wieder.", "tokens": ["Auch", "oh\u00b7ne", "Ur\u00b7laub", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Man hei\u00dft mit freudigem Gesicht", "tokens": ["Man", "hei\u00dft", "mit", "freu\u00b7di\u00b7gem", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich \u00fcberall willkommen,", "tokens": ["Dich", "\u00fc\u00b7be\u00b7rall", "will\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und doch verr\u00e4th dein Anblick nicht,", "tokens": ["Und", "doch", "ver\u00b7r\u00e4\u00b7th", "dein", "An\u00b7blick", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ob du als Freund gekommen.", "tokens": ["Ob", "du", "als", "Freund", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Was hilft es uns, wird gleich von dir", "tokens": ["Was", "hilft", "es", "uns", ",", "wird", "gleich", "von", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$,", "VAFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein eigen Buch geschrieben,", "tokens": ["Ein", "ei\u00b7gen", "Buch", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir wissen doch nicht, sollen wir", "tokens": ["Wir", "wis\u00b7sen", "doch", "nicht", ",", "sol\u00b7len", "wir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich hassen oder lieben.", "tokens": ["Dich", "has\u00b7sen", "o\u00b7der", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Gleich bei dem ersten Kompliment", "tokens": ["Gleich", "bei", "dem", "ers\u00b7ten", "Kom\u00b7pli\u00b7ment"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00e4ngst du schon an zu blasen,", "tokens": ["F\u00e4ngst", "du", "schon", "an", "zu", "bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und machst zugleich uns ein Pr\u00e4sent", "tokens": ["Und", "machst", "zu\u00b7gleich", "uns", "ein", "Pr\u00e4\u00b7sent"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PPER", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mit Frost und rothen Nasen.", "tokens": ["Mit", "Frost", "und", "ro\u00b7then", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da kommt Lakey, Friseur, Barbier", "tokens": ["Da", "kommt", "La\u00b7key", ",", "Fri\u00b7seur", ",", "Bar\u00b7bier"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "NE", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit dir in's Haus gelaufen,", "tokens": ["Mit", "dir", "in's", "Haus", "ge\u00b7lau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die uns den kleinsten Wunsch von dir", "tokens": ["Die", "uns", "den", "kleins\u00b7ten", "Wunsch", "von", "dir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Um baares Geld verkaufen.", "tokens": ["Um", "baa\u00b7res", "Geld", "ver\u00b7kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Kaum bist du da, so figurirt", "tokens": ["Kaum", "bist", "du", "da", ",", "so", "fi\u00b7gu\u00b7rirt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "$,", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Nam' auf allen Th\u00fcren,", "tokens": ["Dein", "Nam'", "auf", "al\u00b7len", "Th\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und was gedruckt, geschrieben wird,", "tokens": ["Und", "was", "ge\u00b7druckt", ",", "ge\u00b7schrie\u00b7ben", "wird", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "VVPP", "$,", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df deinen Namen f\u00fchren.", "tokens": ["Mu\u00df", "dei\u00b7nen", "Na\u00b7men", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ja mache dich nur breit damit:", "tokens": ["Ja", "ma\u00b7che", "dich", "nur", "breit", "da\u00b7mit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Schreibt man, damit sie jeder sieht,", "tokens": ["Schreibt", "man", ",", "da\u00b7mit", "sie", "je\u00b7der", "sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.9": {"line.1": {"text": "Du l\u00e4ssest dich das neue Jahr", "tokens": ["Du", "l\u00e4s\u00b7sest", "dich", "das", "neu\u00b7e", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Menschen tituliren,", "tokens": ["Von", "Men\u00b7schen", "ti\u00b7tu\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Und kannst doch weder graues Haar,", "tokens": ["Und", "kannst", "doch", "we\u00b7der", "grau\u00b7es", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch Jungfern renoviren.", "tokens": ["Noch", "Jung\u00b7fern", "re\u00b7no\u00b7vi\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Du machst die Damen und die Herr'n", "tokens": ["Du", "machst", "die", "Da\u00b7men", "und", "die", "Herr'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In ihrem Ehstand k\u00e4lter,", "tokens": ["In", "ih\u00b7rem", "Eh\u00b7stand", "k\u00e4l\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auch sieht dich nie ein M\u00e4dchen gern,", "tokens": ["Auch", "sieht", "dich", "nie", "ein", "M\u00e4d\u00b7chen", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du machst es ja nur \u00e4lter.", "tokens": ["Du", "machst", "es", "ja", "nur", "\u00e4l\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Nein, unser ein's ist nicht so toll,", "tokens": ["Nein", ",", "un\u00b7ser", "ein's", "ist", "nicht", "so", "toll", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPOSAT", "PIS", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich vor der Hand zu preisen;", "tokens": ["Dich", "vor", "der", "Hand", "zu", "prei\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Verdienst du es, so wird sich's wohl", "tokens": ["Ver\u00b7dienst", "du", "es", ",", "so", "wird", "sich's", "wohl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "VAFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Ende schon noch weisen.", "tokens": ["Am", "En\u00b7de", "schon", "noch", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Und juckt's dich denn nach Lob so sehr,", "tokens": ["Und", "juckt's", "dich", "denn", "nach", "Lob", "so", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So la\u00df dich's nicht verdriessen,", "tokens": ["So", "la\u00df", "dich's", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Uns deinen ganzen Kram vorher", "tokens": ["Uns", "dei\u00b7nen", "gan\u00b7zen", "Kram", "vor\u00b7her"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Bischen aufzuschliessen.", "tokens": ["Ein", "Bi\u00b7schen", "auf\u00b7zu\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Sag' an, wird heuer Korn und Wein", "tokens": ["Sag'", "an", ",", "wird", "heu\u00b7er", "Korn", "und", "Wein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "VAFIN", "ADV", "NN", "KON", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und Kraut und Kohl gedeihen?", "tokens": ["Und", "Kraut", "und", "Kohl", "ge\u00b7dei\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wird uns dein Lenz mit Sonnenschein", "tokens": ["Wird", "uns", "dein", "Lenz", "mit", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu rechter Zeit erfreuen?", "tokens": ["Zu", "rech\u00b7ter", "Zeit", "er\u00b7freu\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wird man nicht \u00fcber deine Pflicht", "tokens": ["Wird", "man", "nicht", "\u00fc\u00b7ber", "dei\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dich hageln seh'n und blitzen?", "tokens": ["Dich", "ha\u00b7geln", "seh'n", "und", "blit\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VVINF", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und werden wir im Sommer nicht", "tokens": ["Und", "wer\u00b7den", "wir", "im", "Som\u00b7mer", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "APPRART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie K\u00e4lberbraten schwitzen?", "tokens": ["Wie", "K\u00e4l\u00b7ber\u00b7bra\u00b7ten", "schwit\u00b7zen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Wirst du dich weigern, dann und wann", "tokens": ["Wirst", "du", "dich", "wei\u00b7gern", ",", "dann", "und", "wann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "VVFIN", "$,", "ADV", "KON", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Felder zu begiessen,", "tokens": ["Die", "Fel\u00b7der", "zu", "be\u00b7gies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und werden wir um Regen dann", "tokens": ["Und", "wer\u00b7den", "wir", "um", "Re\u00b7gen", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dich wieder bitten m\u00fcssen?", "tokens": ["Dich", "wie\u00b7der", "bit\u00b7ten", "m\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und wenn du regnest, wird dir's da", "tokens": ["Und", "wenn", "du", "reg\u00b7nest", ",", "wird", "dir's", "da"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht etwa g\u00e4h behagen,", "tokens": ["Nicht", "et\u00b7wa", "g\u00e4h", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Herren all', ", "tokens": ["Die", "Her\u00b7ren", "all'", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Vom Graben wegzujagen?", "tokens": ["Vom", "Gra\u00b7ben", "weg\u00b7zu\u00b7ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Wirst du mit uns am Ende, wie", "tokens": ["Wirst", "du", "mit", "uns", "am", "En\u00b7de", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "APPRART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein toller Bruder, spassen,", "tokens": ["Dein", "tol\u00b7ler", "Bru\u00b7der", ",", "spas\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und uns mit Blitz und Donner, wie", "tokens": ["Und", "uns", "mit", "Blitz", "und", "Don\u00b7ner", ",", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "APPR", "NN", "KON", "NN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Grobian, verlassen?", "tokens": ["Der", "Gro\u00b7bi\u00b7an", ",", "ver\u00b7las\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Und was an dir politisch ist,", "tokens": ["Und", "was", "an", "dir", "po\u00b7li\u00b7tisch", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sprich, wird uns das auch frommen?", "tokens": ["Sprich", ",", "wird", "uns", "das", "auch", "from\u00b7men", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "VAFIN", "PPER", "PDS", "ADV", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es wird ja wohl der Antichrist", "tokens": ["Es", "wird", "ja", "wohl", "der", "An\u00b7ti\u00b7ch\u00b7rist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit dir nicht etwa kommen?", "tokens": ["Mit", "dir", "nicht", "et\u00b7wa", "kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Wird heuer, wie die Sage geht:", "tokens": ["Wird", "heu\u00b7er", ",", "wie", "die", "Sa\u00b7ge", "geht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Hirt und Schafstall werden?", "tokens": ["Ein", "Hirt", "und", "Schaf\u00b7stall", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sag' oder ist der Herr Prophet", "tokens": ["Sag'", "o\u00b7der", "ist", "der", "Herr", "Pro\u00b7phet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das einz'ge Schaf auf Erden?", "tokens": ["Das", "einz'\u00b7ge", "Schaf", "auf", "Er\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Wird Aberglaube die Vernunft", "tokens": ["Wird", "A\u00b7berg\u00b7lau\u00b7be", "die", "Ver\u00b7nunft"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Wien noch lang bekriegen,", "tokens": ["In", "Wi\u00b7en", "noch", "lang", "be\u00b7krie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und wird die Wahrheit bald die Zunft", "tokens": ["Und", "wird", "die", "Wahr\u00b7heit", "bald", "die", "Zunft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Eiferer besiegen?", "tokens": ["Der", "Ei\u00b7fe\u00b7rer", "be\u00b7sie\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Sag' an, wird's bei den wenigen", "tokens": ["Sag'", "an", ",", "wird's", "bei", "den", "we\u00b7ni\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "VAFIN", "APPR", "ART", "PIAT"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Apostelbriefen bleiben,", "tokens": ["A\u00b7pos\u00b7tel\u00b7brie\u00b7fen", "blei\u00b7ben", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wird kein Bischof mehr so sch\u00f6n", "tokens": ["Und", "wird", "kein", "Bi\u00b7schof", "mehr", "so", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIAT", "NN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An seine Sch\u00e4flein schreiben?", "tokens": ["An", "sei\u00b7ne", "Sch\u00e4f\u00b7lein", "schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Wird Pater Fast denn hier fortan", "tokens": ["Wird", "Pa\u00b7ter", "Fast", "denn", "hier", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "NE", "KON", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Amt der Sendung schmieren,", "tokens": ["Im", "Amt", "der", "Sen\u00b7dung", "schmie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wird man den geplagten Mann", "tokens": ["Und", "wird", "man", "den", "ge\u00b7plag\u00b7ten", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht einmal jubiliren?", "tokens": ["Nicht", "ein\u00b7mal", "ju\u00b7bi\u00b7li\u00b7ren", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Wird Pater Pochlin, um in Eil", "tokens": ["Wird", "Pa\u00b7ter", "Poch\u00b7lin", ",", "um", "in", "Eil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "NE", "$,", "KOUI", "APPR", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Die Gegner zu verjagen,", "tokens": ["Die", "Geg\u00b7ner", "zu", "ver\u00b7ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Noch ferner mit dem Fleischerbeil", "tokens": ["Noch", "fer\u00b7ner", "mit", "dem", "Flei\u00b7scher\u00b7beil"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach ihren Stirnen schlagen?", "tokens": ["Nach", "ih\u00b7ren", "Stir\u00b7nen", "schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Wird unser P\u00f6bel, gro\u00df und klein,", "tokens": ["Wird", "un\u00b7ser", "P\u00f6\u00b7bel", ",", "gro\u00df", "und", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch immerfort in Haufen", "tokens": ["Noch", "im\u00b7mer\u00b7fort", "in", "Hau\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mit gleicher Lust zum Rabenstein,", "tokens": ["Mit", "glei\u00b7cher", "Lust", "zum", "Ra\u00b7ben\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und in die Hetze laufen?", "tokens": ["Und", "in", "die", "Het\u00b7ze", "lau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Wird er noch stets in's Schauspiel geh'n,", "tokens": ["Wird", "er", "noch", "stets", "in's", "Schau\u00b7spiel", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Um da mit allen Vieren", "tokens": ["Um", "da", "mit", "al\u00b7len", "Vie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem Purzelbaum des Sterbenden", "tokens": ["Dem", "Pur\u00b7zel\u00b7baum", "des", "Ster\u00b7ben\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Im St\u00fcck zu applaudiren?", "tokens": ["Im", "St\u00fcck", "zu", "ap\u00b7plau\u00b7di\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Sag' an, wird uns're Scriblerschaar", "tokens": ["Sag'", "an", ",", "wird", "un\u00b7s'\u00b7re", "Scrib\u00b7ler\u00b7schaar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "VAFIN", "PPOSAT", "NN"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Das Sudeln nicht verdriessen,", "tokens": ["Das", "Su\u00b7deln", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und werd' ich l\u00e4nger, als dies Jahr,", "tokens": ["Und", "werd'", "ich", "l\u00e4n\u00b7ger", ",", "als", "dies", "Jahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "PDS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie recensiren m\u00fcssen?", "tokens": ["Sie", "re\u00b7cen\u00b7si\u00b7ren", "m\u00fcs\u00b7sen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Erf\u00fcllest du dies alles hier", "tokens": ["Er\u00b7f\u00fcl\u00b7lest", "du", "dies", "al\u00b7les", "hier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDS", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach Wunsch vor deinem Ende,", "tokens": ["Nach", "Wunsch", "vor", "dei\u00b7nem", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So preis' ich dich, und klopfe dir", "tokens": ["So", "preis'", "ich", "dich", ",", "und", "klop\u00b7fe", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Freuden in die H\u00e4nde.", "tokens": ["Mit", "Freu\u00b7den", "in", "die", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}