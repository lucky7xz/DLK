{"textgrid.poem.46181": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Von \u00fcbersch\u00f6nen augen", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O der lieb wahrer hort und port,", "tokens": ["O", "der", "lieb", "wah\u00b7rer", "hort", "und", "port", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJD", "ADJA", "NN", "KON", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "ihr meiner sch\u00f6nen Myrten augen,", "tokens": ["ihr", "mei\u00b7ner", "sch\u00f6\u00b7nen", "Myr\u00b7ten", "au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wan anderst ein so schlechtes wort", "tokens": ["wan", "an\u00b7derst", "ein", "so", "schlech\u00b7tes", "wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "kan euch zu nennen gnugsam taugen!", "tokens": ["kan", "euch", "zu", "nen\u00b7nen", "gnug\u00b7sam", "tau\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKZU", "VVINF", "ADJD", "VVFIN", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.5": {"text": "zwar augen kan man euch, weil ihrem angesicht", "tokens": ["zwar", "au\u00b7gen", "kan", "man", "euch", ",", "weil", "ih\u00b7rem", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NN", "VMFIN", "PIS", "PPER", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ihr klare augen seid, zu sein verleugnen nicht,", "tokens": ["ihr", "kla\u00b7re", "au\u00b7gen", "seid", ",", "zu", "sein", "ver\u00b7leug\u00b7nen", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$,", "APPR", "PPOSAT", "ADJA", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "doch darf man euch kaum augen nennen,", "tokens": ["doch", "darf", "man", "euch", "kaum", "au\u00b7gen", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PPER", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "weil ihr so sch\u00f6n und tugendhaft,", "tokens": ["weil", "ihr", "so", "sch\u00f6n", "und", "tu\u00b7gend\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "sondern von wegen eurer kraft", "tokens": ["son\u00b7dern", "von", "we\u00b7gen", "eu\u00b7rer", "kraft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "mu\u00df man euch himmelisch bekennen.", "tokens": ["mu\u00df", "man", "euch", "him\u00b7me\u00b7lisch", "be\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPER", "ADJD", "VVINF", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.2": {"line.1": {"text": "Zwar mit so wunderreichem pracht,", "tokens": ["Zwar", "mit", "so", "wun\u00b7der\u00b7rei\u00b7chem", "pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "damit sich dise augen zieren,", "tokens": ["da\u00b7mit", "sich", "di\u00b7se", "au\u00b7gen", "zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "kan, es sei gleich tag oder nacht,", "tokens": ["kan", ",", "es", "sei", "gleich", "tag", "o\u00b7der", "nacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PPER", "VAFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "der himmel selbs niemal prachtieren.", "tokens": ["der", "him\u00b7mel", "selbs", "nie\u00b7mal", "prach\u00b7tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "wan schon dem himmel gleich ihr heiter glatte stirn", "tokens": ["wan", "schon", "dem", "him\u00b7mel", "gleich", "ihr", "hei\u00b7ter", "glat\u00b7te", "stirn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "erleuchtet diese welt durch euch, als ein gestirn:", "tokens": ["er\u00b7leuch\u00b7tet", "die\u00b7se", "welt", "durch", "euch", ",", "als", "ein", "ge\u00b7stirn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPER", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "so ist jedoch in euch vermischet", "tokens": ["so", "ist", "je\u00b7doch", "in", "euch", "ver\u00b7mi\u00b7schet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "das braun und liecht mit solchem schein,", "tokens": ["das", "braun", "und", "liecht", "mit", "sol\u00b7chem", "schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "da\u00df es ja mu\u00df ein wunder sein,", "tokens": ["da\u00df", "es", "ja", "mu\u00df", "ein", "wun\u00b7der", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "wie ihrer jedes uns erfrischet.", "tokens": ["wie", "ih\u00b7rer", "je\u00b7des", "uns", "er\u00b7fri\u00b7schet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "PIAT", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So darf auch mein warhafter mund", "tokens": ["So", "darf", "auch", "mein", "war\u00b7haf\u00b7ter", "mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "euch mit der sonnen nicht vergleichen,", "tokens": ["euch", "mit", "der", "son\u00b7nen", "nicht", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "weil ihr glanz, wie dem umkreis kund,", "tokens": ["weil", "ihr", "glanz", ",", "wie", "dem", "um\u00b7kreis", "kund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PWAV", "ART", "NN", "PTKVZ", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "mu\u00df euerm glanz und w\u00fcrkung weichen:", "tokens": ["mu\u00df", "eu\u00b7erm", "glanz", "und", "w\u00fcr\u00b7kung", "wei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und zweier sonnen schein bedeutet krieg und leid,", "tokens": ["und", "zwei\u00b7er", "son\u00b7nen", "schein", "be\u00b7deu\u00b7tet", "krieg", "und", "leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "VVFIN", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "da euer zwillingliecht erwecket frid und freud;", "tokens": ["da", "eu\u00b7er", "zwil\u00b7ling\u00b7liecht", "er\u00b7we\u00b7cket", "frid", "und", "freud", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "die sonn durch ihre brunst beschweret,", "tokens": ["die", "sonn", "durch", "ih\u00b7re", "brunst", "be\u00b7schwe\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die sie anschauen mit verdru\u00df,", "tokens": ["die", "sie", "an\u00b7schau\u00b7en", "mit", "ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "da ihr mit s\u00fc\u00dfem lusts eingu\u00df", "tokens": ["da", "ihr", "mit", "s\u00fc\u00b7\u00dfem", "lusts", "ein\u00b7gu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "durch das gesicht das herz vermehret.", "tokens": ["durch", "das", "ge\u00b7sicht", "das", "herz", "ver\u00b7meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer sich, gl\u00fcckselig, kan in euch", "tokens": ["Wer", "sich", ",", "gl\u00fcck\u00b7se\u00b7lig", ",", "kan", "in", "euch"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PRF", "$,", "ADJD", "$,", "VMFIN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "besehen, wird reichlich gesegnet,", "tokens": ["be\u00b7se\u00b7hen", ",", "wird", "reich\u00b7lich", "ge\u00b7seg\u00b7net", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "dan ihr ganz wunderlich liebreich", "tokens": ["dan", "ihr", "ganz", "wun\u00b7der\u00b7lich", "lieb\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ADV", "ADJD", "ADJD"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "sein herz mit freuden \u00fcberregnet;", "tokens": ["sein", "herz", "mit", "freu\u00b7den", "\u00fc\u00b7ber\u00b7reg\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die strahlen eures liechts und eures anblicks glanz", "tokens": ["die", "strah\u00b7len", "eu\u00b7res", "liechts", "und", "eu\u00b7res", "an\u00b7blicks", "glanz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "seind zugleich der lieb pfeil und auch der keuschheit schanz;", "tokens": ["seind", "zu\u00b7gleich", "der", "lieb", "pfeil", "und", "auch", "der", "keuschheit", "schanz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "NN", "KON", "ADV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "dan sie mit lieb und lust entleben", "tokens": ["dan", "sie", "mit", "lieb", "und", "lust", "ent\u00b7le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPR", "ADJD", "KON", "NN", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "und dan mit s\u00fc\u00dfer forcht und ehr", "tokens": ["und", "dan", "mit", "s\u00fc\u00b7\u00dfer", "forcht", "und", "ehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "widrum belebend, uns die lehr,", "tokens": ["wid\u00b7rum", "be\u00b7le\u00b7bend", ",", "uns", "die", "lehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "$,", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "den engeln gleich zu leben, geben.", "tokens": ["den", "en\u00b7geln", "gleich", "zu", "le\u00b7ben", ",", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Daher, o augen braun und klar,", "tokens": ["Da\u00b7her", ",", "o", "au\u00b7gen", "braun", "und", "klar", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "FM", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "schwarzlecht und hell, wie blitz und dunder;", "tokens": ["schwarz\u00b7lecht", "und", "hell", ",", "wie", "blitz", "und", "dun\u00b7der", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "$,", "PWAV", "ADJD", "KON", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der sch\u00f6nheit und lieb wieg und bahr,", "tokens": ["der", "sch\u00f6n\u00b7heit", "und", "lieb", "wieg", "und", "bahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "der natur schatz und gr\u00f6stes wunder,", "tokens": ["der", "na\u00b7tur", "schatz", "und", "gr\u00f6s\u00b7tes", "wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "ganz \u00fcbermenschlich sch\u00f6n mu\u00df ich mit leid und wohn", "tokens": ["ganz", "\u00fc\u00b7ber\u00b7menschlich", "sch\u00f6n", "mu\u00df", "ich", "mit", "leid", "und", "wohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "VMFIN", "PPER", "APPR", "ADJD", "KON", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "bekennen euch zugleich der g\u00f6tter straf und lohn:", "tokens": ["be\u00b7ken\u00b7nen", "euch", "zu\u00b7gleich", "der", "g\u00f6t\u00b7ter", "straf", "und", "lohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "VVFIN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "dan ihr k\u00f6nt ja mit euern blicken,", "tokens": ["dan", "ihr", "k\u00f6nt", "ja", "mit", "eu\u00b7ern", "bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "der sch\u00f6nheit, lieb und tugend sitz,", "tokens": ["der", "sch\u00f6n\u00b7heit", ",", "lieb", "und", "tu\u00b7gend", "sitz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "wie durch gesch\u00fctz, hitz, spitz und blitz", "tokens": ["wie", "durch", "ge\u00b7sch\u00fctz", ",", "hitz", ",", "spitz", "und", "blitz"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "NE", "$,", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "das herz zerst\u00fccken und erquicken.", "tokens": ["das", "herz", "zer\u00b7st\u00fc\u00b7cken", "und", "er\u00b7qui\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}