{"dta.poem.19083": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxV.  Auf Herrn Johann Andreas Ro-  \n thens 40. Jahrs-Tag.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Der du der Hertzen-K\u00f6nig bist,", "tokens": ["Der", "du", "der", "Hert\u00b7zen\u00b7K\u00f6\u00b7nig", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und aller Kr\u00e4fte jener Welten,", "tokens": ["Und", "al\u00b7ler", "Kr\u00e4f\u00b7te", "je\u00b7ner", "Wel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dem unser Hertz gereget ist;", "tokens": ["Dem", "un\u00b7ser", "Hertz", "ge\u00b7re\u00b7get", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df seine Regung vor dir gelten:", "tokens": ["La\u00df", "sei\u00b7ne", "Re\u00b7gung", "vor", "dir", "gel\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dir opfert auf der ", "tokens": ["Dir", "op\u00b7fert", "auf", "der"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ein Hauffe deiner Unterthanen", "tokens": ["Ein", "Hauf\u00b7fe", "dei\u00b7ner", "Un\u00b7ter\u00b7tha\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Und die vom Feind erk\u00e4mpfte ", "tokens": ["Und", "die", "vom", "Feind", "er\u00b7k\u00e4mpf\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Uns ist zwar wohl bekannt,", "tokens": ["Uns", "ist", "zwar", "wohl", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Wie di\u00df Geschenck bewandt.", "tokens": ["Wie", "di\u00df", "Ge\u00b7schenck", "be\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Du pflegst nichts halbes anzunehmen.", "tokens": ["Du", "pflegst", "nichts", "hal\u00b7bes", "an\u00b7zu\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Bi\u00df da\u00df wir ", "tokens": ["Bi\u00df", "da\u00df", "wir"], "token_info": ["word", "word", "word"], "pos": ["APPR", "KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Die theure ", "tokens": ["Die", "theu\u00b7re"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Mu\u00df sich der treue Theil noch sch\u00e4men.", "tokens": ["Mu\u00df", "sich", "der", "treu\u00b7e", "Theil", "noch", "sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Doch werde dir ein Lob ", "tokens": ["Doch", "wer\u00b7de", "dir", "ein", "Lob"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Was sich an diesem Tage findet.", "tokens": ["Was", "sich", "an", "die\u00b7sem", "Ta\u00b7ge", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es lobet dich di\u00df ", "tokens": ["Es", "lo\u00b7bet", "dich", "di\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PDS"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Am ", "tokens": ["Am"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Schon ", "tokens": ["Schon"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Und bi\u00df daher in guter Ruh", "tokens": ["Und", "bi\u00df", "da\u00b7her", "in", "gu\u00b7ter", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dein Evangelium bedienen;", "tokens": ["Dein", "E\u00b7van\u00b7ge\u00b7li\u00b7um", "be\u00b7die\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Zu einer Zions-Zier", "tokens": ["Zu", "ei\u00b7ner", "Zi\u00b7ons\u00b7Zier"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Nun vor ", "tokens": ["Nun", "vor"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.10": {"text": "Vor manche Nation,", "tokens": ["Vor", "man\u00b7che", "Na\u00b7tion", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Ja in den Banden schon,", "tokens": ["Ja", "in", "den", "Ban\u00b7den", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.12": {"text": "Zum Theil gebraucht, theils zubereitet.", "tokens": ["Zum", "Theil", "ge\u00b7braucht", ",", "theils", "zu\u00b7be\u00b7rei\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Ward auch den Tag mit uns verkn\u00fcpfet.", "tokens": ["Ward", "auch", "den", "Tag", "mit", "uns", "ver\u00b7kn\u00fcp\u00b7fet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch di\u00df ist das geringste Heyl,", "tokens": ["Doch", "di\u00df", "ist", "das", "ge\u00b7rings\u00b7te", "Heyl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dar\u00fcber unser Hertze h\u00fcpfet.", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "un\u00b7ser", "Hert\u00b7ze", "h\u00fcp\u00b7fet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die allergr\u00f6ste Gnade war", "tokens": ["Die", "al\u00b7ler\u00b7gr\u00f6s\u00b7te", "Gna\u00b7de", "war"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df eben heute gleich ein Jahr", "tokens": ["Da\u00df", "e\u00b7ben", "heu\u00b7te", "gleich", "ein", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sich alles unter dich gebeuget,", "tokens": ["Sich", "al\u00b7les", "un\u00b7ter", "dich", "ge\u00b7beu\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da man das freye Volck", "tokens": ["Da", "man", "das", "frey\u00b7e", "Volck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Von dieser Zeugen-Wolck", "tokens": ["Von", "die\u00b7ser", "Zeu\u00b7gen\u00b7Wolck"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Bem\u00fchet war in ", "tokens": ["Be\u00b7m\u00fc\u00b7het", "war", "in"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "VAFIN", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Und zu der Einigkeit,", "tokens": ["Und", "zu", "der", "Ei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Die dein Befehl gebeut,", "tokens": ["Die", "dein", "Be\u00b7fehl", "ge\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Sich jederman bereden lassen.", "tokens": ["Sich", "je\u00b7der\u00b7man", "be\u00b7re\u00b7den", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PIS", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Gewi\u00df, wer um die Kirche wei\u00df,", "tokens": ["Ge\u00b7wi\u00df", ",", "wer", "um", "die", "Kir\u00b7che", "wei\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ums Geheimni\u00df deiner Heerde,", "tokens": ["Und", "ums", "Ge\u00b7heim\u00b7ni\u00df", "dei\u00b7ner", "Heer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der kennt auch deiner Knechte Schwei\u00df,", "tokens": ["Der", "kennt", "auch", "dei\u00b7ner", "Knech\u00b7te", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und was dabey erlitten werde:", "tokens": ["Und", "was", "da\u00b7bey", "er\u00b7lit\u00b7ten", "wer\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PAV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der wei\u00df zu allem Uberflu\u00df,", "tokens": ["Der", "wei\u00df", "zu", "al\u00b7lem", "U\u00b7ber\u00b7flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wovon wir hier nur wenig stammlen,", "tokens": ["Wo\u00b7von", "wir", "hier", "nur", "we\u00b7nig", "stamm\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was einer da erfahren mu\u00df,", "tokens": ["Was", "ei\u00b7ner", "da", "er\u00b7fah\u00b7ren", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wo sich viel Kinder GOttes sammlen.", "tokens": ["Wo", "sich", "viel", "Kin\u00b7der", "Got\u00b7tes", "samm\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PIAT", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Und wer das Lied vernimmt,", "tokens": ["Und", "wer", "das", "Lied", "ver\u00b7nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Das Paulus angestimmt:", "tokens": ["Das", "Pau\u00b7lus", "an\u00b7ge\u00b7stimmt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Der siehet einen Plan", "tokens": ["Der", "sie\u00b7het", "ei\u00b7nen", "Plan"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Halb vor ein Wunder an,", "tokens": ["Halb", "vor", "ein", "Wun\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Wo sich die Br\u00fcder ", "tokens": ["Wo", "sich", "die", "Br\u00fc\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Die Welt, die noch im Argen liegt", "tokens": ["Die", "Welt", ",", "die", "noch", "im", "Ar\u00b7gen", "liegt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und in der Tiefe des Verderbens,", "tokens": ["Und", "in", "der", "Tie\u00b7fe", "des", "Ver\u00b7der\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wird in dem Todes-Schlaf gewiegt:", "tokens": ["Wird", "in", "dem", "To\u00b7des\u00b7Schlaf", "ge\u00b7wiegt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da braucht es keines neuen Sterbens,", "tokens": ["Da", "braucht", "es", "kei\u00b7nes", "neu\u00b7en", "Ster\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "All ein, so bald die Stunde blickt,", "tokens": ["All", "ein", ",", "so", "bald", "die", "Stun\u00b7de", "blickt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df JEsu Wort in einer K\u00fcrtze,", "tokens": ["Da\u00df", "Je\u00b7su", "Wort", "in", "ei\u00b7ner", "K\u00fcrt\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Den Grund des Hertzens \u00fcberst\u00fcrtze,", "tokens": ["Den", "Grund", "des", "Hert\u00b7zens", "\u00fc\u00b7bers\u00b7t\u00fcrt\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenns alle Aeste bricht,", "tokens": ["Wenns", "al\u00b7le", "A\u00b7es\u00b7te", "bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Durch B\u00e4tt und Furchen sticht,", "tokens": ["Durch", "B\u00e4tt", "und", "Fur\u00b7chen", "sticht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Um sich den Acker aufzureissen,", "tokens": ["Um", "sich", "den", "A\u00b7cker", "auf\u00b7zu\u00b7reis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und bi\u00df aufs Leben trift:", "tokens": ["Und", "bi\u00df", "aufs", "Le\u00b7ben", "trift", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Da braust der alte Gift,", "tokens": ["Da", "braust", "der", "al\u00b7te", "Gift", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Und all es hebet an zu kreissen.", "tokens": ["Und", "all", "es", "he\u00b7bet", "an", "zu", "kreis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PPER", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Hirte, de\u00df die Schafe sind,", "tokens": ["Der", "Hir\u00b7te", ",", "de\u00df", "die", "Scha\u00b7fe", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der will sie auf die Achseln nehmen:", "tokens": ["Der", "will", "sie", "auf", "die", "Ach\u00b7seln", "neh\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch, da\u00df sich da kein Zwang befindt,", "tokens": ["Doch", ",", "da\u00df", "sich", "da", "kein", "Zwang", "be\u00b7findt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PRF", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es mu\u00df sich alles selbst bequemen.", "tokens": ["Es", "mu\u00df", "sich", "al\u00b7les", "selbst", "be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PIS", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Auch hat der Seelen-Feind noch Macht", "tokens": ["Auch", "hat", "der", "See\u00b7len\u00b7Feind", "noch", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Ungegr\u00fcndten zu verwirren:", "tokens": ["Die", "Un\u00b7ge\u00b7gr\u00fcnd\u00b7ten", "zu", "ver\u00b7wir\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da werden Meynungen gebracht;", "tokens": ["Da", "wer\u00b7den", "Mey\u00b7nun\u00b7gen", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Daran sich theure Seelen irren.", "tokens": ["Da\u00b7ran", "sich", "theu\u00b7re", "See\u00b7len", "ir\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Hier spricht ein treuer Knecht:", "tokens": ["Hier", "spricht", "ein", "treu\u00b7er", "Knecht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Mit Beten ringst du recht,", "tokens": ["Mit", "Be\u00b7ten", "ringst", "du", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Der Heyland mu\u00df sich dein erbarmen.", "tokens": ["Der", "Hey\u00b7land", "mu\u00df", "sich", "dein", "er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Dort heists: ", "tokens": ["Dort", "heists", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Die Seele m\u00fchet sich,", "tokens": ["Die", "See\u00b7le", "m\u00fc\u00b7het", "sich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Und r\u00fcckt sich aus den Gnaden-Armen.", "tokens": ["Und", "r\u00fcckt", "sich", "aus", "den", "Gna\u00b7den\u00b7Ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Damit ist Christi Schaar gezweyt:", "tokens": ["Da\u00b7mit", "ist", "Chris\u00b7ti", "Schaar", "ge\u00b7zweyt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein iedes Theil will JEsum haben.", "tokens": ["Ein", "ie\u00b7des", "Theil", "will", "Je\u00b7sum", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VMFIN", "NE", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der spricht: ", "tokens": ["Der", "spricht", ":"], "token_info": ["word", "word", "punct"], "pos": ["PDS", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Ich werde mich zu tode traben,", "tokens": ["Ich", "wer\u00b7de", "mich", "zu", "to\u00b7de", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn ich mir selber helffen will,", "tokens": ["Wenn", "ich", "mir", "sel\u00b7ber", "helf\u00b7fen", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er mu\u00df mir erst die Kr\u00e4fte geben,", "tokens": ["Er", "mu\u00df", "mir", "erst", "die", "Kr\u00e4f\u00b7te", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und eh' ich sein Gebot erf\u00fcll,", "tokens": ["Und", "eh'", "ich", "sein", "Ge\u00b7bot", "er\u00b7f\u00fcll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mu\u00df ich vor allen Dingen leben.", "tokens": ["Mu\u00df", "ich", "vor", "al\u00b7len", "Din\u00b7gen", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Da spricht der andre nun:", "tokens": ["Da", "spricht", "der", "and\u00b7re", "nun", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "So wird er mir den Lohn nicht rauben,", "tokens": ["So", "wird", "er", "mir", "den", "Lohn", "nicht", "rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Die Welt hat keinen Streit;", "tokens": ["Die", "Welt", "hat", "kei\u00b7nen", "Streit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Denn sie ist gleich so weit", "tokens": ["Denn", "sie", "ist", "gleich", "so", "weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Den Schafen, die des Hirten Hand", "tokens": ["Den", "Scha\u00b7fen", ",", "die", "des", "Hir\u00b7ten", "Hand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Selbst auf die Weide hingef\u00fchret,", "tokens": ["Selbst", "auf", "die", "Wei\u00b7de", "hin\u00b7ge\u00b7f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ist sie gesund und wohl bekannt:", "tokens": ["Ist", "sie", "ge\u00b7sund", "und", "wohl", "be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die andern werden matt gesp\u00fchret.", "tokens": ["Die", "an\u00b7dern", "wer\u00b7den", "matt", "ge\u00b7sp\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie mercken, da\u00df es so nicht geht,", "tokens": ["Sie", "mer\u00b7cken", ",", "da\u00df", "es", "so", "nicht", "geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "KOUS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der HErr mu\u00df ihnen ", "tokens": ["Der", "Herr", "mu\u00df", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Wo etwan ein Erk\u00e4nntni\u00df steht", "tokens": ["Wo", "et\u00b7wan", "ein", "Er\u00b7k\u00e4nnt\u00b7ni\u00df", "steht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Vom neuen Himmel oder Erden,", "tokens": ["Vom", "neu\u00b7en", "Him\u00b7mel", "o\u00b7der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Da greiffen sie bald zu,", "tokens": ["Da", "greif\u00b7fen", "sie", "bald", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Da suchen sie sich Ruh!", "tokens": ["Da", "su\u00b7chen", "sie", "sich", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Jhr Anfang ist der andern Ende.", "tokens": ["Ihr", "An\u00b7fang", "ist", "der", "an\u00b7dern", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da lauffen sie sich tumm,", "tokens": ["Da", "lauf\u00b7fen", "sie", "sich", "tumm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Und kehren doch wohl um", "tokens": ["Und", "keh\u00b7ren", "doch", "wohl", "um"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "In ihres Hirten treue H\u00e4nde.", "tokens": ["In", "ih\u00b7res", "Hir\u00b7ten", "treu\u00b7e", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Inzwischen hat die Welt gelacht,", "tokens": ["I\u00b7nzwi\u00b7schen", "hat", "die", "Welt", "ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die uns den Holtz-Weg lauffen sehen.", "tokens": ["Die", "uns", "den", "Holtz\u00b7Weg", "lauf\u00b7fen", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Seelen, die es recht gemacht,", "tokens": ["Die", "See\u00b7len", ",", "die", "es", "recht", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind da, die Jrrenden zu schm\u00e4hen,", "tokens": ["Sind", "da", ",", "die", "Jr\u00b7ren\u00b7den", "zu", "schm\u00e4\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df einer, der herum geirrt,", "tokens": ["Da\u00df", "ei\u00b7ner", ",", "der", "he\u00b7rum", "ge\u00b7irrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "APZR", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und will sich nun zu rechte fragen,", "tokens": ["Und", "will", "sich", "nun", "zu", "rech\u00b7te", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "APPR", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Von einem Theil entbl\u00f6sset wird,", "tokens": ["Von", "ei\u00b7nem", "Theil", "ent\u00b7bl\u00f6s\u00b7set", "wird", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Vom andern aber wund geschlagen.", "tokens": ["Vom", "an\u00b7dern", "a\u00b7ber", "wund", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Dar\u00fcber denn entbrennt,", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "denn", "ent\u00b7brennt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Wer Christi Treue kennt,", "tokens": ["Wer", "Chris\u00b7ti", "Treu\u00b7e", "kennt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und mu\u00df auf beyden Seiten rechten.", "tokens": ["Und", "mu\u00df", "auf", "bey\u00b7den", "Sei\u00b7ten", "rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "PIAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Was denckt ein Fremder dann,", "tokens": ["Was", "denckt", "ein", "Frem\u00b7der", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Der das nicht fassen kan,", "tokens": ["Der", "das", "nicht", "fas\u00b7sen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Von JEsu Reich und seinen Knechten?", "tokens": ["Von", "Je\u00b7su", "Reich", "und", "sei\u00b7nen", "Knech\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Und, JEsu! wer erzittert nicht", "tokens": ["Und", ",", "Je\u00b7su", "!", "wer", "er\u00b7zit\u00b7tert", "nicht"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NE", "$.", "PWS", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor einem solchen Schwarm der Secten,", "tokens": ["Vor", "ei\u00b7nem", "sol\u00b7chen", "Schwarm", "der", "Sec\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die alle, so sie angericht,", "tokens": ["Die", "al\u00b7le", ",", "so", "sie", "an\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf einer Streu von Wahrheit heckten.", "tokens": ["Auf", "ei\u00b7ner", "Streu", "von", "Wahr\u00b7heit", "heck\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da jede gute Seelen hat,", "tokens": ["Da", "je\u00b7de", "gu\u00b7te", "See\u00b7len", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die ohne ihren Vorsatz schwermen.", "tokens": ["Die", "oh\u00b7ne", "ih\u00b7ren", "Vor\u00b7satz", "schwer\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wer wolte sich um deine Stadt", "tokens": ["Wer", "wol\u00b7te", "sich", "um", "dei\u00b7ne", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nicht immer schon zum voraus hermen.", "tokens": ["Nicht", "im\u00b7mer", "schon", "zum", "vo\u00b7raus", "her\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "APPRART", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Spricht Luther: ", "tokens": ["Spricht", "Lu\u00b7ther", ":"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NE", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "So f\u00e4hrt der P\u00f6bel zu,", "tokens": ["So", "f\u00e4hrt", "der", "P\u00f6\u00b7bel", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und glaubts, und bleibt in seinen S\u00fcnden,", "tokens": ["Und", "glaubts", ",", "und", "bleibt", "in", "sei\u00b7nen", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wer wei\u00df, wenns Spinnen trift,", "tokens": ["Wer", "wei\u00df", ",", "wenns", "Spin\u00b7nen", "trift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Ob sie nicht eben Gift", "tokens": ["Ob", "sie", "nicht", "e\u00b7ben", "Gift"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "In diesem unsern Honig finden.", "tokens": ["In", "die\u00b7sem", "un\u00b7sern", "Ho\u00b7nig", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Inzwischen sey gebenedeyt,", "tokens": ["I\u00b7nzwi\u00b7schen", "sey", "ge\u00b7be\u00b7ne\u00b7deyt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Anbetungs-w\u00fcrdiger Gebieter,", "tokens": ["An\u00b7be\u00b7tungs\u00b7w\u00fcr\u00b7di\u00b7ger", "Ge\u00b7bie\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Da\u00df du uns bi\u00df auf diese Zeit,", "tokens": ["Da\u00df", "du", "uns", "bi\u00df", "auf", "die\u00b7se", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die reine Quelle deiner G\u00fcter,", "tokens": ["Die", "rei\u00b7ne", "Quel\u00b7le", "dei\u00b7ner", "G\u00fc\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die lautre Gnaden-Bothschaft giebst,", "tokens": ["Die", "laut\u00b7re", "Gna\u00b7den\u00b7Both\u00b7schaft", "giebst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Ernst zur Heiligung erweckest,", "tokens": ["Und", "Ernst", "zur", "Hei\u00b7li\u00b7gung", "er\u00b7we\u00b7ckest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch unsre kleine Leuchte liebst,", "tokens": ["Auch", "uns\u00b7re", "klei\u00b7ne", "Leuch\u00b7te", "liebst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und unter keinen Scheffel steckest,", "tokens": ["Und", "un\u00b7ter", "kei\u00b7nen", "Schef\u00b7fel", "ste\u00b7ckest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Noch von der St\u00e4te r\u00fcckst,", "tokens": ["Noch", "von", "der", "St\u00e4\u00b7te", "r\u00fcckst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.10": {"text": "Vielmehr auf alle blickst,", "tokens": ["Viel\u00b7mehr", "auf", "al\u00b7le", "blickst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Die eigentlich ins Hau\u00df geh\u00f6ren,", "tokens": ["Die", "ei\u00b7gent\u00b7lich", "ins", "Hau\u00df", "ge\u00b7h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ja, wie du immer pflegst,", "tokens": ["Ja", ",", "wie", "du", "im\u00b7mer", "pflegst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Wohl andre mit erregst,", "tokens": ["Wohl", "and\u00b7re", "mit", "er\u00b7regst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Da\u00df sie sich nach dem Lichte kehren.", "tokens": ["Da\u00df", "sie", "sich", "nach", "dem", "Lich\u00b7te", "keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}