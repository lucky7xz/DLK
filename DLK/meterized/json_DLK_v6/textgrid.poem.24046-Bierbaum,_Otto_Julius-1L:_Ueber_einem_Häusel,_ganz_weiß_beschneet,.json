{"textgrid.poem.24046": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ueber einem H\u00e4usel, ganz wei\u00df beschneet,", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ueber einem H\u00e4usel, ganz wei\u00df beschneet,", "tokens": ["Ue\u00b7ber", "ei\u00b7nem", "H\u00e4u\u00b7sel", ",", "ganz", "wei\u00df", "be\u00b7schneet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Golden ein flimmernder Funkelstern steht.", "tokens": ["Gol\u00b7den", "ein", "flim\u00b7mern\u00b7der", "Fun\u00b7kels\u00b7tern", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+--+--++-+", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Wei\u00df alle Wege, die B\u00e4ume alle wei\u00df,", "tokens": ["Wei\u00df", "al\u00b7le", "We\u00b7ge", ",", "die", "B\u00e4u\u00b7me", "al\u00b7le", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "ART", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Milde des goldenen Sternes Geglei\u00df.", "tokens": ["Mil\u00b7de", "des", "gol\u00b7de\u00b7nen", "Ster\u00b7nes", "Ge\u00b7glei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.3": {"line.1": {"text": "Gelb aus dem Fenster ein Lichtschein schr\u00e4g", "tokens": ["Gelb", "aus", "dem", "Fens\u00b7ter", "ein", "Licht\u00b7schein", "schr\u00e4g"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN", "ART", "NN", "ADJD"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Ueber das G\u00e4rtchen, \u00fcber den Weg.", "tokens": ["Ue\u00b7ber", "das", "G\u00e4rt\u00b7chen", ",", "\u00fc\u00b7ber", "den", "Weg", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Sieh, da \u00fcber den Feldweg quer", "tokens": ["Sieh", ",", "da", "\u00fc\u00b7ber", "den", "Feld\u00b7weg", "quer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "APPR", "ART", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Stakt ein steingrauer Alter her;", "tokens": ["Stakt", "ein", "stein\u00b7grau\u00b7er", "Al\u00b7ter", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ganz in Lumpen und Flicken getan,", "tokens": ["Ganz", "in", "Lum\u00b7pen", "und", "Fli\u00b7cken", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und h\u00e4lt vor dem Hause an.", "tokens": ["Und", "h\u00e4lt", "vor", "dem", "Hau\u00b7se", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Haucht in die H\u00e4nde und sieht sich um,", "tokens": ["Haucht", "in", "die", "H\u00e4n\u00b7de", "und", "sieht", "sich", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "KON", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Blickt zum Sterne und wartet stumm.", "tokens": ["Blickt", "zum", "Ster\u00b7ne", "und", "war\u00b7tet", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.7": {"line.1": {"text": "Kommt von der andern Seite an", "tokens": ["Kommt", "von", "der", "an\u00b7dern", "Sei\u00b7te", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wieder ein alter zerlumpter Mann.", "tokens": ["Wie\u00b7der", "ein", "al\u00b7ter", "zer\u00b7lump\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Geben sich beide stumm die Hand,", "tokens": ["Ge\u00b7ben", "sich", "bei\u00b7de", "stumm", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PIS", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Starren zum Sterne unverwandt.", "tokens": ["Star\u00b7ren", "zum", "Ster\u00b7ne", "un\u00b7ver\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.9": {"line.1": {"text": "Kommt ein dritter und gr\u00fc\u00dft die zwei,", "tokens": ["Kommt", "ein", "drit\u00b7ter", "und", "gr\u00fc\u00dft", "die", "zwei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "KON", "VVFIN", "ART", "CARD", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Raunen und tuscheln und deuten die drei.", "tokens": ["Rau\u00b7nen", "und", "tu\u00b7scheln", "und", "deu\u00b7ten", "die", "drei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "KON", "VVFIN", "ART", "CARD", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.10": {"line.1": {"text": "Blicken zum Sterne, blicken zur Th\u00fcr;", "tokens": ["Bli\u00b7cken", "zum", "Ster\u00b7ne", ",", "bli\u00b7cken", "zur", "Th\u00fcr", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,", "VVFIN", "APPRART", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Tritt ein b\u00e4rtiger Mann herf\u00fcr:", "tokens": ["Tritt", "ein", "b\u00e4r\u00b7ti\u00b7ger", "Mann", "her\u00b7f\u00fcr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.11": {"line.1": {"text": "\u00bbkamt in M\u00fchen und Sehnen weit;", "tokens": ["\u00bb", "kamt", "in", "M\u00fc\u00b7hen", "und", "Seh\u00b7nen", "weit", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "NN", "KON", "NN", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Geht nach Hause! Es ist nicht die Zeit ...\u00ab", "tokens": ["Geht", "nach", "Hau\u00b7se", "!", "Es", "ist", "nicht", "die", "Zeit", "...", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "NN", "$.", "PPER", "VAFIN", "PTKNEG", "ART", "NN", "$(", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Senken die K\u00f6pfe die drei und gehn", "tokens": ["Sen\u00b7ken", "die", "K\u00f6p\u00b7fe", "die", "drei", "und", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ART", "CARD", "KON", "VVINF"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "M\u00fcde fort. Es hebt sich ein Wehn,", "tokens": ["M\u00fc\u00b7de", "fort", ".", "Es", "hebt", "sich", "ein", "Wehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Hebt sich ein St\u00fcrmen, Wirbeln, Gebraus,", "tokens": ["Hebt", "sich", "ein", "St\u00fcr\u00b7men", ",", "Wir\u00b7beln", ",", "Ge\u00b7braus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und der goldene Stern l\u00f6scht aus.", "tokens": ["Und", "der", "gol\u00b7de\u00b7ne", "Stern", "l\u00f6scht", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}}}}