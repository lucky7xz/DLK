{"textgrid.poem.53085": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es ist ja nun an dem, da\u00df mein Herr Robertihn", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es ist ja nun an dem, da\u00df mein Herr Robertihn", "tokens": ["Es", "ist", "ja", "nun", "an", "dem", ",", "da\u00df", "mein", "Herr", "Ro\u00b7ber\u00b7tihn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "ART", "$,", "KOUS", "PPOSAT", "NN", "NE"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Mit seinem Hochzeit-Fest nicht l\u00e4nger wil verziehn,", "tokens": ["Mit", "sei\u00b7nem", "Hoch\u00b7zeit\u00b7Fest", "nicht", "l\u00e4n\u00b7ger", "wil", "ver\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er fasst jhm ein Schlu\u00df, bey dem es sol verbleiben,", "tokens": ["Er", "fasst", "jhm", "ein", "Schlu\u00df", ",", "bey", "dem", "es", "sol", "ver\u00b7blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Den auch der Himmel sich erbeut zu vnterschreiben,", "tokens": ["Den", "auch", "der", "Him\u00b7mel", "sich", "er\u00b7beut", "zu", "vn\u00b7ter\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da\u00df dieser sch\u00f6ne Tag das alles offenbahr", "tokens": ["Da\u00df", "die\u00b7ser", "sch\u00f6\u00b7ne", "Tag", "das", "al\u00b7les", "of\u00b7fen\u00b7bahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "ART", "PIS", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sol machen, was bi\u00dfher jhm selbst kaum k\u00fcndig war.", "tokens": ["Sol", "ma\u00b7chen", ",", "was", "bi\u00df\u00b7her", "jhm", "selbst", "kaum", "k\u00fcn\u00b7dig", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PRELS", "ADV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er kann die Flamme nun nicht l\u00e4nger heimlich halten,", "tokens": ["Er", "kann", "die", "Flam\u00b7me", "nun", "nicht", "l\u00e4n\u00b7ger", "heim\u00b7lich", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "PTKNEG", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Giebt seiner Liebe stat, die vngehindert walten", "tokens": ["Giebt", "sei\u00b7ner", "Lie\u00b7be", "stat", ",", "die", "vn\u00b7ge\u00b7hin\u00b7dert", "wal\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "VVFIN", "$,", "PRELS", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vnd jhn beherrschen mu\u00df, er kennt die Art der Zeit", "tokens": ["Vnd", "jhn", "be\u00b7herr\u00b7schen", "mu\u00df", ",", "er", "kennt", "die", "Art", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVINF", "VMFIN", "$,", "PPER", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Vnd seine liebe Braut wird jetzt jhm zugetreut.", "tokens": ["Vnd", "sei\u00b7ne", "lie\u00b7be", "Braut", "wird", "jetzt", "jhm", "zu\u00b7ge\u00b7treut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vnd seh' ich nicht hierumb den Himmel sich bewegen,", "tokens": ["Vnd", "seh'", "ich", "nicht", "hie\u00b7rumb", "den", "Him\u00b7mel", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "PAV", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Wolcken fl\u00fcchtig seyn, des Wetters Last sich legen?", "tokens": ["Die", "Wol\u00b7cken", "fl\u00fcch\u00b7tig", "seyn", ",", "des", "Wet\u00b7ters", "Last", "sich", "le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAINF", "$,", "ART", "NN", "VVFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die G\u00f6tter werden eins, in einer grossen Zahl", "tokens": ["Die", "G\u00f6t\u00b7ter", "wer\u00b7den", "eins", ",", "in", "ei\u00b7ner", "gros\u00b7sen", "Zahl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PIS", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Zu fahren Himmel-ab auff dieses Frewden-Mahl.", "tokens": ["Zu", "fah\u00b7ren", "Him\u00b7mel\u00b7ab", "auff", "die\u00b7ses", "Fre\u00b7wden\u00b7Mahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ach, man kennt dich an dem Bogen,", "tokens": ["Ach", ",", "man", "kennt", "dich", "an", "dem", "Bo\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PIS", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "S\u00fcsser Amor, deine Tracht", "tokens": ["S\u00fcs\u00b7ser", "A\u00b7mor", ",", "dei\u00b7ne", "Tracht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat dich leichtlich kunt gemacht!", "tokens": ["Hat", "dich", "leicht\u00b7lich", "kunt", "ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "O komm gl\u00fcckhafft eingezogen!", "tokens": ["O", "komm", "gl\u00fcck\u00b7hafft", "ein\u00b7ge\u00b7zo\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Komm, ver\u00fcbe deine Pflicht,", "tokens": ["Komm", ",", "ver\u00b7\u00fc\u00b7be", "dei\u00b7ne", "Pflicht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Triff das Hertz vnd fehle nicht.", "tokens": ["Triff", "das", "Hertz", "vnd", "feh\u00b7le", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "VVFIN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Juno wil das Brautbett machen,", "tokens": ["Ju\u00b7no", "wil", "das", "Braut\u00b7bett", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Venus hat in jhrer Handt", "tokens": ["Ve\u00b7nus", "hat", "in", "jhrer", "Handt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der verliebten Sinnen Brandt", "tokens": ["Der", "ver\u00b7lieb\u00b7ten", "Sin\u00b7nen", "Brandt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd rings vmb sich Schertz vnd Lachen.", "tokens": ["Vnd", "rings", "vmb", "sich", "Schertz", "vnd", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PRF", "NN", "KON", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Hymen eylet was er kan,", "tokens": ["Hy\u00b7men", "ey\u00b7let", "was", "er", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PWS", "PPER", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Steckt die Fackeln bey jhr an.", "tokens": ["Steckt", "die", "Fa\u00b7ckeln", "bey", "jhr", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auch mein einiges Verlangen,", "tokens": ["Auch", "mein", "ei\u00b7ni\u00b7ges", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Phoebus ist mit Frewden hier,", "tokens": ["Phoe\u00b7bus", "ist", "mit", "Frew\u00b7den", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner g\u00fcldnen Lauten Zier", "tokens": ["Sei\u00b7ner", "g\u00fcld\u00b7nen", "Lau\u00b7ten", "Zier"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Hat er auff der Schulter hangen,", "tokens": ["Hat", "er", "auff", "der", "Schul\u00b7ter", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Der neun Schwestern volles Chor", "tokens": ["Der", "neun", "Schwes\u00b7tern", "vol\u00b7les", "Chor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gehet jhm theils nach theils vor.", "tokens": ["Ge\u00b7het", "jhm", "theils", "nach", "theils", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Halt, was werden sie beginnen?", "tokens": ["Halt", ",", "was", "wer\u00b7den", "sie", "be\u00b7gin\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd wo ist es hin gemeynt,", "tokens": ["Vnd", "wo", "ist", "es", "hin", "ge\u00b7meynt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das voraus Apollo scheint", "tokens": ["Das", "vo\u00b7raus", "A\u00b7pol\u00b7lo", "scheint"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ADV", "NE", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Tieffen Sachen nach zu sinnen?", "tokens": ["Tief\u00b7fen", "Sa\u00b7chen", "nach", "zu", "sin\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist mir recht, sie seyn bem\u00fcht", "tokens": ["Ist", "mir", "recht", ",", "sie", "seyn", "be\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "PPER", "VAINF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Auff ein newes Hochzeit-Liedt.", "tokens": ["Auff", "ein", "ne\u00b7wes", "Hoch\u00b7zeit\u00b7Liedt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Wol dir, du werthes Paar! Dein Wesen mu\u00df f\u00fcr allen", "tokens": ["Wol", "dir", ",", "du", "wert\u00b7hes", "Paar", "!", "Dein", "We\u00b7sen", "mu\u00df", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "PPER", "ADJA", "NN", "$.", "PPOSAT", "NN", "VMFIN", "APPR", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dem Himmel, da\u00df er dir so g\u00fcnstig ist, gefallen;", "tokens": ["Dem", "Him\u00b7mel", ",", "da\u00df", "er", "dir", "so", "g\u00fcns\u00b7tig", "ist", ",", "ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "ADJD", "VAFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schaw vmb dich, wie er thut, er steht Gedancken vol", "tokens": ["Schaw", "vmb", "dich", ",", "wie", "er", "thut", ",", "er", "steht", "Ge\u00b7dan\u00b7cken", "vol"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vnd wei\u00df nicht, was f\u00fcr Dienst er jetzt erweisen sol.", "tokens": ["Vnd", "wei\u00df", "nicht", ",", "was", "f\u00fcr", "Dienst", "er", "jetzt", "er\u00b7wei\u00b7sen", "sol", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "PRELS", "APPR", "NN", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er reitzt auch meinen Geist vnd zwingt mich lo\u00dfzugehen,", "tokens": ["Er", "reitzt", "auch", "mei\u00b7nen", "Geist", "vnd", "zwingt", "mich", "lo\u00df\u00b7zu\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Adern wallen mir, ich kan nicht stille stehen.", "tokens": ["Die", "A\u00b7dern", "wal\u00b7len", "mir", ",", "ich", "kan", "nicht", "stil\u00b7le", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "PPER", "VMFIN", "PTKNEG", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Apollo geusset gantz sich meinem Hertzen ein", "tokens": ["A\u00b7pol\u00b7lo", "geus\u00b7set", "gantz", "sich", "mei\u00b7nem", "Hert\u00b7zen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVPP", "ADV", "PRF", "PPOSAT", "NN", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vnd ich beginne fast nicht bey mir selbst zu sein.", "tokens": ["Vnd", "ich", "be\u00b7gin\u00b7ne", "fast", "nicht", "bey", "mir", "selbst", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "PPER", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Verzeiht mir beyderseit vnd lasst euch nicht verdriessen,", "tokens": ["Ver\u00b7zeiht", "mir", "bey\u00b7der\u00b7seit", "vnd", "lasst", "euch", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn ich mir was zu frey den Z\u00fcgel lasse schiessen,", "tokens": ["Wenn", "ich", "mir", "was", "zu", "frey", "den", "Z\u00fc\u00b7gel", "las\u00b7se", "schies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PIS", "PTKA", "ADJD", "ART", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Verh\u00e4nge meinem Sinn aus Liebe was zu viel,", "tokens": ["Ver\u00b7h\u00e4n\u00b7ge", "mei\u00b7nem", "Sinn", "aus", "Lie\u00b7be", "was", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "PRELS", "APPR", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Frewde, so mich treibt, kennt weder Ma\u00df noch Ziel:", "tokens": ["Die", "Frew\u00b7de", ",", "so", "mich", "treibt", ",", "kennt", "we\u00b7der", "Ma\u00df", "noch", "Ziel", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VVFIN", "KON", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Trawre nicht, stell ein die Klage,", "tokens": ["Traw\u00b7re", "nicht", ",", "stell", "ein", "die", "Kla\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "ADJD", "ART", "ART", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Sch\u00f6ne Braut, es hat nicht Noth!", "tokens": ["Sch\u00f6\u00b7ne", "Braut", ",", "es", "hat", "nicht", "Noth", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "PTKNEG", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schaw, es ist noch hoch am Tage", "tokens": ["Schaw", ",", "es", "ist", "noch", "hoch", "am", "Ta\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd sehr weit vom Abend-Roht,", "tokens": ["Vnd", "sehr", "weit", "vom", "A\u00b7ben\u00b7dRoht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das vns bringen sol die Nacht,", "tokens": ["Das", "vns", "brin\u00b7gen", "sol", "die", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVINF", "VMFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die dich so bek\u00fcmmert macht.", "tokens": ["Die", "dich", "so", "be\u00b7k\u00fcm\u00b7mert", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Die Ihr wohnt in schwartzen Zelten,", "tokens": ["Die", "Ihr", "wohnt", "in", "schwart\u00b7zen", "Zel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "O jhr Schatten, eilet nicht,", "tokens": ["O", "jhr", "Schat\u00b7ten", ",", "ei\u00b7let", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$,", "VVFIN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lasst die Braut bey euch was gelten,", "tokens": ["Lasst", "die", "Braut", "bey", "euch", "was", "gel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie helt an vmb stetes Liecht,", "tokens": ["Sie", "helt", "an", "vmb", "ste\u00b7tes", "Liecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Stetes Liecht zwar kan nicht seyn,", "tokens": ["Ste\u00b7tes", "Liecht", "zwar", "kan", "nicht", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VMFIN", "PTKNEG", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Doch ein Auffschub jhrer Pein.", "tokens": ["Doch", "ein", "Auff\u00b7schub", "jhrer", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.9": {"line.1": {"text": "Gebt der Bitte raum vnd stelle,", "tokens": ["Gebt", "der", "Bit\u00b7te", "raum", "vnd", "stel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seht, wie Sie so vbel thut,", "tokens": ["Seht", ",", "wie", "Sie", "so", "vbel", "thut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+----", "measure": "dactylic.init"}, "line.3": {"text": "Himmel, Erde, See vnd Helle", "tokens": ["Him\u00b7mel", ",", "Er\u00b7de", ",", "See", "vnd", "Hel\u00b7le"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Legen hin den wilden Muth,", "tokens": ["Le\u00b7gen", "hin", "den", "wil\u00b7den", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sie brauchet die Gewalt", "tokens": ["Wenn", "sie", "brau\u00b7chet", "die", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihrer kl\u00e4glichen Gestalt.", "tokens": ["Ih\u00b7rer", "kl\u00e4g\u00b7li\u00b7chen", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Aber, Sch\u00f6nste, deine Sorgen", "tokens": ["A\u00b7ber", ",", "Sch\u00f6ns\u00b7te", ",", "dei\u00b7ne", "Sor\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seyn nur zu belachen wehrt,", "tokens": ["Seyn", "nur", "zu", "be\u00b7la\u00b7chen", "wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn der Sonnen-Liecht sich Morgen", "tokens": ["Wenn", "der", "Son\u00b7nen\u00b7Liecht", "sich", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PRF", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wieder zu vns hat gekehrt,", "tokens": ["Wie\u00b7der", "zu", "vns", "hat", "ge\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wirstu, gleub es mir, mein Kindt,", "tokens": ["Wirs\u00b7tu", ",", "gleub", "es", "mir", ",", "mein", "Kindt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Anders seyn als jetzt gesinnt.", "tokens": ["An\u00b7ders", "seyn", "als", "jetzt", "ge\u00b7sinnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAINF", "KOKOM", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Hastu lust darnach zu fragen,", "tokens": ["Has\u00b7tu", "lust", "dar\u00b7nach", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PAV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meinest gantz, hie sey Gefahr,", "tokens": ["Mei\u00b7nest", "gantz", ",", "hie", "sey", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "VAFIN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deine Mutter wird dir sagen,", "tokens": ["Dei\u00b7ne", "Mut\u00b7ter", "wird", "dir", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die das auch, was du bist, war,", "tokens": ["Die", "das", "auch", ",", "was", "du", "bist", ",", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PDS", "ADV", "$,", "PWS", "PPER", "VAFIN", "$,", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der auch du bald gleich wirst sehn,", "tokens": ["Der", "auch", "du", "bald", "gleich", "wirst", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "ADV", "ADV", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn es vmb ein Thun geschehn.", "tokens": ["Wenn", "es", "vmb", "ein", "Thun", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Welche sol man h\u00f6her halten?", "tokens": ["Wel\u00b7che", "sol", "man", "h\u00f6\u00b7her", "hal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die sich bawt aus jhrem Mann,", "tokens": ["Die", "sich", "bawt", "aus", "jhrem", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Oder die daheim mu\u00df alten", "tokens": ["O\u00b7der", "die", "da\u00b7heim", "mu\u00df", "al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "VMFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd nicht ehlich werden kan?", "tokens": ["Vnd", "nicht", "eh\u00b7lich", "wer\u00b7den", "kan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jener Bl\u00fcth' ist Segens vol,", "tokens": ["Je\u00b7ner", "Bl\u00fcth'", "ist", "Se\u00b7gens", "vol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NE", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Diese stirbt eh als sie sol.", "tokens": ["Die\u00b7se", "stirbt", "eh", "als", "sie", "sol", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KOUS", "KOUS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Vieh vnd Menschen m\u00fcssen hassen", "tokens": ["Vieh", "vnd", "Men\u00b7schen", "m\u00fcs\u00b7sen", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Solchen Weinstock, der nicht tr\u00e4gt,", "tokens": ["Sol\u00b7chen", "Wein\u00b7stock", ",", "der", "nicht", "tr\u00e4gt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Den sein Ehgatt hat verlassen;", "tokens": ["Den", "sein", "Eh\u00b7gatt", "hat", "ver\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber welcher Trauben hegt", "tokens": ["A\u00b7ber", "wel\u00b7cher", "Trau\u00b7ben", "hegt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd an Vlmen steht gesetzt", "tokens": ["Vnd", "an", "Vl\u00b7men", "steht", "ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VVFIN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wird ja billich hoch gesch\u00e4tzt.", "tokens": ["Wird", "ja", "bil\u00b7lich", "hoch", "ge\u00b7sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Komm, Nacht, komm! kompt Himmels Flammen!", "tokens": ["Komm", ",", "Nacht", ",", "komm", "!", "kompt", "Him\u00b7mels", "Flam\u00b7men", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VVFIN", "$.", "VVFIN", "NN", "NN", "$."], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Vnd entdecket den Verdru\u00df,", "tokens": ["Vnd", "ent\u00b7de\u00b7cket", "den", "Ver\u00b7dru\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kompt doch eilends, f\u00fcgt zusammen", "tokens": ["Kompt", "doch", "ei\u00b7lends", ",", "f\u00fcgt", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "$,", "VVFIN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was zusammen sol vnd mu\u00df,", "tokens": ["Was", "zu\u00b7sam\u00b7men", "sol", "vnd", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "KON", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Macht der Braut den Mi\u00dfverstandt,", "tokens": ["Macht", "der", "Braut", "den", "Mi\u00df\u00b7ver\u00b7standt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die vergebne Furcht, bekant.", "tokens": ["Die", "ver\u00b7geb\u00b7ne", "Furcht", ",", "be\u00b7kant", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Ihr k\u00f6nnt Leib vnd Seele speisen", "tokens": ["Ihr", "k\u00f6nnt", "Leib", "vnd", "See\u00b7le", "spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch den Schlaff, der auch vns nehrt,", "tokens": ["Durch", "den", "Schlaff", ",", "der", "auch", "vns", "nehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "K\u00f6nnt auch Buhler vnterweisen,", "tokens": ["K\u00f6nnt", "auch", "Buh\u00b7ler", "vn\u00b7ter\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Darumb helt Euch Venus wehrt", "tokens": ["Da\u00b7rumb", "helt", "Euch", "Ve\u00b7nus", "wehrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "NN", "VVFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Vnd schickt ewrer s\u00fcssen Rhue", "tokens": ["Vnd", "schickt", "ew\u00b7rer", "s\u00fcs\u00b7sen", "Rhue"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "All jhr Volck vnd Sch\u00fcler zu.", "tokens": ["All", "jhr", "Volck", "vnd", "Sch\u00fc\u00b7ler", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ihr benehmet jungen Leuten", "tokens": ["Ihr", "be\u00b7neh\u00b7met", "jun\u00b7gen", "Leu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihre Furcht vnd bl\u00f6den Sinn,", "tokens": ["Ih\u00b7re", "Furcht", "vnd", "bl\u00f6\u00b7den", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wisset recht sie zu bedeuten,", "tokens": ["Wis\u00b7set", "recht", "sie", "zu", "be\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alles macht sich zu euch hin", "tokens": ["Al\u00b7les", "macht", "sich", "zu", "euch", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "APPR", "PPER", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd erlanget Sieg vnd Prei\u00df,", "tokens": ["Vnd", "er\u00b7lan\u00b7get", "Sieg", "vnd", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was sonst nichts von Liebe wei\u00df.", "tokens": ["Was", "sonst", "nichts", "von", "Lie\u00b7be", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Schlage nicht die Augen nieder,", "tokens": ["Schla\u00b7ge", "nicht", "die", "Au\u00b7gen", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00f6nste, gib dich willig drein;", "tokens": ["Sch\u00f6ns\u00b7te", ",", "gib", "dich", "wil\u00b7lig", "drein", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Morgen sprechen wir vns wieder,", "tokens": ["Mor\u00b7gen", "spre\u00b7chen", "wir", "vns", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PRF", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "O, es wird schon anders seyn.", "tokens": ["O", ",", "es", "wird", "schon", "an\u00b7ders", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADV", "ADV", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Komm! Die Nacht, der Sternen Chor", "tokens": ["Komm", "!", "Die", "Nacht", ",", "der", "Ster\u00b7nen", "Chor"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$.", "ART", "NN", "$,", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Fodern dich bereit hervor.", "tokens": ["Fo\u00b7dern", "dich", "be\u00b7reit", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Vnd du, Herr Br\u00e4utigam, hast gnug in deinen Jahren,", "tokens": ["Vnd", "du", ",", "Herr", "Br\u00e4u\u00b7ti\u00b7gam", ",", "hast", "gnug", "in", "dei\u00b7nen", "Jah\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "NN", "NE", "$,", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was Kunst vnd Tugend sey, erlernet vnd erfahren,", "tokens": ["Was", "Kunst", "vnd", "Tu\u00b7gend", "sey", ",", "er\u00b7ler\u00b7net", "vnd", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VAFIN", "$,", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df aber fehlt dir noch, wend hie nun Arbeit an,", "tokens": ["Di\u00df", "a\u00b7ber", "fehlt", "dir", "noch", ",", "wend", "hie", "nun", "Ar\u00b7beit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "ADV", "ADV", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auch hie wird Flei\u00df erheischt, zeuch aus den ernsten Mann", "tokens": ["Auch", "hie", "wird", "Flei\u00df", "er\u00b7heischt", ",", "zeuch", "aus", "den", "erns\u00b7ten", "Mann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "NN", "VVFIN", "$,", "VVIMP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vnd lerne Kindisch seyn; hie mag kein Cato sitzen,", "tokens": ["Vnd", "ler\u00b7ne", "Kin\u00b7disch", "seyn", ";", "hie", "mag", "kein", "Ca\u00b7to", "sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "VAINF", "$.", "ADV", "VMFIN", "PIAT", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein sawrer Curius hat Wei\u00dfheit hiezu schwitzen.", "tokens": ["Kein", "saw\u00b7rer", "Cu\u00b7rius", "hat", "Wei\u00df\u00b7heit", "hie\u00b7zu", "schwit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NE", "VAFIN", "NN", "PAV", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "Cupido ist ein Kind,", "tokens": ["Cu\u00b7pi\u00b7do", "ist", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Was schertzt vnd liebt auff Erden", "tokens": ["Was", "schertzt", "vnd", "liebt", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mu\u00df seyn wie er gesinnt,", "tokens": ["Mu\u00df", "seyn", "wie", "er", "ge\u00b7sinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "KOKOM", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Mu\u00df mit jhm kindisch werden.", "tokens": ["Mu\u00df", "mit", "jhm", "kin\u00b7disch", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Schertz ist hie Befehlichshaber, hie hat Kurtzweil oberhand,", "tokens": ["Schertz", "ist", "hie", "Be\u00b7feh\u00b7lichs\u00b7ha\u00b7ber", ",", "hie", "hat", "Kurt\u00b7zweil", "o\u00b7ber\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "NN", "$,", "ADV", "VAFIN", "NN", "ADV", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Hie wird auch ein grawes Alter offt in Kindheit vmbgewand,", "tokens": ["Hie", "wird", "auch", "ein", "gra\u00b7wes", "Al\u00b7ter", "offt", "in", "Kind\u00b7heit", "vmb\u00b7ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "----+-+-+-+-+-+", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Dieser Hal\u00df von Alabaster, dieser weissen Stirne Schein,", "tokens": ["Die\u00b7ser", "Hal\u00df", "von", "A\u00b7la\u00b7bas\u00b7ter", ",", "die\u00b7ser", "weis\u00b7sen", "Stir\u00b7ne", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NE", "$,", "PDAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.4": {"text": "Diese Rosen-rothe Wangen, dieser H\u00e4nde Helffenbein", "tokens": ["Die\u00b7se", "Ro\u00b7sen\u00b7ro\u00b7the", "Wan\u00b7gen", ",", "die\u00b7ser", "H\u00e4n\u00b7de", "Helf\u00b7fen\u00b7bein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "$,", "PDAT", "NN", "NE"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Werden dir den Sinn berauben, werden dich, mein Robertihn,", "tokens": ["Wer\u00b7den", "dir", "den", "Sinn", "be\u00b7rau\u00b7ben", ",", "wer\u00b7den", "dich", ",", "mein", "Ro\u00b7ber\u00b7tihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVINF", "$,", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Offt dir selbst vn\u00e4hnlich machen vnd dir allen Muth entziehn.", "tokens": ["Offt", "dir", "selbst", "vn\u00b7\u00e4hn\u00b7lich", "ma\u00b7chen", "vnd", "dir", "al\u00b7len", "Muth", "ent\u00b7ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "ADJD", "VVINF", "KON", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.7": {"text": "Schaw doch her, vor diesen Augen legte Juppiter beyseit", "tokens": ["Schaw", "doch", "her", ",", "vor", "die\u00b7sen", "Au\u00b7gen", "leg\u00b7te", "Jup\u00b7pi\u00b7ter", "bey\u00b7seit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PTKVZ", "$,", "APPR", "PDAT", "NN", "VVFIN", "NE", "NN"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.8": {"text": "Seinen Blitz vnd Donnerkeulen, Thetis Sohn gieng' aus dem Streit,", "tokens": ["Sei\u00b7nen", "Blitz", "vnd", "Don\u00b7ner\u00b7keu\u00b7len", ",", "The\u00b7tis", "Sohn", "gieng'", "aus", "dem", "Streit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$,", "NE", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Solch Kr\u00e4ffte, solch Verm\u00f6gen hat die Sch\u00f6nheit deiner Braut.", "tokens": ["Solch", "Kr\u00e4ff\u00b7te", ",", "solch", "Ver\u00b7m\u00f6\u00b7gen", "hat", "die", "Sch\u00f6n\u00b7heit", "dei\u00b7ner", "Braut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.21": {"line.1": {"text": "La\u00df sie das Tag-Liecht tragen", "tokens": ["La\u00df", "sie", "das", "Tag\u00b7Liecht", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als sonst die Morgenr\u00f6th,", "tokens": ["Als", "sonst", "die", "Mor\u00b7gen\u00b7r\u00f6th", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die vor der Sonnen Wagen", "tokens": ["Die", "vor", "der", "Son\u00b7nen", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In g\u00fcldnen Haaren geht;", "tokens": ["In", "g\u00fcld\u00b7nen", "Haa\u00b7ren", "geht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Man solt' in Irrthumb schweben,", "tokens": ["Man", "solt'", "in", "Irr\u00b7thumb", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nicht wissen, wer es sey,", "tokens": ["Nicht", "wis\u00b7sen", ",", "wer", "es", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein solches Liecht vnd Leben", "tokens": ["Ein", "sol\u00b7ches", "Liecht", "vnd", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wohnt deiner Liebsten bey.", "tokens": ["Wohnt", "dei\u00b7ner", "Liebs\u00b7ten", "bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Ich hett hie guten Fug von jhrer Zucht zu singen,", "tokens": ["Ich", "hett", "hie", "gu\u00b7ten", "Fug", "von", "jhrer", "Zucht", "zu", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie eingezogen sie jhr Leben hin kan bringen,", "tokens": ["Wie", "ein\u00b7ge\u00b7zo\u00b7gen", "sie", "jhr", "Le\u00b7ben", "hin", "kan", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "PPER", "PPOSAT", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was f\u00fcr Bescheidenheit vnd guter Sitten Pracht", "tokens": ["Was", "f\u00fcr", "Be\u00b7schei\u00b7den\u00b7heit", "vnd", "gu\u00b7ter", "Sit\u00b7ten", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "KON", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Au\u00df jhr ein edles Bild des Frawen-Zimmers macht;", "tokens": ["Au\u00df", "jhr", "ein", "ed\u00b7les", "Bild", "des", "Fra\u00b7wen\u00b7Zim\u00b7mers", "macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "K\u00f6nnt' jhre Lust, die sie zu B\u00fcchern tr\u00e4gt, beschreiben", "tokens": ["K\u00f6nnt'", "jhre", "Lust", ",", "die", "sie", "zu", "B\u00fc\u00b7chern", "tr\u00e4gt", ",", "be\u00b7schrei\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Vnd wie sie manchen Tag mit lesen kan vertreiben,", "tokens": ["Vnd", "wie", "sie", "man\u00b7chen", "Tag", "mit", "le\u00b7sen", "kan", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PIAT", "NN", "APPR", "VVINF", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dadurch sie wol bedacht des b\u00f6sen m\u00fcssig geht,", "tokens": ["Da\u00b7durch", "sie", "wol", "be\u00b7dacht", "des", "b\u00f6\u00b7sen", "m\u00fcs\u00b7sig", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "VVFIN", "ART", "ADJA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Darnach so manches Mensch mit Flei\u00df vnd Willen steht.", "tokens": ["Dar\u00b7nach", "so", "man\u00b7ches", "Mensch", "mit", "Flei\u00df", "vnd", "Wil\u00b7len", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mir aber wil von dem zu sagen nicht geziemen,", "tokens": ["Mir", "a\u00b7ber", "wil", "von", "dem", "zu", "sa\u00b7gen", "nicht", "ge\u00b7zie\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "APPR", "ART", "PTKZU", "VVINF", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was diese Stadt an jhr vorhin schon weis zu r\u00fchmen", "tokens": ["Was", "die\u00b7se", "Stadt", "an", "jhr", "vor\u00b7hin", "schon", "weis", "zu", "r\u00fch\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PDAT", "NN", "APPR", "PPER", "ADV", "ADV", "PTKVZ", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Vnd k\u00fcndig ist ohn mich, sie sey nun wer sie wil,", "tokens": ["Vnd", "k\u00fcn\u00b7dig", "ist", "ohn", "mich", ",", "sie", "sey", "nun", "wer", "sie", "wil", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "PPER", "$,", "PPER", "VAFIN", "ADV", "PWS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "From, sitsam, h\u00e4u\u00dflich, sch\u00f6n, bescheiden, fleissig, still.", "tokens": ["From", ",", "sit\u00b7sam", ",", "h\u00e4u\u00df\u00b7lich", ",", "sch\u00f6n", ",", "be\u00b7schei\u00b7den", ",", "fleis\u00b7sig", ",", "still", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sie ist die deine nun mit allen jhren Gaben,", "tokens": ["Sie", "ist", "die", "dei\u00b7ne", "nun", "mit", "al\u00b7len", "jhren", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PPOSAT", "ADV", "APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Hie den Lohn soltest du f\u00fcr deine Tugend haben,", "tokens": ["Hie", "den", "Lohn", "sol\u00b7test", "du", "f\u00fcr", "dei\u00b7ne", "Tu\u00b7gend", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Sitten, den Verstandt, die dir des H\u00f6chsten Raht", "tokens": ["Die", "Sit\u00b7ten", ",", "den", "Ver\u00b7standt", ",", "die", "dir", "des", "H\u00f6chs\u00b7ten", "Raht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "PRELS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Durch vnbewegten Schlu\u00df l\u00e4ngst vorbehalten hat.", "tokens": ["Durch", "vn\u00b7be\u00b7weg\u00b7ten", "Schlu\u00df", "l\u00e4ngst", "vor\u00b7be\u00b7hal\u00b7ten", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "An dem Herren mu\u00df es liegen,", "tokens": ["An", "dem", "Her\u00b7ren", "mu\u00df", "es", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er sieht was sich vnverwandt", "tokens": ["Er", "sieht", "was", "sich", "vn\u00b7ver\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PWS", "PRF", "ADJD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "K\u00fcnfftig sol zusammen f\u00fcgen", "tokens": ["K\u00fcnff\u00b7tig", "sol", "zu\u00b7sam\u00b7men", "f\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VMFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den s\u00fcssen Heyrahts-Standt:", "tokens": ["In", "den", "s\u00fcs\u00b7sen", "Hey\u00b7rahts\u00b7Standt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zwar der Mensch kan jhm zu lieben", "tokens": ["Zwar", "der", "Mensch", "kan", "jhm", "zu", "lie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seines gleichen au\u00dfersehn,", "tokens": ["Sei\u00b7nes", "glei\u00b7chen", "au\u00b7\u00dfer\u00b7sehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Was bey Gott nicht ist verschrieben,", "tokens": ["Was", "bey", "Gott", "nicht", "ist", "ver\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PTKNEG", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Kan vnd mu\u00df auch nicht geschehn.", "tokens": ["Kan", "vnd", "mu\u00df", "auch", "nicht", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KON", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Du magst nun deiner M\u00fch vnd Arbeit wol geniessen,", "tokens": ["Du", "magst", "nun", "dei\u00b7ner", "M\u00fch", "vnd", "Ar\u00b7beit", "wol", "ge\u00b7nies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es wird dir wol bezahlt, la\u00df dich es nicht verdriessen,", "tokens": ["Es", "wird", "dir", "wol", "be\u00b7zahlt", ",", "la\u00df", "dich", "es", "nicht", "ver\u00b7dries\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,", "VVIMP", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vnd hettest du dich gleich gewaget vmb den Nort,", "tokens": ["Vnd", "het\u00b7test", "du", "dich", "gleich", "ge\u00b7wa\u00b7get", "vmb", "den", "Nort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die schwere Stra\u00df entdeckt an den Chinenser Port", "tokens": ["Die", "schwe\u00b7re", "Stra\u00df", "ent\u00b7deckt", "an", "den", "Chi\u00b7nen\u00b7ser", "Port"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Bey Nova-Zembla weg, viel Hungers-Noth erlitten", "tokens": ["Bey", "No\u00b7va\u00b7Zem\u00b7bla", "weg", ",", "viel", "Hun\u00b7ger\u00b7sNoth", "er\u00b7lit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "PTKVZ", "$,", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit B\u00e4ren wilder Art, mit Ey\u00df vnd Frost gestritten,", "tokens": ["Mit", "B\u00e4\u00b7ren", "wil\u00b7der", "Art", ",", "mit", "Ey\u00df", "vnd", "Frost", "ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja hettest du gleich auch den newen Magellan", "tokens": ["Ja", "het\u00b7test", "du", "gleich", "auch", "den", "ne\u00b7wen", "Ma\u00b7gel\u00b7lan"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "VAFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Durch viel Gefahr vnd Noth der Erden kundt gethan", "tokens": ["Durch", "viel", "Ge\u00b7fahr", "vnd", "Noth", "der", "Er\u00b7den", "kundt", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "ART", "NN", "PTKVZ", "VVPP"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Vnd werest Hellen-ab wie Hercules gegangen,", "tokens": ["Vnd", "we\u00b7rest", "Hel\u00b7len\u00b7ab", "wie", "Her\u00b7cu\u00b7les", "ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NN", "KOKOM", "NN", "VVPP", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.10": {"text": "Was k\u00f6ntestu hievor f\u00fcr gr\u00f6ssern Lohn empfangen", "tokens": ["Was", "k\u00f6n\u00b7tes\u00b7tu", "hie\u00b7vor", "f\u00fcr", "gr\u00f6s\u00b7sern", "Lohn", "emp\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PAV", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Als eben dieses Gut? es kan auff so viel Pein", "tokens": ["Als", "e\u00b7ben", "die\u00b7ses", "Gut", "?", "es", "kan", "auff", "so", "viel", "Pein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PDAT", "NN", "$.", "PPER", "VMFIN", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.12": {"text": "Dir, Pelops, thewrer nicht Hippodamia seyn.", "tokens": ["Dir", ",", "Pe\u00b7lops", ",", "thew\u00b7rer", "nicht", "Hip\u00b7po\u00b7da\u00b7mia", "seyn", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "$,", "ADJD", "PTKNEG", "NE", "VAINF", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Was Frewde wird dein Hertz, was volle Gn\u00fcg empfinden,", "tokens": ["Was", "Frew\u00b7de", "wird", "dein", "Hertz", ",", "was", "vol\u00b7le", "Gn\u00fcg", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PWS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wenn sie dir deinen Geist wird inniglich entbinden,", "tokens": ["Wenn", "sie", "dir", "dei\u00b7nen", "Geist", "wird", "in\u00b7nig\u00b7lich", "ent\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NN", "VAFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wird allen Vnmuth fern au\u00df deiner Seelen thun", "tokens": ["Wird", "al\u00b7len", "Vn\u00b7muth", "fern", "au\u00df", "dei\u00b7ner", "See\u00b7len", "thun"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Vnd schaffen was du wilt. Wolan, so gehe nun,", "tokens": ["Vnd", "schaf\u00b7fen", "was", "du", "wilt", ".", "Wo\u00b7lan", ",", "so", "ge\u00b7he", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VMFIN", "$.", "ADV", "$,", "ADV", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Nim ein dein eignes Reich vnd hersche nach belieben!", "tokens": ["Nim", "ein", "dein", "eig\u00b7nes", "Reich", "vnd", "her\u00b7sche", "nach", "be\u00b7lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "PPOSAT", "ADJA", "NN", "KON", "VVFIN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Es steht dir frey, was dich gel\u00fcstet, zu ver\u00fcben,", "tokens": ["Es", "steht", "dir", "frey", ",", "was", "dich", "ge\u00b7l\u00fcs\u00b7tet", ",", "zu", "ver\u00b7\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PWS", "PPER", "VVPP", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Trotz einem, der sich hie wolt' etwas vnterstehn,", "tokens": ["Trotz", "ei\u00b7nem", ",", "der", "sich", "hie", "wolt'", "et\u00b7was", "vn\u00b7ter\u00b7stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PRF", "ADV", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Das nicht nach deinem Sinn vnd Willen solte gehn,", "tokens": ["Das", "nicht", "nach", "dei\u00b7nem", "Sinn", "vnd", "Wil\u00b7len", "sol\u00b7te", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "APPR", "PPOSAT", "NN", "KON", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Hie ist kein Herr als du. Die Augen als zwo Sonnen,", "tokens": ["Hie", "ist", "kein", "Herr", "als", "du", ".", "Die", "Au\u00b7gen", "als", "zwo", "Son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "KOUS", "PPER", "$.", "ART", "NN", "KOKOM", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die dich vor langer Zeit durch jhre Krafft gewonnen,", "tokens": ["Die", "dich", "vor", "lan\u00b7ger", "Zeit", "durch", "jhre", "Krafft", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Der keusche Mund, das Haar seyn nun dein Eigenthum", "tokens": ["Der", "keu\u00b7sche", "Mund", ",", "das", "Haar", "seyn", "nun", "dein", "Ei\u00b7gen\u00b7thum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "PPOSAT", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Vnd mehren vberau\u00df dein Ansehn Ehr vnd Ruhm.", "tokens": ["Vnd", "meh\u00b7ren", "vbe\u00b7rau\u00df", "dein", "An\u00b7sehn", "Ehr", "vnd", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "Es wird von jederman dein guter Sinn gepriesen,", "tokens": ["Es", "wird", "von", "je\u00b7der\u00b7man", "dein", "gu\u00b7ter", "Sinn", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIS", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Da\u00df du dich hierin auch behutsam hast erwiesen", "tokens": ["Da\u00df", "du", "dich", "hie\u00b7rin", "auch", "be\u00b7hut\u00b7sam", "hast", "er\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ADV", "ADJD", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Vnd dir an deine Seit' ein solches Mensch gelegt,", "tokens": ["Vnd", "dir", "an", "dei\u00b7ne", "Seit'", "ein", "sol\u00b7ches", "Mensch", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "ART", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Das in Geberden Zucht vnd Trew im Hertzen tr\u00e4gt.", "tokens": ["Das", "in", "Ge\u00b7ber\u00b7den", "Zucht", "vnd", "Trew", "im", "Hert\u00b7zen", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.26": {"line.1": {"text": "Wer sich hie auff Gut wil gr\u00fcnden,", "tokens": ["Wer", "sich", "hie", "auff", "Gut", "wil", "gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat auff schwaches Ey\u00df gebawt;", "tokens": ["Hat", "auff", "schwa\u00b7ches", "Ey\u00df", "ge\u00b7bawt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gl\u00fcck vnd Geld pflegt zu verschwinden", "tokens": ["Gl\u00fcck", "vnd", "Geld", "pflegt", "zu", "ver\u00b7schwin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie der Schnee thut, wenn es thawt:", "tokens": ["Wie", "der", "Schnee", "thut", ",", "wenn", "es", "thawt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Wie ein Dunst, der aus den Kl\u00fcfften", "tokens": ["Wie", "ein", "Dunst", ",", "der", "aus", "den", "Kl\u00fcff\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vber sich gen Himmel f\u00e4hrt", "tokens": ["Vber", "sich", "gen", "Him\u00b7mel", "f\u00e4hrt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "APPR", "NN", "VVFIN"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vnd von Winden in den L\u00fcfften", "tokens": ["Vnd", "von", "Win\u00b7den", "in", "den", "L\u00fcff\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird zerstoben vnd verz\u00e4hrt.", "tokens": ["Wird", "zer\u00b7sto\u00b7ben", "vnd", "ver\u00b7z\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Ein standhaffter Sinn bestehet,", "tokens": ["Ein", "stand\u00b7haff\u00b7ter", "Sinn", "be\u00b7ste\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Krieget Prei\u00df vnd schwebt empor,", "tokens": ["Krie\u00b7get", "Prei\u00df", "vnd", "schwebt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd die Zucht im Hertzen gehet", "tokens": ["Vnd", "die", "Zucht", "im", "Hert\u00b7zen", "ge\u00b7het"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tausent Tonnen Goldes vor.", "tokens": ["Tau\u00b7sent", "Ton\u00b7nen", "Gol\u00b7des", "vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Du siehst nicht auff den Schein der eusserlichen Sachen,", "tokens": ["Du", "siehst", "nicht", "auff", "den", "Schein", "der", "eus\u00b7ser\u00b7li\u00b7chen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der nur die Augen f\u00fcllt vnd keinen gut kan machen,", "tokens": ["Der", "nur", "die", "Au\u00b7gen", "f\u00fcllt", "vnd", "kei\u00b7nen", "gut", "kan", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "KON", "PIAT", "ADJD", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du thust was dir gefellt vnd h\u00f6rest g\u00e4ntzlich nicht", "tokens": ["Du", "thust", "was", "dir", "ge\u00b7fellt", "vnd", "h\u00f6\u00b7rest", "g\u00e4ntz\u00b7lich", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VVPP", "KON", "VVFIN", "ADJD", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den, der dich meistern wil vnd solch ein Vrtheil spricht,", "tokens": ["Den", ",", "der", "dich", "meis\u00b7tern", "wil", "vnd", "solch", "ein", "Vrtheil", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PRF", "VVINF", "VMFIN", "KON", "PIAT", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "So nimmer kan bestehn, der sich pflegt zu verwirren", "tokens": ["So", "nim\u00b7mer", "kan", "be\u00b7stehn", ",", "der", "sich", "pflegt", "zu", "ver\u00b7wir\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VMFIN", "VVINF", "$,", "PRELS", "PRF", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Vnd doch f\u00fcr weise sch\u00e4tzt. Was? er sol dich nun irren?", "tokens": ["Vnd", "doch", "f\u00fcr", "wei\u00b7se", "sch\u00e4tzt", ".", "Was", "?", "er", "sol", "dich", "nun", "ir\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADV", "VVFIN", "$.", "PWS", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er, welcher wenig Witz in dem Gehirne helt,", "tokens": ["Er", ",", "wel\u00b7cher", "we\u00b7nig", "Witz", "in", "dem", "Ge\u00b7hir\u00b7ne", "helt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dich, der sein gantzes Thun auff solchen Grund gestellt,", "tokens": ["Dich", ",", "der", "sein", "gant\u00b7zes", "Thun", "auff", "sol\u00b7chen", "Grund", "ge\u00b7stellt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Der blo\u00df auff Wei\u00dfheit steht, dich, der erst vberleget,", "tokens": ["Der", "blo\u00df", "auff", "Wei\u00df\u00b7heit", "steht", ",", "dich", ",", "der", "erst", "vber\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$,", "PPER", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Erst auff das Ende sieht, dan nachzusetzen pfleget?", "tokens": ["Erst", "auff", "das", "En\u00b7de", "sieht", ",", "dan", "nach\u00b7zu\u00b7set\u00b7zen", "pfle\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,", "ADV", "VVIZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ach st\u00fcnd' es mir nur jetzt mit deinem Willen frey", "tokens": ["Ach", "st\u00fcnd'", "es", "mir", "nur", "jetzt", "mit", "dei\u00b7nem", "Wil\u00b7len", "frey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "VVFIN", "PPER", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zu singen, was dein Lob vnd deine Tugend sey,", "tokens": ["Zu", "sin\u00b7gen", ",", "was", "dein", "Lob", "vnd", "dei\u00b7ne", "Tu\u00b7gend", "sey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PRELS", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "In was Volkommenheit dich deine Kunst genommen,", "tokens": ["In", "was", "Vol\u00b7kom\u00b7men\u00b7heit", "dich", "dei\u00b7ne", "Kunst", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ich w\u00fcste, was ich th\u00e4t'; ich wolt' auff Dinge kommen,", "tokens": ["Ich", "w\u00fcs\u00b7te", ",", "was", "ich", "th\u00e4t'", ";", "ich", "wolt'", "auff", "Din\u00b7ge", "kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$.", "PPER", "VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die mein Verh\u00e4ngnus mir au\u00df Vngunst hat versagt", "tokens": ["Die", "mein", "Ver\u00b7h\u00e4ng\u00b7nus", "mir", "au\u00df", "Vn\u00b7gunst", "hat", "ver\u00b7sagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "PPER", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Vnd deinem Geist ertheilt, der in die Wolcken ragt", "tokens": ["Vnd", "dei\u00b7nem", "Geist", "er\u00b7theilt", ",", "der", "in", "die", "Wol\u00b7cken", "ragt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Vnd mich hierunten lesst nicht anders, als die Eichen", "tokens": ["Vnd", "mich", "hier\u00b7un\u00b7ten", "lesst", "nicht", "an\u00b7ders", ",", "als", "die", "Ei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "VVFIN", "PTKNEG", "ADV", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vnd Tannen-B\u00e4ume sonst den kleinen Kattich-Str\u00e4uchen", "tokens": ["Vnd", "Tan\u00b7nen\u00b7B\u00e4u\u00b7me", "sonst", "den", "klei\u00b7nen", "Kat\u00b7tich\u00b7Str\u00e4u\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Am frischen Haffe thun, du soltest mir allein", "tokens": ["Am", "fri\u00b7schen", "Haf\u00b7fe", "thun", ",", "du", "sol\u00b7test", "mir", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$,", "PPER", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Zu einem sch\u00f6nen Lied' ein reicher Vorrath seyn;", "tokens": ["Zu", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Lied'", "ein", "rei\u00b7cher", "Vor\u00b7rath", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Du aber bist, mein Freundt, auch die\u00dffals zu bescheiden", "tokens": ["Du", "a\u00b7ber", "bist", ",", "mein", "Freundt", ",", "auch", "die\u00df\u00b7fals", "zu", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "$,", "PPOSAT", "NN", "$,", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Vnd g\u00e4ntzlich nicht gewohnt dein eigen Lob zu leiden:", "tokens": ["Vnd", "g\u00e4ntz\u00b7lich", "nicht", "ge\u00b7wohnt", "dein", "ei\u00b7gen", "Lob", "zu", "lei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKNEG", "ADJD", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Kurtz, du beginnst, was dir hernach nicht leid seyn kan,", "tokens": ["Kurtz", ",", "du", "be\u00b7ginnst", ",", "was", "dir", "her\u00b7nach", "nicht", "leid", "seyn", "kan", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "$,", "PWS", "PPER", "ADV", "PTKNEG", "ADJD", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Vnd siehst der Sachen Lauff mit solchen Augen an,", "tokens": ["Vnd", "siehst", "der", "Sa\u00b7chen", "Lauff", "mit", "sol\u00b7chen", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Die Hertz seyn vnd Verstandt, vnd solttest allermassen", "tokens": ["Die", "Hertz", "seyn", "vnd", "Ver\u00b7standt", ",", "vnd", "solt\u00b7test", "al\u00b7ler\u00b7mas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAINF", "KON", "NN", "$,", "KON", "XY", "XY"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Dich eines jeden Wahn herumbher f\u00fchren lassen,", "tokens": ["Dich", "ei\u00b7nes", "je\u00b7den", "Wahn", "he\u00b7rum\u00b7bher", "f\u00fch\u00b7ren", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "PIAT", "NN", "APZR", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Gerad' als sonst bey vns der zoticht-rauche B\u00e4hr", "tokens": ["Ge\u00b7rad'", "als", "sonst", "bey", "vns", "der", "zo\u00b7ticht\u00b7rau\u00b7che", "B\u00e4hr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ADV", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Den Maulkorb leiden mu\u00df vnd folget hin vnd her,", "tokens": ["Den", "Maul\u00b7korb", "lei\u00b7den", "mu\u00df", "vnd", "fol\u00b7get", "hin", "vnd", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "KON", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wohin sein Leiter wil? O nein, such einzuschliessen", "tokens": ["Wo\u00b7hin", "sein", "Lei\u00b7ter", "wil", "?", "O", "nein", ",", "such", "ein\u00b7zu\u00b7schlies\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "VMFIN", "$.", "NE", "PTKANT", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Des Pregels strengen Gang, er wird wol Wege wissen,", "tokens": ["Des", "Pre\u00b7gels", "stren\u00b7gen", "Gang", ",", "er", "wird", "wol", "We\u00b7ge", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PPER", "VAFIN", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Zu kommen in die See, die Glut geht lo\u00df vnd frey,", "tokens": ["Zu", "kom\u00b7men", "in", "die", "See", ",", "die", "Glut", "geht", "lo\u00df", "vnd", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PTKVZ", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Vnd springt dar\u00fcber auch die B\u00fcchse gleich entzwey.", "tokens": ["Vnd", "springt", "da\u00b7r\u00fc\u00b7ber", "auch", "die", "B\u00fcch\u00b7se", "gleich", "ent\u00b7zwey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ADV", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Es kan bey vns kein ding zwar vnberedet bleiben,", "tokens": ["Es", "kan", "bey", "vns", "kein", "ding", "zwar", "vn\u00b7be\u00b7re\u00b7det", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PIAT", "NN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Du aber lessest es den starken Ost-Wind treiben", "tokens": ["Du", "a\u00b7ber", "les\u00b7sest", "es", "den", "star\u00b7ken", "Ost\u00b7Wind", "trei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Hin auff die W\u00fcste Fluth vnd thust, was gut vnd recht", "tokens": ["Hin", "auff", "die", "W\u00fcs\u00b7te", "Fluth", "vnd", "thust", ",", "was", "gut", "vnd", "recht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "KON", "VVFIN", "$,", "PRELS", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "F\u00fcr weisen Augen scheint, bist keiner Thorheit Knecht.", "tokens": ["F\u00fcr", "wei\u00b7sen", "Au\u00b7gen", "scheint", ",", "bist", "kei\u00b7ner", "Thor\u00b7heit", "Knecht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "VAFIN", "PIAT", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Horch aber zu! was da? Es sind Appollos Seiten,", "tokens": ["Horch", "a\u00b7ber", "zu", "!", "was", "da", "?", "Es", "sind", "Ap\u00b7pol\u00b7los", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKVZ", "$.", "PWS", "ADV", "$.", "PPER", "VAFIN", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Der kompt vnd wil dich hin zu deiner Rhue begleiten,", "tokens": ["Der", "kompt", "vnd", "wil", "dich", "hin", "zu", "dei\u00b7ner", "Rhue", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VMFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "In dem das Amor blo\u00df auff Boltzen ist bedacht", "tokens": ["In", "dem", "das", "A\u00b7mor", "blo\u00df", "auff", "Bolt\u00b7zen", "ist", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NE", "ADV", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Vnd tausent jetzt verscheusst, jetzt tausent wieder macht,", "tokens": ["Vnd", "tau\u00b7sent", "jetzt", "ver\u00b7scheusst", ",", "jetzt", "tau\u00b7sent", "wie\u00b7der", "macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVFIN", "$,", "ADV", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Vnd Hymen allbereit die Kertzen angez\u00fcndet,", "tokens": ["Vnd", "Hy\u00b7men", "all\u00b7be\u00b7reit", "die", "Kert\u00b7zen", "an\u00b7ge\u00b7z\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Dione beyder Hertz in einen Knohten bindet,", "tokens": ["Dio\u00b7ne", "bey\u00b7der", "Hertz", "in", "ei\u00b7nen", "Knoh\u00b7ten", "bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.43": {"text": "Beschleusst er, Cynthius, ein guter K\u00fcnste-Mann,", "tokens": ["Be\u00b7schleusst", "er", ",", "Cyn\u00b7thi\u00b7us", ",", "ein", "gu\u00b7ter", "K\u00fcns\u00b7te\u00b7Mann", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Die\u00df Hochzeit-Fest vnd hebt sein kurtzes Braut-Lied an:", "tokens": ["Die\u00df", "Hoch\u00b7zeit\u00b7Fest", "vnd", "hebt", "sein", "kurt\u00b7zes", "Braut\u00b7Lied", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Wollt jhr nicht ein Ende machen,", "tokens": ["Wollt", "jhr", "nicht", "ein", "En\u00b7de", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihr verliebtes Seelen-Paar?", "tokens": ["Ihr", "ver\u00b7lieb\u00b7tes", "See\u00b7len\u00b7Paar", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seht, es ist mit allen Sachen,", "tokens": ["Seht", ",", "es", "ist", "mit", "al\u00b7len", "Sa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die dazu geh\u00f6ren, klar,", "tokens": ["Die", "da\u00b7zu", "ge\u00b7h\u00f6\u00b7ren", ",", "klar", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PAV", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Kompt, der Himmel sagt euch Rhue,", "tokens": ["Kompt", ",", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Meiner Sonnen Pferde trincken,", "tokens": ["Mei\u00b7ner", "Son\u00b7nen", "Pfer\u00b7de", "trin\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hundert liechter Sterne Goldt", "tokens": ["Hun\u00b7dert", "liech\u00b7ter", "Ster\u00b7ne", "Goldt"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seh ich euch zu Ehren blincken,", "tokens": ["Seh", "ich", "euch", "zu", "Eh\u00b7ren", "blin\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nacht vnd alles ist euch hold.", "tokens": ["Nacht", "vnd", "al\u00b7les", "ist", "euch", "hold", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PIS", "VAFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kompt, der Himmel sagt euch Rhue,", "tokens": ["Kompt", ",", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "O das selige Begn\u00fcgen,", "tokens": ["O", "das", "se\u00b7li\u00b7ge", "Be\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So jhr findet beyderseit!", "tokens": ["So", "jhr", "fin\u00b7det", "bey\u00b7der\u00b7seit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kan sich auch was besser f\u00fcgen?", "tokens": ["Kan", "sich", "auch", "was", "bes\u00b7ser", "f\u00fc\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "PWS", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was hat besser je gefreyt?", "tokens": ["Was", "hat", "bes\u00b7ser", "je", "ge\u00b7freyt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "ADV", "VVPP", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.5": {"text": "Kompt, der Himmel sagt euch Rhue,", "tokens": ["Kompt", ",", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Deiner Liebsten Glantz vnd Gaben", "tokens": ["Dei\u00b7ner", "Liebs\u00b7ten", "Glantz", "vnd", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Rahmen, Br\u00e4utgam, manchen ein,", "tokens": ["Rah\u00b7men", ",", "Br\u00e4ut\u00b7gam", ",", "man\u00b7chen", "ein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "PIAT", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber der sie muste haben", "tokens": ["A\u00b7ber", "der", "sie", "mus\u00b7te", "ha\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "VMFIN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Soltest du vnd niemand seyn.", "tokens": ["Sol\u00b7test", "du", "vnd", "nie\u00b7mand", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KON", "PIS", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kompt, der Himmel sagt euch Rhue,", "tokens": ["Kompt", ",", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Diesen Mann von klugen Sinnen", "tokens": ["Die\u00b7sen", "Mann", "von", "klu\u00b7gen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd von solcher hohen Kunst", "tokens": ["Vnd", "von", "sol\u00b7cher", "ho\u00b7hen", "Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Soltest du, Braut, nur gewinnen,", "tokens": ["Sol\u00b7test", "du", ",", "Braut", ",", "nur", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "NN", "$,", "ADV", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Du nur lindern seine Brunst.", "tokens": ["Du", "nur", "lin\u00b7dern", "sei\u00b7ne", "Brunst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kompt, der Himmel sagt euch Rhue,", "tokens": ["Kompt", ",", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Nun man fordert von euch Samen,", "tokens": ["Nun", "man", "for\u00b7dert", "von", "euch", "Sa\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "APPR", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Den doch ich vor allen such',", "tokens": ["Den", "doch", "ich", "vor", "al\u00b7len", "such'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auff, vnd schreibet ewren Nahmen", "tokens": ["Auff", ",", "vnd", "schrei\u00b7bet", "ew\u00b7ren", "Nah\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der sp\u00e4ten Nachwelt Buch!", "tokens": ["In", "der", "sp\u00e4\u00b7ten", "Nach\u00b7welt", "Buch", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Kompt, der Himmel sagt euch Rhue,", "tokens": ["Kompt", ",", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Kompt jhr? ja, es sol nicht triegen,", "tokens": ["Kompt", "jhr", "?", "ja", ",", "es", "sol", "nicht", "trie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PTKANT", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ich sage, wird geschehn,", "tokens": ["Was", "ich", "sa\u00b7ge", ",", "wird", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das man j\u00e4hrlich in der Wiegen", "tokens": ["Das", "man", "j\u00e4hr\u00b7lich", "in", "der", "Wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ewrer Liebe Frucht wird sehn.", "tokens": ["Ew\u00b7rer", "Lie\u00b7be", "Frucht", "wird", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn der Himmel sagt euch Rhue,", "tokens": ["Denn", "der", "Him\u00b7mel", "sagt", "euch", "Rhue", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gl\u00fcck vnd grossen Segen zu.", "tokens": ["Gl\u00fcck", "vnd", "gros\u00b7sen", "Se\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}