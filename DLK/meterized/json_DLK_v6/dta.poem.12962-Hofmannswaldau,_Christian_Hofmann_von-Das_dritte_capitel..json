{"dta.poem.12962": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Das dritte capitel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wie selig ist ein mensch, der aus der wahrheit munde", "tokens": ["Wie", "se\u00b7lig", "ist", "ein", "mensch", ",", "der", "aus", "der", "wahr\u00b7heit", "mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das wort des lebens lerut, und sie selbst reden h\u00f6rt.", "tokens": ["Das", "wort", "des", "le\u00b7bens", "le\u00b7rut", ",", "und", "sie", "selbst", "re\u00b7den", "h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,", "KON", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Von menschen wird der mensch doch nicht so wohl ge-", "tokens": ["Von", "men\u00b7schen", "wird", "der", "mensch", "doch", "nicht", "so", "wohl", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "ADV", "PTKNEG", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "lehrt.", "tokens": ["lehrt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Und von ihm selber kommt kein hertze bis zum grunde.", "tokens": ["Und", "von", "ihm", "sel\u00b7ber", "kommt", "kein", "hert\u00b7ze", "bis", "zum", "grun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ADV", "VVFIN", "PIAT", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ach waruni zancken wir um dinge, die subtil", "tokens": ["Ach", "wa\u00b7ru\u00b7ni", "zan\u00b7cken", "wir", "um", "din\u00b7ge", ",", "die", "sub\u00b7til"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "ITJ", "VVFIN", "PPER", "APPR", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.7": {"text": "Und doch nichts n\u00fctze sind? da GOtt um solcher willen,", "tokens": ["Und", "doch", "nichts", "n\u00fct\u00b7ze", "sind", "?", "da", "Gott", "um", "sol\u00b7cher", "wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIS", "VVFIN", "VAFIN", "$.", "KOUS", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den, der sie gleich nicht wei\u00df, doch nicht verdammen will.", "tokens": ["Den", ",", "der", "sie", "gleich", "nicht", "wei\u00df", ",", "doch", "nicht", "ver\u00b7dam\u00b7men", "will", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn GOtt sieht auf das hertz, und nicht auf unsre grillen.", "tokens": ["Denn", "Gott", "sieht", "auf", "das", "hertz", ",", "und", "nicht", "auf", "uns\u00b7re", "gril\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "PTKNEG", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wir aber gehn dennoch und k\u00fcmmern uns um sachen,", "tokens": ["Wir", "a\u00b7ber", "gehn", "den\u00b7noch", "und", "k\u00fcm\u00b7mern", "uns", "um", "sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die doch mehr unser schad, als unser nutzen sind.", "tokens": ["Die", "doch", "mehr", "un\u00b7ser", "schad", ",", "als", "un\u00b7ser", "nut\u00b7zen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "PPOSAT", "ADJD", "$,", "KOUS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So bleibt der tolle mensch bey heller sonne blind.", "tokens": ["So", "bleibt", "der", "tol\u00b7le", "mensch", "bey", "hel\u00b7ler", "son\u00b7ne", "blind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach last uns doch einmal von diesem schlaf erwachen!", "tokens": ["Ach", "last", "uns", "doch", "ein\u00b7mal", "von", "die\u00b7sem", "schlaf", "er\u00b7wa\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Die streit- und rede-kunst gilt hier wahrhafftig nicht.", "tokens": ["Die", "streit", "und", "re\u00b7de\u00b7kunst", "gilt", "hier", "wahr\u00b7haff\u00b7tig", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VVFIN", "ADV", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Von solchen eltern wird die wahrheit nicht gebohren,", "tokens": ["Von", "sol\u00b7chen", "el\u00b7tern", "wird", "die", "wahr\u00b7heit", "nicht", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo nicht des Lichtes wort des hertzens nebel bricht,", "tokens": ["Wo", "nicht", "des", "Lich\u00b7tes", "wort", "des", "hert\u00b7zens", "ne\u00b7bel", "bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ART", "NN", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Und allen irrthum d\u00e4mpfft, so gehen wir verlohren.", "tokens": ["Und", "al\u00b7len", "irr\u00b7thum", "d\u00e4mpfft", ",", "so", "ge\u00b7hen", "wir", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Denn alle dinge sind aus einem Wort entsprossen,", "tokens": ["Denn", "al\u00b7le", "din\u00b7ge", "sind", "aus", "ei\u00b7nem", "Wort", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und alles lehret uns zu diesem Worte gehn.", "tokens": ["Und", "al\u00b7les", "leh\u00b7ret", "uns", "zu", "die\u00b7sem", "Wor\u00b7te", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPR", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer dieses nicht vernimmt, der kan auch nichts verstehn,", "tokens": ["Wer", "die\u00b7ses", "nicht", "ver\u00b7nimmt", ",", "der", "kan", "auch", "nichts", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "PTKNEG", "VVFIN", "$,", "PRELS", "VMFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil es der anfang ist, aus dem der witz geflossen.", "tokens": ["Weil", "es", "der", "an\u00b7fang", "ist", ",", "aus", "dem", "der", "witz", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$,", "APPR", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Drum wer in allen dich, und alles in dir liebt,", "tokens": ["Drum", "wer", "in", "al\u00b7len", "dich", ",", "und", "al\u00b7les", "in", "dir", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PWS", "APPR", "PIAT", "PPER", "$,", "KON", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der mag von dir, o Wort! du brunnen aller gaben!", "tokens": ["Der", "mag", "von", "dir", ",", "o", "Wort", "!", "du", "brun\u00b7nen", "al\u00b7ler", "ga\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "PPER", "$,", "FM", "NN", "$.", "PPER", "NN", "PIAT", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wohl einen festen sinn, der sich im guten \u00fcbt,", "tokens": ["Wohl", "ei\u00b7nen", "fes\u00b7ten", "sinn", ",", "der", "sich", "im", "gu\u00b7ten", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PRELS", "PRF", "APPRART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ein in GOtt vergn\u00fcgt und ruhig hertze haben.", "tokens": ["Und", "ein", "in", "Gott", "ver\u00b7gn\u00fcgt", "und", "ru\u00b7hig", "hert\u00b7ze", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NN", "VVPP", "KON", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Drum, o du einige, du ewig-lichte Wahrheit!", "tokens": ["Drum", ",", "o", "du", "ei\u00b7ni\u00b7ge", ",", "du", "e\u00b7wig\u00b7lich\u00b7te", "Wahr\u00b7heit", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "FM", "PPER", "PIS", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vereinige mich doch mit dir in deiner brunst!", "tokens": ["Ver\u00b7ei\u00b7ni\u00b7ge", "mich", "doch", "mit", "dir", "in", "dei\u00b7ner", "brunst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was ich sonst les\u2019 und h\u00f6r\u2019, ist freylich nur ein dunst", "tokens": ["Was", "ich", "sonst", "les'", "und", "h\u00f6r'", ",", "ist", "frey\u00b7lich", "nur", "ein", "dunst"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADJD", "KON", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor deines Geistes krafft, und deines wortes klarheit.", "tokens": ["Vor", "dei\u00b7nes", "Geis\u00b7tes", "krafft", ",", "und", "dei\u00b7nes", "wor\u00b7tes", "klar\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was meine seele w\u00fcnscht, das find\u2019 ich blos in dir.", "tokens": ["Was", "mei\u00b7ne", "see\u00b7le", "w\u00fcnscht", ",", "das", "find'", "ich", "blos", "in", "dir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "PDS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Drum schweigt, ihr Lehrer! schweigt! und alle welt sey stille!", "tokens": ["Drum", "schweigt", ",", "ihr", "Leh\u00b7rer", "!", "schweigt", "!", "und", "al\u00b7le", "welt", "sey", "stil\u00b7le", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PPOSAT", "NN", "$.", "VVFIN", "$.", "KON", "PIAT", "NN", "VAFIN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du aber red\u2019 allein, ach red\u2019 allein zu mir,", "tokens": ["Du", "a\u00b7ber", "red'", "al\u00b7lein", ",", "ach", "red'", "al\u00b7lein", "zu", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "$,", "ITJ", "VVFIN", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Damit nichts, als dein wort des hertzens grund erf\u00fclle.", "tokens": ["Da\u00b7mit", "nichts", ",", "als", "dein", "wort", "des", "hert\u00b7zens", "grund", "er\u00b7f\u00fcl\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "$,", "KOUS", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.5": {"line.1": {"text": "Je mehr man in ihm selbst der einfalt sich beflei\u00dfet,", "tokens": ["Je", "mehr", "man", "in", "ihm", "selbst", "der", "ein\u00b7falt", "sich", "be\u00b7flei\u00b7\u00dfet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "APPR", "PPER", "ADV", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und aus der \u00e4usern welt in sein gewissen geht,", "tokens": ["Und", "aus", "der", "\u00e4u\u00b7sern", "welt", "in", "sein", "ge\u00b7wis\u00b7sen", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Je tiefre dinge man ohn alle m\u00fch versteht,", "tokens": ["Je", "tief\u00b7re", "din\u00b7ge", "man", "ohn", "al\u00b7le", "m\u00fch", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PIS", "APPR", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil GOtt den niedrigen licht und verstand verhei\u00dfet.", "tokens": ["Weil", "Gott", "den", "nied\u00b7ri\u00b7gen", "licht", "und", "ver\u00b7stand", "ver\u00b7hei\u00b7\u00dfet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "ADJA", "NN", "KON", "VVFIN", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ein geist, der lanter ist, und an der einfalt h\u00e4lt,", "tokens": ["Ein", "geist", ",", "der", "lan\u00b7ter", "ist", ",", "und", "an", "der", "ein\u00b7falt", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "L\u00e4st durch gesch\u00e4ffte sich nicht hin und her zerstreuen,", "tokens": ["L\u00e4st", "durch", "ge\u00b7sch\u00e4ff\u00b7te", "sich", "nicht", "hin", "und", "her", "zer\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "PRF", "PTKNEG", "PTKVZ", "KON", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Er flieht den eigen-ruhm, verleugnet neid und welt,", "tokens": ["Er", "flieht", "den", "ei\u00b7gen\u00b7ruhm", ",", "ver\u00b7leug\u00b7net", "neid", "und", "welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und will sich \u00fcber nichts, als GOttes ehr erfreuen.", "tokens": ["Und", "will", "sich", "\u00fc\u00b7ber", "nichts", ",", "als", "Got\u00b7tes", "ehr", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "PIS", "$,", "KOUS", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Wer mit der creutzigung der wilden l\u00fcste s\u00e4umet;", "tokens": ["Wer", "mit", "der", "creut\u00b7zi\u00b7gung", "der", "wil\u00b7den", "l\u00fcs\u00b7te", "s\u00e4u\u00b7met", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ART", "ADJA", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der macht ihm seine last un\u00fcberwindlich gro\u00df.", "tokens": ["Der", "macht", "ihm", "sei\u00b7ne", "last", "un\u00b7\u00fc\u00b7berw\u00b7ind\u00b7lich", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPOSAT", "VVFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Drum giebt ein frommer mensch von aussen sich nicht blos,", "tokens": ["Drum", "giebt", "ein", "from\u00b7mer", "mensch", "von", "aus\u00b7sen", "sich", "nicht", "blos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "APPR", "VVFIN", "PRF", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er habe denn zuvor innwendig aufger\u00e4umet.", "tokens": ["Er", "ha\u00b7be", "denn", "zu\u00b7vor", "inn\u00b7wen\u00b7dig", "auf\u00b7ge\u00b7r\u00e4u\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die b\u00f6se neigung mu\u00df durchaus get\u00f6dtet seyn,", "tokens": ["Die", "b\u00f6\u00b7se", "nei\u00b7gung", "mu\u00df", "durc\u00b7haus", "ge\u00b7t\u00f6d\u00b7tet", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und deine liebe sich nach der vernunfft regieren.", "tokens": ["Und", "dei\u00b7ne", "lie\u00b7be", "sich", "nach", "der", "ver\u00b7nunfft", "re\u00b7gie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VVFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Denn der begierden sturm rei\u00dft alle tugend ein,", "tokens": ["Denn", "der", "be\u00b7gier\u00b7den", "sturm", "rei\u00dft", "al\u00b7le", "tu\u00b7gend", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und l\u00e4st das hertze nicht die sanffte wahrheit f\u00fchren.", "tokens": ["Und", "l\u00e4st", "das", "hert\u00b7ze", "nicht", "die", "sanff\u00b7te", "wahr\u00b7heit", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Das mu\u00df ich wol gestehn: Sich selber \u00fcberwinden,", "tokens": ["Das", "mu\u00df", "ich", "wol", "ge\u00b7stehn", ":", "Sich", "sel\u00b7ber", "\u00fc\u00b7berw\u00b7in\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVPP", "$.", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist vor den zarten sinn der schwerste krieg und streit.", "tokens": ["Ist", "vor", "den", "zar\u00b7ten", "sinn", "der", "schwers\u00b7te", "krieg", "und", "streit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indessen must du dich aus GOttes krafft bereit,", "tokens": ["In\u00b7des\u00b7sen", "must", "du", "dich", "aus", "Got\u00b7tes", "krafft", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "NN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und niemals tr\u00e4g und faul, zu solchem kampffe finden.", "tokens": ["Und", "nie\u00b7mals", "tr\u00e4g", "und", "faul", ",", "zu", "sol\u00b7chem", "kampf\u00b7fe", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "ADJD", "$,", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das soll die arbeit seyn, davon wir itzt nicht ruhn.", "tokens": ["Das", "soll", "die", "ar\u00b7beit", "seyn", ",", "da\u00b7von", "wir", "itzt", "nicht", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "VAINF", "$,", "PAV", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der mensch mu\u00df tag vor tag sich in dem HErren st\u00e4rcken;", "tokens": ["Der", "mensch", "mu\u00df", "tag", "vor", "tag", "sich", "in", "dem", "Her\u00b7ren", "st\u00e4r\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "NN", "APPR", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn hier ist keine ruh, wir haben stets zu thun;", "tokens": ["Denn", "hier", "ist", "kei\u00b7ne", "ruh", ",", "wir", "ha\u00b7ben", "stets", "zu", "thun", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dort aber ruhen wir von allen unsern wercken.", "tokens": ["Dort", "a\u00b7ber", "ru\u00b7hen", "wir", "von", "al\u00b7len", "un\u00b7sern", "wer\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Was uns vollkommen scheint, ist dennoch unvollkommen.", "tokens": ["Was", "uns", "voll\u00b7kom\u00b7men", "scheint", ",", "ist", "den\u00b7noch", "un\u00b7voll\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVFIN", "$,", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der helleste verstand hat gleichwol nacht und dunst.", "tokens": ["Der", "hel\u00b7les\u00b7te", "ver\u00b7stand", "hat", "gleich\u00b7wol", "nacht", "und", "dunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "NN", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die selbst-erkenntni\u00df ist weit \u00fcber alle kunst.", "tokens": ["Die", "selbst\u00b7er\u00b7kennt\u00b7ni\u00df", "ist", "weit", "\u00fc\u00b7ber", "al\u00b7le", "kunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl diesem, der von sich die masqve weggenommen,", "tokens": ["Wohl", "die\u00b7sem", ",", "der", "von", "sich", "die", "mas\u00b7qve", "weg\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "$,", "PRELS", "APPR", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und seine nichtigkeit in demuth zugesteht!", "tokens": ["Und", "sei\u00b7ne", "nich\u00b7tig\u00b7keit", "in", "de\u00b7muth", "zu\u00b7ge\u00b7steht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Denn wahre demuth ist die rechte Jacobs-leiter.", "tokens": ["Denn", "wah\u00b7re", "de\u00b7muth", "ist", "die", "rech\u00b7te", "Ja\u00b7cobs\u00b7lei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Ein pharis\u00e4er f\u00e4llt, ie mehr er sich erh\u00f6ht,", "tokens": ["Ein", "pha\u00b7ri\u00b7s\u00e4\u00b7er", "f\u00e4llt", ",", "ie", "mehr", "er", "sich", "er\u00b7h\u00f6ht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ADV", "ADV", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wer sich erniedriget, der kommt bey GOtt viel weiter.", "tokens": ["Wer", "sich", "er\u00b7nied\u00b7ri\u00b7get", ",", "der", "kommt", "bey", "Gott", "viel", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVFIN", "$,", "PRELS", "VVFIN", "APPR", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ich habe mit dem wahn der thoren nichts zu schaffen,", "tokens": ["Ich", "ha\u00b7be", "mit", "dem", "wahn", "der", "tho\u00b7ren", "nichts", "zu", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ART", "NN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da alle wissenschafft und kunst verworffen heist.", "tokens": ["Da", "al\u00b7le", "wis\u00b7sen\u00b7schafft", "und", "kunst", "ver\u00b7worf\u00b7fen", "heist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was GOtt verworffen hat, verdammt kein guter geist,", "tokens": ["Was", "Gott", "ver\u00b7worf\u00b7fen", "hat", ",", "ver\u00b7dammt", "kein", "gu\u00b7ter", "geist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVPP", "VAFIN", "$,", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch wenn wir alle kunst und witz zusammen raffen,", "tokens": ["Doch", "wenn", "wir", "al\u00b7le", "kunst", "und", "witz", "zu\u00b7sam\u00b7men", "raf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "KON", "VVIMP", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So sind sie dennoch nicht der tugend vorzuziehn:", "tokens": ["So", "sind", "sie", "den\u00b7noch", "nicht", "der", "tu\u00b7gend", "vor\u00b7zu\u00b7ziehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein gut gewissen ist weit besser, als viel wissen.", "tokens": ["Ein", "gut", "ge\u00b7wis\u00b7sen", "ist", "weit", "bes\u00b7ser", ",", "als", "viel", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVPP", "VAFIN", "ADJD", "ADJD", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und die sich sonst um nichts, als um verstand bem\u00fchn,", "tokens": ["Und", "die", "sich", "sonst", "um", "nichts", ",", "als", "um", "ver\u00b7stand", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "ADV", "APPR", "PIS", "$,", "KOUS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die werden von dem strom des irrthums hingerissen.", "tokens": ["Die", "wer\u00b7den", "von", "dem", "strom", "des", "irr\u00b7thums", "hin\u00b7ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Ach da\u00df man sich so sehr der heiligung beflisse,", "tokens": ["Ach", "da\u00df", "man", "sich", "so", "sehr", "der", "hei\u00b7li\u00b7gung", "be\u00b7flis\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "KOUS", "PIS", "PRF", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der wahren heiligung, die reine fr\u00fcchte tr\u00e4gt,", "tokens": ["Der", "wah\u00b7ren", "hei\u00b7li\u00b7gung", ",", "die", "rei\u00b7ne", "fr\u00fcch\u00b7te", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als man sich auf gez\u00e4nck und leere fragen legt;", "tokens": ["Als", "man", "sich", "auf", "ge\u00b7z\u00e4nck", "und", "lee\u00b7re", "fra\u00b7gen", "legt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPR", "NN", "KON", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00e4ren in der welt nicht so viel \u00e4rgernisse!", "tokens": ["So", "w\u00e4\u00b7ren", "in", "der", "welt", "nicht", "so", "viel", "\u00e4r\u00b7ger\u00b7nis\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "PTKNEG", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein die fr\u00f6mmigkeit hat vor uns gute ruh,", "tokens": ["Al\u00b7lein", "die", "fr\u00f6m\u00b7mig\u00b7keit", "hat", "vor", "uns", "gu\u00b7te", "ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "APPR", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dieweil sie mehrentheils nicht gro\u00dfe titel bringet;", "tokens": ["Die\u00b7weil", "sie", "meh\u00b7ren\u00b7theils", "nicht", "gro\u00b7\u00dfe", "ti\u00b7tel", "brin\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Drum eilet man der welt, und ihren schulen zu,", "tokens": ["Drum", "ei\u00b7let", "man", "der", "welt", ",", "und", "ih\u00b7ren", "schu\u00b7len", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "ART", "NN", "$,", "KON", "PPOSAT", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wo Aristoteles von eitler ehre singet.", "tokens": ["Wo", "A\u00b7ris\u00b7to\u00b7te\u00b7les", "von", "eit\u00b7ler", "eh\u00b7re", "sin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Doch, wird der Richter auch an jenem tage fragen,", "tokens": ["Doch", ",", "wird", "der", "Rich\u00b7ter", "auch", "an", "je\u00b7nem", "ta\u00b7ge", "fra\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ART", "NN", "ADV", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie viel du disputirt und durchgelesen hast?", "tokens": ["Wie", "viel", "du", "dis\u00b7pu\u00b7tirt", "und", "durch\u00b7ge\u00b7le\u00b7sen", "hast", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVPP", "KON", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nein! sondern ob du auch dem HErren seine last", "tokens": ["Nein", "!", "son\u00b7dern", "ob", "du", "auch", "dem", "Her\u00b7ren", "sei\u00b7ne", "last"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "KON", "KOUS", "PPER", "ADV", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In creutzigung der welt geduldig nachgetragen.", "tokens": ["In", "creut\u00b7zi\u00b7gung", "der", "welt", "ge\u00b7dul\u00b7dig", "nach\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo ist die excellentz, die vor nicht langer zeit", "tokens": ["Wo", "ist", "die", "ex\u00b7cel\u00b7lentz", ",", "die", "vor", "nicht", "lan\u00b7ger", "zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "APPR", "PTKNEG", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf der catheder stund und sich so hoch vermessen?", "tokens": ["Auf", "der", "cat\u00b7he\u00b7der", "stund", "und", "sich", "so", "hoch", "ver\u00b7mes\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Jm leben macht er sich mit vielem wissen breit;", "tokens": ["Jm", "le\u00b7ben", "macht", "er", "sich", "mit", "vie\u00b7lem", "wis\u00b7sen", "breit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVINF", "VVFIN", "PPER", "PRF", "APPR", "PIS", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Jtzt aber, da er liegt, ist seiner schon vergessen.", "tokens": ["Jtzt", "a\u00b7ber", ",", "da", "er", "liegt", ",", "ist", "sei\u00b7ner", "schon", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "VAFIN", "PPOSAT", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wie bald vergeht der ruhm, den uns die welt gegeben:", "tokens": ["Wie", "bald", "ver\u00b7geht", "der", "ruhm", ",", "den", "uns", "die", "welt", "ge\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ach h\u00e4ttest du so gut gelebt, als disputirt,", "tokens": ["Ach", "h\u00e4t\u00b7test", "du", "so", "gut", "ge\u00b7lebt", ",", "als", "dis\u00b7pu\u00b7tirt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,", "KOUS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So spr\u00e4che man mit recht: Er hatte wohl studirt.", "tokens": ["So", "spr\u00e4\u00b7che", "man", "mit", "recht", ":", "Er", "hat\u00b7te", "wohl", "stu\u00b7dirt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADJD", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn wie viel menschen sind, die nach dem schatten streben,", "tokens": ["Denn", "wie", "viel", "men\u00b7schen", "sind", ",", "die", "nach", "dem", "schat\u00b7ten", "stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "NN", "VAFIN", "$,", "PRELS", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und in der nichtigkeit der eitlen kunst vergehn.", "tokens": ["Und", "in", "der", "nich\u00b7tig\u00b7keit", "der", "eit\u00b7len", "kunst", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gott l\u00e4st sich nur durch lieb\u2019 und tiefe demuth finden;", "tokens": ["Gott", "l\u00e4st", "sich", "nur", "durch", "lieb'", "und", "tie\u00b7fe", "de\u00b7muth", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADV", "APPR", "VVFIN", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie aber suchen sich durch klugheit zu erh\u00f6hn,", "tokens": ["Sie", "a\u00b7ber", "su\u00b7chen", "sich", "durch", "klug\u00b7heit", "zu", "er\u00b7h\u00f6hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bis sie mit ihrem wahn, als wie ein rauch, verschwinden.", "tokens": ["Bis", "sie", "mit", "ih\u00b7rem", "wahn", ",", "als", "wie", "ein", "rauch", ",", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "$,", "KOUS", "KOKOM", "ART", "ADJD", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Der ist alleine gro\u00df, wer nicht nach ehre trachtet,", "tokens": ["Der", "ist", "al\u00b7lei\u00b7ne", "gro\u00df", ",", "wer", "nicht", "nach", "eh\u00b7re", "trach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,", "PWS", "PTKNEG", "APPR", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Klein in ihm selber ist, und gro\u00dfe liebe weist.", "tokens": ["Klein", "in", "ihm", "sel\u00b7ber", "ist", ",", "und", "gro\u00b7\u00dfe", "lie\u00b7be", "weist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "ADV", "VAFIN", "$,", "KON", "ADJA", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der ist ein kluger geist, der das, was irdisch hei\u00dft,", "tokens": ["Der", "ist", "ein", "klu\u00b7ger", "geist", ",", "der", "das", ",", "was", "ir\u00b7disch", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PDS", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und nur das fleisch ergetzt, vor koth und treber achtet,", "tokens": ["Und", "nur", "das", "fleisch", "er\u00b7getzt", ",", "vor", "koth", "und", "tre\u00b7ber", "ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVPP", "$,", "APPR", "NN", "KON", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Weil er sonst keinen schatz, als JEsum, liebt und sucht.", "tokens": ["Weil", "er", "sonst", "kei\u00b7nen", "schatz", ",", "als", "Je\u00b7sum", ",", "liebt", "und", "sucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "$,", "KOUS", "NE", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wer des HErren wort vor seine beste speise", "tokens": ["Und", "wer", "des", "Her\u00b7ren", "wort", "vor", "sei\u00b7ne", "bes\u00b7te", "spei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ART", "NN", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In seinem leben h\u00e4lt, den eigensinn verflucht,", "tokens": ["In", "sei\u00b7nem", "le\u00b7ben", "h\u00e4lt", ",", "den", "ei\u00b7gen\u00b7sinn", "ver\u00b7flucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "VVINF", "VVFIN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und GOtt gehorchen lernt, der ist wahrhafftig weise.", "tokens": ["Und", "Gott", "ge\u00b7hor\u00b7chen", "lernt", ",", "der", "ist", "wahr\u00b7haff\u00b7tig", "wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "VVFIN", "$,", "PRELS", "VAFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}