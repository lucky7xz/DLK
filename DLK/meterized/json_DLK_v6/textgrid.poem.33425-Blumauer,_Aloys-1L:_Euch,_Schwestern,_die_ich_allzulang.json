{"textgrid.poem.33425": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "1L: Euch, Schwestern, die ich allzulang", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Euch, Schwestern, die ich allzulang", "tokens": ["Euch", ",", "Schwes\u00b7tern", ",", "die", "ich", "all\u00b7zu\u00b7lang"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "PRELS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geneckt, und manche Pille zwang", "tokens": ["Ge\u00b7neckt", ",", "und", "man\u00b7che", "Pil\u00b7le", "zwang"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KON", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Gnaden zu verschlingen,", "tokens": ["In", "Gna\u00b7den", "zu", "ver\u00b7schlin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Will ich ein Lobgedicht anheut',", "tokens": ["Will", "ich", "ein", "Lob\u00b7ge\u00b7dicht", "an\u00b7heut'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So sch\u00f6n, als wie ihr selber seid,", "tokens": ["So", "sch\u00f6n", ",", "als", "wie", "ihr", "sel\u00b7ber", "seid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "KOKOM", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum S\u00f6hnungsopfer bringen.", "tokens": ["Zum", "S\u00f6h\u00b7nungs\u00b7op\u00b7fer", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ja, Schwestern, um euch noch weit mehr,", "tokens": ["Ja", ",", "Schwes\u00b7tern", ",", "um", "euch", "noch", "weit", "mehr", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "KOUI", "PPER", "ADV", "ADJD", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als je ein Panegyriker", "tokens": ["Als", "je", "ein", "Pa\u00b7ne\u00b7gy\u00b7ri\u00b7ker"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Es konnte, zu verbinden,", "tokens": ["Es", "konn\u00b7te", ",", "zu", "ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So sollt ihr selbst in dem Gedicht,", "tokens": ["So", "sollt", "ihr", "selbst", "in", "dem", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das heut zu eu'rem Lobe spricht,", "tokens": ["Das", "heut", "zu", "eu'\u00b7rem", "Lo\u00b7be", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Wort erdichtet finden.", "tokens": ["Kein", "Wort", "er\u00b7dich\u00b7tet", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ihr Schwestern, war't vom Anbeginn", "tokens": ["Ihr", "Schwes\u00b7tern", ",", "wa\u00b7r't", "vom", "An\u00b7be\u00b7ginn"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Blume Tausendsch\u00f6n, worin", "tokens": ["Die", "Blu\u00b7me", "Tau\u00b7send\u00b7sch\u00f6n", ",", "wo\u00b7rin"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "NE", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich alle Reize gatten:", "tokens": ["Sich", "al\u00b7le", "Rei\u00b7ze", "gat\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Uns aber pflanzte die Natur", "tokens": ["Uns", "a\u00b7ber", "pflanz\u00b7te", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In diese Welt als B\u00e4ume nur,", "tokens": ["In", "die\u00b7se", "Welt", "als", "B\u00e4u\u00b7me", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KOUS", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Um euch zu \u00fcberschatten.", "tokens": ["Um", "euch", "zu", "\u00fc\u00b7bersc\u00b7hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ihr seid \u2013 mit Ehrfurcht sag' ich es \u2013", "tokens": ["Ihr", "seid", "\u2013", "mit", "Ehr\u00b7furcht", "sag'", "ich", "es", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "APPR", "NN", "VVFIN", "PPER", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das auserw\u00e4hlete Gef\u00e4\u00df", "tokens": ["Das", "au\u00b7ser\u00b7w\u00e4h\u00b7le\u00b7te", "Ge\u00b7f\u00e4\u00df"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Von aller Menschen Leben:", "tokens": ["Von", "al\u00b7ler", "Men\u00b7schen", "Le\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr seid es, die des Mannes Haupt,", "tokens": ["Ihr", "seid", "es", ",", "die", "des", "Man\u00b7nes", "Haupt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit er nicht ein Thier sich glaubt,", "tokens": ["Da\u00b7mit", "er", "nicht", "ein", "Thier", "sich", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Empor zum Himmel heben.", "tokens": ["Em\u00b7por", "zum", "Him\u00b7mel", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ihr seid der Menschlichkeit Magnet,", "tokens": ["Ihr", "seid", "der", "Menschlich\u00b7keit", "Mag\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der alles, was auf F\u00fcssen geht", "tokens": ["Der", "al\u00b7les", ",", "was", "auf", "F\u00fcs\u00b7sen", "geht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "$,", "PRELS", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kriecht, kann attrahiren:", "tokens": ["Und", "kriecht", ",", "kann", "at\u00b7tra\u00b7hi\u00b7ren", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr seid der Mittelpunkt, worin", "tokens": ["Ihr", "seid", "der", "Mit\u00b7tel\u00b7punkt", ",", "wo\u00b7rin"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich Heid' und Christ und Mandarin", "tokens": ["Sich", "Heid'", "und", "Christ", "und", "Man\u00b7da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "NE", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Bettler concentriren.", "tokens": ["Und", "Bett\u00b7ler", "con\u00b7cent\u00b7ri\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der Knabe, J\u00fcngling und der Mann", "tokens": ["Der", "Kna\u00b7be", ",", "J\u00fcng\u00b7ling", "und", "der", "Mann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind euch mit Liebe zugethan:", "tokens": ["Sind", "euch", "mit", "Lie\u00b7be", "zu\u00b7ge\u00b7than", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Greis thut seine Triebe", "tokens": ["Der", "Greis", "thut", "sei\u00b7ne", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Euch noch als W\u00e4rterinnen kund,", "tokens": ["Euch", "noch", "als", "W\u00e4r\u00b7te\u00b7rin\u00b7nen", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KOUS", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und so seid ihr das Alpha und", "tokens": ["Und", "so", "seid", "ihr", "das", "Al\u00b7pha", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN", "KON"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Omega uns'rer Liebe.", "tokens": ["O\u00b7me\u00b7ga", "un\u00b7s'\u00b7rer", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ihr waret schon im Paradies", "tokens": ["Ihr", "wa\u00b7ret", "schon", "im", "Pa\u00b7ra\u00b7dies"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So klug, durch einen Apfelbi\u00df", "tokens": ["So", "klug", ",", "durch", "ei\u00b7nen", "Ap\u00b7fel\u00b7bi\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Sterben einzuf\u00fchren,", "tokens": ["Das", "Ster\u00b7ben", "ein\u00b7zu\u00b7f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Damit's an Wechsel nicht gebricht,", "tokens": ["Da\u00b7mit's", "an", "Wech\u00b7sel", "nicht", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wir am Ewigleben nicht", "tokens": ["Und", "wir", "am", "E\u00b7wig\u00b7le\u00b7ben", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPRART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu Tod uns ennuiren.", "tokens": ["Zu", "Tod", "uns", "en\u00b7nu\u00b7i\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und h\u00e4ttet ihr uns nebst dem Tod", "tokens": ["Und", "h\u00e4t\u00b7tet", "ihr", "uns", "nebst", "dem", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht auch noch Seuchen, Hungersnoth,", "tokens": ["Nicht", "auch", "noch", "Seu\u00b7chen", ",", "Hun\u00b7gers\u00b7noth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und Pestilenz gegeben,", "tokens": ["Und", "Pes\u00b7ti\u00b7lenz", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie k\u00f6nnten jetzt die Medicer,", "tokens": ["Wie", "k\u00f6nn\u00b7ten", "jetzt", "die", "Me\u00b7di\u00b7cer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die B\u00e4cker und das ganze Heer", "tokens": ["Die", "B\u00e4\u00b7cker", "und", "das", "gan\u00b7ze", "Heer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von Apothekern leben?", "tokens": ["Von", "A\u00b7pot\u00b7he\u00b7kern", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Ja, h\u00e4tten wir von eu'rer Hand", "tokens": ["Ja", ",", "h\u00e4t\u00b7ten", "wir", "von", "eu'\u00b7rer", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VAFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht auch zu Wasser und zu Land", "tokens": ["Nicht", "auch", "zu", "Was\u00b7ser", "und", "zu", "Land"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Oft Krieg und Donnerwetter,", "tokens": ["Oft", "Krieg", "und", "Don\u00b7ner\u00b7wet\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Held C\u00e4sar w\u00e4r' ein Donquixot,", "tokens": ["Held", "C\u00e4\u00b7sar", "w\u00e4r'", "ein", "Don\u00b7qui\u00b7xot", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und Franklin, der dem Blitz gebot,", "tokens": ["Und", "Fran\u00b7klin", ",", "der", "dem", "Blitz", "ge\u00b7bot", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nichts als ein Pflasterfreter.", "tokens": ["Nichts", "als", "ein", "Pflas\u00b7ter\u00b7fre\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und w\u00e4ren in der biblischen", "tokens": ["Und", "w\u00e4\u00b7ren", "in", "der", "bib\u00b7li\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Pandora-B\u00fcchse unbeseh'n", "tokens": ["Pan\u00b7dora\u00b7B\u00fcch\u00b7se", "un\u00b7be\u00b7seh'n"], "token_info": ["word", "word"], "pos": ["NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die G\u00fcter all' geblieben,", "tokens": ["Die", "G\u00fc\u00b7ter", "all'", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sagt selber, h\u00e4tte Leibnitz je", "tokens": ["Sagt", "sel\u00b7ber", ",", "h\u00e4t\u00b7te", "Leib\u00b7nitz", "je"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "VAFIN", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die g\u00f6ttliche Theodicee", "tokens": ["Die", "g\u00f6tt\u00b7li\u00b7che", "Theo\u00b7di\u00b7cee"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Zu unserm Trost geschrieben?", "tokens": ["Zu", "un\u00b7serm", "Trost", "ge\u00b7schrie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Doch all' dies und des Guten mehr,", "tokens": ["Doch", "all'", "dies", "und", "des", "Gu\u00b7ten", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "PDS", "KON", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wof\u00fcr euch der Profanen Heer", "tokens": ["Wo\u00b7f\u00fcr", "euch", "der", "Pro\u00b7fa\u00b7nen", "Heer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit lautem Danke preiset,", "tokens": ["Mit", "lau\u00b7tem", "Dan\u00b7ke", "prei\u00b7set", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ist nicht zu achten gegen das,", "tokens": ["Ist", "nicht", "zu", "ach\u00b7ten", "ge\u00b7gen", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "PTKZU", "VVINF", "APPR", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was ihr noch stets ohn' Unterla\u00df", "tokens": ["Was", "ihr", "noch", "stets", "ohn'", "Un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Maurerei erweiset.", "tokens": ["Der", "Mau\u00b7re\u00b7rei", "er\u00b7wei\u00b7set", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Euch danken wir es, Schwesterchen,", "tokens": ["Euch", "dan\u00b7ken", "wir", "es", ",", "Schwes\u00b7ter\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "$,", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Da\u00df wir die meisten Suchenden", "tokens": ["Da\u00df", "wir", "die", "meis\u00b7ten", "Su\u00b7chen\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon vorbereitet finden:", "tokens": ["Schon", "vor\u00b7be\u00b7rei\u00b7tet", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr lehret sie Verschwiegenheit,", "tokens": ["Ihr", "leh\u00b7ret", "sie", "Ver\u00b7schwie\u00b7gen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Geduld und Unterw\u00fcrfigkeit,", "tokens": ["Ge\u00b7duld", "und", "Un\u00b7ter\u00b7w\u00fcr\u00b7fig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr lehret sie erblinden.", "tokens": ["Ihr", "leh\u00b7ret", "sie", "er\u00b7blin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Bei euch gew\u00f6hnet ohne M\u00fch'", "tokens": ["Bei", "euch", "ge\u00b7w\u00f6h\u00b7net", "oh\u00b7ne", "M\u00fch'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der junge Maurerz\u00f6gling fr\u00fch", "tokens": ["Der", "jun\u00b7ge", "Mau\u00b7rer\u00b7z\u00f6g\u00b7ling", "fr\u00fch"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Finsteren zu sitzen:", "tokens": ["Im", "Fins\u00b7te\u00b7ren", "zu", "sit\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr gebt ihm auch wohl gar den Muth,", "tokens": ["Ihr", "gebt", "ihm", "auch", "wohl", "gar", "den", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um einen Blick von euch sein Blut", "tokens": ["Um", "ei\u00b7nen", "Blick", "von", "euch", "sein", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "APPR", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Zweikampf zu verspritzen.", "tokens": ["Im", "Zwei\u00b7kampf", "zu", "ver\u00b7sprit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Ihr lehret auch den Suchenden", "tokens": ["Ihr", "leh\u00b7ret", "auch", "den", "Su\u00b7chen\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als Maurer reisen, lehrt ihn geh'n", "tokens": ["Als", "Mau\u00b7rer", "rei\u00b7sen", ",", "lehrt", "ihn", "geh'n"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "VVINF", "$,", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf Wegen, gleich dem Glase:", "tokens": ["Auf", "We\u00b7gen", ",", "gleich", "dem", "Gla\u00b7se", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr thut hierin noch mehr als wir;", "tokens": ["Ihr", "thut", "hie\u00b7rin", "noch", "mehr", "als", "wir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir f\u00fchr'n ihn an der Hand \u2013 und ihr \u2013", "tokens": ["Wir", "f\u00fchr'n", "ihn", "an", "der", "Hand", "\u2013", "und", "ihr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KON", "PPOSAT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr f\u00fchrt ihn bei der Nase.", "tokens": ["Ihr", "f\u00fchrt", "ihn", "bei", "der", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Durch euch hat uns're Bruderschaft", "tokens": ["Durch", "euch", "hat", "un\u00b7s'\u00b7re", "Bru\u00b7der\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "An Wachstum, Gr\u00f6sse und an Kraft", "tokens": ["An", "Wachs\u00b7tum", ",", "Gr\u00f6s\u00b7se", "und", "an", "Kraft"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So m\u00e4chtig zugenommen;", "tokens": ["So", "m\u00e4ch\u00b7tig", "zu\u00b7ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die K\u00fcnste die der Maurer liebt,", "tokens": ["Die", "K\u00fcns\u00b7te", "die", "der", "Mau\u00b7rer", "liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Tugendregeln, die er \u00fcbt,", "tokens": ["Die", "Tu\u00b7gend\u00b7re\u00b7geln", ",", "die", "er", "\u00fcbt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hat er von euch bekommen.", "tokens": ["Hat", "er", "von", "euch", "be\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Der Wind, den ihr mit eu'rer Pracht", "tokens": ["Der", "Wind", ",", "den", "ihr", "mit", "eu'\u00b7rer", "Pracht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus unserm Gold und Silber macht,", "tokens": ["Aus", "un\u00b7serm", "Gold", "und", "Sil\u00b7ber", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist Anla\u00df uns gewesen,", "tokens": ["Ist", "An\u00b7la\u00df", "uns", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PPER", "VAPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df wir uns auch der theuern Kunst", "tokens": ["Da\u00df", "wir", "uns", "auch", "der", "theu\u00b7ern", "Kunst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ergaben, unser Gold in Dunst", "tokens": ["Er\u00b7ga\u00b7ben", ",", "un\u00b7ser", "Gold", "in", "Dunst"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hermetisch aufzul\u00f6sen,", "tokens": ["Her\u00b7me\u00b7tisch", "auf\u00b7zu\u00b7l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.17": {"line.1": {"text": "Ihr Schwestern, lehrtet uns zugleich", "tokens": ["Ihr", "Schwes\u00b7tern", ",", "lehr\u00b7tet", "uns", "zu\u00b7gleich"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kunst, den Teufel, der in euch", "tokens": ["Die", "Kunst", ",", "den", "Teu\u00b7fel", ",", "der", "in", "euch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "PRELS", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Weibern steckt, zu bannen,", "tokens": ["Als", "Wei\u00b7bern", "steckt", ",", "zu", "ban\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und \u00fcberzeugt uns anbei,", "tokens": ["Und", "\u00fc\u00b7berz\u00b7eugt", "uns", "an\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+----+", "measure": "dactylic.init"}, "line.5": {"text": "Da\u00df es vergeb'ne M\u00fche sei,", "tokens": ["Da\u00df", "es", "ver\u00b7ge\u00b7b'\u00b7ne", "M\u00fc\u00b7he", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Ihn je zu \u00fcbermannen.", "tokens": ["Ihn", "je", "zu", "\u00fc\u00b7berm\u00b7an\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Nur ihr erf\u00fcllt den Maurer fr\u00fch", "tokens": ["Nur", "ihr", "er\u00b7f\u00fcllt", "den", "Mau\u00b7rer", "fr\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Weisheit und Philosophie", "tokens": ["Mit", "Weis\u00b7heit", "und", "Phi\u00b7lo\u00b7so\u00b7phie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Fu\u00df bis auf zum Scheitel.", "tokens": ["Vom", "Fu\u00df", "bis", "auf", "zum", "Schei\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Von euch belehrt, rief fr\u00fche schon", "tokens": ["Von", "euch", "be\u00b7lehrt", ",", "rief", "fr\u00fc\u00b7he", "schon"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "VVPP", "$,", "VVFIN", "ADJA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Urgro\u00dfmeister Salomon:", "tokens": ["Der", "Ur\u00b7gro\u00df\u00b7meis\u00b7ter", "Sa\u00b7lo\u00b7mon", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie ist doch alles eitel!", "tokens": ["Wie", "ist", "doch", "al\u00b7les", "ei\u00b7tel", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "PIS", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Ihr, Schwestern, wart die ersten d'ran,", "tokens": ["Ihr", ",", "Schwes\u00b7tern", ",", "wart", "die", "ers\u00b7ten", "d'\u00b7ran", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "VVFIN", "ART", "ADJA", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der G\u00fcter Ungleichheit, die man", "tokens": ["Der", "G\u00fc\u00b7ter", "Un\u00b7gleich\u00b7heit", ",", "die", "man"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf Erden sieht, zu heilen:", "tokens": ["Auf", "Er\u00b7den", "sieht", ",", "zu", "hei\u00b7len", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr fanget bei euch selber an,", "tokens": ["Ihr", "fan\u00b7get", "bei", "euch", "sel\u00b7ber", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und lehret jeden Ehemann", "tokens": ["Und", "leh\u00b7ret", "je\u00b7den", "E\u00b7he\u00b7mann"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Gut mit andern theilen.", "tokens": ["Sein", "Gut", "mit", "an\u00b7dern", "thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Und, Schwestern, w\u00e4re nicht zugleich", "tokens": ["Und", ",", "Schwes\u00b7tern", ",", "w\u00e4\u00b7re", "nicht", "zu\u00b7gleich"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "VAFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der M\u00e4nner Menschenlieb' an euch", "tokens": ["Der", "M\u00e4n\u00b7ner", "Men\u00b7schen\u00b7lieb'", "an", "euch"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sichtbar oft zu schauen,", "tokens": ["So", "sicht\u00b7bar", "oft", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie k\u00f6nnten wir als Maurer nun", "tokens": ["Wie", "k\u00f6nn\u00b7ten", "wir", "als", "Mau\u00b7rer", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "KOUS", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den armen Waisen Gutes thun,", "tokens": ["Den", "ar\u00b7men", "Wai\u00b7sen", "Gu\u00b7tes", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Findelh\u00e4user bauen? \u2013", "tokens": ["Und", "Fin\u00b7del\u00b7h\u00e4u\u00b7ser", "bau\u00b7en", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Um euch nun, liebe Schwesterchen,", "tokens": ["Um", "euch", "nun", ",", "lie\u00b7be", "Schwes\u00b7ter\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "F\u00fcr alles, was durch euch gescheh'n,", "tokens": ["F\u00fcr", "al\u00b7les", ",", "was", "durch", "euch", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach W\u00fcrden zu belohnen,", "tokens": ["Nach", "W\u00fcr\u00b7den", "zu", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So geben wir zur Dankbarkeit", "tokens": ["So", "ge\u00b7ben", "wir", "zur", "Dank\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein dreifach Feuer euch anheut'", "tokens": ["Ein", "drei\u00b7fach", "Feu\u00b7er", "euch", "an\u00b7heut'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus unseren Kanonen.", "tokens": ["Aus", "un\u00b7se\u00b7ren", "Ka\u00b7no\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}