{"textgrid.poem.53700": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Couplet f\u00fcr die Bier-Abteilung", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In den berliner Stra\u00dfen", "tokens": ["In", "den", "ber\u00b7li\u00b7ner", "Stra\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "da siehst du heut, mein Kind,", "tokens": ["da", "siehst", "du", "heut", ",", "mein", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "wie \u00fcber alle Ma\u00dfen", "tokens": ["wie", "\u00fc\u00b7ber", "al\u00b7le", "Ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "besetzt die Autos sind.", "tokens": ["be\u00b7setzt", "die", "Au\u00b7tos", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der Chef mit Prokuristen,", "tokens": ["Der", "Chef", "mit", "Pro\u00b7ku\u00b7ris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Agenten und Juristen \u2013", "tokens": ["A\u00b7gen\u00b7ten", "und", "Ju\u00b7ris\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.7": {"text": "sie quetschen sich zwecks Billigkeit", "tokens": ["sie", "quet\u00b7schen", "sich", "zwecks", "Bil\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "eng aneinander an:", "tokens": ["eng", "an\u00b7ein\u00b7an\u00b7der", "an", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Acht Mann in einem Auto \u2013", "tokens": ["Acht", "Mann", "in", "ei\u00b7nem", "Au\u00b7to", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "ein Auto und acht Mann.", "tokens": ["ein", "Au\u00b7to", "und", "acht", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Emilie, s\u00fc\u00dfes T\u00f6pfchen", "tokens": ["E\u00b7mi\u00b7lie", ",", "s\u00fc\u00b7\u00dfes", "T\u00f6pf\u00b7chen"], "token_info": ["word", "punct", "word", "word"], "pos": ["NE", "$,", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "der Suppe meiner Lust:", "tokens": ["der", "Sup\u00b7pe", "mei\u00b7ner", "Lust", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "ich lege gern mein K\u00f6pfchen", "tokens": ["ich", "le\u00b7ge", "gern", "mein", "K\u00f6pf\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "an deine linke Brust.", "tokens": ["an", "dei\u00b7ne", "lin\u00b7ke", "Brust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Du schw\u00f6rst, ich sei alleine.", "tokens": ["Du", "schw\u00f6rst", ",", "ich", "sei", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich glaub es gern, du Kleine!", "tokens": ["Ich", "glaub", "es", "gern", ",", "du", "Klei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Denn k\u00e4men alle, die du liebst:", "tokens": ["Denn", "k\u00e4\u00b7men", "al\u00b7le", ",", "die", "du", "liebst", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dann r\u00fcckten da heran", "tokens": ["dann", "r\u00fcck\u00b7ten", "da", "he\u00b7ran"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "acht Mann in einem Auto \u2013", "tokens": ["acht", "Mann", "in", "ei\u00b7nem", "Au\u00b7to", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "ein Auto und acht Mann!", "tokens": ["ein", "Au\u00b7to", "und", "acht", "Mann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wenn diese Republike", "tokens": ["Wenn", "die\u00b7se", "Re\u00b7pub\u00b7li\u00b7ke"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PDAT", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "den Zimt so weitermacht,", "tokens": ["den", "Zimt", "so", "wei\u00b7ter\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "wird eines Tags sie stike", "tokens": ["wird", "ei\u00b7nes", "Tags", "sie", "sti\u00b7ke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "von hinten umgebracht.", "tokens": ["von", "hin\u00b7ten", "um\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Herrn Ge\u00dflers Reichsgardisten", "tokens": ["Herrn", "Ge\u00df\u00b7lers", "Reichs\u00b7gar\u00b7dis\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["NN", "NE", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "erziehn dann Monarchisten.", "tokens": ["er\u00b7ziehn", "dann", "Mon\u00b7ar\u00b7chis\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Man wird ein bi\u00dfchen schreiben . . .", "tokens": ["Man", "wird", "ein", "bi\u00df\u00b7chen", "schrei\u00b7ben", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PIS", "VAFIN", "ART", "PIS", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Die meisten werden bleiben.", "tokens": ["Die", "meis\u00b7ten", "wer\u00b7den", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Der Rest, der f\u00e4hrt zum Tor hinaus", "tokens": ["Der", "Rest", ",", "der", "f\u00e4hrt", "zum", "Tor", "hin\u00b7aus"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "APPRART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "mit Schwarz-Rot-Gold voran.", "tokens": ["mit", "Schwa\u00b7rz\u00b7Rot\u00b7Gold", "vo\u00b7ran", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$."], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.11": {"text": "Es wird die Herrn begleiten:", "tokens": ["Es", "wird", "die", "Herrn", "be\u00b7glei\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Ein Leutnant und zehn Mann \u2013!", "tokens": ["Ein", "Leut\u00b7nant", "und", "zehn", "Mann", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "KON", "CARD", "NN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}