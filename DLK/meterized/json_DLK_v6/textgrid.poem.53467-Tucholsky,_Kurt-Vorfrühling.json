{"textgrid.poem.53467": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Vorfr\u00fchling", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sieh da: nun ist der fette Dichter wieder", "tokens": ["Sieh", "da", ":", "nun", "ist", "der", "fet\u00b7te", "Dich\u00b7ter", "wie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKVZ", "$.", "ADV", "VAFIN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "von seinem Winterschl\u00e4fchen aufgewacht,", "tokens": ["von", "sei\u00b7nem", "Win\u00b7ter\u00b7schl\u00e4f\u00b7chen", "auf\u00b7ge\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und er entlockt der Harfe heitre Lieder,", "tokens": ["und", "er", "ent\u00b7lockt", "der", "Har\u00b7fe", "heit\u00b7re", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ti p\u00fcng \u2013 die Winde wehn, der Himmel lacht.", "tokens": ["ti", "p\u00fcng", "\u2013", "die", "Win\u00b7de", "wehn", ",", "der", "Him\u00b7mel", "lacht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "$(", "ART", "NN", "VVINF", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Er schauet sanft verkl\u00e4rt, und eine Putte", "tokens": ["Er", "schau\u00b7et", "sanft", "ver\u00b7kl\u00e4rt", ",", "und", "ei\u00b7ne", "Put\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "VVPP", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "h\u00e4lt \u00fcber seinem Kopf den Lorbeerkranz.", "tokens": ["h\u00e4lt", "\u00fc\u00b7ber", "sei\u00b7nem", "Kopf", "den", "Lor\u00b7beer\u00b7kranz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Vorfr\u00fchling n\u00e4hert sich, die junge Nutte,", "tokens": ["Vor\u00b7fr\u00fch\u00b7ling", "n\u00e4\u00b7hert", "sich", ",", "die", "jun\u00b7ge", "Nut\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "und probt, noch sch\u00fcchtern, einen kleinen Tanz.", "tokens": ["und", "probt", ",", "noch", "sch\u00fcch\u00b7tern", ",", "ei\u00b7nen", "klei\u00b7nen", "Tanz", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVINF", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Das Barometer droht mit seinem Zeiger:", "tokens": ["Das", "Ba\u00b7ro\u00b7me\u00b7ter", "droht", "mit", "sei\u00b7nem", "Zei\u00b7ger", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbnicht immer feste druff! Ich falle bald.\u00ab", "tokens": ["\u00bb", "nicht", "im\u00b7mer", "fes\u00b7te", "druff", "!", "Ich", "fal\u00b7le", "bald", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKNEG", "ADV", "ADJA", "PAV", "$.", "PPER", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Selbst Barometer schw\u00e4tzen. Gro\u00dfe Schweiger", "tokens": ["Selbst", "Ba\u00b7ro\u00b7me\u00b7ter", "schw\u00e4t\u00b7zen", ".", "Gro\u00b7\u00dfe", "Schwei\u00b7ger"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "NN", "VVINF", "$.", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "sind selten in dem Land des Theobald.", "tokens": ["sind", "sel\u00b7ten", "in", "dem", "Land", "des", "Theo\u00b7bald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "ART", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Noch immer Zabern und Theaterpleiten,", "tokens": ["Noch", "im\u00b7mer", "Za\u00b7bern", "und", "The\u00b7a\u00b7ter\u00b7plei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und wie man wieder auf den Fasching geht,", "tokens": ["und", "wie", "man", "wie\u00b7der", "auf", "den", "Fa\u00b7sching", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Protestbeschl\u00fcsse, andre Lustbarkeiten \u2013", "tokens": ["Pro\u00b7test\u00b7be\u00b7schl\u00fcs\u00b7se", ",", "and\u00b7re", "Lust\u00b7bar\u00b7kei\u00b7ten", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "und alles red't und alles red't.", "tokens": ["und", "al\u00b7les", "red't", "und", "al\u00b7les", "red'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "PIS", "VVFIN", "KON", "PIS", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und wenn man dieses Deutschland sieht und diese", "tokens": ["Und", "wenn", "man", "die\u00b7ses", "Deutschland", "sieht", "und", "die\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "PDAT", "NN", "VVFIN", "KON", "PDS"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "mit Parsifalleri \u2013 und -fallerein", "tokens": ["mit", "Par\u00b7si\u00b7fal\u00b7le\u00b7ri", "\u2013", "und"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "$(", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "von Hammeln abgegraste Geisteswiese \u2013", "tokens": ["von", "Ham\u00b7meln", "ab\u00b7ge\u00b7gras\u00b7te", "Geis\u00b7tes\u00b7wie\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ah Fr\u00fchling! Hier soll immer Winter sein!", "tokens": ["ah", "Fr\u00fch\u00b7ling", "!", "Hier", "soll", "im\u00b7mer", "Win\u00b7ter", "sein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$.", "ADV", "VMFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}