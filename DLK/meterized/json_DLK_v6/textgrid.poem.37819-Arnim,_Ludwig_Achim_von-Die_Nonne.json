{"textgrid.poem.37819": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Die Nonne", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Stund ich auf hohen Bergen", "tokens": ["Stund", "ich", "auf", "ho\u00b7hen", "Ber\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ADJA", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Und sah wohl \u00fcber den Rhein,", "tokens": ["Und", "sah", "wohl", "\u00fc\u00b7ber", "den", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ein Schifflein sah ich fahren,", "tokens": ["Ein", "Schif\u00b7flein", "sah", "ich", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Ritter waren drey,", "tokens": ["Der", "Rit\u00b7ter", "wa\u00b7ren", "drey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "CARD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der j\u00fcngste, der darunter war,", "tokens": ["Der", "j\u00fcngs\u00b7te", ",", "der", "da\u00b7run\u00b7ter", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "PAV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das war ein Grafensohn,", "tokens": ["Das", "war", "ein", "Gra\u00b7fen\u00b7sohn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "H\u00e4tt' mir die Eh versprochen,", "tokens": ["H\u00e4tt'", "mir", "die", "Eh", "ver\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So jung als er noch war.", "tokens": ["So", "jung", "als", "er", "noch", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Er that von seinem Finger herab,", "tokens": ["Er", "that", "von", "sei\u00b7nem", "Fin\u00b7ger", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ein Ringlein von Golde so roth:", "tokens": ["Ein", "Rin\u00b7glein", "von", "Gol\u00b7de", "so", "roth", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADV", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "\u00bbnimm hin, du H\u00fcbsche, du Feine,", "tokens": ["\u00bb", "nimm", "hin", ",", "du", "H\u00fcb\u00b7sche", ",", "du", "Fei\u00b7ne", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$,", "PPER", "NN", "$,", "PPER", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Trag ihn nach meinem Tod!\u00ab", "tokens": ["Trag", "ihn", "nach", "mei\u00b7nem", "Tod", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbwas soll ich mit dem Ringlein thun,", "tokens": ["\u00bb", "was", "soll", "ich", "mit", "dem", "Rin\u00b7glein", "thun", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn ichs nicht tragen darf?\u00ab", "tokens": ["Wenn", "ichs", "nicht", "tra\u00b7gen", "darf", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbey sag, du hasts gefunden,", "tokens": ["\u00bb", "ey", "sag", ",", "du", "hasts", "ge\u00b7fun\u00b7den", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Draussen im gr\u00fcnen Gras!\u00ab", "tokens": ["Draus\u00b7sen", "im", "gr\u00fc\u00b7nen", "Gras", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "\u00bbey das w\u00e4re ja gelogen,", "tokens": ["\u00bb", "ey", "das", "w\u00e4\u00b7re", "ja", "ge\u00b7lo\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "XY", "PDS", "VAFIN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "St\u00fcnd mir gar \u00fcbel an,", "tokens": ["St\u00fcnd", "mir", "gar", "\u00fc\u00b7bel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Viel lieber will ich sagen:", "tokens": ["Viel", "lie\u00b7ber", "will", "ich", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der jung Graf w\u00e4r mein Mann.\u00ab", "tokens": ["Der", "jung", "Graf", "w\u00e4r", "mein", "Mann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NE", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u00bbey, Jungfer, w\u00e4rt ihr ein wenig reich,", "tokens": ["\u00bb", "ey", ",", "Jung\u00b7fer", ",", "w\u00e4rt", "ihr", "ein", "we\u00b7nig", "reich", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "NE", "$,", "VAFIN", "PPER", "ART", "PIS", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "W\u00e4rt ihr ein edler Zweig,", "tokens": ["W\u00e4rt", "ihr", "ein", "ed\u00b7ler", "Zweig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "F\u00fcrwahr ich wollt euch nehmen,", "tokens": ["F\u00fcr\u00b7wahr", "ich", "wollt", "euch", "neh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir w\u00e4ren einander gleich!\u00ab", "tokens": ["Wir", "w\u00e4\u00b7ren", "ein\u00b7an\u00b7der", "gleich", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbund ob ich schon nicht reiche bin,", "tokens": ["\u00bb", "und", "ob", "ich", "schon", "nicht", "rei\u00b7che", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "PTKNEG", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aller Ehren bin ich voll.", "tokens": ["Al\u00b7ler", "Eh\u00b7ren", "bin", "ich", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Meine Ehr will ich behalten,", "tokens": ["Mei\u00b7ne", "Ehr", "will", "ich", "be\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bis da\u00df meins Gleichen kommt.\u00ab", "tokens": ["Bis", "da\u00df", "meins", "Glei\u00b7chen", "kommt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "KOUS", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u00bbkommt aber deines Gleichen nicht,", "tokens": ["\u00bb", "kommt", "a\u00b7ber", "dei\u00b7nes", "Glei\u00b7chen", "nicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was f\u00e4ngst du darnach an?\u00ab", "tokens": ["Was", "f\u00e4ngst", "du", "dar\u00b7nach", "an", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PAV", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdarnach geh ich in das Kloster,", "tokens": ["\u00bb", "dar\u00b7nach", "geh", "ich", "in", "das", "Klos\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu werden eine Nonn'.\u00ab", "tokens": ["Zu", "wer\u00b7den", "ei\u00b7ne", "Nonn'", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Es stund wohl an ein Vierteljahr,", "tokens": ["Es", "stund", "wohl", "an", "ein", "Vier\u00b7tel\u00b7jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Grafen tr\u00e4umts gar schwer,", "tokens": ["Dem", "Gra\u00b7fen", "tr\u00e4umts", "gar", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als ob sein herzallerliebster Schatz", "tokens": ["Als", "ob", "sein", "her\u00b7zal\u00b7ler\u00b7liebs\u00b7ter", "Schatz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Ins Kloster zogen w\u00e4r.", "tokens": ["Ins", "Klos\u00b7ter", "zo\u00b7gen", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbsteh auf, steh auf, lieb Reitknecht mein!", "tokens": ["\u00bb", "steh", "auf", ",", "steh", "auf", ",", "lieb", "Reit\u00b7knecht", "mein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "ADJD", "NN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sattel mir und dir ein Pferd,", "tokens": ["Sat\u00b7tel", "mir", "und", "dir", "ein", "Pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KON", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir wollen reiten \u00fcber Berg und Thal,", "tokens": ["Wir", "wol\u00b7len", "rei\u00b7ten", "\u00fc\u00b7ber", "Berg", "und", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das M\u00e4del ist alles werth.\u00ab", "tokens": ["Das", "M\u00e4\u00b7del", "ist", "al\u00b7les", "werth", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "ADJD", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und als sie vor das Kloster kamen,", "tokens": ["Und", "als", "sie", "vor", "das", "Klos\u00b7ter", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie klopften ans hohe Haus:", "tokens": ["Sie", "klopf\u00b7ten", "ans", "ho\u00b7he", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbkomm' raus, du H\u00fcbsche, du Feine,", "tokens": ["\u00bb", "komm'", "raus", ",", "du", "H\u00fcb\u00b7sche", ",", "du", "Fei\u00b7ne", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "PPER", "NN", "$,", "PPER", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Komm nur ein wenig raus.\u00ab", "tokens": ["Komm", "nur", "ein", "we\u00b7nig", "raus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ART", "PIS", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbwas soll ich aber draussen thun?", "tokens": ["\u00bb", "was", "soll", "ich", "a\u00b7ber", "draus\u00b7sen", "thun", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hab ich ein kurzes Haar!", "tokens": ["Hab", "ich", "ein", "kur\u00b7zes", "Haar", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mein Haar ist abgeschnitten,", "tokens": ["Mein", "Haar", "ist", "ab\u00b7ge\u00b7schnit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es ist vergangen ein Jahr.\u00ab", "tokens": ["Es", "ist", "ver\u00b7gan\u00b7gen", "ein", "Jahr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "Der Graf entsezt sich in der Still,", "tokens": ["Der", "Graf", "ent\u00b7sezt", "sich", "in", "der", "Still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sa\u00df da auf einem Stein',", "tokens": ["Sa\u00df", "da", "auf", "ei\u00b7nem", "Stein'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er weint die hellen Thr\u00e4nen,", "tokens": ["Er", "weint", "die", "hel\u00b7len", "Thr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Konnt sich nicht wieder freun.", "tokens": ["Konnt", "sich", "nicht", "wie\u00b7der", "freun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKNEG", "ADV", "VVINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "Mit ihren schneeweissen H\u00e4ndelein", "tokens": ["Mit", "ih\u00b7ren", "schnee\u00b7weis\u00b7sen", "H\u00e4n\u00b7del\u00b7ein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gr\u00e4bt sie dem Grafen ein Grab,", "tokens": ["Gr\u00e4bt", "sie", "dem", "Gra\u00b7fen", "ein", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Aus ihren schwarzbraunen Aeugelein", "tokens": ["Aus", "ih\u00b7ren", "schwarz\u00b7brau\u00b7nen", "A\u00b7e\u00b7u\u00b7ge\u00b7lein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-++-+-+-+", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Sie ihm das Weihwasser gab.", "tokens": ["Sie", "ihm", "das", "Weih\u00b7was\u00b7ser", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "So mu\u00df es allen Junggesellen gehn,", "tokens": ["So", "mu\u00df", "es", "al\u00b7len", "Jung\u00b7ge\u00b7sel\u00b7len", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die trachten nach gro\u00dfem Gut!", "tokens": ["Die", "trach\u00b7ten", "nach", "gro\u00b7\u00dfem", "Gut", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie h\u00e4tten als gern sch\u00f6ne Weiber,", "tokens": ["Sie", "h\u00e4t\u00b7ten", "als", "gern", "sch\u00f6\u00b7ne", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind aber nicht reich genug.", "tokens": ["Sind", "a\u00b7ber", "nicht", "reich", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "ADJD", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}