{"textgrid.poem.60969": {"metadata": {"author": {"name": "Platen, August von", "birth": "N.A.", "death": "N.A."}, "title": "Klagelied der polnischen Verbannten in Sibirien", "genre": "verse", "period": "N.A.", "pub_year": 1815, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Aus den H\u00fctten, die der Schnee bestiebte,", "tokens": ["Aus", "den", "H\u00fct\u00b7ten", ",", "die", "der", "Schnee", "be\u00b7stieb\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Sammelt euch um dieses Feur, Geliebte!", "tokens": ["Sam\u00b7melt", "euch", "um", "die\u00b7ses", "Feur", ",", "Ge\u00b7lieb\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "La\u00dft in freien Worten Trost uns suchen,", "tokens": ["La\u00dft", "in", "frei\u00b7en", "Wor\u00b7ten", "Trost", "uns", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "APPR", "ADJA", "NN", "NN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Unsern W\u00fcrger im Gesang verfluchen.", "tokens": ["Un\u00b7sern", "W\u00fcr\u00b7ger", "im", "Ge\u00b7sang", "ver\u00b7flu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "W\u00f6lfe blo\u00df bev\u00f6lkern hier der \u00d6de", "tokens": ["W\u00f6l\u00b7fe", "blo\u00df", "be\u00b7v\u00f6l\u00b7kern", "hier", "der", "\u00d6\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADJD", "ADV", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Weiten Raum, den uns bestimmt der Schn\u00f6de:", "tokens": ["Wei\u00b7ten", "Raum", ",", "den", "uns", "be\u00b7stimmt", "der", "Schn\u00f6\u00b7de", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Hat Natur sogar mit ihm im Bunde", "tokens": ["Hat", "Na\u00b7tur", "so\u00b7gar", "mit", "ihm", "im", "Bun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ADV", "APPR", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Starr bezaubert diese gro\u00dfe Runde?", "tokens": ["Starr", "be\u00b7zau\u00b7bert", "die\u00b7se", "gro\u00b7\u00dfe", "Run\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PDAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Hat sie solche W\u00fcsten einst erschaffen,", "tokens": ["Hat", "sie", "sol\u00b7che", "W\u00fcs\u00b7ten", "einst", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Um der Freiheit Kinder hinzuraffen?", "tokens": ["Um", "der", "Frei\u00b7heit", "Kin\u00b7der", "hin\u00b7zu\u00b7raf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Hat sie ihm zu Lieb dies Eis verdichtet,", "tokens": ["Hat", "sie", "ihm", "zu", "Lieb", "dies", "Eis", "ver\u00b7dich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "APPR", "NN", "PDS", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Diesen Schnee zu solchen H\u00f6hn geschichtet?", "tokens": ["Die\u00b7sen", "Schnee", "zu", "sol\u00b7chen", "H\u00f6hn", "ge\u00b7schich\u00b7tet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Unser K\u00f6nig, denn so m\u00f6cht er hei\u00dfen,", "tokens": ["Un\u00b7ser", "K\u00f6\u00b7nig", ",", "denn", "so", "m\u00f6cht", "er", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "L\u00e4\u00dft von wilden Tieren uns zerrei\u00dfen!", "tokens": ["L\u00e4\u00dft", "von", "wil\u00b7den", "Tie\u00b7ren", "uns", "zer\u00b7rei\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und warum? so fragt die Welt beleidigt:", "tokens": ["Und", "wa\u00b7rum", "?", "so", "fragt", "die", "Welt", "be\u00b7lei\u00b7digt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "$.", "ADV", "VVFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Weil wir unser Vaterland verteidigt!", "tokens": ["Weil", "wir", "un\u00b7ser", "Va\u00b7ter\u00b7land", "ver\u00b7tei\u00b7digt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "H\u00f6rt und staunt, Europas Volksgemeinden!", "tokens": ["H\u00f6rt", "und", "staunt", ",", "Eu\u00b7ro\u00b7pas", "Volks\u00b7ge\u00b7mein\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "KON", "VVFIN", "$,", "NE", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Unser K\u00f6nig wohnt bei unsern Feinden!", "tokens": ["Un\u00b7ser", "K\u00f6\u00b7nig", "wohnt", "bei", "un\u00b7sern", "Fein\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Erst des eignen heiligen Schwurs Ver\u00e4chter,", "tokens": ["Erst", "des", "eig\u00b7nen", "hei\u00b7li\u00b7gen", "Schwurs", "Ver\u00b7\u00e4ch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.4": {"text": "Schickt er endlich alle seine Schl\u00e4chter!", "tokens": ["Schickt", "er", "end\u00b7lich", "al\u00b7le", "sei\u00b7ne", "Schl\u00e4ch\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Kranz des Ruhms, von V\u00e4tern einst erworben,", "tokens": ["Kranz", "des", "Ruhms", ",", "von", "V\u00e4\u00b7tern", "einst", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Bist du wirklich v\u00f6llig abgestorben?", "tokens": ["Bist", "du", "wirk\u00b7lich", "v\u00f6l\u00b7lig", "ab\u00b7ge\u00b7stor\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Baum der Freiheit, den wir einst begossen,", "tokens": ["Baum", "der", "Frei\u00b7heit", ",", "den", "wir", "einst", "be\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Wirst du nie mehr aus der Erde sprossen?", "tokens": ["Wirst", "du", "nie", "mehr", "aus", "der", "Er\u00b7de", "spros\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Waren nicht auch wir ein Volk wie eines?", "tokens": ["Wa\u00b7ren", "nicht", "auch", "wir", "ein", "Volk", "wie", "ei\u00b7nes", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "PPER", "ART", "NN", "KOKOM", "PIS", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Sind wir w\u00fcrdig schon des Leichensteines?", "tokens": ["Sind", "wir", "w\u00fcr\u00b7dig", "schon", "des", "Lei\u00b7chen\u00b7stei\u00b7nes", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Darf der Unhold unsres Namens spotten,", "tokens": ["Darf", "der", "Un\u00b7hold", "uns\u00b7res", "Na\u00b7mens", "spot\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Darf er's wagen, selbst uns auszurotten?", "tokens": ["Darf", "er's", "wa\u00b7gen", ",", "selbst", "uns", "aus\u00b7zu\u00b7rot\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVINF", "$,", "ADV", "PPER", "VVIZU", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "M\u00f6cht er uns des irdischen Guts berauben,", "tokens": ["M\u00f6cht", "er", "uns", "des", "ir\u00b7di\u00b7schen", "Guts", "be\u00b7rau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.2": {"text": "Wenn er feindlich nur sich nicht dem Glauben,", "tokens": ["Wenn", "er", "feind\u00b7lich", "nur", "sich", "nicht", "dem", "Glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "PRF", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Der ans Vaterland sich schlie\u00dft, erwiese!", "tokens": ["Der", "ans", "Va\u00b7ter\u00b7land", "sich", "schlie\u00dft", ",", "er\u00b7wie\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "APPRART", "NN", "PRF", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Welche Tr\u00e4nen sind gerecht wie diese?", "tokens": ["Wel\u00b7che", "Tr\u00e4\u00b7nen", "sind", "ge\u00b7recht", "wie", "die\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VAFIN", "ADJD", "KOKOM", "PDS", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Schuldbewu\u00dft verdammt der \u00dcberwinder", "tokens": ["Schuld\u00b7be\u00b7wu\u00dft", "ver\u00b7dammt", "der", "\u00dc\u00b7berw\u00b7in\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Selbst die junge Wi\u00dfbegier der Kinder;", "tokens": ["Selbst", "die", "jun\u00b7ge", "Wi\u00df\u00b7be\u00b7gier", "der", "Kin\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df sie nicht im Ehedem sich spiegeln,", "tokens": ["Da\u00df", "sie", "nicht", "im", "E\u00b7he\u00b7dem", "sich", "spie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "L\u00e4\u00dft er selbst der B\u00fccher Schatz versiegeln!", "tokens": ["L\u00e4\u00dft", "er", "selbst", "der", "B\u00fc\u00b7cher", "Schatz", "ver\u00b7sie\u00b7geln", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Doch umsonst! Welch Volk wir einst gewesen,", "tokens": ["Doch", "um\u00b7sonst", "!", "Welch", "Volk", "wir", "einst", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PIAT", "NN", "PPER", "ADV", "VAPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wird der Sohn im Blick des Vaters lesen;", "tokens": ["Wird", "der", "Sohn", "im", "Blick", "des", "Va\u00b7ters", "le\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ja, das Kind, entwachsen edlem Stamme,", "tokens": ["Ja", ",", "das", "Kind", ",", "ent\u00b7wach\u00b7sen", "ed\u00b7lem", "Stam\u00b7me", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Saugt sich Freiheit aus der Milch der Amme.", "tokens": ["Saugt", "sich", "Frei\u00b7heit", "aus", "der", "Milch", "der", "Am\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Ja, zum Himmel steigen unsre Klagen;", "tokens": ["Ja", ",", "zum", "Him\u00b7mel", "stei\u00b7gen", "uns\u00b7re", "Kla\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "APPRART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Fern hinab durch alle Zeit sie tragen", "tokens": ["Fern", "hin\u00b7ab", "durch", "al\u00b7le", "Zeit", "sie", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "PIAT", "NN", "PPER", "VVINF"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Werden Dichter einst, durch alle Lande:", "tokens": ["Wer\u00b7den", "Dich\u00b7ter", "einst", ",", "durch", "al\u00b7le", "Lan\u00b7de", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "$,", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ewig w\u00e4hrt, o W\u00fctrich, deine Schande!", "tokens": ["E\u00b7wig", "w\u00e4hrt", ",", "o", "W\u00fct\u00b7rich", ",", "dei\u00b7ne", "Schan\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "FM", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Aus der Gruft, in der du uns begraben,", "tokens": ["Aus", "der", "Gruft", ",", "in", "der", "du", "uns", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Schwingt der Genius doch sich auf erhaben,", "tokens": ["Schwingt", "der", "Ge\u00b7nius", "doch", "sich", "auf", "er\u00b7ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PRF", "APPR", "ADJD", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Seine Fl\u00fcgel dehnt er aus gewaltig,", "tokens": ["Sei\u00b7ne", "Fl\u00fc\u00b7gel", "dehnt", "er", "aus", "ge\u00b7wal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Seine Stimme klingt so silberhaltig!", "tokens": ["Sei\u00b7ne", "Stim\u00b7me", "klingt", "so", "sil\u00b7ber\u00b7hal\u00b7tig", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "Diese Worte spricht er zum Despoten:", "tokens": ["Die\u00b7se", "Wor\u00b7te", "spricht", "er", "zum", "Des\u00b7po\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Blo\u00df dem Leichnam siegst du ob, dem toten,", "tokens": ["Blo\u00df", "dem", "Leich\u00b7nam", "siegst", "du", "ob", ",", "dem", "to\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "KOUS", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "W\u00e4hrend stets der Geist in unserm Volke", "tokens": ["W\u00e4h\u00b7rend", "stets", "der", "Geist", "in", "un\u00b7serm", "Vol\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "H\u00f6her strebt als deine Donnerwolke!", "tokens": ["H\u00f6\u00b7her", "strebt", "als", "dei\u00b7ne", "Don\u00b7ner\u00b7wol\u00b7ke", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KOKOM", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Tr\u00fcge nicht des Menschen Seele Waffen,", "tokens": ["Tr\u00fc\u00b7ge", "nicht", "des", "Men\u00b7schen", "See\u00b7le", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "H\u00e4tte Gott die Welt umsonst erschaffen,", "tokens": ["H\u00e4t\u00b7te", "Gott", "die", "Welt", "um\u00b7sonst", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und der Erdball, \u00fcber den wir schleichen,", "tokens": ["Und", "der", "Erd\u00b7ball", ",", "\u00fc\u00b7ber", "den", "wir", "schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "W\u00e4r ein Spiel f\u00fcr dich und deinesgleichen!", "tokens": ["W\u00e4r", "ein", "Spiel", "f\u00fcr", "dich", "und", "dei\u00b7nes\u00b7glei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "PPER", "KON", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "Zwar Nerone hat es viel gegeben;", "tokens": ["Zwar", "Ne\u00b7ro\u00b7ne", "hat", "es", "viel", "ge\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch sie w\u00fcrgten blo\u00df das einzle Leben;", "tokens": ["Doch", "sie", "w\u00fcrg\u00b7ten", "blo\u00df", "das", "einz\u00b7le", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "V\u00f6lkerm\u00f6rder, aller Scham entbl\u00f6\u00dfte,", "tokens": ["V\u00f6l\u00b7ker\u00b7m\u00f6r\u00b7der", ",", "al\u00b7ler", "Scham", "ent\u00b7bl\u00f6\u00df\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Gab es wenige, doch du bist der gr\u00f6\u00dfte!", "tokens": ["Gab", "es", "we\u00b7ni\u00b7ge", ",", "doch", "du", "bist", "der", "gr\u00f6\u00df\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "$,", "KON", "PPER", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.16": {"line.1": {"text": "Magst du denn vernichten und verbannen,", "tokens": ["Magst", "du", "denn", "ver\u00b7nich\u00b7ten", "und", "ver\u00b7ban\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "KON", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Eure Seelen sind von Stein, Tyrannen!", "tokens": ["Eu\u00b7re", "See\u00b7len", "sind", "von", "Stein", ",", "Ty\u00b7ran\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Aber naht ein Augenblick der Rache,", "tokens": ["A\u00b7ber", "naht", "ein", "Au\u00b7gen\u00b7blick", "der", "Ra\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Dann gedenk an deine Schuld, o Drache!", "tokens": ["Dann", "ge\u00b7denk", "an", "dei\u00b7ne", "Schuld", ",", "o", "Dra\u00b7che", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "FM", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.17": {"line.1": {"text": "Was wir \u00e4chzten unter deinen F\u00fc\u00dfen,", "tokens": ["Was", "wir", "\u00e4chz\u00b7ten", "un\u00b7ter", "dei\u00b7nen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wird der Sohn, es wird's der Enkel b\u00fc\u00dfen!", "tokens": ["Wird", "der", "Sohn", ",", "es", "wird's", "der", "En\u00b7kel", "b\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Mehr als eine Krone wird zerbrechen,", "tokens": ["Mehr", "als", "ei\u00b7ne", "Kro\u00b7ne", "wird", "zer\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Denn den Himmel kannst du nicht bestechen!", "tokens": ["Denn", "den", "Him\u00b7mel", "kannst", "du", "nicht", "be\u00b7ste\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "Ein Harmodius wird zuletzt sich finden,", "tokens": ["Ein", "Har\u00b7mo\u00b7dius", "wird", "zu\u00b7letzt", "sich", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ADV", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Wird ums blutige Schwert die Myrte winden:", "tokens": ["Wird", "ums", "blu\u00b7ti\u00b7ge", "Schwert", "die", "Myr\u00b7te", "win\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Dann, o dann auf unsere Gr\u00e4ber pflanze", "tokens": ["Dann", ",", "o", "dann", "auf", "un\u00b7se\u00b7re", "Gr\u00e4\u00b7ber", "pflan\u00b7ze"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "FM", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Einen Zweig er aus dem sch\u00f6nsten Kranze!", "tokens": ["Ei\u00b7nen", "Zweig", "er", "aus", "dem", "sch\u00f6ns\u00b7ten", "Kran\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}