{"textgrid.poem.57375": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00dcber Avignons Blutgericht ragt das der Lo\u00e4re", "genre": "verse", "period": "N.A.", "pub_year": 1795, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00dcber Avignons Blutgericht ragt das der Lo\u00e4re", "tokens": ["\u00dc\u00b7ber", "A\u00b7vi\u00b7gnons", "Blut\u00b7ge\u00b7richt", "ragt", "das", "der", "Lo\u00e4\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NN", "VVFIN", "ART", "ART", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Hoch empor; die Sprache vermag doch", "tokens": ["Hoch", "em\u00b7por", ";", "die", "Spra\u00b7che", "ver\u00b7mag", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$.", "ART", "NN", "VVFIN", "ADV"], "meter": "+-+-+-++-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Dort zu stammeln: hier fehlt's ganz an den Worten ihr, sind ihr", "tokens": ["Dort", "zu", "stam\u00b7meln", ":", "hier", "fehlt's", "ganz", "an", "den", "Wor\u00b7ten", "ihr", ",", "sind", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PTKZU", "VVINF", "$.", "ADV", "VVFIN", "ADV", "APPR", "ART", "NN", "PPER", "$,", "VAFIN", "PPER"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "Selbst die lebendsten todt; sie verstummet!", "tokens": ["Selbst", "die", "le\u00b7bends\u00b7ten", "todt", ";", "sie", "ver\u00b7stum\u00b7met", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "ADJD", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-++-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Wissbegierigen k\u00f6nte vielleicht wortlose Geberdung", "tokens": ["Wiss\u00b7be\u00b7gie\u00b7ri\u00b7gen", "k\u00f6n\u00b7te", "viel\u00b7leicht", "wort\u00b7lo\u00b7se", "Ge\u00b7ber\u00b7dung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ADV", "ADJA", "NN"], "meter": "+-+--+--+-+----", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Das, das Niegesehene bilden:", "tokens": ["Das", ",", "das", "Nie\u00b7ge\u00b7se\u00b7he\u00b7ne", "bil\u00b7den", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PIS", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Aber w\u00fcrden sie nicht entfliehn? nicht, wenn vor Entsetzen", "tokens": ["A\u00b7ber", "w\u00fcr\u00b7den", "sie", "nicht", "ent\u00b7fliehn", "?", "nicht", ",", "wenn", "vor", "Ent\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "VVINF", "$.", "PTKNEG", "$,", "KOUS", "APPR", "NN"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Sie einwurzelten, schnell sich verh\u00fcllen?", "tokens": ["Sie", "ein\u00b7wur\u00b7zel\u00b7ten", ",", "schnell", "sich", "ver\u00b7h\u00fcl\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "PRF", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Habt ihr Thr\u00e4nen, die ganz des Guten innerstes r\u00fchren,", "tokens": ["Habt", "ihr", "Thr\u00e4\u00b7nen", ",", "die", "ganz", "des", "Gu\u00b7ten", "in\u00b7ners\u00b7tes", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADJA", "VVINF", "$,"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Thr\u00e4nen des tiefsten Grams, blutige Thr\u00e4nen; so weint!", "tokens": ["Thr\u00e4\u00b7nen", "des", "tiefs\u00b7ten", "Grams", ",", "blu\u00b7ti\u00b7ge", "Thr\u00e4\u00b7nen", ";", "so", "weint", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,", "ADJA", "NN", "$.", "ADV", "VVFIN", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.11": {"text": "K\u00f6nige, Schaaren aus V\u00f6lkern vollf\u00fchreten viele, nicht kleine", "tokens": ["K\u00f6\u00b7ni\u00b7ge", ",", "Schaa\u00b7ren", "aus", "V\u00f6l\u00b7kern", "voll\u00b7f\u00fch\u00b7re\u00b7ten", "vie\u00b7le", ",", "nicht", "klei\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "APPR", "NN", "VVFIN", "PIS", "$,", "PTKNEG", "ADJA"], "meter": "+--+--+--+--+--+-", "measure": "hexameter"}, "line.12": {"text": "Greuel in Jahrhunderten. Frankreichs", "tokens": ["Greu\u00b7el", "in", "Jahr\u00b7hun\u00b7der\u00b7ten", ".", "Fran\u00b7kreichs"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "APPR", "NN", "$.", "NE"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Freye, die Herscher, das Volk zu Schaaren vollf\u00fchreten gr\u00f6ssre,", "tokens": ["Frey\u00b7e", ",", "die", "Her\u00b7scher", ",", "das", "Volk", "zu", "Schaa\u00b7ren", "voll\u00b7f\u00fch\u00b7re\u00b7ten", "gr\u00f6ss\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,", "ART", "NN", "APPR", "NN", "ADJA", "ADJA", "$,"], "meter": "+--+--+-+-++--+-", "measure": "dactylic.di.plus"}, "line.14": {"text": "Mehr, eh Ein Mondhundert entflohn war.", "tokens": ["Mehr", ",", "eh", "Ein", "Mond\u00b7hun\u00b7dert", "ent\u00b7flohn", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Jenes Gericht, der Wasserehn Erfinder, es blickte", "tokens": ["Je\u00b7nes", "Ge\u00b7richt", ",", "der", "Was\u00b7se\u00b7rehn", "Er\u00b7fin\u00b7der", ",", "es", "blick\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "NN", "$,", "PPER", "VVFIN"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.16": {"text": "Stets nach der H\u00f6he der Staatsumschaffung;", "tokens": ["Stets", "nach", "der", "H\u00f6\u00b7he", "der", "Staat\u00b7sum\u00b7schaf\u00b7fung", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.17": {"text": "Ha der Lo\u00e4re Todesgericht hat empor sich geschwungen", "tokens": ["Ha", "der", "Lo\u00e4\u00b7re", "To\u00b7des\u00b7ge\u00b7richt", "hat", "em\u00b7por", "sich", "ge\u00b7schwun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "NN", "VAFIN", "PPER", "PRF", "VVPP"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.18": {"text": "Bis in der Greuel gesunkensten Abgrund!", "tokens": ["Bis", "in", "der", "Greu\u00b7el", "ge\u00b7sun\u00b7kens\u00b7ten", "Ab\u00b7grund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "---+--+--+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Habt ihr Thr\u00e4nen, die ganz des Guten innerstes r\u00fchren,", "tokens": ["Habt", "ihr", "Thr\u00e4\u00b7nen", ",", "die", "ganz", "des", "Gu\u00b7ten", "in\u00b7ners\u00b7tes", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "ADJA", "VVINF", "$,"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "Thr\u00e4nen des tiefsten Grams, blutige Thr\u00e4nen; so weint!", "tokens": ["Thr\u00e4\u00b7nen", "des", "tiefs\u00b7ten", "Grams", ",", "blu\u00b7ti\u00b7ge", "Thr\u00e4\u00b7nen", ";", "so", "weint", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,", "ADJA", "NN", "$.", "ADV", "VVFIN", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.21": {"text": "Wunderbar! neues Licht hat den Wissenschaften geleuchtet,", "tokens": ["Wun\u00b7der\u00b7bar", "!", "neu\u00b7es", "Licht", "hat", "den", "Wis\u00b7sen\u00b7schaf\u00b7ten", "ge\u00b7leuch\u00b7tet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ADJA", "NN", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.22": {"text": "Durch die tollhausw\u00fcrdigen Richter!", "tokens": ["Durch", "die", "toll\u00b7haus\u00b7w\u00fcr\u00b7di\u00b7gen", "Rich\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.23": {"text": "Denn, durch sie, ist geendet ein Streit der Weisen; wir wissen", "tokens": ["Denn", ",", "durch", "sie", ",", "ist", "ge\u00b7en\u00b7det", "ein", "Streit", "der", "Wei\u00b7sen", ";", "wir", "wis\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "APPR", "PPER", "$,", "VAFIN", "VVPP", "ART", "NN", "ART", "NN", "$.", "PPER", "VVINF"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Jetzo, dass Seelen, haben die Thiere.", "tokens": ["Jet\u00b7zo", ",", "dass", "See\u00b7len", ",", "ha\u00b7ben", "die", "Thie\u00b7re", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "NN", "$,", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Habt ihr Thr\u00e4nen, wie keine floss der entheiligten Menschheit,", "tokens": ["Habt", "ihr", "Thr\u00e4\u00b7nen", ",", "wie", "kei\u00b7ne", "floss", "der", "en\u00b7thei\u00b7lig\u00b7ten", "Menschheit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PWAV", "PIAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.26": {"text": "Thr\u00e4nen des tiefsten Grams, blutige Thr\u00e4nen; so weint!", "tokens": ["Thr\u00e4\u00b7nen", "des", "tiefs\u00b7ten", "Grams", ",", "blu\u00b7ti\u00b7ge", "Thr\u00e4\u00b7nen", ";", "so", "weint", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,", "ADJA", "NN", "$.", "ADV", "VVFIN", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}}}}}