{"textgrid.poem.54303": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Clotildgen bild sich viel auf ihre Charmen ein,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Clotildgen bild sich viel auf ihre Charmen ein,", "tokens": ["Clo\u00b7tild\u00b7gen", "bild", "sich", "viel", "auf", "ih\u00b7re", "Char\u00b7men", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PRF", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch denckt sie vielmahl selbst: wie kan es m\u00f6glich seyn,", "tokens": ["Doch", "denckt", "sie", "viel\u00b7mahl", "selbst", ":", "wie", "kan", "es", "m\u00f6g\u00b7lich", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$.", "PWAV", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df sich ein gantzes Heer um meine Gunst bem\u00fchet?", "tokens": ["Da\u00df", "sich", "ein", "gant\u00b7zes", "Heer", "um", "mei\u00b7ne", "Gunst", "be\u00b7m\u00fc\u00b7het", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie wei\u00df fast selber nicht, warum man nach ihr siehet.", "tokens": ["Sie", "wei\u00df", "fast", "sel\u00b7ber", "nicht", ",", "wa\u00b7rum", "man", "nach", "ihr", "sie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKNEG", "$,", "PWAV", "PIS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Ansehn und Verstand ist, d\u00fcnckt mich, gantz gemein,", "tokens": ["Ihr", "An\u00b7sehn", "und", "Ver\u00b7stand", "ist", ",", "d\u00fcnckt", "mich", ",", "gantz", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAFIN", "$,", "VVFIN", "PPER", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und dennoch fallen viel in ihren Sprenckel ein.", "tokens": ["Und", "den\u00b7noch", "fal\u00b7len", "viel", "in", "ih\u00b7ren", "Spren\u00b7ckel", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn tritt das liebe Kind von ungefehr ans Fenster,", "tokens": ["Denn", "tritt", "das", "lie\u00b7be", "Kind", "von", "un\u00b7ge\u00b7fehr", "ans", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So stellen sich daf\u00fcr am lichten Tag Gespenster.", "tokens": ["So", "stel\u00b7len", "sich", "da\u00b7f\u00fcr", "am", "lich\u00b7ten", "Tag", "Ge\u00b7spens\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PAV", "APPRART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Bald wird ein Feder-Busch von Haupte gleich ger\u00fcckt,", "tokens": ["Bald", "wird", "ein", "Fe\u00b7der\u00b7Busch", "von", "Haup\u00b7te", "gleich", "ge\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da sich hingegen auch ein armes W\u00fcrmgen b\u00fcckt.", "tokens": ["Da", "sich", "hin\u00b7ge\u00b7gen", "auch", "ein", "ar\u00b7mes", "W\u00fcrm\u00b7gen", "b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Drum soll auch Amor ihr den Liebesdienst erweisen,", "tokens": ["Drum", "soll", "auch", "A\u00b7mor", "ihr", "den", "Lie\u00b7bes\u00b7dienst", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ADV", "NE", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und nun ihr Rechnungs-Rath von Complimenten heissen.", "tokens": ["Und", "nun", "ihr", "Rech\u00b7nungs\u00b7Rath", "von", "Com\u00b7pli\u00b7men\u00b7ten", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPOSAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Allein er gab ihr n\u00e4chst gar deutlich zu verstehn,", "tokens": ["Al\u00b7lein", "er", "gab", "ihr", "n\u00e4chst", "gar", "deut\u00b7lich", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er k\u00f6nte di\u00dfmahl nicht in ihre Dienste gehn:", "tokens": ["Er", "k\u00f6n\u00b7te", "di\u00df\u00b7mahl", "nicht", "in", "ih\u00b7re", "Diens\u00b7te", "gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Hencker, sprach er, mag dergleichen Amt erwehlen,", "tokens": ["Der", "Hen\u00b7cker", ",", "sprach", "er", ",", "mag", "derg\u00b7lei\u00b7chen", "Amt", "er\u00b7weh\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PIS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wer wolte wohl bey dir die Complimenten zehlen?", "tokens": ["Wer", "wol\u00b7te", "wohl", "bey", "dir", "die", "Com\u00b7pli\u00b7men\u00b7ten", "zeh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "APPR", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Aus ieden Steine springt ein Spa\u00df-Galan heraus /", "tokens": ["Aus", "ie\u00b7den", "Stei\u00b7ne", "springt", "ein", "Spa\u00df\u00b7Ga\u00b7lan", "he\u00b7raus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und die belagern recht dein und das Nachbahrs Hau\u00df.", "tokens": ["Und", "die", "be\u00b7la\u00b7gern", "recht", "dein", "und", "das", "Nach\u00b7bahrs", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PPOSAT", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Schau, wie die M\u00e4nnerchen zu gantzen Schaar und Hauffen", "tokens": ["Schau", ",", "wie", "die", "M\u00e4n\u00b7ner\u00b7chen", "zu", "gant\u00b7zen", "Schaar", "und", "Hauf\u00b7fen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.20": {"text": "Mit krummen Lorenzen vor deine Fenster lauffen.", "tokens": ["Mit", "krum\u00b7men", "Lo\u00b7ren\u00b7zen", "vor", "dei\u00b7ne", "Fens\u00b7ter", "lauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Sie neigen wahrlich sich so tieff, wie man ersieht,", "tokens": ["Sie", "nei\u00b7gen", "wahr\u00b7lich", "sich", "so", "tieff", ",", "wie", "man", "er\u00b7sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PRF", "ADV", "ADJD", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wie Puppen, welche man an einen Faden zieht.", "tokens": ["Wie", "Pup\u00b7pen", ",", "wel\u00b7che", "man", "an", "ei\u00b7nen", "Fa\u00b7den", "zieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "PIS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Denn ieder der im Gru\u00df will fast den Nacken brechen,", "tokens": ["Denn", "ie\u00b7der", "der", "im", "Gru\u00df", "will", "fast", "den", "Na\u00b7cken", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "APPRART", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Sucht, wie du selber weist, den andern abzustechen.", "tokens": ["Sucht", ",", "wie", "du", "sel\u00b7ber", "weist", ",", "den", "an\u00b7dern", "ab\u00b7zu\u00b7ste\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,", "ART", "ADJA", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Wenn Beutels Rechen-Buch, und hundert andre mehr,", "tokens": ["Wenn", "Beu\u00b7tels", "Re\u00b7chen\u00b7Buch", ",", "und", "hun\u00b7dert", "and\u00b7re", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "$,", "KON", "CARD", "PIS", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Mir gleich bey solchen Amt zu Dienst und Willen w\u00e4r,", "tokens": ["Mir", "gleich", "bey", "sol\u00b7chen", "Amt", "zu", "Dienst", "und", "Wil\u00b7len", "w\u00e4r", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PIAT", "NN", "APPR", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "So w\u00fcrd ich wahrlich doch, bey so gestalten Sachen,", "tokens": ["So", "w\u00fcrd", "ich", "wahr\u00b7lich", "doch", ",", "bey", "so", "ge\u00b7stal\u00b7ten", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "$,", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Die Zahlen reichten nicht, kein Facit k\u00f6nnen machen.", "tokens": ["Die", "Zah\u00b7len", "reich\u00b7ten", "nicht", ",", "kein", "Fa\u00b7cit", "k\u00f6n\u00b7nen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "$,", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Schrieb ich den Schwall und Schwarm von deinen Charmen auf,", "tokens": ["Schrieb", "ich", "den", "Schwall", "und", "Schwarm", "von", "dei\u00b7nen", "Char\u00b7men", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So gieng ein Rie\u00df Pappier in einer Stunde drauf.", "tokens": ["So", "gieng", "ein", "Rie\u00df", "Pap\u00b7pier", "in", "ei\u00b7ner", "Stun\u00b7de", "drauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und mein! Wer wolte mir daf\u00fcr die Kosten zahlen?", "tokens": ["Und", "mein", "!", "Wer", "wol\u00b7te", "mir", "da\u00b7f\u00fcr", "die", "Kos\u00b7ten", "zah\u00b7len", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "$.", "PWS", "VMFIN", "PPER", "PAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die meisten suchen nur zum Spa\u00df mit dir zu dahlen,", "tokens": ["Die", "meis\u00b7ten", "su\u00b7chen", "nur", "zum", "Spa\u00df", "mit", "dir", "zu", "dah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "APPRART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Sie wenden, seh ich wohl, auf dich nicht allzu viel,", "tokens": ["Sie", "wen\u00b7den", ",", "seh", "ich", "wohl", ",", "auf", "dich", "nicht", "all\u00b7zu", "viel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "VVFIN", "PPER", "ADV", "$,", "APPR", "PPER", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Dieweil ein jeder dich umsonst nur haben will.", "tokens": ["Die\u00b7weil", "ein", "je\u00b7der", "dich", "um\u00b7sonst", "nur", "ha\u00b7ben", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIAT", "PRF", "ADV", "ADV", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Dein Beutel aber kan die M\u00fche nicht belohnen,", "tokens": ["Dein", "Beu\u00b7tel", "a\u00b7ber", "kan", "die", "M\u00fc\u00b7he", "nicht", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Und also wirst du mich mit solchen Dienst verschonen.", "tokens": ["Und", "al\u00b7so", "wirst", "du", "mich", "mit", "sol\u00b7chen", "Dienst", "ver\u00b7scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PRF", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Inzwischen wei\u00df ich nicht, ob jetzt Clotildgen lacht", "tokens": ["I\u00b7nzwi\u00b7schen", "wei\u00df", "ich", "nicht", ",", "ob", "jetzt", "Clo\u00b7tild\u00b7gen", "lacht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "ADV", "NN", "VVFIN"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.38": {"text": "Und ob sie dieser Korb nicht schamroth hat gemacht,", "tokens": ["Und", "ob", "sie", "die\u00b7ser", "Korb", "nicht", "scham\u00b7roth", "hat", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDAT", "NN", "PTKNEG", "ADJD", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Denn Amor, d\u00fcnckt mich, hat der Welt gar klar entdecket,", "tokens": ["Denn", "A\u00b7mor", ",", "d\u00fcnckt", "mich", ",", "hat", "der", "Welt", "gar", "klar", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ART", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Was hinter selbiger vor Trug und Blendwerck stecket.", "tokens": ["Was", "hin\u00b7ter", "sel\u00b7bi\u00b7ger", "vor", "Trug", "und", "Blend\u00b7werck", "ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ADJD", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}