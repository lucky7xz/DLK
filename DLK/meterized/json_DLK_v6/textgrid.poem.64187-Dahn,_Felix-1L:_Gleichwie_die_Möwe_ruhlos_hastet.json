{"textgrid.poem.64187": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gleichwie die M\u00f6we ruhlos hastet", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gleichwie die M\u00f6we ruhlos hastet", "tokens": ["Gleich\u00b7wie", "die", "M\u00f6\u00b7we", "ruh\u00b7los", "has\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Land zu Meer, von Meer zu Land", "tokens": ["Von", "Land", "zu", "Meer", ",", "von", "Meer", "zu", "Land"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN", "$,", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kaum im Flug die Schwinge rastet", "tokens": ["Und", "kaum", "im", "Flug", "die", "Schwin\u00b7ge", "ras\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auf Wellenschaum, auf D\u00fcnensand: \u2013", "tokens": ["Auf", "Wel\u00b7len\u00b7schaum", ",", "auf", "D\u00fc\u00b7nen\u00b7sand", ":", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So wogen wir auf irren Bahnen", "tokens": ["So", "wo\u00b7gen", "wir", "auf", "ir\u00b7ren", "Bah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Deich zu Flut, von Flut zu Deich,", "tokens": ["Von", "Deich", "zu", "Flut", ",", "von", "Flut", "zu", "Deich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "NN", "$,", "APPR", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zerschliss'ne Segel unsre Fahnen,", "tokens": ["Zer\u00b7schliss'\u00b7ne", "Se\u00b7gel", "uns\u00b7re", "Fah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein morsches Schifflein unser Reich.", "tokens": ["Ein", "mor\u00b7sches", "Schif\u00b7flein", "un\u00b7ser", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Oft nur den letzten Schu\u00df im Laufe, \u2013", "tokens": ["Oft", "nur", "den", "letz\u00b7ten", "Schu\u00df", "im", "Lau\u00b7fe", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Sturm gepeitscht, vom Feind gehetzt, \u2013", "tokens": ["Vom", "Sturm", "ge\u00b7peitscht", ",", "vom", "Feind", "ge\u00b7hetzt", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "APPRART", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein adeliger Bettlerhaufe, \u2013", "tokens": ["Ein", "a\u00b7de\u00b7li\u00b7ger", "Bett\u00b7ler\u00b7hau\u00b7fe", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den Hut zerhaun, das Wams zerfetzt: \u2013 \u2013", "tokens": ["Den", "Hut", "zer\u00b7haun", ",", "das", "Wams", "zer\u00b7fetzt", ":", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ART", "NN", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und doch erbebt das stolze Spanien,", "tokens": ["Und", "doch", "er\u00b7bebt", "das", "stol\u00b7ze", "Spa\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In dessen Reich der Tag nicht sinkt,", "tokens": ["In", "des\u00b7sen", "Reich", "der", "Tag", "nicht", "sinkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn unser Racheruf: \u00bbOranien!\u00ab", "tokens": ["Wenn", "un\u00b7ser", "Ra\u00b7ch\u00b7e\u00b7ruf", ":", "\u00bb", "O\u00b7ra\u00b7ni\u00b7en", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$.", "$(", "NE", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich \u00fcber Albas Heere schwingt.", "tokens": ["Sich", "\u00fc\u00b7ber", "Al\u00b7bas", "Hee\u00b7re", "schwingt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ihr bebt mit Recht! Von Sklavenschande", "tokens": ["Ihr", "bebt", "mit", "Recht", "!", "Von", "Skla\u00b7ven\u00b7schan\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bei Gott, wird dieser Boden rein,", "tokens": ["Bei", "Gott", ",", "wird", "die\u00b7ser", "Bo\u00b7den", "rein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "VAFIN", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und m\u00fc\u00dften alle Niederlande", "tokens": ["Und", "m\u00fc\u00df\u00b7ten", "al\u00b7le", "Nie\u00b7der\u00b7lan\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von Meeresflut verschlungen sein!", "tokens": ["Von", "Mee\u00b7res\u00b7flut", "ver\u00b7schlun\u00b7gen", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Durchstecht den Deich, rei\u00dft auf die Schleusen!", "tokens": ["Durch\u00b7stecht", "den", "Deich", ",", "rei\u00dft", "auf", "die", "Schleu\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ers\u00e4uft die fremde Tyrannei!", "tokens": ["Er\u00b7s\u00e4uft", "die", "frem\u00b7de", "Ty\u00b7ran\u00b7nei", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es naht die See, es nahn die Geusen:", "tokens": ["Es", "naht", "die", "See", ",", "es", "nahn", "die", "Geu\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Land wird Meer, doch wird es frei!", "tokens": ["Das", "Land", "wird", "Meer", ",", "doch", "wird", "es", "frei", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$,", "ADV", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}