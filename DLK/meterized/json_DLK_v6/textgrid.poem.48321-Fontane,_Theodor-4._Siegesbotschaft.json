{"textgrid.poem.48321": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "4. Siegesbotschaft", "genre": "verse", "period": "N.A.", "pub_year": 1888, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tanz", "tokens": ["Tanz"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Ist heut' im Kruge zu Vehlefanz.", "tokens": ["Ist", "heut'", "im", "Kru\u00b7ge", "zu", "Veh\u00b7le\u00b7fanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "APPR", "NE", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Oben, auf rotgestrichner Empore,", "tokens": ["O\u00b7ben", ",", "auf", "rot\u00b7ge\u00b7strich\u00b7ner", "Em\u00b7po\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Sitzt die Musik in vollem Chore:", "tokens": ["Sitzt", "die", "Mu\u00b7sik", "in", "vol\u00b7lem", "Cho\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Klarinette, Geigen, Contreba\u00df,", "tokens": ["Kla\u00b7ri\u00b7net\u00b7te", ",", "Gei\u00b7gen", ",", "Cont\u00b7re\u00b7ba\u00df", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Und vor jedem ein Pult und ein Wei\u00dfbierglas.", "tokens": ["Und", "vor", "je\u00b7dem", "ein", "Pult", "und", "ein", "Wei\u00df\u00b7bier\u00b7glas", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Und unten drehn sich, in Schott'schem und Walzer,", "tokens": ["Und", "un\u00b7ten", "drehn", "sich", ",", "in", "Schott'\u00b7schem", "und", "Wal\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "PRF", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Die Paare, dazwischen ein Juchzer, ein Schnalzer,", "tokens": ["Die", "Paa\u00b7re", ",", "da\u00b7zwi\u00b7schen", "ein", "Juch\u00b7zer", ",", "ein", "Schnal\u00b7zer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "Und Zug und Hitze und blakende Lichter,", "tokens": ["Und", "Zug", "und", "Hit\u00b7ze", "und", "bla\u00b7ken\u00b7de", "Lich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Am Fenster neugierige Kindergesichter,", "tokens": ["Am", "Fens\u00b7ter", "neu\u00b7gie\u00b7ri\u00b7ge", "Kin\u00b7der\u00b7ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-++--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Ein Rempeln und Rennen, ein Sto\u00dfen und Stemmen,", "tokens": ["Ein", "Rem\u00b7peln", "und", "Ren\u00b7nen", ",", "ein", "Sto\u00b7\u00dfen", "und", "Stem\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.12": {"text": "Und mit eins: \u00bbDa kommt ja der Neumann aus Cremmen.", "tokens": ["Und", "mit", "eins", ":", "\u00bb", "Da", "kommt", "ja", "der", "Neu\u00b7mann", "aus", "Crem\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "$.", "$(", "ADV", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Der Laatsche-Neumann. Was will denn der?", "tokens": ["Der", "Laatsche\u00b7Neu\u00b7mann", ".", "Was", "will", "denn", "der", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PWS", "VMFIN", "ADV", "ART", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Laatsche-Neumann, hierher, hierher,", "tokens": ["Laatsche\u00b7Neu\u00b7mann", ",", "hier\u00b7her", ",", "hier\u00b7her", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "PAV", "$,", "PAV", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Er bringt was, stillgestanden, stramm,", "tokens": ["Er", "bringt", "was", ",", "still\u00b7ge\u00b7stan\u00b7den", ",", "stramm", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ich wett', er bringt ein Telegramm.\u00ab", "tokens": ["Ich", "wett'", ",", "er", "bringt", "ein", "Te\u00b7le\u00b7gramm", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Und Neumann, pl\u00f6tzlich steht er oben,", "tokens": ["Und", "Neu\u00b7mann", ",", "pl\u00f6tz\u00b7lich", "steht", "er", "o\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ADJD", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Sie haben ihn auf den Tisch gehoben.", "tokens": ["Sie", "ha\u00b7ben", "ihn", "auf", "den", "Tisch", "ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bblesen ...\u00ab", "tokens": ["\u00bb", "le\u00b7sen", "...", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "VVINF", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "\u00bbmu\u00df erst zu Puste kommen ...\u00ab", "tokens": ["\u00bb", "mu\u00df", "erst", "zu", "Pus\u00b7te", "kom\u00b7men", "...", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$(", "$("], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "\u00bblesen ...\u00ab", "tokens": ["\u00bb", "le\u00b7sen", "...", "\u00ab"], "token_info": ["punct", "word", "punct", "punct"], "pos": ["$(", "VVINF", "$(", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.5": {"text": "Feldwebel Probst beim Sturme geblieben.", "tokens": ["Feld\u00b7we\u00b7bel", "Probst", "beim", "Stur\u00b7me", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Verluste wenig. Danske viel ...\u00ab", "tokens": ["Ver\u00b7lus\u00b7te", "we\u00b7nig", ".", "Dans\u00b7ke", "viel", "...", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "$.", "NE", "ADV", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Alles sich in die Arme fiel,", "tokens": ["Al\u00b7les", "sich", "in", "die", "Ar\u00b7me", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und zu wissen, wie's eigentlich gewesen,", "tokens": ["Und", "zu", "wis\u00b7sen", ",", "wie's", "ei\u00b7gent\u00b7lich", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKZU", "VVINF", "$,", "VVFIN", "ADV", "VAPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Mu\u00df Neumann es immer wieder lesen.", "tokens": ["Mu\u00df", "Neu\u00b7mann", "es", "im\u00b7mer", "wie\u00b7der", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Dem aber will es nicht mehr zu Sinn.", "tokens": ["Dem", "a\u00b7ber", "will", "es", "nicht", "mehr", "zu", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbvehlefanzer, wo denkt ihr hin,", "tokens": ["\u00bb", "veh\u00b7le\u00b7fan\u00b7zer", ",", "wo", "denkt", "ihr", "hin", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "PWAV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Habe noch andre gute Bekannte ...\u00ab", "tokens": ["Ha\u00b7be", "noch", "and\u00b7re", "gu\u00b7te", "Be\u00b7kann\u00b7te", "...", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "ADJA", "ADJA", "NN", "$(", "$("], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "\u00bbwelche denn, welche?\u00ab", "tokens": ["\u00bb", "wel\u00b7che", "denn", ",", "wel\u00b7che", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "PRELS", "ADV", "$,", "PRELS", "$.", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "\u00bbmu\u00df noch nach Schwante.\u00ab", "tokens": ["\u00bb", "mu\u00df", "noch", "nach", "Schwan\u00b7te", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "ADV", "APPR", "NN", "$.", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbschwante, die lumpigen tausend Schritt,", "tokens": ["\u00bb", "schwan\u00b7te", ",", "die", "lum\u00b7pi\u00b7gen", "tau\u00b7send", "Schritt", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "ART", "ADJA", "CARD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Hurra, Neumann, da kommen wir mit.\u00ab", "tokens": ["Hur\u00b7ra", ",", "Neu\u00b7mann", ",", "da", "kom\u00b7men", "wir", "mit", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "NE", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Und hinein in die laue Fr\u00fchlingsnacht", "tokens": ["Und", "hin\u00b7ein", "in", "die", "lau\u00b7e", "Fr\u00fch\u00b7lings\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ganz Vehlefanz hat sich aufgemacht.", "tokens": ["Ganz", "Veh\u00b7le\u00b7fanz", "hat", "sich", "auf\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "PRF", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Neumann laatscht nach.", "tokens": ["Neu\u00b7mann", "laatscht", "nach", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.8": {"line.1": {"text": "Schwante lag schon in Schlaf,", "tokens": ["Schwan\u00b7te", "lag", "schon", "in", "Schlaf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Als aber die Siegesbotschaft es traf,", "tokens": ["Als", "a\u00b7ber", "die", "Sie\u00b7ges\u00b7bot\u00b7schaft", "es", "traf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ward's wach.", "tokens": ["Ward's", "wach", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "PTKVZ", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.9": {"line.1": {"text": "Der Mond am Himmel stand,", "tokens": ["Der", "Mond", "am", "Him\u00b7mel", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und in Jubel stand das Havelland.", "tokens": ["Und", "in", "Ju\u00b7bel", "stand", "das", "Ha\u00b7vel\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}