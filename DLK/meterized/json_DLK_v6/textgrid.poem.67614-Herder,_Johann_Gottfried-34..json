{"textgrid.poem.67614": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "34.", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eine feine, glatte Maus", "tokens": ["Ei\u00b7ne", "fei\u00b7ne", ",", "glat\u00b7te", "Maus"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Suchte sich in stolzer Jugend", "tokens": ["Such\u00b7te", "sich", "in", "stol\u00b7zer", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Braut aus.", "tokens": ["Ei\u00b7ne", "Braut", "aus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Und wie jeder Freier begann,", "tokens": ["Und", "wie", "je\u00b7der", "Frei\u00b7er", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Fing sie hoch an:", "tokens": ["Fing", "sie", "hoch", "an", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "\u00bbmeine Braut, sie sei von Tugend,", "tokens": ["\u00bb", "mei\u00b7ne", "Braut", ",", "sie", "sei", "von", "Tu\u00b7gend", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Sch\u00f6ne, W\u00e4rme, Wonne!", "tokens": ["Sch\u00f6\u00b7ne", ",", "W\u00e4r\u00b7me", ",", "Won\u00b7ne", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "Kurz, sie sei die Jungfrau \u2013 Sonne!\u00ab", "tokens": ["Kurz", ",", "sie", "sei", "die", "Jung\u00b7frau", "\u2013", "Son\u00b7ne", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "ART", "NN", "$(", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Eine Weile blieb sie stehn.", "tokens": ["Ei\u00b7ne", "Wei\u00b7le", "blieb", "sie", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "\u00bbh\u00f6r es, hohe Jungfrau Sonne!", "tokens": ["\u00bb", "h\u00f6r", "es", ",", "ho\u00b7he", "Jung\u00b7frau", "Son\u00b7ne", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Doch sie will es nicht verstehn,", "tokens": ["Doch", "sie", "will", "es", "nicht", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "Ist so stolz, hm! und so warm", "tokens": ["Ist", "so", "stolz", ",", "hm", "!", "und", "so", "warm"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJD", "$,", "NE", "$.", "KON", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "D\u00fcnkt mich ihr im Arm.", "tokens": ["D\u00fcnkt", "mich", "ihr", "im", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPRART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "La\u00df sie! ich will weiter gehn.", "tokens": ["La\u00df", "sie", "!", "ich", "will", "wei\u00b7ter", "gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "Die eben dort vor\u00fcberzieht", "tokens": ["Die", "e\u00b7ben", "dort", "vor\u00b7\u00fc\u00b7berz\u00b7ieht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und ebenso wie ich die stolze Sonne flieht", "tokens": ["Und", "e\u00b7ben\u00b7so", "wie", "ich", "die", "stol\u00b7ze", "Son\u00b7ne", "flieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KOKOM", "PPER", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und, wie ich merke, selbst die Sonne d\u00e4mpft", "tokens": ["Und", ",", "wie", "ich", "mer\u00b7ke", ",", "selbst", "die", "Son\u00b7ne", "d\u00e4mpft"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Und mit ihr k\u00e4mpft \u2013", "tokens": ["Und", "mit", "ihr", "k\u00e4mpft", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.19": {"text": "Sei, hohe Wolke, mir zur Braut", "tokens": ["Sei", ",", "ho\u00b7he", "Wol\u00b7ke", ",", "mir", "zur", "Braut"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "In Deinem Schoo\u00df vertraut!\u00ab", "tokens": ["In", "Dei\u00b7nem", "Schoo\u00df", "ver\u00b7traut", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Die Wolke \u00f6ffnet' ihren Schoo\u00df", "tokens": ["Die", "Wol\u00b7ke", "\u00f6ff\u00b7net'", "ih\u00b7ren", "Schoo\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und regnete drauf los.", "tokens": ["Und", "reg\u00b7ne\u00b7te", "drauf", "los", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "\u00bbdie hohe Braut ist na\u00df,", "tokens": ["\u00bb", "die", "ho\u00b7he", "Braut", "ist", "na\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Ein leckes Fa\u00df!\u00ab", "tokens": ["Ein", "le\u00b7ckes", "Fa\u00df", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.25": {"text": "Kurz, die klug gewaschne Maus", "tokens": ["Kurz", ",", "die", "klug", "ge\u00b7waschne", "Maus"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PRELS", "ADJD", "ADJA", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.26": {"text": "Ging in ihr Loch", "tokens": ["Ging", "in", "ihr", "Loch"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN"], "meter": "++-+", "measure": "iambic.di"}, "line.27": {"text": "Und sucht' sich eine M\u00e4usin aus", "tokens": ["Und", "sucht'", "sich", "ei\u00b7ne", "M\u00e4u\u00b7sin", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und hat sie noch.", "tokens": ["Und", "hat", "sie", "noch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "La\u00dft ihn nur, den Brausewind!", "tokens": ["La\u00dft", "ihn", "nur", ",", "den", "Brau\u00b7se\u00b7wind", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er wird werden, was wir sind.", "tokens": ["Er", "wird", "wer\u00b7den", ",", "was", "wir", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VAINF", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Kein Herr Student", "tokens": ["Kein", "Herr", "Stu\u00b7dent"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Thut's minder als auf Pr\u00e4sident,", "tokens": ["Thut's", "min\u00b7der", "als", "auf", "Pr\u00e4\u00b7si\u00b7dent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf Leibarzt oder Suprint'dent;", "tokens": ["Auf", "Leib\u00b7arzt", "o\u00b7der", "Su\u00b7print'\u00b7dent", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Zuletzt wird er wo K\u00fcster", "tokens": ["Zu\u00b7letzt", "wird", "er", "wo", "K\u00fcs\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PWAV", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Oder Philister.", "tokens": ["O\u00b7der", "Phi\u00b7lis\u00b7ter", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}}}}