{"textgrid.poem.57008": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Die Probe", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu einem seltsamen Versuch", "tokens": ["Zu", "ei\u00b7nem", "selt\u00b7sa\u00b7men", "Ver\u00b7such"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "erstand ich mir ein Nadelbuch.", "tokens": ["er\u00b7stand", "ich", "mir", "ein", "Na\u00b7del\u00b7buch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und zu dem Buch ein altes zwar,", "tokens": ["Und", "zu", "dem", "Buch", "ein", "al\u00b7tes", "zwar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "doch \u00e4u\u00dferst k\u00fchnes Dromedar.", "tokens": ["doch", "\u00e4u\u00b7\u00dferst", "k\u00fch\u00b7nes", "Dro\u00b7me\u00b7dar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein Reicher auch daneben stand,", "tokens": ["Ein", "Rei\u00b7cher", "auch", "da\u00b7ne\u00b7ben", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PAV", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "zween S\u00e4cke Gold in jeder Hand.", "tokens": ["zween", "S\u00e4\u00b7cke", "Gold", "in", "je\u00b7der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Reiche ging alsdann herf\u00fcr", "tokens": ["Der", "Rei\u00b7che", "ging", "als\u00b7dann", "her\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und klopfte an die Himmelst\u00fcr.", "tokens": ["und", "klopf\u00b7te", "an", "die", "Him\u00b7mel\u00b7st\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Drauf Petrus sprach: \u00bbGeschrieben steht,", "tokens": ["Drauf", "Pet\u00b7rus", "sprach", ":", "\u00bb", "Ge\u00b7schrie\u00b7ben", "steht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PAV", "FM", "VVFIN", "$.", "$(", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ein Kamel weit eher geht", "tokens": ["da\u00df", "ein", "Ka\u00b7mel", "weit", "e\u00b7her", "geht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJD", "ADV", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "durchs Nadel\u00f6hr, als Du, du Heid,", "tokens": ["durchs", "Na\u00b7de\u00b7l\u00f6hr", ",", "als", "Du", ",", "du", "Heid", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "durch diese T\u00fcre gro\u00df und breit!\u00ab", "tokens": ["durch", "die\u00b7se", "T\u00fc\u00b7re", "gro\u00df", "und", "breit", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich, glaubend fest an Gottes Wort,", "tokens": ["Ich", ",", "glau\u00b7bend", "fest", "an", "Got\u00b7tes", "Wort", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "ADJD", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ermunterte das Tier sofort,", "tokens": ["er\u00b7mun\u00b7ter\u00b7te", "das", "Tier", "so\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "ihm zeigend hinterm Nadel\u00f6hr", "tokens": ["ihm", "zei\u00b7gend", "hin\u00b7term", "Na\u00b7de\u00b7l\u00f6hr"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ein Zuckerh\u00f6rnchen als Douceur.", "tokens": ["ein", "Zu\u00b7cker\u00b7h\u00f6rn\u00b7chen", "als", "Dou\u00b7ce\u00b7ur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Und in der Tat! Das Vieh ging durch,", "tokens": ["Und", "in", "der", "Tat", "!", "Das", "Vieh", "ging", "durch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "obzwar sich quetschend wie ein Lurch!", "tokens": ["ob\u00b7zwar", "sich", "quet\u00b7schend", "wie", "ein", "Lurch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Reiche aber sah ganz stier", "tokens": ["Der", "Rei\u00b7che", "a\u00b7ber", "sah", "ganz", "stier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "ADV", "VVFIN", "ADV", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und sagte nichts als \u00bbWehe mir!\u00ab", "tokens": ["und", "sag\u00b7te", "nichts", "als", "\u00bb", "We\u00b7he", "mir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PIS", "KOKOM", "$(", "NN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}