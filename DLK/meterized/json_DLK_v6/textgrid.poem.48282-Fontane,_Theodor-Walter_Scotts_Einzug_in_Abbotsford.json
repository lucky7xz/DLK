{"textgrid.poem.48282": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Walter Scotts Einzug in Abbotsford", "genre": "verse", "period": "N.A.", "pub_year": 1888, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sir Walter, er zieht von Edinburg her", "tokens": ["Sir", "Wal\u00b7ter", ",", "er", "zieht", "von", "E\u00b7din\u00b7burg", "her"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "APPR", "NE", "APZR"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gen Abbotsford, das noch \u00f6d' und leer,", "tokens": ["Gen", "Ab\u00b7bots\u00b7ford", ",", "das", "noch", "\u00f6d'", "und", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PRELS", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Drum f\u00fchrt er mit sich, f\u00fcr Hof und Haus,", "tokens": ["Drum", "f\u00fchrt", "er", "mit", "sich", ",", "f\u00fcr", "Hof", "und", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "PRF", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was ein Schlo\u00dfherr braucht jahrein jahraus:", "tokens": ["Was", "ein", "Schlo\u00df\u00b7herr", "braucht", "ja\u00b7hrein", "ja\u00b7hraus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Kisten und Kasten, gro\u00df und klein,", "tokens": ["Kis\u00b7ten", "und", "Kas\u00b7ten", ",", "gro\u00df", "und", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Diener, Doggen und Papagein,", "tokens": ["Die\u00b7ner", ",", "Dog\u00b7gen", "und", "Pa\u00b7pa\u00b7gein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Und dazwischen ", "tokens": ["Und", "da\u00b7zwi\u00b7schen"], "token_info": ["word", "word"], "pos": ["KON", "PAV"], "meter": "--+-", "measure": "anapaest.init"}, "line.8": {"text": "Er altert\u00fcmernd erwarb, errang \u2013", "tokens": ["Er", "al\u00b7ter\u00b7t\u00fc\u00b7mernd", "er\u00b7warb", ",", "er\u00b7rang", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$,", "VVFIN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "F\u00fcr ein Museum \u00fcbergenug,", "tokens": ["F\u00fcr", "ein", "Mu\u00b7se\u00b7um", "\u00fc\u00b7ber\u00b7ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Ein Dreiundzwanzigwagenzug.", "tokens": ["Ein", "Drei\u00b7und\u00b7zwan\u00b7zig\u00b7wa\u00b7gen\u00b7zug", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Ist er an Bruce und Balliol:", "tokens": ["Ist", "er", "an", "Bru\u00b7ce", "und", "Bal\u00b7li\u00b7ol", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NE", "KON", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Ein Steinkreuz, ein Kamm, eine Totenurn',", "tokens": ["Ein", "Stein\u00b7kreuz", ",", "ein", "Kamm", ",", "ei\u00b7ne", "To\u00b7ten\u00b7urn'", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Alles vom Felde von Bannockburn,", "tokens": ["Al\u00b7les", "vom", "Fel\u00b7de", "von", "Ban\u00b7nock\u00b7burn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPRART", "NN", "APPR", "NE", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Auch ein Lehnschwert mit Runenschrift auf und ab,", "tokens": ["Auch", "ein", "Lehn\u00b7schwert", "mit", "Ru\u00b7nen\u00b7schrift", "auf", "und", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Das K\u00f6nig Robert dem Douglas gab.", "tokens": ["Das", "K\u00f6\u00b7nig", "Ro\u00b7bert", "dem", "Doug\u00b7las", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Auf dem ", "tokens": ["Auf", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Drin gefangen sa\u00df Richard Coeur de Lion,", "tokens": ["Drin", "ge\u00b7fan\u00b7gen", "sa\u00df", "Ric\u00b7hard", "Co\u00b7eur", "de", "Li\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "NE", "NE", "NE", "NE", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Eine Harfe von Blondel (neu zu beziehn),", "tokens": ["Ei\u00b7ne", "Har\u00b7fe", "von", "Blon\u00b7del", "(", "neu", "zu", "be\u00b7ziehn", ")", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$(", "ADJD", "PTKZU", "VVINF", "$(", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ein S\u00e4bel von Sultan Saladin,", "tokens": ["Ein", "S\u00e4\u00b7bel", "von", "Sul\u00b7tan", "Sa\u00b7la\u00b7din", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+--+---+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Eschenbogen und Tartsche von Robin Hood", "tokens": ["E\u00b7schen\u00b7bo\u00b7gen", "und", "Tart\u00b7sche", "von", "Ro\u00b7bin", "Hood"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "NE", "NE"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Und ein Stock Bruder Tucks aus dem Nottingham-Wood.", "tokens": ["Und", "ein", "Stock", "Bru\u00b7der", "Tucks", "aus", "dem", "Not\u00b7ting\u00b7ham\u00b7Wood", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "NN", "APPR", "ART", "NN", "$."], "meter": "--++-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Und auf dem ", "tokens": ["Und", "auf", "dem"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Das Zelt von Charles le T\u00e9m\u00e9raire,", "tokens": ["Das", "Zelt", "von", "Char\u00b7les", "le", "T\u00e9m\u00e9raire", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NE", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der Spie\u00df, der dem Herzog, eh' er's gedacht,", "tokens": ["Der", "Spie\u00df", ",", "der", "dem", "Her\u00b7zog", ",", "eh'", "er's", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NE", "$,", "KOUS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von Bauernhand den Tod gebracht;", "tokens": ["Von", "Bau\u00b7ern\u00b7hand", "den", "Tod", "ge\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Barbierzeug (Becken von goldener Bronze)", "tokens": ["Bar\u00b7bier\u00b7zeug", "(", "Be\u00b7cken", "von", "gol\u00b7de\u00b7ner", "Bron\u00b7ze", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "APPR", "ADJA", "NN", "$("], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.6": {"text": "\u2013 Prachtst\u00fcck aus den Tagen von Louis onze \u2013", "tokens": ["\u2013", "Pracht\u00b7st\u00fcck", "aus", "den", "Ta\u00b7gen", "von", "Lou\u00b7is", "on\u00b7ze", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "APPR", "ART", "NN", "APPR", "NE", "NE", "$("], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.7": {"text": "Zuletzt auch die Leiter, drauf, Strick in Hand,", "tokens": ["Zu\u00b7letzt", "auch", "die", "Lei\u00b7ter", ",", "drauf", ",", "Strick", "in", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,", "PAV", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Ehren-Tristan des Winks gew\u00e4rtig stand.", "tokens": ["Eh\u00b7ren\u00b7Tris\u00b7tan", "des", "Winks", "ge\u00b7w\u00e4r\u00b7tig", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Dann, bunt durcheinander, aus Heimat und Fremd',", "tokens": ["Dann", ",", "bunt", "durch\u00b7ein\u00b7an\u00b7der", ",", "aus", "Hei\u00b7mat", "und", "Fremd'", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJD", "PTKVZ", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Erzne Schienen und ein Kettenhemd,", "tokens": ["Erz\u00b7ne", "Schie\u00b7nen", "und", "ein", "Ket\u00b7ten\u00b7hemd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ein blutroter Mantel von Meister Hans,", "tokens": ["Ein", "blut\u00b7ro\u00b7ter", "Man\u00b7tel", "von", "Meis\u00b7ter", "Hans", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Ein Dragonersattel von Preston-Pans,", "tokens": ["Ein", "Dra\u00b7go\u00b7ner\u00b7sat\u00b7tel", "von", "Pre\u00b7ston\u00b7Pans", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,"], "meter": "+---+--+-+", "measure": "trochaic.tetra.relaxed"}, "line.5": {"text": "Spinnrad und Spule von K\u00f6nigin Maud,", "tokens": ["Spinn\u00b7rad", "und", "Spu\u00b7le", "von", "K\u00f6\u00b7ni\u00b7gin", "Maud", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "NE", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Inful und Krummstab von Erzbischof Laud,", "tokens": ["In\u00b7ful", "und", "Krumm\u00b7stab", "von", "Erz\u00b7bi\u00b7schof", "Laud", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NN", "NE", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Zwei Bildnisse, Kreid' und in Pastell,", "tokens": ["Zwei", "Bild\u00b7nis\u00b7se", ",", "Kreid'", "und", "in", "Pas\u00b7tell", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Von der wei\u00dfen Dame von Avenell,", "tokens": ["Von", "der", "wei\u00b7\u00dfen", "Da\u00b7me", "von", "A\u00b7ve\u00b7nell", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NE", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "Eine Spitzenkrause, die Darnley trug,", "tokens": ["Ei\u00b7ne", "Spit\u00b7zen\u00b7krau\u00b7se", ",", "die", "Darn\u00b7ley", "trug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PAV", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Eine dito von Bothwell, der Darnley erschlug,", "tokens": ["Ei\u00b7ne", "di\u00b7to", "von", "Both\u00b7well", ",", "der", "Darn\u00b7ley", "er\u00b7schlug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NE", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--++-+", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Eine Schildpattwiege, drin ", "tokens": ["Ei\u00b7ne", "Schild\u00b7patt\u00b7wie\u00b7ge", ",", "drin"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.12": {"text": "(als man sie taufte) Queen Mary lag,", "tokens": ["(", "als", "man", "sie", "tauf\u00b7te", ")", "Que\u00b7en", "Ma\u00b7ry", "lag", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "PPER", "VVFIN", "$(", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ihr Hinrichtungsblock aus Fotheringhay,", "tokens": ["Ihr", "Hin\u00b7rich\u00b7tungs\u00b7block", "aus", "Fo\u00b7the\u00b7ring\u00b7hay", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gebetbuch der Johanna Gray,", "tokens": ["Ge\u00b7bet\u00b7buch", "der", "Jo\u00b7han\u00b7na", "Gray", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kanzel und Sanduhr von John Knox,", "tokens": ["Kan\u00b7zel", "und", "San\u00b7duhr", "von", "John", "Knox", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Eine Riesenper\u00fccke des \u00e4lteren Fox,", "tokens": ["Ei\u00b7ne", "Rie\u00b7sen\u00b7pe\u00b7r\u00fc\u00b7cke", "des", "\u00e4l\u00b7te\u00b7ren", "Fox", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Eine Cromwell-Pistole mit Kugel im Lauf,", "tokens": ["Ei\u00b7ne", "Crom\u00b7well\u00b7Pis\u00b7to\u00b7le", "mit", "Ku\u00b7gel", "im", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+---+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Von Floddenfield ein verrosteter Knauf,", "tokens": ["Von", "Flod\u00b7den\u00b7field", "ein", "ver\u00b7ros\u00b7te\u00b7ter", "Knauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Auf t\u00fcrmt sich's (und mehr noch) Zoll um Zoll,", "tokens": ["Auf", "t\u00fcrmt", "sich's", "(", "und", "mehr", "noch", ")", "Zoll", "um", "Zoll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "$(", "KON", "ADV", "ADV", "$(", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dreiundzwanzig Wagen voll.", "tokens": ["Drei\u00b7und\u00b7zwan\u00b7zig", "Wa\u00b7gen", "voll", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und auf dem letzten, sonnumblitzt,", "tokens": ["Und", "auf", "dem", "letz\u00b7ten", ",", "son\u00b7num\u00b7blitzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sir Walter selber, ein Gl\u00fccklicher, sitzt,", "tokens": ["Sir", "Wal\u00b7ter", "sel\u00b7ber", ",", "ein", "Gl\u00fcck\u00b7li\u00b7cher", ",", "sitzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "NE", "ADV", "$,", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er l\u00e4chelt und tr\u00e4umt und f\u00fchrt im Geist", "tokens": ["Er", "l\u00e4\u00b7chelt", "und", "tr\u00e4umt", "und", "f\u00fchrt", "im", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Den Stab schon, der allem die Stelle weist.", "tokens": ["Den", "Stab", "schon", ",", "der", "al\u00b7lem", "die", "Stel\u00b7le", "weist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Eine Stelle find't jedes irgendwo,", "tokens": ["Ei\u00b7ne", "Stel\u00b7le", "find't", "je\u00b7des", "ir\u00b7gend\u00b7wo", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "ADV", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Sei's in Quentin Durward, in Ivanho,", "tokens": ["Sei's", "in", "Quen\u00b7tin", "Dur\u00b7ward", ",", "in", "I\u00b7van\u00b7ho", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "NE", "$,", "APPR", "NE", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "Eine Stelle find't jedes, fr\u00fch oder spat,", "tokens": ["Ei\u00b7ne", "Stel\u00b7le", "find't", "je\u00b7des", ",", "fr\u00fch", "o\u00b7der", "spat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "In Abt oder Kloster oder Pirat,", "tokens": ["In", "Abt", "o\u00b7der", "Klos\u00b7ter", "o\u00b7der", "Pi\u00b7rat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Eine Stelle haben, finden sie,", "tokens": ["Ei\u00b7ne", "Stel\u00b7le", "ha\u00b7ben", ",", "fin\u00b7den", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Sei's in Woodstock oder in Waverlie.", "tokens": ["Sei's", "in", "Wood\u00b7stock", "o\u00b7der", "in", "Wa\u00b7ver\u00b7lie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Requisitenkammer, Schatzkammer noch mehr,", "tokens": ["Re\u00b7qui\u00b7si\u00b7ten\u00b7kam\u00b7mer", ",", "Schatz\u00b7kam\u00b7mer", "noch", "mehr", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "ADV", "ADV", "$,"], "meter": "+---+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "So kommt der Zug von Edinburg her.", "tokens": ["So", "kommt", "der", "Zug", "von", "E\u00b7din\u00b7burg", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dreiundzwanzig Wagen. Nun ladet ab", "tokens": ["Drei\u00b7und\u00b7zwan\u00b7zig", "Wa\u00b7gen", ".", "Nun", "la\u00b7det", "ab"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["CARD", "NN", "$.", "ADV", "VVFIN", "PTKVZ"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Und, Sir Walter, schwinge den Zauberstab!", "tokens": ["Und", ",", "Sir", "Wal\u00b7ter", ",", "schwin\u00b7ge", "den", "Zau\u00b7ber\u00b7stab", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "NE", "$,", "VVFIN", "ART", "NN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}