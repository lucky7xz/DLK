{"textgrid.poem.47333": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "Loblied auf den Wesir", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "M\u00f6nch! die Predigt schenk' ich dir,", "tokens": ["M\u00f6nch", "!", "die", "Pre\u00b7digt", "schenk'", "ich", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die mir nicht kann taugen;", "tokens": ["Die", "mir", "nicht", "kann", "tau\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Denn es winkt ein Becher mir", "tokens": ["Denn", "es", "winkt", "ein", "Be\u00b7cher", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zwei sch\u00f6ne Augen.", "tokens": ["Und", "zwei", "sch\u00f6\u00b7ne", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Niemals hat mir Doppelrausch", "tokens": ["Nie\u00b7mals", "hat", "mir", "Dop\u00b7pel\u00b7rausch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tadelswert geschienen.", "tokens": ["Ta\u00b7dels\u00b7wert", "ge\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ist es nicht ein edler Tausch,", "tokens": ["Ist", "es", "nicht", "ein", "ed\u00b7ler", "Tausch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Lipp- und Wein-Rubinen?", "tokens": ["Lipp", "und", "Wein\u00b7Ru\u00b7bi\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Gott sei Dank, die Polizei", "tokens": ["Gott", "sei", "Dank", ",", "die", "Po\u00b7li\u00b7zei"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VAFIN", "NN", "$,", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist heut nachts gestorben.", "tokens": ["Ist", "heut", "nachts", "ge\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Um die Stell' hat frank und frei", "tokens": ["Um", "die", "Stell'", "hat", "frank", "und", "frei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich der Rausch beworben.", "tokens": ["Sich", "der", "Rausch", "be\u00b7wor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Sitz' in Schenken mit Verstand,", "tokens": ["Sitz'", "in", "Schen\u00b7ken", "mit", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sei nicht stumm beim Weine,", "tokens": ["Sei", "nicht", "stumm", "beim", "Wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Nimm ein Liederbuch zur Hand,", "tokens": ["Nimm", "ein", "Lie\u00b7der\u00b7buch", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn du willst, das meine.", "tokens": ["Wenn", "du", "willst", ",", "das", "mei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "$,", "PRELS", "PPOSAT", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Wer nach leichten Melodien", "tokens": ["Wer", "nach", "leich\u00b7ten", "Me\u00b7lo\u00b7dien"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Singet meine T\u00f6ne,", "tokens": ["Sin\u00b7get", "mei\u00b7ne", "T\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wird die Sorge sehn entfliehn", "tokens": ["Wird", "die", "Sor\u00b7ge", "sehn", "ent\u00b7fliehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "VVINF", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sich nahn die Sch\u00f6ne.", "tokens": ["Und", "sich", "nahn", "die", "Sch\u00f6\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Liebchen! gib mir nur den Duft", "tokens": ["Lieb\u00b7chen", "!", "gib", "mir", "nur", "den", "Duft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VVIMP", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Von des Bechers Schaume,", "tokens": ["Von", "des", "Be\u00b7chers", "Schau\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich n\u00e4hre bis zur Gruft", "tokens": ["Und", "ich", "n\u00e4h\u00b7re", "bis", "zur", "Gruft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mich mit Wonnetraume.", "tokens": ["Mich", "mit", "Won\u00b7ne\u00b7trau\u00b7me", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Lilien und Rosen sind", "tokens": ["Li\u00b7li\u00b7en", "und", "Ro\u00b7sen", "sind"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00f6n durch deine Blicke.", "tokens": ["Sch\u00f6n", "durch", "dei\u00b7ne", "Bli\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "W\u00fcrze du den Fr\u00fchlingswind,", "tokens": ["W\u00fcr\u00b7ze", "du", "den", "Fr\u00fch\u00b7lings\u00b7wind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sein Hauch erquickte.", "tokens": ["Da\u00df", "sein", "Hauch", "er\u00b7quick\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Wenn du einem Mann wie mir", "tokens": ["Wenn", "du", "ei\u00b7nem", "Mann", "wie", "mir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "KOKOM", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ursach' gibst zu klagen,", "tokens": ["Ur\u00b7sach'", "gibst", "zu", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Werd' ich dich bei dem Wesir", "tokens": ["Werd'", "ich", "dich", "bei", "dem", "We\u00b7sir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Unsrer Zeit verklagen. \u2013", "tokens": ["Uns\u00b7rer", "Zeit", "ver\u00b7kla\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Er, der Wesir, der Strebepfeiler", "tokens": ["Er", ",", "der", "We\u00b7sir", ",", "der", "Stre\u00b7be\u00b7pfei\u00b7ler"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Des Reichs der Welt,", "tokens": ["Des", "Reichs", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ihn preist als Gnadenrechtserteiler", "tokens": ["Ihn", "preist", "als", "Gna\u00b7den\u00b7rech\u00b7tser\u00b7tei\u00b7ler"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Blum' im Feld.", "tokens": ["Die", "Blum'", "im", "Feld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Saatfelder segnete durch seine", "tokens": ["Saat\u00b7fel\u00b7der", "seg\u00b7ne\u00b7te", "durch", "sei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Verwaltung Er.", "tokens": ["Ver\u00b7wal\u00b7tung", "Er", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Im Schachte reifen Edelsteine,", "tokens": ["Im", "Schach\u00b7te", "rei\u00b7fen", "E\u00b7del\u00b7stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Perlen im Meer.", "tokens": ["Per\u00b7len", "im", "Meer", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.11": {"line.1": {"text": "Sein leichter Wink bringt in Bewegung", "tokens": ["Sein", "leich\u00b7ter", "Wink", "bringt", "in", "Be\u00b7we\u00b7gung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der R\u00e4der Schwung,", "tokens": ["Der", "R\u00e4\u00b7der", "Schwung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und der bewegten Herzen Regung", "tokens": ["Und", "der", "be\u00b7weg\u00b7ten", "Her\u00b7zen", "Re\u00b7gung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist Huldigung.", "tokens": ["Ist", "Hul\u00b7di\u00b7gung", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Der Himmel geht in stetem Kreise,", "tokens": ["Der", "Him\u00b7mel", "geht", "in", "ste\u00b7tem", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Mond und Jahr", "tokens": ["Und", "Mond", "und", "Jahr"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und Herbst und Fr\u00fchling wechseln leise,", "tokens": ["Und", "Herbst", "und", "Fr\u00fch\u00b7ling", "wech\u00b7seln", "lei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unwandelbar.", "tokens": ["Un\u00b7wan\u00b7del\u00b7bar", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.13": {"line.1": {"text": "Bis zu dem Tage des Gerichtes,", "tokens": ["Bis", "zu", "dem", "Ta\u00b7ge", "des", "Ge\u00b7rich\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wo Gott dir lohnt,", "tokens": ["Wo", "Gott", "dir", "lohnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Sei hell vom Glanze deines Lichtes", "tokens": ["Sei", "hell", "vom", "Glan\u00b7ze", "dei\u00b7nes", "Lich\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Haus bewohnt.", "tokens": ["Dein", "Haus", "be\u00b7wohnt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "Dein Haus, der Weisen und der Dichter", "tokens": ["Dein", "Haus", ",", "der", "Wei\u00b7sen", "und", "der", "Dich\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erdparadies,", "tokens": ["Erd\u00b7pa\u00b7ra\u00b7dies", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+---", "measure": "dactylic.init"}, "line.3": {"text": "Dazwischen Schenkenangesichter,", "tokens": ["Da\u00b7zwi\u00b7schen", "Schen\u00b7ken\u00b7an\u00b7ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "punct"], "pos": ["PAV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sch\u00f6n wie Huris.", "tokens": ["Sch\u00f6n", "wie", "Hu\u00b7ris", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NE", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.15": {"line.1": {"text": "Hafis, der mit dem Glanz von Eden", "tokens": ["Ha\u00b7fis", ",", "der", "mit", "dem", "Glanz", "von", "E\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Lob verbr\u00e4mt,", "tokens": ["Dein", "Lob", "ver\u00b7br\u00e4mt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Thu'st du die Lippen auf zu reden,", "tokens": ["Thu'st", "du", "die", "Lip\u00b7pen", "auf", "zu", "re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schweigt er besch\u00e4mt.", "tokens": ["Schweigt", "er", "be\u00b7sch\u00e4mt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}}}}