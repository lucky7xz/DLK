{"textgrid.poem.53383": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wer wissen wil was ein Soldat,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer wissen wil was ein Soldat,", "tokens": ["Wer", "wis\u00b7sen", "wil", "was", "ein", "Sol\u00b7dat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "VMFIN", "PIS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der zwar ein Hertz zu fechten hat,", "tokens": ["Der", "zwar", "ein", "Hertz", "zu", "fech\u00b7ten", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht aber viel von Gl\u00fcck sol sagen,", "tokens": ["Nicht", "a\u00b7ber", "viel", "von", "Gl\u00fcck", "sol", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "APPR", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr Noht und Elend m\u00fcss' ertragen,", "tokens": ["F\u00fcr", "Noht", "und", "E\u00b7lend", "m\u00fcss'", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und wie der Herr zu seiner Zeit", "tokens": ["Und", "wie", "der", "Herr", "zu", "sei\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Seinen au\u00df der Dienstbarkeit", "tokens": ["Die", "Sei\u00b7nen", "au\u00df", "der", "Dienst\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd au\u00df der schweren Arbeits-Ketten", "tokens": ["Vnd", "au\u00df", "der", "schwe\u00b7ren", "Ar\u00b7beits\u00b7Ket\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Freuden wisse zu erretten,", "tokens": ["Mit", "Freu\u00b7den", "wis\u00b7se", "zu", "er\u00b7ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der sehe Hans von Kalckstein an,", "tokens": ["Der", "se\u00b7he", "Hans", "von", "Kalck\u00b7stein", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er wird in diesem werthen Mann", "tokens": ["Er", "wird", "in", "die\u00b7sem", "wert\u00b7hen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tapfferkeit sammt Noht und Grauen", "tokens": ["Die", "Tapf\u00b7fer\u00b7keit", "sammt", "Noht", "und", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gleich wie in einem Spiegel schauen.", "tokens": ["Gleich", "wie", "in", "ei\u00b7nem", "Spie\u00b7gel", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Du Weichling, welcher f\u00fcr den Feind", "tokens": ["Du", "Weich\u00b7ling", ",", "wel\u00b7cher", "f\u00fcr", "den", "Feind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Allein die reiche Beute meint,", "tokens": ["Al\u00b7lein", "die", "rei\u00b7che", "Beu\u00b7te", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und seine Mannheit darthut nimmer,", "tokens": ["Und", "sei\u00b7ne", "Mann\u00b7heit", "dar\u00b7thut", "nim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ohn wann er k\u00f6mt zum Frauenzimmer.", "tokens": ["Ohn", "wann", "er", "k\u00f6mt", "zum", "Frau\u00b7en\u00b7zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAV", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Geh, troll dich nur von hinnen weit;", "tokens": ["Geh", ",", "troll", "dich", "nur", "von", "hin\u00b7nen", "weit", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "PPER", "ADV", "APPR", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr, die jhr liebt Gefahr und Streit,", "tokens": ["Ihr", ",", "die", "jhr", "liebt", "Ge\u00b7fahr", "und", "Streit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd reicht dem Feind hin euer Leder,", "tokens": ["Vnd", "reicht", "dem", "Feind", "hin", "eu\u00b7er", "Le\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt, sch\u00e4rfft mir beydes Geist und Feder.", "tokens": ["Kommt", ",", "sch\u00e4rfft", "mir", "bey\u00b7des", "Geist", "und", "Fe\u00b7der", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich f\u00fchle nicht gemeinen Brand,", "tokens": ["Ich", "f\u00fch\u00b7le", "nicht", "ge\u00b7mei\u00b7nen", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wil durch eine weise Hand", "tokens": ["Vnd", "wil", "durch", "ei\u00b7ne", "wei\u00b7se", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Nachwelt zu erkennen geben", "tokens": ["Der", "Nach\u00b7welt", "zu", "er\u00b7ken\u00b7nen", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "De\u00df werthen Mannes Gl\u00fcck und Leben.", "tokens": ["De\u00df", "wert\u00b7hen", "Man\u00b7nes", "Gl\u00fcck", "und", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Er war von vierzehn Jahren kaum,", "tokens": ["Er", "war", "von", "vier\u00b7zehn", "Jah\u00b7ren", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "CARD", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als er sich mit dem weiten Raum", "tokens": ["Als", "er", "sich", "mit", "dem", "wei\u00b7ten", "Raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Der Arbeit au\u00dfzog einzulassen,", "tokens": ["Der", "Ar\u00b7beit", "au\u00df\u00b7zog", "ein\u00b7zu\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd, was zur Tugend f\u00fchrt, zu fassen.", "tokens": ["Vnd", ",", "was", "zur", "Tu\u00b7gend", "f\u00fchrt", ",", "zu", "fas\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Sein treues Hertz und reiner Mund", "tokens": ["Sein", "treu\u00b7es", "Hertz", "und", "rei\u00b7ner", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward Joachim von Lo\u00df erst kund,", "tokens": ["Ward", "Joa\u00b7ch\u00b7im", "von", "Lo\u00df", "erst", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "APPR", "NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da ist er bey dem grossen Sachsen", "tokens": ["Da", "ist", "er", "bey", "dem", "gros\u00b7sen", "Sach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zwey Jahr an Leib und Witz gewachsen.", "tokens": ["Zwey", "Jahr", "an", "Leib", "und", "Witz", "ge\u00b7wach\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Da er von dannen weiter kam,", "tokens": ["Da", "er", "von", "dan\u00b7nen", "wei\u00b7ter", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd Jochim Schulenburg jhn nahm,", "tokens": ["Vnd", "Jo\u00b7chim", "Schu\u00b7len\u00b7burg", "jhn", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der auff Liebrose war gesessen,", "tokens": ["Der", "auff", "Lie\u00b7bro\u00b7se", "war", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df seiner Trew noch nicht vergessen.", "tokens": ["Da\u00df", "sei\u00b7ner", "Trew", "noch", "nicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nach diesem macht er sich zur\u00fcck,", "tokens": ["Nach", "die\u00b7sem", "macht", "er", "sich", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00f6ret hie von schlechtem Gl\u00fcck,", "tokens": ["Und", "h\u00f6\u00b7ret", "hie", "von", "schlech\u00b7tem", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dann jhm der Vater, sein Verlangen,", "tokens": ["Dann", "jhm", "der", "Va\u00b7ter", ",", "sein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Schon durch den Tod war au\u00dfgegangen.", "tokens": ["Schon", "durch", "den", "Tod", "war", "au\u00df\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Was solt' er thun? Sein Alter war", "tokens": ["Was", "solt'", "er", "thun", "?", "Sein", "Al\u00b7ter", "war"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da eben acht und zehen Jahr.", "tokens": ["Da", "e\u00b7ben", "acht", "und", "ze\u00b7hen", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "CARD", "KON", "CARD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In dem er anders nichts kan schaffen,", "tokens": ["In", "dem", "er", "an\u00b7ders", "nichts", "kan", "schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PIS", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gewinnt er Liebe zu den Waffen.", "tokens": ["Ge\u00b7winnt", "er", "Lie\u00b7be", "zu", "den", "Waf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "O k\u00f6nt' ein Mensch von ferne sehn", "tokens": ["O", "k\u00f6nt'", "ein", "Mensch", "von", "fer\u00b7ne", "sehn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "ART", "NN", "APPR", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was k\u00fcnfftig sol mit jhm geschehn,", "tokens": ["Was", "k\u00fcnff\u00b7tig", "sol", "mit", "jhm", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VMFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er w\u00fcrde manches Vngl\u00fcck meiden,", "tokens": ["Er", "w\u00fcr\u00b7de", "man\u00b7ches", "Vn\u00b7gl\u00fcck", "mei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nein, hierau\u00df quillt das meiste Leiden.", "tokens": ["Nein", ",", "hier\u00b7au\u00df", "quillt", "das", "meis\u00b7te", "Lei\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Di\u00df was wir haben in der Hand,", "tokens": ["Di\u00df", "was", "wir", "ha\u00b7ben", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist offtmals uns nicht recht bekand,", "tokens": ["Ist", "offt\u00b7mals", "uns", "nicht", "recht", "be\u00b7kand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPER", "PTKNEG", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df wir es w\u00fcsten aller Enden", "tokens": ["Da\u00df", "wir", "es", "w\u00fcs\u00b7ten", "al\u00b7ler", "En\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zu unserm Vortheil anzuwenden.", "tokens": ["Zu", "un\u00b7serm", "Vor\u00b7theil", "an\u00b7zu\u00b7wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ist die Gelegenheit vorbey,", "tokens": ["Ist", "die", "Ge\u00b7le\u00b7gen\u00b7heit", "vor\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Vnd nicht gebraucht, ereugt sich Rew", "tokens": ["Vnd", "nicht", "ge\u00b7braucht", ",", "e\u00b7reugt", "sich", "Rew"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PTKNEG", "VVPP", "$,", "VVFIN", "PRF", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verlust und Gram, und was von Plagen", "tokens": ["Ver\u00b7lust", "und", "Gram", ",", "und", "was", "von", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "KON", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Epimetheus mu\u00df ertragen.", "tokens": ["Ein", "E\u00b7pi\u00b7me\u00b7theus", "mu\u00df", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}}, "stanza.15": {"line.1": {"text": "Geschweige da\u00df der Zukunfft Stand", "tokens": ["Ge\u00b7schwei\u00b7ge", "da\u00df", "der", "Zu\u00b7kunfft", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zuvor uns solte seyn bekand.", "tokens": ["Zu\u00b7vor", "uns", "sol\u00b7te", "seyn", "be\u00b7kand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "VAINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Di\u00df hat auch dieser Mann empfunden", "tokens": ["Di\u00df", "hat", "auch", "die\u00b7ser", "Mann", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "PDAT", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch manche Leibs- und Hertzens-Wunden.", "tokens": ["Durch", "man\u00b7che", "Leibs", "und", "Hert\u00b7zens\u00b7Wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "TRUNC", "KON", "NN", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}}, "stanza.16": {"line.1": {"text": "Er geht in Lieffland, und verspricht", "tokens": ["Er", "geht", "in", "Lief\u00b7fland", ",", "und", "ver\u00b7spricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil dazumal die Moscowitten", "tokens": ["Weil", "da\u00b7zu\u00b7mal", "die", "Mo\u00b7sco\u00b7wit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit jhm Smolensko wegen stritten.", "tokens": ["Mit", "jhm", "Smo\u00b7lens\u00b7ko", "we\u00b7gen", "strit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NE", "APPR", "VVFIN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Da sahe gantz Littauen jhn,", "tokens": ["Da", "sa\u00b7he", "gantz", "Lit\u00b7tau\u00b7en", "jhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df jhn die Wild hie\u00df weiter ziehn,", "tokens": ["Bi\u00df", "jhn", "die", "Wild", "hie\u00df", "wei\u00b7ter", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NE", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd jhn die Nieper auffgenommen,", "tokens": ["Vnd", "jhn", "die", "Nie\u00b7per", "auff\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wohin das gantze Heer war kommen.", "tokens": ["Wo\u00b7hin", "das", "gant\u00b7ze", "Heer", "war", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Hie sah' er seiner Mannheit Feld,", "tokens": ["Hie", "sah'", "er", "sei\u00b7ner", "Mann\u00b7heit", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie offt verlie\u00df er das Gezelt,", "tokens": ["Wie", "offt", "ver\u00b7lie\u00df", "er", "das", "Ge\u00b7zelt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat jetzt insonders, jetzt mit Hauffen", "tokens": ["Hat", "jetzt", "in\u00b7son\u00b7ders", ",", "jetzt", "mit", "Hauf\u00b7fen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "$,", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Feind ein Vortheil abgelauffen.", "tokens": ["Dem", "Feind", "ein", "Vor\u00b7theil", "ab\u00b7ge\u00b7lauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Sie suchten in Smolensko Brod", "tokens": ["Sie", "such\u00b7ten", "in", "Smo\u00b7lens\u00b7ko", "Brod"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Zu bringen f\u00fcr der Hungersnoht,", "tokens": ["Zu", "brin\u00b7gen", "f\u00fcr", "der", "Hun\u00b7gers\u00b7noht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Di\u00df hat der Moscowit gerochen,", "tokens": ["Di\u00df", "hat", "der", "Mo\u00b7sco\u00b7wit", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd in dem Walde sich verkrochen.", "tokens": ["Vnd", "in", "dem", "Wal\u00b7de", "sich", "ver\u00b7kro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Vnd als er es verhindern wil", "tokens": ["Vnd", "als", "er", "es", "ver\u00b7hin\u00b7dern", "wil"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entsteht ein sch\u00f6nes Waffenspiel,", "tokens": ["Ent\u00b7steht", "ein", "sch\u00f6\u00b7nes", "Waf\u00b7fen\u00b7spiel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es wird gefochten manche Stunden,", "tokens": ["Es", "wird", "ge\u00b7foch\u00b7ten", "man\u00b7che", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bi\u00df da\u00df der Feind ward \u00fcberwunden.", "tokens": ["Bi\u00df", "da\u00df", "der", "Feind", "ward", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Da ward de\u00df Kalcksteins tapffere Hand", "tokens": ["Da", "ward", "de\u00df", "Kalck\u00b7steins", "tapf\u00b7fe\u00b7re", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "F\u00fcr vielen andern gnug erkant,", "tokens": ["F\u00fcr", "vie\u00b7len", "an\u00b7dern", "gnug", "er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er w\u00fctet umb sich hin und wieder,", "tokens": ["Er", "w\u00fc\u00b7tet", "umb", "sich", "hin", "und", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "PTKVZ", "KON", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd legte manchen Mann danieder.", "tokens": ["Vnd", "leg\u00b7te", "man\u00b7chen", "Mann", "da\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Bleibt so der Sieg nun jmmer sein?", "tokens": ["Bleibt", "so", "der", "Sieg", "nun", "jm\u00b7mer", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd f\u00fchrt das Gl\u00fcck jhn nur hinein,", "tokens": ["Vnd", "f\u00fchrt", "das", "Gl\u00fcck", "jhn", "nur", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wil sich wieder von jhm drehen,", "tokens": ["Vnd", "wil", "sich", "wie\u00b7der", "von", "jhm", "dre\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Eh er sich dessen wird versehen?", "tokens": ["Eh", "er", "sich", "des\u00b7sen", "wird", "ver\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PDS", "VAFIN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.23": {"line.1": {"text": "Nicht anders, als die Rede singt,", "tokens": ["Nicht", "an\u00b7ders", ",", "als", "die", "Re\u00b7de", "singt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man dem Feinde Vorraht bringt,", "tokens": ["Da\u00df", "man", "dem", "Fein\u00b7de", "Vor\u00b7raht", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schickt Chotgewitz au\u00df Deutsch' und Polen,", "tokens": ["Schickt", "Chot\u00b7ge\u00b7witz", "au\u00df", "Deut\u00b7sch'", "und", "Po\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "NE", "KON", "NE", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "De\u00dfwegen Kundschafft einzuholen.", "tokens": ["De\u00df\u00b7we\u00b7gen", "Kund\u00b7schafft", "ein\u00b7zu\u00b7ho\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Den Deutschen wohnt' auch Kalckstein bey,", "tokens": ["Den", "Deut\u00b7schen", "wohnt'", "auch", "Kalck\u00b7stein", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vorraht war ein blo\u00df Geschrey,", "tokens": ["Der", "Vor\u00b7raht", "war", "ein", "blo\u00df", "Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als solches Thomascheffsky sp\u00fcrte,", "tokens": ["Als", "sol\u00b7ches", "Tho\u00b7ma\u00b7scheffs\u00b7ky", "sp\u00fcr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der die zween Hauffen Pohlen f\u00fchrte,", "tokens": ["Der", "die", "zween", "Hauf\u00b7fen", "Poh\u00b7len", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "VVFIN", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Wil er Gefangne bringen ein,", "tokens": ["Wil", "er", "Ge\u00b7fang\u00b7ne", "brin\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die dessen Zeugen sollen seyn,", "tokens": ["Die", "des\u00b7sen", "Zeu\u00b7gen", "sol\u00b7len", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRELAT", "NN", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd nimmt (o Vorwitz hoch zu schelten!)", "tokens": ["Vnd", "nimmt", "(", "o", "Vor\u00b7witz", "hoch", "zu", "schel\u00b7ten", "!", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$(", "FM", "NN", "ADJD", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Schiltwach von den Haupt-Gezelten.", "tokens": ["Die", "Schilt\u00b7wach", "von", "den", "Haup\u00b7tGe\u00b7zel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Da kriegt die K\u00fchnheit jhren Lohn", "tokens": ["Da", "kriegt", "die", "K\u00fchn\u00b7heit", "jhren", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Nicht eine halbe Meil davon,", "tokens": ["Nicht", "ei\u00b7ne", "hal\u00b7be", "Meil", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie werden alle rings umbgeben,", "tokens": ["Sie", "wer\u00b7den", "al\u00b7le", "rings", "umb\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er k\u00f6mmt sammt vielen umb sein Leben.", "tokens": ["Er", "k\u00f6mmt", "sammt", "vie\u00b7len", "umb", "sein", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Herr Kalckstein k\u00e4mpffet ritterlich,", "tokens": ["Herr", "Kalck\u00b7stein", "k\u00e4mpf\u00b7fet", "rit\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wehrt gleich einem L\u00f6wen sich,", "tokens": ["Vnd", "wehrt", "gleich", "ei\u00b7nem", "L\u00f6\u00b7wen", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat manchen Streich sammt einer Wunden", "tokens": ["Hat", "man\u00b7chen", "Streich", "sammt", "ei\u00b7ner", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Schu\u00df forn an dem Haupt empfunden.", "tokens": ["Vom", "Schu\u00df", "forn", "an", "dem", "Haupt", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Doch siegt des Feindes grosse Macht,", "tokens": ["Doch", "siegt", "des", "Fein\u00b7des", "gros\u00b7se", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er wird gefangen weggebracht,", "tokens": ["Er", "wird", "ge\u00b7fan\u00b7gen", "weg\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd mu\u00df zwey Jahr viel harte Plagen", "tokens": ["Vnd", "mu\u00df", "zwey", "Jahr", "viel", "har\u00b7te", "Pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "CARD", "NN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Thurn weit zu Stolitza tragen.", "tokens": ["Im", "Thurn", "weit", "zu", "Sto\u00b7lit\u00b7za", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.29": {"line.1": {"text": "Dir, Alexander Le\u00dfle, sey", "tokens": ["Dir", ",", "A\u00b7lex\u00b7an\u00b7der", "Le\u00df\u00b7le", ",", "sey"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "NE", "NE", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gott zugethan mit aller Trew,", "tokens": ["Gott", "zu\u00b7ge\u00b7than", "mit", "al\u00b7ler", "Trew", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dir und den Deutschen, die zu leben", "tokens": ["Dir", "und", "den", "Deut\u00b7schen", ",", "die", "zu", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "KON", "ART", "NN", "$,", "PRELS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihm heimlich Vnterhalt gegeben.", "tokens": ["Ihm", "heim\u00b7lich", "Vn\u00b7ter\u00b7halt", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Jedoch als Le\u00dfle wird befreyt,", "tokens": ["Je\u00b7doch", "als", "Le\u00df\u00b7le", "wird", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6mmt er noch mehr in Dienstbarkeit,", "tokens": ["K\u00f6mmt", "er", "noch", "mehr", "in", "Dienst\u00b7bar\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Abgesandter war zugegen", "tokens": ["Ein", "Ab\u00b7ge\u00b7sand\u00b7ter", "war", "zu\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und zwar der Crimmer-Tartarn wegen.", "tokens": ["Und", "zwar", "der", "Crim\u00b7mer\u00b7\u00b7Tar\u00b7tarn", "we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Der h\u00f6rt von der Gefangnen Noht,", "tokens": ["Der", "h\u00f6rt", "von", "der", "Ge\u00b7fang\u00b7nen", "Noht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Viel blieben Hungers wegen tod,", "tokens": ["Viel", "blie\u00b7ben", "Hun\u00b7gers", "we\u00b7gen", "tod", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel w\u00fcrden sonst ihr junges Leben", "tokens": ["Viel", "w\u00fcr\u00b7den", "sonst", "ihr", "jun\u00b7ges", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gezwungen kl\u00e4glich auffzugeben.", "tokens": ["Ge\u00b7zwun\u00b7gen", "kl\u00e4g\u00b7lich", "auff\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Vnd bittet ihrer funffzehn au\u00df,", "tokens": ["Vnd", "bit\u00b7tet", "ih\u00b7rer", "funff\u00b7zehn", "au\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "CARD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die f\u00fchrt er weg fern in sein Haus,", "tokens": ["Die", "f\u00fchrt", "er", "weg", "fern", "in", "sein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihn Kalckstein mit, der jhm nach gn\u00fcgen", "tokens": ["Ihn", "Kalck\u00b7stein", "mit", ",", "der", "jhm", "nach", "gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Soll seinen Acker knechtisch pfl\u00fcgen.", "tokens": ["Soll", "sei\u00b7nen", "A\u00b7cker", "knech\u00b7tisch", "pfl\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Wo nimt er hierzu Kr\u00e4ffte her?", "tokens": ["Wo", "nimt", "er", "hier\u00b7zu", "Kr\u00e4ff\u00b7te", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PAV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Leib ist von den Banden schwer,", "tokens": ["Sein", "Leib", "ist", "von", "den", "Ban\u00b7den", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Thurn hatt' jhm die Macht entzogen,", "tokens": ["Der", "Thurn", "hatt'", "jhm", "die", "Macht", "ent\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd alles Blut schier au\u00dfgesogen.", "tokens": ["Vnd", "al\u00b7les", "Blut", "schier", "au\u00df\u00b7ge\u00b7so\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Constantinopel f\u00e4llt jhm ein,", "tokens": ["Con\u00b7stan\u00b7ti\u00b7no\u00b7pel", "f\u00e4llt", "jhm", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da w\u00fcnschet er verkaufft zu seyn,", "tokens": ["Da", "w\u00fcn\u00b7schet", "er", "ver\u00b7kaufft", "zu", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Au\u00df Hoffnung der, so ist gefangen,", "tokens": ["Au\u00df", "Hoff\u00b7nung", "der", ",", "so", "ist", "ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "$,", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "K\u00f6nn' eh zur Freyheit da gelangen.", "tokens": ["K\u00f6nn'", "eh", "zur", "Frey\u00b7heit", "da", "ge\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KOUS", "APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Er bringet seine Bitte vor,", "tokens": ["Er", "brin\u00b7get", "sei\u00b7ne", "Bit\u00b7te", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Tartar reichet jhr sein Ohr,", "tokens": ["Der", "Tar\u00b7tar", "rei\u00b7chet", "jhr", "sein", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sagt Ja: und als der Fr\u00fcling kommen,", "tokens": ["Sagt", "Ja", ":", "und", "als", "der", "Fr\u00fc\u00b7ling", "kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKANT", "$.", "KON", "KOUS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da hat Byzantz jhn auffgenommen.", "tokens": ["Da", "hat", "By\u00b7zantz", "jhn", "auff\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Da wird er auff den Marckt gestellt,", "tokens": ["Da", "wird", "er", "auff", "den", "Marckt", "ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd auch verkaufft f\u00fcr wenig Geld,", "tokens": ["Vnd", "auch", "ver\u00b7kaufft", "f\u00fcr", "we\u00b7nig", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mu\u00df in strenge Knechtschafft gehen", "tokens": ["Und", "mu\u00df", "in", "stren\u00b7ge", "Knecht\u00b7schafft", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auff erst-gefertigter Galeen.", "tokens": ["Auff", "er\u00b7stge\u00b7fer\u00b7tig\u00b7ter", "Ga\u00b7leen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.37": {"line.1": {"text": "Vnd damit wallt er hin und her", "tokens": ["Vnd", "da\u00b7mit", "wallt", "er", "hin", "und", "her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bald in den Str\u00f6men, bald im Meer,", "tokens": ["Bald", "in", "den", "Str\u00f6\u00b7men", ",", "bald", "im", "Meer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird \u00fcber seinem Dienst geschlagen,", "tokens": ["Wird", "\u00fc\u00b7ber", "sei\u00b7nem", "Dienst", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd mu\u00df Durst, Hitz und Hunger tragen.", "tokens": ["Vnd", "mu\u00df", "Durst", ",", "Hitz", "und", "Hun\u00b7ger", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Wie mag er jhm in solcher Noht", "tokens": ["Wie", "mag", "er", "jhm", "in", "sol\u00b7cher", "Noht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gew\u00fcnschet haben offt den Tod,", "tokens": ["Ge\u00b7w\u00fcn\u00b7schet", "ha\u00b7ben", "offt", "den", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd Gott gefleht, er woll jhn retten", "tokens": ["Vnd", "Gott", "ge\u00b7fleht", ",", "er", "woll", "jhn", "ret\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVPP", "$,", "PPER", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Au\u00df dieses schweren Dienstes Ketten.", "tokens": ["Au\u00df", "die\u00b7ses", "schwe\u00b7ren", "Diens\u00b7tes", "Ket\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Was Jammer hat es jhm gebracht,", "tokens": ["Was", "Jam\u00b7mer", "hat", "es", "jhm", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wann er an Preussen je gedacht", "tokens": ["Wann", "er", "an", "Preus\u00b7sen", "je", "ge\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Wunsch es nur so gut zu haben,", "tokens": ["Mit", "Wunsch", "es", "nur", "so", "gut", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "ADV", "ADV", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als die hie pfl\u00fcgen oder graben.", "tokens": ["Als", "die", "hie", "pfl\u00fc\u00b7gen", "o\u00b7der", "gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "War dieses also gnug? Ach nein,", "tokens": ["War", "die\u00b7ses", "al\u00b7so", "gnug", "?", "Ach", "nein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADV", "$.", "NN", "PTKANT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es war der Anfang seiner Pein,", "tokens": ["Es", "war", "der", "An\u00b7fang", "sei\u00b7ner", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wiewol erst nach drey vollen Jahren", "tokens": ["Wie\u00b7wol", "erst", "nach", "drey", "vol\u00b7len", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Bassa todes ist verfahren.", "tokens": ["Sein", "Bas\u00b7sa", "to\u00b7des", "ist", "ver\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Weil dieser alles durchgebracht,", "tokens": ["Weil", "die\u00b7ser", "al\u00b7les", "durch\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd eine grosse Schuld gemacht,", "tokens": ["Vnd", "ei\u00b7ne", "gros\u00b7se", "Schuld", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df man sein Gut da \u00fcber hauffen,", "tokens": ["Mu\u00df", "man", "sein", "Gut", "da", "\u00fc\u00b7ber", "hauf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PPOSAT", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den Schuldnern gnug zu thun, verkauffen.", "tokens": ["Den", "Schuld\u00b7nern", "gnug", "zu", "thun", ",", "ver\u00b7kauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Der Bassa, welcher, Rhodos, dich", "tokens": ["Der", "Bas\u00b7sa", ",", "wel\u00b7cher", ",", "Rho\u00b7dos", ",", "dich"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "NE", "$,", "PRELS", "$,", "NE", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beherrscht, bringt die Galee an sich,", "tokens": ["Be\u00b7herrscht", ",", "bringt", "die", "Ga\u00b7lee", "an", "sich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "APPR", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd diesen lieben Mann imgleichen,", "tokens": ["Vnd", "die\u00b7sen", "lie\u00b7ben", "Mann", "im\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer kan sein Elend gnug erreichen?", "tokens": ["Wer", "kan", "sein", "E\u00b7lend", "gnug", "er\u00b7rei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Die Herren haben sich verkehrt,", "tokens": ["Die", "Her\u00b7ren", "ha\u00b7ben", "sich", "ver\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht seine Noht, die jmmer w\u00e4hrt,", "tokens": ["Nicht", "sei\u00b7ne", "Noht", ",", "die", "jm\u00b7mer", "w\u00e4hrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd zwischen mehr als tausend F\u00e4llen", "tokens": ["Vnd", "zwi\u00b7schen", "mehr", "als", "tau\u00b7send", "F\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "KOKOM", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn umbgetrieben auff den Wellen.", "tokens": ["Ihn", "umb\u00b7ge\u00b7trie\u00b7ben", "auff", "den", "Wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Er sagt auff einem Finger her", "tokens": ["Er", "sagt", "auff", "ei\u00b7nem", "Fin\u00b7ger", "her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Inseln im Aegeer Meer,", "tokens": ["Die", "In\u00b7seln", "im", "A\u00b7e\u00b7geer", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ist offt Eubeen umbgeflogen,", "tokens": ["Ist", "offt", "Eu\u00b7be\u00b7en", "umb\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NE", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Offt durch den Hellespont gezogen.", "tokens": ["Offt", "durch", "den", "Hel\u00b7les\u00b7pont", "ge\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Durch die so offt geschehne Fahrt", "tokens": ["Durch", "die", "so", "offt", "ge\u00b7scheh\u00b7ne", "Fahrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hin nach Constantinopel ward", "tokens": ["Hin", "nach", "Con\u00b7stan\u00b7ti\u00b7no\u00b7pel", "ward"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die See jhm k\u00fcndig solcher massen,", "tokens": ["Die", "See", "jhm", "k\u00fcn\u00b7dig", "sol\u00b7cher", "mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als bey uns hie nicht sind die Strassen.", "tokens": ["Als", "bey", "uns", "hie", "nicht", "sind", "die", "Stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "ADV", "PTKNEG", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Offt sahe Co und Le\u00dfbos jhn,", "tokens": ["Offt", "sa\u00b7he", "Co", "und", "Le\u00df\u00b7bos", "jhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "KON", "NE", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Offt Sunium f\u00fcr\u00fcber ziehn,", "tokens": ["Offt", "Su\u00b7ni\u00b7um", "f\u00fc\u00b7r\u00fc\u00b7ber", "ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Riem hat Delos offt bestriechen,", "tokens": ["Sein", "Riem", "hat", "De\u00b7los", "offt", "be\u00b7strie\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist offt f\u00fcr Candien gewichen.", "tokens": ["Ist", "offt", "f\u00fcr", "Can\u00b7di\u00b7en", "ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Vorau\u00df die handelreiche Stadt,", "tokens": ["Vor\u00b7au\u00df", "die", "han\u00b7del\u00b7rei\u00b7che", "Stadt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die den ber\u00fchmten Pharos hat,", "tokens": ["Die", "den", "be\u00b7r\u00fchm\u00b7ten", "Pha\u00b7ros", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo Alexander ligt begraben,", "tokens": ["Wo", "A\u00b7lex\u00b7an\u00b7der", "ligt", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die soll er offt besuchet haben.", "tokens": ["Die", "soll", "er", "offt", "be\u00b7su\u00b7chet", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Mit was Gem\u00fct hat er erkant", "tokens": ["Mit", "was", "Ge\u00b7m\u00fct", "hat", "er", "er\u00b7kant"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Christen hochbedrengten Stand,", "tokens": ["Der", "Chris\u00b7ten", "hoch\u00b7be\u00b7dreng\u00b7ten", "Stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wie beseufftzt' er hin und wieder", "tokens": ["Vnd", "wie", "be\u00b7seufftzt'", "er", "hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den Drangsal seiner Glaubens-Br\u00fcder.", "tokens": ["Den", "Dran\u00b7gsal", "sei\u00b7ner", "Glau\u00b7bens\u00b7Br\u00fc\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Da\u00df Gott ihr grosses Angst-Geschrey,", "tokens": ["Da\u00df", "Gott", "ihr", "gros\u00b7ses", "Angst\u00b7Ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Saracenen Tyranney,", "tokens": ["Der", "Sa\u00b7ra\u00b7ce\u00b7nen", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des T\u00fcrcken Stoltz an allen Enden", "tokens": ["Des", "T\u00fcr\u00b7cken", "Stoltz", "an", "al\u00b7len", "En\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gar kein Erbarmen tr\u00e4gt zu wenden?", "tokens": ["Gar", "kein", "Er\u00b7bar\u00b7men", "tr\u00e4gt", "zu", "wen\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Vnd keinen Heiland aufferweckt", "tokens": ["Vnd", "kei\u00b7nen", "Hei\u00b7land", "auf\u00b7fer\u00b7weckt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der jhn mit seinem Wetter schreckt,", "tokens": ["Der", "jhn", "mit", "sei\u00b7nem", "Wet\u00b7ter", "schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd mus das grosse Theil der Erden", "tokens": ["Vnd", "mus", "das", "gros\u00b7se", "Theil", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Von jhm ohn End besessen werden?", "tokens": ["Von", "jhm", "ohn", "End", "be\u00b7ses\u00b7sen", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Wir werden hie von uns verheert", "tokens": ["Wir", "wer\u00b7den", "hie", "von", "uns", "ver\u00b7heert"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd fallen selbst in unser Schwerd,", "tokens": ["Vnd", "fal\u00b7len", "selbst", "in", "un\u00b7ser", "Schwerd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Macht, die ihn gnug k\u00f6nte zwingen,", "tokens": ["Durch", "Macht", ",", "die", "ihn", "gnug", "k\u00f6n\u00b7te", "zwin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind wir bem\u00fcht vns vmbzubringen.", "tokens": ["Sind", "wir", "be\u00b7m\u00fcht", "vns", "vmbzu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.52": {"line.1": {"text": "Indessen w\u00e4chst sein Vbermuth", "tokens": ["In\u00b7des\u00b7sen", "w\u00e4chst", "sein", "Vber\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Durch der so sch\u00f6nen L\u00e4nder Gut,", "tokens": ["Durch", "der", "so", "sch\u00f6\u00b7nen", "L\u00e4n\u00b7der", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hofft auch unser Land zu kriegen", "tokens": ["Und", "hofft", "auch", "un\u00b7ser", "Land", "zu", "krie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil wir vns in den Haaren liegen.", "tokens": ["Weil", "wir", "vns", "in", "den", "Haa\u00b7ren", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Wo aber bleibt Herr Kalckstein mir?", "tokens": ["Wo", "a\u00b7ber", "bleibt", "Herr", "Kalck\u00b7stein", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "NN", "NN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sonne bringt des Sommers Zier", "tokens": ["Die", "Son\u00b7ne", "bringt", "des", "Som\u00b7mers", "Zier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indessen siebenmal der Erden,", "tokens": ["In\u00b7des\u00b7sen", "sie\u00b7ben\u00b7mal", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "L\u00e4sst siebenmal es Winter werden.", "tokens": ["L\u00e4sst", "sie\u00b7ben\u00b7mal", "es", "Win\u00b7ter", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Weil er von diesem Bassa wei\u00df", "tokens": ["Weil", "er", "von", "die\u00b7sem", "Bas\u00b7sa", "wei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd ihm gedient in Frost und Schwei\u00df,", "tokens": ["Vnd", "ihm", "ge\u00b7dient", "in", "Frost", "und", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd Gott nun endlich auch sein Flehen", "tokens": ["Vnd", "Gott", "nun", "end\u00b7lich", "auch", "sein", "Fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "ADV", "ADV", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In Gnaden anhebt anzusehen,", "tokens": ["In", "Gna\u00b7den", "an\u00b7hebt", "an\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Ach aber durch was Schwierigkeit!", "tokens": ["Ach", "a\u00b7ber", "durch", "was", "Schwie\u00b7rig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "APPR", "PRELS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Oelschnitz hielt' vmb selbe Zeit", "tokens": ["Ein", "O\u00b7el\u00b7schnitz", "hielt'", "vmb", "sel\u00b7be", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sich zu Constantinopel eben", "tokens": ["Sich", "zu", "Con\u00b7stan\u00b7ti\u00b7no\u00b7pel", "e\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "APPR", "NE", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(was kan sich endlich nicht begeben?)", "tokens": ["(", "was", "kan", "sich", "end\u00b7lich", "nicht", "be\u00b7ge\u00b7ben", "?", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VMFIN", "PRF", "ADV", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Der sorgt vnd thut mit aller Trew", "tokens": ["Der", "sorgt", "vnd", "thut", "mit", "al\u00b7ler", "Trew"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob er wo zu erfragen sey,", "tokens": ["Ob", "er", "wo", "zu", "er\u00b7fra\u00b7gen", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PWAV", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Nachricht fehlet allerwegen,", "tokens": ["Die", "Nach\u00b7richt", "feh\u00b7let", "al\u00b7ler\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie weit ist Rhodos abgelegen?", "tokens": ["Wie", "weit", "ist", "Rho\u00b7dos", "ab\u00b7ge\u00b7le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "NE", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Wer kan nur forschen die Galee?", "tokens": ["Wer", "kan", "nur", "for\u00b7schen", "die", "Ga\u00b7lee", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo schweiffet sie auff welcher See?", "tokens": ["Wo", "schweif\u00b7fet", "sie", "auff", "wel\u00b7cher", "See", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "PWAT", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ob sie mag umb Egyptens Ecken", "tokens": ["Ob", "sie", "mag", "umb", "E\u00b7gyp\u00b7tens", "E\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "APPR", "NE", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Vmb Cypern oder sonst wo stecken?", "tokens": ["Vmb", "Cy\u00b7pern", "o\u00b7der", "sonst", "wo", "ste\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "ADV", "PWAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Doch f\u00fcget sich was Gott behagt,", "tokens": ["Doch", "f\u00fc\u00b7get", "sich", "was", "Gott", "be\u00b7hagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PWS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er wird zuletzt noch ausgefragt,", "tokens": ["Er", "wird", "zu\u00b7letzt", "noch", "aus\u00b7ge\u00b7fragt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was Frewd' entstund in seinem Hertzen", "tokens": ["Was", "Fre\u00b7wd'", "ent\u00b7stund", "in", "sei\u00b7nem", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "KON", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nach des so langen Dienstes Schmertzen!", "tokens": ["Nach", "des", "so", "lan\u00b7gen", "Diens\u00b7tes", "Schmert\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Constantinopel aber macht", "tokens": ["Con\u00b7stan\u00b7ti\u00b7no\u00b7pel", "a\u00b7ber", "macht"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ihm nicht lang die Hoffnung lacht,", "tokens": ["Da\u00df", "ihm", "nicht", "lang", "die", "Hoff\u00b7nung", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er solt' und muste dahin kommen", "tokens": ["Er", "solt'", "und", "mus\u00b7te", "da\u00b7hin", "kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "PAV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wolt' er in Freyheit seyn genommen.", "tokens": ["Wolt'", "er", "in", "Frey\u00b7heit", "seyn", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Was Hoffnung war zu diesem nun?", "tokens": ["Was", "Hoff\u00b7nung", "war", "zu", "die\u00b7sem", "nun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "APPR", "PDAT", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was solt er immer nachmals thun?", "tokens": ["Was", "solt", "er", "im\u00b7mer", "nach\u00b7mals", "thun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Solt' ihm die\u00df Mittel auch entfliehen?", "tokens": ["Solt'", "ihm", "die\u00df", "Mit\u00b7tel", "auch", "ent\u00b7flie\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie hat er da zu Gott geschrien.", "tokens": ["Wie", "hat", "er", "da", "zu", "Gott", "ge\u00b7schri\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Der ihm auch dazumal nicht schlieff,", "tokens": ["Der", "ihm", "auch", "da\u00b7zu\u00b7mal", "nicht", "schlieff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Herr mu\u00df ein Maltheser Schiff", "tokens": ["Sein", "Herr", "mu\u00df", "ein", "Mal\u00b7the\u00b7ser", "Schiff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "ART", "NN", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Ohn zweiffel ihm zu gut bezwingen", "tokens": ["Ohn", "zweif\u00b7fel", "ihm", "zu", "gut", "be\u00b7zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PPER", "PTKA", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd nach Constantinopel bringen,", "tokens": ["Vnd", "nach", "Con\u00b7stan\u00b7ti\u00b7no\u00b7pel", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Da f\u00e4hrt er mit und jauchtzend ein,", "tokens": ["Da", "f\u00e4hrt", "er", "mit", "und", "jaucht\u00b7zend", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch bald er\u00e4ugt sich wieder Pein,", "tokens": ["Doch", "bald", "er\u00b7\u00e4ugt", "sich", "wie\u00b7der", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er wil der Knechtschafft sich entbinden,", "tokens": ["Er", "wil", "der", "Knecht\u00b7schafft", "sich", "ent\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo war nun Geld hiezu zu finden?", "tokens": ["Wo", "war", "nun", "Geld", "hie\u00b7zu", "zu", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Eh' er nach Hause schreiben kan", "tokens": ["Eh'", "er", "nach", "Hau\u00b7se", "schrei\u00b7ben", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wiederumb Bericht k\u00f6mpt an,", "tokens": ["Vnd", "wie\u00b7de\u00b7rumb", "Be\u00b7richt", "k\u00f6mpt", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was Zeit ist mitler weil vergangen,", "tokens": ["Was", "Zeit", "ist", "mit\u00b7ler", "weil", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "ADV", "KOUS", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie kr\u00e4nckt ihn Sorg hie, da Verlangen.", "tokens": ["Wie", "kr\u00e4nckt", "ihn", "Sorg", "hie", ",", "da", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "NN", "ADV", "$,", "KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Indessen f\u00e4hrt er wiederumb", "tokens": ["In\u00b7des\u00b7sen", "f\u00e4hrt", "er", "wie\u00b7de\u00b7rumb"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Insuln durch gerad und krumm,", "tokens": ["Die", "In\u00b7suln", "durch", "ge\u00b7rad", "und", "krumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aegypten-ein vnd auch zur\u00fccke", "tokens": ["A\u00b7egyp\u00b7ten\u00b7ein", "vnd", "auch", "zu\u00b7r\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "KON", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd sieht Byzantz mit gutem Gl\u00fccke.", "tokens": ["Vnd", "sieht", "By\u00b7zantz", "mit", "gu\u00b7tem", "Gl\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Sein L\u00f6segeld zwar h\u00e4tt' er gern,", "tokens": ["Sein", "L\u00f6\u00b7se\u00b7geld", "zwar", "h\u00e4tt'", "er", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das aber hielte sich gar fern,", "tokens": ["Das", "a\u00b7ber", "hiel\u00b7te", "sich", "gar", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "PRF", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er geht erb\u00e4rmlich abgerissen", "tokens": ["Er", "geht", "er\u00b7b\u00e4rm\u00b7lich", "ab\u00b7ge\u00b7ris\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nackt an dem Leib, nackt an den F\u00fcssen.", "tokens": ["Nackt", "an", "dem", "Leib", ",", "nackt", "an", "den", "F\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Er macht an den und jenen sich,", "tokens": ["Er", "macht", "an", "den", "und", "je\u00b7nen", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "KON", "PDS", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein ieder fragt, wo kenn' ich dich?", "tokens": ["Ein", "ie\u00b7der", "fragt", ",", "wo", "kenn'", "ich", "dich", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wer wil einem Menschen trawen", "tokens": ["Vnd", "wer", "wil", "ei\u00b7nem", "Men\u00b7schen", "tra\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VMFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wann er einhergeht als ein Grawen?", "tokens": ["Wann", "er", "ein\u00b7her\u00b7geht", "als", "ein", "Gra\u00b7wen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Ein Koch aus Holland war zuletzt", "tokens": ["Ein", "Koch", "aus", "Hol\u00b7land", "war", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NE", "APPR", "NE", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ihn in rechte Freyheit setzt,", "tokens": ["Der", "ihn", "in", "rech\u00b7te", "Frey\u00b7heit", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Geld ihm vorstreckt, doch indessen", "tokens": ["Das", "Geld", "ihm", "vor\u00b7streckt", ",", "doch", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "PPER", "VVPP", "$,", "ADV", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich und sein Vortheil unvergessen.", "tokens": ["Sich", "und", "sein", "Vor\u00b7theil", "un\u00b7ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KON", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Vnd die\u00df hat also Gott geschickt", "tokens": ["Vnd", "die\u00df", "hat", "al\u00b7so", "Gott", "ge\u00b7schickt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "ADV", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der seinen Jammer angeblickt", "tokens": ["Der", "sei\u00b7nen", "Jam\u00b7mer", "an\u00b7ge\u00b7blickt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd ihn einmal zur guten Stunden", "tokens": ["Vnd", "ihn", "ein\u00b7mal", "zur", "gu\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Der strengen Dienstbarkeit entbunden.", "tokens": ["Der", "stren\u00b7gen", "Dienst\u00b7bar\u00b7keit", "ent\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Darauff k\u00f6mpt auch sein Wechsel an,", "tokens": ["Dar\u00b7auff", "k\u00f6mpt", "auch", "sein", "Wech\u00b7sel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie hocherfrewet ist der Mann,", "tokens": ["Wie", "ho\u00b7cher\u00b7fre\u00b7wet", "ist", "der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihm mu\u00df das Hertz im Leibe wallen,", "tokens": ["Ihm", "mu\u00df", "das", "Hertz", "im", "Lei\u00b7be", "wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Lobgesang ist Gott f\u00fcr allen.", "tokens": ["Sein", "Lob\u00b7ge\u00b7sang", "ist", "Gott", "f\u00fcr", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Wo ist sein lang-gewachsen Har", "tokens": ["Wo", "ist", "sein", "lang\u00b7ge\u00b7wach\u00b7sen", "Har"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd was erst schewlichs an ihm war?", "tokens": ["Vnd", "was", "erst", "schew\u00b7lichs", "an", "ihm", "war", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VVFIN", "APPR", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er darff die Armut nicht mehr leiden,", "tokens": ["Er", "darff", "die", "Ar\u00b7mut", "nicht", "mehr", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "An stat des Sackes tr\u00e4gt er Seiden.", "tokens": ["An", "stat", "des", "Sa\u00b7ckes", "tr\u00e4gt", "er", "Sei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "VVFIN", "PPER", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "F\u00fcr Wasser trinckt er edlen Wein,", "tokens": ["F\u00fcr", "Was\u00b7ser", "trinckt", "er", "ed\u00b7len", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gieng erst verzagt ietzt frisch herein,", "tokens": ["Gieng", "erst", "ver\u00b7zagt", "ietzt", "frisch", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kan eilends grosse Freunde nennen", "tokens": ["Kan", "ei\u00b7lends", "gros\u00b7se", "Freun\u00b7de", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den vormals niemand wolte kennen.", "tokens": ["Den", "vor\u00b7mals", "nie\u00b7mand", "wol\u00b7te", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Die\u00df ist des Gl\u00fcckes Wanckelmuth,", "tokens": ["Die\u00df", "ist", "des", "Gl\u00fc\u00b7ckes", "Wan\u00b7ckel\u00b7muth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das kehrt sich allzeit nach dem Gut,", "tokens": ["Das", "kehrt", "sich", "all\u00b7zeit", "nach", "dem", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Vnd hat dahin zu kommen Grawen", "tokens": ["Vnd", "hat", "da\u00b7hin", "zu", "kom\u00b7men", "Gra\u00b7wen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PAV", "PTKZU", "VVINF", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wo Noth vnd Armuth ist zu schawen.", "tokens": ["Wo", "Noth", "vnd", "Ar\u00b7muth", "ist", "zu", "scha\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.73": {"line.1": {"text": "Nichts ist mehr \u00fcbrig als da\u00df er", "tokens": ["Nichts", "ist", "mehr", "\u00fcb\u00b7rig", "als", "da\u00df", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "KOKOM", "KOUS", "PPER"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Sein Segel lencket auff das Meer", "tokens": ["Sein", "Se\u00b7gel", "len\u00b7cket", "auff", "das", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und eilet zu den lieben Seinen", "tokens": ["Und", "ei\u00b7let", "zu", "den", "lie\u00b7ben", "Sei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die lange Zeit nach ihm schon weinen.", "tokens": ["Die", "lan\u00b7ge", "Zeit", "nach", "ihm", "schon", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Die\u00df thut er, Chio nimmt ihn auff,", "tokens": ["Die\u00df", "thut", "er", ",", "Chio", "nimmt", "ihn", "auff", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "NE", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Von dannen kehrt er seinen Lauff", "tokens": ["Von", "dan\u00b7nen", "kehrt", "er", "sei\u00b7nen", "Lauff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sicilien zu, k\u00f6mpt nach Messinen,", "tokens": ["Si\u00b7ci\u00b7li\u00b7en", "zu", ",", "k\u00f6mpt", "nach", "Mes\u00b7si\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Da wil es ihm zu seyn nicht dienen,", "tokens": ["Da", "wil", "es", "ihm", "zu", "seyn", "nicht", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "PTKZU", "VAINF", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Er wendet stracks nach Napels sich,", "tokens": ["Er", "wen\u00b7det", "stracks", "nach", "Na\u00b7pels", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "PRF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von dannen schawt er, Rom, auch dich,", "tokens": ["Von", "dan\u00b7nen", "schawt", "er", ",", "Rom", ",", "auch", "dich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "$,", "NE", "$,", "ADV", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von dar Livorno ihn genommen", "tokens": ["Von", "dar", "Li\u00b7vor\u00b7no", "ihn", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und nach Marsilien heisset kommen.", "tokens": ["Und", "nach", "Mar\u00b7si\u00b7li\u00b7en", "heis\u00b7set", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.76": {"line.1": {"text": "Er f\u00e4hrt durch Franckreich an der Rhon", "tokens": ["Er", "f\u00e4hrt", "durch", "Fran\u00b7ck\u00b7reich", "an", "der", "Rhon"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vnd spricht die sch\u00f6ne Stad Lyon,", "tokens": ["Vnd", "spricht", "die", "sch\u00f6\u00b7ne", "Stad", "Ly\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bi\u00df da\u00df Pari\u00df ihn weiter schicket", "tokens": ["Bi\u00df", "da\u00df", "Pa\u00b7ri\u00df", "ihn", "wei\u00b7ter", "schi\u00b7cket"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "NE", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd er so, Holland, dich erblicket.", "tokens": ["Vnd", "er", "so", ",", "Hol\u00b7land", ",", "dich", "er\u00b7bli\u00b7cket", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "NE", "$,", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Das bringet ihn mit trewer Hand", "tokens": ["Das", "brin\u00b7get", "ihn", "mit", "tre\u00b7wer", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "In sein gew\u00fcnschtes Vaterland,", "tokens": ["In", "sein", "ge\u00b7w\u00fcnschtes", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem er sich nicht hatt' vmbfangen", "tokens": ["Mit", "dem", "er", "sich", "nicht", "hatt'", "vmb\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "PRF", "PTKNEG", "VAFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil vierzehn Jahr herumb gegangen.", "tokens": ["Weil", "vier\u00b7zehn", "Jahr", "he\u00b7rumb", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "APZR", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Sey wehrte Mutter hoch erfrewt,", "tokens": ["Sey", "wehr\u00b7te", "Mut\u00b7ter", "hoch", "er\u00b7frewt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hie endet sich dein langes Leid,", "tokens": ["Hie", "en\u00b7det", "sich", "dein", "lan\u00b7ges", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du hattest deinen Sohn verlohren", "tokens": ["Du", "hat\u00b7test", "dei\u00b7nen", "Sohn", "ver\u00b7loh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den siehst du ietzt als new gebohren.", "tokens": ["Den", "siehst", "du", "ietzt", "als", "new", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "KOUS", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Er k\u00f6mpt der alle Kindes-Pflicht", "tokens": ["Er", "k\u00f6mpt", "der", "al\u00b7le", "Kin\u00b7des\u00b7Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dir, wenn du alten must, verspricht,", "tokens": ["Dir", ",", "wenn", "du", "al\u00b7ten", "must", ",", "ver\u00b7spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "KOUS", "PPER", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd wenn du solst von hinnen r\u00fccken", "tokens": ["Vnd", "wenn", "du", "solst", "von", "hin\u00b7nen", "r\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VMFIN", "APPR", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Augen selbst dir zu wil dr\u00fccken.", "tokens": ["Die", "Au\u00b7gen", "selbst", "dir", "zu", "wil", "dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPR", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Er setzt sich auff sein Vater-Gut", "tokens": ["Er", "setzt", "sich", "auff", "sein", "Va\u00b7ter\u00b7Gut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd nimmt dasselb in fleissig' Hut,", "tokens": ["Vnd", "nimmt", "das\u00b7selb", "in", "fleis\u00b7sig'", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist wol mit Gott und sich zu frieden", "tokens": ["Ist", "wol", "mit", "Gott", "und", "sich", "zu", "frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd von dem leichten Gl\u00fcck geschieden.", "tokens": ["Vnd", "von", "dem", "leich\u00b7ten", "Gl\u00fcck", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "Er trawt demselben nimmermehr,", "tokens": ["Er", "trawt", "dem\u00b7sel\u00b7ben", "nim\u00b7mer\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd strebet nicht nach eitler Ehr,", "tokens": ["Vnd", "stre\u00b7bet", "nicht", "nach", "eit\u00b7ler", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat gnug erkant da\u00df alle Sachen", "tokens": ["Hat", "gnug", "er\u00b7kant", "da\u00df", "al\u00b7le", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "VVPP", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vns nur vergebne Hoffnung machen.", "tokens": ["Vns", "nur", "ver\u00b7geb\u00b7ne", "Hoff\u00b7nung", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Was grosses h\u00e4tt er k\u00f6nnen seyn,", "tokens": ["Was", "gros\u00b7ses", "h\u00e4tt", "er", "k\u00f6n\u00b7nen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "VAFIN", "PPER", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem sein Frantz\u00f6sisch und Latein", "tokens": ["Dem", "sein", "Frant\u00b7z\u00f6\u00b7sisch", "und", "La\u00b7tein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bekant war, der Bescheid darneben", "tokens": ["Be\u00b7kant", "war", ",", "der", "Be\u00b7scheid", "dar\u00b7ne\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$,", "ART", "NN", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den wilden Tartern kunte geben.", "tokens": ["Den", "wil\u00b7den", "Tar\u00b7tern", "kun\u00b7te", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Der Moscowitisch vnd darnach", "tokens": ["Der", "Mo\u00b7sco\u00b7wi\u00b7tisch", "vnd", "dar\u00b7nach"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch T\u00fcrckisch mehr als fertig sprach,", "tokens": ["Auch", "T\u00fcr\u00b7ckisch", "mehr", "als", "fer\u00b7tig", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PIAT", "KOKOM", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Welschland vnd der Pohl vernommen", "tokens": ["Den", "Wel\u00b7schland", "vnd", "der", "Pohl", "ver\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht auff das Deutsch einmal zu kommen,", "tokens": ["Nicht", "auff", "das", "Deutsch", "ein\u00b7mal", "zu", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Der aus der massen wol verstand", "tokens": ["Der", "aus", "der", "mas\u00b7sen", "wol", "ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Krieg zu Wasser und zu Land,", "tokens": ["Den", "Krieg", "zu", "Was\u00b7ser", "und", "zu", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als welcher offtmals selbst gestritten,", "tokens": ["Als", "wel\u00b7cher", "offt\u00b7mals", "selbst", "ge\u00b7strit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRELS", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der wust umb aller V\u00f6lcker Sitten.", "tokens": ["Der", "wust", "umb", "al\u00b7ler", "V\u00f6l\u00b7cker", "Sit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.85": {"line.1": {"text": "Der grosse Wei\u00dfheit ihm erbawt", "tokens": ["Der", "gros\u00b7se", "Wei\u00df\u00b7heit", "ihm", "er\u00b7bawt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus allem was er ie geschawt,", "tokens": ["Aus", "al\u00b7lem", "was", "er", "ie", "ge\u00b7schawt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tag vnd Nacht wust hin zubringen", "tokens": ["Der", "Tag", "vnd", "Nacht", "wust", "hin", "zu\u00b7brin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Vnterricht von vielen Dingen.", "tokens": ["Mit", "Vn\u00b7ter\u00b7richt", "von", "vie\u00b7len", "Din\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.86": {"line.1": {"text": "Homerus r\u00fchm' Vlysses Fahrt", "tokens": ["Ho\u00b7me\u00b7rus", "r\u00fchm'", "Vlys\u00b7ses", "Fahrt"], "token_info": ["word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dadurch er vieler Menschen Art", "tokens": ["Da\u00b7durch", "er", "vie\u00b7ler", "Men\u00b7schen", "Art"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel St\u00e4dt vnd L\u00e4nder hat vernommen", "tokens": ["Viel", "St\u00e4dt", "vnd", "L\u00e4n\u00b7der", "hat", "ver\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd so zu grosser Wei\u00dfheit kommen.", "tokens": ["Vnd", "so", "zu", "gros\u00b7ser", "Wei\u00df\u00b7heit", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Da\u00df mir es mein Homer verzeih'", "tokens": ["Da\u00df", "mir", "es", "mein", "Ho\u00b7mer", "ver\u00b7zeih'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "PPOSAT", "NE", "VVFIN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Vlysses k\u00f6mpt hie gar nicht bey,", "tokens": ["Vlys\u00b7ses", "k\u00f6mpt", "hie", "gar", "nicht", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "PTKNEG", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aus einer Flieg ein Pferd zu machen,", "tokens": ["Aus", "ei\u00b7ner", "Flieg", "ein", "Pferd", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sind offt der Tichter eigne Sachen.", "tokens": ["Sind", "offt", "der", "Tich\u00b7ter", "eig\u00b7ne", "Sa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Hie dieses Arbeit und Gefahr", "tokens": ["Hie", "die\u00b7ses", "Ar\u00b7beit", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PDAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist warlich mehr als allzu wahr,", "tokens": ["Ist", "war\u00b7lich", "mehr", "als", "all\u00b7zu", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "KOKOM", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er ist Vlyssi allerwegen", "tokens": ["Er", "ist", "Vlys\u00b7si", "al\u00b7ler\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NE", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit Noht vnd Reisen \u00fcberlegen.", "tokens": ["Mit", "Noht", "vnd", "Rei\u00b7sen", "\u00fc\u00b7berl\u00b7e\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.89": {"line.1": {"text": "Doch wuchs ihm nimmermehr der Muth", "tokens": ["Doch", "wuchs", "ihm", "nim\u00b7mer\u00b7mehr", "der", "Muth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey dieser grossen Tugend Gut,", "tokens": ["Bey", "die\u00b7ser", "gros\u00b7sen", "Tu\u00b7gend", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er war still, sitsam und bescheiden", "tokens": ["Er", "war", "still", ",", "sit\u00b7sam", "und", "be\u00b7schei\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "ADJD", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd gnug gelehrt auch vnrecht leiden.", "tokens": ["Vnd", "gnug", "ge\u00b7lehrt", "auch", "vn\u00b7recht", "lei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.90": {"line.1": {"text": "Sein Raht sprang offt mit aller Trew", "tokens": ["Sein", "Raht", "sprang", "offt", "mit", "al\u00b7ler", "Trew"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem lieben Vaterlande bey,", "tokens": ["Dem", "lie\u00b7ben", "Va\u00b7ter\u00b7lan\u00b7de", "bey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat unser H\u00e4upt an sich gezogen", "tokens": ["Hat", "un\u00b7ser", "H\u00e4upt", "an", "sich", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "PRF", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das ihm gar gn\u00e4digst war gewogen.", "tokens": ["Das", "ihm", "gar", "gn\u00e4\u00b7digst", "war", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.91": {"line.1": {"text": "Auch hat nach der betr\u00fcbten Zeit", "tokens": ["Auch", "hat", "nach", "der", "be\u00b7tr\u00fcb\u00b7ten", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Herr vielf\u00e4ltig ihn erfrewt,", "tokens": ["Der", "Herr", "viel\u00b7f\u00e4l\u00b7tig", "ihn", "er\u00b7frewt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Job nach den bekr\u00e4nckten Stunden", "tokens": ["Wie", "Job", "nach", "den", "be\u00b7kr\u00e4nck\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Gutes siebenfach empfunden.", "tokens": ["Viel", "Gu\u00b7tes", "sie\u00b7ben\u00b7fach", "emp\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.92": {"line.1": {"text": "Die edle Gro\u00dfpfersfelderinn", "tokens": ["Die", "ed\u00b7le", "Gro\u00df\u00b7pfers\u00b7fel\u00b7de\u00b7rinn"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War hochgew\u00fcnscht nach seinem Sinn", "tokens": ["War", "hoch\u00b7ge\u00b7w\u00fcnscht", "nach", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und macht' ihn Vater solcher Erben", "tokens": ["Und", "macht'", "ihn", "Va\u00b7ter", "sol\u00b7cher", "Er\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch die er ewig nicht sol sterben.", "tokens": ["Durch", "die", "er", "e\u00b7wig", "nicht", "sol", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.93": {"line.1": {"text": "Sein Segen nam imgleichen zu", "tokens": ["Sein", "Se\u00b7gen", "nam", "im\u00b7glei\u00b7chen", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd bracht' ihm alle Gn\u00fcg vnd Ruh,", "tokens": ["Vnd", "bracht'", "ihm", "al\u00b7le", "Gn\u00fcg", "vnd", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die ihm auff sein gehabtes Leiden", "tokens": ["Die", "ihm", "auff", "sein", "ge\u00b7hab\u00b7tes", "Lei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Erwecket nicht geringe Frewden.", "tokens": ["Er\u00b7we\u00b7cket", "nicht", "ge\u00b7rin\u00b7ge", "Frew\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.94": {"line.1": {"text": "Indessen wird er alt und schwach", "tokens": ["In\u00b7des\u00b7sen", "wird", "er", "alt", "und", "schwach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn ihm der Jugend Ungemach", "tokens": ["Denn", "ihm", "der", "Ju\u00b7gend", "Un\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht einen schlechten Sto\u00df gegeben,", "tokens": ["Nicht", "ei\u00b7nen", "schlech\u00b7ten", "Sto\u00df", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst h\u00e4tt' er lange m\u00f6gen leben.", "tokens": ["Sonst", "h\u00e4tt'", "er", "lan\u00b7ge", "m\u00f6\u00b7gen", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.95": {"line.1": {"text": "Der Tod auch klopffet bey ihm an,", "tokens": ["Der", "Tod", "auch", "klopf\u00b7fet", "bey", "ihm", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch hie erzeigt er seinen Mann,", "tokens": ["Auch", "hie", "er\u00b7zeigt", "er", "sei\u00b7nen", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er gr\u00fcndet sich auff Christi Wunden", "tokens": ["Er", "gr\u00fcn\u00b7det", "sich", "auff", "Chris\u00b7ti", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd wartet einer selgen Stunden.", "tokens": ["Vnd", "war\u00b7tet", "ei\u00b7ner", "sel\u00b7gen", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.96": {"line.1": {"text": "Die k\u00f6mmt vnd tr\u00e4gt ihn auff der Hand", "tokens": ["Die", "k\u00f6mmt", "vnd", "tr\u00e4gt", "ihn", "auff", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Engel in sein Vaterland,", "tokens": ["Der", "En\u00b7gel", "in", "sein", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da er f\u00fcr seinen Kampff auff Erden", "tokens": ["Da", "er", "f\u00fcr", "sei\u00b7nen", "Kampff", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nun ewig wird gekr\u00f6hnet werden.", "tokens": ["Nun", "e\u00b7wig", "wird", "ge\u00b7kr\u00f6h\u00b7net", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.97": {"line.1": {"text": "Wenn grosse Tugend lieb seyn kan", "tokens": ["Wenn", "gros\u00b7se", "Tu\u00b7gend", "lieb", "seyn", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "NN", "ADJD", "VAINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der sehe stets sein Leben an,", "tokens": ["Der", "se\u00b7he", "stets", "sein", "Le\u00b7ben", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es wird ihn bessern aller massen", "tokens": ["Es", "wird", "ihn", "bes\u00b7sern", "al\u00b7ler", "mas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im Fall er Vnterricht wil fassen.", "tokens": ["Im", "Fall", "er", "Vn\u00b7ter\u00b7richt", "wil", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Er wird erkennen wo man hin", "tokens": ["Er", "wird", "er\u00b7ken\u00b7nen", "wo", "man", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVINF", "PWAV", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Noht sol wenden Hertz und Sinn,", "tokens": ["In", "Noht", "sol", "wen\u00b7den", "Hertz", "und", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd da\u00df ein Mensch, voraus Soldaten,", "tokens": ["Vnd", "da\u00df", "ein", "Mensch", ",", "vo\u00b7raus", "Sol\u00b7da\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Leicht k\u00f6nnen in Gefahr gerahten,", "tokens": ["Leicht", "k\u00f6n\u00b7nen", "in", "Ge\u00b7fahr", "ge\u00b7rah\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.99": {"line.1": {"text": "Vnd wie der Herr zwar eine Zeit", "tokens": ["Vnd", "wie", "der", "Herr", "zwar", "ei\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von vns zu treten scheint sehr weit,", "tokens": ["Von", "vns", "zu", "tre\u00b7ten", "scheint", "sehr", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKZU", "VVINF", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd doch zuletzt von allen B\u00f6sen", "tokens": ["Vnd", "doch", "zu\u00b7letzt", "von", "al\u00b7len", "B\u00f6\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vns herrlich wisse zu erl\u00f6sen.", "tokens": ["Vns", "herr\u00b7lich", "wis\u00b7se", "zu", "er\u00b7l\u00f6\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.100": {"line.1": {"text": "Wen die\u00df Exempel nicht bewegt", "tokens": ["Wen", "die\u00df", "Ex\u00b7em\u00b7pel", "nicht", "be\u00b7wegt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PDS", "NN", "PTKNEG", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ihm Lust zum Guten nicht erregt,", "tokens": ["Ihm", "Lust", "zum", "Gu\u00b7ten", "nicht", "er\u00b7regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPRART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der f\u00fchlt in ihm kein Tugend-Fewer", "tokens": ["Der", "f\u00fchlt", "in", "ihm", "kein", "Tu\u00b7gen\u00b7dFe\u00b7wer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd ist ein Block und Ungehewer.", "tokens": ["Vnd", "ist", "ein", "Block", "und", "Un\u00b7ge\u00b7he\u00b7wer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}}}}