{"textgrid.poem.31746": {"metadata": {"author": {"name": "Weerth, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Mary", "genre": "verse", "period": "N.A.", "pub_year": 1845, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Von Irland kam sie mit der Flut,", "tokens": ["Von", "Ir\u00b7land", "kam", "sie", "mit", "der", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie kam von Tipperary;", "tokens": ["Sie", "kam", "von", "Tip\u00b7per\u00b7a\u00b7ry", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sie hatte warmes, rasches Blut,", "tokens": ["Sie", "hat\u00b7te", "war\u00b7mes", ",", "ra\u00b7sches", "Blut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die junge Dirn, die Mary.", "tokens": ["Die", "jun\u00b7ge", "Dirn", ",", "die", "Ma\u00b7ry", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und als sie keck ans Ufer sprang,", "tokens": ["Und", "als", "sie", "keck", "ans", "U\u00b7fer", "sprang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da riefen die Matrosen:", "tokens": ["Da", "rie\u00b7fen", "die", "Mat\u00b7ro\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u00bbdie Dirne Mary, Gott sei Dank,", "tokens": ["\u00bb", "die", "Dir\u00b7ne", "Ma\u00b7ry", ",", "Gott", "sei", "Dank", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NE", "$,", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gleicht einer wilden Rosen!\u00ab", "tokens": ["Gleicht", "ei\u00b7ner", "wil\u00b7den", "Ro\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und als sie schritt zum Markte frank,", "tokens": ["Und", "als", "sie", "schritt", "zum", "Mark\u00b7te", "frank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach ein Gesell mit Gr\u00fc\u00dfen:", "tokens": ["Sprach", "ein", "Ge\u00b7sell", "mit", "Gr\u00fc\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdie Dirne Mary, Gott sei Dank,", "tokens": ["\u00bb", "die", "Dir\u00b7ne", "Ma\u00b7ry", ",", "Gott", "sei", "Dank", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NE", "$,", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geht auf zwei wei\u00dfen F\u00fc\u00dfen.\u00ab", "tokens": ["Geht", "auf", "zwei", "wei\u00b7\u00dfen", "F\u00fc\u00b7\u00dfen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "CARD", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und als sie sa\u00df zu Liverpool", "tokens": ["Und", "als", "sie", "sa\u00df", "zu", "Li\u00b7ver\u00b7po\u00b7ol"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Mit schwarz verwegnen Blicken,", "tokens": ["Mit", "schwarz", "ver\u00b7weg\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da wollten sich um ihren Stuhl", "tokens": ["Da", "woll\u00b7ten", "sich", "um", "ih\u00b7ren", "Stuhl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Menschen schier erdr\u00fccken.", "tokens": ["Die", "Men\u00b7schen", "schier", "er\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Von Irland kam sie mit der Flut,", "tokens": ["Von", "Ir\u00b7land", "kam", "sie", "mit", "der", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie kam von Tipperary:", "tokens": ["Sie", "kam", "von", "Tip\u00b7per\u00b7a\u00b7ry", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u00bbwer kauft Orangen, frisch und gut?\u00ab", "tokens": ["\u00bb", "wer", "kauft", "O\u00b7ran\u00b7gen", ",", "frisch", "und", "gut", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VVFIN", "NN", "$,", "ADJD", "KON", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So rief die Dirn, die Mary.", "tokens": ["So", "rief", "die", "Dirn", ",", "die", "Ma\u00b7ry", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Und Mohr und Perser und Mulatt", "tokens": ["Und", "Mohr", "und", "Per\u00b7ser", "und", "Mu\u00b7latt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Juden wie Getaufte \u2013", "tokens": ["Und", "Ju\u00b7den", "wie", "Ge\u00b7tauf\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KOKOM", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Das ganze Volk der Handelsstadt,", "tokens": ["Das", "gan\u00b7ze", "Volk", "der", "Han\u00b7dels\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Es kam und kaufte, kaufte.", "tokens": ["Es", "kam", "und", "kauf\u00b7te", ",", "kauf\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da fuhr kein Schiff den Flu\u00df hinauf,", "tokens": ["Da", "fuhr", "kein", "Schiff", "den", "Flu\u00df", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da schwamm auch keins zum Meere:", "tokens": ["Da", "schwamm", "auch", "keins", "zum", "Mee\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sa\u00df ein verliebter Schiffsjung drauf", "tokens": ["Sa\u00df", "ein", "ver\u00b7lieb\u00b7ter", "Schiffs\u00b7jung", "drauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dacht: Oh, wenn ich w\u00e4re", "tokens": ["Und", "dacht", ":", "Oh", ",", "wenn", "ich", "w\u00e4\u00b7re"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "ITJ", "$,", "KOUS", "PPER", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Erst auf dem Markt zu Liverpool,", "tokens": ["Erst", "auf", "dem", "Markt", "zu", "Li\u00b7ver\u00b7po\u00b7ol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Da sitzt von Tipperary,", "tokens": ["Da", "sitzt", "von", "Tip\u00b7per\u00b7a\u00b7ry", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Mit den Orangen auf dem Stuhl,", "tokens": ["Mit", "den", "O\u00b7ran\u00b7gen", "auf", "dem", "Stuhl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die junge Dirn, die Mary!", "tokens": ["Die", "jun\u00b7ge", "Dirn", ",", "die", "Ma\u00b7ry", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Gab es wohl gr\u00f6\u00dfre Liebe je?", "tokens": ["Gab", "es", "wohl", "gr\u00f6\u00df\u00b7re", "Lie\u00b7be", "je", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "ADV", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Die Dirn am Mersey-Strande", "tokens": ["Die", "Dirn", "am", "Mer\u00b7sey\u00b7Stran\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hatt tausend Sch\u00e4tze auf der See", "tokens": ["Hatt", "tau\u00b7send", "Sch\u00e4t\u00b7ze", "auf", "der", "See"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "CARD", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mehr noch auf dem Lande.", "tokens": ["Und", "mehr", "noch", "auf", "dem", "Lan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "In jeder Zone, wo der Mast", "tokens": ["In", "je\u00b7der", "Zo\u00b7ne", ",", "wo", "der", "Mast"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von einem Fahrzeug krachte,", "tokens": ["Von", "ei\u00b7nem", "Fahr\u00b7zeug", "krach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Schwamm eine Seemannsseele fast,", "tokens": ["Schwamm", "ei\u00b7ne", "See\u00b7manns\u00b7see\u00b7le", "fast", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die an Orangen dachte. \u2013", "tokens": ["Die", "an", "O\u00b7ran\u00b7gen", "dach\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ob auch die Lippen brannten,", "tokens": ["Ob", "auch", "die", "Lip\u00b7pen", "brann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Stets an des Markts gesch\u00e4ft'ger Eck", "tokens": ["Stets", "an", "des", "Markts", "ge\u00b7sch\u00e4ft'\u00b7ger", "Eck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den b\u00e4rtigen Bekannten.", "tokens": ["Den", "b\u00e4r\u00b7ti\u00b7gen", "Be\u00b7kann\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "O Leid um all die frischen K\u00fcss \u2013", "tokens": ["O", "Leid", "um", "all", "die", "fri\u00b7schen", "K\u00fcss", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "PIAT", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie hatte kein Erbarmen,", "tokens": ["Sie", "hat\u00b7te", "kein", "Er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Sie fluchte, schrie, und ach, sie ri\u00df", "tokens": ["Sie", "fluch\u00b7te", ",", "schrie", ",", "und", "ach", ",", "sie", "ri\u00df"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "KON", "XY", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sich los aus allen Armen!", "tokens": ["Sich", "los", "aus", "al\u00b7len", "Ar\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und mit dem Geld, das sie gewann", "tokens": ["Und", "mit", "dem", "Geld", ",", "das", "sie", "ge\u00b7wann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr saft'ge, goldne Fr\u00fcchte,", "tokens": ["F\u00fcr", "saft'\u00b7ge", ",", "gold\u00b7ne", "Fr\u00fcch\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Lief hurtig sie nach Hause dann", "tokens": ["Lief", "hur\u00b7tig", "sie", "nach", "Hau\u00b7se", "dann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "PPER", "APPR", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit zornigem Gesichte.", "tokens": ["Mit", "zor\u00b7ni\u00b7gem", "Ge\u00b7sich\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie nahm das Geld und schlo\u00df es ein;", "tokens": ["Sie", "nahm", "das", "Geld", "und", "schlo\u00df", "es", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und erst im Januare", "tokens": ["Und", "erst", "im", "Ja\u00b7nu\u00b7a\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Gen Irland sandte flink und fein", "tokens": ["Gen", "Ir\u00b7land", "sand\u00b7te", "flink", "und", "fein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das blanke sie und bare.", "tokens": ["Das", "blan\u00b7ke", "sie", "und", "ba\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u00bbdas ist f\u00fcr meines Volkes Heil,", "tokens": ["\u00bb", "das", "ist", "f\u00fcr", "mei\u00b7nes", "Vol\u00b7kes", "Heil", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das schenk ich euern Kassen!", "tokens": ["Das", "schenk", "ich", "eu\u00b7ern", "Kas\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf, sch\u00e4rft den S\u00e4bel und das Beil", "tokens": ["Auf", ",", "sch\u00e4rft", "den", "S\u00e4\u00b7bel", "und", "das", "Beil"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "$,", "VVFIN", "ART", "NN", "KON", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und sch\u00fcrt das alte Hassen!", "tokens": ["Und", "sch\u00fcrt", "das", "al\u00b7te", "Has\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wild \u00fcberwuchern m\u00f6chte gern", "tokens": ["Wild", "\u00fc\u00b7berw\u00b7uc\u00b7hern", "m\u00f6ch\u00b7te", "gern"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVINF", "VMFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Klee von Tipperary", "tokens": ["Den", "Klee", "von", "Tip\u00b7per\u00b7a\u00b7ry"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Die Rose England \u2013 gr\u00fc\u00dft den Herrn", "tokens": ["Die", "Ro\u00b7se", "En\u00b7gland", "\u2013", "gr\u00fc\u00dft", "den", "Herrn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$(", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "O'Connell von der Mary.\u00ab", "tokens": ["O'\u00b7Connell", "von", "der", "Ma\u00b7ry", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "ART", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}