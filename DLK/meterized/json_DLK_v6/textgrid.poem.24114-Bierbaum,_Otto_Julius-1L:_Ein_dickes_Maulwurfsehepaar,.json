{"textgrid.poem.24114": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein dickes Maulwurfsehepaar,", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein dickes Maulwurfsehepaar,", "tokens": ["Ein", "di\u00b7ckes", "Maul\u00b7wurf\u00b7se\u00b7he\u00b7paar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das gl\u00e4nzend schwarz wie Sammet war,", "tokens": ["Das", "gl\u00e4n\u00b7zend", "schwarz", "wie", "Sam\u00b7met", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJD", "KOKOM", "NE", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erfuhr Familienzuwachs. Froh", "tokens": ["Er\u00b7fuhr", "Fa\u00b7mi\u00b7li\u00b7en\u00b7zu\u00b7wachs", ".", "Froh"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "NN", "$.", "NN"], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Lag die Frau Maulwurf auf dem Stroh", "tokens": ["Lag", "die", "Frau", "Maul\u00b7wurf", "auf", "dem", "Stroh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "NN", "APPR", "ART", "NN"], "meter": "+-++-+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Und leckte jedes Junge", "tokens": ["Und", "leck\u00b7te", "je\u00b7des", "Jun\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mit ihrer schmalen Zunge.", "tokens": ["Mit", "ih\u00b7rer", "schma\u00b7len", "Zun\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Da rief sie pl\u00f6tzlich: \u00bbWunderlich,", "tokens": ["Da", "rief", "sie", "pl\u00f6tz\u00b7lich", ":", "\u00bb", "Wun\u00b7der\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$.", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir scheint, ich wei\u00df nicht, irr ich mich,", "tokens": ["Mir", "scheint", ",", "ich", "wei\u00df", "nicht", ",", "irr", "ich", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "$,", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mich d\u00fcnkts: Das Eine von den Drei'n,", "tokens": ["Mich", "d\u00fcnkts", ":", "Das", "Ei\u00b7ne", "von", "den", "Drei'n", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PDS", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das mu\u00df was ganz besondres sein.", "tokens": ["Das", "mu\u00df", "was", "ganz", "be\u00b7sond\u00b7res", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PWS", "ADV", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Leck du ihm doch mal auch das Fell!", "tokens": ["Leck", "du", "ihm", "doch", "mal", "auch", "das", "Fell", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PPER", "ADV", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht wahr: Das sp\u00fcrt sich an wie \u2013 hell!?\u00ab", "tokens": ["Nicht", "wahr", ":", "Das", "sp\u00fcrt", "sich", "an", "wie", "\u2013", "hell", "!?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PTKNEG", "PTKVZ", "$.", "PDS", "VVFIN", "PRF", "PTKVZ", "KOKOM", "$(", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Gatte brummte: \u00bbDummes Ding!", "tokens": ["Der", "Gat\u00b7te", "brumm\u00b7te", ":", "\u00bb", "Dum\u00b7mes", "Ding", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Red doch nicht wie ein Engerling!\u00ab", "tokens": ["Red", "doch", "nicht", "wie", "ein", "En\u00b7ger\u00b7ling", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "PTKNEG", "KOKOM", "ART", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Sie aber, spitzig: \u00bbLiebes Kind,", "tokens": ["Sie", "a\u00b7ber", ",", "spit\u00b7zig", ":", "\u00bb", "Lie\u00b7bes", "Kind", ","], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJD", "$.", "$(", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin doch wohl nicht zungenblind:", "tokens": ["Ich", "bin", "doch", "wohl", "nicht", "zun\u00b7gen\u00b7blind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Dritte, kleinste da, ist \u2013 wei\u00df!\u00ab", "tokens": ["Das", "Drit\u00b7te", ",", "kleins\u00b7te", "da", ",", "ist", "\u2013", "wei\u00df", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "ADV", "$,", "VAFIN", "$(", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbda\u00df ich dich in die Schaufel bei\u00df!\u00ab", "tokens": ["\u00bb", "da\u00df", "ich", "dich", "in", "die", "Schau\u00b7fel", "bei\u00df", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PRF", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zornwatschelnd kam er aus der Ecke,", "tokens": ["Zorn\u00b7wat\u00b7schelnd", "kam", "er", "aus", "der", "E\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hub an ein pr\u00fcfendes Gelecke,", "tokens": ["Hub", "an", "ein", "pr\u00fc\u00b7fen\u00b7des", "Ge\u00b7le\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "That \u00bbHem\u00ab und \u00bbHum\u00ab und knurrte dann:", "tokens": ["That", "\u00bb", "Hem", "\u00ab", "und", "\u00bb", "Hum", "\u00ab", "und", "knurr\u00b7te", "dann", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "KON", "$(", "NE", "$(", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdas leckt sich wirklich helle an.", "tokens": ["\u00bb", "das", "leckt", "sich", "wirk\u00b7lich", "hel\u00b7le", "an", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "PRF", "ADJD", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Wunder, scheint mir, ist geschehn,", "tokens": ["Ein", "Wun\u00b7der", ",", "scheint", "mir", ",", "ist", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich will Gro\u00dfvatern holen gehn.\u00ab", "tokens": ["Ich", "will", "Gro\u00df\u00b7va\u00b7tern", "ho\u00b7len", "gehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "NN", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Nahm einen dicken Engerling,", "tokens": ["Nahm", "ei\u00b7nen", "di\u00b7cken", "En\u00b7ger\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der in der Vorratskammer hing,", "tokens": ["Der", "in", "der", "Vor\u00b7rats\u00b7kam\u00b7mer", "hing", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Fra\u00df ihn befriedigt auf und ging.", "tokens": ["Fra\u00df", "ihn", "be\u00b7frie\u00b7digt", "auf", "und", "ging", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nach vielem W\u00fchlen kreuz und quer,", "tokens": ["Nach", "vie\u00b7lem", "W\u00fch\u00b7len", "kreuz", "und", "quer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bracht endlich er den Ahnen her.", "tokens": ["Bracht", "end\u00b7lich", "er", "den", "Ah\u00b7nen", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der sch\u00fcttelte den R\u00fcssel sehr", "tokens": ["Der", "sch\u00fct\u00b7tel\u00b7te", "den", "R\u00fcs\u00b7sel", "sehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und meinte, nie, so alt er w\u00e4re,", "tokens": ["Und", "mein\u00b7te", ",", "nie", ",", "so", "alt", "er", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hab er vernommen solche M\u00e4re.", "tokens": ["Hab", "er", "ver\u00b7nom\u00b7men", "sol\u00b7che", "M\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch, als geleckt der Maulwurfsgreis,", "tokens": ["Doch", ",", "als", "ge\u00b7leckt", "der", "Maul\u00b7wurfs\u00b7greis", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach er: \u00bbDer Junge da ist wei\u00df,\u00ab", "tokens": ["Sprach", "er", ":", "\u00bb", "Der", "Jun\u00b7ge", "da", "ist", "wei\u00df", ",", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$.", "$(", "ART", "NN", "ADV", "VAFIN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und sch\u00fcttelte noch mehr", "tokens": ["Und", "sch\u00fct\u00b7tel\u00b7te", "noch", "mehr"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Den R\u00fcssel hin und her.", "tokens": ["Den", "R\u00fcs\u00b7sel", "hin", "und", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Bald war im ganzen Land herum", "tokens": ["Bald", "war", "im", "gan\u00b7zen", "Land", "he\u00b7rum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPRART", "ADJA", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das seltsame Mirakulum;", "tokens": ["Das", "selt\u00b7sa\u00b7me", "Mi\u00b7ra\u00b7ku\u00b7lum", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gevatter und Gevatterin", "tokens": ["Ge\u00b7vat\u00b7ter", "und", "Ge\u00b7vat\u00b7te\u00b7rin"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Trug es gesch\u00e4ftig her und hin,", "tokens": ["Trug", "es", "ge\u00b7sch\u00e4f\u00b7tig", "her", "und", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Und schnell von Ferne und von Nah", "tokens": ["Und", "schnell", "von", "Fer\u00b7ne", "und", "von", "Nah"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Warn wispernd Gratulanten da.", "tokens": ["Warn", "wis\u00b7pernd", "Gra\u00b7tu\u00b7lan\u00b7ten", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das wei\u00dfe Fell ging fast entzwei", "tokens": ["Das", "wei\u00b7\u00dfe", "Fell", "ging", "fast", "ent\u00b7zwei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von allzu vieler Leckerei,", "tokens": ["Von", "all\u00b7zu", "vie\u00b7ler", "Le\u00b7cke\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PTKA", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und Mama Maulwurf schlo\u00df das Thor,", "tokens": ["Und", "Ma\u00b7ma", "Maul\u00b7wurf", "schlo\u00df", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Lie\u00df niemand mehr zum Lecken vor.", "tokens": ["Lie\u00df", "nie\u00b7mand", "mehr", "zum", "Le\u00b7cken", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Sie war ein wenig eitel schon", "tokens": ["Sie", "war", "ein", "we\u00b7nig", "ei\u00b7tel", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "PIS", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf diesen wei\u00dfgeborenen Sohn,", "tokens": ["Auf", "die\u00b7sen", "wei\u00df\u00b7ge\u00b7bo\u00b7re\u00b7nen", "Sohn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Und, wie nun schon die M\u00fctter sind,", "tokens": ["Und", ",", "wie", "nun", "schon", "die", "M\u00fct\u00b7ter", "sind", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ADV", "ADV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er wurde bald ihr H\u00e4tschelkind.", "tokens": ["Er", "wur\u00b7de", "bald", "ihr", "H\u00e4t\u00b7schel\u00b7kind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "So wuchs bewundert er heran", "tokens": ["So", "wuchs", "be\u00b7wun\u00b7dert", "er", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Wunderknaben zum Wundermann,", "tokens": ["Vom", "Wun\u00b7der\u00b7kna\u00b7ben", "zum", "Wun\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Augen rot, das Fell schneewei\u00df,", "tokens": ["Die", "Au\u00b7gen", "rot", ",", "das", "Fell", "schnee\u00b7wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Stolz war auf ihn der ganze Kreis.", "tokens": ["Stolz", "war", "auf", "ihn", "der", "gan\u00b7ze", "Kreis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Er selber aber zeigte sich", "tokens": ["Er", "sel\u00b7ber", "a\u00b7ber", "zeig\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Recht sonderbar und wunderlich:", "tokens": ["Recht", "son\u00b7der\u00b7bar", "und", "wun\u00b7der\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mocht ungern bei den andern sein,", "tokens": ["Mocht", "un\u00b7gern", "bei", "den", "an\u00b7dern", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sa\u00df tr\u00e4umend gern f\u00fcr sich allein;", "tokens": ["Sa\u00df", "tr\u00e4u\u00b7mend", "gern", "f\u00fcr", "sich", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "APPR", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zumal das W\u00fchlen schien ihm sehr", "tokens": ["Zu\u00b7mal", "das", "W\u00fch\u00b7len", "schien", "ihm", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verha\u00dft, wie wenn er kein Maulwurf w\u00e4r.", "tokens": ["Ver\u00b7ha\u00dft", ",", "wie", "wenn", "er", "kein", "Maul\u00b7wurf", "w\u00e4r", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOKOM", "KOUS", "PPER", "PIAT", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denn in den engen Winkelg\u00e4ngen", "tokens": ["Denn", "in", "den", "en\u00b7gen", "Win\u00b7kel\u00b7g\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Blieb ihm gar viel am Felle h\u00e4ngen,", "tokens": ["Blieb", "ihm", "gar", "viel", "am", "Fel\u00b7le", "h\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Das zu dem Wei\u00dfe gar nicht pa\u00dfte.", "tokens": ["Das", "zu", "dem", "Wei\u00b7\u00dfe", "gar", "nicht", "pa\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Es schien, da\u00df er das Erdreich ha\u00dfte.", "tokens": ["Es", "schien", ",", "da\u00df", "er", "das", "Er\u00b7dreich", "ha\u00df\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Das machte schon viel b\u00f6ses Blut:", "tokens": ["Das", "mach\u00b7te", "schon", "viel", "b\u00f6\u00b7ses", "Blut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbder Wei\u00dfe d\u00fcnkt sich wohl zu gut,", "tokens": ["\u00bb", "der", "Wei\u00b7\u00dfe", "d\u00fcnkt", "sich", "wohl", "zu", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "PRF", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr unsrer Heimat heiligen Dreck!?", "tokens": ["F\u00fcr", "uns\u00b7rer", "Hei\u00b7mat", "hei\u00b7li\u00b7gen", "Dreck", "!?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Der Frevler b\u00fcrstet sich ihn weg,", "tokens": ["Der", "Frev\u00b7ler", "b\u00fcrs\u00b7tet", "sich", "ihn", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Statt patriotisch ihn als Zier", "tokens": ["Statt", "pat\u00b7ri\u00b7o\u00b7tisch", "ihn", "als", "Zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "PPER", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Im Fell zu tragen, so wie wir!", "tokens": ["Im", "Fell", "zu", "tra\u00b7gen", ",", "so", "wie", "wir", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$,", "ADV", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Entartung ist sein wei\u00dfes Fell!", "tokens": ["Ent\u00b7ar\u00b7tung", "ist", "sein", "wei\u00b7\u00dfes", "Fell", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er ist uns \u00fcberhaupt zu hell.\u00ab", "tokens": ["Er", "ist", "uns", "\u00fc\u00b7ber\u00b7haupt", "zu", "hell", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So hob es mit Gemurmel an,", "tokens": ["So", "hob", "es", "mit", "Ge\u00b7mur\u00b7mel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Doch ein Geknurre wurd es dann,", "tokens": ["Doch", "ein", "Ge\u00b7knur\u00b7re", "wurd", "es", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Als stolz der Wei\u00dfe widersprach.", "tokens": ["Als", "stolz", "der", "Wei\u00b7\u00dfe", "wi\u00b7der\u00b7sprach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Auch warf man ihm schon Klumpen nach.", "tokens": ["Auch", "warf", "man", "ihm", "schon", "Klum\u00b7pen", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Da blieb er immer mehr f\u00fcr sich,", "tokens": ["Da", "blieb", "er", "im\u00b7mer", "mehr", "f\u00fcr", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gemieden und absonderlich.", "tokens": ["Ge\u00b7mie\u00b7den", "und", "ab\u00b7son\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und eines Tags, da f\u00fchlte er,", "tokens": ["Und", "ei\u00b7nes", "Tags", ",", "da", "f\u00fchl\u00b7te", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er am falschen Platze w\u00e4r.", "tokens": ["Da\u00df", "er", "am", "fal\u00b7schen", "Plat\u00b7ze", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Heraus! Hinauf! Zu gro\u00df der Drang!", "tokens": ["He\u00b7raus", "!", "Hin\u00b7auf", "!", "Zu", "gro\u00df", "der", "Drang", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "$.", "PTKA", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er baute einen eignen Gang.", "tokens": ["Er", "bau\u00b7te", "ei\u00b7nen", "eig\u00b7nen", "Gang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und nicht hinab und nicht quer um,", "tokens": ["Und", "nicht", "hin\u00b7ab", "und", "nicht", "quer", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PTKVZ", "KON", "PTKNEG", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Nein: grad hinauf! Das Publikum", "tokens": ["Nein", ":", "grad", "hin\u00b7auf", "!", "Das", "Pub\u00b7li\u00b7kum"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$.", "ADV", "PTKVZ", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Stand halb entsetzt, halb h\u00f6hnisch da,", "tokens": ["Stand", "halb", "ent\u00b7setzt", ",", "halb", "h\u00f6h\u00b7nisch", "da", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als es den steilen Aufstieg sah:", "tokens": ["Als", "es", "den", "stei\u00b7len", "Auf\u00b7stieg", "sah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "\u00bbwart, B\u00fcrschchen, das bekommt dir schlecht,", "tokens": ["\u00bb", "wart", ",", "B\u00fcr\u00b7schchen", ",", "das", "be\u00b7kommt", "dir", "schlecht", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "PDS", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Der Augenschmerz geschieht dir recht,", "tokens": ["Der", "Au\u00b7gen\u00b7schmerz", "ge\u00b7schieht", "dir", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Wenn oben dich die Sonne bei\u00dft,", "tokens": ["Wenn", "o\u00b7ben", "dich", "die", "Son\u00b7ne", "bei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Du warst zum letzten Male dreist!\u00ab", "tokens": ["Du", "warst", "zum", "letz\u00b7ten", "Ma\u00b7le", "dreist", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Vergn\u00fcglich harrten Alle", "tokens": ["Ver\u00b7gn\u00fcg\u00b7lich", "harr\u00b7ten", "Al\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da\u00df er herunter falle", "tokens": ["Da\u00df", "er", "her\u00b7un\u00b7ter", "fal\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und winsle; \u00bbAch, das Licht thut weh,", "tokens": ["Und", "wins\u00b7le", ";", "\u00bb", "Ach", ",", "das", "Licht", "thut", "weh", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ITJ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich steige nie mehr in die H\u00f6h!\u00ab", "tokens": ["Ich", "stei\u00b7ge", "nie", "mehr", "in", "die", "H\u00f6h", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Er aber, wie von Freude toll,", "tokens": ["Er", "a\u00b7ber", ",", "wie", "von", "Freu\u00b7de", "toll", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Rief: \u00bbBr\u00fcder, kommt! So wundervoll,", "tokens": ["Rief", ":", "\u00bb", "Br\u00fc\u00b7der", ",", "kommt", "!", "So", "wun\u00b7der\u00b7voll", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "$,", "VVFIN", "$.", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie nie ichs tr\u00e4umte, ist es hier,", "tokens": ["Wie", "nie", "ichs", "tr\u00e4um\u00b7te", ",", "ist", "es", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIS", "VVFIN", "$,", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt, kommt zum Licht, ach, kommt zu mir!", "tokens": ["Kommt", ",", "kommt", "zum", "Licht", ",", "ach", ",", "kommt", "zu", "mir", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "APPRART", "NN", "$,", "ITJ", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich hab das Gl\u00fcck, das Gl\u00fcck gefunden,", "tokens": ["Ich", "hab", "das", "Gl\u00fcck", ",", "das", "Gl\u00fcck", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und ihr lebt in der H\u00f6lle unten!", "tokens": ["Und", "ihr", "lebt", "in", "der", "H\u00f6l\u00b7le", "un\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Mir nach, mir nach, mir nach zum Licht!", "tokens": ["Mir", "nach", ",", "mir", "nach", ",", "mir", "nach", "zum", "Licht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PPER", "PTKVZ", "$,", "PPER", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kommt alle, kommt und zaudert nicht!\u00ab", "tokens": ["Kommt", "al\u00b7le", ",", "kommt", "und", "zau\u00b7dert", "nicht", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "$,", "VVFIN", "KON", "VVFIN", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Wie das der schwarze Schwarm vernahm,", "tokens": ["Wie", "das", "der", "schwar\u00b7ze", "Schwarm", "ver\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jachhei\u00dfe Wut ihn \u00fcberkam:", "tokens": ["Jach\u00b7hei\u00b7\u00dfe", "Wut", "ihn", "\u00fc\u00b7ber\u00b7kam", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbherunter mit dem Galgenstrick!", "tokens": ["\u00bb", "her\u00b7un\u00b7ter", "mit", "dem", "Gal\u00b7gen\u00b7strick", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Herunter! Brecht ihm das Genick!\u00ab", "tokens": ["Her\u00b7un\u00b7ter", "!", "Brecht", "ihm", "das", "Ge\u00b7nick", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "NN", "PPER", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "\u00bbkommt, kommt zum Licht! Oh, kommt zu mir!\u00ab", "tokens": ["\u00bb", "kommt", ",", "kommt", "zum", "Licht", "!", "Oh", ",", "kommt", "zu", "mir", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "APPRART", "NN", "$.", "ITJ", "$,", "VVFIN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u00bbja, warte nur! Wir kommen dir!\u00ab", "tokens": ["\u00bb", "ja", ",", "war\u00b7te", "nur", "!", "Wir", "kom\u00b7men", "dir", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und w\u00e4hrend er begeistert schrie,", "tokens": ["Und", "w\u00e4h\u00b7rend", "er", "be\u00b7geis\u00b7tert", "schrie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da gruben sie und w\u00fchlten sie", "tokens": ["Da", "gru\u00b7ben", "sie", "und", "w\u00fchl\u00b7ten", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Viel krumme G\u00e4nge zu ihm hin", "tokens": ["Viel", "krum\u00b7me", "G\u00e4n\u00b7ge", "zu", "ihm", "hin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "APPR", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und packten ihn und zerrten ihn \u2013", "tokens": ["Und", "pack\u00b7ten", "ihn", "und", "zerr\u00b7ten", "ihn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hinab. Und haben sein Fell zerfetzt", "tokens": ["Hin\u00b7ab", ".", "Und", "ha\u00b7ben", "sein", "Fell", "zer\u00b7fetzt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "KON", "VAFIN", "PPOSAT", "NN", "VVPP"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und totgebissen ihn zuletzt.", "tokens": ["Und", "tot\u00b7ge\u00b7bis\u00b7sen", "ihn", "zu\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Da lag der Wei\u00dfe still im Dreck,", "tokens": ["Da", "lag", "der", "Wei\u00b7\u00dfe", "still", "im", "Dreck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Befriedigt trollten die Schwarzen weg", "tokens": ["Be\u00b7frie\u00b7digt", "troll\u00b7ten", "die", "Schwar\u00b7zen", "weg"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "VVFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und fra\u00dfen viele Engerlinge", "tokens": ["Und", "fra\u00b7\u00dfen", "vie\u00b7le", "En\u00b7ger\u00b7lin\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und waren zufrieden und guter Dinge.", "tokens": ["Und", "wa\u00b7ren", "zu\u00b7frie\u00b7den", "und", "gu\u00b7ter", "Din\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.23": {"line.1": {"text": "Doch, da\u00df die Nachwelt einst erfahr,", "tokens": ["Doch", ",", "da\u00df", "die", "Nach\u00b7welt", "einst", "er\u00b7fahr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mal ein wei\u00dfer Maulwurf war,", "tokens": ["Da\u00df", "mal", "ein", "wei\u00b7\u00dfer", "Maul\u00b7wurf", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zum Beweis das Fell erseh,", "tokens": ["Und", "zum", "Be\u00b7weis", "das", "Fell", "er\u00b7seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bildeten sie ein Komitee:", "tokens": ["Bil\u00b7de\u00b7ten", "sie", "ein", "Ko\u00b7mi\u00b7tee", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "\u00bbzu des wei\u00dfen Vlie\u00dfes Konservierung.\u00ab", "tokens": ["\u00bb", "zu", "des", "wei\u00b7\u00dfen", "Vlie\u00b7\u00dfes", "Kon\u00b7ser\u00b7vie\u00b7rung", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "ART", "ADJA", "NN", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.24": {"line.1": {"text": "Das erfand eine praktische Balsamierung,", "tokens": ["Das", "er\u00b7fand", "ei\u00b7ne", "prak\u00b7ti\u00b7sche", "Bal\u00b7sa\u00b7mie\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und des Maulwurfreiches wei\u00dfer Sohn", "tokens": ["Und", "des", "Maul\u00b7wur\u00b7frei\u00b7ches", "wei\u00b7\u00dfer", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ward beigesetzt im Pantheon.", "tokens": ["Ward", "bei\u00b7ge\u00b7setzt", "im", "Pan\u00b7the\u00b7on", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}