{"textgrid.poem.66141": {"metadata": {"author": {"name": "Schubart, Christian Friedrich Daniel", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vom Tobaksgotte Telesphor", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vom Tobaksgotte Telesphor", "tokens": ["Vom", "To\u00b7baks\u00b7got\u00b7te", "Te\u00b7les\u00b7phor"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Unterschriebner Kopf und Rohr,", "tokens": ["Hat", "Un\u00b7ter\u00b7schrieb\u00b7ner", "Kopf", "und", "Rohr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch Ulmer Stahl und Schwamm und Stein,", "tokens": ["Auch", "Ul\u00b7mer", "Stahl", "und", "Schwamm", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nebst einem Tobak extrafein", "tokens": ["Nebst", "ei\u00b7nem", "To\u00b7bak", "ext\u00b7ra\u00b7fein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Empfangen durch der Freunde Hand.", "tokens": ["Emp\u00b7fan\u00b7gen", "durch", "der", "Freun\u00b7de", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist Rath \u2013 doch Biedermann ist mehr;", "tokens": ["Ist", "Rath", "\u2013", "doch", "Bie\u00b7der\u00b7mann", "ist", "mehr", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$(", "KON", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Drum hat er so viel Fett und Schmeer.", "tokens": ["Drum", "hat", "er", "so", "viel", "Fett", "und", "Schmeer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der andre, ", "tokens": ["Der", "and\u00b7re", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "PIS", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ist gar ein hochber\u00fchmter Mann,", "tokens": ["Ist", "gar", "ein", "hoch\u00b7be\u00b7r\u00fchm\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der B\u00fcchlein schreibt so fein und zart,", "tokens": ["Der", "B\u00fcch\u00b7lein", "schreibt", "so", "fein", "und", "zart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Da\u00df einem 's Wasser l\u00e4uft in Bart.", "tokens": ["Da\u00df", "ei\u00b7nem", "'s", "Was\u00b7ser", "l\u00e4uft", "in", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Der dritte, der j\u00fcngst bei mir war,", "tokens": ["Der", "drit\u00b7te", ",", "der", "j\u00fcngst", "bei", "mir", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "ADV", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Hei\u00dft ", "tokens": ["Hei\u00dft"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.14": {"text": "Empfindsam ist das Herzlein sein,", "tokens": ["Emp\u00b7find\u00b7sam", "ist", "das", "Herz\u00b7lein", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Drum liebt ihn auch manch's M\u00e4del fein.", "tokens": ["Drum", "liebt", "ihn", "auch", "man\u00b7ch's", "M\u00e4\u00b7del", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PIS", "NN", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Mit vielem Danke dies testirt", "tokens": ["Mit", "vie\u00b7lem", "Dan\u00b7ke", "dies", "tes\u00b7tirt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "PTKANT", "PDS", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Mit Brief und Namen \u2013 unpetschirt,", "tokens": ["Mit", "Brief", "und", "Na\u00b7men", "\u2013", "un\u00b7pet\u00b7schirt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Denn ein Gefangner siegelt nicht", "tokens": ["Denn", "ein", "Ge\u00b7fang\u00b7ner", "sie\u00b7gelt", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Mit Lack \u2013 weil Thr\u00e4nen vom Gesicht", "tokens": ["Mit", "Lack", "\u2013", "weil", "Thr\u00e4\u00b7nen", "vom", "Ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "KOUS", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ihm tr\u00f6pfeln statt des Siegelwachs.", "tokens": ["Ihm", "tr\u00f6p\u00b7feln", "statt", "des", "Sie\u00b7gel\u00b7wachs", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}