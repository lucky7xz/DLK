{"textgrid.poem.53371": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mv\u00df der Mensch nicht stets in Pein", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mv\u00df der Mensch nicht stets in Pein", "tokens": ["Mv\u00df", "der", "Mensch", "nicht", "stets", "in", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "PTKNEG", "ADV", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd in Streit auff Erden seyn?", "tokens": ["Vnd", "in", "Streit", "auff", "Er\u00b7den", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "APPR", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind nicht seine Tage", "tokens": ["Sind", "nicht", "sei\u00b7ne", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "PPOSAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Eines Tagel\u00f6hners gleich?", "tokens": ["Ei\u00b7nes", "Ta\u00b7ge\u00b7l\u00f6h\u00b7ners", "gleich", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er sey d\u00fcrfftig oder reich", "tokens": ["Er", "sey", "d\u00fcr\u00b7ff\u00b7tig", "o\u00b7der", "reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn trifft seine Plage.", "tokens": ["Ihn", "trifft", "sei\u00b7ne", "Pla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Ein Soldat im Krieges-Heer", "tokens": ["Ein", "Sol\u00b7dat", "im", "Krie\u00b7ge\u00b7sHeer"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat es besser weder er,", "tokens": ["Hat", "es", "bes\u00b7ser", "we\u00b7der", "er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "KON", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn er ruht zu zeiten,", "tokens": ["Denn", "er", "ruht", "zu", "zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dieser nie, was ist sein Feld?", "tokens": ["Die\u00b7ser", "nie", ",", "was", "ist", "sein", "Feld", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "$,", "PWS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mit der gantzen b\u00f6sen Welt", "tokens": ["Mit", "der", "gant\u00b7zen", "b\u00f6\u00b7sen", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat der Mensch zu streiten.", "tokens": ["Hat", "der", "Mensch", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Jenes Feind ist eusserlich", "tokens": ["Je\u00b7nes", "Feind", "ist", "eus\u00b7ser\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser k\u00e4mpfft erst selbst mit sich,", "tokens": ["Die\u00b7ser", "k\u00e4mpfft", "erst", "selbst", "mit", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "APPR", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sucht sein Hertz zu meistern,", "tokens": ["Sucht", "sein", "Hertz", "zu", "meis\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nachmals mit der Hellen-Klufft", "tokens": ["Nach\u00b7mals", "mit", "der", "Hel\u00b7len\u00b7Klufft"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mehr, auch droben in der Lufft", "tokens": ["Mehr", ",", "auch", "dro\u00b7ben", "in", "der", "Lufft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "$,", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit den b\u00f6sen Geistern.", "tokens": ["Mit", "den", "b\u00f6\u00b7sen", "Geis\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Vbergeh' ich Gl\u00fcck und Fall", "tokens": ["Vber\u00b7geh'", "ich", "Gl\u00fcck", "und", "Fall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Vnd was st\u00fcrmet \u00fcberall?", "tokens": ["Vnd", "was", "st\u00fcr\u00b7met", "\u00fc\u00b7be\u00b7rall", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was uns von dem Morgen", "tokens": ["Was", "uns", "von", "dem", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "An bis in die Nachtzeit kr\u00e4nckt,", "tokens": ["An", "bis", "in", "die", "Nacht\u00b7zeit", "kr\u00e4nckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vnd die niemand gnug bedenckt", "tokens": ["Vnd", "die", "nie\u00b7mand", "gnug", "be\u00b7denckt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "PIS", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit viel tausent Sorgen?", "tokens": ["Mit", "viel", "tau\u00b7sent", "Sor\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "CARD", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Wider solcher Arbeit Noht", "tokens": ["Wi\u00b7der", "sol\u00b7cher", "Ar\u00b7beit", "Noht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist kein Mittel als der Tod,", "tokens": ["Ist", "kein", "Mit\u00b7tel", "als", "der", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber ist zu k\u00e4mpffen", "tokens": ["A\u00b7ber", "ist", "zu", "k\u00e4mpf\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Je gewesen, so ist dann,", "tokens": ["Je", "ge\u00b7we\u00b7sen", ",", "so", "ist", "dann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAPP", "$,", "ADV", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn zuletzt der Todten-Mann", "tokens": ["Wenn", "zu\u00b7letzt", "der", "Tod\u00b7ten\u00b7Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ubrig ist zu d\u00e4mpfen.", "tokens": ["Ub\u00b7rig", "ist", "zu", "d\u00e4mp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "O wie he\u00dflich siehet aus", "tokens": ["O", "wie", "he\u00df\u00b7lich", "sie\u00b7het", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADJD", "VVFIN", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Er, sein Grab, das Knochen-Hau\u00df,", "tokens": ["Er", ",", "sein", "Grab", ",", "das", "Kno\u00b7chen\u00b7Hau\u00df", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was ist dann zu leiden?", "tokens": ["Was", "ist", "dann", "zu", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Wenn das Hertz nicht Kr\u00e4ffte wei\u00df", "tokens": ["Wenn", "das", "Hertz", "nicht", "Kr\u00e4ff\u00b7te", "wei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und uns netzt der Todes-Schwei\u00df,", "tokens": ["Und", "uns", "netzt", "der", "To\u00b7des\u00b7Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Seel und Leib sich scheiden.", "tokens": ["Seel", "und", "Leib", "sich", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Aber \u00fcber selig weit", "tokens": ["A\u00b7ber", "\u00fc\u00b7ber", "se\u00b7lig", "weit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind die Todten allerseit", "tokens": ["Sind", "die", "Tod\u00b7ten", "al\u00b7ler\u00b7seit"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die im Herren sterben,", "tokens": ["Die", "im", "Her\u00b7ren", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Denn der Geist bejaht, da\u00df sie", "tokens": ["Denn", "der", "Geist", "be\u00b7jaht", ",", "da\u00df", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "$,", "KOUS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Von der schweren Arbeit hie", "tokens": ["Von", "der", "schwe\u00b7ren", "Ar\u00b7beit", "hie"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Erst die Rhu erwerben.", "tokens": ["Erst", "die", "Rhu", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Auch sind ihre Wercke wach,", "tokens": ["Auch", "sind", "ih\u00b7re", "Wer\u00b7cke", "wach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn sie folgen ihnen nach,", "tokens": ["Denn", "sie", "fol\u00b7gen", "ih\u00b7nen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr Gebeht in N\u00f6hten", "tokens": ["Ihr", "Ge\u00b7beht", "in", "N\u00f6h\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ihre Lieb' ihr Glaubens-Schein", "tokens": ["Ih\u00b7re", "Lieb'", "ihr", "Glau\u00b7bens\u00b7Schein"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sampt Gedult und Hoffnung seyn", "tokens": ["Sampt", "Ge\u00b7dult", "und", "Hoff\u00b7nung", "seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was kein Tod kan t\u00f6dten.", "tokens": ["Was", "kein", "Tod", "kan", "t\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Da\u00df wir keines Kampffes schew", "tokens": ["Da\u00df", "wir", "kei\u00b7nes", "Kampf\u00b7fes", "schew"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tragen, steh, o Gott, uns bey,", "tokens": ["Tra\u00b7gen", ",", "steh", ",", "o", "Gott", ",", "uns", "bey", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "FM", "NN", "$,", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch des Geistes Waffen,", "tokens": ["Durch", "des", "Geis\u00b7tes", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Thu uns sanfft die Augen zu,", "tokens": ["Thu", "uns", "sanfft", "die", "Au\u00b7gen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Damit wir in stoltzer Rhu", "tokens": ["Da\u00b7mit", "wir", "in", "stolt\u00b7zer", "Rhu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nach der Arbeit schlaffen.", "tokens": ["Nach", "der", "Ar\u00b7beit", "schlaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}