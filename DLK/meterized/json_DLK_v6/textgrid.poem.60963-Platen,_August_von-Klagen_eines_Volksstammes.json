{"textgrid.poem.60963": {"metadata": {"author": {"name": "Platen, August von", "birth": "N.A.", "death": "N.A."}, "title": "Klagen eines Volksstammes", "genre": "verse", "period": "N.A.", "pub_year": 1815, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich hatte manchen wackern Sohn,", "tokens": ["Ich", "hat\u00b7te", "man\u00b7chen", "wa\u00b7ckern", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der liegt nun auf der Bahre;", "tokens": ["Der", "liegt", "nun", "auf", "der", "Bah\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er starb f\u00fcr Vaterland und Thron,", "tokens": ["Er", "starb", "f\u00fcr", "Va\u00b7ter\u00b7land", "und", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die mir verhie\u00dfen gro\u00dfen Lohn:", "tokens": ["Die", "mir", "ver\u00b7hie\u00b7\u00dfen", "gro\u00b7\u00dfen", "Lohn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wartete f\u00fcnfzehn Jahre.", "tokens": ["Ich", "war\u00b7te\u00b7te", "f\u00fcnf\u00b7zehn", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Doch nimmer kam der Tag herbei,", "tokens": ["Doch", "nim\u00b7mer", "kam", "der", "Tag", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu gr\u00fcnden meine Rechte:", "tokens": ["Zu", "gr\u00fcn\u00b7den", "mei\u00b7ne", "Rech\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des F\u00fcrsten Rat, von Eiden frei,", "tokens": ["Des", "F\u00fcrs\u00b7ten", "Rat", ",", "von", "Ei\u00b7den", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verriet mich an die Mongolei", "tokens": ["Ver\u00b7riet", "mich", "an", "die", "Mon\u00b7go\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und stempelte mich zum Knechte!", "tokens": ["Und", "stem\u00b7pel\u00b7te", "mich", "zum", "Knech\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Da ward mit allzu keckem Mut", "tokens": ["Da", "ward", "mit", "all\u00b7zu", "ke\u00b7ckem", "Mut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PTKA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Bund geschlossen eilig,", "tokens": ["Ein", "Bund", "ge\u00b7schlos\u00b7sen", "ei\u00b7lig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Besiegelt auch durch Griechenblut:", "tokens": ["Be\u00b7sie\u00b7gelt", "auch", "durch", "Grie\u00b7chen\u00b7blut", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meineide galten ihm f\u00fcr gut,", "tokens": ["Mei\u00b7nei\u00b7de", "gal\u00b7ten", "ihm", "f\u00fcr", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ja, Tyrannei f\u00fcr heilig!", "tokens": ["Ja", ",", "Ty\u00b7ran\u00b7nei", "f\u00fcr", "hei\u00b7lig", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "APPR", "ADJD", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}}, "stanza.4": {"line.1": {"text": "O F\u00fcrst, an eignem Volke reich,", "tokens": ["O", "F\u00fcrst", ",", "an", "eig\u00b7nem", "Vol\u00b7ke", "reich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "APPR", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was k\u00fcmmern dich Kalm\u00fccken?", "tokens": ["Was", "k\u00fcm\u00b7mern", "dich", "Kal\u00b7m\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gehuldigt h\u00e4tte dir sogleich", "tokens": ["Ge\u00b7hul\u00b7digt", "h\u00e4t\u00b7te", "dir", "sog\u00b7leich"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Jahren einst das Deutsche Reich;", "tokens": ["Vor", "Jah\u00b7ren", "einst", "das", "Deut\u00b7sche", "Reich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nun kehrt es dir den R\u00fccken.", "tokens": ["Nun", "kehrt", "es", "dir", "den", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du konntest schlichten jeden Streit", "tokens": ["Du", "konn\u00b7test", "schlich\u00b7ten", "je\u00b7den", "Streit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf da\u00df die Freiheit siege;", "tokens": ["Auf", "da\u00df", "die", "Frei\u00b7heit", "sie\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Nun aber drohn, durch dich entzweit,", "tokens": ["Nun", "a\u00b7ber", "drohn", ",", "durch", "dich", "ent\u00b7zweit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$,", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Vaterland Zerrissenheit", "tokens": ["Dem", "Va\u00b7ter\u00b7land", "Zer\u00b7ris\u00b7sen\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und drei\u00dfigj\u00e4hrige Kriege.", "tokens": ["Und", "drei\u00b7\u00dfig\u00b7j\u00e4h\u00b7ri\u00b7ge", "Krie\u00b7ge", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Wohl sahn in f\u00fcnfzehn Jahren wir", "tokens": ["Wohl", "sahn", "in", "f\u00fcnf\u00b7zehn", "Jah\u00b7ren", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "CARD", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geschehn so viele Zeichen,", "tokens": ["Ge\u00b7schehn", "so", "vie\u00b7le", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und jedes rief: O folge mir!", "tokens": ["Und", "je\u00b7des", "rief", ":", "O", "fol\u00b7ge", "mir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "$.", "NE", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch kr\u00e4ftiger schien die Knute dir", "tokens": ["Doch", "kr\u00e4f\u00b7ti\u00b7ger", "schien", "die", "Knu\u00b7te", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Als St\u00e4be deutscher Eichen!", "tokens": ["Als", "St\u00e4\u00b7be", "deut\u00b7scher", "Ei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Der Bund, den jedes Herz verwarf,", "tokens": ["Der", "Bund", ",", "den", "je\u00b7des", "Herz", "ver\u00b7warf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie lange soll er w\u00e4hren?", "tokens": ["Wie", "lan\u00b7ge", "soll", "er", "w\u00e4h\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn f\u00fcrder ich nicht klagen darf,", "tokens": ["Wenn", "f\u00fcr\u00b7der", "ich", "nicht", "kla\u00b7gen", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mach ich meine Klinge scharf", "tokens": ["So", "mach", "ich", "mei\u00b7ne", "Klin\u00b7ge", "scharf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und trockne meine Z\u00e4hren.", "tokens": ["Und", "trock\u00b7ne", "mei\u00b7ne", "Z\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}