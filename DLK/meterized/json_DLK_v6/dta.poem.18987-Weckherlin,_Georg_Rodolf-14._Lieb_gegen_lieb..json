{"dta.poem.18987": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "14.  \n  Lieb gegen lieb.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Demnach mich Amor selbs nu mehr ein lange", "tokens": ["Dem\u00b7nach", "mich", "A\u00b7mor", "selbs", "nu", "mehr", "ein", "lan\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PRF", "NE", "ADV", "ADV", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zeit", "tokens": ["Zeit"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Gez\u00fcchtiget/ vnd recht zu kriegen vnderrichtet/", "tokens": ["Ge\u00b7z\u00fcch\u00b7ti\u00b7get", "/", "vnd", "recht", "zu", "krie\u00b7gen", "vn\u00b7der\u00b7rich\u00b7tet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "KON", "ADJD", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat endlich sich mein muht/ mein lang-erw\u00fcnsch-", "tokens": ["Hat", "end\u00b7lich", "sich", "mein", "muht", "/", "mein", "lang\u00b7er\u00b7w\u00fcn\u00b7sch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "PRF", "PPOSAT", "VVFIN", "$(", "PPOSAT", "TRUNC"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "te beut/", "tokens": ["te", "beut", "/"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Oder den sch\u00f6nsten tod zuerwerben/ verpflichtet.", "tokens": ["O\u00b7der", "den", "sch\u00f6ns\u00b7ten", "tod", "zu\u00b7er\u00b7wer\u00b7ben", "/", "ver\u00b7pflich\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF", "$(", "VVPP", "$."], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Darumb als in dem feld sich Myrta/ nicht mehr weit", "tokens": ["Da\u00b7rumb", "als", "in", "dem", "feld", "sich", "Myr\u00b7ta", "/", "nicht", "mehr", "weit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "KOKOM", "APPR", "ART", "NN", "PRF", "NE", "$(", "PTKNEG", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von mir/ forchtlo\u00df befand/ vn\u0304 newe list erdichtet/", "tokens": ["Von", "mir", "/", "forcht\u00b7lo\u00df", "be\u00b7fand", "/", "vn\u0304", "ne\u00b7we", "list", "er\u00b7dich\u00b7tet", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$(", "ADV", "VVFIN", "$(", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "--++-++--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hab/ wie sie wider mich/ ich wider Sie (den streit", "tokens": ["Hab", "/", "wie", "sie", "wi\u00b7der", "mich", "/", "ich", "wi\u00b7der", "Sie", "(", "den", "streit"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$(", "PWAV", "PPER", "APPR", "PPER", "$(", "PPER", "APPR", "PPER", "$(", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Anfangend) die gescho\u00df d\u2019 anblick stracks gerichtet.", "tokens": ["An\u00b7fan\u00b7gend", ")", "die", "ge\u00b7scho\u00df", "d'", "an\u00b7blick", "stracks", "ge\u00b7rich\u00b7tet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "ART", "NN", "NE", "NE", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Das treffen war sehr gro\u00df. Dan jhrer augen blick", "tokens": ["Das", "tref\u00b7fen", "war", "sehr", "gro\u00df", ".", "Dan", "jhrer", "au\u00b7gen", "blick"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVINF", "VAFIN", "ADV", "ADJD", "$.", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Nicht nur wie pfeil vnd plitz/ sondern wie grosse", "tokens": ["Nicht", "nur", "wie", "pfeil", "vnd", "plitz", "/", "son\u00b7dern", "wie", "gros\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "KOKOM", "NN", "KON", "NE", "$(", "KON", "PWAV", "ADJA"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "st\u00fcck/", "tokens": ["st\u00fcck", "/"], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$("], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Zerschmetterten mein hertz/ vorhin voll taussent", "tokens": ["Zer\u00b7schmet\u00b7ter\u00b7ten", "mein", "hertz", "/", "vor\u00b7hin", "voll", "taus\u00b7sent"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$(", "ADV", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wunden.", "tokens": ["wun\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["ADJA", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.4": {"line.1": {"text": "Endlich hat meine kunst vn\u0304 m\u00fch den weeg gefunden/", "tokens": ["End\u00b7lich", "hat", "mei\u00b7ne", "kunst", "vn\u0304", "m\u00fch", "den", "weeg", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "KON", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da\u00df/ wie Mein/ so jhr hertz/ numehr mit gleichem", "tokens": ["Da\u00df", "/", "wie", "Mein", "/", "so", "jhr", "hertz", "/", "nu\u00b7mehr", "mit", "glei\u00b7chem"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "$(", "KOKOM", "PPOSAT", "$(", "ADV", "PPOSAT", "NN", "$(", "ADV", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "glick", "tokens": ["glick"], "token_info": ["word"], "pos": ["XY"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Verwundet/ sich ergab/ sigreich vnd vberwunden.", "tokens": ["Ver\u00b7wun\u00b7det", "/", "sich", "er\u00b7gab", "/", "sig\u00b7reich", "vnd", "vber\u00b7wun\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "PRF", "VVFIN", "$(", "ADJD", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}}}}