{"dta.poem.2371": {"metadata": {"author": {"name": "Neumark, Georg", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1652", "urn": "urn:nbn:de:kobv:b4-20428-0", "language": ["de:0.99"], "booktitle": "Neumark, Georg: Poetisch- und Musikalisches Lustw\u00e4ldchen. Hamburg, 1652."}, "poem": {"stanza.1": {"line.1": {"text": "Es fieng ein Sch\u00e4fer an zu klagen/", "tokens": ["Es", "fi\u00b7eng", "ein", "Sch\u00e4\u00b7fer", "an", "zu", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie seines Hertzens treue Gunst/", "tokens": ["Wie", "sei\u00b7nes", "Hert\u00b7zens", "treu\u00b7e", "Gunst", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von Karitillen dieser Tagen/", "tokens": ["Von", "Ka\u00b7ri\u00b7til\u00b7len", "die\u00b7ser", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gehalten w\u00fcrde fast \u00fcmsonst.", "tokens": ["Ge\u00b7hal\u00b7ten", "w\u00fcr\u00b7de", "fast", "\u00fcm\u00b7sonst", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Thr\u00e4nenwasser von ihm randte/", "tokens": ["Das", "Thr\u00e4\u00b7nen\u00b7was\u00b7ser", "von", "ihm", "rand\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Weil Sie ihn nicht vor treu erkante.", "tokens": ["Weil", "Sie", "ihn", "nicht", "vor", "treu", "er\u00b7kan\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "APPR", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Er lie\u00df die Schaf' alleine weiden/", "tokens": ["Er", "lie\u00df", "die", "Schaf'", "al\u00b7lei\u00b7ne", "wei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sagt\u2019: ", "tokens": ["Sagt'", ":"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Mich zwingt von dir mein ", "tokens": ["Mich", "zwingt", "von", "dir", "mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPOSAT"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Damit gieng Er dem Walde zu/", "tokens": ["Da\u00b7mit", "gieng", "Er", "dem", "Wal\u00b7de", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "PTKZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein Hertze/ sagt\u2019 ", "tokens": ["Sein", "Hert\u00b7ze", "/", "sagt'"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPOSAT", "VVFIN", "$(", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Da\u00df Er kaum wust' ein Wort zu sprechen.", "tokens": ["Da\u00df", "Er", "kaum", "wust'", "ein", "Wort", "zu", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Mir d\u00fcnkt di\u00df waren seine Worte/", "tokens": ["Mir", "d\u00fcnkt", "di\u00df", "wa\u00b7ren", "sei\u00b7ne", "Wor\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ", "tokens": ["So"], "token_info": ["word"], "pos": ["ADV"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "An einem Bach\u2019 am w\u00fcsten Ohrte/", "tokens": ["An", "ei\u00b7nem", "Bach'", "am", "w\u00fcs\u00b7ten", "Ohr\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der \u00e4hnlich war der schwartzen Nacht:", "tokens": ["Der", "\u00e4hn\u00b7lich", "war", "der", "schwart\u00b7zen", "Nacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "H\u00f6rt zu ihr B\u00fcsch\u2019 ihr W\u00fcsteneyen/", "tokens": ["H\u00f6rt", "zu", "ihr", "B\u00fcsch'", "ihr", "W\u00fcs\u00b7te\u00b7ne\u00b7yen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "PPOSAT", "NN", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "H\u00f6rt/ an sprach ", "tokens": ["H\u00f6rt", "/", "an", "sprach"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVIMP", "$(", "APPR", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Fang' ich nur an sie zu besingen/", "tokens": ["Fang'", "ich", "nur", "an", "sie", "zu", "be\u00b7sin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie die ein Auszug unsrer ", "tokens": ["Sie", "die", "ein", "Aus\u00b7zug", "uns\u00b7rer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ART", "NN", "PPOSAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So m\u00f6chte mir das Hertze springen/", "tokens": ["So", "m\u00f6ch\u00b7te", "mir", "das", "Hert\u00b7ze", "sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PDS", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vor innerlichem Weh und ", "tokens": ["Vor", "in\u00b7ner\u00b7li\u00b7chem", "Weh", "und"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und da\u00df/ weil ihr mein treues Flehen/", "tokens": ["Und", "da\u00df", "/", "weil", "ihr", "mein", "treu\u00b7es", "Fle\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "$(", "KOUS", "PPER", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So gar nicht wil zu Hertzen gehen.", "tokens": ["So", "gar", "nicht", "wil", "zu", "Hert\u00b7zen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "VMFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich bin ja nicht/ wie mancher pfleget/", "tokens": ["Ich", "bin", "ja", "nicht", "/", "wie", "man\u00b7cher", "pfle\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "$(", "PWAV", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der nur mit blo\u00dfen Worten schwehrt/", "tokens": ["Der", "nur", "mit", "blo\u00b7\u00dfen", "Wor\u00b7ten", "schwehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dessen Hertz nichts wares heget/", "tokens": ["Und", "des\u00b7sen", "Hertz", "nichts", "wa\u00b7res", "he\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PIS", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der nur ", "tokens": ["Der", "nur"], "token_info": ["word", "word"], "pos": ["ART", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Der blo\u00df vermeint aus geilen Sinnen", "tokens": ["Der", "blo\u00df", "ver\u00b7meint", "aus", "gei\u00b7len", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Liebsten ", "tokens": ["Der", "Liebs\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.6": {"line.1": {"text": "Hab\u2019 ich der liebsten ", "tokens": ["Hab'", "ich", "der", "liebs\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Nicht das erwiesen jederzeit/", "tokens": ["Nicht", "das", "er\u00b7wie\u00b7sen", "je\u00b7der\u00b7zeit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PDS", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was das Verm\u00f6gen meinem Willen/", "tokens": ["Was", "das", "Ver\u00b7m\u00f6\u00b7gen", "mei\u00b7nem", "Wil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verg\u00f6nnet hat nach M\u00fcgligkeit.", "tokens": ["Ver\u00b7g\u00f6n\u00b7net", "hat", "nach", "M\u00fcg\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie kan wenn Sie nur selbst wil zeugen/", "tokens": ["Sie", "kan", "wenn", "Sie", "nur", "selbst", "wil", "zeu\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KOUS", "PPER", "ADV", "ADV", "VMFIN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df ich bin g\u00e4ntzlich ihr Leibeigen.", "tokens": ["Da\u00df", "ich", "bin", "g\u00e4ntz\u00b7lich", "ihr", "Leib\u00b7ei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+++-", "measure": "unknown.measure.penta"}}, "stanza.7": {"line.1": {"text": "Hab\u2019 ich nicht etlichmal erw\u00e4hlet/", "tokens": ["Hab'", "ich", "nicht", "et\u00b7lich\u00b7mal", "er\u00b7w\u00e4h\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bey Nacht\u2019 ein na\u00df-betautes ", "tokens": ["Bey", "Nacht'", "ein", "na\u00df\u00b7be\u00b7tau\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf welchem ich mich so gequ\u00e4let/", "tokens": ["Auf", "wel\u00b7chem", "ich", "mich", "so", "ge\u00b7qu\u00e4\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Sie betracht ohn unterla\u00df/", "tokens": ["Und", "Sie", "be\u00b7tracht", "ohn", "un\u00b7ter\u00b7la\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da ich doch wol bey meinen Schafen/", "tokens": ["Da", "ich", "doch", "wol", "bey", "mei\u00b7nen", "Scha\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jm sanften Bette k\u00f6nnen schlafen.", "tokens": ["Jm", "sanf\u00b7ten", "Bet\u00b7te", "k\u00f6n\u00b7nen", "schla\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und dieses m\u00fcst' ihr ja gestehen/", "tokens": ["Und", "die\u00b7ses", "m\u00fcst'", "ihr", "ja", "ge\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Jhr Stre\u00fcch\u2019 und auch du gantz Revier/", "tokens": ["Ihr", "Stre\u00b7\u00fcch'", "und", "auch", "du", "gantz", "Re\u00b7vier", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADV", "PPER", "ADV", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Bewegt zum Trauren neben mir.", "tokens": ["Be\u00b7wegt", "zum", "Trau\u00b7ren", "ne\u00b7ben", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Du Nachtigall kanst einig sagen/", "tokens": ["Du", "Nach\u00b7ti\u00b7gall", "kanst", "ei\u00b7nig", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VMFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von meinen innerlichen ", "tokens": ["Von", "mei\u00b7nen", "in\u00b7ner\u00b7li\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Hab\u2019 ich nicht meinen Leib geritzet/", "tokens": ["Hab'", "ich", "nicht", "mei\u00b7nen", "Leib", "ge\u00b7rit\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PTKNEG", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und von daraus mein Blut gebracht", "tokens": ["Und", "von", "da\u00b7raus", "mein", "Blut", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PAV", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo mir mein redlichs Hertze sitzet/", "tokens": ["Wo", "mir", "mein", "red\u00b7lichs", "Hert\u00b7ze", "sit\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So ihr zu dienen war bedacht.", "tokens": ["So", "ihr", "zu", "die\u00b7nen", "war", "be\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie willig war es gar zu sterben/", "tokens": ["Wie", "wil\u00b7lig", "war", "es", "gar", "zu", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr treues Hertz nur zu erwerben.", "tokens": ["Ihr", "treu\u00b7es", "Hertz", "nur", "zu", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die\u00df/ und auch noch viel andre Sachen", "tokens": ["Die\u00df", "/", "und", "auch", "noch", "viel", "and\u00b7re", "Sa\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "$(", "KON", "ADV", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So meine ", "tokens": ["So", "mei\u00b7ne"], "token_info": ["word", "word"], "pos": ["ADV", "PPOSAT"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Setzt Sie bi\u00dfweilen mit verlachen", "tokens": ["Setzt", "Sie", "bi\u00df\u00b7wei\u00b7len", "mit", "ver\u00b7la\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und eitlem Mi\u00dftrau hinten an.", "tokens": ["Und", "eit\u00b7lem", "Mi\u00df\u00b7trau", "hin\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch ruff\u2019 ich an euch Himmelslichter", "tokens": ["Doch", "ruff'", "ich", "an", "euch", "Him\u00b7mels\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPER", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jhr werdet sein mein rechter Richter.", "tokens": ["Ihr", "wer\u00b7det", "sein", "mein", "rech\u00b7ter", "Rich\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Hab\u2019 ich Sie nicht gleich meinem Hertzen/", "tokens": ["Hab'", "ich", "Sie", "nicht", "gleich", "mei\u00b7nem", "Hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "PTKNEG", "ADV", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und noch viel treulicher geliebt/", "tokens": ["Und", "noch", "viel", "treu\u00b7li\u00b7cher", "ge\u00b7liebt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So bleiben auf mir Noht und Schmertzen/", "tokens": ["So", "blei\u00b7ben", "auf", "mir", "Noht", "und", "Schmert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch das/ was mich vor dem betr\u00fcbt.", "tokens": ["Auch", "das", "/", "was", "mich", "vor", "dem", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "PWS", "PPER", "APPR", "ART", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Wie oft sagt ", "tokens": ["Wie", "oft", "sagt"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Da\u00df ich Sie lieb' alleine. (Reine.)", "tokens": ["Da\u00df", "ich", "Sie", "lieb'", "al\u00b7lei\u00b7ne", ".", "(", "Rei\u00b7ne", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ADV", "$.", "$(", "NE", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ja wenn ich f\u00fcnd\u2019 in meinen Sinnen/", "tokens": ["Ja", "wenn", "ich", "f\u00fcnd'", "in", "mei\u00b7nen", "Sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ihr m\u00f6cht angenehme sein/", "tokens": ["Was", "ihr", "m\u00f6cht", "an\u00b7ge\u00b7neh\u00b7me", "sein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "ADJA", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein ", "tokens": ["Mein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Solt\u2019 ihr ohn allen falschen Schein.", "tokens": ["Solt'", "ihr", "ohn", "al\u00b7len", "fal\u00b7schen", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu treuen Diensten sein ergeben/", "tokens": ["Zu", "treu\u00b7en", "Diens\u00b7ten", "sein", "er\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und solt' es sein mit meinem Leben.", "tokens": ["Und", "solt'", "es", "sein", "mit", "mei\u00b7nem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPOSAT", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Nuschliesset doch ihr frommen ", "tokens": ["Nuschlies\u00b7set", "doch", "ihr", "from\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sey Richter unparteische Welt/", "tokens": ["Sey", "Rich\u00b7ter", "un\u00b7par\u00b7tei\u00b7sche", "Welt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob ich zu nennen sey ein Sp\u00f6tter/", "tokens": ["Ob", "ich", "zu", "nen\u00b7nen", "sey", "ein", "Sp\u00f6t\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKZU", "VVINF", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie Sie mich offtmals daf\u00fcr h\u00e4lt.", "tokens": ["Wie", "Sie", "mich", "offt\u00b7mals", "da\u00b7f\u00fcr", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bin ichs so schiessen ", "tokens": ["Bin", "ichs", "so", "schies\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "ADV", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Hier \u00fcber meinen ", "tokens": ["Hier", "\u00fc\u00b7ber", "mei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "Geh hin mit deinem sanften Wehen/", "tokens": ["Geh", "hin", "mit", "dei\u00b7nem", "sanf\u00b7ten", "We\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du Sachteseusler Westenwind/", "tokens": ["Du", "Sach\u00b7te\u00b7seus\u00b7ler", "Wes\u00b7ten\u00b7wind", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Geh mach die sch\u00f6nste Nymf verstehen/", "tokens": ["Geh", "mach", "die", "sch\u00f6ns\u00b7te", "Nymf", "ver\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das allerliebste Hertzenkind.", "tokens": ["Das", "al\u00b7ler\u00b7liebs\u00b7te", "Hert\u00b7zen\u00b7kind", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ich Sie lieb' als meine Seele/", "tokens": ["Da\u00df", "ich", "Sie", "lieb'", "als", "mei\u00b7ne", "See\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "KOKOM", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bi\u00df in die schwartze Grabesh\u00f6hle.", "tokens": ["Bi\u00df", "in", "die", "schwart\u00b7ze", "Gra\u00b7bes\u00b7h\u00f6h\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Sag wil Sie ferner mir nicht trauen/", "tokens": ["Sag", "wil", "Sie", "fer\u00b7ner", "mir", "nicht", "trau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "ADV", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So soll Sie dessen sein gewi\u00df/", "tokens": ["So", "soll", "Sie", "des\u00b7sen", "sein", "ge\u00b7wi\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PDS", "PPOSAT", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich mich wil der Welt berauben/", "tokens": ["Da\u00df", "ich", "mich", "wil", "der", "Welt", "be\u00b7rau\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit mancher Noht und Hertzverdrie\u00df.", "tokens": ["Mit", "man\u00b7cher", "Noht", "und", "Hertz\u00b7ver\u00b7drie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wil sagen: gute Nacht ihr W\u00e4lder/", "tokens": ["Wil", "sa\u00b7gen", ":", "gu\u00b7te", "Nacht", "ihr", "W\u00e4l\u00b7der", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$.", "ADJA", "NN", "PPOSAT", "NN", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Zu tausend guter Nacht ihr Felder.", "tokens": ["Zu", "tau\u00b7send", "gu\u00b7ter", "Nacht", "ihr", "Fel\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "So sang mit bittren heissen Thr\u00e4nen", "tokens": ["So", "sang", "mit", "bit\u00b7tren", "heis\u00b7sen", "Thr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der treue ", "tokens": ["Der", "treu\u00b7e"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Kaum kunt' Er mehr ein Wort erw\u00e4hnen", "tokens": ["Kaum", "kunt'", "Er", "mehr", "ein", "Wort", "er\u00b7w\u00e4h\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als die\u00df so Er mit Seuftzen lallt:", "tokens": ["Als", "die\u00df", "so", "Er", "mit", "Seuft\u00b7zen", "lallt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ADV", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ach m\u00f6chte Sie sich doch bed\u00e4nken", "tokens": ["Ach", "m\u00f6ch\u00b7te", "Sie", "sich", "doch", "be\u00b7d\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und mich hinfort nicht mehr so kr\u00e4nken.", "tokens": ["Und", "mich", "hin\u00b7fort", "nicht", "mehr", "so", "kr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PTKNEG", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}