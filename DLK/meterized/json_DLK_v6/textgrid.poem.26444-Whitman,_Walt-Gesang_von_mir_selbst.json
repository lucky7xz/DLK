{"textgrid.poem.26444": {"metadata": {"author": {"name": "Whitman, Walt", "birth": "N.A.", "death": "N.A."}, "title": "Gesang von mir selbst", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich feiere mich selbst und singe mich selbst,", "tokens": ["Ich", "fei\u00b7e\u00b7re", "mich", "selbst", "und", "sin\u00b7ge", "mich", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Und was ich mir anma\u00dfe, das sollt ihr euch anma\u00dfen,", "tokens": ["Und", "was", "ich", "mir", "an\u00b7ma\u00b7\u00dfe", ",", "das", "sollt", "ihr", "euch", "an\u00b7ma\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "VVFIN", "$,", "PDS", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+---+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Denn jedes Atom, das mir geh\u00f6rt, geh\u00f6rt auch euch!", "tokens": ["Denn", "je\u00b7des", "A\u00b7tom", ",", "das", "mir", "ge\u00b7h\u00f6rt", ",", "ge\u00b7h\u00f6rt", "auch", "euch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "ADV", "PPER", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Meine Zunge, jedes Teilchen meines Blutes ist hier aus diesem Boden, aus dieser Luft gebildet,", "tokens": ["Mei\u00b7ne", "Zun\u00b7ge", ",", "je\u00b7des", "Teil\u00b7chen", "mei\u00b7nes", "Blu\u00b7tes", "ist", "hier", "aus", "die\u00b7sem", "Bo\u00b7den", ",", "aus", "die\u00b7ser", "Luft", "ge\u00b7bil\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PIAT", "NN", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PDAT", "NN", "$,", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+--+-+-+--+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Von Eltern geboren, die hier von \u00e4hnlichen Eltern geboren, und diese wieder von \u00e4hnlichen Eltern,", "tokens": ["Von", "El\u00b7tern", "ge\u00b7bo\u00b7ren", ",", "die", "hier", "von", "\u00e4hn\u00b7li\u00b7chen", "El\u00b7tern", "ge\u00b7bo\u00b7ren", ",", "und", "die\u00b7se", "wie\u00b7der", "von", "\u00e4hn\u00b7li\u00b7chen", "El\u00b7tern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "PRELS", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,", "KON", "PDS", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+--+--+--+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "So beginne ich jetzt, siebenunddrei\u00dfig Jahre alt, in vollkommener Gesundheit,", "tokens": ["So", "be\u00b7gin\u00b7ne", "ich", "jetzt", ",", "sie\u00b7be\u00b7nund\u00b7drei\u00b7\u00dfig", "Jah\u00b7re", "alt", ",", "in", "voll\u00b7kom\u00b7me\u00b7ner", "Ge\u00b7sund\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "CARD", "NN", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "--+--++--+-+-+---+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Und hoffe nicht eher aufzuh\u00f6ren, bis zum Tode.", "tokens": ["Und", "hof\u00b7fe", "nicht", "e\u00b7her", "auf\u00b7zu\u00b7h\u00f6\u00b7ren", ",", "bis", "zum", "To\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "VVINF", "$,", "KOUS", "APPRART", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "H\u00e4user und R\u00e4ume sind voller Wohlger\u00fcche, die B\u00fccherb\u00f6rter sind voller D\u00fcfte,", "tokens": ["H\u00e4u\u00b7ser", "und", "R\u00e4u\u00b7me", "sind", "vol\u00b7ler", "Wohl\u00b7ge\u00b7r\u00fc\u00b7che", ",", "die", "B\u00fc\u00b7cher\u00b7b\u00f6r\u00b7ter", "sind", "vol\u00b7ler", "D\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "+--+--+-+-+--+-+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Die ich einatme, die ich kenne und liebe,", "tokens": ["Die", "ich", "ei\u00b7nat\u00b7me", ",", "die", "ich", "ken\u00b7ne", "und", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Essenz w\u00fcrde mich berauschen, aber ich lasse es nicht zu.", "tokens": ["Die", "Es\u00b7senz", "w\u00fcr\u00b7de", "mich", "be\u00b7rau\u00b7schen", ",", "a\u00b7ber", "ich", "las\u00b7se", "es", "nicht", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVINF", "$,", "KON", "PPER", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.4": {"line.1": {"text": "Sie ist immer f\u00fcr meinen Mund; ich bin verliebt in sie,", "tokens": ["Sie", "ist", "im\u00b7mer", "f\u00fcr", "mei\u00b7nen", "Mund", ";", "ich", "bin", "ver\u00b7liebt", "in", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "VVPP", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Ich will zum H\u00fcgelhang am Walde gehen und unverkleidet und nackt sein,", "tokens": ["Ich", "will", "zum", "H\u00fc\u00b7gel\u00b7hang", "am", "Wal\u00b7de", "ge\u00b7hen", "und", "un\u00b7ver\u00b7klei\u00b7det", "und", "nackt", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "APPRART", "NN", "VVINF", "KON", "ADJD", "KON", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Denn ich lechze danach, mit ihr in Ber\u00fchrung zu kommen.", "tokens": ["Denn", "ich", "lech\u00b7ze", "da\u00b7nach", ",", "mit", "ihr", "in", "Be\u00b7r\u00fch\u00b7rung", "zu", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PAV", "$,", "APPR", "PPOSAT", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "--+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Ich h\u00f6rte die Schw\u00e4tzer schwatzen vom Anfang und vom Ende,", "tokens": ["Ich", "h\u00f6r\u00b7te", "die", "Schw\u00e4t\u00b7zer", "schwat\u00b7zen", "vom", "An\u00b7fang", "und", "vom", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVFIN", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Aber ich rede nicht vom Anfang oder vom Ende.", "tokens": ["A\u00b7ber", "ich", "re\u00b7de", "nicht", "vom", "An\u00b7fang", "o\u00b7der", "vom", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "APPRART", "NN", "KON", "APPRART", "NN", "$."], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}}, "stanza.6": {"line.1": {"text": "Nie war mehr Anfang als jetzt,", "tokens": ["Nie", "war", "mehr", "An\u00b7fang", "als", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "KOKOM", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Nie mehr Jugend oder mehr Alter als jetzt,", "tokens": ["Nie", "mehr", "Ju\u00b7gend", "o\u00b7der", "mehr", "Al\u00b7ter", "als", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "PIAT", "NN", "KOKOM", "ADV", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Nie wird es mehr Vollkommenheit geben als jetzt,", "tokens": ["Nie", "wird", "es", "mehr", "Voll\u00b7kom\u00b7men\u00b7heit", "ge\u00b7ben", "als", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "VVINF", "KOKOM", "ADV", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Oder mehr Himmel und H\u00f6lle als jetzt.", "tokens": ["O\u00b7der", "mehr", "Him\u00b7mel", "und", "H\u00f6l\u00b7le", "als", "jetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "NN", "KOKOM", "ADV", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.7": {"line.1": {"text": "Dr\u00e4ngen und Dr\u00e4ngen und Dr\u00e4ngen \u2013", "tokens": ["Dr\u00e4n\u00b7gen", "und", "Dr\u00e4n\u00b7gen", "und", "Dr\u00e4n\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Immer der zeugende Drang der Welt.", "tokens": ["Im\u00b7mer", "der", "zeu\u00b7gen\u00b7de", "Drang", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Aus dem Dunkel treten Gleichwertige einander entgegen, immer Stoff und Wachstum, immer Geschlecht,", "tokens": ["Aus", "dem", "Dun\u00b7kel", "tre\u00b7ten", "Gleich\u00b7wer\u00b7ti\u00b7ge", "ein\u00b7an\u00b7der", "ent\u00b7ge\u00b7gen", ",", "im\u00b7mer", "Stoff", "und", "Wachs\u00b7tum", ",", "im\u00b7mer", "Ge\u00b7schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "ADV", "PTKVZ", "$,", "ADV", "NN", "KON", "NN", "$,", "ADV", "NN", "$,"], "meter": "--+-+-+----+--+-+-+-+-+--+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Immer die Verkn\u00fcpfung der Identit\u00e4t, immer Unterscheidung, immer ein br\u00fcnstiges Leben.", "tokens": ["Im\u00b7mer", "die", "Ver\u00b7kn\u00fcp\u00b7fung", "der", "I\u00b7den\u00b7ti\u00b7t\u00e4t", ",", "im\u00b7mer", "Un\u00b7ter\u00b7schei\u00b7dung", ",", "im\u00b7mer", "ein", "br\u00fcns\u00b7ti\u00b7ges", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,", "ADV", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+---+--+-+-+-+-+-+--+--+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.9": {"line.1": {"text": "Es weiter auszugr\u00fcbeln ist nutzlos. Gelehrte und Ungelehrte f\u00fchlen, da\u00df es so ist.", "tokens": ["Es", "wei\u00b7ter", "aus\u00b7zu\u00b7gr\u00fc\u00b7beln", "ist", "nutz\u00b7los", ".", "Ge\u00b7lehr\u00b7te", "und", "Un\u00b7ge\u00b7lehr\u00b7te", "f\u00fch\u00b7len", ",", "da\u00df", "es", "so", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "VAFIN", "ADJD", "$.", "NN", "KON", "NN", "VVINF", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+--+--+--+-+-+--+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "St\u00e4mmig wie ein Ro\u00df, z\u00e4rtlich, stolz, elektrisch,", "tokens": ["St\u00e4m\u00b7mig", "wie", "ein", "Ro\u00df", ",", "z\u00e4rt\u00b7lich", ",", "stolz", ",", "e\u00b7lekt\u00b7risch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.3": {"text": "Ich und dies Geheimnis \u2013 hier stehen wir!", "tokens": ["Ich", "und", "dies", "Ge\u00b7heim\u00b7nis", "\u2013", "hier", "ste\u00b7hen", "wir", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PDS", "NN", "$(", "ADV", "VVFIN", "PPER", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Klar und rein ist meine Seele, und klar und rein ist alles, was nicht meine Seele ist.", "tokens": ["Klar", "und", "rein", "ist", "mei\u00b7ne", "See\u00b7le", ",", "und", "klar", "und", "rein", "ist", "al\u00b7les", ",", "was", "nicht", "mei\u00b7ne", "See\u00b7le", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VAFIN", "PPOSAT", "NN", "$,", "KON", "ADJD", "KON", "ADJD", "VAFIN", "PIS", "$,", "PRELS", "PTKNEG", "PPOSAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.11": {"line.1": {"text": "Fehlt eins, so fehlen beide, und das Ungesehene wird durch das Gesehene bewiesen,", "tokens": ["Fehlt", "eins", ",", "so", "feh\u00b7len", "bei\u00b7de", ",", "und", "das", "Un\u00b7ge\u00b7se\u00b7he\u00b7ne", "wird", "durch", "das", "Ge\u00b7se\u00b7he\u00b7ne", "be\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "ADV", "VVFIN", "PIS", "$,", "KON", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+--++---+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Bis dieses wieder zum Unsichtbaren wird und seinerseits Beweise empf\u00e4ngt.", "tokens": ["Bis", "die\u00b7ses", "wie\u00b7der", "zum", "Un\u00b7sicht\u00b7ba\u00b7ren", "wird", "und", "sei\u00b7ner\u00b7seits", "Be\u00b7wei\u00b7se", "emp\u00b7f\u00e4ngt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADV", "APPRART", "NN", "VAFIN", "KON", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-+-+--+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.12": {"line.1": {"text": "Abseits vom Ziehen und Zerren steht, was ", "tokens": ["Ab\u00b7seits", "vom", "Zie\u00b7hen", "und", "Zer\u00b7ren", "steht", ",", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "APPRART", "NN", "KON", "NN", "VVFIN", "$,", "PWS"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Vergn\u00fcgt, gef\u00e4llig, teilnehmend, m\u00fc\u00dfig, einheitlich,", "tokens": ["Ver\u00b7gn\u00fcgt", ",", "ge\u00b7f\u00e4l\u00b7lig", ",", "teil\u00b7neh\u00b7mend", ",", "m\u00fc\u00b7\u00dfig", ",", "ein\u00b7heit\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "$,", "VVPP", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Blickt nieder, steht aufrecht oder st\u00fctzt den gebogenen Arm auf einen unfa\u00dfbaren sicheren Halt,", "tokens": ["Blickt", "nie\u00b7der", ",", "steht", "auf\u00b7recht", "o\u00b7der", "st\u00fctzt", "den", "ge\u00b7bo\u00b7ge\u00b7nen", "Arm", "auf", "ei\u00b7nen", "un\u00b7fa\u00df\u00b7ba\u00b7ren", "si\u00b7che\u00b7ren", "Halt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "VVFIN", "ADJD", "KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+--+-+-+-+-+--+", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Sieht mit seitlich gewendetem Haupte zu, neugierig was nun kommen mag,", "tokens": ["Sieht", "mit", "seit\u00b7lich", "ge\u00b7wen\u00b7de\u00b7tem", "Haup\u00b7te", "zu", ",", "neu\u00b7gie\u00b7rig", "was", "nun", "kom\u00b7men", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,", "ADJD", "PWS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "--+--+--+-+-+-+-+-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "In und au\u00dfer dem Spiel, aufpassend und sich dar\u00fcber wundernd.", "tokens": ["In", "und", "au\u00b7\u00dfer", "dem", "Spiel", ",", "auf\u00b7pas\u00b7send", "und", "sich", "da\u00b7r\u00fc\u00b7ber", "wun\u00b7dernd", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "APPR", "ART", "NN", "$,", "VVPP", "KON", "PRF", "PAV", "VVPP", "$."], "meter": "--+--+-+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.13": {"line.1": {"text": "Ich glaube an dich, meine Seele; das andere, das ich bin, darf sich nicht vor dir erniedrigen,", "tokens": ["Ich", "glau\u00b7be", "an", "dich", ",", "mei\u00b7ne", "See\u00b7le", ";", "das", "an\u00b7de\u00b7re", ",", "das", "ich", "bin", ",", "darf", "sich", "nicht", "vor", "dir", "er\u00b7nied\u00b7ri\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "PPOSAT", "NN", "$.", "ART", "ADJA", "$,", "PRELS", "PPER", "VAFIN", "$,", "VMFIN", "PRF", "PTKNEG", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+--+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Noch darfst du vor dem andern erniedrigt sein.", "tokens": ["Noch", "darfst", "du", "vor", "dem", "an\u00b7dern", "er\u00b7nied\u00b7rigt", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "VVPP", "VAINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.14": {"line.1": {"text": "Ich gedenke, wie wir einst an einem so klaren Sommermorgen im Freien lagen,", "tokens": ["Ich", "ge\u00b7den\u00b7ke", ",", "wie", "wir", "einst", "an", "ei\u00b7nem", "so", "kla\u00b7ren", "Som\u00b7mer\u00b7mor\u00b7gen", "im", "Frei\u00b7en", "la\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "APPR", "ART", "ADV", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+--+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Wie du dein Haupt quer \u00fcber meine H\u00fcften legtest und dich leise auf mir umkehrtest,", "tokens": ["Wie", "du", "dein", "Haupt", "quer", "\u00fc\u00b7ber", "mei\u00b7ne", "H\u00fcf\u00b7ten", "leg\u00b7test", "und", "dich", "lei\u00b7se", "auf", "mir", "um\u00b7kehr\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "KON", "PPER", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Und mir das Hemd am Brustknochen \u00f6ffnetest und die Zunge in mein blo\u00dfgelegtes Herz hineintauchtest,", "tokens": ["Und", "mir", "das", "Hemd", "am", "Brust\u00b7kno\u00b7chen", "\u00f6ff\u00b7ne\u00b7test", "und", "die", "Zun\u00b7ge", "in", "mein", "blo\u00df\u00b7ge\u00b7leg\u00b7tes", "Herz", "hin\u00b7ein\u00b7tauch\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "APPRART", "NN", "VVFIN", "KON", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+--+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Und hinaufreichtest, bis du meinen Bart f\u00fchltest, und hinunter, bis du meine F\u00fc\u00dfe hieltest.", "tokens": ["Und", "hin\u00b7auf\u00b7reich\u00b7test", ",", "bis", "du", "mei\u00b7nen", "Bart", "f\u00fchl\u00b7test", ",", "und", "hin\u00b7un\u00b7ter", ",", "bis", "du", "mei\u00b7ne", "F\u00fc\u00b7\u00dfe", "hiel\u00b7test", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$,", "KON", "PTKVZ", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-++-+-+-+-+-+-+-", "measure": "unknown.measure.octa.plus"}}, "stanza.15": {"line.1": {"text": "Ein Kind sagte: Was ist das Gras? und brachte es mir mit vollen H\u00e4nden;", "tokens": ["Ein", "Kind", "sag\u00b7te", ":", "Was", "ist", "das", "Gras", "?", "und", "brach\u00b7te", "es", "mir", "mit", "vol\u00b7len", "H\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWS", "VAFIN", "ART", "NN", "$.", "KON", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+-+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wie sollte ich dem Kinde antworten? ich wei\u00df ebensowenig was es ist, wie das Kind.", "tokens": ["Wie", "soll\u00b7te", "ich", "dem", "Kin\u00b7de", "ant\u00b7wor\u00b7ten", "?", "ich", "wei\u00df", "e\u00b7ben\u00b7so\u00b7we\u00b7nig", "was", "es", "ist", ",", "wie", "das", "Kind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "PPER", "VVFIN", "ADV", "PWS", "PPER", "VAFIN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+---+---+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}}, "stanza.16": {"line.1": {"text": "Ich meine, es mu\u00df die Fahne meines eigenen Gem\u00fctes sein, aus hoffnungsgr\u00fcnem Tuch gewoben ...", "tokens": ["Ich", "mei\u00b7ne", ",", "es", "mu\u00df", "die", "Fah\u00b7ne", "mei\u00b7nes", "ei\u00b7ge\u00b7nen", "Ge\u00b7m\u00fc\u00b7tes", "sein", ",", "aus", "hoff\u00b7nungs\u00b7gr\u00fc\u00b7nem", "Tuch", "ge\u00b7wo\u00b7ben", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "VAINF", "$,", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Oder ich meine, das Gras ist selber ein Kindlein, das der Pflanzenwuchs zeugte ...", "tokens": ["O\u00b7der", "ich", "mei\u00b7ne", ",", "das", "Gras", "ist", "sel\u00b7ber", "ein", "Kin\u00b7dlein", ",", "das", "der", "Pflan\u00b7zen\u00b7wuchs", "zeug\u00b7te", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADV", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$("], "meter": "+--+--+-+--+-+-+--+-", "measure": "dactylic.di.plus"}}, "stanza.17": {"line.1": {"text": "Ich will ihm oder ihr gleich zeigen, da\u00df es ein ebensolches Gl\u00fcck ist, zu sterben, und ich wei\u00df es.", "tokens": ["Ich", "will", "ihm", "o\u00b7der", "ihr", "gleich", "zei\u00b7gen", ",", "da\u00df", "es", "ein", "e\u00b7ben\u00b7sol\u00b7ches", "Gl\u00fcck", "ist", ",", "zu", "ster\u00b7ben", ",", "und", "ich", "wei\u00df", "es", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "KON", "PPER", "ADV", "VVINF", "$,", "KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$,", "PTKZU", "VVINF", "$,", "KON", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+----+-++-+-+-+-", "measure": "unknown.measure.octa.plus"}}, "stanza.18": {"line.1": {"text": "Ich bin nicht eine Erde, noch der Anhang einer Erde,", "tokens": ["Ich", "bin", "nicht", "ei\u00b7ne", "Er\u00b7de", ",", "noch", "der", "An\u00b7hang", "ei\u00b7ner", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ART", "NN", "$,", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "Ich bin der Genosse und Gef\u00e4hrte der Menschen, alle ebenso unsterblich und unergr\u00fcndlich wie ich,", "tokens": ["Ich", "bin", "der", "Ge\u00b7nos\u00b7se", "und", "Ge\u00b7f\u00e4hr\u00b7te", "der", "Men\u00b7schen", ",", "al\u00b7le", "e\u00b7ben\u00b7so", "uns\u00b7terb\u00b7lich", "und", "un\u00b7er\u00b7gr\u00fcnd\u00b7lich", "wie", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NN", "ART", "NN", "$,", "PIS", "ADV", "ADJD", "KON", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+--+-+-+--+-+-+---+--+-+-++", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "(sie wissen nicht wie unsterblich sie sind, doch ich wei\u00df es).", "tokens": ["(", "sie", "wis\u00b7sen", "nicht", "wie", "uns\u00b7terb\u00b7lich", "sie", "sind", ",", "doch", "ich", "wei\u00df", "es", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "KOKOM", "ADJD", "PPER", "VAFIN", "$,", "KON", "PPER", "VVFIN", "PPER", "$(", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Jede Art f\u00fcr sich und ihr eigen; f\u00fcr mich die meine, m\u00e4nnlich und weiblich,", "tokens": ["Je\u00b7de", "Art", "f\u00fcr", "sich", "und", "ihr", "ei\u00b7gen", ";", "f\u00fcr", "mich", "die", "mei\u00b7ne", ",", "m\u00e4nn\u00b7lich", "und", "weib\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PRF", "KON", "PPER", "ADJD", "$.", "APPR", "PPER", "ART", "PPOSAT", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+--+--+-+-+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "F\u00fcr mich die, welche Knaben waren und die Frauen lieben,", "tokens": ["F\u00fcr", "mich", "die", ",", "wel\u00b7che", "Kna\u00b7ben", "wa\u00b7ren", "und", "die", "Frau\u00b7en", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "$,", "PWAT", "NN", "VAFIN", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.3": {"text": "F\u00fcr mich der Mann, der stolz ist und f\u00fchlt wie es sticht, gering geachtet zu werden,", "tokens": ["F\u00fcr", "mich", "der", "Mann", ",", "der", "stolz", "ist", "und", "f\u00fchlt", "wie", "es", "sticht", ",", "ge\u00b7ring", "ge\u00b7ach\u00b7tet", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "KON", "VVFIN", "KOKOM", "PPER", "VVFIN", "$,", "ADJD", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+--+--+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "F\u00fcr mich das Liebchen und die alte Jungfer, f\u00fcr mich M\u00fctter und die M\u00fctter von M\u00fcttern,", "tokens": ["F\u00fcr", "mich", "das", "Lieb\u00b7chen", "und", "die", "al\u00b7te", "Jung\u00b7fer", ",", "f\u00fcr", "mich", "M\u00fct\u00b7ter", "und", "die", "M\u00fct\u00b7ter", "von", "M\u00fct\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "KON", "ART", "ADJA", "NN", "$,", "APPR", "PPER", "NN", "KON", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus"}, "line.5": {"text": "F\u00fcr mich Lippen, die gel\u00e4chelt haben, Augen, die Tr\u00e4nen vergossen,", "tokens": ["F\u00fcr", "mich", "Lip\u00b7pen", ",", "die", "ge\u00b7l\u00e4\u00b7chelt", "ha\u00b7ben", ",", "Au\u00b7gen", ",", "die", "Tr\u00e4\u00b7nen", "ver\u00b7gos\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "$,", "PRELS", "VVPP", "VAINF", "$,", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+--+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": "F\u00fcr mich Kinder und die Erzeuger von Kindern.", "tokens": ["F\u00fcr", "mich", "Kin\u00b7der", "und", "die", "Er\u00b7zeu\u00b7ger", "von", "Kin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "KON", "ART", "NN", "APPR", "NN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}}, "stanza.20": {"line.1": {"text": "Enth\u00fclle dich! f\u00fcr mich bist du nicht schuldig, nicht veraltet, noch verworfen,", "tokens": ["Ent\u00b7h\u00fcl\u00b7le", "dich", "!", "f\u00fcr", "mich", "bist", "du", "nicht", "schul\u00b7dig", ",", "nicht", "ver\u00b7al\u00b7tet", ",", "noch", "ver\u00b7wor\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "APPR", "PPER", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,", "PTKNEG", "VVPP", "$,", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Und bin rings um dich, beharrlich, erobernd, unerm\u00fcdlich, und lasse mich nicht absch\u00fctteln.", "tokens": ["Und", "bin", "rings", "um", "dich", ",", "be\u00b7harr\u00b7lich", ",", "er\u00b7o\u00b7bernd", ",", "un\u00b7er\u00b7m\u00fcd\u00b7lich", ",", "und", "las\u00b7se", "mich", "nicht", "ab\u00b7sch\u00fct\u00b7teln", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "PPER", "$,", "ADJD", "$,", "VVPP", "$,", "ADJD", "$,", "KON", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+--+-+-+--+-+-+--", "measure": "iambic.octa.plus.relaxed"}}, "stanza.21": {"line.1": {"text": "Der Junge und das rotbackige M\u00e4dchen wenden sich seitw\u00e4rts zum buschigen H\u00fcgel hinan,", "tokens": ["Der", "Jun\u00b7ge", "und", "das", "rot\u00b7ba\u00b7cki\u00b7ge", "M\u00e4d\u00b7chen", "wen\u00b7den", "sich", "seit\u00b7w\u00e4rts", "zum", "bu\u00b7schi\u00b7gen", "H\u00fc\u00b7gel", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN", "VVFIN", "PRF", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+--+-+-+-+---", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich ersp\u00e4he sie oben vom Gipfel ...", "tokens": ["Ich", "er\u00b7sp\u00e4\u00b7he", "sie", "o\u00b7ben", "vom", "Gip\u00b7fel", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$("], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.22": {"line.1": {"text": "Der Selbstm\u00f6rder liegt hingestreckt auf dem blutigen Boden der Schlafstube,", "tokens": ["Der", "Selbst\u00b7m\u00f6r\u00b7der", "liegt", "hin\u00b7ge\u00b7streckt", "auf", "dem", "blu\u00b7ti\u00b7gen", "Bo\u00b7den", "der", "Schlaf\u00b7stu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+--+--+--", "measure": "amphibrach.penta.plus"}, "line.2": {"text": "Ich betrachte den Leichnam mit den blutbespritzten Haaren, und beachte, wo die Pistole hinfiel ...", "tokens": ["Ich", "be\u00b7trach\u00b7te", "den", "Leich\u00b7nam", "mit", "den", "blut\u00b7be\u00b7spritz\u00b7ten", "Haa\u00b7ren", ",", "und", "be\u00b7ach\u00b7te", ",", "wo", "die", "Pis\u00b7to\u00b7le", "hin\u00b7fiel", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,", "KON", "VVFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$("], "meter": "+-+--+-+-+-+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.23": {"line.1": {"text": "Die weiten Tore der Dorfscheune stehen offen,", "tokens": ["Die", "wei\u00b7ten", "To\u00b7re", "der", "Dorf\u00b7scheu\u00b7ne", "ste\u00b7hen", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das getrocknete Gras der Erntezeit belastet den langsam gezogenen Wagen,", "tokens": ["Das", "ge\u00b7trock\u00b7ne\u00b7te", "Gras", "der", "Ern\u00b7te\u00b7zeit", "be\u00b7las\u00b7tet", "den", "lang\u00b7sam", "ge\u00b7zo\u00b7ge\u00b7nen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+--+--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Das hellklare Licht spielt \u00fcber dem Durcheinander von Graubraun und Gr\u00fcn,", "tokens": ["Das", "hell\u00b7kla\u00b7re", "Licht", "spielt", "\u00fc\u00b7ber", "dem", "Durch\u00b7ein\u00b7an\u00b7der", "von", "Grau\u00b7braun", "und", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+--+-+--+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Die Haufen sind aufgeschichtet, da\u00df ihre Last sich biegt.", "tokens": ["Die", "Hau\u00b7fen", "sind", "auf\u00b7ge\u00b7schich\u00b7tet", ",", "da\u00df", "ih\u00b7re", "Last", "sich", "biegt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "KOUS", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Ich bin da, ich helfe; ich kam, hingestreckt oben auf der Ladung,", "tokens": ["Ich", "bin", "da", ",", "ich", "hel\u00b7fe", ";", "ich", "kam", ",", "hin\u00b7ge\u00b7streckt", "o\u00b7ben", "auf", "der", "La\u00b7dung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--++-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Ich f\u00fchlte ihre sanften St\u00f6\u00dfe, ein Bein auf dem andern ruhend,", "tokens": ["Ich", "f\u00fchl\u00b7te", "ih\u00b7re", "sanf\u00b7ten", "St\u00f6\u00b7\u00dfe", ",", "ein", "Bein", "auf", "dem", "an\u00b7dern", "ru\u00b7hend", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+--+--+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Ich springe von dem Querbalken und fasse den Klee und das Zittergras,", "tokens": ["Ich", "sprin\u00b7ge", "von", "dem", "Quer\u00b7bal\u00b7ken", "und", "fas\u00b7se", "den", "Klee", "und", "das", "Zit\u00b7ter\u00b7gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+---+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und w\u00e4lze mich kopf\u00fcber und verwirre meine Haare in den Rispen!", "tokens": ["Und", "w\u00e4l\u00b7ze", "mich", "kopf\u00b7\u00fc\u00b7ber", "und", "ver\u00b7wir\u00b7re", "mei\u00b7ne", "Haa\u00b7re", "in", "den", "Ris\u00b7pen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.5": {"text": "Wandernd, \u00fcberrascht \u00fcber meine eigene Behendigkeit und Fr\u00f6hlichkeit.", "tokens": ["Wan\u00b7dernd", ",", "\u00fc\u00b7berr\u00b7ascht", "\u00fc\u00b7ber", "mei\u00b7ne", "ei\u00b7ge\u00b7ne", "Be\u00b7hen\u00b7dig\u00b7keit", "und", "Fr\u00f6h\u00b7lich\u00b7keit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+--+-+-+---+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.25": {"line.1": {"text": "Am sp\u00e4ten Nachmittag eine sichere Stelle aufsuchend, um die Nacht zuzubringen,", "tokens": ["Am", "sp\u00e4\u00b7ten", "Nach\u00b7mit\u00b7tag", "ei\u00b7ne", "si\u00b7che\u00b7re", "Stel\u00b7le", "auf\u00b7su\u00b7chend", ",", "um", "die", "Nacht", "zu\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,", "KOUI", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+--+--+-+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Z\u00fcnde ich ein Feuer an und brate das frischerlegte Wild,", "tokens": ["Z\u00fcn\u00b7de", "ich", "ein", "Feu\u00b7er", "an", "und", "bra\u00b7te", "das", "fri\u00b7scher\u00b7leg\u00b7te", "Wild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "PTKVZ", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Schlafe auf den zusammengeschichteten Bl\u00e4ttern ein, mit meinem Hund und dem Gewehr an der Seite.", "tokens": ["Schla\u00b7fe", "auf", "den", "zu\u00b7sam\u00b7men\u00b7ge\u00b7schich\u00b7te\u00b7ten", "Bl\u00e4t\u00b7tern", "ein", ",", "mit", "mei\u00b7nem", "Hund", "und", "dem", "Ge\u00b7wehr", "an", "der", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,", "APPR", "PPOSAT", "NN", "KON", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+--+--+--+-+-+-+-+-+--+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.26": {"line.1": {"text": "Das Yankee-Klipperschiff ist unter den Oberbramsegeln, es durchschneidet das Gefunkel und Gesch\u00e4ume,", "tokens": ["Das", "Y\u00b7an\u00b7kee\u00b7Klip\u00b7per\u00b7schiff", "ist", "un\u00b7ter", "den", "O\u00b7berb\u00b7ram\u00b7se\u00b7geln", ",", "es", "durch\u00b7schnei\u00b7det", "das", "Ge\u00b7fun\u00b7kel", "und", "Ge\u00b7sch\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Meine Augen sehen das Land versinken, ich lehne mich \u00fcber den Bug oder rufe jubelnd vom Verdeck.", "tokens": ["Mei\u00b7ne", "Au\u00b7gen", "se\u00b7hen", "das", "Land", "ver\u00b7sin\u00b7ken", ",", "ich", "leh\u00b7ne", "mich", "\u00fc\u00b7ber", "den", "Bug", "o\u00b7der", "ru\u00b7fe", "ju\u00b7belnd", "vom", "Ver\u00b7deck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "VVINF", "$,", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "KON", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "+-+-+--+-+--+--+--+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.27": {"line.1": {"text": "Die Schiffer und Muschelgr\u00e4ber machten sich fr\u00fch auf und warteten auf mich,", "tokens": ["Die", "Schif\u00b7fer", "und", "Mu\u00b7schel\u00b7gr\u00e4\u00b7ber", "mach\u00b7ten", "sich", "fr\u00fch", "auf", "und", "war\u00b7te\u00b7ten", "auf", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "PRF", "ADJD", "PTKVZ", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+--+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich steckte mir die Hose in die Stiefel und ging mit und hatte einen vergn\u00fcgten Tag,", "tokens": ["Ich", "steck\u00b7te", "mir", "die", "Ho\u00b7se", "in", "die", "Stie\u00b7fel", "und", "ging", "mit", "und", "hat\u00b7te", "ei\u00b7nen", "ver\u00b7gn\u00fcg\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "KON", "VVFIN", "APPR", "KON", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+--+-+", "measure": "iambic.octa.plus"}, "line.3": {"text": "Du h\u00e4ttest an dem Tage bei uns sein sollen, beim Muschel-Kochkessel!", "tokens": ["Du", "h\u00e4t\u00b7test", "an", "dem", "Ta\u00b7ge", "bei", "uns", "sein", "sol\u00b7len", ",", "beim", "Mu\u00b7schel\u00b7Koch\u00b7kes\u00b7sel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "PPER", "VAINF", "VMFIN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+--+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.28": {"line.1": {"text": "Achtundzwanzig junge M\u00e4nner baden am Strande;", "tokens": ["Acht\u00b7und\u00b7zwan\u00b7zig", "jun\u00b7ge", "M\u00e4n\u00b7ner", "ba\u00b7den", "am", "Stran\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Achtundzwanzig junge M\u00e4nner, und alle so vertraulich,", "tokens": ["Acht\u00b7und\u00b7zwan\u00b7zig", "jun\u00b7ge", "M\u00e4n\u00b7ner", ",", "und", "al\u00b7le", "so", "ver\u00b7trau\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$,", "KON", "PIS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Achtundzwanzig Jahre keuschen Frauenlebens, und alle so einsam. \u2013", "tokens": ["Acht\u00b7und\u00b7zwan\u00b7zig", "Jah\u00b7re", "keu\u00b7schen", "Frau\u00b7en\u00b7le\u00b7bens", ",", "und", "al\u00b7le", "so", "ein\u00b7sam", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["CARD", "NN", "ADJA", "NN", "$,", "KON", "PIS", "ADV", "ADJD", "$.", "$("], "meter": "+-+-+-+-+--+-+--+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.29": {"line.1": {"text": "Sie ist Besitzerin des sch\u00f6nen Hauses beim ansteigenden Ufer;", "tokens": ["Sie", "ist", "Be\u00b7sit\u00b7ze\u00b7rin", "des", "sch\u00f6\u00b7nen", "Hau\u00b7ses", "beim", "an\u00b7stei\u00b7gen\u00b7den", "U\u00b7fer", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+---+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Sch\u00f6n und reich gekleidet, lauert sie hinter den Fenstervorh\u00e4ngen.", "tokens": ["Sch\u00f6n", "und", "reich", "ge\u00b7klei\u00b7det", ",", "lau\u00b7ert", "sie", "hin\u00b7ter", "den", "Fens\u00b7ter\u00b7vor\u00b7h\u00e4n\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+--+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Ach, der allt\u00e4glichste von ihnen ist sch\u00f6n in ihren Augen!", "tokens": ["Ach", ",", "der", "all\u00b7t\u00e4g\u00b7lichs\u00b7te", "von", "ih\u00b7nen", "ist", "sch\u00f6n", "in", "ih\u00b7ren", "Au\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "ADJA", "APPR", "PPER", "VAFIN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.30": {"line.1": {"text": "Wohin willst denn du, meine Dame? ich sehe dich schon,", "tokens": ["Wo\u00b7hin", "willst", "denn", "du", ",", "mei\u00b7ne", "Da\u00b7me", "?", "ich", "se\u00b7he", "dich", "schon", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "KON", "PPER", "$,", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Du pl\u00e4tscherst mit unten im Wasser, bleibst du auch m\u00e4uschenstill in deiner Stube.", "tokens": ["Du", "pl\u00e4t\u00b7scherst", "mit", "un\u00b7ten", "im", "Was\u00b7ser", ",", "bleibst", "du", "auch", "m\u00e4u\u00b7schen\u00b7still", "in", "dei\u00b7ner", "Stu\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPRART", "NN", "$,", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+--+-+-+-+-+-", "measure": "amphibrach.tetra.plus"}}, "stanza.31": {"line.1": {"text": "Tanzend und lachend lief an den Strand die neunundzwanzigste Badende,", "tokens": ["Tan\u00b7zend", "und", "la\u00b7chend", "lief", "an", "den", "Strand", "die", "neun\u00b7und\u00b7zwan\u00b7zigs\u00b7te", "Ba\u00b7den\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+-+-+---+-", "measure": "iambic.septa.invert"}, "line.2": {"text": "Die andern sahen sie nicht \u2013 aber sie sah die andern und liebte sie.", "tokens": ["Die", "an\u00b7dern", "sa\u00b7hen", "sie", "nicht", "\u2013", "a\u00b7ber", "sie", "sah", "die", "an\u00b7dern", "und", "lieb\u00b7te", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PTKNEG", "$(", "KON", "PPER", "VVFIN", "ART", "ADJA", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+---+--+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.32": {"line.1": {"text": "Die B\u00e4rte der jungen M\u00e4nner glitzerten vom Na\u00df, es rann von ihrem langen Haar herab,", "tokens": ["Die", "B\u00e4r\u00b7te", "der", "jun\u00b7gen", "M\u00e4n\u00b7ner", "glit\u00b7zer\u00b7ten", "vom", "Na\u00df", ",", "es", "rann", "von", "ih\u00b7rem", "lan\u00b7gen", "Haar", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "ADV", "$,"], "meter": "-+--+-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Kleine B\u00e4chlein rieselten ihnen \u00fcber den Leib.", "tokens": ["Klei\u00b7ne", "B\u00e4ch\u00b7lein", "rie\u00b7sel\u00b7ten", "ih\u00b7nen", "\u00fc\u00b7ber", "den", "Leib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+--+", "measure": "trochaic.hexa.relaxed"}}, "stanza.33": {"line.1": {"text": "Eine unsichtbare Hand strich auch \u00fcber ihren Leib,", "tokens": ["Ei\u00b7ne", "un\u00b7sicht\u00b7ba\u00b7re", "Hand", "strich", "auch", "\u00fc\u00b7ber", "ih\u00b7ren", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+---+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Sie glitt zitternd an ihren Schl\u00e4fen und Rippen herab.", "tokens": ["Sie", "glitt", "zit\u00b7ternd", "an", "ih\u00b7ren", "Schl\u00e4\u00b7fen", "und", "Rip\u00b7pen", "her\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "KON", "NN", "ADV", "$."], "meter": "-+--+--+--+--+", "measure": "amphibrach.penta.plus"}}, "stanza.34": {"line.1": {"text": "Schmiede mit geschw\u00e4rzten und zottigen Br\u00fcsten umringen den Ambo\u00df,", "tokens": ["Schmie\u00b7de", "mit", "ge\u00b7schw\u00e4rz\u00b7ten", "und", "zot\u00b7ti\u00b7gen", "Br\u00fcs\u00b7ten", "um\u00b7rin\u00b7gen", "den", "Am\u00b7bo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "KON", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+--+--+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Ein jeder h\u00e4lt seinen Schlaghammer, alle Hammer im Schwung, das Feuer gl\u00fcht;", "tokens": ["Ein", "je\u00b7der", "h\u00e4lt", "sei\u00b7nen", "Schlag\u00b7ham\u00b7mer", ",", "al\u00b7le", "Ham\u00b7mer", "im", "Schwung", ",", "das", "Feu\u00b7er", "gl\u00fcht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPOSAT", "NN", "$,", "PIAT", "NN", "APPRART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+----+--+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Von der aschenbestreuten Schwelle folge ich ihren Bewegungen,", "tokens": ["Von", "der", "asc\u00b7hen\u00b7be\u00b7streu\u00b7ten", "Schwel\u00b7le", "fol\u00b7ge", "ich", "ih\u00b7ren", "Be\u00b7we\u00b7gun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+--+---+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Von oben herunter schwingen die Hammer, schwingen so langsam hoch, so sicher,", "tokens": ["Von", "o\u00b7ben", "her\u00b7un\u00b7ter", "schwin\u00b7gen", "die", "Ham\u00b7mer", ",", "schwin\u00b7gen", "so", "lang\u00b7sam", "hoch", ",", "so", "si\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVFIN", "ART", "NN", "$,", "VVFIN", "ADV", "ADJD", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+--+-+--+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Sie hasten nicht, ein jeder schl\u00e4gt an die richtige Stelle.", "tokens": ["Sie", "has\u00b7ten", "nicht", ",", "ein", "je\u00b7der", "schl\u00e4gt", "an", "die", "rich\u00b7ti\u00b7ge", "Stel\u00b7le", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "ART", "PIS", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.35": {"line.1": {"text": "Ich schaue den malerischen Riesen an und liebe ihn, und halte mich dabei nicht auf,", "tokens": ["Ich", "schau\u00b7e", "den", "ma\u00b7le\u00b7ri\u00b7schen", "Rie\u00b7sen", "an", "und", "lie\u00b7be", "ihn", ",", "und", "hal\u00b7te", "mich", "da\u00b7bei", "nicht", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "$,", "KON", "VVFIN", "PRF", "PAV", "PTKNEG", "PTKVZ", "$,"], "meter": "-+--+-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich gehe auch mit dem Gespann.", "tokens": ["Ich", "ge\u00b7he", "auch", "mit", "dem", "Ge\u00b7spann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Mein Schritt verscheucht Waldenterich und Ente auf meinen entlegenen, tagelangen Streifz\u00fcgen,", "tokens": ["Mein", "Schritt", "ver\u00b7scheucht", "Wal\u00b7den\u00b7te\u00b7rich", "und", "En\u00b7te", "auf", "mei\u00b7nen", "ent\u00b7le\u00b7ge\u00b7nen", ",", "ta\u00b7ge\u00b7lan\u00b7gen", "Streif\u00b7z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NE", "KON", "NN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-++--+-+--+-+-+-+-+-++-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Sie fliegen zusammen auf, langsam kreisend.", "tokens": ["Sie", "flie\u00b7gen", "zu\u00b7sam\u00b7men", "auf", ",", "lang\u00b7sam", "krei\u00b7send", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,", "ADJD", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.37": {"line.1": {"text": "Ich glaube an diese befl\u00fcgelten Zweckm\u00e4\u00dfigkeiten,", "tokens": ["Ich", "glau\u00b7be", "an", "die\u00b7se", "be\u00b7fl\u00fc\u00b7gel\u00b7ten", "Zweck\u00b7m\u00e4\u00b7\u00dfig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--++-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und bekenne Rot, Wei\u00df, Gelb, spielend in mir,", "tokens": ["Und", "be\u00b7ken\u00b7ne", "Rot", ",", "Wei\u00df", ",", "Gelb", ",", "spie\u00b7lend", "in", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVFIN", "$,", "ADJD", "$,", "ADJD", "APPR", "PPER", "$,"], "meter": "+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Und halte das Gr\u00fcn und das Veilchenblau und die Federbuschkrone f\u00fcr absichtlich,", "tokens": ["Und", "hal\u00b7te", "das", "Gr\u00fcn", "und", "das", "Veil\u00b7chen\u00b7blau", "und", "die", "Fe\u00b7der\u00b7buschkro\u00b7ne", "f\u00fcr", "ab\u00b7sicht\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "ART", "NN", "KON", "ART", "NN", "APPR", "ADJD", "$,"], "meter": "-+--+--+-+--+-+--+--", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Und nenne die Schildkr\u00f6te nicht wertlos, weil sie nicht etwas anderes ist;", "tokens": ["Und", "nen\u00b7ne", "die", "Schild\u00b7kr\u00f6\u00b7te", "nicht", "wert\u00b7los", ",", "weil", "sie", "nicht", "et\u00b7was", "an\u00b7de\u00b7res", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "PIS", "VAFIN", "$."], "meter": "-+--++-+--+--+-+--+", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Die Elster im Walde hat die Tonleiter nicht studiert und trillert doch gut genug f\u00fcr mich,", "tokens": ["Die", "Els\u00b7ter", "im", "Wal\u00b7de", "hat", "die", "Ton\u00b7lei\u00b7ter", "nicht", "stu\u00b7diert", "und", "tril\u00b7lert", "doch", "gut", "ge\u00b7nug", "f\u00fcr", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "ART", "NN", "PTKNEG", "VVFIN", "KON", "VVFIN", "ADV", "ADJD", "ADV", "APPR", "PPER", "$,"], "meter": "-+--+-+-++-+-+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.6": {"text": "Und der Anblick der kastanienbraunen Stute treibt besch\u00e4mend alle Albernheiten aus mir.", "tokens": ["Und", "der", "An\u00b7blick", "der", "kas\u00b7ta\u00b7ni\u00b7en\u00b7brau\u00b7nen", "Stu\u00b7te", "treibt", "be\u00b7sch\u00e4\u00b7mend", "al\u00b7le", "Al\u00b7bern\u00b7hei\u00b7ten", "aus", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "ADJD", "PIAT", "NN", "APPR", "PPER", "$."], "meter": "--+--+-+-+-+-+-+-+-+-+--+", "measure": "anapaest.di.plus"}}, "stanza.38": {"line.1": {"text": "Der wilde G\u00e4nserich lenkt seinen Flug durch die k\u00fchle Nacht,", "tokens": ["Der", "wil\u00b7de", "G\u00e4n\u00b7se\u00b7rich", "lenkt", "sei\u00b7nen", "Flug", "durch", "die", "k\u00fch\u00b7le", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Ja-honk! ruft er, und es klingt mir wie eine Einladung,", "tokens": ["Ja\u00b7honk", "!", "ruft", "er", ",", "und", "es", "klingt", "mir", "wie", "ei\u00b7ne", "Ein\u00b7la\u00b7dung", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "$,", "KON", "PPER", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "--+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Vorwitzigen m\u00f6gen es f\u00fcr bedeutungslos halten, ich aber finde, aufhorchend,", "tokens": ["Die", "Vor\u00b7wit\u00b7zi\u00b7gen", "m\u00f6\u00b7gen", "es", "f\u00fcr", "be\u00b7deu\u00b7tungs\u00b7los", "hal\u00b7ten", ",", "ich", "a\u00b7ber", "fin\u00b7de", ",", "auf\u00b7hor\u00b7chend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "APPR", "ADJD", "VVINF", "$,", "PPER", "ADV", "VVFIN", "$,", "VVPP", "$,"], "meter": "-+---+--+-+--+--+-+-+--", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Da\u00df es seinen Zweck und Platz hat dort oben im winterlichen Himmel.", "tokens": ["Da\u00df", "es", "sei\u00b7nen", "Zweck", "und", "Platz", "hat", "dort", "o\u00b7ben", "im", "win\u00b7ter\u00b7li\u00b7chen", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "KON", "NN", "VAFIN", "ADV", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.39": {"line.1": {"text": "Mein Gl\u00fcck versuchend, meine Habe verschwendend f\u00fcr ungeheuren Gewinn,", "tokens": ["Mein", "Gl\u00fcck", "ver\u00b7su\u00b7chend", ",", "mei\u00b7ne", "Ha\u00b7be", "ver\u00b7schwen\u00b7dend", "f\u00fcr", "un\u00b7ge\u00b7heu\u00b7ren", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "PPOSAT", "NN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+--+-+--+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Mich schm\u00fcckend, um mich dem ersten Besten, der mich will, hinzugeben,", "tokens": ["Mich", "schm\u00fc\u00b7ckend", ",", "um", "mich", "dem", "ers\u00b7ten", "Bes\u00b7ten", ",", "der", "mich", "will", ",", "hin\u00b7zu\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "KOUI", "PRF", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VMFIN", "$,", "VVIZU", "$,"], "meter": "-+--+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Nicht vom Himmel fordernd, da\u00df er mir zu Gefallen herunterkomme,", "tokens": ["Nicht", "vom", "Him\u00b7mel", "for\u00b7dernd", ",", "da\u00df", "er", "mir", "zu", "Ge\u00b7fal\u00b7len", "her\u00b7un\u00b7ter\u00b7kom\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "VVPP", "$,", "KOUS", "PPER", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Sondern ihn ewig mit vollen H\u00e4nden ausstreuend.", "tokens": ["Son\u00b7dern", "ihn", "e\u00b7wig", "mit", "vol\u00b7len", "H\u00e4n\u00b7den", "aus\u00b7streu\u00b7end", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.40": {"line.1": {"text": "Alles bek\u00e4mpfe ich leichter als meine eigene Verschiedenartigkeit,", "tokens": ["Al\u00b7les", "be\u00b7k\u00e4mp\u00b7fe", "ich", "leich\u00b7ter", "als", "mei\u00b7ne", "ei\u00b7ge\u00b7ne", "Ver\u00b7schie\u00b7den\u00b7ar\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KOKOM", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-+-+-+-+", "measure": "dactylic.tri.plus"}, "line.2": {"text": "Atme die Luft, doch lasse genug \u00fcbrig,", "tokens": ["At\u00b7me", "die", "Luft", ",", "doch", "las\u00b7se", "ge\u00b7nug", "\u00fcb\u00b7rig", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ADV", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Bin nicht aufgeblasen und bin da, wohin ich geh\u00f6re.", "tokens": ["Bin", "nicht", "auf\u00b7ge\u00b7bla\u00b7sen", "und", "bin", "da", ",", "wo\u00b7hin", "ich", "ge\u00b7h\u00f6\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVINF", "KON", "VAFIN", "ADV", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+--+-+-+-+-", "measure": "trochaic.septa.relaxed"}}, "stanza.41": {"line.1": {"text": "Dies ist das Gras, das \u00fcberall w\u00e4chst, wo Land und Wasser ist,", "tokens": ["Dies", "ist", "das", "Gras", ",", "das", "\u00fc\u00b7be\u00b7rall", "w\u00e4chst", ",", "wo", "Land", "und", "Was\u00b7ser", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "PWAV", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Dies die gemeinsame Luft, in der die Erdkugel sich badet.", "tokens": ["Dies", "die", "ge\u00b7mein\u00b7sa\u00b7me", "Luft", ",", "in", "der", "die", "Erd\u00b7ku\u00b7gel", "sich", "ba\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "$,", "APPR", "PRELS", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.42": {"line.1": {"text": "Die Lebendigen schlafen ihre Zeit und die Toten schlafen ihre Zeit,", "tokens": ["Die", "Le\u00b7ben\u00b7di\u00b7gen", "schla\u00b7fen", "ih\u00b7re", "Zeit", "und", "die", "To\u00b7ten", "schla\u00b7fen", "ih\u00b7re", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "KON", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Der alte Ehemann schl\u00e4ft bei seinem Weib und der junge Ehemann schl\u00e4ft bei seinem Weib,", "tokens": ["Der", "al\u00b7te", "E\u00b7he\u00b7mann", "schl\u00e4ft", "bei", "sei\u00b7nem", "Weib", "und", "der", "jun\u00b7ge", "E\u00b7he\u00b7mann", "schl\u00e4ft", "bei", "sei\u00b7nem", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+--+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Diese alle dr\u00e4ngen sich hinein zu mir und ich dr\u00e4nge mich aus mir hinaus zu ihnen,", "tokens": ["Die\u00b7se", "al\u00b7le", "dr\u00e4n\u00b7gen", "sich", "hin\u00b7ein", "zu", "mir", "und", "ich", "dr\u00e4n\u00b7ge", "mich", "aus", "mir", "hin\u00b7aus", "zu", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "PIS", "VVFIN", "PRF", "APZR", "APPR", "PPER", "KON", "PPER", "VVFIN", "PRF", "APPR", "PPER", "APZR", "APPR", "PPER", "$,"], "meter": "+-+-+-+-+--+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Und was es hei\u00dft Einer von Diesen zu sein, mehr oder weniger, das bin ich,", "tokens": ["Und", "was", "es", "hei\u00dft", "Ei\u00b7ner", "von", "Die\u00b7sen", "zu", "sein", ",", "mehr", "o\u00b7der", "we\u00b7ni\u00b7ger", ",", "das", "bin", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "PIS", "APPR", "PDS", "PTKZU", "VAINF", "$,", "ADV", "KON", "ADV", "$,", "PDS", "VAFIN", "PPER", "$,"], "meter": "-+--+--+--+-+-+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.5": {"text": "Und aus einem und allen webe ich den Gesang von mir selbst.", "tokens": ["Und", "aus", "ei\u00b7nem", "und", "al\u00b7len", "we\u00b7be", "ich", "den", "Ge\u00b7sang", "von", "mir", "selbst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "KON", "PIS", "VVFIN", "PPER", "ART", "NN", "APPR", "PPER", "ADV", "$."], "meter": "--+--+-+-+--+--+", "measure": "anapaest.di.plus"}}, "stanza.43": {"line.1": {"text": "Mit m\u00e4chtiger Musik komme ich, mit Zinken und Trommeln,", "tokens": ["Mit", "m\u00e4ch\u00b7ti\u00b7ger", "Mu\u00b7sik", "kom\u00b7me", "ich", ",", "mit", "Zin\u00b7ken", "und", "Trom\u00b7meln", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich spiele M\u00e4rsche nicht nur f\u00fcr anerkannte Sieger, ich spiele M\u00e4rsche f\u00fcr Besiegte und Erschlagene.", "tokens": ["Ich", "spie\u00b7le", "M\u00e4r\u00b7sche", "nicht", "nur", "f\u00fcr", "an\u00b7er\u00b7kann\u00b7te", "Sie\u00b7ger", ",", "ich", "spie\u00b7le", "M\u00e4r\u00b7sche", "f\u00fcr", "Be\u00b7sieg\u00b7te", "und", "Er\u00b7schla\u00b7ge\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$,", "PPER", "VVFIN", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-+-+-+--+-+-+-+--+---", "measure": "iambic.octa.plus.relaxed"}}, "stanza.44": {"line.1": {"text": "Ich trommle und trommle weiter f\u00fcr die Toten.", "tokens": ["Ich", "tromm\u00b7le", "und", "tromm\u00b7le", "wei\u00b7ter", "f\u00fcr", "die", "To\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich setze an und blase mein Lautestes und Fr\u00f6hlichstes f\u00fcr sie.", "tokens": ["Ich", "set\u00b7ze", "an", "und", "bla\u00b7se", "mein", "Lau\u00b7tes\u00b7tes", "und", "Fr\u00f6h\u00b7lichs\u00b7tes", "f\u00fcr", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPOSAT", "NN", "KON", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+--+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.45": {"line.1": {"text": "Ein Hoch f\u00fcr Die, denen es fehlschlug!", "tokens": ["Ein", "Hoch", "f\u00fcr", "Die", ",", "de\u00b7nen", "es", "fehl\u00b7schlug", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "F\u00fcr Die, deren Kriegsschiffe in der See versanken,", "tokens": ["F\u00fcr", "Die", ",", "de\u00b7ren", "Kriegs\u00b7schif\u00b7fe", "in", "der", "See", "ver\u00b7san\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELAT", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Und f\u00fcr Die, welche selber untergingen,", "tokens": ["Und", "f\u00fcr", "Die", ",", "wel\u00b7che", "sel\u00b7ber", "un\u00b7ter\u00b7gin\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und allen Generalen, die Schlachten verloren, und allen besiegten Helden!", "tokens": ["Und", "al\u00b7len", "Ge\u00b7ne\u00b7ra\u00b7len", ",", "die", "Schlach\u00b7ten", "ver\u00b7lo\u00b7ren", ",", "und", "al\u00b7len", "be\u00b7sieg\u00b7ten", "Hel\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "ART", "NN", "VVPP", "$,", "KON", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+--+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Und den zahllosen unbekannten Helden, gleich den gr\u00f6\u00dften Helden, die man kennt!", "tokens": ["Und", "den", "zahl\u00b7lo\u00b7sen", "un\u00b7be\u00b7kann\u00b7ten", "Hel\u00b7den", ",", "gleich", "den", "gr\u00f6\u00df\u00b7ten", "Hel\u00b7den", ",", "die", "man", "kennt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "$,", "ADV", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}}, "stanza.46": {"line.1": {"text": "Dies ist das Mahl f\u00fcr Alle aufs gleiche gerichtet, das Fleisch f\u00fcr den nat\u00fcrlichen Hunger,", "tokens": ["Dies", "ist", "das", "Mahl", "f\u00fcr", "Al\u00b7le", "aufs", "glei\u00b7che", "ge\u00b7rich\u00b7tet", ",", "das", "Fleisch", "f\u00fcr", "den", "na\u00b7t\u00fcr\u00b7li\u00b7chen", "Hun\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PIAT", "APPRART", "ADJA", "VVPP", "$,", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+--+---+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich will, da\u00df keiner gering gesch\u00e4tzt oder \u00fcbergangen wird,", "tokens": ["Ich", "will", ",", "da\u00df", "kei\u00b7ner", "ge\u00b7ring", "ge\u00b7sch\u00e4tzt", "o\u00b7der", "\u00fc\u00b7ber\u00b7gan\u00b7gen", "wird", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PIS", "ADJD", "VVPP", "KON", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Die Maitresse, der Schmarotzer, der Dieb werden hiermit eingeladen,", "tokens": ["Die", "Mai\u00b7tres\u00b7se", ",", "der", "Schma\u00b7rot\u00b7zer", ",", "der", "Dieb", "wer\u00b7den", "hier\u00b7mit", "ein\u00b7ge\u00b7la\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-++-++--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Der dicklippige Sklave wird geladen, der Geschlechtskranke wird geladen,", "tokens": ["Der", "dick\u00b7lip\u00b7pi\u00b7ge", "Skla\u00b7ve", "wird", "ge\u00b7la\u00b7den", ",", "der", "Ge\u00b7schlechts\u00b7kran\u00b7ke", "wird", "ge\u00b7la\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Es soll kein Unterschied zwischen ihnen und den Andern sein.", "tokens": ["Es", "soll", "kein", "Un\u00b7ter\u00b7schied", "zwi\u00b7schen", "ih\u00b7nen", "und", "den", "An\u00b7dern", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "APPR", "PPER", "KON", "ART", "ADJA", "VAINF", "$."], "meter": "-+-+-++-+-+-+-+", "measure": "unknown.measure.octa.plus"}}, "stanza.47": {"line.1": {"text": "Dies ist der Druck einer sch\u00fcchternen Hand, das Wogen und Duften des Haares,", "tokens": ["Dies", "ist", "der", "Druck", "ei\u00b7ner", "sch\u00fcch\u00b7ter\u00b7nen", "Hand", ",", "das", "Wo\u00b7gen", "und", "Duf\u00b7ten", "des", "Haa\u00b7res", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+--+--+-+--+--+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Die Ber\u00fchrung meiner Lippen mit den deinen, das Murmeln der Sehnsucht,", "tokens": ["Die", "Be\u00b7r\u00fch\u00b7rung", "mei\u00b7ner", "Lip\u00b7pen", "mit", "den", "dei\u00b7nen", ",", "das", "Mur\u00b7meln", "der", "Sehn\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ART", "PPOSAT", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+--+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Die ferne Tiefe und H\u00f6he, mein eigenes Antlitz spiegelnd,", "tokens": ["Die", "fer\u00b7ne", "Tie\u00b7fe", "und", "H\u00f6\u00b7he", ",", "mein", "ei\u00b7ge\u00b7nes", "Ant\u00b7litz", "spie\u00b7gelnd", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die gedankenvolle Verschmelzung meiner selbst und die Wiederausl\u00f6sung.", "tokens": ["Die", "ge\u00b7dan\u00b7ken\u00b7vol\u00b7le", "Ver\u00b7schmel\u00b7zung", "mei\u00b7ner", "selbst", "und", "die", "Wie\u00b7de\u00b7raus\u00b7l\u00f6\u00b7sung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "ADV", "KON", "ART", "NN", "$."], "meter": "+-+-+--+-+-+--+--+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.48": {"line.1": {"text": "In dieser Stunde sage ich Dinge im Vertrauen,", "tokens": ["In", "die\u00b7ser", "Stun\u00b7de", "sa\u00b7ge", "ich", "Din\u00b7ge", "im", "Ver\u00b7trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nicht jedermann sage ich sie, aber dir will ich sie sagen.", "tokens": ["Nicht", "je\u00b7der\u00b7mann", "sa\u00b7ge", "ich", "sie", ",", "a\u00b7ber", "dir", "will", "ich", "sie", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VVFIN", "PPER", "PPER", "$,", "KON", "PPER", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+--+-+-+-+++-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.49": {"line.1": {"text": "Wer geht da? Gierig, grob, mystisch, nackt;", "tokens": ["Wer", "geht", "da", "?", "Gie\u00b7rig", ",", "grob", ",", "mys\u00b7tisch", ",", "nackt", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "$.", "NE", "$,", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie kommt es, da\u00df ich St\u00e4rke ziehe aus dem Rindfleisch, das ich esse?", "tokens": ["Wie", "kommt", "es", ",", "da\u00df", "ich", "St\u00e4r\u00b7ke", "zie\u00b7he", "aus", "dem", "Rind\u00b7fleisch", ",", "das", "ich", "es\u00b7se", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "NN", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-++-+-+", "measure": "unknown.measure.octa.plus"}, "line.3": {"text": "Allem, was ich als das Meine bezeichne, sollst du ein Deiniges gegen\u00fcberstellen,", "tokens": ["Al\u00b7lem", ",", "was", "ich", "als", "das", "Mei\u00b7ne", "be\u00b7zeich\u00b7ne", ",", "sollst", "du", "ein", "Dei\u00b7ni\u00b7ges", "ge\u00b7gen\u00b7\u00fc\u00b7bers\u00b7tel\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PWS", "PPER", "KOUS", "ART", "PPOSAT", "VVFIN", "$,", "VMFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+--+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Sonst w\u00e4re es verlorene Zeit, mir zuzuh\u00f6ren.", "tokens": ["Sonst", "w\u00e4\u00b7re", "es", "ver\u00b7lo\u00b7re\u00b7ne", "Zeit", ",", "mir", "zu\u00b7zu\u00b7h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJA", "NN", "$,", "PPER", "VVIZU", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.50": {"line.1": {"text": "Ich schn\u00fcffle nicht umher mit dem Allerwelts-Geschn\u00fcffel,", "tokens": ["Ich", "schn\u00fcff\u00b7le", "nicht", "um\u00b7her", "mit", "dem", "Al\u00b7ler\u00b7welts\u00b7Ge\u00b7schn\u00fcf\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich wimmere nicht mit dem Allerwelts-Gewimmer,", "tokens": ["Ich", "wim\u00b7me\u00b7re", "nicht", "mit", "dem", "Al\u00b7ler\u00b7welts\u00b7Ge\u00b7wim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df die Monate leer sind und der Boden nur Schlamm und Kot.", "tokens": ["Da\u00df", "die", "Mo\u00b7na\u00b7te", "leer", "sind", "und", "der", "Bo\u00b7den", "nur", "Schlamm", "und", "Kot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "VAFIN", "KON", "ART", "NN", "ADV", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.51": {"line.1": {"text": "In allem Volk sehe ich mich selbst, keiner ist mehr, keiner um ein Gerstenkorn weniger.", "tokens": ["In", "al\u00b7lem", "Volk", "se\u00b7he", "ich", "mich", "selbst", ",", "kei\u00b7ner", "ist", "mehr", ",", "kei\u00b7ner", "um", "ein", "Gers\u00b7ten\u00b7korn", "we\u00b7ni\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "VVFIN", "PPER", "PRF", "ADV", "$,", "PIS", "VAFIN", "ADV", "$,", "PIS", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Das Gute und B\u00f6se, das ich von mir selber sage, sage ich von ihnen.", "tokens": ["Das", "Gu\u00b7te", "und", "B\u00f6\u00b7se", ",", "das", "ich", "von", "mir", "sel\u00b7ber", "sa\u00b7ge", ",", "sa\u00b7ge", "ich", "von", "ih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "PRELS", "PPER", "APPR", "PPER", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+--+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.52": {"line.1": {"text": "Ich wei\u00df, ich bin kerngesund und fest,", "tokens": ["Ich", "wei\u00df", ",", "ich", "bin", "kern\u00b7ge\u00b7sund", "und", "fest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "KON", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zu mir streben alle Dinge des Weltalls in unaufh\u00f6rlicher Flut,", "tokens": ["Zu", "mir", "stre\u00b7ben", "al\u00b7le", "Din\u00b7ge", "des", "Welt\u00b7alls", "in", "un\u00b7auf\u00b7h\u00f6r\u00b7li\u00b7cher", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIAT", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+--+-+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Alle sind an mich geschrieben, und ich mu\u00df die Schrift entziffern.", "tokens": ["Al\u00b7le", "sind", "an", "mich", "ge\u00b7schrie\u00b7ben", ",", "und", "ich", "mu\u00df", "die", "Schrift", "ent\u00b7zif\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPER", "VVPP", "$,", "KON", "PPER", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}}, "stanza.53": {"line.1": {"text": "Ich bin wie ich bin, das ist genug,", "tokens": ["Ich", "bin", "wie", "ich", "bin", ",", "das", "ist", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "PPER", "VAFIN", "$,", "PDS", "VAFIN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wird mich kein andrer in der Welt gewahr, sitze ich hier zufrieden,", "tokens": ["Wird", "mich", "kein", "an\u00b7drer", "in", "der", "Welt", "ge\u00b7wahr", ",", "sit\u00b7ze", "ich", "hier", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PIAT", "ADJA", "APPR", "ART", "NN", "ADJD", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+--+--+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Und wenn mich jeder und alle bemerken, sitze ich auch zufrieden.", "tokens": ["Und", "wenn", "mich", "je\u00b7der", "und", "al\u00b7le", "be\u00b7mer\u00b7ken", ",", "sit\u00b7ze", "ich", "auch", "zu\u00b7frie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "KON", "PIS", "VVINF", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+--+--+-+--+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.54": {"line.1": {"text": "Eine Welt wird meiner gewahr, und zwar mir bei weitem die gr\u00f6\u00dfte Welt, und das bin ich selbst,", "tokens": ["Ei\u00b7ne", "Welt", "wird", "mei\u00b7ner", "ge\u00b7wahr", ",", "und", "zwar", "mir", "bei", "wei\u00b7tem", "die", "gr\u00f6\u00df\u00b7te", "Welt", ",", "und", "das", "bin", "ich", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "ADJD", "$,", "KON", "ADV", "PPER", "APPR", "PIS", "ART", "ADJA", "NN", "$,", "KON", "PDS", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+--+-+--+--+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Und ob ich zu dem Meinigen heute gelange oder nach zehntausend oder zehn Millionen Jahren,", "tokens": ["Und", "ob", "ich", "zu", "dem", "Mei\u00b7ni\u00b7gen", "heu\u00b7te", "ge\u00b7lan\u00b7ge", "o\u00b7der", "nach", "zehn\u00b7tau\u00b7send", "o\u00b7der", "zehn", "Mil\u00b7lion\u00b7en", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "PPOSS", "ADV", "ADJA", "KON", "APPR", "CARD", "KON", "CARD", "NN", "NN", "$,"], "meter": "-+-+-+--+--+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "So kann ich's getrost jetzt hinnehmen, und ebenso getrost kann ich warten.", "tokens": ["So", "kann", "ich's", "ge\u00b7trost", "jetzt", "hin\u00b7neh\u00b7men", ",", "und", "e\u00b7ben\u00b7so", "ge\u00b7trost", "kann", "ich", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVFIN", "ADV", "VVPP", "$,", "KON", "ADV", "ADJD", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+--+--+---+--+-", "measure": "amphibrach.tetra.plus"}}, "stanza.55": {"line.1": {"text": "Die St\u00e4tte, wo ich Fu\u00df fasse, ist fest wie mit Eisenklammern in Granit,", "tokens": ["Die", "St\u00e4t\u00b7te", ",", "wo", "ich", "Fu\u00df", "fas\u00b7se", ",", "ist", "fest", "wie", "mit", "Ei\u00b7sen\u00b7klam\u00b7mern", "in", "Gra\u00b7nit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "NN", "VVFIN", "$,", "VAFIN", "ADJD", "KOKOM", "APPR", "NN", "APPR", "NE", "$,"], "meter": "-+-+-++--+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich verlache Das, was ihr Aufl\u00f6sung nennt,", "tokens": ["Ich", "ver\u00b7la\u00b7che", "Das", ",", "was", "ihr", "Auf\u00b7l\u00f6\u00b7sung", "nennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Und ich kenne die F\u00fclle der Zeit.", "tokens": ["Und", "ich", "ken\u00b7ne", "die", "F\u00fcl\u00b7le", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}}, "stanza.56": {"line.1": {"text": "Bei mir sind die Seligkeiten des Himmels und die Qualen der H\u00f6lle,", "tokens": ["Bei", "mir", "sind", "die", "Se\u00b7lig\u00b7kei\u00b7ten", "des", "Him\u00b7mels", "und", "die", "Qua\u00b7len", "der", "H\u00f6l\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+--+-+-+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Die ersten veredle und vermehre ich in mir, die letzteren \u00fcbersetze ich in eine neue Sprache.", "tokens": ["Die", "ers\u00b7ten", "ve\u00b7red\u00b7le", "und", "ver\u00b7meh\u00b7re", "ich", "in", "mir", ",", "die", "letz\u00b7te\u00b7ren", "\u00fc\u00b7bers\u00b7et\u00b7ze", "ich", "in", "ei\u00b7ne", "neu\u00b7e", "Spra\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "KON", "VVFIN", "PPER", "APPR", "PPER", "$,", "PRELS", "PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.57": {"line.1": {"text": "Ich bin der Dichter des Weibes gleichwie des Mannes,", "tokens": ["Ich", "bin", "der", "Dich\u00b7ter", "des", "Wei\u00b7bes", "gleich\u00b7wie", "des", "Man\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+--+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und ich sage, es ist ebenso gro\u00df ein Weib zu sein wie ein Mann,", "tokens": ["Und", "ich", "sa\u00b7ge", ",", "es", "ist", "e\u00b7ben\u00b7so", "gro\u00df", "ein", "Weib", "zu", "sein", "wie", "ein", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "ART", "NN", "PTKZU", "VAINF", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+--+--+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Und ich sage, es gibt nichts Gr\u00f6\u00dferes als eine Mutter der Menschen.", "tokens": ["Und", "ich", "sa\u00b7ge", ",", "es", "gibt", "nichts", "Gr\u00f6\u00b7\u00dfe\u00b7res", "als", "ei\u00b7ne", "Mut\u00b7ter", "der", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PIS", "ADJA", "KOKOM", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.58": {"line.1": {"text": "Ich singe den Sang des Hochgef\u00fchls und des Stolzes,", "tokens": ["Ich", "sin\u00b7ge", "den", "Sang", "des", "Hoch\u00b7ge\u00b7f\u00fchls", "und", "des", "Stol\u00b7zes", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wir haben uns geduckt und gedem\u00fctigt genug,", "tokens": ["Wir", "ha\u00b7ben", "uns", "ge\u00b7duckt", "und", "ge\u00b7de\u00b7m\u00fc\u00b7tigt", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "KON", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Ich zeige, da\u00df Gr\u00f6\u00dfe nur Entwicklung ist.", "tokens": ["Ich", "zei\u00b7ge", ",", "da\u00df", "Gr\u00f6\u00b7\u00dfe", "nur", "Ent\u00b7wick\u00b7lung", "ist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.59": {"line.1": {"text": "Hast du die andern \u00fcberholt? Bist du der Pr\u00e4sident?", "tokens": ["Hast", "du", "die", "an\u00b7dern", "\u00fc\u00b7berh\u00b7olt", "?", "Bist", "du", "der", "Pr\u00e4\u00b7si\u00b7dent", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "VVPP", "$.", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Es ist eine Kleinigkeit; sie werden alle weiter als bis dahin gelangen, und immer noch weiter.", "tokens": ["Es", "ist", "ei\u00b7ne", "Klei\u00b7nig\u00b7keit", ";", "sie", "wer\u00b7den", "al\u00b7le", "wei\u00b7ter", "als", "bis", "da\u00b7hin", "ge\u00b7lan\u00b7gen", ",", "und", "im\u00b7mer", "noch", "wei\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "PPER", "VAFIN", "PIS", "ADV", "KOKOM", "APPR", "PAV", "VVINF", "$,", "KON", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+--+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.60": {"line.1": {"text": "Ich bin es, der da wandelt mit der zarten, wachsenden Nacht;", "tokens": ["Ich", "bin", "es", ",", "der", "da", "wan\u00b7delt", "mit", "der", "zar\u00b7ten", ",", "wach\u00b7sen\u00b7den", "Nacht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "ADV", "VVFIN", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.2": {"text": "Der Erde und dem Meer, von der Nacht halb umfangen, rufe ich zu:", "tokens": ["Der", "Er\u00b7de", "und", "dem", "Meer", ",", "von", "der", "Nacht", "halb", "um\u00b7fan\u00b7gen", ",", "ru\u00b7fe", "ich", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "APPR", "ART", "NN", "ADJD", "VVPP", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+--+--+-+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Dr\u00fccke dich fest an mich, blo\u00df-busige Nacht \u2013 dr\u00fccke dich fest an mich, magnetische, n\u00e4hrende Nacht!", "tokens": ["Dr\u00fc\u00b7cke", "dich", "fest", "an", "mich", ",", "blo\u00df\u00b7bu\u00b7si\u00b7ge", "Nacht", "\u2013", "dr\u00fc\u00b7cke", "dich", "fest", "an", "mich", ",", "mag\u00b7ne\u00b7ti\u00b7sche", ",", "n\u00e4h\u00b7ren\u00b7de", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "PPER", "$,", "ADJA", "NN", "$(", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+--++-+-+-++-+-+--+--+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Nacht der S\u00fcdwinde \u2013 Nacht der wenigen gro\u00dfen Sterne,", "tokens": ["Nacht", "der", "S\u00fcd\u00b7win\u00b7de", "\u2013", "Nacht", "der", "we\u00b7ni\u00b7gen", "gro\u00b7\u00dfen", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "NN", "ART", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Stille, nickende Nacht \u2013 rasende nackte Sommernacht!", "tokens": ["Stil\u00b7le", ",", "ni\u00b7cken\u00b7de", "Nacht", "\u2013", "ra\u00b7sen\u00b7de", "nack\u00b7te", "Som\u00b7mer\u00b7nacht", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$(", "ADJA", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "L\u00e4chle, du woll\u00fcstige, k\u00fchl angehauchte Erde!", "tokens": ["L\u00e4ch\u00b7le", ",", "du", "wol\u00b7l\u00fcs\u00b7ti\u00b7ge", ",", "k\u00fchl", "an\u00b7ge\u00b7hauch\u00b7te", "Er\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADJA", "$,", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+--++-+-+-", "measure": "trochaic.septa.relaxed"}, "line.7": {"text": "Erde der schlummernden, zerflie\u00dfenden B\u00e4ume,", "tokens": ["Er\u00b7de", "der", "schlum\u00b7mern\u00b7den", ",", "zer\u00b7flie\u00b7\u00dfen\u00b7den", "B\u00e4u\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "Erde nach Sonnenuntergang \u2013 Erde der nebelumh\u00fcllten Berggipfel,", "tokens": ["Er\u00b7de", "nach", "Son\u00b7nen\u00b7un\u00b7ter\u00b7gang", "\u2013", "Er\u00b7de", "der", "ne\u00b7be\u00b7lum\u00b7h\u00fcll\u00b7ten", "Berg\u00b7gip\u00b7fel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$(", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.9": {"text": "Erde des Glanzes und Schattens, den Spiegel des Flusses bunt besprenkelnd,", "tokens": ["Er\u00b7de", "des", "Glan\u00b7zes", "und", "Schat\u00b7tens", ",", "den", "Spie\u00b7gel", "des", "Flus\u00b7ses", "bunt", "be\u00b7spren\u00b7kelnd", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "$,", "ART", "NN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "+--+--+--+--+-+-+-", "measure": "dactylic.tetra.plus"}, "line.10": {"text": "Erde der durchsichtigen klargrauen Wolken, heller und klarer um meinetwillen,", "tokens": ["Er\u00b7de", "der", "durch\u00b7sich\u00b7ti\u00b7gen", "klar\u00b7grau\u00b7en", "Wol\u00b7ken", ",", "hel\u00b7ler", "und", "kla\u00b7rer", "um", "mei\u00b7net\u00b7wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "APPR", "ADV", "$,"], "meter": "+---+---+-+-+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.11": {"text": "Weitumfassende Erde \u2013 reiche Apfelbl\u00fcten-Erde,", "tokens": ["Wei\u00b7tum\u00b7fas\u00b7sen\u00b7de", "Er\u00b7de", "\u2013", "rei\u00b7che", "Ap\u00b7fel\u00b7bl\u00fc\u00b7ten\u00b7Er\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.12": {"text": "L\u00e4chle, denn dein Geliebter kommt!", "tokens": ["L\u00e4ch\u00b7le", ",", "denn", "dein", "Ge\u00b7lieb\u00b7ter", "kommt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.61": {"line.1": {"text": "Verschwenderin! Du hast mir Liebe gegeben \u2013 darum gebe auch ich dir Liebe,", "tokens": ["Ver\u00b7schwen\u00b7de\u00b7rin", "!", "Du", "hast", "mir", "Lie\u00b7be", "ge\u00b7ge\u00b7ben", "\u2013", "da\u00b7rum", "ge\u00b7be", "auch", "ich", "dir", "Lie\u00b7be", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VAFIN", "PPER", "NN", "VVPP", "$(", "PAV", "VVFIN", "ADV", "PPER", "PPER", "NN", "$,"], "meter": "-+-+-+-+--+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "O unaussprechliche leidenschaftliche Liebe!", "tokens": ["O", "un\u00b7aus\u00b7sprech\u00b7li\u00b7che", "lei\u00b7den\u00b7schaft\u00b7li\u00b7che", "Lie\u00b7be", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.62": {"line.1": {"text": "Meer der langgestreckten Grundwogen,", "tokens": ["Meer", "der", "lang\u00b7ge\u00b7streck\u00b7ten", "Grund\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Meer, das in breiten, bebenden Z\u00fcgen atmet,", "tokens": ["Meer", ",", "das", "in", "brei\u00b7ten", ",", "be\u00b7ben\u00b7den", "Z\u00fc\u00b7gen", "at\u00b7met", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "APPR", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Meer mit dem Salz des Lebens und den nicht gegrabenen, doch immerbereiten Gr\u00e4bern,", "tokens": ["Meer", "mit", "dem", "Salz", "des", "Le\u00b7bens", "und", "den", "nicht", "ge\u00b7gra\u00b7be\u00b7nen", ",", "doch", "im\u00b7mer\u00b7be\u00b7rei\u00b7ten", "Gr\u00e4\u00b7bern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN", "KON", "ART", "PTKNEG", "VVPP", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+---+--+-+-", "measure": "iambic.octa.plus.invert"}, "line.4": {"text": "Heulende, sturmgepeitschte, launige und liebliche See,", "tokens": ["Heu\u00b7len\u00b7de", ",", "sturm\u00b7ge\u00b7peitschte", ",", "lau\u00b7ni\u00b7ge", "und", "lieb\u00b7li\u00b7che", "See", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "+--+-+--+-+--+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Ich bin eins mit dir, ich bin eine Phase und bin alle Phasen!", "tokens": ["Ich", "bin", "eins", "mit", "dir", ",", "ich", "bin", "ei\u00b7ne", "Pha\u00b7se", "und", "bin", "al\u00b7le", "Pha\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPR", "PPER", "$,", "PPER", "VAFIN", "ART", "NN", "KON", "VAFIN", "PIAT", "NN", "$."], "meter": "-+--+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Lobsinger der Liebenden und solcher, die einander in den Armen ruhen.", "tokens": ["Lob\u00b7sin\u00b7ger", "der", "Lie\u00b7ben\u00b7den", "und", "sol\u00b7cher", ",", "die", "ein\u00b7an\u00b7der", "in", "den", "Ar\u00b7men", "ru\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "PIAT", "$,", "PRELS", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.63": {"line.1": {"text": "Ich bin es, der Sympathie verk\u00fcndet,", "tokens": ["Ich", "bin", "es", ",", "der", "Sym\u00b7pa\u00b7thie", "ver\u00b7k\u00fcn\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "(soll ich ein Verzeichnis von den Sachen im Hause machen, und das Haus \u00fcbersehen, das sie enth\u00e4lt?)", "tokens": ["(", "soll", "ich", "ein", "Ver\u00b7zeich\u00b7nis", "von", "den", "Sa\u00b7chen", "im", "Hau\u00b7se", "ma\u00b7chen", ",", "und", "das", "Haus", "\u00fc\u00b7ber\u00b7se\u00b7hen", ",", "das", "sie", "ent\u00b7h\u00e4lt", "?", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VMFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "$,", "KON", "ART", "NN", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+--+-+-+-+--+--+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.64": {"line.1": {"text": "Ich bin nicht nur der Dichter der G\u00fcte, ich weigre mich nicht, auch der Dichter des B\u00f6sen zu sein.", "tokens": ["Ich", "bin", "nicht", "nur", "der", "Dich\u00b7ter", "der", "G\u00fc\u00b7te", ",", "ich", "weig\u00b7re", "mich", "nicht", ",", "auch", "der", "Dich\u00b7ter", "des", "B\u00f6\u00b7sen", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "ADV", "ART", "NN", "ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+--+--+-+-+-+--+--+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.65": {"line.1": {"text": "Was f\u00fcr ein Gepl\u00e4rre \u00fcber Tugend und Laster!", "tokens": ["Was", "f\u00fcr", "ein", "Ge\u00b7pl\u00e4r\u00b7re", "\u00fc\u00b7ber", "Tu\u00b7gend", "und", "Las\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das \u00dcbel treibt mich an und die Verbesserung des \u00dcbels treibt mich an, ich stehe unbek\u00fcmmert,", "tokens": ["Das", "\u00dc\u00b7bel", "treibt", "mich", "an", "und", "die", "Ver\u00b7bes\u00b7se\u00b7rung", "des", "\u00dc\u00b7bels", "treibt", "mich", "an", ",", "ich", "ste\u00b7he", "un\u00b7be\u00b7k\u00fcm\u00b7mert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "KON", "ART", "NN", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Mein Gang ist nicht der Gang eines Tadlers oder eines Verwerfenden,", "tokens": ["Mein", "Gang", "ist", "nicht", "der", "Gang", "ei\u00b7nes", "Tad\u00b7lers", "o\u00b7der", "ei\u00b7nes", "Ver\u00b7wer\u00b7fen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKNEG", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+--+--", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Ich benetze die Wurzeln von Allem was gewachsen ist.", "tokens": ["Ich", "be\u00b7net\u00b7ze", "die", "Wur\u00b7zeln", "von", "Al\u00b7lem", "was", "ge\u00b7wach\u00b7sen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PIS", "PWS", "VVPP", "VAFIN", "$."], "meter": "--+--+--+-+-+-+", "measure": "anapaest.tri.plus"}}, "stanza.66": {"line.1": {"text": "Hast du etwa Furcht vor Skrofeln aus der nie erschlaffenden Zeugungsf\u00fclle?", "tokens": ["Hast", "du", "et\u00b7wa", "Furcht", "vor", "Skro\u00b7feln", "aus", "der", "nie", "er\u00b7schlaf\u00b7fen\u00b7den", "Zeu\u00b7gungs\u00b7f\u00fcl\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "APPR", "NN", "APPR", "ART", "ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Vermutest du, die himmlischen Gesetze w\u00e4ren zu \u00fcberarbeiten und zu berichtigen?", "tokens": ["Ver\u00b7mu\u00b7test", "du", ",", "die", "himm\u00b7li\u00b7schen", "Ge\u00b7set\u00b7ze", "w\u00e4\u00b7ren", "zu", "\u00fc\u00b7be\u00b7rar\u00b7bei\u00b7ten", "und", "zu", "be\u00b7rich\u00b7ti\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "VAFIN", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+--+--+--+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.67": {"line.1": {"text": "Ich finde die eine Seite als Gegengewicht und die antipodische Seite auch als Gegengewicht,", "tokens": ["Ich", "fin\u00b7de", "die", "ei\u00b7ne", "Sei\u00b7te", "als", "Ge\u00b7gen\u00b7ge\u00b7wicht", "und", "die", "an\u00b7ti\u00b7po\u00b7di\u00b7sche", "Sei\u00b7te", "auch", "als", "Ge\u00b7gen\u00b7ge\u00b7wicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ART", "NN", "KOUS", "NN", "KON", "ART", "ADJA", "NN", "ADV", "KOUS", "NN", "$,"], "meter": "-+--+-+--+--+--+-+--+-+-+--+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Die sanfte Lehre ebenso hilfreich wie die starke Lehre,", "tokens": ["Die", "sanf\u00b7te", "Leh\u00b7re", "e\u00b7ben\u00b7so", "hilf\u00b7reich", "wie", "die", "star\u00b7ke", "Leh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Gedanken und Taten der Gegenwart, unser Aufwachen und erstes Ansetzen,", "tokens": ["Ge\u00b7dan\u00b7ken", "und", "Ta\u00b7ten", "der", "Ge\u00b7gen\u00b7wart", ",", "un\u00b7ser", "Auf\u00b7wa\u00b7chen", "und", "ers\u00b7tes", "An\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ART", "NN", "$,", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+--+--+--+--+-++-", "measure": "amphibrach.penta.plus"}, "line.4": {"text": "Diese Minute, die \u00fcber die vergangenen Dezillionen zu mir kommt \u2013", "tokens": ["Die\u00b7se", "Mi\u00b7nu\u00b7te", ",", "die", "\u00fc\u00b7ber", "die", "ver\u00b7gan\u00b7ge\u00b7nen", "De\u00b7zil\u00b7li\u00b7o\u00b7nen", "zu", "mir", "kommt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PRELS", "APPR", "ART", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "+--+--+-+-+-+-+-+-+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Es gibt nichts Besseres als sie, und Jetzt!", "tokens": ["Es", "gibt", "nichts", "Bes\u00b7se\u00b7res", "als", "sie", ",", "und", "Jetzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PIS", "KOKOM", "PPER", "$,", "KON", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.68": {"line.1": {"text": "Endlose Entfaltung der Worte der Zeiten,", "tokens": ["End\u00b7lo\u00b7se", "Ent\u00b7fal\u00b7tung", "der", "Wor\u00b7te", "der", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "+---+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und meins ein Wort der Modernen, das Wort: Masse!", "tokens": ["Und", "meins", "ein", "Wort", "der", "Mo\u00b7der\u00b7nen", ",", "das", "Wort", ":", "Mas\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "ART", "NN", "ART", "NN", "$,", "ART", "NN", "$.", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.69": {"line.1": {"text": "Ein Wort des Glaubens, das nimmer t\u00e4uscht,", "tokens": ["Ein", "Wort", "des", "Glau\u00b7bens", ",", "das", "nim\u00b7mer", "t\u00e4uscht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hier oder fortan, mir ist es gleich, ich vertraue der ", "tokens": ["Hier", "o\u00b7der", "for\u00b7tan", ",", "mir", "ist", "es", "gleich", ",", "ich", "ver\u00b7trau\u00b7e", "der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "$,", "PPER", "VAFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "ART"], "meter": "-+--+-+-+--+--", "measure": "iambic.penta.relaxed"}}, "stanza.70": {"line.1": {"text": "Sie allein ist ohne Unterbrechung, sie allein rundet und vollendet alles,", "tokens": ["Sie", "al\u00b7lein", "ist", "oh\u00b7ne", "Un\u00b7ter\u00b7bre\u00b7chung", ",", "sie", "al\u00b7lein", "run\u00b7det", "und", "voll\u00b7en\u00b7det", "al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "APPR", "NN", "$,", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+-+-+-+--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Dies mystische verwirrende Wunder allein vollendet alles.", "tokens": ["Dies", "mys\u00b7ti\u00b7sche", "ver\u00b7wir\u00b7ren\u00b7de", "Wun\u00b7der", "al\u00b7lein", "voll\u00b7en\u00b7det", "al\u00b7les", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "ADJA", "NN", "ADV", "VVFIN", "PIS", "$."], "meter": "-+-+-+--+--+---+-", "measure": "iambic.hexa.relaxed"}}, "stanza.71": {"line.1": {"text": "Ich nehme die Wirklichkeit hin und wage nicht, sie in Frage zu ziehen,", "tokens": ["Ich", "neh\u00b7me", "die", "Wirk\u00b7lich\u00b7keit", "hin", "und", "wa\u00b7ge", "nicht", ",", "sie", "in", "Fra\u00b7ge", "zu", "zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "PTKNEG", "$,", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Durchtr\u00e4nkt von Materialismus von Anfang bis zu Ende.", "tokens": ["Durch\u00b7tr\u00e4nkt", "von", "Ma\u00b7te\u00b7ri\u00b7a\u00b7lis\u00b7mus", "von", "An\u00b7fang", "bis", "zu", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "APPR", "NN", "APPR", "APPR", "NN", "$."], "meter": "++-+-+-+--+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.72": {"line.1": {"text": "Hoch lebe die positive Wissenschaft! Es lebe die exakte Demonstration!", "tokens": ["Hoch", "le\u00b7be", "die", "po\u00b7si\u00b7ti\u00b7ve", "Wis\u00b7sen\u00b7schaft", "!", "Es", "le\u00b7be", "die", "ex\u00b7ak\u00b7te", "De\u00b7monst\u00b7ra\u00b7ti\u00b7on", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+---+-+-+-+-+-+-+--+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Man hole Mauerpfeffer gemischt mit Ceder und Fliederzweigen;", "tokens": ["Man", "ho\u00b7le", "Mau\u00b7er\u00b7pfef\u00b7fer", "ge\u00b7mischt", "mit", "Ce\u00b7der", "und", "Flie\u00b7der\u00b7zwei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Dies ist der Lexikograph, dies der Chemiker, dieser machte eine Grammatik der alten Keilschriften,", "tokens": ["Dies", "ist", "der", "Le\u00b7xi\u00b7ko\u00b7graph", ",", "dies", "der", "Che\u00b7mi\u00b7ker", ",", "die\u00b7ser", "mach\u00b7te", "ei\u00b7ne", "Gram\u00b7ma\u00b7tik", "der", "al\u00b7ten", "Keil\u00b7schrif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PDS", "ART", "NN", "$,", "PDS", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Diese Seeleute lenkten das Schiff durch gef\u00e4hrliche, unbekannte Meere,", "tokens": ["Die\u00b7se", "See\u00b7leu\u00b7te", "lenk\u00b7ten", "das", "Schiff", "durch", "ge\u00b7f\u00e4hr\u00b7li\u00b7che", ",", "un\u00b7be\u00b7kann\u00b7te", "Mee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "ART", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "--+--+--+--+--+-+-+-", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "Dies ist der Geologe, dieser arbeitet mit dem Zergliederungsmesser, und dies ist ein Mathematiker.", "tokens": ["Dies", "ist", "der", "Geo\u00b7lo\u00b7ge", ",", "die\u00b7ser", "ar\u00b7bei\u00b7tet", "mit", "dem", "Zer\u00b7glie\u00b7de\u00b7rungs\u00b7mes\u00b7ser", ",", "und", "dies", "ist", "ein", "Ma\u00b7the\u00b7ma\u00b7ti\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PDS", "VVFIN", "APPR", "ART", "NN", "$,", "KON", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-+--+--+--+--+-+--", "measure": "iambic.octa.plus.relaxed"}}, "stanza.73": {"line.1": {"text": "Meine Herren! Euch geb\u00fchren stets die h\u00f6chsten Ehren,", "tokens": ["Mei\u00b7ne", "Her\u00b7ren", "!", "Euch", "ge\u00b7b\u00fch\u00b7ren", "stets", "die", "h\u00f6chs\u00b7ten", "Eh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.2": {"text": "Eure Tatsachen sind n\u00fctzlich, doch meine Wohnung sind sie nicht,", "tokens": ["Eu\u00b7re", "Tat\u00b7sa\u00b7chen", "sind", "n\u00fctz\u00b7lich", ",", "doch", "mei\u00b7ne", "Woh\u00b7nung", "sind", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KON", "PPOSAT", "NN", "VAFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+---+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Durch sie trete ich erst in einen Vorhof meiner Wohnung ein.", "tokens": ["Durch", "sie", "tre\u00b7te", "ich", "erst", "in", "ei\u00b7nen", "Vor\u00b7hof", "mei\u00b7ner", "Woh\u00b7nung", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.74": {"line.1": {"text": "Ungest\u00fcm, fleischlich, sinnlich, essend, trinkend und zeugend,", "tokens": ["Un\u00b7ge\u00b7st\u00fcm", ",", "fleischlich", ",", "sinn\u00b7lich", ",", "es\u00b7send", ",", "trin\u00b7kend", "und", "zeu\u00b7gend", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ADJD", "$,", "VVPP", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Kein \u00dcberschw\u00e4nglicher, keiner der \u00fcber M\u00e4nnern und Weibern steht, oder abseits von ihnen,", "tokens": ["Kein", "\u00dc\u00b7bersc\u00b7hw\u00e4ng\u00b7li\u00b7cher", ",", "kei\u00b7ner", "der", "\u00fc\u00b7ber", "M\u00e4n\u00b7nern", "und", "Wei\u00b7bern", "steht", ",", "o\u00b7der", "ab\u00b7seits", "von", "ih\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIS", "ART", "APPR", "NN", "KON", "NN", "VVFIN", "$,", "KON", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+--+--+-+--+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Nicht bescheiden, noch unbescheiden.", "tokens": ["Nicht", "be\u00b7schei\u00b7den", ",", "noch", "un\u00b7be\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.75": {"line.1": {"text": "Schraubt die Schl\u00f6sser von den T\u00fcren los,", "tokens": ["Schraubt", "die", "Schl\u00f6s\u00b7ser", "von", "den", "T\u00fc\u00b7ren", "los", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Schraubt die T\u00fcren selber los von ihren Pfosten!", "tokens": ["Schraubt", "die", "T\u00fc\u00b7ren", "sel\u00b7ber", "los", "von", "ih\u00b7ren", "Pfos\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}}, "stanza.76": {"line.1": {"text": "Wer einen andern erniedrigt, erniedrigt mich,", "tokens": ["Wer", "ei\u00b7nen", "an\u00b7dern", "er\u00b7nied\u00b7rigt", ",", "er\u00b7nied\u00b7rigt", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "VVPP", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und alles was getan oder gesagt wird, f\u00e4llt schlie\u00dflich auf mich zur\u00fcck.", "tokens": ["Und", "al\u00b7les", "was", "ge\u00b7tan", "o\u00b7der", "ge\u00b7sagt", "wird", ",", "f\u00e4llt", "schlie\u00df\u00b7lich", "auf", "mich", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PWS", "VVPP", "KON", "VVPP", "VAFIN", "$,", "VVFIN", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+--+--+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Durch mich wogt und wogt die Geistesflut, durch mich die Str\u00f6mung und der Zeiger.", "tokens": ["Durch", "mich", "wogt", "und", "wogt", "die", "Geis\u00b7tes\u00b7flut", ",", "durch", "mich", "die", "Str\u00f6\u00b7mung", "und", "der", "Zei\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,", "APPR", "PPER", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.77": {"line.1": {"text": "Durch mich verbotene Stimmen,", "tokens": ["Durch", "mich", "ver\u00b7bo\u00b7te\u00b7ne", "Stim\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJA", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Stimmen der Geschlechter und Begierden, verschleierte Stimmen, ich ziehe den Schleier weg,", "tokens": ["Stim\u00b7men", "der", "Ge\u00b7schlech\u00b7ter", "und", "Be\u00b7gier\u00b7den", ",", "ver\u00b7schlei\u00b7er\u00b7te", "Stim\u00b7men", ",", "ich", "zie\u00b7he", "den", "Schlei\u00b7er", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "KON", "NN", "$,", "ADJA", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+---+-+-+--+--+--+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Unz\u00fcchtige Stimmen, durch mich erhellt und verkl\u00e4rt.", "tokens": ["Un\u00b7z\u00fcch\u00b7ti\u00b7ge", "Stim\u00b7men", ",", "durch", "mich", "er\u00b7hellt", "und", "ver\u00b7kl\u00e4rt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "-+--+--+-+--+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Ich presse mir nicht den Finger auf den Mund,", "tokens": ["Ich", "pres\u00b7se", "mir", "nicht", "den", "Fin\u00b7ger", "auf", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ich halte die Eingeweide nicht f\u00fcr geringer als den Kopf und das Herz,", "tokens": ["Ich", "hal\u00b7te", "die", "Ein\u00b7ge\u00b7wei\u00b7de", "nicht", "f\u00fcr", "ge\u00b7rin\u00b7ger", "als", "den", "Kopf", "und", "das", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "ADJD", "KOKOM", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+-+--+-+-+-+--+", "measure": "iambic.octa.plus.relaxed"}, "line.6": {"text": "Begattung ist f\u00fcr mich nicht br\u00fcnstiger als der Tod.", "tokens": ["Be\u00b7gat\u00b7tung", "ist", "f\u00fcr", "mich", "nicht", "br\u00fcns\u00b7ti\u00b7ger", "als", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "PTKNEG", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.78": {"line.1": {"text": "Ich glaube an das Fleisch und die Begierden,", "tokens": ["Ich", "glau\u00b7be", "an", "das", "Fleisch", "und", "die", "Be\u00b7gier\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Gesicht, Geh\u00f6r, Gef\u00fchl sind Wunder, und jeder Teil und Fetzen von mir ist ein Wunder.", "tokens": ["Ge\u00b7sicht", ",", "Ge\u00b7h\u00f6r", ",", "Ge\u00b7f\u00fchl", "sind", "Wun\u00b7der", ",", "und", "je\u00b7der", "Teil", "und", "Fet\u00b7zen", "von", "mir", "ist", "ein", "Wun\u00b7der", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "VAFIN", "NN", "$,", "KON", "PIAT", "NN", "KON", "NN", "APPR", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.79": {"line.1": {"text": "G\u00f6ttlich bin ich innen und au\u00dfen und mache heilig was ich ber\u00fchre, oder was mich ber\u00fchrt,", "tokens": ["G\u00f6tt\u00b7lich", "bin", "ich", "in\u00b7nen", "und", "au\u00b7\u00dfen", "und", "ma\u00b7che", "hei\u00b7lig", "was", "ich", "be\u00b7r\u00fch\u00b7re", ",", "o\u00b7der", "was", "mich", "be\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "KON", "ADV", "KON", "VVFIN", "ADJD", "PWS", "PPER", "VVFIN", "$,", "KON", "PWS", "PPER", "VVPP", "$,"], "meter": "+-+-+--+--+-+-++-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Der Duft dieser Achselh\u00f6hlen ein Aroma feiner als Gebete,", "tokens": ["Der", "Duft", "die\u00b7ser", "Ach\u00b7sel\u00b7h\u00f6h\u00b7len", "ein", "A\u00b7ro\u00b7ma", "fei\u00b7ner", "als", "Ge\u00b7be\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDAT", "NN", "ART", "NN", "ADJA", "KOUS", "NN", "$,"], "meter": "-+--+-+-+++-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Dieses Haupt mehr als Kirchen, Bibeln und alle Glaubensbekenntnisse.", "tokens": ["Die\u00b7ses", "Haupt", "mehr", "als", "Kir\u00b7chen", ",", "Bi\u00b7beln", "und", "al\u00b7le", "Glau\u00b7bens\u00b7be\u00b7kennt\u00b7nis\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PIAT", "KOKOM", "NN", "$,", "NN", "KON", "PIAT", "NN", "$."], "meter": "+-+--+-+--+-+--+--", "measure": "trochaic.septa.relaxed"}}, "stanza.80": {"line.1": {"text": "Den Tagesanbruch zu schauen!", "tokens": ["Den", "Ta\u00b7ge\u00b7san\u00b7bruch", "zu", "schau\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Das erste Licht macht die ungeheure und durchsichtige Schattenwelt verblassen,", "tokens": ["Das", "ers\u00b7te", "Licht", "macht", "die", "un\u00b7ge\u00b7heu\u00b7re", "und", "durch\u00b7sich\u00b7ti\u00b7ge", "Schat\u00b7ten\u00b7welt", "ver\u00b7blas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "KON", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Die Luft schmeckt meinem Gaumen gut.", "tokens": ["Die", "Luft", "schmeckt", "mei\u00b7nem", "Gau\u00b7men", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "Etwas, das ich nicht sehe, richtet l\u00fcsterne Zacken empor,", "tokens": ["Et\u00b7was", ",", "das", "ich", "nicht", "se\u00b7he", ",", "rich\u00b7tet", "l\u00fcs\u00b7ter\u00b7ne", "Za\u00b7cken", "em\u00b7por", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$,", "VVFIN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Meere von gl\u00e4nzend hellem Saft \u00fcberfluten den Himmel.", "tokens": ["Mee\u00b7re", "von", "gl\u00e4n\u00b7zend", "hel\u00b7lem", "Saft", "\u00fc\u00b7berf\u00b7lu\u00b7ten", "den", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJD", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}}, "stanza.82": {"line.1": {"text": "Des Himmels Verweilen bei der Erde, das t\u00e4gliche Schlie\u00dfen ihrer Vereinigung,", "tokens": ["Des", "Him\u00b7mels", "Ver\u00b7wei\u00b7len", "bei", "der", "Er\u00b7de", ",", "das", "t\u00e4g\u00b7li\u00b7che", "Schlie\u00b7\u00dfen", "ih\u00b7rer", "Ver\u00b7ei\u00b7ni\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ART", "NN", "$,", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+--+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Der Ruf der Herausforderung von Osten her, gerade jetzt \u00fcber meinem Haupte,", "tokens": ["Der", "Ruf", "der", "Her\u00b7aus\u00b7for\u00b7de\u00b7rung", "von", "Os\u00b7ten", "her", ",", "ge\u00b7ra\u00b7de", "jetzt", "\u00fc\u00b7ber", "mei\u00b7nem", "Haup\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NN", "PTKVZ", "$,", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Der h\u00f6hnische Spottruf: Siehe denn, ob du Herr wirst!", "tokens": ["Der", "h\u00f6h\u00b7ni\u00b7sche", "Spott\u00b7ruf", ":", "Sie\u00b7he", "denn", ",", "ob", "du", "Herr", "wirst", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVIMP", "ADV", "$,", "KOUS", "PPER", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.83": {"line.1": {"text": "Blendend und gewaltig, wie schnell w\u00fcrde der Sonnenaufgang mich t\u00f6ten,", "tokens": ["Blen\u00b7dend", "und", "ge\u00b7wal\u00b7tig", ",", "wie", "schnell", "w\u00fcr\u00b7de", "der", "Son\u00b7nen\u00b7auf\u00b7gang", "mich", "t\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "$,", "PWAV", "ADJD", "VAFIN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+--+-+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "K\u00f6nnte ich nicht jetzt und allezeit aus mir selber Sonnenaufgang entsenden!", "tokens": ["K\u00f6nn\u00b7te", "ich", "nicht", "jetzt", "und", "al\u00b7le\u00b7zeit", "aus", "mir", "sel\u00b7ber", "Son\u00b7nen\u00b7auf\u00b7gang", "ent\u00b7sen\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "KON", "ADV", "APPR", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-+--+-+-+--+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.84": {"line.1": {"text": "Wir gehen auch blendend und gewaltig auf wie die Sonne,", "tokens": ["Wir", "ge\u00b7hen", "auch", "blen\u00b7dend", "und", "ge\u00b7wal\u00b7tig", "auf", "wie", "die", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "PTKVZ", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wir fanden unser eigenes Ich, o meine Seele, in der Klarheit und K\u00fchle des Tagesanbruchs!", "tokens": ["Wir", "fan\u00b7den", "un\u00b7ser", "ei\u00b7ge\u00b7nes", "Ich", ",", "o", "mei\u00b7ne", "See\u00b7le", ",", "in", "der", "Klar\u00b7heit", "und", "K\u00fch\u00b7le", "des", "Ta\u00b7ge\u00b7san\u00b7bruchs", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "PPER", "$,", "FM", "PPOSAT", "NN", "$,", "APPR", "ART", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+---+--+-+-+--+--+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.85": {"line.1": {"text": "Mit einer Drehung meiner Zunge umfange ich Welten und Massen von Welten.", "tokens": ["Mit", "ei\u00b7ner", "Dre\u00b7hung", "mei\u00b7ner", "Zun\u00b7ge", "um\u00b7fan\u00b7ge", "ich", "Wel\u00b7ten", "und", "Mas\u00b7sen", "von", "Wel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+--+--+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.86": {"line.1": {"text": "Die Sprache ist der Zwilling meines Schauens, sie kann sich selbst nicht messen,", "tokens": ["Die", "Spra\u00b7che", "ist", "der", "Zwil\u00b7ling", "mei\u00b7nes", "Schau\u00b7ens", ",", "sie", "kann", "sich", "selbst", "nicht", "mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$,", "PPER", "VMFIN", "PRF", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Sie reizt mich unaufh\u00f6rlich, sie spricht spottend:", "tokens": ["Sie", "reizt", "mich", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", ",", "sie", "spricht", "spot\u00b7tend", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Lieber Walt, du enth\u00e4ltst doch genug, warum gibst du es nicht von dir?", "tokens": ["Lie\u00b7ber", "Walt", ",", "du", "ent\u00b7h\u00e4ltst", "doch", "ge\u00b7nug", ",", "wa\u00b7rum", "gibst", "du", "es", "nicht", "von", "dir", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "PPER", "VVFIN", "ADV", "ADV", "$,", "PWAV", "VVFIN", "PPER", "PPER", "PTKNEG", "APPR", "PPER", "$."], "meter": "+-+--+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.87": {"line.1": {"text": "Komm nur! ich lasse mich nicht necken, du h\u00e4ltst zu viel vom Ausdr\u00fccken,", "tokens": ["Komm", "nur", "!", "ich", "las\u00b7se", "mich", "nicht", "ne\u00b7cken", ",", "du", "h\u00e4ltst", "zu", "viel", "vom", "Aus\u00b7dr\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,", "PPER", "VVFIN", "APPR", "PIAT", "APPRART", "NN", "$,"], "meter": "-+-+--+---+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wei\u00dft du nicht, o Sprache, wie die Knospen sich in dir entfalten?", "tokens": ["Wei\u00dft", "du", "nicht", ",", "o", "Spra\u00b7che", ",", "wie", "die", "Knos\u00b7pen", "sich", "in", "dir", "ent\u00b7fal\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$,", "FM", "NN", "$,", "PWAV", "ART", "NN", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.3": {"text": "Wartend im Dunkeln, vom Frost beh\u00fctet,", "tokens": ["War\u00b7tend", "im", "Dun\u00b7keln", ",", "vom", "Frost", "be\u00b7h\u00fc\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "ADJA", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Der Schmutz zur\u00fcckweichend vor meinen prophetischen Rufen,", "tokens": ["Der", "Schmutz", "zu\u00b7r\u00fcck\u00b7wei\u00b7chend", "vor", "mei\u00b7nen", "pro\u00b7phe\u00b7ti\u00b7schen", "Ru\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.5": {"text": "Mein Ich, allen Ursachen zu Grunde liegend, um sie endlich ins Gleichgewicht zu bringen,", "tokens": ["Mein", "Ich", ",", "al\u00b7len", "Ur\u00b7sa\u00b7chen", "zu", "Grun\u00b7de", "lie\u00b7gend", ",", "um", "sie", "end\u00b7lich", "ins", "Gleich\u00b7ge\u00b7wicht", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "PPER", "$,", "PIAT", "NN", "APPR", "NN", "VVPP", "$,", "KOUI", "PPER", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+---+-+-+-+--+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": "Mein Wissen lebendige Teile von mir, das mit der Bedeutung aller Dinge Schritt h\u00e4lt:", "tokens": ["Mein", "Wis\u00b7sen", "le\u00b7ben\u00b7di\u00b7ge", "Tei\u00b7le", "von", "mir", ",", "das", "mit", "der", "Be\u00b7deu\u00b7tung", "al\u00b7ler", "Din\u00b7ge", "Schritt", "h\u00e4lt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "APPR", "PPER", "$,", "PRELS", "APPR", "ART", "NN", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+---+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Gl\u00fcckseligkeit (wer immer mich h\u00f6rt, Mann oder Weib, mag heute noch aufbrechen, sie zu finden).", "tokens": ["Gl\u00fcck\u00b7se\u00b7lig\u00b7keit", "(", "wer", "im\u00b7mer", "mich", "h\u00f6rt", ",", "Mann", "o\u00b7der", "Weib", ",", "mag", "heu\u00b7te", "noch", "auf\u00b7bre\u00b7chen", ",", "sie", "zu", "fin\u00b7den", ")", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$(", "PWS", "ADV", "PPER", "VVFIN", "$,", "NN", "KON", "NN", "$,", "VMFIN", "ADV", "ADV", "VVINF", "$,", "PPER", "PTKZU", "VVINF", "$(", "$."], "meter": "+--+-+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}}, "stanza.88": {"line.1": {"text": "Schreiben und Reden beweisen mich nicht,", "tokens": ["Schrei\u00b7ben", "und", "Re\u00b7den", "be\u00b7wei\u00b7sen", "mich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Ich trage den reichlichsten Beweis und alles andere in meinem Antlitz,", "tokens": ["Ich", "tra\u00b7ge", "den", "reich\u00b7lichs\u00b7ten", "Be\u00b7weis", "und", "al\u00b7les", "an\u00b7de\u00b7re", "in", "mei\u00b7nem", "Ant\u00b7litz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "PIS", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.89": {"line.1": {"text": "Ich will jetzt nichts tun als lauschen,", "tokens": ["Ich", "will", "jetzt", "nichts", "tun", "als", "lau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIS", "VVINF", "KOKOM", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Um das, was ich h\u00f6re, in diesem Liede aufzufangen, damit alle T\u00f6ne dazu beitragen.", "tokens": ["Um", "das", ",", "was", "ich", "h\u00f6\u00b7re", ",", "in", "die\u00b7sem", "Lie\u00b7de", "auf\u00b7zu\u00b7fan\u00b7gen", ",", "da\u00b7mit", "al\u00b7le", "T\u00f6\u00b7ne", "da\u00b7zu", "bei\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "PDAT", "NN", "VVIZU", "$,", "KOUS", "PIAT", "NN", "PAV", "VVINF", "$."], "meter": "-+--+--+-+-+-+-+-+-+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.90": {"line.1": {"text": "Ich h\u00f6re das Cello (es ist des J\u00fcnglings Herzensklage),", "tokens": ["Ich", "h\u00f6\u00b7re", "das", "Cel\u00b7lo", "(", "es", "ist", "des", "J\u00fcng\u00b7lings", "Her\u00b7zens\u00b7kla\u00b7ge", ")", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "PPER", "VAFIN", "ART", "ADJA", "NN", "$(", "$,"], "meter": "-+--++-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Ich h\u00f6re das Klappenhorn, die T\u00f6ne dringen schnell in mein Ohr", "tokens": ["Ich", "h\u00f6\u00b7re", "das", "Klap\u00b7pen\u00b7horn", ",", "die", "T\u00f6\u00b7ne", "drin\u00b7gen", "schnell", "in", "mein", "Ohr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Und durchsch\u00fcttern mit wild-s\u00fc\u00dfen St\u00f6\u00dfen mir Bauch und Brust.", "tokens": ["Und", "durch\u00b7sch\u00fct\u00b7tern", "mit", "wild\u00b7s\u00fc\u00b7\u00dfen", "St\u00f6\u00b7\u00dfen", "mir", "Bauch", "und", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PPER", "NN", "KON", "NN", "$."], "meter": "--+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.91": {"line.1": {"text": "Ich h\u00f6re den Chorgesang, eine gro\u00dfe Oper,", "tokens": ["Ich", "h\u00f6\u00b7re", "den", "Chor\u00b7ge\u00b7sang", ",", "ei\u00b7ne", "gro\u00b7\u00dfe", "O\u00b7per", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ach! Das ist wahrhaftig Musik \u2013 die stimmt zu mir.", "tokens": ["Ach", "!", "Das", "ist", "wahr\u00b7haf\u00b7tig", "Mu\u00b7sik", "\u2013", "die", "stimmt", "zu", "mir", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PDS", "VAFIN", "ADJD", "NN", "$(", "ART", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.92": {"line.1": {"text": "Eine Tenorstimme, gro\u00df und frisch wie die Sch\u00f6pfung, erf\u00fcllt mich,", "tokens": ["Ei\u00b7ne", "Te\u00b7nor\u00b7stim\u00b7me", ",", "gro\u00df", "und", "frisch", "wie", "die", "Sch\u00f6p\u00b7fung", ",", "er\u00b7f\u00fcllt", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "ADJD", "KOKOM", "ART", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-+--+--+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Der bogenf\u00f6rmigen W\u00f6lbung seines Mundes entstr\u00f6mt es und f\u00fcllt mich ganz.", "tokens": ["Der", "bo\u00b7gen\u00b7f\u00f6r\u00b7mi\u00b7gen", "W\u00f6l\u00b7bung", "sei\u00b7nes", "Mun\u00b7des", "ent\u00b7str\u00f6mt", "es", "und", "f\u00fcllt", "mich", "ganz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+-+-+--+--+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.93": {"line.1": {"text": "Ist dies eine Ber\u00fchrung? mich durchzuckend zu einem neuen Wesen?", "tokens": ["Ist", "dies", "ei\u00b7ne", "Be\u00b7r\u00fch\u00b7rung", "?", "mich", "durch\u00b7zu\u00b7ckend", "zu", "ei\u00b7nem", "neu\u00b7en", "We\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$.", "PPER", "VVPP", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Flammen und \u00c4ther str\u00f6men ein auf meine Adern,", "tokens": ["Flam\u00b7men", "und", "\u00c4\u00b7ther", "str\u00f6\u00b7men", "ein", "auf", "mei\u00b7ne", "A\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ART", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Verr\u00e4terische F\u00fchlh\u00f6rner, von mir ausgestreckt um ihnen zu helfen,", "tokens": ["Ver\u00b7r\u00e4\u00b7te\u00b7ri\u00b7sche", "F\u00fchl\u00b7h\u00f6r\u00b7ner", ",", "von", "mir", "aus\u00b7ge\u00b7streckt", "um", "ih\u00b7nen", "zu", "hel\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "PPER", "VVFIN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Mein Fleisch und Blut Blitze ausstrahlend, um zu treffen was kaum verschieden von mir ist,", "tokens": ["Mein", "Fleisch", "und", "Blut", "Blit\u00b7ze", "aus\u00b7strah\u00b7lend", ",", "um", "zu", "tref\u00b7fen", "was", "kaum", "ver\u00b7schie\u00b7den", "von", "mir", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "NN", "VVPP", "$,", "KOUI", "PTKZU", "VVINF", "PRELS", "ADV", "VVPP", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-++-+--+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Auf allen Seiten ein Jucken und Reizen, das meine Glieder straff werden,", "tokens": ["Auf", "al\u00b7len", "Sei\u00b7ten", "ein", "Ju\u00b7cken", "und", "Rei\u00b7zen", ",", "das", "mei\u00b7ne", "Glie\u00b7der", "straff", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "KON", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "VAINF", "$,"], "meter": "-+-+--+--+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "Aus meines Herzens Euter pre\u00dft es den zur\u00fcckgehaltenen letzten Tropfen,", "tokens": ["Aus", "mei\u00b7nes", "Her\u00b7zens", "Eu\u00b7ter", "pre\u00dft", "es", "den", "zu\u00b7r\u00fcck\u00b7ge\u00b7hal\u00b7te\u00b7nen", "letz\u00b7ten", "Trop\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NE", "VVFIN", "PPER", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.7": {"text": "Benimmt sich schamlos gegen mich, k\u00fcmmert sich um keine Zur\u00fcckweisung,", "tokens": ["Be\u00b7nimmt", "sich", "scham\u00b7los", "ge\u00b7gen", "mich", ",", "k\u00fcm\u00b7mert", "sich", "um", "kei\u00b7ne", "Zu\u00b7r\u00fcck\u00b7wei\u00b7sung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "PPER", "$,", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.8": {"text": "Beraubt mich meines Besten, als w\u00e4re es mit Vorsatz,", "tokens": ["Be\u00b7raubt", "mich", "mei\u00b7nes", "Bes\u00b7ten", ",", "als", "w\u00e4\u00b7re", "es", "mit", "Vor\u00b7satz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,", "KOKOM", "VAFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Kn\u00f6pft meine Kleider auf, fa\u00dft mich um den blo\u00dfen Leib,", "tokens": ["Kn\u00f6pft", "mei\u00b7ne", "Klei\u00b7der", "auf", ",", "fa\u00dft", "mich", "um", "den", "blo\u00b7\u00dfen", "Leib", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKVZ", "$,", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.10": {"text": "T\u00e4uscht meine Verwirrung mit der Ruhe des Sonnenscheins und der Wiesen,", "tokens": ["T\u00e4uscht", "mei\u00b7ne", "Ver\u00b7wir\u00b7rung", "mit", "der", "Ru\u00b7he", "des", "Son\u00b7nen\u00b7scheins", "und", "der", "Wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.11": {"text": "Schleppt meine \u00fcbrigen Sinne unz\u00fcchtig von mir weg,", "tokens": ["Schleppt", "mei\u00b7ne", "\u00fcb\u00b7ri\u00b7gen", "Sin\u00b7ne", "un\u00b7z\u00fcch\u00b7tig", "von", "mir", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "ADJA", "NN", "ADJD", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.12": {"text": "Keine R\u00fccksicht, keine Acht auf meine sinkende Kraft oder auf meinen Zorn,", "tokens": ["Kei\u00b7ne", "R\u00fcck\u00b7sicht", ",", "kei\u00b7ne", "Acht", "auf", "mei\u00b7ne", "sin\u00b7ken\u00b7de", "Kraft", "o\u00b7der", "auf", "mei\u00b7nen", "Zorn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "CARD", "APPR", "PPOSAT", "ADJA", "NN", "KON", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.13": {"text": "Die \u00fcbrige Herde herbeiholend, da\u00df sie sich eine Weile erg\u00f6tzen,", "tokens": ["Die", "\u00fcb\u00b7ri\u00b7ge", "Her\u00b7de", "her\u00b7bei\u00b7ho\u00b7lend", ",", "da\u00df", "sie", "sich", "ei\u00b7ne", "Wei\u00b7le", "er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,", "KOUS", "PPER", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.14": {"text": "Dann alle vereint auf einem Vorsprung stehen, um mich zu verh\u00f6hnen!", "tokens": ["Dann", "al\u00b7le", "ver\u00b7eint", "auf", "ei\u00b7nem", "Vor\u00b7sprung", "ste\u00b7hen", ",", "um", "mich", "zu", "ver\u00b7h\u00f6h\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVPP", "APPR", "ART", "NN", "VVFIN", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.94": {"line.1": {"text": "Die Schildwachen verlassen jeden andern Teil von mir,", "tokens": ["Die", "Schild\u00b7wa\u00b7chen", "ver\u00b7las\u00b7sen", "je\u00b7den", "an\u00b7dern", "Teil", "von", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+---+-+-+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Sie haben mich h\u00fclflos einem roten R\u00e4uber ausgeliefert,", "tokens": ["Sie", "ha\u00b7ben", "mich", "h\u00fcl\u00b7flos", "ei\u00b7nem", "ro\u00b7ten", "R\u00e4u\u00b7ber", "aus\u00b7ge\u00b7lie\u00b7fert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Sie kommen alle auf den Vorsprung, um gegen mich zu zeugen und mitzuhelfen.", "tokens": ["Sie", "kom\u00b7men", "al\u00b7le", "auf", "den", "Vor\u00b7sprung", ",", "um", "ge\u00b7gen", "mich", "zu", "zeu\u00b7gen", "und", "mit\u00b7zu\u00b7hel\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "NN", "$,", "KOUI", "APPR", "PPER", "PTKZU", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+--+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.95": {"line.1": {"text": "Ich bin Verr\u00e4tern preisgegeben!", "tokens": ["Ich", "bin", "Ver\u00b7r\u00e4\u00b7tern", "preis\u00b7ge\u00b7ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich rede verwirrt, ich habe den Verstand verloren, ich bin selbst der gr\u00f6\u00dfte Verr\u00e4ter,", "tokens": ["Ich", "re\u00b7de", "ver\u00b7wirrt", ",", "ich", "ha\u00b7be", "den", "Ver\u00b7stand", "ver\u00b7lo\u00b7ren", ",", "ich", "bin", "selbst", "der", "gr\u00f6\u00df\u00b7te", "Ver\u00b7r\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+--+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Ich ging selber zuerst auf die Spitze des Vorsprungs, meine eigenen H\u00e4nde trugen mich dorthin.", "tokens": ["Ich", "ging", "sel\u00b7ber", "zu\u00b7erst", "auf", "die", "Spit\u00b7ze", "des", "Vor\u00b7sprungs", ",", "mei\u00b7ne", "ei\u00b7ge\u00b7nen", "H\u00e4n\u00b7de", "tru\u00b7gen", "mich", "dor\u00b7thin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "ART", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+---+--+--+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.96": {"line.1": {"text": "Schurkische Ber\u00fchrung was machst du? der Atem erstickt in meiner Kehle,", "tokens": ["Schur\u00b7ki\u00b7sche", "Be\u00b7r\u00fch\u00b7rung", "was", "machst", "du", "?", "der", "A\u00b7tem", "er\u00b7stickt", "in", "mei\u00b7ner", "Keh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PWS", "VVFIN", "PPER", "$.", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+---+--+--+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "\u00d6ffne deine Fluttore, du bist zu stark f\u00fcr mich!", "tokens": ["\u00d6ff\u00b7ne", "dei\u00b7ne", "Flut\u00b7to\u00b7re", ",", "du", "bist", "zu", "stark", "f\u00fcr", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "PTKA", "ADJD", "APPR", "PPER", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}}, "stanza.97": {"line.1": {"text": "Blinde, liebevolle, ringende Ber\u00fchrung, verh\u00fcllte, verkappte, scharfzahnige Ber\u00fchrung!", "tokens": ["Blin\u00b7de", ",", "lie\u00b7be\u00b7vol\u00b7le", ",", "rin\u00b7gen\u00b7de", "Be\u00b7r\u00fch\u00b7rung", ",", "ver\u00b7h\u00fcll\u00b7te", ",", "ver\u00b7kapp\u00b7te", ",", "scharf\u00b7zah\u00b7ni\u00b7ge", "Be\u00b7r\u00fch\u00b7rung", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+---+--+--+-+-+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Hat es dir so weh getan, mich loszulassen?", "tokens": ["Hat", "es", "dir", "so", "weh", "ge\u00b7tan", ",", "mich", "los\u00b7zu\u00b7las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Dem Enteilenden auf der Spur folgt das Ankommende, die ewige Zahlung ewigen Darlehns,", "tokens": ["Dem", "Ent\u00b7ei\u00b7len\u00b7den", "auf", "der", "Spur", "folgt", "das", "An\u00b7kom\u00b7men\u00b7de", ",", "die", "e\u00b7wi\u00b7ge", "Zah\u00b7lung", "e\u00b7wi\u00b7gen", "Dar\u00b7lehns", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "--+--+-+--+----+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Reichlich str\u00f6mt der Regen herunter, und noch reicher wird nachher der Ausgleich sein.", "tokens": ["Reich\u00b7lich", "str\u00f6mt", "der", "Re\u00b7gen", "her\u00b7un\u00b7ter", ",", "und", "noch", "rei\u00b7cher", "wird", "nach\u00b7her", "der", "Aus\u00b7gleich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KON", "ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.98": {"line.1": {"text": "Landschaften werden da entworfen, m\u00e4nnlich volle, goldene Landschaften.", "tokens": ["Land\u00b7schaf\u00b7ten", "wer\u00b7den", "da", "ent\u00b7wor\u00b7fen", ",", "m\u00e4nn\u00b7lich", "vol\u00b7le", ",", "gol\u00b7de\u00b7ne", "Land\u00b7schaf\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "VVPP", "$,", "ADJD", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+--++-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.99": {"line.1": {"text": "Alle Wahrheiten harren in allen Dingen,", "tokens": ["Al\u00b7le", "Wahr\u00b7hei\u00b7ten", "har\u00b7ren", "in", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Sie haben's nicht eilig mit ihrer Befreiung, noch widerstehen sie ihr,", "tokens": ["Sie", "ha\u00b7ben's", "nicht", "ei\u00b7lig", "mit", "ih\u00b7rer", "Be\u00b7frei\u00b7ung", ",", "noch", "wi\u00b7der\u00b7ste\u00b7hen", "sie", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "APPR", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+--+--+--+--+-+--+", "measure": "amphibrach.penta.plus"}, "line.3": {"text": "Sie bed\u00fcrfen nicht der Zange des Geburtshelfers.", "tokens": ["Sie", "be\u00b7d\u00fcr\u00b7fen", "nicht", "der", "Zan\u00b7ge", "des", "Ge\u00b7burts\u00b7hel\u00b7fers", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-++-", "measure": "unknown.measure.septa"}, "line.4": {"text": "Das Unbedeutende ist mir so wichtig wie irgend etwas,", "tokens": ["Das", "Un\u00b7be\u00b7deu\u00b7ten\u00b7de", "ist", "mir", "so", "wich\u00b7tig", "wie", "ir\u00b7gend", "et\u00b7was", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADJD", "KOKOM", "ADV", "PIS", "$,"], "meter": "-+-+--+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "(was ist weniger oder was ist mehr als eine Ber\u00fchrung?).", "tokens": ["(", "was", "ist", "we\u00b7ni\u00b7ger", "o\u00b7der", "was", "ist", "mehr", "als", "ei\u00b7ne", "Be\u00b7r\u00fch\u00b7rung", "?", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PWS", "VAFIN", "ADV", "KON", "PWS", "VAFIN", "PIS", "KOKOM", "ART", "NN", "$.", "$(", "$."], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.100": {"line.1": {"text": "Logik und Predigten \u00fcberzeugen niemals,", "tokens": ["Lo\u00b7gik", "und", "Pre\u00b7dig\u00b7ten", "\u00fc\u00b7berz\u00b7eu\u00b7gen", "nie\u00b7mals", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der feuchte Dunst der Nacht dringt tiefer in meine Seele.", "tokens": ["Der", "feuch\u00b7te", "Dunst", "der", "Nacht", "dringt", "tie\u00b7fer", "in", "mei\u00b7ne", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.101": {"line.1": {"text": "Ich glaube ein Grashalm ist nicht geringer als das Tagewerk der Sterne,", "tokens": ["Ich", "glau\u00b7be", "ein", "Gras\u00b7halm", "ist", "nicht", "ge\u00b7rin\u00b7ger", "als", "das", "Ta\u00b7ge\u00b7werk", "der", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "KOKOM", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und die Ameise ist ebenso vollkommen, oder ein Sandkorn, oder des Zaunk\u00f6nigs Ei,", "tokens": ["Und", "die", "A\u00b7mei\u00b7se", "ist", "e\u00b7ben\u00b7so", "voll\u00b7kom\u00b7men", ",", "o\u00b7der", "ein", "Sand\u00b7korn", ",", "o\u00b7der", "des", "Zaun\u00b7k\u00f6\u00b7nigs", "Ei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,", "KON", "ART", "NN", "$,", "KON", "ART", "NN", "NN", "$,"], "meter": "--+---+-+-+-+--+-+--+--+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Die Baumkr\u00f6te ist ein Meisterst\u00fcck f\u00fcr den Allerh\u00f6chsten,", "tokens": ["Die", "Baum\u00b7kr\u00f6\u00b7te", "ist", "ein", "Meis\u00b7ter\u00b7st\u00fcck", "f\u00fcr", "den", "Al\u00b7ler\u00b7h\u00f6chs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-++-+-+-+--+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Die Brombeer-Ranken k\u00f6nnten die Hallen des Himmels schm\u00fccken,", "tokens": ["Die", "Brom\u00b7beer\u00b7Ran\u00b7ken", "k\u00f6nn\u00b7ten", "die", "Hal\u00b7len", "des", "Him\u00b7mels", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und das schmalste Gelenkband meiner Hand spottet aller Maschinerie,", "tokens": ["Und", "das", "schmals\u00b7te", "Ge\u00b7lenk\u00b7band", "mei\u00b7ner", "Hand", "spot\u00b7tet", "al\u00b7ler", "Ma\u00b7schi\u00b7ne\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "--+--+-+-+--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Eine Kuh, mit gesenktem Kopfe wiederk\u00e4uend, \u00fcbertrifft jede Bilds\u00e4ule,", "tokens": ["Ei\u00b7ne", "Kuh", ",", "mit", "ge\u00b7senk\u00b7tem", "Kop\u00b7fe", "wie\u00b7der\u00b7k\u00e4u\u00b7end", ",", "\u00fc\u00b7bert\u00b7rifft", "je\u00b7de", "Bild\u00b7s\u00e4u\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ADJA", "NN", "VVPP", "$,", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+--+-+-+-+-+--+-+--", "measure": "trochaic.octa.plus.relaxed"}, "line.7": {"text": "Und eine Maus ist Wunders genug, um unz\u00e4hlige Ungl\u00e4ubige zu bekehren.", "tokens": ["Und", "ei\u00b7ne", "Maus", "ist", "Wun\u00b7ders", "ge\u00b7nug", ",", "um", "un\u00b7z\u00e4h\u00b7li\u00b7ge", "Un\u00b7gl\u00e4u\u00b7bi\u00b7ge", "zu", "be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "ADV", "$,", "KOUI", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.102": {"line.1": {"text": "Ich finde, ich habe Gneis in mir, Kohle, langhaariges Moos, Fr\u00fcchte, \u00c4hren, e\u00dfbare Wurzeln,", "tokens": ["Ich", "fin\u00b7de", ",", "ich", "ha\u00b7be", "Gneis", "in", "mir", ",", "Koh\u00b7le", ",", "lang\u00b7haa\u00b7ri\u00b7ges", "Moos", ",", "Fr\u00fcch\u00b7te", ",", "\u00c4h\u00b7ren", ",", "e\u00df\u00b7ba\u00b7re", "Wur\u00b7zeln", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "NN", "APPR", "PPER", "$,", "NN", "$,", "ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-++-+--+-+-+-+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Und bin aus gutem Grunde \u00fcber das hinausgekommen, was hinter mir liegt,", "tokens": ["Und", "bin", "aus", "gu\u00b7tem", "Grun\u00b7de", "\u00fc\u00b7ber", "das", "hin\u00b7aus\u00b7ge\u00b7kom\u00b7men", ",", "was", "hin\u00b7ter", "mir", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "APPR", "ART", "VVINF", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+--+--+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Kann aber, wenn ich will, alles wieder zur\u00fcckrufen.", "tokens": ["Kann", "a\u00b7ber", ",", "wenn", "ich", "will", ",", "al\u00b7les", "wie\u00b7der", "zu\u00b7r\u00fcck\u00b7ru\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$,", "KOUS", "PPER", "VMFIN", "$,", "PIS", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.103": {"line.1": {"text": "Vergebens alle Eile und Scheu!", "tokens": ["Ver\u00b7ge\u00b7bens", "al\u00b7le", "Ei\u00b7le", "und", "Scheu", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Vergebens stehen die Gegenst\u00e4nde meilenweit voneinander entfernt und nehmen mannigfache Gestalt an,", "tokens": ["Ver\u00b7ge\u00b7bens", "ste\u00b7hen", "die", "Ge\u00b7gen\u00b7st\u00e4n\u00b7de", "mei\u00b7len\u00b7weit", "von\u00b7ein\u00b7an\u00b7der", "ent\u00b7fernt", "und", "neh\u00b7men", "man\u00b7nig\u00b7fa\u00b7che", "Ge\u00b7stalt", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "KON", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+--+--+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Umsonst sinkt der Ozean in die H\u00f6hlung der Wellen und es lauern die Ungeheuer der Tiefe,", "tokens": ["Um\u00b7sonst", "sinkt", "der", "O\u00b7ze\u00b7an", "in", "die", "H\u00f6h\u00b7lung", "der", "Wel\u00b7len", "und", "es", "lau\u00b7ern", "die", "Un\u00b7ge\u00b7heu\u00b7er", "der", "Tie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "KON", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+--+--+-+-+--+-+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Vergebens steigt der M\u00e4usefalk in den Himmel,", "tokens": ["Ver\u00b7ge\u00b7bens", "steigt", "der", "M\u00e4u\u00b7se\u00b7falk", "in", "den", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Vergebens verkriecht sich die Schlange unter die Schlingpflanzen und Holzkl\u00f6tze,", "tokens": ["Ver\u00b7ge\u00b7bens", "ver\u00b7kriecht", "sich", "die", "Schlan\u00b7ge", "un\u00b7ter", "die", "Schling\u00b7pflan\u00b7zen", "und", "Holz\u00b7kl\u00f6t\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-+-+-+--+--", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Vergebens fl\u00fcchtet das Elch in die innersten Gr\u00fcnde des Waldes,", "tokens": ["Ver\u00b7ge\u00b7bens", "fl\u00fcch\u00b7tet", "das", "Elch", "in", "die", "in\u00b7ners\u00b7ten", "Gr\u00fcn\u00b7de", "des", "Wal\u00b7des", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Vergebens segelt der Schermesserschn\u00e4bler gen Norden bis Labrador hinauf,", "tokens": ["Ver\u00b7ge\u00b7bens", "se\u00b7gelt", "der", "Scher\u00b7mes\u00b7ser\u00b7schn\u00e4b\u00b7ler", "gen", "Nor\u00b7den", "bis", "Lab\u00b7ra\u00b7dor", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+-+--+--+--+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.8": {"text": "Ich bin rasch hinterher, ich klettre ihm nach bis zum Nest in der Felsenritze.", "tokens": ["Ich", "bin", "rasch", "hin\u00b7ter\u00b7her", ",", "ich", "klett\u00b7re", "ihm", "nach", "bis", "zum", "Nest", "in", "der", "Fel\u00b7sen\u00b7rit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "APPR", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+--+--+--+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.104": {"line.1": {"text": "Sie schwitzen und wimmern nicht \u00fcber ihre traurige Lage,", "tokens": ["Sie", "schwit\u00b7zen", "und", "wim\u00b7mern", "nicht", "\u00fc\u00b7ber", "ih\u00b7re", "trau\u00b7ri\u00b7ge", "La\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie liegen nicht im Dunkeln wach und weinen \u00fcber ihre S\u00fcnden,", "tokens": ["Sie", "lie\u00b7gen", "nicht", "im", "Dun\u00b7keln", "wach", "und", "wei\u00b7nen", "\u00fc\u00b7ber", "ih\u00b7re", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPRART", "ADJA", "ADJD", "KON", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.3": {"text": "Sie erregen in mir keinen Ekel, denn sie debattieren nicht \u00fcber ihre Pflichten gegen Gott,", "tokens": ["Sie", "er\u00b7re\u00b7gen", "in", "mir", "kei\u00b7nen", "E\u00b7kel", ",", "denn", "sie", "de\u00b7bat\u00b7tie\u00b7ren", "nicht", "\u00fc\u00b7ber", "ih\u00b7re", "Pflich\u00b7ten", "ge\u00b7gen", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PIAT", "NN", "$,", "KON", "PPER", "PDS", "PTKNEG", "APPR", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "--+-+-+-+--+--+--+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Kein einziges kniet vor einem andern oder vor seinesgleichen, der vor Tausenden von Jahren lebte,", "tokens": ["Kein", "ein\u00b7zi\u00b7ges", "kniet", "vor", "ei\u00b7nem", "an\u00b7dern", "o\u00b7der", "vor", "sei\u00b7nes\u00b7glei\u00b7chen", ",", "der", "vor", "Tau\u00b7sen\u00b7den", "von", "Jah\u00b7ren", "leb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VVFIN", "APPR", "ART", "ADJA", "KON", "APPR", "VVINF", "$,", "PRELS", "APPR", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+--+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.5": {"text": "Kein einziges ist \u00bbrespektabel\u00ab oder ungl\u00fcckselig auf der ganzen Erde.", "tokens": ["Kein", "ein\u00b7zi\u00b7ges", "ist", "\u00bb", "res\u00b7pek\u00b7ta\u00b7bel", "\u00ab", "o\u00b7der", "un\u00b7gl\u00fcck\u00b7se\u00b7lig", "auf", "der", "gan\u00b7zen", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "VAFIN", "$(", "ADJD", "$(", "KON", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-++-+-+-+-+-+-+-+-", "measure": "unknown.measure.octa.plus"}}, "stanza.105": {"line.1": {"text": "So zeigen sie ihre Beziehungen zu mir, und ich erkenne sie an,", "tokens": ["So", "zei\u00b7gen", "sie", "ih\u00b7re", "Be\u00b7zie\u00b7hun\u00b7gen", "zu", "mir", ",", "und", "ich", "er\u00b7ken\u00b7ne", "sie", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "PPER", "$,", "KON", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+--+---+--+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Sie bringen mir Zeichen von mir selbst und beweisen deutlich ihren Anteil daran.", "tokens": ["Sie", "brin\u00b7gen", "mir", "Zei\u00b7chen", "von", "mir", "selbst", "und", "be\u00b7wei\u00b7sen", "deut\u00b7lich", "ih\u00b7ren", "An\u00b7teil", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "APPR", "PPER", "ADV", "KON", "VVFIN", "ADJD", "PPOSAT", "NN", "PAV", "$."], "meter": "-+--+-+-+--+-+-+-+--+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.106": {"line.1": {"text": "Ich wundere mich selbst, woher sie diese Zeichen haben k\u00f6nnen?", "tokens": ["Ich", "wun\u00b7de\u00b7re", "mich", "selbst", ",", "wo\u00b7her", "sie", "die\u00b7se", "Zei\u00b7chen", "ha\u00b7ben", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "PDAT", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.2": {"text": "Bin ich selber dort vor riesigen Zeitr\u00e4umen vorbeigegangen und habe sie nachl\u00e4ssig hinfallen lassen?", "tokens": ["Bin", "ich", "sel\u00b7ber", "dort", "vor", "rie\u00b7si\u00b7gen", "Zeit\u00b7r\u00e4u\u00b7men", "vor\u00b7bei\u00b7ge\u00b7gan\u00b7gen", "und", "ha\u00b7be", "sie", "nach\u00b7l\u00e4s\u00b7sig", "hin\u00b7fal\u00b7len", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "APPR", "ADJA", "NN", "VVPP", "KON", "VAFIN", "PPER", "ADJD", "VVINF", "VVINF", "$."], "meter": "+-+-+-+--++-+--+--+---+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Ich selber, vorr\u00fcckend, damals und jetzt und ewig?", "tokens": ["Ich", "sel\u00b7ber", ",", "vor\u00b7r\u00fc\u00b7ckend", ",", "da\u00b7mals", "und", "jetzt", "und", "e\u00b7wig", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "VVPP", "$,", "ADV", "KON", "ADV", "KON", "ADJD", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Immer mehr sammelnd und offenbarend, mit Schnelligkeit,", "tokens": ["Im\u00b7mer", "mehr", "sam\u00b7melnd", "und", "of\u00b7fen\u00b7ba\u00b7rend", ",", "mit", "Schnel\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADJD", "$,", "APPR", "NN", "$,"], "meter": "+--+--+-+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Unendlich und von allerlei Gattung, gleich wie diese unter ihnen,", "tokens": ["Un\u00b7end\u00b7lich", "und", "von", "al\u00b7ler\u00b7lei", "Gat\u00b7tung", ",", "gleich", "wie", "die\u00b7se", "un\u00b7ter", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "APPR", "PIAT", "NN", "$,", "ADV", "KOKOM", "PDS", "APPR", "PPER", "$,"], "meter": "-+-+-+-++-+-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.6": {"text": "Nicht zu vornehm gegen diejenigen, die mir meine Erinnerungszeichen geben,", "tokens": ["Nicht", "zu", "vor\u00b7nehm", "ge\u00b7gen", "die\u00b7je\u00b7ni\u00b7gen", ",", "die", "mir", "mei\u00b7ne", "E\u00b7rin\u00b7ne\u00b7rungs\u00b7zei\u00b7chen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKA", "ADJD", "APPR", "PDS", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+----+--+-+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.7": {"text": "Hier suche ich mir einen aus, den ich liebe, und nun gehe ich br\u00fcderlich mit ihm.", "tokens": ["Hier", "su\u00b7che", "ich", "mir", "ei\u00b7nen", "aus", ",", "den", "ich", "lie\u00b7be", ",", "und", "nun", "ge\u00b7he", "ich", "br\u00fc\u00b7der\u00b7lich", "mit", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "PTKVZ", "$,", "PRELS", "PPER", "VVFIN", "$,", "KON", "ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+--+--+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.107": {"line.1": {"text": "Ein Prachtst\u00fcck von einem Hengst, lebhaft und empf\u00e4nglich f\u00fcr meine Liebkosungen,", "tokens": ["Ein", "Pracht\u00b7st\u00fcck", "von", "ei\u00b7nem", "Hengst", ",", "leb\u00b7haft", "und", "emp\u00b7f\u00e4ng\u00b7lich", "f\u00fcr", "mei\u00b7ne", "Lieb\u00b7ko\u00b7sun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+--+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Sein Kopf ist hoch in der Stirn, breit zwischen den Ohren,", "tokens": ["Sein", "Kopf", "ist", "hoch", "in", "der", "Stirn", ",", "breit", "zwi\u00b7schen", "den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "APPR", "ART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-++-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Glieder gl\u00e4nzend und geschmeidig, der Schweif streift den Boden,", "tokens": ["Die", "Glie\u00b7der", "gl\u00e4n\u00b7zend", "und", "ge\u00b7schmei\u00b7dig", ",", "der", "Schweif", "streift", "den", "Bo\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+--++-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Die Augen voll funkelnder Bosheit, die Ohren fein geschnitten, geschmeidig in der Bewegung.", "tokens": ["Die", "Au\u00b7gen", "voll", "fun\u00b7keln\u00b7der", "Bos\u00b7heit", ",", "die", "Oh\u00b7ren", "fein", "ge\u00b7schnit\u00b7ten", ",", "ge\u00b7schmei\u00b7dig", "in", "der", "Be\u00b7we\u00b7gung", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "VVPP", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+-+-+--+-+--+-", "measure": "amphibrach.tetra.plus"}}, "stanza.108": {"line.1": {"text": "Seine wohlgebauten Glieder beben vor Lust, wenn wir im Kreise herumtoben.", "tokens": ["Sei\u00b7ne", "wohl\u00b7ge\u00b7bau\u00b7ten", "Glie\u00b7der", "be\u00b7ben", "vor", "Lust", ",", "wenn", "wir", "im", "Krei\u00b7se", "her\u00b7um\u00b7to\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,", "KOUS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-+--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.109": {"line.1": {"text": "Ich benutze dich nur eine Minute, mein Hengst, dann gebe ich dich frei,", "tokens": ["Ich", "be\u00b7nut\u00b7ze", "dich", "nur", "ei\u00b7ne", "Mi\u00b7nu\u00b7te", ",", "mein", "Hengst", ",", "dann", "ge\u00b7be", "ich", "dich", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "+-+-+-+--+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Wozu brauche ich deine Spr\u00fcnge, da ich dich selbst im Galopp \u00fcberholen kann?", "tokens": ["Wo\u00b7zu", "brau\u00b7che", "ich", "dei\u00b7ne", "Spr\u00fcn\u00b7ge", ",", "da", "ich", "dich", "selbst", "im", "Ga\u00b7lopp", "\u00fc\u00b7berh\u00b7o\u00b7len", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PRF", "ADV", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "--+--+-+--+-+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Selbst wenn ich sitze oder stehe, komme ich doch schneller weiter als du!", "tokens": ["Selbst", "wenn", "ich", "sit\u00b7ze", "o\u00b7der", "ste\u00b7he", ",", "kom\u00b7me", "ich", "doch", "schnel\u00b7ler", "wei\u00b7ter", "als", "du", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus"}}, "stanza.110": {"line.1": {"text": "Raum und Zeit \u2013 jetzt sehe ich da\u00df es wahr ist, was ich erriet,", "tokens": ["Raum", "und", "Zeit", "\u2013", "jetzt", "se\u00b7he", "ich", "da\u00df", "es", "wahr", "ist", ",", "was", "ich", "er\u00b7riet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$(", "ADV", "VVFIN", "PPER", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Da ich m\u00fc\u00dfig auf dem Grase lag,", "tokens": ["Da", "ich", "m\u00fc\u00b7\u00dfig", "auf", "dem", "Gra\u00b7se", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Was ich erriet, als ich allein im Bette lag,", "tokens": ["Was", "ich", "er\u00b7riet", ",", "als", "ich", "al\u00b7lein", "im", "Bet\u00b7te", "lag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wieder erriet, als ich wandelte am Meeresgestade, unter den erbleichenden Sternen des Morgens.", "tokens": ["Und", "wie\u00b7der", "er\u00b7riet", ",", "als", "ich", "wan\u00b7del\u00b7te", "am", "Mee\u00b7res\u00b7ge\u00b7sta\u00b7de", ",", "un\u00b7ter", "den", "er\u00b7blei\u00b7chen\u00b7den", "Ster\u00b7nen", "des", "Mor\u00b7gens", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "ART", "ADV", "$."], "meter": "-+--+--+-+-+--+-+-+-+--+--+-", "measure": "amphibrach.tri.plus"}}, "stanza.111": {"line.1": {"text": "Ich fliege den Flug einer fl\u00fcssigen, trinkenden Seele,", "tokens": ["Ich", "flie\u00b7ge", "den", "Flug", "ei\u00b7ner", "fl\u00fcs\u00b7si\u00b7gen", ",", "trin\u00b7ken\u00b7den", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.2": {"text": "Meine Bahn geht tief unter die Messungen des Bleilots!", "tokens": ["Mei\u00b7ne", "Bahn", "geht", "tief", "un\u00b7ter", "die", "Mes\u00b7sun\u00b7gen", "des", "Blei\u00b7lots", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.112": {"line.1": {"text": "Ich nehme mir vom K\u00f6rperlichen und Unk\u00f6rperlichen,", "tokens": ["Ich", "neh\u00b7me", "mir", "vom", "K\u00f6r\u00b7per\u00b7li\u00b7chen", "und", "Un\u00b7k\u00f6r\u00b7per\u00b7li\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-+--", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Keine Wache kann mir den Eintritt verwehren, kein Gesetz mich hindern.", "tokens": ["Kei\u00b7ne", "Wa\u00b7che", "kann", "mir", "den", "Ein\u00b7tritt", "ver\u00b7weh\u00b7ren", ",", "kein", "Ge\u00b7setz", "mich", "hin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,", "PIAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.113": {"line.1": {"text": "Nur f\u00fcr kurze Zeit liege ich mit meinem Schiff vor Anker,", "tokens": ["Nur", "f\u00fcr", "kur\u00b7ze", "Zeit", "lie\u00b7ge", "ich", "mit", "mei\u00b7nem", "Schiff", "vor", "An\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "+-+-++-+-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.2": {"text": "Meine Boote kreuzen best\u00e4ndig oder bringen mir ihre Berichte.", "tokens": ["Mei\u00b7ne", "Boo\u00b7te", "kreu\u00b7zen", "be\u00b7st\u00e4n\u00b7dig", "o\u00b7der", "brin\u00b7gen", "mir", "ih\u00b7re", "Be\u00b7rich\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "KON", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+--+-+-+--+--+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.114": {"line.1": {"text": "Ich bin ein Freibeuter, ich biwakiere an den Wachtfeuern hereinbrechender Feinde,", "tokens": ["Ich", "bin", "ein", "Frei\u00b7beu\u00b7ter", ",", "ich", "bi\u00b7wa\u00b7kie\u00b7re", "an", "den", "Wacht\u00b7feu\u00b7ern", "her\u00b7ein\u00b7bre\u00b7chen\u00b7der", "Fein\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+---+-+-+-++-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich werfe den Br\u00e4utigam aus dem Bett und bleibe selber bei der Braut,", "tokens": ["Ich", "wer\u00b7fe", "den", "Br\u00e4u\u00b7ti\u00b7gam", "aus", "dem", "Bett", "und", "blei\u00b7be", "sel\u00b7ber", "bei", "der", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NE", "APPR", "ART", "NN", "KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ich presse sie die ganze Nacht an meine Schenkel und Lippen.", "tokens": ["Ich", "pres\u00b7se", "sie", "die", "gan\u00b7ze", "Nacht", "an", "mei\u00b7ne", "Schen\u00b7kel", "und", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.115": {"line.1": {"text": "Meine Stimme ist des Weibes Stimme, der Aufschrei am Treppengel\u00e4nder,", "tokens": ["Mei\u00b7ne", "Stim\u00b7me", "ist", "des", "Wei\u00b7bes", "Stim\u00b7me", ",", "der", "Auf\u00b7schrei", "am", "Trep\u00b7pen\u00b7ge\u00b7l\u00e4n\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+--+--+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Sie bringen mir meines Mannes Leiche herauf, triefend \u2013 ertrunken.", "tokens": ["Sie", "brin\u00b7gen", "mir", "mei\u00b7nes", "Man\u00b7nes", "Lei\u00b7che", "her\u00b7auf", ",", "trie\u00b7fend", "\u2013", "er\u00b7trun\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "PTKVZ", "$,", "VVPP", "$(", "VVINF", "$."], "meter": "-+--+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.116": {"line.1": {"text": "Ich frage den Verwundeten nicht, wie es ihm geht, ich werde selber der Verwundete,", "tokens": ["Ich", "fra\u00b7ge", "den", "Ver\u00b7wun\u00b7de\u00b7ten", "nicht", ",", "wie", "es", "ihm", "geht", ",", "ich", "wer\u00b7de", "sel\u00b7ber", "der", "Ver\u00b7wun\u00b7de\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PWAV", "PPER", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Meine Wunden werden brandig, w\u00e4hrend ich mich auf meinen Stock lehne und zuschaue.", "tokens": ["Mei\u00b7ne", "Wun\u00b7den", "wer\u00b7den", "bran\u00b7dig", ",", "w\u00e4h\u00b7rend", "ich", "mich", "auf", "mei\u00b7nen", "Stock", "leh\u00b7ne", "und", "zu\u00b7schau\u00b7e", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+-+--+-+-++-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.117": {"line.1": {"text": "Ich bin der zerquetschte Feuerwehrmann mit zerbrochenem Brustbein,", "tokens": ["Ich", "bin", "der", "zer\u00b7quetschte", "Feu\u00b7er\u00b7wehr\u00b7mann", "mit", "zer\u00b7bro\u00b7che\u00b7nem", "Brust\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+---+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "St\u00fcrzende Mauern begruben mich unter ihren Tr\u00fcmmern,", "tokens": ["St\u00fcr\u00b7zen\u00b7de", "Mau\u00b7ern", "be\u00b7gru\u00b7ben", "mich", "un\u00b7ter", "ih\u00b7ren", "Tr\u00fcm\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+--+-+-+-", "measure": "elegiambus"}, "line.3": {"text": "Glut und Rauch atmete ich ein, h\u00f6rte den gellenden Schrei meiner Kameraden,", "tokens": ["Glut", "und", "Rauch", "at\u00b7me\u00b7te", "ich", "ein", ",", "h\u00f6r\u00b7te", "den", "gel\u00b7len\u00b7den", "Schrei", "mei\u00b7ner", "Ka\u00b7me\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+---+--+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "H\u00f6rte das ferne Klickklack ihrer Hacken und Schaufeln,", "tokens": ["H\u00f6r\u00b7te", "das", "fer\u00b7ne", "Klick\u00b7klack", "ih\u00b7rer", "Ha\u00b7cken", "und", "Schau\u00b7feln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.5": {"text": "Sie haben die Balken wegger\u00e4umt, nun ziehen sie mich sanft hervor.", "tokens": ["Sie", "ha\u00b7ben", "die", "Bal\u00b7ken", "weg\u00b7ge\u00b7r\u00e4umt", ",", "nun", "zie\u00b7hen", "sie", "mich", "sanft", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "ADV", "VVFIN", "PPER", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.118": {"line.1": {"text": "Ich liege in der Nachtluft im roten Hemde, Schweigen herrscht um meinetwillen,", "tokens": ["Ich", "lie\u00b7ge", "in", "der", "Nacht\u00b7luft", "im", "ro\u00b7ten", "Hem\u00b7de", ",", "Schwei\u00b7gen", "herrscht", "um", "mei\u00b7net\u00b7wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPRART", "ADJA", "NN", "$,", "NN", "VVFIN", "APPR", "ADV", "$,"], "meter": "-+-+-++-+-+-+-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.2": {"text": "Schmerzlos liege ich da, ersch\u00f6pft, doch nicht ungl\u00fccklich,", "tokens": ["Schmerz\u00b7los", "lie\u00b7ge", "ich", "da", ",", "er\u00b7sch\u00f6pft", ",", "doch", "nicht", "un\u00b7gl\u00fcck\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "$,", "VVPP", "$,", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Wei\u00df und sch\u00f6n sind die Gesichter, die mich umgeben, die H\u00e4upter entbl\u00f6\u00dft von den Feuerhelmen,", "tokens": ["Wei\u00df", "und", "sch\u00f6n", "sind", "die", "Ge\u00b7sich\u00b7ter", ",", "die", "mich", "um\u00b7ge\u00b7ben", ",", "die", "H\u00e4up\u00b7ter", "ent\u00b7bl\u00f6\u00dft", "von", "den", "Feu\u00b7er\u00b7hel\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+--+--+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Die knieende Menge schwindet allm\u00e4hlich mit dem Lichte der Fackeln.", "tokens": ["Die", "kni\u00b7e\u00b7en\u00b7de", "Men\u00b7ge", "schwin\u00b7det", "all\u00b7m\u00e4h\u00b7lich", "mit", "dem", "Lich\u00b7te", "der", "Fa\u00b7ckeln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.119": {"line.1": {"text": "Ich bin ein alter Artillerist, ich erz\u00e4hle vom Bombardement meiner Festung,", "tokens": ["Ich", "bin", "ein", "al\u00b7ter", "Ar\u00b7til\u00b7le\u00b7rist", ",", "ich", "er\u00b7z\u00e4h\u00b7le", "vom", "Bom\u00b7bar\u00b7de\u00b7ment", "mei\u00b7ner", "Fes\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+--++-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich bin wieder dort \u2013", "tokens": ["Ich", "bin", "wie\u00b7der", "dort", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wieder der lange Trommelwirbel,", "tokens": ["Wie\u00b7der", "der", "lan\u00b7ge", "Trom\u00b7mel\u00b7wir\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wieder die feindlichen Gesch\u00fctze, die M\u00f6rser,", "tokens": ["Wie\u00b7der", "die", "feind\u00b7li\u00b7chen", "Ge\u00b7sch\u00fct\u00b7ze", ",", "die", "M\u00f6r\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Wieder antworten Kanonen meinen horchenden Ohren.", "tokens": ["Wie\u00b7der", "ant\u00b7wor\u00b7ten", "Ka\u00b7no\u00b7nen", "mei\u00b7nen", "hor\u00b7chen\u00b7den", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.120": {"line.1": {"text": "Ich beteilige mich, sehe und h\u00f6re alles,", "tokens": ["Ich", "be\u00b7tei\u00b7li\u00b7ge", "mich", ",", "se\u00b7he", "und", "h\u00f6\u00b7re", "al\u00b7les", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "KON", "VVFIN", "PIS", "$,"], "meter": "+-+---+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Die Rufe, Fl\u00fcche, das Gebr\u00fcll, den Beifall f\u00fcr wohlgezielte Sch\u00fcsse,", "tokens": ["Die", "Ru\u00b7fe", ",", "Fl\u00fc\u00b7che", ",", "das", "Ge\u00b7br\u00fcll", ",", "den", "Bei\u00b7fall", "f\u00fcr", "wohl\u00b7ge\u00b7ziel\u00b7te", "Sch\u00fcs\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Arbeiter, die Besch\u00e4digungen untersuchen, machen notwendige Ausbesserungen,", "tokens": ["Ar\u00b7bei\u00b7ter", ",", "die", "Be\u00b7sch\u00e4\u00b7di\u00b7gun\u00b7gen", "un\u00b7ter\u00b7su\u00b7chen", ",", "ma\u00b7chen", "not\u00b7wen\u00b7di\u00b7ge", "Aus\u00b7bes\u00b7se\u00b7run\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "VVINF", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-++--+--+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Das Einfallen der Granaten durch das zerrissene Dach, das f\u00e4cherf\u00f6rmige Platzen,", "tokens": ["Das", "Ein\u00b7fal\u00b7len", "der", "Gra\u00b7na\u00b7ten", "durch", "das", "zer\u00b7ris\u00b7se\u00b7ne", "Dach", ",", "das", "f\u00e4\u00b7cher\u00b7f\u00f6r\u00b7mi\u00b7ge", "Plat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+--+-+--+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Das Sausen von Gliedern, K\u00f6pfen, Steinen, Holz, Eisen hoch in der Luft.", "tokens": ["Das", "Sau\u00b7sen", "von", "Glie\u00b7dern", ",", "K\u00f6p\u00b7fen", ",", "Stei\u00b7nen", ",", "Holz", ",", "Ei\u00b7sen", "hoch", "in", "der", "Luft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+-++-+--+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.121": {"line.1": {"text": "Wieder gurgelt der Mund meines sterbenden Generals, heftig schwenkt er mit der Hand,", "tokens": ["Wie\u00b7der", "gur\u00b7gelt", "der", "Mund", "mei\u00b7nes", "ster\u00b7ben\u00b7den", "Ge\u00b7ne\u00b7rals", ",", "hef\u00b7tig", "schwenkt", "er", "mit", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "ADJA", "NN", "$,", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "--+--+--+--+--+-+-+-+", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "Und keucht durch das geronnene Blut: \u00bbDenkt nicht an mich \u2013 denkt \u2013 an die Schanzen\u00ab ...", "tokens": ["Und", "keucht", "durch", "das", "ge\u00b7ron\u00b7ne\u00b7ne", "Blut", ":", "\u00bb", "Denkt", "nicht", "an", "mich", "\u2013", "denkt", "\u2013", "an", "die", "Schan\u00b7zen", "\u00ab", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "$(", "VVFIN", "PTKNEG", "APPR", "PPER", "$(", "VVFIN", "$(", "APPR", "ART", "NN", "$(", "$("], "meter": "-+-+-+--+-+---+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.122": {"line.1": {"text": "M\u00f6chtest du von einem Seegefecht aus fr\u00fcherer Zeit h\u00f6ren?", "tokens": ["M\u00f6ch\u00b7test", "du", "von", "ei\u00b7nem", "See\u00b7ge\u00b7fecht", "aus", "fr\u00fc\u00b7he\u00b7rer", "Zeit", "h\u00f6\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+---+-", "measure": "unknown.measure.septa"}, "line.2": {"text": "M\u00f6chtest du wissen, wer gewonnen hat beim Lichte des Mondes und der Sterne?", "tokens": ["M\u00f6ch\u00b7test", "du", "wis\u00b7sen", ",", "wer", "ge\u00b7won\u00b7nen", "hat", "beim", "Lich\u00b7te", "des", "Mon\u00b7des", "und", "der", "Ster\u00b7ne", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "PWS", "VVPP", "VAFIN", "APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "H\u00f6r' die Geschichte, wie sie mir meines Gro\u00dfvaters Vater, der Matrose, erz\u00e4hlte.", "tokens": ["H\u00f6r'", "die", "Ge\u00b7schich\u00b7te", ",", "wie", "sie", "mir", "mei\u00b7nes", "Gro\u00df\u00b7va\u00b7ters", "Va\u00b7ter", ",", "der", "Mat\u00b7ro\u00b7se", ",", "er\u00b7z\u00e4hl\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "PPER", "PPOSAT", "NN", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$."], "meter": "+--+-+--+--+-+---+--+-", "measure": "iambic.octa.plus.invert"}}, "stanza.123": {"line.1": {"text": "Der Gang von und nach der Pulverkammer ist jetzt durch Wachen gesperrt,", "tokens": ["Der", "Gang", "von", "und", "nach", "der", "Pul\u00b7ver\u00b7kam\u00b7mer", "ist", "jetzt", "durch", "Wa\u00b7chen", "ge\u00b7sperrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "KON", "APPR", "ART", "NN", "VAFIN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Sie sehen manche fremde Gesichter und wissen nicht, wem zu trauen ist.", "tokens": ["Sie", "se\u00b7hen", "man\u00b7che", "frem\u00b7de", "Ge\u00b7sich\u00b7ter", "und", "wis\u00b7sen", "nicht", ",", "wem", "zu", "trau\u00b7en", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "KON", "VVFIN", "PTKNEG", "$,", "PWS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+--+--+--+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.124": {"line.1": {"text": "Unsere Fregatte f\u00e4ngt Feuer,", "tokens": ["Un\u00b7se\u00b7re", "Fre\u00b7gat\u00b7te", "f\u00e4ngt", "Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "$,"], "meter": "+--++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Die andern fragen, ob wir Gnade verlangen,", "tokens": ["Die", "an\u00b7dern", "fra\u00b7gen", ",", "ob", "wir", "Gna\u00b7de", "ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "$,", "KOUS", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ob wir die Flagge streichen und das Gefecht aus ist?", "tokens": ["Ob", "wir", "die", "Flag\u00b7ge", "strei\u00b7chen", "und", "das", "Ge\u00b7fecht", "aus", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "KON", "ART", "NN", "APPR", "VAFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.125": {"line.1": {"text": "Nun lache ich zufrieden, denn ich h\u00f6re die Stimme meines Kapit\u00e4ns:", "tokens": ["Nun", "la\u00b7che", "ich", "zu\u00b7frie\u00b7den", ",", "denn", "ich", "h\u00f6\u00b7re", "die", "Stim\u00b7me", "mei\u00b7nes", "Ka\u00b7pi\u00b7t\u00e4ns", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "KON", "PPER", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "\u00bbwir streichen nicht\u00ab ruft er gelassen, \u00bbwir fangen erst an zu fechten!\u00ab", "tokens": ["\u00bb", "wir", "strei\u00b7chen", "nicht", "\u00ab", "ruft", "er", "ge\u00b7las\u00b7sen", ",", "\u00bb", "wir", "fan\u00b7gen", "erst", "an", "zu", "fech\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "$(", "VVFIN", "PPER", "VVPP", "$,", "$(", "PPER", "VVFIN", "ADV", "APPR", "PTKZU", "VVINF", "$.", "$("], "meter": "-+--+--+--+--+-+-", "measure": "amphibrach.penta.plus"}}, "stanza.126": {"line.1": {"text": "Sie halten tapfer aus w\u00e4hrend der ganzen Aktion.", "tokens": ["Sie", "hal\u00b7ten", "tap\u00b7fer", "aus", "w\u00e4h\u00b7rend", "der", "gan\u00b7zen", "Ak\u00b7ti\u00b7on", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.127": {"line.1": {"text": "Keinen Augenblick Unterbrechung;", "tokens": ["Kei\u00b7nen", "Au\u00b7gen\u00b7blick", "Un\u00b7ter\u00b7bre\u00b7chung", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Die Lecke steigen, schnell trotz der Pumpen, das Feuer fri\u00dft nach der Pulverkammer hin,", "tokens": ["Die", "Le\u00b7cke", "stei\u00b7gen", ",", "schnell", "trotz", "der", "Pum\u00b7pen", ",", "das", "Feu\u00b7er", "fri\u00dft", "nach", "der", "Pul\u00b7ver\u00b7kam\u00b7mer", "hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ADJD", "APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+--+-+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Eine der Pumpen ist weggeschossen, man glaubt allgemein da\u00df wir sinken.", "tokens": ["Ei\u00b7ne", "der", "Pum\u00b7pen", "ist", "weg\u00b7ge\u00b7schos\u00b7sen", ",", "man", "glaubt", "all\u00b7ge\u00b7mein", "da\u00df", "wir", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "VVPP", "$,", "PIS", "VVFIN", "ADV", "KOUS", "PPER", "VVINF", "$."], "meter": "+--+--+-+--+--+--+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Ruhig steht der kleine Kapit\u00e4n;", "tokens": ["Ru\u00b7hig", "steht", "der", "klei\u00b7ne", "Ka\u00b7pi\u00b7t\u00e4n", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Er ist nicht in Eile, seine Stimme ist weder laut noch schwach,", "tokens": ["Er", "ist", "nicht", "in", "Ei\u00b7le", ",", "sei\u00b7ne", "Stim\u00b7me", "ist", "we\u00b7der", "laut", "noch", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "APPR", "NN", "$,", "PPOSAT", "NN", "VAFIN", "KON", "ADJD", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+--+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": "Seine Augen geben uns mehr Licht als unsere Gefechtslaternen.", "tokens": ["Sei\u00b7ne", "Au\u00b7gen", "ge\u00b7ben", "uns", "mehr", "Licht", "als", "un\u00b7se\u00b7re", "Ge\u00b7fechts\u00b7la\u00b7ter\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PIAT", "NN", "KOKOM", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.128": {"line.1": {"text": "Ihr Lotterbuben dort auf der Wache! seht nach euren Waffen!", "tokens": ["Ihr", "Lot\u00b7ter\u00b7bu\u00b7ben", "dort", "auf", "der", "Wa\u00b7che", "!", "seht", "nach", "eu\u00b7ren", "Waf\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "$.", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Herein durch die eroberten T\u00fcren dr\u00e4ngen sie \u2013 Ich bin besessen!", "tokens": ["Her\u00b7ein", "durch", "die", "er\u00b7o\u00b7ber\u00b7ten", "T\u00fc\u00b7ren", "dr\u00e4n\u00b7gen", "sie", "\u2013", "Ich", "bin", "be\u00b7ses\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Verk\u00f6rpere in mir alle Wesen, ge\u00e4chtete oder leidende,", "tokens": ["Ver\u00b7k\u00f6r\u00b7pe\u00b7re", "in", "mir", "al\u00b7le", "We\u00b7sen", ",", "ge\u00e4ch\u00b7te\u00b7te", "o\u00b7der", "lei\u00b7den\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PIAT", "NN", "$,", "ADJA", "KON", "ADJA", "$,"], "meter": "-+--+-+-+-+--+-+--", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Sehe mich selbst im Gef\u00e4ngnis in der Gestalt eines andern,", "tokens": ["Se\u00b7he", "mich", "selbst", "im", "Ge\u00b7f\u00e4ng\u00b7nis", "in", "der", "Ge\u00b7stalt", "ei\u00b7nes", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "ART", "ADJA", "$,"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.5": {"text": "Und f\u00fchle den dumpfen, ununterbrochenen Schmerz.", "tokens": ["Und", "f\u00fch\u00b7le", "den", "dum\u00b7pfen", ",", "un\u00b7un\u00b7ter\u00b7bro\u00b7che\u00b7nen", "Schmerz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+---+-+-+--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "Meinetwegen schultern die Aufseher der Str\u00e4flinge ihre Gewehre und halten Wache,", "tokens": ["Mei\u00b7net\u00b7we\u00b7gen", "schul\u00b7tern", "die", "Auf\u00b7se\u00b7her", "der", "Str\u00e4f\u00b7lin\u00b7ge", "ih\u00b7re", "Ge\u00b7weh\u00b7re", "und", "hal\u00b7ten", "Wa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+--+-+-++-+--+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.7": {"text": "Ich bin es, den man morgens hinausl\u00e4\u00dft und nachts einsperrt, hinter verriegelten T\u00fcren.", "tokens": ["Ich", "bin", "es", ",", "den", "man", "mor\u00b7gens", "hin\u00b7aus\u00b7l\u00e4\u00dft", "und", "nachts", "ein\u00b7sperrt", ",", "hin\u00b7ter", "ver\u00b7rie\u00b7gel\u00b7ten", "T\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "PIS", "ADV", "VVFIN", "KON", "ADV", "VVPP", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+--+--+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.129": {"line.1": {"text": "Bittende verk\u00f6rpern sich in mir, und ich bin in ihnen verk\u00f6rpert,", "tokens": ["Bit\u00b7ten\u00b7de", "ver\u00b7k\u00f6r\u00b7pern", "sich", "in", "mir", ",", "und", "ich", "bin", "in", "ih\u00b7nen", "ver\u00b7k\u00f6r\u00b7pert", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "PPER", "$,", "KON", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "+---+--+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Ich halte meinen Hut hin, sitze versch\u00e4mt und bettle.", "tokens": ["Ich", "hal\u00b7te", "mei\u00b7nen", "Hut", "hin", ",", "sit\u00b7ze", "ver\u00b7sch\u00e4mt", "und", "bett\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "VVFIN", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.130": {"line.1": {"text": "Da\u00df ich die rinnenden Tr\u00e4nen vergessen k\u00f6nnte, und die Schl\u00e4ge der Keulen und Hammer,", "tokens": ["Da\u00df", "ich", "die", "rin\u00b7nen\u00b7den", "Tr\u00e4\u00b7nen", "ver\u00b7ges\u00b7sen", "k\u00f6nn\u00b7te", ",", "und", "die", "Schl\u00e4\u00b7ge", "der", "Keu\u00b7len", "und", "Ham\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVINF", "VMFIN", "$,", "KON", "ART", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Da\u00df ich wie ein Unbeteiligter meine eigene Kreuzigung und blutige Kr\u00f6nung mitansehen k\u00f6nnte!", "tokens": ["Da\u00df", "ich", "wie", "ein", "Un\u00b7be\u00b7tei\u00b7lig\u00b7ter", "mei\u00b7ne", "ei\u00b7ge\u00b7ne", "Kreu\u00b7zi\u00b7gung", "und", "blu\u00b7ti\u00b7ge", "Kr\u00f6\u00b7nung", "mi\u00b7tan\u00b7se\u00b7hen", "k\u00f6nn\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "PPOSAT", "ADJA", "NN", "KON", "ADJA", "NN", "VVINF", "VMFIN", "$."], "meter": "-+--+-+--+-+--+---+--+---+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.131": {"line.1": {"text": "Jetzt erinnere ich mich,", "tokens": ["Jetzt", "e\u00b7rin\u00b7ne\u00b7re", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Ich nehme die \u00fcbriggebliebene Bruchzahl wieder auf,", "tokens": ["Ich", "neh\u00b7me", "die", "\u00fcb\u00b7rig\u00b7ge\u00b7blie\u00b7be\u00b7ne", "Bruch\u00b7zahl", "wie\u00b7der", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.3": {"text": "Das Felsengrab vervielfacht, was ihm oder irgend einem andern Grabe anvertraut war,", "tokens": ["Das", "Fel\u00b7sen\u00b7grab", "ver\u00b7viel\u00b7facht", ",", "was", "ihm", "o\u00b7der", "ir\u00b7gend", "ei\u00b7nem", "an\u00b7dern", "Gra\u00b7be", "an\u00b7ver\u00b7traut", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "PWS", "PPER", "KON", "ADV", "ART", "ADJA", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Leichen stehen auf, klaffende Wunden heilen, Fesseln fallen von mir ab.", "tokens": ["Lei\u00b7chen", "ste\u00b7hen", "auf", ",", "klaf\u00b7fen\u00b7de", "Wun\u00b7den", "hei\u00b7len", ",", "Fes\u00b7seln", "fal\u00b7len", "von", "mir", "ab", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$,", "ADJA", "NN", "VVINF", "$,", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+--+--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.132": {"line.1": {"text": "Ich ziehe fort, wieder mit h\u00f6chster Kraft erf\u00fcllt, Einer aus dem allgemeinen unendlichen Zuge,", "tokens": ["Ich", "zie\u00b7he", "fort", ",", "wie\u00b7der", "mit", "h\u00f6chs\u00b7ter", "Kraft", "er\u00b7f\u00fcllt", ",", "Ei\u00b7ner", "aus", "dem", "all\u00b7ge\u00b7mei\u00b7nen", "un\u00b7end\u00b7li\u00b7chen", "Zu\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,", "PIS", "APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+---+-+--+-+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Im Binnenland und am Meeresstrand wandeln wir nun, \u00fcberschreiten alle Grenzen,", "tokens": ["Im", "Bin\u00b7nen\u00b7land", "und", "am", "Mee\u00b7res\u00b7strand", "wan\u00b7deln", "wir", "nun", ",", "\u00fc\u00b7bersc\u00b7hrei\u00b7ten", "al\u00b7le", "Gren\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+--+-++-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Unsere schnellen Verordnungen verbreiten sich \u00fcber die ganze Erde,", "tokens": ["Un\u00b7se\u00b7re", "schnel\u00b7len", "Ver\u00b7ord\u00b7nun\u00b7gen", "ver\u00b7brei\u00b7ten", "sich", "\u00fc\u00b7ber", "die", "gan\u00b7ze", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+--++--+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Bl\u00fcten tragen wir auf unsern H\u00fcten, das Wachstum von Jahrtausenden.", "tokens": ["Bl\u00fc\u00b7ten", "tra\u00b7gen", "wir", "auf", "un\u00b7sern", "H\u00fc\u00b7ten", ",", "das", "Wachs\u00b7tum", "von", "Jahr\u00b7tau\u00b7sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-+--+--++--", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.133": {"line.1": {"text": "Ihr Z\u00f6glinge, ich gr\u00fc\u00dfe euch. Kommt nur herbei!", "tokens": ["Ihr", "Z\u00f6g\u00b7lin\u00b7ge", ",", "ich", "gr\u00fc\u00b7\u00dfe", "euch", ".", "Kommt", "nur", "her\u00b7bei", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "$.", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Setzt eure Anmerkungen fort, fahrt fort zu fragen.", "tokens": ["Setzt", "eu\u00b7re", "An\u00b7mer\u00b7kun\u00b7gen", "fort", ",", "fahrt", "fort", "zu", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.134": {"line.1": {"text": "Dieser freundliche und fesselfreie Wilde \u2013 wer mag er sein?", "tokens": ["Die\u00b7ser", "freund\u00b7li\u00b7che", "und", "fes\u00b7sel\u00b7frei\u00b7e", "Wil\u00b7de", "\u2013", "wer", "mag", "er", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "KON", "ADJA", "NN", "$(", "PWS", "VMFIN", "PPER", "VAINF", "$."], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Wartet er noch auf die Zivilisation, oder l\u00e4\u00dft er sie hinter sich und meistert sie?", "tokens": ["War\u00b7tet", "er", "noch", "auf", "die", "Zi\u00b7vi\u00b7li\u00b7sa\u00b7ti\u00b7on", ",", "o\u00b7der", "l\u00e4\u00dft", "er", "sie", "hin\u00b7ter", "sich", "und", "meis\u00b7tert", "sie", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "PPER", "APPR", "PRF", "KON", "VVFIN", "PPER", "$."], "meter": "+--++--+-+-+--+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.135": {"line.1": {"text": "\u00dcberall, wo er hingeht, nehmen M\u00e4nner und Frauen ihn auf und verlangen nach ihm,", "tokens": ["\u00dc\u00b7be\u00b7rall", ",", "wo", "er", "hin\u00b7geht", ",", "neh\u00b7men", "M\u00e4n\u00b7ner", "und", "Frau\u00b7en", "ihn", "auf", "und", "ver\u00b7lan\u00b7gen", "nach", "ihm", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "NN", "KON", "NN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "--+--+-+-+--+--+--+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Sie wollen, da\u00df er sie lieb habe und ber\u00fchre, sie anspreche, bei ihnen bleibe.", "tokens": ["Sie", "wol\u00b7len", ",", "da\u00df", "er", "sie", "lieb", "ha\u00b7be", "und", "be\u00b7r\u00fch\u00b7re", ",", "sie", "an\u00b7spre\u00b7che", ",", "bei", "ih\u00b7nen", "blei\u00b7be", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PPER", "PPER", "ADJD", "VAFIN", "KON", "VVFIN", "$,", "PPER", "VVFIN", "$,", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+--+--+-+-+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.136": {"line.1": {"text": "Flitter des Sonnenscheins, ich brauche dein Leuchten nicht, geh' nur!", "tokens": ["Flit\u00b7ter", "des", "Son\u00b7nen\u00b7scheins", ",", "ich", "brau\u00b7che", "dein", "Leuch\u00b7ten", "nicht", ",", "geh'", "nur", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "PPER", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$,", "VVFIN", "ADV", "$."], "meter": "+--+-+-+--+-+-+", "measure": "iambic.septa.invert"}, "line.2": {"text": "Du beleuchtest nur die Oberfl\u00e4chen, ich dringe durch Oberfl\u00e4chen wie durch Tiefen.", "tokens": ["Du", "be\u00b7leuch\u00b7test", "nur", "die", "O\u00b7berf\u00b7l\u00e4\u00b7chen", ",", "ich", "drin\u00b7ge", "durch", "O\u00b7berf\u00b7l\u00e4\u00b7chen", "wie", "durch", "Tie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "KOKOM", "APPR", "NN", "$."], "meter": "+-+-+-+-+--+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.137": {"line.1": {"text": "Erde, Du scheinst etwas von mir zu erwarten?", "tokens": ["Er\u00b7de", ",", "Du", "scheinst", "et\u00b7was", "von", "mir", "zu", "er\u00b7war\u00b7ten", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "PIS", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-++--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Sprich, alte Haube, wo fehlt's denn?", "tokens": ["Sprich", ",", "al\u00b7te", "Hau\u00b7be", ",", "wo", "fehlt's", "denn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "ADJA", "NN", "$,", "PWAV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.138": {"line.1": {"text": "Mann und Weib, ich m\u00f6chte gern sagen wie lieb ich euch habe, aber ich kann es nicht,", "tokens": ["Mann", "und", "Weib", ",", "ich", "m\u00f6ch\u00b7te", "gern", "sa\u00b7gen", "wie", "lieb", "ich", "euch", "ha\u00b7be", ",", "a\u00b7ber", "ich", "kann", "es", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "PPER", "VMFIN", "ADV", "VVINF", "KOKOM", "ADJD", "PPER", "PPER", "VAFIN", "$,", "KON", "PPER", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+-+--+--+--+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Ich m\u00f6chte sagen was in mir ist, und was in euch ist, aber ich kann es nicht,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "sa\u00b7gen", "was", "in", "mir", "ist", ",", "und", "was", "in", "euch", "ist", ",", "a\u00b7ber", "ich", "kann", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "PRELS", "APPR", "PPER", "VAFIN", "$,", "KON", "PWS", "APPR", "PPER", "VAFIN", "$,", "KON", "PPER", "VMFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+--+-+--+--+--+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Ich m\u00f6chte mein Sehnen k\u00fcnden, den Herzschlag meiner N\u00e4chte und Tage.", "tokens": ["Ich", "m\u00f6ch\u00b7te", "mein", "Seh\u00b7nen", "k\u00fcn\u00b7den", ",", "den", "Herz\u00b7schlag", "mei\u00b7ner", "N\u00e4ch\u00b7te", "und", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+--+-+--+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.139": {"line.1": {"text": "Seht! ich gebe keine Vorlesungen oder kleine milde Gaben,", "tokens": ["Seht", "!", "ich", "ge\u00b7be", "kei\u00b7ne", "Vor\u00b7le\u00b7sun\u00b7gen", "o\u00b7der", "klei\u00b7ne", "mil\u00b7de", "Ga\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "VVFIN", "PIAT", "NN", "KON", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Wann ich gebe, gebe ich mich selbst.", "tokens": ["Wann", "ich", "ge\u00b7be", ",", "ge\u00b7be", "ich", "mich", "selbst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.140": {"line.1": {"text": "Du da! schlapp, mit schlottrigen Knien,", "tokens": ["Du", "da", "!", "schlapp", ",", "mit", "schlott\u00b7ri\u00b7gen", "Kni\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$.", "ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "\u00d6ffne deine klapprigen Kinnbacken, bis ich dir Mark in die Knochen geblasen!", "tokens": ["\u00d6ff\u00b7ne", "dei\u00b7ne", "klapp\u00b7ri\u00b7gen", "Kinn\u00b7ba\u00b7cken", ",", "bis", "ich", "dir", "Mark", "in", "die", "Kno\u00b7chen", "ge\u00b7bla\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "PPER", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+--+--+--+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Breite deine Handfl\u00e4chen aus und ziehe die Klappen deiner Taschen heraus,", "tokens": ["Brei\u00b7te", "dei\u00b7ne", "Hand\u00b7fl\u00e4\u00b7chen", "aus", "und", "zie\u00b7he", "die", "Klap\u00b7pen", "dei\u00b7ner", "Ta\u00b7schen", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKVZ", "KON", "VVFIN", "ART", "NN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+--+-+--+-+-+--+", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Und was ich habe, verschenke ich.", "tokens": ["Und", "was", "ich", "ha\u00b7be", ",", "ver\u00b7schen\u00b7ke", "ich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.141": {"line.1": {"text": "Ich frage nicht wer du bist \u2013 das ist Nebensache,", "tokens": ["Ich", "fra\u00b7ge", "nicht", "wer", "du", "bist", "\u2013", "das", "ist", "Ne\u00b7ben\u00b7sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWS", "PPER", "VAFIN", "$(", "PDS", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du kannst nichts tun und nichts sein, ohne da\u00df ich dich umfassen werde.", "tokens": ["Du", "kannst", "nichts", "tun", "und", "nichts", "sein", ",", "oh\u00b7ne", "da\u00df", "ich", "dich", "um\u00b7fas\u00b7sen", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "VVINF", "KON", "PIS", "VAINF", "$,", "KOUI", "KOUS", "PPER", "PRF", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.142": {"line.1": {"text": "Zu einem Sterbenden eile ich und drehe den T\u00fcrknopf,", "tokens": ["Zu", "ei\u00b7nem", "Ster\u00b7ben\u00b7den", "ei\u00b7le", "ich", "und", "dre\u00b7he", "den", "T\u00fcr\u00b7knopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Schlage das Bettzeug zur\u00fcck bis zum Fu\u00dfende,", "tokens": ["Schla\u00b7ge", "das", "Bett\u00b7zeug", "zu\u00b7r\u00fcck", "bis", "zum", "Fu\u00b7\u00dfen\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKVZ", "APPR", "APPRART", "NN", "$,"], "meter": "+--+--+--+--", "measure": "dactylic.tetra"}, "line.3": {"text": "Lasse Arzt und Priester nach Hause gehn.", "tokens": ["Las\u00b7se", "Arzt", "und", "Pries\u00b7ter", "nach", "Hau\u00b7se", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.143": {"line.1": {"text": "Ich packe den sinkenden Mann und hebe ihn mit unwiderstehlichem Willen,", "tokens": ["Ich", "pa\u00b7cke", "den", "sin\u00b7ken\u00b7den", "Mann", "und", "he\u00b7be", "ihn", "mit", "un\u00b7wi\u00b7der\u00b7steh\u00b7li\u00b7chem", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+--+-+--+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "O Verzweifelnder, hier ist mein Nacken!", "tokens": ["O", "Ver\u00b7zwei\u00b7feln\u00b7der", ",", "hier", "ist", "mein", "Na\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Bei Gott, du sollst nicht untergehn! H\u00e4nge dich mit deinem ganzen Gewicht auf mich,", "tokens": ["Bei", "Gott", ",", "du", "sollst", "nicht", "un\u00b7ter\u00b7gehn", "!", "H\u00e4n\u00b7ge", "dich", "mit", "dei\u00b7nem", "gan\u00b7zen", "Ge\u00b7wicht", "auf", "mich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$.", "NN", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+--+-+-+-+--+-+", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Ich blase dich voll mit gewaltigem Odem, ich mache dich flott,", "tokens": ["Ich", "bla\u00b7se", "dich", "voll", "mit", "ge\u00b7wal\u00b7ti\u00b7gem", "O\u00b7dem", ",", "ich", "ma\u00b7che", "dich", "flott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "$,", "PPER", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+--+--+--+--+--+", "measure": "amphibrach.penta.plus"}, "line.5": {"text": "Alle R\u00e4ume im Hause f\u00fclle ich mit einer bewaffneten Macht,", "tokens": ["Al\u00b7le", "R\u00e4u\u00b7me", "im", "Hau\u00b7se", "f\u00fcl\u00b7le", "ich", "mit", "ei\u00b7ner", "be\u00b7waff\u00b7ne\u00b7ten", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+--+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Mit denen, die mich lieben \u2013 Besiegern des Grabes.", "tokens": ["Mit", "de\u00b7nen", ",", "die", "mich", "lie\u00b7ben", "\u2013", "Be\u00b7sie\u00b7gern", "des", "Gra\u00b7bes", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "$,", "PRELS", "PPER", "VVINF", "$(", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.144": {"line.1": {"text": "Schlafe! \u2013 Ich und sie halten Wacht die ganze Nacht,", "tokens": ["Schla\u00b7fe", "!", "\u2013", "Ich", "und", "sie", "hal\u00b7ten", "Wacht", "die", "gan\u00b7ze", "Nacht", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "KON", "PPER", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Nicht der Zweifel, nicht der Tod soll es wagen, einen Finger an dich zu legen,", "tokens": ["Nicht", "der", "Zwei\u00b7fel", ",", "nicht", "der", "Tod", "soll", "es", "wa\u00b7gen", ",", "ei\u00b7nen", "Fin\u00b7ger", "an", "dich", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PTKNEG", "ART", "NN", "VMFIN", "PPER", "VVINF", "$,", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+--+-+-+--+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Ich habe dich umarmt, und fortan besitze ich dich f\u00fcr mich,", "tokens": ["Ich", "ha\u00b7be", "dich", "um\u00b7armt", ",", "und", "for\u00b7tan", "be\u00b7sit\u00b7ze", "ich", "dich", "f\u00fcr", "mich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "$,", "KON", "ADV", "VVFIN", "PPER", "PRF", "APPR", "PPER", "$,"], "meter": "-+-+-+-+--+--+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und wenn du morgen fr\u00fch aufstehst, wirst du sehen, da\u00df es so ist, wie ich dir sage.", "tokens": ["Und", "wenn", "du", "mor\u00b7gen", "fr\u00fch", "auf\u00b7stehst", ",", "wirst", "du", "se\u00b7hen", ",", "da\u00df", "es", "so", "ist", ",", "wie", "ich", "dir", "sa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,", "VAFIN", "PPER", "VVINF", "$,", "KOUS", "PPER", "ADV", "VAFIN", "$,", "PWAV", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Meine eigene Stimme, vollklingend, entschieden und endg\u00fcltig.", "tokens": ["Mei\u00b7ne", "ei\u00b7ge\u00b7ne", "Stim\u00b7me", ",", "voll\u00b7klin\u00b7gend", ",", "ent\u00b7schie\u00b7den", "und", "end\u00b7g\u00fcl\u00b7tig", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVPP", "$,", "VVPP", "KON", "ADJD", "$."], "meter": "+-+--+--+--+-+-+-", "measure": "trochaic.septa.relaxed"}}, "stanza.145": {"line.1": {"text": "Die kleinen unz\u00e4hligen M\u00e4nnlein, die in Kragen und Fracks herumh\u00fcpfen,", "tokens": ["Die", "klei\u00b7nen", "un\u00b7z\u00e4h\u00b7li\u00b7gen", "M\u00e4nn\u00b7lein", ",", "die", "in", "Kra\u00b7gen", "und", "Fracks", "her\u00b7um\u00b7h\u00fcp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,", "PRELS", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ich wei\u00df wer sie sind (es sind wirklich weder W\u00fcrmer noch Fl\u00f6he),", "tokens": ["Ich", "wei\u00df", "wer", "sie", "sind", "(", "es", "sind", "wirk\u00b7lich", "we\u00b7der", "W\u00fcr\u00b7mer", "noch", "Fl\u00f6\u00b7he", ")", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PWS", "PPER", "VAFIN", "$(", "PPER", "VAFIN", "ADJD", "KON", "NN", "ADV", "NN", "$(", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ich erkenne meine Doppelg\u00e4nger, der schw\u00e4chste und seichteste ist unvertilgbar wie ich,", "tokens": ["Ich", "er\u00b7ken\u00b7ne", "mei\u00b7ne", "Dop\u00b7pel\u00b7g\u00e4n\u00b7ger", ",", "der", "schw\u00e4chs\u00b7te", "und", "seich\u00b7tes\u00b7te", "ist", "un\u00b7ver\u00b7tilg\u00b7bar", "wie", "ich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "KON", "ADJA", "VAFIN", "ADJD", "KOKOM", "PPER", "$,"], "meter": "--+-+-+-+--+--+-+-+-+-++", "measure": "iambic.octa.plus.relaxed"}, "line.4": {"text": "Was ich tue und sage, das harrt auch ihrer,", "tokens": ["Was", "ich", "tue", "und", "sa\u00b7ge", ",", "das", "harrt", "auch", "ih\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "PPOSAT", "$,"], "meter": "-++-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Jeder Gedanke, der in mir zappelt, zappelt auch in ihnen.", "tokens": ["Je\u00b7der", "Ge\u00b7dan\u00b7ke", ",", "der", "in", "mir", "zap\u00b7pelt", ",", "zap\u00b7pelt", "auch", "in", "ih\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}}, "stanza.146": {"line.1": {"text": "Niedergeschlagene Zweifler, tr\u00fcbsinnig und ausgesto\u00dfen,", "tokens": ["Nie\u00b7der\u00b7ge\u00b7schla\u00b7ge\u00b7ne", "Zweif\u00b7ler", ",", "tr\u00fcb\u00b7sin\u00b7nig", "und", "aus\u00b7ge\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KON", "VVINF", "$,"], "meter": "+--+--+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Frivol, m\u00fcrrisch, verdrossen, zornig, ger\u00fchrt, entmutigt, und atheistisch,", "tokens": ["Fri\u00b7vol", ",", "m\u00fcr\u00b7risch", ",", "ver\u00b7dros\u00b7sen", ",", "zor\u00b7nig", ",", "ge\u00b7r\u00fchrt", ",", "ent\u00b7mu\u00b7tigt", ",", "und", "at\u00b7heis\u00b7tisch", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "$,", "VVPP", "$,", "ADJD", "$,", "VVPP", "$,", "VVPP", "$,", "KON", "ADJD", "$,"], "meter": "-+-+-+-+--+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Ich kenne euch alle! ich kenne das Meer von Qual, Zweifel, Verzweiflung und Unglauben.", "tokens": ["Ich", "ken\u00b7ne", "euch", "al\u00b7le", "!", "ich", "ken\u00b7ne", "das", "Meer", "von", "Qual", ",", "Zwei\u00b7fel", ",", "Ver\u00b7zwei\u00b7flung", "und", "Un\u00b7glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$.", "PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+-++--+--+--", "measure": "amphibrach.tetra.plus"}}, "stanza.147": {"line.1": {"text": "Ich wei\u00df nicht, was unversucht ist, und was nachher kommt,", "tokens": ["Ich", "wei\u00df", "nicht", ",", "was", "un\u00b7ver\u00b7sucht", "ist", ",", "und", "was", "nach\u00b7her", "kommt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "ADJD", "VAFIN", "$,", "KON", "PWS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.2": {"text": "Aber ich wei\u00df, es wird sich schon zeigen und ausreichen, es kann nicht fehlen.", "tokens": ["A\u00b7ber", "ich", "wei\u00df", ",", "es", "wird", "sich", "schon", "zei\u00b7gen", "und", "aus\u00b7rei\u00b7chen", ",", "es", "kann", "nicht", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "PRF", "ADV", "VVINF", "KON", "VVINF", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+--+-+--+---+--+-+-", "measure": "iambic.septa.invert"}}, "stanza.148": {"line.1": {"text": "Es ist Zeit, da\u00df ich mich erkl\u00e4re \u2013 erheben wir uns!", "tokens": ["Es", "ist", "Zeit", ",", "da\u00df", "ich", "mich", "er\u00b7kl\u00e4\u00b7re", "\u2013", "er\u00b7he\u00b7ben", "wir", "uns", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$(", "VVFIN", "PPER", "PPER", "$."], "meter": "-++--+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das Bekannte streife ich hinweg,", "tokens": ["Das", "Be\u00b7kann\u00b7te", "strei\u00b7fe", "ich", "hin\u00b7weg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ich lasse alle M\u00e4nner und Weiber mit mir vom Stapel laufen, ins ", "tokens": ["Ich", "las\u00b7se", "al\u00b7le", "M\u00e4n\u00b7ner", "und", "Wei\u00b7ber", "mit", "mir", "vom", "Sta\u00b7pel", "lau\u00b7fen", ",", "ins"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "KON", "NN", "APPR", "PPER", "APPRART", "NN", "VVINF", "$,", "APPRART"], "meter": "-+-+-+--+--+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.149": {"line.1": {"text": "Die Uhr zeigt die Minute \u2013 aber was zeigt die Ewigkeit?", "tokens": ["Die", "Uhr", "zeigt", "die", "Mi\u00b7nu\u00b7te", "\u2013", "a\u00b7ber", "was", "zeigt", "die", "E\u00b7wig\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$(", "KON", "PWS", "VVFIN", "ART", "NN", "$."], "meter": "-++--+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Soweit haben wir schon Trillionen von Sommern und Wintern ersch\u00f6pft,", "tokens": ["So\u00b7weit", "ha\u00b7ben", "wir", "schon", "Tril\u00b7li\u00b7o\u00b7nen", "von", "Som\u00b7mern", "und", "Win\u00b7tern", "er\u00b7sch\u00f6pft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "ADV", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+-+--+--+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Es sind noch Trillionen voraus, und diesen wieder Trillionen voraus.", "tokens": ["Es", "sind", "noch", "Tril\u00b7li\u00b7o\u00b7nen", "vo\u00b7raus", ",", "und", "die\u00b7sen", "wie\u00b7der", "Tril\u00b7li\u00b7o\u00b7nen", "vo\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "PTKVZ", "$,", "KON", "PDS", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+-+-+--+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.150": {"line.1": {"text": "Geburten haben uns F\u00fclle und Mannigfaltigkeit gebracht,", "tokens": ["Ge\u00b7bur\u00b7ten", "ha\u00b7ben", "uns", "F\u00fcl\u00b7le", "und", "Man\u00b7nig\u00b7fal\u00b7tig\u00b7keit", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Und wieder andere Geburten werden uns F\u00fclle und Mannigfaltigkeit bringen.", "tokens": ["Und", "wie\u00b7der", "an\u00b7de\u00b7re", "Ge\u00b7bur\u00b7ten", "wer\u00b7den", "uns", "F\u00fcl\u00b7le", "und", "Man\u00b7nig\u00b7fal\u00b7tig\u00b7keit", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VAFIN", "PPER", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Waren die Menschen mordgierig oder eifers\u00fcchtig gegen dich, mein Bruder, meine Schwester?", "tokens": ["Wa\u00b7ren", "die", "Men\u00b7schen", "mord\u00b7gie\u00b7rig", "o\u00b7der", "ei\u00b7fer\u00b7s\u00fcch\u00b7tig", "ge\u00b7gen", "dich", ",", "mein", "Bru\u00b7der", ",", "mei\u00b7ne", "Schwes\u00b7ter", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-+-+-+-+-+-+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Es tut mir leid um dich, gegen mich waren sie nicht mordgierig und eifers\u00fcchtig,", "tokens": ["Es", "tut", "mir", "leid", "um", "dich", ",", "ge\u00b7gen", "mich", "wa\u00b7ren", "sie", "nicht", "mord\u00b7gie\u00b7rig", "und", "ei\u00b7fer\u00b7s\u00fcch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "$,", "APPR", "PPER", "VAFIN", "PPER", "PTKNEG", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+--+-+--+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Alles war sanft zu mir, ich f\u00fchre keine Rechnung mit der Klage,", "tokens": ["Al\u00b7les", "war", "sanft", "zu", "mir", ",", "ich", "f\u00fch\u00b7re", "kei\u00b7ne", "Rech\u00b7nung", "mit", "der", "Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADJD", "APPR", "PPER", "$,", "PPER", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.invert"}, "line.6": {"text": "(was habe ich mit Klagen zu tun?)", "tokens": ["(", "was", "ha\u00b7be", "ich", "mit", "Kla\u00b7gen", "zu", "tun", "?", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.151": {"line.1": {"text": "Ich bin ein Gipfel vollbrachter Dinge und umschlie\u00dfe Dinge, die sein werden.", "tokens": ["Ich", "bin", "ein", "Gip\u00b7fel", "voll\u00b7brach\u00b7ter", "Din\u00b7ge", "und", "um\u00b7schlie\u00b7\u00dfe", "Din\u00b7ge", ",", "die", "sein", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "VAINF", "$."], "meter": "-+-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Mein Embryo war niemals erstarrt, nichts konnte ihn erdr\u00fccken.", "tokens": ["Mein", "Emb\u00b7ryo", "war", "nie\u00b7mals", "er\u00b7starrt", ",", "nichts", "konn\u00b7te", "ihn", "er\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "$,", "PIS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.152": {"line.1": {"text": "Seinetwillen verdichtete sich der Sternnebel zu einer Kugel,", "tokens": ["Sei\u00b7net\u00b7wil\u00b7len", "ver\u00b7dich\u00b7te\u00b7te", "sich", "der", "Stern\u00b7ne\u00b7bel", "zu", "ei\u00b7ner", "Ku\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Erdschichten t\u00fcrmten sich langsam, ihm ein Ruhelager zu geben,", "tokens": ["Erd\u00b7schich\u00b7ten", "t\u00fcrm\u00b7ten", "sich", "lang\u00b7sam", ",", "ihm", "ein", "Ru\u00b7he\u00b7la\u00b7ger", "zu", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADJD", "$,", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+-+-+-+--+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Ungeheure Pflanzen gaben ihm Nahrung,", "tokens": ["Un\u00b7ge\u00b7heu\u00b7re", "Pflan\u00b7zen", "ga\u00b7ben", "ihm", "Nah\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Riesige Saurier trugen ihn in ihrem Rachen und setzten ihn sorgsam nieder.", "tokens": ["Rie\u00b7si\u00b7ge", "Sau\u00b7rier", "tru\u00b7gen", "ihn", "in", "ih\u00b7rem", "Ra\u00b7chen", "und", "setz\u00b7ten", "ihn", "sorg\u00b7sam", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "+--+-+-+-+-+--+--+-+-", "measure": "iambic.octa.plus.invert"}}, "stanza.153": {"line.1": {"text": "Alle Kr\u00e4fte wurden best\u00e4ndig benutzt, um mich zu vervollst\u00e4ndigen und zu begl\u00fccken,", "tokens": ["Al\u00b7le", "Kr\u00e4f\u00b7te", "wur\u00b7den", "be\u00b7st\u00e4n\u00b7dig", "be\u00b7nutzt", ",", "um", "mich", "zu", "ver\u00b7voll\u00b7st\u00e4n\u00b7di\u00b7gen", "und", "zu", "be\u00b7gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADJD", "VVPP", "$,", "KOUI", "PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "--+-+--+--+-+--++-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Jetzt stehe ich auf dieser Stelle, mit meiner r\u00fcstigen Seele.", "tokens": ["Jetzt", "ste\u00b7he", "ich", "auf", "die\u00b7ser", "Stel\u00b7le", ",", "mit", "mei\u00b7ner", "r\u00fcs\u00b7ti\u00b7gen", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PDAT", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.154": {"line.1": {"text": "O Spanne der Jugend! Stets vorw\u00e4rts getriebene Elastizit\u00e4t!", "tokens": ["O", "Span\u00b7ne", "der", "Ju\u00b7gend", "!", "Stets", "vor\u00b7w\u00e4rts", "ge\u00b7trie\u00b7be\u00b7ne", "E\u00b7las\u00b7ti\u00b7zi\u00b7t\u00e4t", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "$.", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+---+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "O Mannesalter! Im Gleichgewicht, bl\u00fchend und voll.", "tokens": ["O", "Man\u00b7ne\u00b7sal\u00b7ter", "!", "Im", "Gleich\u00b7ge\u00b7wicht", ",", "bl\u00fc\u00b7hend", "und", "voll", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "APPRART", "NN", "$,", "VVPP", "KON", "ADJD", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.3": {"text": "O Greisenalter, herrlich aufsteigend. O willkommen, unaussprechliche Anmut entschwindender Tage!", "tokens": ["O", "Grei\u00b7sen\u00b7al\u00b7ter", ",", "herr\u00b7lich", "auf\u00b7stei\u00b7gend", ".", "O", "will\u00b7kom\u00b7men", ",", "un\u00b7aus\u00b7sprech\u00b7li\u00b7che", "An\u00b7mut", "ent\u00b7schwin\u00b7den\u00b7der", "Ta\u00b7ge", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJD", "VVPP", "$.", "NE", "ADJD", "$,", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-+-+--+--+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.155": {"line.1": {"text": "Jeder Zustand verk\u00fcndet nicht nur sich selbst, er verk\u00fcndet auch, was aus ihm und nach ihm entsteht,", "tokens": ["Je\u00b7der", "Zu\u00b7stand", "ver\u00b7k\u00fcn\u00b7det", "nicht", "nur", "sich", "selbst", ",", "er", "ver\u00b7k\u00fcn\u00b7det", "auch", ",", "was", "aus", "ihm", "und", "nach", "ihm", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PTKNEG", "ADV", "PRF", "ADV", "$,", "PPER", "VVFIN", "ADV", "$,", "PRELS", "APPR", "PPER", "KON", "APPR", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-+-+-+--+--+", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Und das geheimnisvolle Dunkel verk\u00fcndet so viel wie nur irgend etwas.", "tokens": ["Und", "das", "ge\u00b7heim\u00b7nis\u00b7vol\u00b7le", "Dun\u00b7kel", "ver\u00b7k\u00fcn\u00b7det", "so", "viel", "wie", "nur", "ir\u00b7gend", "et\u00b7was", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADV", "PIAT", "KOKOM", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+-+--+--+--+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.156": {"line.1": {"text": "Blicke noch so weit \u2013 grenzenloser Raum liegt dar\u00fcber hinaus,", "tokens": ["Bli\u00b7cke", "noch", "so", "weit", "\u2013", "gren\u00b7zen\u00b7lo\u00b7ser", "Raum", "liegt", "da\u00b7r\u00fc\u00b7ber", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADJD", "$(", "ADJA", "NN", "VVFIN", "PAV", "APZR", "$,"], "meter": "+-+-++-+-+-++--+", "measure": "iambic.octa.plus.octa.plus.chol"}, "line.2": {"text": "Z\u00e4hle noch so hoch \u2013 rundum gibt es grenzenlose Zeit.", "tokens": ["Z\u00e4h\u00b7le", "noch", "so", "hoch", "\u2013", "run\u00b7dum", "gibt", "es", "gren\u00b7zen\u00b7lo\u00b7se", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADJD", "$(", "ADV", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}}, "stanza.157": {"line.1": {"text": "Mein Stelldichein ist festgesetzt, es ist sicher,", "tokens": ["Mein", "Stell\u00b7dich\u00b7ein", "ist", "fest\u00b7ge\u00b7setzt", ",", "es", "ist", "si\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Herr wird dort sein und warten, bis ich komme unter vollendeten Bedingungen,", "tokens": ["Der", "Herr", "wird", "dort", "sein", "und", "war\u00b7ten", ",", "bis", "ich", "kom\u00b7me", "un\u00b7ter", "voll\u00b7en\u00b7de\u00b7ten", "Be\u00b7din\u00b7gun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VAINF", "KON", "VVINF", "$,", "KOUS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "--+-+-+-+-+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Der gro\u00dfe Camerado, der treu Liebende, nach dem ich mich sehne, wird dort sein.", "tokens": ["Der", "gro\u00b7\u00dfe", "Ca\u00b7me\u00b7ra\u00b7do", ",", "der", "treu", "Lie\u00b7ben\u00b7de", ",", "nach", "dem", "ich", "mich", "seh\u00b7ne", ",", "wird", "dort", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "PRELS", "ADJD", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "VVFIN", "$,", "VAFIN", "ADV", "VAINF", "$."], "meter": "-+-+--+--+--+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.158": {"line.1": {"text": "Nicht ich, nicht irgend ein anderer kann diese Stra\u00dfe f\u00fcr dich gehen,", "tokens": ["Nicht", "ich", ",", "nicht", "ir\u00b7gend", "ein", "an\u00b7de\u00b7rer", "kann", "die\u00b7se", "Stra\u00b7\u00dfe", "f\u00fcr", "dich", "ge\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPER", "$,", "PTKNEG", "ADV", "ART", "ADJA", "VMFIN", "PDAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Du mu\u00dft sie selber gehen.", "tokens": ["Du", "mu\u00dft", "sie", "sel\u00b7ber", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.159": {"line.1": {"text": "Sie liegt nicht weit, sie ist in greifbarer N\u00e4he,", "tokens": ["Sie", "liegt", "nicht", "weit", ",", "sie", "ist", "in", "greif\u00b7ba\u00b7rer", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "$,", "PPER", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vielleicht bist du von deiner Geburt an darauf gewesen und wu\u00dftest es nicht,", "tokens": ["Viel\u00b7leicht", "bist", "du", "von", "dei\u00b7ner", "Ge\u00b7burt", "an", "da\u00b7rauf", "ge\u00b7we\u00b7sen", "und", "wu\u00df\u00b7test", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "APPR", "PAV", "VAPP", "KON", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+--+--+-+--+--+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Oder sie ist \u00fcberall, zu Wasser und zu Lande.", "tokens": ["O\u00b7der", "sie", "ist", "\u00fc\u00b7be\u00b7rall", ",", "zu", "Was\u00b7ser", "und", "zu", "Lan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "$,", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.160": {"line.1": {"text": "Schultere deine Sachen, lieber Sohn, wie ich die meinen, und la\u00df uns forteilen,", "tokens": ["Schul\u00b7te\u00b7re", "dei\u00b7ne", "Sa\u00b7chen", ",", "lie\u00b7ber", "Sohn", ",", "wie", "ich", "die", "mei\u00b7nen", ",", "und", "la\u00df", "uns", "for\u00b7tei\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "ADV", "NN", "$,", "PWAV", "PPER", "ART", "VVFIN", "$,", "KON", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+--+-+-+-+-+-+--+--+-", "measure": "iambic.octa.plus.invert"}, "line.2": {"text": "Wundervolle St\u00e4dte und freie V\u00f6lker erreichen wir unterwegs.", "tokens": ["Wun\u00b7der\u00b7vol\u00b7le", "St\u00e4d\u00b7te", "und", "frei\u00b7e", "V\u00f6l\u00b7ker", "er\u00b7rei\u00b7chen", "wir", "un\u00b7ter\u00b7wegs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+--+-+--+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Wenn du m\u00fcde wirst, so la\u00df mir beide Lasten und st\u00fctze deine Hand auf meine H\u00fcfte,", "tokens": ["Wenn", "du", "m\u00fc\u00b7de", "wirst", ",", "so", "la\u00df", "mir", "bei\u00b7de", "Las\u00b7ten", "und", "st\u00fct\u00b7ze", "dei\u00b7ne", "Hand", "auf", "mei\u00b7ne", "H\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "ADV", "VVIMP", "PPER", "PIAT", "NN", "KON", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": "Du sollst mir ein andermal den gleichen Dienst erweisen,", "tokens": ["Du", "sollst", "mir", "ein", "an\u00b7der\u00b7mal", "den", "glei\u00b7chen", "Dienst", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Denn nachdem wir einmal aufgebrochen, ruhn wir nimmer mehr aus.", "tokens": ["Denn", "nach\u00b7dem", "wir", "ein\u00b7mal", "auf\u00b7ge\u00b7bro\u00b7chen", ",", "ruhn", "wir", "nim\u00b7mer", "mehr", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "$,", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+--+", "measure": "iambic.octa.plus.octa.plus.chol"}}, "stanza.161": {"line.1": {"text": "Du stellst mir auch Fragen, und ich h\u00f6re dich,", "tokens": ["Du", "stellst", "mir", "auch", "Fra\u00b7gen", ",", "und", "ich", "h\u00f6\u00b7re", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich antworte, da\u00df ich nicht antworten kann, du mu\u00dft es selber herausfinden.", "tokens": ["Ich", "ant\u00b7wor\u00b7te", ",", "da\u00df", "ich", "nicht", "ant\u00b7wor\u00b7ten", "kann", ",", "du", "mu\u00dft", "es", "sel\u00b7ber", "her\u00b7aus\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+--+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.162": {"line.1": {"text": "Lange genug hast du ver\u00e4chtliche Tr\u00e4ume getr\u00e4umt,", "tokens": ["Lan\u00b7ge", "ge\u00b7nug", "hast", "du", "ver\u00b7\u00e4cht\u00b7li\u00b7che", "Tr\u00e4u\u00b7me", "ge\u00b7tr\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADJA", "NN", "VVPP", "$,"], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Jetzt reibe ich dir den Schlaf aus den Augen,", "tokens": ["Jetzt", "rei\u00b7be", "ich", "dir", "den", "Schlaf", "aus", "den", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Du mu\u00dft dich an das Blenden des Lichtes und jedes Augenblickes in deinem Leben gew\u00f6hnen.", "tokens": ["Du", "mu\u00dft", "dich", "an", "das", "Blen\u00b7den", "des", "Lich\u00b7tes", "und", "je\u00b7des", "Au\u00b7gen\u00b7bli\u00b7ckes", "in", "dei\u00b7nem", "Le\u00b7ben", "ge\u00b7w\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "KON", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-+-+--+-+--+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.163": {"line.1": {"text": "Ich bin der Lehrer der Athleten,", "tokens": ["Ich", "bin", "der", "Leh\u00b7rer", "der", "Ath\u00b7le\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wer mir eine noch breitere Brust als die meine zeigen kann, beweist die Breite der meinigen,", "tokens": ["Wer", "mir", "ei\u00b7ne", "noch", "brei\u00b7te\u00b7re", "Brust", "als", "die", "mei\u00b7ne", "zei\u00b7gen", "kann", ",", "be\u00b7weist", "die", "Brei\u00b7te", "der", "mei\u00b7ni\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "ADV", "ADJA", "NN", "KOKOM", "ART", "PPOSAT", "VVINF", "VMFIN", "$,", "VVFIN", "ART", "NN", "ART", "PPOSS", "$,"], "meter": "--+--+--+--+-+-+-+-+-+-+-", "measure": "anapaest.tetra.plus"}, "line.3": {"text": "Der ehrt am meisten meinen Stil, der durch ihn lernt, den Lehrer zu vernichten!", "tokens": ["Der", "ehrt", "am", "meis\u00b7ten", "mei\u00b7nen", "Stil", ",", "der", "durch", "ihn", "lernt", ",", "den", "Leh\u00b7rer", "zu", "ver\u00b7nich\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPRART", "PIS", "PPOSAT", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}}, "stanza.164": {"line.1": {"text": "Der Knabe, den ich liebe, wird ein Mann nicht durch ererbte Macht, sondern in seinem eigenen Recht,", "tokens": ["Der", "Kna\u00b7be", ",", "den", "ich", "lie\u00b7be", ",", "wird", "ein", "Mann", "nicht", "durch", "er\u00b7erb\u00b7te", "Macht", ",", "son\u00b7dern", "in", "sei\u00b7nem", "ei\u00b7ge\u00b7nen", "Recht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "ART", "NN", "PTKNEG", "APPR", "ADJA", "NN", "$,", "KON", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+-++--+-+--+", "measure": "iambic.octa.plus"}, "line.2": {"text": "Schlecht lieber als tugendhaft aus Anbequemung oder Furcht;", "tokens": ["Schlecht", "lie\u00b7ber", "als", "tu\u00b7gend\u00b7haft", "aus", "An\u00b7be\u00b7que\u00b7mung", "o\u00b7der", "Furcht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOKOM", "ADJD", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Er liebt sein Sch\u00e4tzchen, verzehrt seinen Braten mit Appetit,", "tokens": ["Er", "liebt", "sein", "Sch\u00e4tz\u00b7chen", ",", "ver\u00b7zehrt", "sei\u00b7nen", "Bra\u00b7ten", "mit", "Ap\u00b7pe\u00b7tit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Unerwiderte Liebe oder Geringsch\u00e4tzung durchschneidet ihn sch\u00e4rfer als scharfer Stahl,", "tokens": ["Un\u00b7er\u00b7wi\u00b7der\u00b7te", "Lie\u00b7be", "o\u00b7der", "Ge\u00b7ring\u00b7sch\u00e4t\u00b7zung", "durch\u00b7schnei\u00b7det", "ihn", "sch\u00e4r\u00b7fer", "als", "schar\u00b7fer", "Stahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "VVFIN", "PPER", "ADJD", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+--+-+---+--+--+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.5": {"text": "Narben und B\u00e4rter und Gesichter mit Blatternarben zieht er den Glattgesichtern vor,", "tokens": ["Nar\u00b7ben", "und", "B\u00e4r\u00b7ter", "und", "Ge\u00b7sich\u00b7ter", "mit", "Blat\u00b7ter\u00b7nar\u00b7ben", "zieht", "er", "den", "Glatt\u00b7ge\u00b7sich\u00b7tern", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+--+-+-+--+-+-+", "measure": "iambic.octa.plus.invert"}, "line.6": {"text": "Und die von der Sonne verbrannten denen, die im Schatten blieben.", "tokens": ["Und", "die", "von", "der", "Son\u00b7ne", "ver\u00b7brann\u00b7ten", "de\u00b7nen", ",", "die", "im", "Schat\u00b7ten", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "ART", "NN", "VVFIN", "PDS", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.165": {"line.1": {"text": "Ich lehre euch, von mir zu gehen \u2013 doch wer kann von mir gehen?", "tokens": ["Ich", "leh\u00b7re", "euch", ",", "von", "mir", "zu", "ge\u00b7hen", "\u2013", "doch", "wer", "kann", "von", "mir", "ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "APPR", "PPER", "PTKZU", "VVINF", "$(", "KON", "PWS", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Ich folge dir von dieser Stunde an, wer du auch seist,", "tokens": ["Ich", "fol\u00b7ge", "dir", "von", "die\u00b7ser", "Stun\u00b7de", "an", ",", "wer", "du", "auch", "seist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PDAT", "NN", "PTKVZ", "$,", "PWS", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Meine Worte kitzeln dir in den Ohren, bis du sie verstehst.", "tokens": ["Mei\u00b7ne", "Wor\u00b7te", "kit\u00b7zeln", "dir", "in", "den", "Oh\u00b7ren", ",", "bis", "du", "sie", "ver\u00b7stehst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.166": {"line.1": {"text": "Ich sage diese Dinge nicht f\u00fcr einen Dollar, oder zum Zeitvertreib w\u00e4hrend ich auf das Boot warte,", "tokens": ["Ich", "sa\u00b7ge", "die\u00b7se", "Din\u00b7ge", "nicht", "f\u00fcr", "ei\u00b7nen", "Dol\u00b7lar", ",", "o\u00b7der", "zum", "Zeit\u00b7ver\u00b7treib", "w\u00e4h\u00b7rend", "ich", "auf", "das", "Boot", "war\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "PTKNEG", "APPR", "ART", "NN", "$,", "KON", "APPRART", "NN", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+--+--+--+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "(du bist es, der spricht, ebensoviel wie ich, ich bin deine Zunge,", "tokens": ["(", "du", "bist", "es", ",", "der", "spricht", ",", "e\u00b7ben\u00b7so\u00b7viel", "wie", "ich", ",", "ich", "bin", "dei\u00b7ne", "Zun\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "$,", "PRELS", "VVFIN", "$,", "ADV", "KOKOM", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+++-+-+-+-", "measure": "unknown.measure.octa.plus"}, "line.3": {"text": "Gebunden in deinem Munde, in meinem beginnt sie sich zu l\u00f6sen).", "tokens": ["Ge\u00b7bun\u00b7den", "in", "dei\u00b7nem", "Mun\u00b7de", ",", "in", "mei\u00b7nem", "be\u00b7ginnt", "sie", "sich", "zu", "l\u00f6\u00b7sen", ")", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "$(", "$."], "meter": "-+--+-+--+--+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.167": {"line.1": {"text": "Willst du mich verstehen, so gehe auf die H\u00f6hen oder an den Meeresstrand,", "tokens": ["Willst", "du", "mich", "ver\u00b7ste\u00b7hen", ",", "so", "ge\u00b7he", "auf", "die", "H\u00f6\u00b7hen", "o\u00b7der", "an", "den", "Mee\u00b7res\u00b7strand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$,", "ADV", "VVFIN", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Die n\u00e4chste M\u00fccke ist eine Erkl\u00e4rung, ein Tropfen oder eine Wellenbewegung ist ein Schl\u00fcssel,", "tokens": ["Die", "n\u00e4chs\u00b7te", "M\u00fc\u00b7cke", "ist", "ei\u00b7ne", "Er\u00b7kl\u00e4\u00b7rung", ",", "ein", "Trop\u00b7fen", "o\u00b7der", "ei\u00b7ne", "Wel\u00b7len\u00b7be\u00b7we\u00b7gung", "ist", "ein", "Schl\u00fcs\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+--+--+--+-+-+-+--+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Der Schlaghammer, das Ruder, die Hands\u00e4ge bekr\u00e4ftigen meine Worte.", "tokens": ["Der", "Schlag\u00b7ham\u00b7mer", ",", "das", "Ru\u00b7der", ",", "die", "Hand\u00b7s\u00e4\u00b7ge", "be\u00b7kr\u00e4f\u00b7ti\u00b7gen", "mei\u00b7ne", "Wor\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+---+--+---+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.168": {"line.1": {"text": "Keine Stube mit geschlossenen Fensterl\u00e4den, keine Schule kann mit mir verkehren,", "tokens": ["Kei\u00b7ne", "Stu\u00b7be", "mit", "ge\u00b7schlos\u00b7se\u00b7nen", "Fens\u00b7ter\u00b7l\u00e4\u00b7den", ",", "kei\u00b7ne", "Schu\u00b7le", "kann", "mit", "mir", "ver\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN", "$,", "PIAT", "NN", "VMFIN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.2": {"text": "Rohes Gesindel und kleine Kinder eher noch, als die.", "tokens": ["Ro\u00b7hes", "Ge\u00b7sin\u00b7del", "und", "klei\u00b7ne", "Kin\u00b7der", "e\u00b7her", "noch", ",", "als", "die", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "ADV", "ADV", "$,", "KOUS", "ART", "$."], "meter": "+--+--+-+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.169": {"line.1": {"text": "Der junge Handwerker steht mir am n\u00e4chsten, er kennt mich wohl,", "tokens": ["Der", "jun\u00b7ge", "Hand\u00b7wer\u00b7ker", "steht", "mir", "am", "n\u00e4chs\u00b7ten", ",", "er", "kennt", "mich", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "ADJA", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Bauernbursch, der im Felde pfl\u00fcgt, f\u00fchlt sich wohl beim Klang meiner Stimme,", "tokens": ["Der", "Bau\u00b7ern\u00b7bursch", ",", "der", "im", "Fel\u00b7de", "pfl\u00fcgt", ",", "f\u00fchlt", "sich", "wohl", "beim", "Klang", "mei\u00b7ner", "Stim\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "PRF", "ADV", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Auf segelnden Schiffen segeln meine Worte, ich gehe mit Fischern und Matrosen und liebe sie.", "tokens": ["Auf", "se\u00b7geln\u00b7den", "Schif\u00b7fen", "se\u00b7geln", "mei\u00b7ne", "Wor\u00b7te", ",", "ich", "ge\u00b7he", "mit", "Fi\u00b7schern", "und", "Mat\u00b7ro\u00b7sen", "und", "lie\u00b7be", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "KON", "VVFIN", "PPER", "$."], "meter": "+---+-+-+-+--+--+--+---+-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.170": {"line.1": {"text": "Mein ist der Soldat im Lager oder auf dem Marsche,", "tokens": ["Mein", "ist", "der", "Sol\u00b7dat", "im", "La\u00b7ger", "o\u00b7der", "auf", "dem", "Mar\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "ART", "NN", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "In der Nacht vor der Schlacht suchen mich manche auf, und ich entt\u00e4usche sie nicht,", "tokens": ["In", "der", "Nacht", "vor", "der", "Schlacht", "su\u00b7chen", "mich", "man\u00b7che", "auf", ",", "und", "ich", "ent\u00b7t\u00e4u\u00b7sche", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "PIS", "PTKVZ", "$,", "KON", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "--+--++--+-+-+-+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "In jener feierlichen Nacht (vielleicht ihrer letzten) suchen mich die, die mich kennen.", "tokens": ["In", "je\u00b7ner", "fei\u00b7er\u00b7li\u00b7chen", "Nacht", "(", "viel\u00b7leicht", "ih\u00b7rer", "letz\u00b7ten", ")", "su\u00b7chen", "mich", "die", ",", "die", "mich", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$(", "ADV", "PPOSAT", "ADJA", "$(", "VVFIN", "PPER", "ART", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.171": {"line.1": {"text": "Mein Gesicht reibt sich an des J\u00e4gers Gesicht, wenn er allein sich niederlegt in seiner Decke,", "tokens": ["Mein", "Ge\u00b7sicht", "reibt", "sich", "an", "des", "J\u00e4\u00b7gers", "Ge\u00b7sicht", ",", "wenn", "er", "al\u00b7lein", "sich", "nie\u00b7der\u00b7legt", "in", "sei\u00b7ner", "De\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$,", "KOUS", "PPER", "ADV", "PRF", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Der Fuhrmann, der an mich denkt, achtet nicht auf das R\u00fctteln des Wagens,", "tokens": ["Der", "Fuhr\u00b7mann", ",", "der", "an", "mich", "denkt", ",", "ach\u00b7tet", "nicht", "auf", "das", "R\u00fct\u00b7teln", "des", "Wa\u00b7gens", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+-+--+-", "measure": "amphibrach.tetra.plus"}, "line.3": {"text": "Die junge Mutter und die alte Mutter begreifen mich,", "tokens": ["Die", "jun\u00b7ge", "Mut\u00b7ter", "und", "die", "al\u00b7te", "Mut\u00b7ter", "be\u00b7grei\u00b7fen", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Das M\u00e4dchen und die Hausfrau lassen die Nadel einen Augenblick ruhn und vergessen, wo sie sind,", "tokens": ["Das", "M\u00e4d\u00b7chen", "und", "die", "Haus\u00b7frau", "las\u00b7sen", "die", "Na\u00b7del", "ei\u00b7nen", "Au\u00b7gen\u00b7blick", "ruhn", "und", "ver\u00b7ges\u00b7sen", ",", "wo", "sie", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "VVINF", "KON", "VVPP", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+--+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.5": {"text": "Sie und alle m\u00f6chten wieder durchdenken, was ich ihnen gesagt habe.", "tokens": ["Sie", "und", "al\u00b7le", "m\u00f6ch\u00b7ten", "wie\u00b7der", "durch\u00b7den\u00b7ken", ",", "was", "ich", "ih\u00b7nen", "ge\u00b7sagt", "ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PIS", "VMFIN", "ADV", "VVINF", "$,", "PWS", "PPER", "PPER", "VVPP", "VAFIN", "$."], "meter": "--+-+-+--+-+-+--+--", "measure": "iambic.septa.relaxed"}}, "stanza.172": {"line.1": {"text": "Ich sage zum Menschengeschlecht: Seid nicht neugierig nach Gott;", "tokens": ["Ich", "sa\u00b7ge", "zum", "Men\u00b7schen\u00b7ge\u00b7schlecht", ":", "Seid", "nicht", "neu\u00b7gie\u00b7rig", "nach", "Gott", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$.", "VAIMP", "PTKNEG", "ADJD", "APPR", "NN", "$."], "meter": "-+--+---+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn ich, neugierig nach allem und jedem, bin doch nicht neugierig nach Gott,", "tokens": ["Denn", "ich", ",", "neu\u00b7gie\u00b7rig", "nach", "al\u00b7lem", "und", "je\u00b7dem", ",", "bin", "doch", "nicht", "neu\u00b7gie\u00b7rig", "nach", "Gott", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADJD", "APPR", "PIS", "KON", "PIS", "$,", "VAFIN", "ADV", "PTKNEG", "ADJD", "APPR", "NN", "$,"], "meter": "---+--+--+-+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "(kein Wort\u00fcberschwang vermag zu sagen, wie ich voll Frieden zu Gott und zum Tode stehe).", "tokens": ["(", "kein", "Wort\u00b7\u00fc\u00b7bersc\u00b7hwang", "ver\u00b7mag", "zu", "sa\u00b7gen", ",", "wie", "ich", "voll", "Frie\u00b7den", "zu", "Gott", "und", "zum", "To\u00b7de", "ste\u00b7he", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIAT", "NN", "VVFIN", "PTKZU", "VVINF", "$,", "PWAV", "PPER", "ADJD", "NN", "APPR", "NN", "KON", "APPRART", "NN", "VVFIN", "$(", "$."], "meter": "--+-+-+-+-+--+--+--+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.173": {"line.1": {"text": "Ich h\u00f6re und sehe Gott in jedem Gegenstand, doch Gott begreif' ich nicht im mindesten,", "tokens": ["Ich", "h\u00f6\u00b7re", "und", "se\u00b7he", "Gott", "in", "je\u00b7dem", "Ge\u00b7gen\u00b7stand", ",", "doch", "Gott", "be\u00b7greif'", "ich", "nicht", "im", "min\u00b7des\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "NN", "APPR", "PIAT", "NN", "$,", "KON", "NN", "VVFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "$,"], "meter": "-+--+-+-+-+-+-+-+-+-+--", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Noch begreife ich, wer noch merkw\u00fcrdiger sein kann als ich selber.", "tokens": ["Noch", "be\u00b7grei\u00b7fe", "ich", ",", "wer", "noch", "merk\u00b7w\u00fcr\u00b7di\u00b7ger", "sein", "kann", "als", "ich", "sel\u00b7ber", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWS", "ADV", "ADJD", "VAINF", "VMFIN", "KOUS", "PPER", "ADV", "$."], "meter": "+-+--+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.174": {"line.1": {"text": "Zu seiner Arbeit eilt entschlossen der Geburtshelfer,", "tokens": ["Zu", "sei\u00b7ner", "Ar\u00b7beit", "eilt", "ent\u00b7schlos\u00b7sen", "der", "Ge\u00b7burts\u00b7hel\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "Ich sehe die helfende Hand, wie sie dr\u00fcckt, empf\u00e4ngt und unterst\u00fctzt,", "tokens": ["Ich", "se\u00b7he", "die", "hel\u00b7fen\u00b7de", "Hand", ",", "wie", "sie", "dr\u00fcckt", ",", "emp\u00b7f\u00e4ngt", "und", "un\u00b7ter\u00b7st\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "-+--+--+--+-+-+-+", "measure": "amphibrach.tetra.plus"}, "line.3": {"text": "Ich b\u00fccke mich an den Schwellen der feinen, biegsamen T\u00fcren", "tokens": ["Ich", "b\u00fc\u00b7cke", "mich", "an", "den", "Schwel\u00b7len", "der", "fei\u00b7nen", ",", "bieg\u00b7sa\u00b7men", "T\u00fc\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und merke den Ausgang, die Erleichterung und das Entweichen.", "tokens": ["Und", "mer\u00b7ke", "den", "Aus\u00b7gang", ",", "die", "Er\u00b7leich\u00b7te\u00b7rung", "und", "das", "Ent\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}}, "stanza.175": {"line.1": {"text": "Und Leben, was dich betrifft, denk' ich, du bist das \u00fcbrig Gebliebene von vielem Sterben,", "tokens": ["Und", "Le\u00b7ben", ",", "was", "dich", "be\u00b7tr\u00b7ifft", ",", "denk'", "ich", ",", "du", "bist", "das", "\u00fcb\u00b7rig", "Ge\u00b7blie\u00b7be\u00b7ne", "von", "vie\u00b7lem", "Ster\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "PIS", "NN", "$,"], "meter": "-+--+-+-+--+-+--+---+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "(ohne Zweifel bin ich schon fr\u00fcher zehntausendmal gestorben).", "tokens": ["(", "oh\u00b7ne", "Zwei\u00b7fel", "bin", "ich", "schon", "fr\u00fc\u00b7her", "zehn\u00b7tau\u00b7send\u00b7mal", "ge\u00b7stor\u00b7ben", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "NN", "VAFIN", "PPER", "ADV", "ADJD", "ADV", "VVPP", "$(", "$."], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}}, "stanza.176": {"line.1": {"text": "Da ist dies Etwas in mir \u2013 ich wei\u00df nicht, was es ist, aber ich wei\u00df, es ist in mir.", "tokens": ["Da", "ist", "dies", "Et\u00b7was", "in", "mir", "\u2013", "ich", "wei\u00df", "nicht", ",", "was", "es", "ist", ",", "a\u00b7ber", "ich", "wei\u00df", ",", "es", "ist", "in", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PDS", "ADV", "APPR", "PPER", "$(", "PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VAFIN", "$,", "KON", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+--+-+-+-+---+-+-+", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Verzerrt und schwei\u00dfig \u2013 dann wird mein K\u00f6rper ruhig und k\u00fchl,", "tokens": ["Ver\u00b7zerrt", "und", "schwei\u00b7\u00dfig", "\u2013", "dann", "wird", "mein", "K\u00f6r\u00b7per", "ru\u00b7hig", "und", "k\u00fchl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "$(", "ADV", "VAFIN", "PPOSAT", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich schlafe ... schlafe lange.", "tokens": ["Ich", "schla\u00b7fe", "...", "schla\u00b7fe", "lan\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.177": {"line.1": {"text": "Ich kenne es nicht, es ist ohne Namen, ist ein unausgesprochenes Wort,", "tokens": ["Ich", "ken\u00b7ne", "es", "nicht", ",", "es", "ist", "oh\u00b7ne", "Na\u00b7men", ",", "ist", "ein", "un\u00b7aus\u00b7ge\u00b7spro\u00b7che\u00b7nes", "Wort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "VAFIN", "APPR", "NN", "$,", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-+--+--+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Es ist in keinem W\u00f6rterbuch, keiner Lautgebung, keinem Symbol.", "tokens": ["Es", "ist", "in", "kei\u00b7nem", "W\u00f6r\u00b7ter\u00b7buch", ",", "kei\u00b7ner", "Laut\u00b7ge\u00b7bung", ",", "kei\u00b7nem", "Sym\u00b7bol", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "Es dreht sich auf etwas, das mehr ist als die Erde, mit der ich mich drehe,", "tokens": ["Es", "dreht", "sich", "auf", "et\u00b7was", ",", "das", "mehr", "ist", "als", "die", "Er\u00b7de", ",", "mit", "der", "ich", "mich", "dre\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIS", "$,", "PRELS", "ADV", "VAFIN", "KOKOM", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.4": {"text": "Ihm ist die Sch\u00f6pfung der Freund, dessen Umarmung mich weckt.", "tokens": ["Ihm", "ist", "die", "Sch\u00f6p\u00b7fung", "der", "Freund", ",", "des\u00b7sen", "Um\u00b7ar\u00b7mung", "mich", "weckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PRELAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+--++--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.178": {"line.1": {"text": "Ich widerspreche mir selbst?", "tokens": ["Ich", "wi\u00b7der\u00b7spre\u00b7che", "mir", "selbst", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Nun gut, ich widerspreche mir selbst.", "tokens": ["Nun", "gut", ",", "ich", "wi\u00b7der\u00b7spre\u00b7che", "mir", "selbst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "(ich bin ja weitr\u00e4umig, ich enthalte Vielheiten).", "tokens": ["(", "ich", "bin", "ja", "weit\u00b7r\u00e4u\u00b7mig", ",", "ich", "ent\u00b7hal\u00b7te", "Viel\u00b7hei\u00b7ten", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VVFIN", "NN", "$(", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.179": {"line.1": {"text": "Das letzte Leuchten des Tages weilt noch um meinetwillen,", "tokens": ["Das", "letz\u00b7te", "Leuch\u00b7ten", "des", "Ta\u00b7ges", "weilt", "noch", "um", "mei\u00b7net\u00b7wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "ADV", "APPR", "ADV", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es wirft mein Ebenbild zu den andern, und treu wie nur eines, auf die schattenumwobene Wildnis,", "tokens": ["Es", "wirft", "mein", "E\u00b7ben\u00b7bild", "zu", "den", "an\u00b7dern", ",", "und", "treu", "wie", "nur", "ei\u00b7nes", ",", "auf", "die", "schat\u00b7ten\u00b7um\u00b7wo\u00b7be\u00b7ne", "Wild\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "$,", "KON", "ADJD", "KOKOM", "ADV", "PIS", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+--+-+-+--+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": "Es lockt mich zum Nebel und D\u00e4mmerschein.", "tokens": ["Es", "lockt", "mich", "zum", "Ne\u00b7bel", "und", "D\u00e4m\u00b7mer\u00b7schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.180": {"line.1": {"text": "Ich scheide wie Luft, ich sch\u00fcttle meine wei\u00dfen Locken gegen die enteilende Sonne,", "tokens": ["Ich", "schei\u00b7de", "wie", "Luft", ",", "ich", "sch\u00fctt\u00b7le", "mei\u00b7ne", "wei\u00b7\u00dfen", "Lo\u00b7cken", "ge\u00b7gen", "die", "ent\u00b7ei\u00b7len\u00b7de", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "$,", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-+-+--+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Ich lasse mein Fleisch in Wirbeln entstr\u00f6men und in F\u00e4den fortflie\u00dfen.", "tokens": ["Ich", "las\u00b7se", "mein", "Fleisch", "in", "Wir\u00b7beln", "ent\u00b7str\u00f6\u00b7men", "und", "in", "F\u00e4\u00b7den", "fort\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "VVPP", "KON", "APPR", "NN", "VVINF", "$."], "meter": "-+--+-+--+-+-+--+-", "measure": "iambic.septa.relaxed"}}, "stanza.181": {"line.1": {"text": "Ich vermache mich dem Schmutz, um aus dem Grase, das ich liebe, zu keimen,", "tokens": ["Ich", "ver\u00b7ma\u00b7che", "mich", "dem", "Schmutz", ",", "um", "aus", "dem", "Gra\u00b7se", ",", "das", "ich", "lie\u00b7be", ",", "zu", "kei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,", "KOUI", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+--+-", "measure": "trochaic.octa.plus"}, "line.2": {"text": "Brauchst du mich wieder, so suche mich unter deinen Stiefelsohlen!", "tokens": ["Brauchst", "du", "mich", "wie\u00b7der", ",", "so", "su\u00b7che", "mich", "un\u00b7ter", "dei\u00b7nen", "Stie\u00b7fel\u00b7soh\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "$,", "ADV", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+--+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.182": {"line.1": {"text": "Kaum wirst du wissen, wer ich bin, oder was ich meine,", "tokens": ["Kaum", "wirst", "du", "wis\u00b7sen", ",", "wer", "ich", "bin", ",", "o\u00b7der", "was", "ich", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "VAFIN", "$,", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch bin ich f\u00fcr dich trotz alledem die Gesundheit,", "tokens": ["Doch", "bin", "ich", "f\u00fcr", "dich", "trotz", "al\u00b7le\u00b7dem", "die", "Ge\u00b7sund\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "PPER", "APPR", "PIS", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und kl\u00e4re und kr\u00e4ftige dein Blut.", "tokens": ["Und", "kl\u00e4\u00b7re", "und", "kr\u00e4f\u00b7ti\u00b7ge", "dein", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.183": {"line.1": {"text": "Kannst du nicht gleich mich erfassen, behalte nur Mut,", "tokens": ["Kannst", "du", "nicht", "gleich", "mich", "er\u00b7fas\u00b7sen", ",", "be\u00b7hal\u00b7te", "nur", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADV", "PPER", "VVINF", "$,", "VVFIN", "ADV", "NN", "$,"], "meter": "+-++--+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Triffst du mich nicht an einer Stelle, so suche wo anders,", "tokens": ["Triffst", "du", "mich", "nicht", "an", "ei\u00b7ner", "Stel\u00b7le", ",", "so", "su\u00b7che", "wo", "an\u00b7ders", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKNEG", "APPR", "ART", "NN", "$,", "ADV", "ADJA", "PWAV", "ADV", "$,"], "meter": "+---+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Irgendwo bleib' ich und warte auf dich.", "tokens": ["Ir\u00b7gend\u00b7wo", "bleib'", "ich", "und", "war\u00b7te", "auf", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "APPR", "PPER", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}}}}