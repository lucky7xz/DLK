{"textgrid.poem.43947": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: O geh nur, harter Sinn, begieb dich au\u00dfer Landes,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O geh nur, harter Sinn, begieb dich au\u00dfer Landes,", "tokens": ["O", "geh", "nur", ",", "har\u00b7ter", "Sinn", ",", "be\u00b7gieb", "dich", "au\u00b7\u00dfer", "Lan\u00b7des", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$,", "ADJA", "NN", "$,", "VVFIN", "PRF", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Fleuch an das Eu\u00dferste des kalten Cymberstrandes,", "tokens": ["Fleuch", "an", "das", "Eu\u00b7\u00dfers\u00b7te", "des", "kal\u00b7ten", "Cym\u00b7ber\u00b7stran\u00b7des", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Fleuch hin, wo Sonn und Tag des Jahres einmahl wacht,", "tokens": ["Fleuch", "hin", ",", "wo", "Sonn", "und", "Tag", "des", "Jah\u00b7res", "ein\u00b7mahl", "wacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PWAV", "NN", "KON", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du solt mich folgen sehn, und wenn mich Frost und Klagen", "tokens": ["Du", "solt", "mich", "fol\u00b7gen", "sehn", ",", "und", "wenn", "mich", "Frost", "und", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "VVINF", "VVINF", "$,", "KON", "KOUS", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor deiner Th\u00fcr erstickt, mit schwerem Herzen sagen:", "tokens": ["Vor", "dei\u00b7ner", "Th\u00fcr", "er\u00b7stickt", ",", "mit", "schwe\u00b7rem", "Her\u00b7zen", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das h\u00e4tt ich nicht gedacht.", "tokens": ["Das", "h\u00e4tt", "ich", "nicht", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Allein, verstocktes Herz, das l\u00e4st sich leicht gedencken,", "tokens": ["Al\u00b7lein", ",", "ver\u00b7stock\u00b7tes", "Herz", ",", "das", "l\u00e4st", "sich", "leicht", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADJA", "NN", "$,", "PDS", "VVFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du h\u00f6rest Tag und Nacht mein ungew\u00f6hnlich Kr\u00e4ncken,", "tokens": ["Du", "h\u00f6\u00b7rest", "Tag", "und", "Nacht", "mein", "un\u00b7ge\u00b7w\u00f6hn\u00b7lich", "Kr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du siehst mich schwach und blos vor Haus und Fenster stehn,", "tokens": ["Du", "siehst", "mich", "schwach", "und", "blos", "vor", "Haus", "und", "Fens\u00b7ter", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "KON", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Nordwind pfeift ums Dach und heulet in den Linden,", "tokens": ["Der", "Nord\u00b7wind", "pfeift", "ums", "Dach", "und", "heu\u00b7let", "in", "den", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "APPR", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich lieg auf Ei\u00df und Schnee, die mehr als du empfinden", "tokens": ["Ich", "lieg", "auf", "Ei\u00df", "und", "Schnee", ",", "die", "mehr", "als", "du", "emp\u00b7fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,", "PRELS", "ADV", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und selbst vor Leid zergehn.", "tokens": ["Und", "selbst", "vor", "Leid", "zer\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ach, grausam sch\u00f6nes Kind, ach las den Hochmuth fahren,", "tokens": ["Ach", ",", "grau\u00b7sam", "sch\u00f6\u00b7nes", "Kind", ",", "ach", "las", "den", "Hoch\u00b7muth", "fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJD", "ADJA", "NN", "$,", "ITJ", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Lieb ist Stolzen gram und st\u00fcrzt sie mit den Jahren,", "tokens": ["Die", "Lieb", "ist", "Stol\u00b7zen", "gram", "und", "st\u00fcrzt", "sie", "mit", "den", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "NE", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es ist noch kurze Zeit, so wendet sich das Blat;", "tokens": ["Es", "ist", "noch", "kur\u00b7ze", "Zeit", ",", "so", "wen\u00b7det", "sich", "das", "Blat", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "$,", "ADV", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du folgst Penelopen, ja, folg ihr auch am Stande,", "tokens": ["Du", "folgst", "Pe\u00b7ne\u00b7lo\u00b7pen", ",", "ja", ",", "folg", "ihr", "auch", "am", "Stan\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PTKANT", "$,", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die wegen seiner H\u00f6h und ihres Ehherrn Schande", "tokens": ["Die", "we\u00b7gen", "sei\u00b7ner", "H\u00f6h", "und", "ih\u00b7res", "Eh\u00b7herrn", "Schan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu halten Ursach hat.", "tokens": ["Zu", "hal\u00b7ten", "Ur\u00b7sach", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Denn ob gleich, gutes Kind, die Klug- und Sch\u00f6nheitsgaben", "tokens": ["Denn", "ob", "gleich", ",", "gu\u00b7tes", "Kind", ",", "die", "Klug", "und", "Sch\u00f6n\u00b7heits\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "$,", "ADJA", "NN", "$,", "ART", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Mutter aller Welt dein Herz bereichert haben,", "tokens": ["Der", "Mut\u00b7ter", "al\u00b7ler", "Welt", "dein", "Herz", "be\u00b7rei\u00b7chert", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "PPOSAT", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Obgleich kein hei\u00dfes Flehn dies Herz in Fe\u00dfel bringt,", "tokens": ["Ob\u00b7gleich", "kein", "hei\u00b7\u00dfes", "Flehn", "dies", "Herz", "in", "Fe\u00b7\u00dfel", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "PDS", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Obgleich dein Angesicht im ersten Lenze gr\u00fcnet", "tokens": ["Ob\u00b7gleich", "dein", "An\u00b7ge\u00b7sicht", "im", "ers\u00b7ten", "Len\u00b7ze", "gr\u00fc\u00b7net"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Kunst und Wi\u00dfenschaft, so treu sie dich bedienet,", "tokens": ["Und", "Kunst", "und", "Wi\u00b7\u00dfen\u00b7schaft", ",", "so", "treu", "sie", "dich", "be\u00b7die\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "ADV", "ADJD", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nur tauben Ohren singt:", "tokens": ["Nur", "tau\u00b7ben", "Oh\u00b7ren", "singt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "So spotte darum nicht, du solt es n\u00e4her geben,", "tokens": ["So", "spot\u00b7te", "da\u00b7rum", "nicht", ",", "du", "solt", "es", "n\u00e4\u00b7her", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PAV", "PTKNEG", "$,", "PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es bleibt nicht immer so, ich will es wohl erleben,", "tokens": ["Es", "bleibt", "nicht", "im\u00b7mer", "so", ",", "ich", "will", "es", "wohl", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "ADV", "$,", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df Iris, die jezt lacht, sich selber strafen soll;", "tokens": ["Da\u00df", "I\u00b7ris", ",", "die", "jezt", "lacht", ",", "sich", "sel\u00b7ber", "stra\u00b7fen", "soll", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PRELS", "ADV", "VVFIN", "$,", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie manche ward vor dir von Freyern hochgepriesen!", "tokens": ["Wie", "man\u00b7che", "ward", "vor", "dir", "von", "Frey\u00b7ern", "hoch\u00b7ge\u00b7prie\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "APPR", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jezt macht ihr Schimpf den Korb, mit dem sie viel verwiesen,", "tokens": ["Jezt", "macht", "ihr", "Schimpf", "den", "Korb", ",", "mit", "dem", "sie", "viel", "ver\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "An Flederwischen voll.", "tokens": ["An", "Fle\u00b7der\u00b7wi\u00b7schen", "voll", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}