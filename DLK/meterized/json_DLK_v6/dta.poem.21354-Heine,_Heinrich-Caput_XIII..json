{"dta.poem.21354": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Caput XIII.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-30602-6", "language": ["de:0.85", "sv:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Censor h\u00e4tte gestrichen darin", "tokens": ["Der", "Cen\u00b7sor", "h\u00e4t\u00b7te", "ge\u00b7stri\u00b7chen", "da\u00b7rin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "PAV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Was etwa anz\u00fcglich auf Erden,", "tokens": ["Was", "et\u00b7wa", "an\u00b7z\u00fcg\u00b7lich", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Und liebend bewahrte dich die Censur", "tokens": ["Und", "lie\u00b7bend", "be\u00b7wahr\u00b7te", "dich", "die", "Cen\u00b7sur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PRF", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Vor dem Gekreuzigtwerden.", "tokens": ["Vor", "dem", "Ge\u00b7kreu\u00b7zigt\u00b7wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ach! h\u00e4ttest du nur einen andern Text", "tokens": ["Ach", "!", "h\u00e4t\u00b7test", "du", "nur", "ei\u00b7nen", "an\u00b7dern", "Text"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zu deiner Bergpredigt genommen,", "tokens": ["Zu", "dei\u00b7ner", "Berg\u00b7pre\u00b7digt", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Besa\u00dfest ja Geist und Talent genug,", "tokens": ["Be\u00b7sa\u00b7\u00dfest", "ja", "Geist", "und", "Ta\u00b7lent", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und konntest schonen die Frommen!", "tokens": ["Und", "konn\u00b7test", "scho\u00b7nen", "die", "From\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Geldwechsler, Banqui\u00e8rs, hast du sogar", "tokens": ["Geld\u00b7wechs\u00b7ler", ",", "Ban\u00b7qui\u00e8rs", ",", "hast", "du", "so\u00b7gar"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit der Peitsche gejagt aus dem Tempel \u2013", "tokens": ["Mit", "der", "Peit\u00b7sche", "ge\u00b7jagt", "aus", "dem", "Tem\u00b7pel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "APPR", "ART", "NN", "$("], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Ungl\u00fccklicher Schw\u00e4rmer, jetzt h\u00e4ngst du am Kreuz", "tokens": ["Un\u00b7gl\u00fcck\u00b7li\u00b7cher", "Schw\u00e4r\u00b7mer", ",", "jetzt", "h\u00e4ngst", "du", "am", "Kreuz"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Als warnendes Exempel!", "tokens": ["Als", "war\u00b7nen\u00b7des", "Ex\u00b7em\u00b7pel", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}