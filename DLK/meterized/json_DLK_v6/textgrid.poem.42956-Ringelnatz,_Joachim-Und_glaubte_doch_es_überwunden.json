{"textgrid.poem.42956": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Und glaubte doch es \u00fcberwunden", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Warum hast du mich ins Gesicht", "tokens": ["Wa\u00b7rum", "hast", "du", "mich", "ins", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "APPRART", "NN"], "meter": "--+-++-+", "measure": "anapaest.init"}, "line.2": {"text": "Geschlagen?", "tokens": ["Ge\u00b7schla\u00b7gen", "?"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und ich konnte nicht", "tokens": ["Und", "ich", "konn\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PTKNEG"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Mich wehren, noch etwas sagen.", "tokens": ["Mich", "weh\u00b7ren", ",", "noch", "et\u00b7was", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "ADV", "PIS", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Warum hat ein Augenblick so roh", "tokens": ["Wa\u00b7rum", "hat", "ein", "Au\u00b7gen\u00b7blick", "so", "roh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Unsre ganze Heimlichkeit zertr\u00fcmmert?", "tokens": ["Uns\u00b7re", "gan\u00b7ze", "Heim\u00b7lich\u00b7keit", "zer\u00b7tr\u00fcm\u00b7mert", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Konntest du denn danach irgendwo", "tokens": ["Konn\u00b7test", "du", "denn", "da\u00b7nach", "ir\u00b7gend\u00b7wo"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "PAV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Gl\u00fccklich sein und unbek\u00fcmmert?", "tokens": ["Gl\u00fcck\u00b7lich", "sein", "und", "un\u00b7be\u00b7k\u00fcm\u00b7mert", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "KON", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Fandest du nie sp\u00e4ter jenen Mut,", "tokens": ["Fan\u00b7dest", "du", "nie", "sp\u00e4\u00b7ter", "je\u00b7nen", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Frei mir neu zu nahn?", "tokens": ["Frei", "mir", "neu", "zu", "nahn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Was uns jemals weh getan,", "tokens": ["Was", "uns", "je\u00b7mals", "weh", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach wie bald war's wieder gut.", "tokens": ["Ach", "wie", "bald", "wa\u00b7r's", "wie\u00b7der", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aber was wir andern Wehes taten, \u2013", "tokens": ["A\u00b7ber", "was", "wir", "an\u00b7dern", "We\u00b7hes", "ta\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWS", "PPER", "ADJA", "NN", "VVFIN", "$,", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "\u2013 \u2013 \u2013 \u2013? \u2013!", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "?", "\u2013", "!"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$.", "$(", "$."]}}, "stanza.5": {"line.1": {"text": "Es ist leicht und ehrlich, wenn ich sag:", "tokens": ["Es", "ist", "leicht", "und", "ehr\u00b7lich", ",", "wenn", "ich", "sag", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Lebe wohl! Gut Nacht! und Guten Tag! \u2013", "tokens": ["Le\u00b7be", "wohl", "!", "Gut", "Nacht", "!", "und", "Gu\u00b7ten", "Tag", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "ADV", "$.", "ADJD", "NN", "$.", "KON", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Auch im Kriege sprachen so Soldaten.", "tokens": ["Auch", "im", "Krie\u00b7ge", "spra\u00b7chen", "so", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "ADV", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}