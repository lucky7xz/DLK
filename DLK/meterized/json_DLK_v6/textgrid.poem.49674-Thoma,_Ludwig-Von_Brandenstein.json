{"textgrid.poem.49674": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Von Brandenstein", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Pr\u00e4sident von Brandenstein, nat\u00fcrlich Preu\u00dfe,", "tokens": ["Pr\u00e4\u00b7si\u00b7dent", "von", "Bran\u00b7den\u00b7stein", ",", "na\u00b7t\u00fcr\u00b7lich", "Preu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "\u2013 Was nach folgendem ganz selbstverst\u00e4ndlich \u2013", "tokens": ["\u2013", "Was", "nach", "fol\u00b7gen\u00b7dem", "ganz", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "APPR", "ADJA", "ADV", "ADJD", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Fuhr auf Kosten seines Staates erster Klasse,", "tokens": ["Fuhr", "auf", "Kos\u00b7ten", "sei\u00b7nes", "Staa\u00b7tes", "ers\u00b7ter", "Klas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Und da \u00e4rgerte ihn etwas sch\u00e4ndlich.", "tokens": ["Und", "da", "\u00e4r\u00b7ger\u00b7te", "ihn", "et\u00b7was", "sch\u00e4nd\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "N\u00e4mlich vis-\u00e0-vis von ihm, da sa\u00df ein K\u00e4rel", "tokens": ["N\u00e4m\u00b7lich", "vis\u00b7\u00e0\u00b7vis", "von", "ihm", ",", "da", "sa\u00df", "ein", "K\u00e4\u00b7rel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NE", "APPR", "PPER", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Gleichfalls gratis. B\u00fcrgerlich in Kleidung,", "tokens": ["Gleich\u00b7falls", "gra\u00b7tis", ".", "B\u00fcr\u00b7ger\u00b7lich", "in", "Klei\u00b7dung", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "R\u00f6llchen, J\u00e4gerhemd und keine B\u00fcgelfalten,", "tokens": ["R\u00f6ll\u00b7chen", ",", "J\u00e4\u00b7ger\u00b7hemd", "und", "kei\u00b7ne", "B\u00fc\u00b7gel\u00b7fal\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Und was sonst noch dient zur Unterscheidung.", "tokens": ["Und", "was", "sonst", "noch", "dient", "zur", "Un\u00b7ter\u00b7schei\u00b7dung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADV", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Dieser K\u00e4rel rauchte! Rauchte 'ne Zigarre,", "tokens": ["Die\u00b7ser", "K\u00e4\u00b7rel", "rauch\u00b7te", "!", "Rauch\u00b7te", "'ne", "Zi\u00b7gar\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "$.", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Wie sie Brandenstein noch nie gerochen!", "tokens": ["Wie", "sie", "Bran\u00b7den\u00b7stein", "noch", "nie", "ge\u00b7ro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Glauben Sie, da\u00df er um die Erlaubnis fragte?", "tokens": ["Glau\u00b7ben", "Sie", ",", "da\u00df", "er", "um", "die", "Er\u00b7laub\u00b7nis", "frag\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Nee! Der K\u00e4rel hat keen' Ton gesprochen.", "tokens": ["Nee", "!", "Der", "K\u00e4\u00b7rel", "hat", "keen'", "Ton", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Hielt das Kraut vergn\u00fcgt von sich mit dicken Fingern,", "tokens": ["Hielt", "das", "Kraut", "ver\u00b7gn\u00fcgt", "von", "sich", "mit", "di\u00b7cken", "Fin\u00b7gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVPP", "APPR", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Und man sah die ungeputzten N\u00e4gel.", "tokens": ["Und", "man", "sah", "die", "un\u00b7ge\u00b7putz\u00b7ten", "N\u00e4\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Denken Sie sich Brandenstein in dieser Lage!", "tokens": ["Den\u00b7ken", "Sie", "sich", "Bran\u00b7den\u00b7stein", "in", "die\u00b7ser", "La\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Vis-\u00e0-vis von einem solchen Flegel!", "tokens": ["Vis\u00b7\u00e0\u00b7vis", "von", "ei\u00b7nem", "sol\u00b7chen", "Fle\u00b7gel", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Na, er wu\u00dfte gleich Bescheid. Wenn erster Klasse", "tokens": ["Na", ",", "er", "wu\u00df\u00b7te", "gleich", "Be\u00b7scheid", ".", "Wenn", "ers\u00b7ter", "Klas\u00b7se"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "ADV", "NN", "$.", "KOUS", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "So was f\u00e4hrt, dann ist's ein Reichstagsbote,", "tokens": ["So", "was", "f\u00e4hrt", ",", "dann", "ist's", "ein", "Reichs\u00b7tags\u00b7bo\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "$,", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Selbstverst\u00e4ndlich einer von der linken Seite,", "tokens": ["Selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "ei\u00b7ner", "von", "der", "lin\u00b7ken", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Volksverf\u00fchrer, Quasselfritze, Knote.", "tokens": ["Volks\u00b7ver\u00b7f\u00fch\u00b7rer", ",", "Quas\u00b7sel\u00b7frit\u00b7ze", ",", "Kno\u00b7te", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Brandenstein beschwerte sich denn auch sehr bitter,", "tokens": ["Bran\u00b7den\u00b7stein", "be\u00b7schwer\u00b7te", "sich", "denn", "auch", "sehr", "bit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Und Entr\u00fcstung kam aus seiner Schleuse.", "tokens": ["Und", "Ent\u00b7r\u00fcs\u00b7tung", "kam", "aus", "sei\u00b7ner", "Schleu\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ist es wirklich n\u00f6tig, noch erst zu versichern:", "tokens": ["Ist", "es", "wirk\u00b7lich", "n\u00f6\u00b7tig", ",", "noch", "erst", "zu", "ver\u00b7si\u00b7chern", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "$,", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Dieser Herr sei Junker und ein Preu\u00dfe?", "tokens": ["Die\u00b7ser", "Herr", "sei", "Jun\u00b7ker", "und", "ein", "Preu\u00b7\u00dfe", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NE", "KON", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}