{"textgrid.poem.52406": {"metadata": {"author": {"name": "Reuter, Fritz", "birth": "N.A.", "death": "N.A."}, "title": "56. De Sokratische Method'", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "De Schaulrat Ix ut Ixenstein,", "tokens": ["De", "Schaul\u00b7rat", "Ix", "ut", "I\u00b7xens\u00b7tein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "De s\u00fcll de Schaulen mal nahseihn", "tokens": ["De", "s\u00fcll", "de", "Schau\u00b7len", "mal", "nah\u00b7seihn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM", "FM", "FM", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Un kamm denn ok nah Ohserin", "tokens": ["Un", "kamm", "denn", "ok", "nah", "Oh\u00b7se\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ADJD", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Tau den Schaulmeister Rosengr\u00e4un.", "tokens": ["Tau", "den", "Schaul\u00b7meis\u00b7ter", "Ro\u00b7sen\u00b7gr\u00e4un", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "NE", "$."], "meter": "+----+-+", "measure": "dactylic.init"}, "line.5": {"text": "Na, nu ward grot Examen sin.", "tokens": ["Na", ",", "nu", "ward", "grot", "E\u00b7xa\u00b7men", "sin", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VAFIN", "ADJD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "De oll Schaulmeister hett in N\u00f6ten", "tokens": ["De", "oll", "Schaul\u00b7meis\u00b7ter", "hett", "in", "N\u00f6\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "NN", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Un sihr in Angst un Bangen seten!", "tokens": ["Un", "sihr", "in", "Angst", "un", "Ban\u00b7gen", "se\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Doch helpt't em nich, hei m\u00f6t heran", "tokens": ["Doch", "helpt't", "em", "nich", ",", "hei", "m\u00f6t", "he\u00b7ran"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PIS", "PTKNEG", "$,", "NE", "NE", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Un wisen, wat hei lihren kann.", "tokens": ["Un", "wi\u00b7sen", ",", "wat", "hei", "lih\u00b7ren", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "$,", "FM", "FM", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Dat deiht hei nu, un kolle Sweit", "tokens": ["Dat", "deiht", "hei", "nu", ",", "un", "kol\u00b7le", "Sweit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "FM", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.11": {"text": "Deiht em von dat Gesicht 'raf lecken.", "tokens": ["Deiht", "em", "von", "dat", "Ge\u00b7sicht", "'raf", "le\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "APPR", "ART", "NN", "NE", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Denn wat hei s\u00fcnst so pr\u00e4chtig weit,", "tokens": ["Denn", "wat", "hei", "s\u00fcnst", "so", "pr\u00e4ch\u00b7tig", "weit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "FM", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Dat is h\u00fct allens in de Hecken,", "tokens": ["Dat", "is", "h\u00fct", "al\u00b7lens", "in", "de", "He\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Un de verdammten Jungs, de weiten nix,", "tokens": ["Un", "de", "ver\u00b7damm\u00b7ten", "Jungs", ",", "de", "wei\u00b7ten", "nix", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,", "NE", "ADJA", "NE", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.15": {"text": "Un unse gaud Herr Schaulrat Ix,", "tokens": ["Un", "un\u00b7se", "gaud", "Herr", "Schaul\u00b7rat", "Ix", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "De sitt so v\u00f6rnehm un so still", "tokens": ["De", "sitt", "so", "v\u00f6r\u00b7nehm", "un", "so", "still"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ADJD", "FM", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "In sinen Lehnstaul achter\u00e4wer leggt,", "tokens": ["In", "si\u00b7nen", "Lehn\u00b7staul", "ach\u00b7te\u00b7r\u00e4\u00b7wer", "leggt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.18": {"text": "As wenn hei all'ns sick marken will,", "tokens": ["As", "wenn", "hei", "all'ns", "sick", "mar\u00b7ken", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "FM", "FM", "FM", "VVINF", "VMFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.19": {"text": "Wat hir v\u00f6r dummes T\u00fcg ward seggt.", "tokens": ["Wat", "hir", "v\u00f6r", "dum\u00b7mes", "T\u00fcg", "ward", "seggt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Doch gung dat beter, as hei dacht,", "tokens": ["Doch", "gung", "dat", "be\u00b7ter", ",", "as", "hei", "dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "$,", "FM", "FM", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.21": {"text": "Denn de Herr Schaulrat hadd vergangen Nacht", "tokens": ["Denn", "de", "Herr", "Schaul\u00b7rat", "hadd", "ver\u00b7gan\u00b7gen", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NN", "NN", "VAFIN", "VVPP", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Ganz pr\u00e4chtig rauht,", "tokens": ["Ganz", "pr\u00e4ch\u00b7tig", "rauht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.23": {"text": "Ok gaud verdaut,", "tokens": ["Ok", "gaud", "ver\u00b7daut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "VVPP", "$,"], "meter": "---+", "measure": "unknown.measure.single"}, "line.24": {"text": "Sin Unnerliw was in de Reih,", "tokens": ["Sin", "Un\u00b7ner\u00b7liw", "was", "in", "de", "Reih", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PRELS", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Un fr\u00fchst\u00fcckt hadd hei h\u00fct v\u00f6r twei.", "tokens": ["Un", "fr\u00fch\u00b7st\u00fcckt", "hadd", "hei", "h\u00fct", "v\u00f6r", "twei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.26": {"text": "Hei seggt denn also blot: \u00bbMein lieber Freund,", "tokens": ["Hei", "seggt", "denn", "al\u00b7so", "blot", ":", "\u00bb", "Mein", "lie\u00b7ber", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ADV", "$.", "$(", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.27": {"text": "Sie unterrichten noch nach alter Mode,", "tokens": ["Sie", "un\u00b7ter\u00b7rich\u00b7ten", "noch", "nach", "al\u00b7ter", "Mo\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Warum nicht nach Sokratischer Methode?\u00ab", "tokens": ["Wa\u00b7rum", "nicht", "nach", "Sok\u00b7ra\u00b7ti\u00b7scher", "Me\u00b7tho\u00b7de", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PTKNEG", "APPR", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "\u00bbich wei\u00df nich, woans diese seind\u00ab,", "tokens": ["\u00bb", "ich", "wei\u00df", "nich", ",", "woans", "die\u00b7se", "seind", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PDS", "VAFIN", "$(", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.30": {"text": "Seggt Rosengr\u00e4un, \u00bbwenn Sie's mich weisen wollen,", "tokens": ["Seggt", "Ro\u00b7sen\u00b7gr\u00e4un", ",", "\u00bb", "wenn", "Sie's", "mich", "wei\u00b7sen", "wol\u00b7len", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "$(", "KOUS", "PIS", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Denn will ich gerne Schul nah hollen.\u00ab", "tokens": ["Denn", "will", "ich", "ger\u00b7ne", "Schul", "nah", "hol\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "NN", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "\u00bbnichts leichter ist als das.", "tokens": ["\u00bb", "nichts", "leich\u00b7ter", "ist", "als", "das", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "ADJD", "VAFIN", "KOKOM", "PDS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Komm her, mein Sohn, und sag mal, was", "tokens": ["Komm", "her", ",", "mein", "Sohn", ",", "und", "sag", "mal", ",", "was"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "PPOSAT", "NN", "$,", "KON", "VVIMP", "ADV", "$,", "PWS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Ist das wohl f\u00fcr ein kleines Fl\u00fc\u00dfchen,", "tokens": ["Ist", "das", "wohl", "f\u00fcr", "ein", "klei\u00b7nes", "Fl\u00fc\u00df\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.35": {"text": "Das dicht hier flie\u00dft am Dorf vorbei?", "tokens": ["Das", "dicht", "hier", "flie\u00dft", "am", "Dorf", "vor\u00b7bei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADV", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Nun, nun! Besinne dich ein bi\u00dfchen!", "tokens": ["Nun", ",", "nun", "!", "Be\u00b7sin\u00b7ne", "dich", "ein", "bi\u00df\u00b7chen", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "VVFIN", "PRF", "ART", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Du wei\u00dft es nicht? \u2013 Nur keine Scheu!", "tokens": ["Du", "wei\u00dft", "es", "nicht", "?", "\u2013", "Nur", "kei\u00b7ne", "Scheu", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Nun sag mal, wenn man B\u00f6ses hat getan,", "tokens": ["Nun", "sag", "mal", ",", "wenn", "man", "B\u00f6\u00b7ses", "hat", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KOUS", "PIS", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.39": {"text": "Was mu\u00df man sp\u00e4ter daf\u00fcr leiden?", "tokens": ["Was", "mu\u00df", "man", "sp\u00e4\u00b7ter", "da\u00b7f\u00fcr", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "ADJD", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "Du, meine Tochter! Bu \u2013 Bu? Wer wei\u00df es von euch beiden?\u00ab", "tokens": ["Du", ",", "mei\u00b7ne", "Toch\u00b7ter", "!", "Bu", "\u2013", "Bu", "?", "Wer", "wei\u00df", "es", "von", "euch", "bei\u00b7den", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "$,", "PPOSAT", "NN", "$.", "NE", "$(", "NE", "$.", "PWS", "VVFIN", "PPER", "APPR", "PPER", "PIAT", "$.", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.41": {"text": "\u00bbdenn tun wir Bu\u00dfe\u00ab, seggt Fik Thran.", "tokens": ["\u00bb", "denn", "tun", "wir", "Bu\u00b7\u00dfe", "\u00ab", ",", "seggt", "Fik", "Thran", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "NN", "$(", "$,", "VVFIN", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "\u00bbganz richtig! Und statt 'Bu\u00dfe' sagt ihr 'Busse',", "tokens": ["\u00bb", "ganz", "rich\u00b7tig", "!", "Und", "statt", "'", "Bu\u00b7\u00dfe", "'", "sagt", "ihr", "'", "Bus\u00b7se", "'", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "$.", "KON", "VVFIN", "$(", "NN", "$(", "VVFIN", "PPER", "$(", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Denn habt den Namen ihr vom Flusse. \u2013", "tokens": ["Denn", "habt", "den", "Na\u00b7men", "ihr", "vom", "Flus\u00b7se", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PPER", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.44": {"text": "In welchen Flu\u00df f\u00e4llt nun die Busse?", "tokens": ["In", "wel\u00b7chen", "Flu\u00df", "f\u00e4llt", "nun", "die", "Bus\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Nun, Kinder, nun! Besinnt euch wieder!", "tokens": ["Nun", ",", "Kin\u00b7der", ",", "nun", "!", "Be\u00b7sinnt", "euch", "wie\u00b7der", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "ADV", "$.", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Was f\u00e4llt wohl all's vom Himmel nieder?", "tokens": ["Was", "f\u00e4llt", "wohl", "all's", "vom", "Him\u00b7mel", "nie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PIS", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Nun?\u00ab \u2013 \u00bbRegen.\u00ab \u2013 \u00bbWeiter!\u00ab \u2013 \u00bbSnei.\u00ab \u2013 \u00bbWas weiter?\u00ab \u2013 \u00bbDak.\u00ab", "tokens": ["Nun", "?", "\u00ab", "\u2013", "\u00bb", "Re\u00b7gen", ".", "\u00ab", "\u2013", "\u00bb", "Wei\u00b7ter", "!", "\u00ab", "\u2013", "\u00bb", "Snei", ".", "\u00ab", "\u2013", "\u00bb", "Was", "wei\u00b7ter", "?", "\u00ab", "\u2013", "\u00bb", "Dak", ".", "\u00ab"], "token_info": ["word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["ADV", "$.", "$(", "$(", "$(", "NN", "$.", "$(", "$(", "$(", "NN", "$.", "$(", "$(", "$(", "NE", "$.", "$(", "$(", "$(", "PWS", "ADV", "$.", "$(", "$(", "$(", "NE", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "\u00bbwas weiter sonst?\u00ab \u2013 \u00bbIck weit't\u00ab, seggt Hanne Knak.", "tokens": ["\u00bb", "was", "wei\u00b7ter", "sonst", "?", "\u00ab", "\u2013", "\u00bb", "Ick", "weit't", "\u00ab", ",", "seggt", "Han\u00b7ne", "Knak", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "ADV", "$.", "$(", "$(", "$(", "PPER", "VVFIN", "$(", "$,", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.49": {"text": "\u00bbnun denn, mein S\u00f6hnchen?\u00ab \u2013 \u00bbHagel.\u00ab \u2013 \u00bbRecht!", "tokens": ["\u00bb", "nun", "denn", ",", "mein", "S\u00f6hn\u00b7chen", "?", "\u00ab", "\u2013", "\u00bb", "Ha\u00b7gel", ".", "\u00ab", "\u2013", "\u00bb", "Recht", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "PPOSAT", "NN", "$.", "$(", "$(", "$(", "NN", "$.", "$(", "$(", "$(", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Und wenn ihr nun statt 'Hagel' 'Havel' sprecht,", "tokens": ["Und", "wenn", "ihr", "nun", "statt", "'", "Ha\u00b7gel", "'", "'", "Ha\u00b7vel", "'", "sprecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "$(", "NE", "$(", "$(", "NE", "$(", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.51": {"text": "So habt ihr's ja heraus, ihr findet", "tokens": ["So", "habt", "ih\u00b7r's", "ja", "he\u00b7raus", ",", "ihr", "fin\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKVZ", "$,", "PPER", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.52": {"text": "Den Flu\u00df, in den die Busse m\u00fcndet.", "tokens": ["Den", "Flu\u00df", ",", "in", "den", "die", "Bus\u00b7se", "m\u00fcn\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Und nun die Havel! Sagt, wie ist ihr Lauf?", "tokens": ["Und", "nun", "die", "Ha\u00b7vel", "!", "Sagt", ",", "wie", "ist", "ihr", "Lauf", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NE", "$.", "VVFIN", "$,", "PWAV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Und welcher Flu\u00df nimmt wohl die Havel auf?", "tokens": ["Und", "wel\u00b7cher", "Flu\u00df", "nimmt", "wohl", "die", "Ha\u00b7vel", "auf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VVFIN", "ADV", "ART", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "Nun? Nun? \u2013 Ihr werd't ihn sicher kennen.", "tokens": ["Nun", "?", "Nun", "?", "\u2013", "Ihr", "werd't", "ihn", "si\u00b7cher", "ken\u00b7nen", "."], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "$.", "$(", "PPER", "VAFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.56": {"text": "Wer kann von euch den Flu\u00df mir nennen? \u2013", "tokens": ["Wer", "kann", "von", "euch", "den", "Flu\u00df", "mir", "nen\u00b7nen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "APPR", "PPER", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Nicht? \u2013 Nun, denn tret mal einer vor, ihr Lieben,", "tokens": ["Nicht", "?", "\u2013", "Nun", ",", "denn", "tret", "mal", "ei\u00b7ner", "vor", ",", "ihr", "Lie\u00b7ben", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "$.", "$(", "ADV", "$,", "KON", "VVFIN", "ADV", "PIS", "PTKVZ", "$,", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.58": {"text": "Damit ich auf den Weg ihm helfe.", "tokens": ["Da\u00b7mit", "ich", "auf", "den", "Weg", "ihm", "hel\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "Nun z\u00e4hle mal!\u00ab \u2013 \u00bbEins, zwei, drei, vier, f\u00fcnf, sechs, sieben.\u00ab", "tokens": ["Nun", "z\u00e4h\u00b7le", "mal", "!", "\u00ab", "\u2013", "\u00bb", "Eins", ",", "zwei", ",", "drei", ",", "vier", ",", "f\u00fcnf", ",", "sechs", ",", "sie\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$.", "$(", "$(", "$(", "NN", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$.", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.60": {"text": "\u00bbnun, weiter!\u00ab \u2013 \u00bbAchte, neune, zehne, elfe.\u00ab", "tokens": ["\u00bb", "nun", ",", "wei\u00b7ter", "!", "\u00ab", "\u2013", "\u00bb", "Ach\u00b7te", ",", "neu\u00b7ne", ",", "zeh\u00b7ne", ",", "el\u00b7fe", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "$.", "$(", "$(", "$(", "NN", "$,", "ADJA", "$,", "VVFIN", "$,", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.61": {"text": "\u00bbhalt an! Statt 'elfe' saget ihr nun 'Elbe';", "tokens": ["\u00bb", "halt", "an", "!", "Statt", "'", "el\u00b7fe", "'", "sa\u00b7get", "ihr", "nun", "'", "El\u00b7be", "'", ";"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$.", "NN", "$(", "NN", "$(", "VVFIN", "PPER", "ADV", "$(", "NE", "$(", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.62": {"text": "Ihr seht, es ist beinah dasselbe. \u2013", "tokens": ["Ihr", "seht", ",", "es", "ist", "bei\u00b7nah", "das\u00b7sel\u00b7be", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "PDAT", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "Nun aber ...\u00ab \u2013 \u00bbHerr\u00ab, seggt Rosengr\u00e4un,", "tokens": ["Nun", "a\u00b7ber", "...", "\u00ab", "\u2013", "\u00bb", "Herr", "\u00ab", ",", "seggt", "Ro\u00b7sen\u00b7gr\u00e4un", ","], "token_info": ["word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "$(", "$(", "$(", "NN", "$(", "$,", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "\u00bbdies St\u00fcck h\u00e4tt ich Sie schon afseihn,", "tokens": ["\u00bb", "dies", "St\u00fcck", "h\u00e4tt", "ich", "Sie", "schon", "af\u00b7seihn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "NN", "VAFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Das k\u00f6nnt ich auch. Wenn Sie das wollen,", "tokens": ["Das", "k\u00f6nnt", "ich", "auch", ".", "Wenn", "Sie", "das", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$.", "KOUS", "PPER", "PDS", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.66": {"text": "Denn m\u00fcggt ick woll 'ne Prauw afhollen.\u00ab", "tokens": ["Denn", "m\u00fcggt", "ick", "woll", "'ne", "Prauw", "af\u00b7hol\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.67": {"text": "\u00bbjawohl, jawohl, mein lieber Freund,", "tokens": ["\u00bb", "ja\u00b7wohl", ",", "ja\u00b7wohl", ",", "mein", "lie\u00b7ber", "Freund", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ITJ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "Das w\u00fcrd' mich ganz besonders freun.\u00ab", "tokens": ["Das", "w\u00fcrd'", "mich", "ganz", "be\u00b7son\u00b7ders", "freun", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "\u00bbna, denn man zu!\u00ab seggt Rosengr\u00e4un,", "tokens": ["\u00bb", "na", ",", "denn", "man", "zu", "!", "\u00ab", "seggt", "Ro\u00b7sen\u00b7gr\u00e4un", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "KON", "PIS", "PTKVZ", "$.", "$(", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "\u00bbda wir nun bei der Elbe seind,", "tokens": ["\u00bb", "da", "wir", "nun", "bei", "der", "El\u00b7be", "seind", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "APPR", "ART", "NE", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "So woll'n wir sehn, wo selbe bleibt.", "tokens": ["So", "woll'n", "wir", "sehn", ",", "wo", "sel\u00b7be", "bleibt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVINF", "$,", "PWAV", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "In's erst geht sie nach Hamborg ran,", "tokens": ["In's", "erst", "geht", "sie", "nach", "Ham\u00b7borg", "ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.73": {"text": "Wo sie sehr starke Schiffohrt treibt", "tokens": ["Wo", "sie", "sehr", "star\u00b7ke", "Schif\u00b7fohrt", "treibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Un wo man wieder sehen kann,", "tokens": ["Un", "wo", "man", "wie\u00b7der", "se\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "PIS", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Wie weise Gott es ingerichtet hat,", "tokens": ["Wie", "wei\u00b7se", "Gott", "es", "in\u00b7ge\u00b7rich\u00b7tet", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NN", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.76": {"text": "Da\u00df bei 'ner jeden gro\u00dfen Stadt", "tokens": ["Da\u00df", "bei", "'ner", "je\u00b7den", "gro\u00b7\u00dfen", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "Ein gro\u00dfer Flu\u00df flie\u00dft auch vorbei,", "tokens": ["Ein", "gro\u00b7\u00dfer", "Flu\u00df", "flie\u00dft", "auch", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Damit die Schiffohrt m\u00f6glich sei.", "tokens": ["Da\u00b7mit", "die", "Schif\u00b7fohrt", "m\u00f6g\u00b7lich", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "Nu sag' mich aber, Jochen Plasten,", "tokens": ["Nu", "sag'", "mich", "a\u00b7ber", ",", "Jo\u00b7chen", "Plas\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.80": {"text": "Wo bleibt nu woll die Elbe nahsten,", "tokens": ["Wo", "bleibt", "nu", "woll", "die", "El\u00b7be", "nahs\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ADV", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.81": {"text": "Wo m\u00fcndet sich die Elbe rein? \u2013", "tokens": ["Wo", "m\u00fcn\u00b7det", "sich", "die", "El\u00b7be", "rein", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VMFIN", "PRF", "ART", "NE", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.82": {"text": "Dat wei\u00dft du nich? \u2013 Na, K\u00f6rling Heinz,", "tokens": ["Dat", "wei\u00dft", "du", "nich", "?", "\u2013", "Na", ",", "K\u00f6r\u00b7ling", "Heinz", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "ITJ", "$,", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.83": {"text": "Komm du mal her, un z\u00e4hl mal eins!\u00bb", "tokens": ["Komm", "du", "mal", "her", ",", "un", "z\u00e4hl", "mal", "eins", "!", "\u00bb"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKVZ", "$,", "FM", "VVFIN", "ADV", "PIS", "$.", "$("], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.84": {"text": "\u00bbeins, zwei, drei, vier, f\u00fcnf, sechs, sieben, acht, neun,", "tokens": ["\u00bb", "eins", ",", "zwei", ",", "drei", ",", "vier", ",", "f\u00fcnf", ",", "sechs", ",", "sie\u00b7ben", ",", "acht", ",", "neun", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "PIS", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$,", "CARD", "$,", "VVFIN", "$,", "CARD", "$,", "CARD", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.85": {"text": "Zehn, elf, zw\u00f6lf ...\u00ab \u2013 Halt!\u00ab seggt Rosengr\u00e4un,", "tokens": ["Zehn", ",", "elf", ",", "zw\u00f6lf", "...", "\u00ab", "\u2013", "Halt", "!", "\u00ab", "seggt", "Ro\u00b7sen\u00b7gr\u00e4un", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["CARD", "$,", "CARD", "$,", "CARD", "$(", "$(", "$(", "VVIMP", "$.", "$(", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.86": {"text": "\u00bbwo m\u00fcndet nun die Elbe rein?", "tokens": ["\u00bb", "wo", "m\u00fcn\u00b7det", "nun", "die", "El\u00b7be", "rein", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "ADV", "ART", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.87": {"text": "F\u00e4llt keinem denn der Name ein? \u2013", "tokens": ["F\u00e4llt", "kei\u00b7nem", "denn", "der", "Na\u00b7me", "ein", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.88": {"text": "Nun, 's ist doch so'ne leichte Sach'!", "tokens": ["Nun", ",", "'s", "ist", "doch", "so'\u00b7ne", "leich\u00b7te", "Sach'", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.89": {"text": "Denkt doch bei 'zw\u00f6lfe' etwas nach!", "tokens": ["Denkt", "doch", "bei", "'", "zw\u00f6l\u00b7fe", "'", "et\u00b7was", "nach", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "$(", "CARD", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "'zw\u00f6lf' \u2013 'zw\u00f6lfe'! \u2013 Tut's euch \u00fcberleggen! \u2013", "tokens": ["'", "zw\u00f6lf", "'", "\u2013", "'", "zw\u00f6l\u00b7fe", "'", "!", "\u2013", "Tut's", "euch", "\u00fc\u00b7ber\u00b7leg\u00b7gen", "!", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "CARD", "$(", "$(", "$(", "CARD", "$(", "$.", "$(", "NE", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.91": {"text": "Seid ihr denn alle in den D\u00e4s'?", "tokens": ["Seid", "ihr", "denn", "al\u00b7le", "in", "den", "D\u00e4s'", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ADV", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "Da stehn sie nu, die D\u00e4melkl\u00e4s'!", "tokens": ["Da", "stehn", "sie", "nu", ",", "die", "D\u00e4\u00b7mel\u00b7kl\u00e4s'", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "Stats 'zw\u00f6lfe' m\u00fc\u00dft ihr 'Nordsee' seggen.\u00ab", "tokens": ["Stats", "'", "zw\u00f6l\u00b7fe", "'", "m\u00fc\u00dft", "ihr", "'", "Nord\u00b7see", "'", "seg\u00b7gen", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "$(", "CARD", "$(", "VMFIN", "PPER", "$(", "NE", "$(", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}