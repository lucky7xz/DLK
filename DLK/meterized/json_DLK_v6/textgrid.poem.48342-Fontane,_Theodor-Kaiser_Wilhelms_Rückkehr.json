{"textgrid.poem.48342": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Kaiser Wilhelms R\u00fcckkehr", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dreifarbig, kranzumwunden", "tokens": ["Drei\u00b7far\u00b7big", ",", "kran\u00b7zum\u00b7wun\u00b7den"], "token_info": ["word", "punct", "word"], "pos": ["NE", "$,", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Unsre Fahnen flattern und wehn,", "tokens": ["Uns\u00b7re", "Fah\u00b7nen", "flat\u00b7tern", "und", "wehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "KON", "VVINF", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Das waren Festesstunden,", "tokens": ["Das", "wa\u00b7ren", "Fes\u00b7tes\u00b7stun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie keine wir noch gesehn;", "tokens": ["Wie", "kei\u00b7ne", "wir", "noch", "ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "PPER", "ADV", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Vielhunderttausendt\u00f6nig", "tokens": ["Viel\u00b7hun\u00b7dert\u00b7tau\u00b7send\u00b7t\u00f6\u00b7nig"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "In L\u00fcften die Gr\u00fc\u00dfe ziehn:", "tokens": ["In", "L\u00fcf\u00b7ten", "die", "Gr\u00fc\u00b7\u00dfe", "ziehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Willkommen ", "tokens": ["Will\u00b7kom\u00b7men"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.8": {"text": "Willkommen in Berlin.", "tokens": ["Will\u00b7kom\u00b7men", "in", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.2": {"line.1": {"text": "Nun steiget h\u00f6her, ihr Schwalben,", "tokens": ["Nun", "stei\u00b7get", "h\u00f6\u00b7her", ",", "ihr", "Schwal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und k\u00fcndet, was es sei:", "tokens": ["Und", "k\u00fcn\u00b7det", ",", "was", "es", "sei", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Blauer Himmel allenthalben,", "tokens": ["Blau\u00b7er", "Him\u00b7mel", "al\u00b7len\u00b7thal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das Wetter ist vorbei.", "tokens": ["Und", "das", "Wet\u00b7ter", "ist", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Es ward uns viel beschieden,", "tokens": ["Es", "ward", "uns", "viel", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Es ward uns gro\u00dfes Gl\u00fcck:", "tokens": ["Es", "ward", "uns", "gro\u00b7\u00dfes", "Gl\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "K\u00f6nig Wilhelm bringt uns den Frieden", "tokens": ["K\u00f6\u00b7nig", "Wil\u00b7helm", "bringt", "uns", "den", "Frie\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Und bringt uns sich selber zur\u00fcck.", "tokens": ["Und", "bringt", "uns", "sich", "sel\u00b7ber", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Er bringt uns sich selber wieder", "tokens": ["Er", "bringt", "uns", "sich", "sel\u00b7ber", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PRF", "ADV", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und Neues zu allem, was war,", "tokens": ["Und", "Neu\u00b7es", "zu", "al\u00b7lem", ",", "was", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PIS", "$,", "PWS", "VAFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Nun entsprie\u00dft ein stolzes Gefieder", "tokens": ["Nun", "ent\u00b7sprie\u00dft", "ein", "stol\u00b7zes", "Ge\u00b7fie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Dem alten preu\u00dfischen Aar.", "tokens": ["Dem", "al\u00b7ten", "preu\u00b7\u00dfi\u00b7schen", "Aar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Das Alte hoch und das Neue", "tokens": ["Das", "Al\u00b7te", "hoch", "und", "das", "Neu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "KON", "ART", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Vom Njemen bis an den Rhein \u2013", "tokens": ["Vom", "Nje\u00b7men", "bis", "an", "den", "Rhein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPR", "ART", "NE", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und wir flechten die alte Treue", "tokens": ["Und", "wir", "flech\u00b7ten", "die", "al\u00b7te", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "In die neue Krone hinein.", "tokens": ["In", "die", "neu\u00b7e", "Kro\u00b7ne", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}