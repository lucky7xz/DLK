{"textgrid.poem.26372": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[mir tat ein bi\u00dfchen Wasser not]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mir tat ein bi\u00dfchen Wasser not,", "tokens": ["Mir", "tat", "ein", "bi\u00df\u00b7chen", "Was\u00b7ser", "not", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Darum nahm ich ein Ruderboot.", "tokens": ["Da\u00b7rum", "nahm", "ich", "ein", "Ru\u00b7der\u00b7boot", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.2": {"line.1": {"text": "Das Reisen hab' ich sehr geliebt,", "tokens": ["Das", "Rei\u00b7sen", "hab'", "ich", "sehr", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil man sich weiter fortbegibt.", "tokens": ["Weil", "man", "sich", "wei\u00b7ter", "fort\u00b7be\u00b7gibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Die N\u00e4he wird uns oft zu nah,", "tokens": ["Die", "N\u00e4\u00b7he", "wird", "uns", "oft", "zu", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr den Fall ist die Ferne da.", "tokens": ["F\u00fcr", "den", "Fall", "ist", "die", "Fer\u00b7ne", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Ein jeder sagt: das Meer ist gro\u00df,", "tokens": ["Ein", "je\u00b7der", "sagt", ":", "das", "Meer", "ist", "gro\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch keiner sagt: drauf ist nichts los.", "tokens": ["Doch", "kei\u00b7ner", "sagt", ":", "drauf", "ist", "nichts", "los", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "PAV", "VAFIN", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Denn denk' ich an die nasse Brut", "tokens": ["Denn", "denk'", "ich", "an", "die", "nas\u00b7se", "Brut"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Fische mit dem kalten Blut,", "tokens": ["Der", "Fi\u00b7sche", "mit", "dem", "kal\u00b7ten", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Erde gr\u00f6\u00dfte Egoisten,", "tokens": ["Der", "Er\u00b7de", "gr\u00f6\u00df\u00b7te", "E\u00b7gois\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die liebeleer ihr Dasein fristen:", "tokens": ["Die", "lie\u00b7be\u00b7leer", "ihr", "Da\u00b7sein", "fris\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Das Weib legt schuldigst Ei an Ei,", "tokens": ["Das", "Weib", "legt", "schul\u00b7digst", "Ei", "an", "Ei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das M\u00e4nnchen schwimmt daran vorbei,", "tokens": ["Das", "M\u00e4nn\u00b7chen", "schwimmt", "da\u00b7ran", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Getrennt lieben die zwei Geschlechter, \u2013", "tokens": ["Ge\u00b7trennt", "lie\u00b7ben", "die", "zwei", "Ge\u00b7schlech\u00b7ter", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VVFIN", "ART", "CARD", "NN", "$,", "$("], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Ich bin und bleib' ein Meerver\u00e4chter.", "tokens": ["Ich", "bin", "und", "bleib'", "ein", "Meer\u00b7ve\u00b7r\u00e4ch\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Trotzdem ward ich jetzt Wassermann,", "tokens": ["Trotz\u00b7dem", "ward", "ich", "jetzt", "Was\u00b7ser\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Kaute Tabak und spuckte dann.", "tokens": ["Kau\u00b7te", "Ta\u00b7bak", "und", "spuck\u00b7te", "dann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "VVFIN", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Ich ruderte und lenkte sehr,", "tokens": ["Ich", "ru\u00b7der\u00b7te", "und", "lenk\u00b7te", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADV", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Als ob ich die Vorsehung w\u00e4r',", "tokens": ["Als", "ob", "ich", "die", "Vor\u00b7se\u00b7hung", "w\u00e4r'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ART", "NN", "VAFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.11": {"line.1": {"text": "Sechs Wochen ruderte ich froh,", "tokens": ["Sechs", "Wo\u00b7chen", "ru\u00b7der\u00b7te", "ich", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und manchmal tat ich auch nur so.", "tokens": ["Und", "manch\u00b7mal", "tat", "ich", "auch", "nur", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Nachts schlief ich still am K\u00fcstenland,", "tokens": ["Nachts", "schlief", "ich", "still", "am", "K\u00fcs\u00b7ten\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wozu sich stets ein Leuchtturm fand.", "tokens": ["Wo\u00b7zu", "sich", "stets", "ein", "Leucht\u00b7turm", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Steiniger ward der K\u00fcstenrahmen,", "tokens": ["Stei\u00b7ni\u00b7ger", "ward", "der", "K\u00fcs\u00b7ten\u00b7rah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Je mehr die Ruder nordw\u00e4rts kamen.", "tokens": ["Je", "mehr", "die", "Ru\u00b7der", "nord\u00b7w\u00e4rts", "ka\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Vom Meer geschliffen runde Steine,", "tokens": ["Vom", "Meer", "ge\u00b7schlif\u00b7fen", "run\u00b7de", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Totensch\u00e4del, gro\u00df und kleine,", "tokens": ["Wie", "To\u00b7ten\u00b7sch\u00e4\u00b7del", ",", "gro\u00df", "und", "klei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADJD", "KON", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Die lagen von der Eiszeit her,", "tokens": ["Die", "la\u00b7gen", "von", "der", "Eis\u00b7zeit", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als wenn das Land ein Kirchhof w\u00e4r'.", "tokens": ["Als", "wenn", "das", "Land", "ein", "Kirch\u00b7hof", "w\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein Seeh\u00fcndlein war mein Begleiter,", "tokens": ["Ein", "See\u00b7h\u00fcnd\u00b7lein", "war", "mein", "Be\u00b7glei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es schwamm acht Tage mit mir weiter;", "tokens": ["Es", "schwamm", "acht", "Ta\u00b7ge", "mit", "mir", "wei\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wie Marionetten an den Dr\u00e4hten", "tokens": ["Wie", "Ma\u00b7ri\u00b7o\u00b7net\u00b7ten", "an", "den", "Dr\u00e4h\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hingen die M\u00f6wen, bellten, kr\u00e4hten.", "tokens": ["Hin\u00b7gen", "die", "M\u00f6\u00b7wen", ",", "bell\u00b7ten", ",", "kr\u00e4h\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.18": {"line.1": {"text": "Vom leeren Himmel auf mich nieder", "tokens": ["Vom", "lee\u00b7ren", "Him\u00b7mel", "auf", "mich", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "PPER", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Windteufel sangen Orgellieder.", "tokens": ["Wind\u00b7teu\u00b7fel", "san\u00b7gen", "Or\u00b7gel\u00b7lie\u00b7der", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.19": {"line.1": {"text": "Das Wasser tanzte in Gestalten,", "tokens": ["Das", "Was\u00b7ser", "tanz\u00b7te", "in", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Meergreise, die den Mund nicht halten,", "tokens": ["Meer\u00b7grei\u00b7se", ",", "die", "den", "Mund", "nicht", "hal\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.20": {"line.1": {"text": "Die spuckten, anstatt da\u00df sie sprachen,", "tokens": ["Die", "spuck\u00b7ten", ",", "an\u00b7statt", "da\u00df", "sie", "spra\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "KOUI", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und tausend unheimliche Sachen", "tokens": ["Und", "tau\u00b7send", "un\u00b7heim\u00b7li\u00b7che", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "CARD", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.21": {"line.1": {"text": "Liefen den ganzen Tag mir nach,", "tokens": ["Lie\u00b7fen", "den", "gan\u00b7zen", "Tag", "mir", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PPER", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Drum sehnte ich mich unter Dach.", "tokens": ["Drum", "sehn\u00b7te", "ich", "mich", "un\u00b7ter", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Auf Pf\u00e4hlen standen in den Klippen", "tokens": ["Auf", "Pf\u00e4h\u00b7len", "stan\u00b7den", "in", "den", "Klip\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00f6lzerne D\u00f6rflein gleich Gerippen,", "tokens": ["H\u00f6l\u00b7zer\u00b7ne", "D\u00f6r\u00b7flein", "gleich", "Ge\u00b7rip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.23": {"line.1": {"text": "Ein Leichenkasten jedes Haus,", "tokens": ["Ein", "Lei\u00b7chen\u00b7kas\u00b7ten", "je\u00b7des", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wurmstichig sah das Ganze aus.", "tokens": ["Wurm\u00b7sti\u00b7chig", "sah", "das", "Gan\u00b7ze", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Hier legte ich die Ruder ein", "tokens": ["Hier", "leg\u00b7te", "ich", "die", "Ru\u00b7der", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und klopfte an. Man rief: Herein!", "tokens": ["Und", "klopf\u00b7te", "an", ".", "Man", "rief", ":", "Her\u00b7ein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "PIS", "VVFIN", "$.", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Doch ehe ich noch eingetreten,", "tokens": ["Doch", "e\u00b7he", "ich", "noch", "ein\u00b7ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zwei M\u00e4dchenaugen mich ersp\u00e4hten;", "tokens": ["Zwei", "M\u00e4d\u00b7chen\u00b7au\u00b7gen", "mich", "er\u00b7sp\u00e4h\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Sie dr\u00fcckten fast die Scheiben aus,", "tokens": ["Sie", "dr\u00fcck\u00b7ten", "fast", "die", "Schei\u00b7ben", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So staunend sahen sie hinaus.", "tokens": ["So", "stau\u00b7nend", "sa\u00b7hen", "sie", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Beim Himmel, dacht' ich, welch Empfang,", "tokens": ["Beim", "Him\u00b7mel", ",", "dacht'", "ich", ",", "welch", "Emp\u00b7fang", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "PPER", "$,", "PWAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Land hat also Lebensklang", "tokens": ["Das", "Land", "hat", "al\u00b7so", "Le\u00b7bens\u00b7klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Der Vater von dem M\u00e4gdelein", "tokens": ["Der", "Va\u00b7ter", "von", "dem", "M\u00e4g\u00b7del\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sah wie ein Weihnachtsmann darein,", "tokens": ["Sah", "wie", "ein", "Weih\u00b7nachts\u00b7mann", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Rotwangig alt und kernig hart,", "tokens": ["Rot\u00b7wan\u00b7gig", "alt", "und", "ker\u00b7nig", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KON", "ADJD", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Schien j\u00fcnger als sein wei\u00dfer Bart.", "tokens": ["Schien", "j\u00fcn\u00b7ger", "als", "sein", "wei\u00b7\u00dfer", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KOKOM", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Er gr\u00fc\u00dfte schweigsam wie ein Fisch,", "tokens": ["Er", "gr\u00fc\u00df\u00b7te", "schweig\u00b7sam", "wie", "ein", "Fisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schweigsam wies er auf den Tisch.", "tokens": ["Und", "schweig\u00b7sam", "wies", "er", "auf", "den", "Tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Die M\u00e4gde kamen, deckten schnell,", "tokens": ["Die", "M\u00e4g\u00b7de", "ka\u00b7men", ",", "deck\u00b7ten", "schnell", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Tischtuch macht das Zimmer hell.", "tokens": ["Ein", "Tischtuch", "macht", "das", "Zim\u00b7mer", "hell", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Ehrfurchtsvoll schwieg man immerfort,", "tokens": ["Ehr\u00b7furchts\u00b7voll", "schwieg", "man", "im\u00b7mer\u00b7fort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00e4r' der Tisch ein h\u00f6hrer Ort.", "tokens": ["Als", "w\u00e4r'", "der", "Tisch", "ein", "h\u00f6h\u00b7rer", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Ich merkte nur, ich war willkommen", "tokens": ["Ich", "merk\u00b7te", "nur", ",", "ich", "war", "will\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und hab' die Sch\u00fcsseln angenommen.", "tokens": ["Und", "hab'", "die", "Sch\u00fcs\u00b7seln", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Das M\u00e4dchen sah ich gar nicht mehr,", "tokens": ["Das", "M\u00e4d\u00b7chen", "sah", "ich", "gar", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ob es eingemauert w\u00e4r'.", "tokens": ["Als", "ob", "es", "ein\u00b7ge\u00b7mau\u00b7ert", "w\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Die M\u00e4gde fl\u00fcsterten im Haus,", "tokens": ["Die", "M\u00e4g\u00b7de", "fl\u00fcs\u00b7ter\u00b7ten", "im", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geheimnisvoll sah manches aus,", "tokens": ["Ge\u00b7heim\u00b7nis\u00b7voll", "sah", "man\u00b7ches", "aus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Und einmal, als es Abend war,", "tokens": ["Und", "ein\u00b7mal", ",", "als", "es", "A\u00b7bend", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erkl\u00e4rte es sich wunderbar.", "tokens": ["Er\u00b7kl\u00e4r\u00b7te", "es", "sich", "wun\u00b7der\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Sturm war und drau\u00dfen laute Nacht,", "tokens": ["Sturm", "war", "und", "drau\u00b7\u00dfen", "lau\u00b7te", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KON", "ADV", "VVFIN", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Manchmal hat dumpf das Meer gekracht.", "tokens": ["Manch\u00b7mal", "hat", "dumpf", "das", "Meer", "ge\u00b7kracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.38": {"line.1": {"text": "Im Schaukelstuhl, den er gern brauchte,", "tokens": ["Im", "Schau\u00b7kel\u00b7stuhl", ",", "den", "er", "gern", "brauch\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vater sa\u00df und Stummel rauchte.", "tokens": ["Der", "Va\u00b7ter", "sa\u00df", "und", "Stum\u00b7mel", "rauch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Grog dampfte, man sah kaum den Tisch,", "tokens": ["Grog", "dampf\u00b7te", ",", "man", "sah", "kaum", "den", "Tisch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "PIS", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Und Grog gibt Sprache auch dem Fisch.", "tokens": ["Und", "Grog", "gibt", "Spra\u00b7che", "auch", "dem", "Fisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Wir taten oft die Gl\u00e4ser heben", "tokens": ["Wir", "ta\u00b7ten", "oft", "die", "Gl\u00e4\u00b7ser", "he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sprachen vom Weltende eben.", "tokens": ["Und", "spra\u00b7chen", "vom", "Wel\u00b7ten\u00b7de", "e\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.41": {"line.1": {"text": "Der Sturm stie\u00df schwer am Dach ums Haus,", "tokens": ["Der", "Sturm", "stie\u00df", "schwer", "am", "Dach", "ums", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf einmal l\u00f6scht die Lampe aus.", "tokens": ["Auf", "ein\u00b7mal", "l\u00f6scht", "die", "Lam\u00b7pe", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Ich springe auf, der Vater flucht,", "tokens": ["Ich", "sprin\u00b7ge", "auf", ",", "der", "Va\u00b7ter", "flucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Streichh\u00f6lzer findet nie, wer sucht.", "tokens": ["Streich\u00b7h\u00f6l\u00b7zer", "fin\u00b7det", "nie", ",", "wer", "sucht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Es mu\u00dften W\u00e4nde offen stehn,", "tokens": ["Es", "mu\u00df\u00b7ten", "W\u00e4n\u00b7de", "of\u00b7fen", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Sturm, der tat das Zimmer drehn.", "tokens": ["Der", "Sturm", ",", "der", "tat", "das", "Zim\u00b7mer", "drehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Ein L\u00e4rm, als w\u00e4r' das Haus zersprungen,", "tokens": ["Ein", "L\u00e4rm", ",", "als", "w\u00e4r'", "das", "Haus", "zer\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOKOM", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Dunkel f\u00fchl' ich mich umschlungen.", "tokens": ["Im", "Dun\u00b7kel", "f\u00fchl'", "ich", "mich", "um\u00b7schlun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Der Sturm, er hatte M\u00e4dchenarme", "tokens": ["Der", "Sturm", ",", "er", "hat\u00b7te", "M\u00e4d\u00b7chen\u00b7ar\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PPER", "VAFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und schnelle Lippen, wilde, warme,", "tokens": ["Und", "schnel\u00b7le", "Lip\u00b7pen", ",", "wil\u00b7de", ",", "war\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Mein Name wurde laut geschrien,", "tokens": ["Mein", "Na\u00b7me", "wur\u00b7de", "laut", "ge\u00b7schri\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dann fiel jemand im Zimmer hin.", "tokens": ["Dann", "fiel", "je\u00b7mand", "im", "Zim\u00b7mer", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.47": {"line.1": {"text": "Wenn so etwas so schnell erscheint,", "tokens": ["Wenn", "so", "et\u00b7was", "so", "schnell", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Glaubt man gar nicht, da\u00df man gemeint", "tokens": ["Glaubt", "man", "gar", "nicht", ",", "da\u00df", "man", "ge\u00b7meint"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "PTKNEG", "$,", "KOUS", "PIS", "VVPP"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.48": {"line.1": {"text": "Tat \u00fcberall nur K\u00fcsse sp\u00fcren,", "tokens": ["Tat", "\u00fc\u00b7be\u00b7rall", "nur", "K\u00fcs\u00b7se", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Licht kam, ich durfte mich nicht r\u00fchren.", "tokens": ["Licht", "kam", ",", "ich", "durf\u00b7te", "mich", "nicht", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Zu meinen F\u00fc\u00dfen, gleich den Leichen,", "tokens": ["Zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", ",", "gleich", "den", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Lag jenes M\u00e4dchen sondergleichen.", "tokens": ["Lag", "je\u00b7nes", "M\u00e4d\u00b7chen", "son\u00b7derg\u00b7lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Der Vater sprach: \u00bbEs ist ein Jammer,", "tokens": ["Der", "Va\u00b7ter", "sprach", ":", "\u00bb", "Es", "ist", "ein", "Jam\u00b7mer", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man bringe sie in ihre Kammer!\u00ab", "tokens": ["Man", "brin\u00b7ge", "sie", "in", "ih\u00b7re", "Kam\u00b7mer", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Die M\u00e4gde hoben sie sacht auf,", "tokens": ["Die", "M\u00e4g\u00b7de", "ho\u00b7ben", "sie", "sacht", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und trugen sie zu sich hinauf.", "tokens": ["Und", "tru\u00b7gen", "sie", "zu", "sich", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Im Zimmer war es schweigsam sehr,", "tokens": ["Im", "Zim\u00b7mer", "war", "es", "schweig\u00b7sam", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Grog, der dampfte auch nicht mehr,", "tokens": ["Der", "Grog", ",", "der", "dampf\u00b7te", "auch", "nicht", "mehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "ADV", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Dem Haus lag etwas auf der Brust,", "tokens": ["Dem", "Haus", "lag", "et\u00b7was", "auf", "der", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da sprach der Vaters: \u00bbHab's gewu\u00dft,", "tokens": ["Da", "sprach", "der", "Va\u00b7ters", ":", "\u00bb", "Hab's", "ge\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Zu selten sieht sie einen Mann,", "tokens": ["Zu", "sel\u00b7ten", "sieht", "sie", "ei\u00b7nen", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gleich verliebt ist sie auch dann.\u00ab", "tokens": ["Und", "gleich", "ver\u00b7liebt", "ist", "sie", "auch", "dann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Die Magd kam: \u00bbAch, sie wacht nicht auf.\u00ab", "tokens": ["Die", "Magd", "kam", ":", "\u00bb", "Ach", ",", "sie", "wacht", "nicht", "auf", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "ITJ", "$,", "PPER", "VVFIN", "PTKNEG", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vater sprach: \u00bbGehn Sie hinauf,", "tokens": ["Der", "Va\u00b7ter", "sprach", ":", "\u00bb", "Gehn", "Sie", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.56": {"line.1": {"text": "Mein Herr, erretten Sie mein Kind,", "tokens": ["Mein", "Herr", ",", "er\u00b7ret\u00b7ten", "Sie", "mein", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da Sie doch ihr Geliebter sind.\u00ab", "tokens": ["Da", "Sie", "doch", "ihr", "Ge\u00b7lieb\u00b7ter", "sind", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Gern menschenfreundlich will ich sein.", "tokens": ["Gern", "men\u00b7schen\u00b7freund\u00b7lich", "will", "ich", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PPER", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Doch ach, mein Herz war nicht mehr mein,", "tokens": ["Doch", "ach", ",", "mein", "Herz", "war", "nicht", "mehr", "mein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Mein Herz, das immer r\u00fcckw\u00e4rts lief,", "tokens": ["Mein", "Herz", ",", "das", "im\u00b7mer", "r\u00fcck\u00b7w\u00e4rts", "lief", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Immer Frau K\u00f6nigin nur rief.", "tokens": ["Im\u00b7mer", "Frau", "K\u00f6\u00b7ni\u00b7gin", "nur", "rief", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "NN", "ADV", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.59": {"line.1": {"text": "Bin darum schleunigst aufgebrochen,", "tokens": ["Bin", "da\u00b7rum", "schleu\u00b7nigst", "auf\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bin morgens in die See gestochen,", "tokens": ["Bin", "mor\u00b7gens", "in", "die", "See", "ge\u00b7sto\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Der Vater hat es sehr beklagt,", "tokens": ["Der", "Va\u00b7ter", "hat", "es", "sehr", "be\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df solch ein Mann wie ich versagt.", "tokens": ["Da\u00df", "solch", "ein", "Mann", "wie", "ich", "ver\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "KOKOM", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}