{"textgrid.poem.67910": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "5. Die Fahrt zur Geliebten", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sonne, wirf den hellesten Stral auf den Orra-See!", "tokens": ["Son\u00b7ne", ",", "wirf", "den", "hel\u00b7les\u00b7ten", "Stral", "auf", "den", "Or\u00b7ra\u00b7See", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVIMP", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Ich m\u00f6chte steigen auf jeden Fichtengipfel,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "stei\u00b7gen", "auf", "je\u00b7den", "Fich\u00b7ten\u00b7gip\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "W\u00fcst' ich nur, ich s\u00e4he den Orra-See.", "tokens": ["W\u00fcst'", "ich", "nur", ",", "ich", "s\u00e4\u00b7he", "den", "Or\u00b7ra\u00b7See", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich stieg' auf ihn und blickte nach meiner Lieben,", "tokens": ["Ich", "stieg'", "auf", "ihn", "und", "blick\u00b7te", "nach", "mei\u00b7ner", "Lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wo unter Blumen sie itzo sey.", "tokens": ["Wo", "un\u00b7ter", "Blu\u00b7men", "sie", "it\u00b7zo", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Ich schnitt' ihm ab die Zweige, die jungen frischen Zweige,", "tokens": ["Ich", "schnitt'", "ihm", "ab", "die", "Zwei\u00b7ge", ",", "die", "jun\u00b7gen", "fri\u00b7schen", "Zwei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Alle Aestchen schnitt' ich ihm ab, die gr\u00fcnen Aestchen. \u2013", "tokens": ["Al\u00b7le", "A\u00b7est\u00b7chen", "schnitt'", "ich", "ihm", "ab", ",", "die", "gr\u00fc\u00b7nen", "A\u00b7est\u00b7chen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PPER", "PTKVZ", "$,", "ART", "ADJA", "NN", "$.", "$("], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}}, "stanza.4": {"line.1": {"text": "H\u00e4tt' ich Fl\u00fcgel, zu dir zu fliegen. Kr\u00e4henfl\u00fcgel,", "tokens": ["H\u00e4tt'", "ich", "Fl\u00fc\u00b7gel", ",", "zu", "dir", "zu", "flie\u00b7gen", ".", "Kr\u00e4\u00b7hen\u00b7fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$,", "APPR", "PPER", "PTKZU", "VVINF", "$.", "NN", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Dem Laufe der Wolken folgt' ich, ziehend zum Orra-See.", "tokens": ["Dem", "Lau\u00b7fe", "der", "Wol\u00b7ken", "folgt'", "ich", ",", "zie\u00b7hend", "zum", "Or\u00b7ra\u00b7See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPER", "$,", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Aber mir fehlen die Fl\u00fcgel, Entenfl\u00fcgel,", "tokens": ["A\u00b7ber", "mir", "feh\u00b7len", "die", "Fl\u00fc\u00b7gel", ",", "En\u00b7ten\u00b7fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "F\u00fcsse, rudernde F\u00fcsse der G\u00e4nse, die hin mich tr\u00fcgen zu dir.", "tokens": ["F\u00fcs\u00b7se", ",", "ru\u00b7dern\u00b7de", "F\u00fcs\u00b7se", "der", "G\u00e4n\u00b7se", ",", "die", "hin", "mich", "tr\u00fc\u00b7gen", "zu", "dir", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "ART", "NN", "$,", "PRELS", "ADV", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "+-+--+--+--+-+--+", "measure": "trochaic.septa.relaxed"}}, "stanza.6": {"line.1": {"text": "Lange gnug hast du gewartet, so viel Tage,", "tokens": ["Lan\u00b7ge", "gnug", "hast", "du", "ge\u00b7war\u00b7tet", ",", "so", "viel", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "VVPP", "$,", "ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Deine sch\u00f6nsten Tage,", "tokens": ["Dei\u00b7ne", "sch\u00f6ns\u00b7ten", "Ta\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mit deinen lieblichen Augen, mit deinem freundlichen Herzen.", "tokens": ["Mit", "dei\u00b7nen", "lieb\u00b7li\u00b7chen", "Au\u00b7gen", ",", "mit", "dei\u00b7nem", "freund\u00b7li\u00b7chen", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Und wolltest du mir auch weit entfliehn,", "tokens": ["Und", "woll\u00b7test", "du", "mir", "auch", "weit", "ent\u00b7fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPER", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich holte dich schnell ein.", "tokens": ["Ich", "hol\u00b7te", "dich", "schnell", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Was ist st\u00e4rker und fester als Eisenketten, als gewundne Flechten,", "tokens": ["Was", "ist", "st\u00e4r\u00b7ker", "und", "fes\u00b7ter", "als", "Ei\u00b7sen\u00b7ket\u00b7ten", ",", "als", "ge\u00b7wund\u00b7ne", "Flech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "KON", "ADJD", "KOKOM", "NN", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "--+--+--+-+-+-+-+-", "measure": "anapaest.tri.plus"}, "line.2": {"text": "So flicht die Lieb' uns unsern Sinn um,", "tokens": ["So", "flicht", "die", "Lieb'", "uns", "un\u00b7sern", "Sinn", "um", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und \u00e4ndert Will' und Gedanken.", "tokens": ["Und", "\u00e4n\u00b7dert", "Will'", "und", "Ge\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Knabenwille ist Windeswille,", "tokens": ["Kna\u00b7ben\u00b7wil\u00b7le", "ist", "Win\u00b7des\u00b7wil\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "J\u00fcnglings Gedanken lange Gedanken.", "tokens": ["J\u00fcng\u00b7lings", "Ge\u00b7dan\u00b7ken", "lan\u00b7ge", "Ge\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJA", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Wollt' ich alle sie h\u00f6ren, alle \u2013", "tokens": ["Wollt'", "ich", "al\u00b7le", "sie", "h\u00f6\u00b7ren", ",", "al\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "PPER", "PIS", "PPER", "VVINF", "$,", "PIAT", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ich irrte ab vom Wege, dem rechten Wege.", "tokens": ["Ich", "irr\u00b7te", "ab", "vom", "We\u00b7ge", ",", "dem", "rech\u00b7ten", "We\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPRART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "Einen Schlu\u00df hab' ich, dem will ich folgen,", "tokens": ["Ei\u00b7nen", "Schlu\u00df", "hab'", "ich", ",", "dem", "will", "ich", "fol\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "So wei\u00df ich, ich finde den rechten Weg.", "tokens": ["So", "wei\u00df", "ich", ",", "ich", "fin\u00b7de", "den", "rech\u00b7ten", "Weg", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}}}}