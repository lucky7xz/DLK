{"textgrid.poem.53387": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Jerusalem du sch\u00f6ne Stadt", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jerusalem du sch\u00f6ne Stadt", "tokens": ["Je\u00b7ru\u00b7sa\u00b7lem", "du", "sch\u00f6\u00b7ne", "Stadt"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wahres Frewden-Leben,", "tokens": ["Vnd", "wah\u00b7res", "Fre\u00b7wden\u00b7Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die der Mann vor gesehen hat", "tokens": ["Die", "der", "Mann", "vor", "ge\u00b7se\u00b7hen", "hat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "VVPP", "VAFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Hoch in den L\u00fcfften schweben,", "tokens": ["Hoch", "in", "den", "L\u00fcff\u00b7ten", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Den Patmos und die w\u00fcste See", "tokens": ["Den", "Pat\u00b7mos", "und", "die", "w\u00fcs\u00b7te", "See"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gef\u00e4nglich hielt' \u00fcmbschlossen,", "tokens": ["Ge\u00b7f\u00e4ng\u00b7lich", "hielt'", "\u00fcmb\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als Sathan alles \u00e4rgste Weh", "tokens": ["Als", "Sa\u00b7than", "al\u00b7les", "\u00e4rgs\u00b7te", "Weh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bracht' auff die Christgenossen,", "tokens": ["Bracht'", "auff", "die", "Christ\u00b7ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Du Wohnhaus solcher Herrligkeit", "tokens": ["Du", "Wohn\u00b7haus", "sol\u00b7cher", "Herr\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "NN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die weder uns zu Sinnen", "tokens": ["Die", "we\u00b7der", "uns", "zu", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KON", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mag kommen noch in diese Zeit,", "tokens": ["Mag", "kom\u00b7men", "noch", "in", "die\u00b7se", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott wohnt bey dir darinnen.", "tokens": ["Gott", "wohnt", "bey", "dir", "da\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der ist dein ewig-helles Liecht,", "tokens": ["Der", "ist", "dein", "e\u00b7wig\u00b7hel\u00b7les", "Liecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von dem du Glantz gewonnen,", "tokens": ["Von", "dem", "du", "Glantz", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dar\u00fcmb darffst du des scheines nicht", "tokens": ["Da\u00b7r\u00fcmb", "darffst", "du", "des", "schei\u00b7nes", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART", "ADJA", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des Mondes noch der Sonnen.", "tokens": ["Des", "Mon\u00b7des", "noch", "der", "Son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das Gold mu\u00df uns das h\u00f6chste seyn,", "tokens": ["Das", "Gold", "mu\u00df", "uns", "das", "h\u00f6chs\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dir wil es unwehrt fallen,", "tokens": ["Dir", "wil", "es", "un\u00b7wehrt", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Th\u00f6r in dir sind Edelstein,", "tokens": ["Die", "Th\u00f6r", "in", "dir", "sind", "E\u00b7del\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Gassen sind Cristallen.", "tokens": ["Die", "Gas\u00b7sen", "sind", "Cris\u00b7tal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Kein Brand, kein Frost beleidigt dich,", "tokens": ["Kein", "Brand", ",", "kein", "Frost", "be\u00b7lei\u00b7digt", "dich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Mangel kan dich irren,", "tokens": ["Kein", "Man\u00b7gel", "kan", "dich", "ir\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "In dir regt keine Mi\u00dfgunst sich,", "tokens": ["In", "dir", "regt", "kei\u00b7ne", "Mi\u00df\u00b7gunst", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PIAT", "NN", "PRF", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Kein Leid kan dich verwirren.", "tokens": ["Kein", "Leid", "kan", "dich", "ver\u00b7wir\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Du nimmst allein die Vnschuld an,", "tokens": ["Du", "nimmst", "al\u00b7lein", "die", "Vn\u00b7schuld", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd kennst allein die Frommen,", "tokens": ["Vnd", "kennst", "al\u00b7lein", "die", "From\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was hie nicht S\u00fcnde lassen kan", "tokens": ["Was", "hie", "nicht", "S\u00fcn\u00b7de", "las\u00b7sen", "kan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PTKNEG", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das thar in dich nicht kommen.", "tokens": ["Das", "thar", "in", "dich", "nicht", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Vnd was hie stets auff Rosen geht,", "tokens": ["Vnd", "was", "hie", "stets", "auff", "Ro\u00b7sen", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Hochmuht ist ergeben,", "tokens": ["Dem", "Hoch\u00b7muht", "ist", "er\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht nach den wahren G\u00fctern steht,", "tokens": ["Nicht", "nach", "den", "wah\u00b7ren", "G\u00fc\u00b7tern", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das wird in dir nicht leben.", "tokens": ["Das", "wird", "in", "dir", "nicht", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Denn die vertr\u00e4get nicht dein Hau\u00df", "tokens": ["Denn", "die", "ver\u00b7tr\u00e4\u00b7get", "nicht", "dein", "Hau\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVFIN", "PTKNEG", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die hie zu Gott nicht eilen,", "tokens": ["Die", "hie", "zu", "Gott", "nicht", "ei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Hunde st\u00f6\u00dft man dort hinaus,", "tokens": ["Die", "Hun\u00b7de", "st\u00f6\u00dft", "man", "dort", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "APZR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Woselbst sie ewig heulen.", "tokens": ["Wo\u00b7selbst", "sie", "e\u00b7wig", "heu\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Du h\u00e4ltest unsre L\u00fcst' im Zaum", "tokens": ["Du", "h\u00e4l\u00b7test", "uns\u00b7re", "L\u00fcst'", "im", "Zaum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beschneidst uns an den Sinnen,", "tokens": ["Be\u00b7schneidst", "uns", "an", "den", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df die Begierden wenig raum", "tokens": ["Da\u00df", "die", "Be\u00b7gier\u00b7den", "we\u00b7nig", "raum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Allhie bey uns gewinnen,", "tokens": ["A\u00b7llhie", "bey", "uns", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da\u00df wir der schn\u00f6den S\u00fcndensucht", "tokens": ["Da\u00df", "wir", "der", "schn\u00f6\u00b7den", "S\u00fcn\u00b7den\u00b7sucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Erden uns entziehen,", "tokens": ["Der", "Er\u00b7den", "uns", "ent\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd durch des Fleisches strenge Zucht", "tokens": ["Vnd", "durch", "des", "Flei\u00b7sches", "stren\u00b7ge", "Zucht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hinauff begierig fliehen.", "tokens": ["Hin\u00b7auff", "be\u00b7gie\u00b7rig", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "Ertragen frewdig Armuht, Noht,", "tokens": ["Er\u00b7tra\u00b7gen", "frew\u00b7dig", "Ar\u00b7muht", ",", "Noht", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ADJD", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In die Gedult uns h\u00fcllen,", "tokens": ["In", "die", "Ge\u00b7dult", "uns", "h\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd standhafft seyn bi\u00df in den Todt,", "tokens": ["Vnd", "stand\u00b7hafft", "seyn", "bi\u00df", "in", "den", "Todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die\u00df ist \u00fcmb deinet willen.", "tokens": ["Die\u00df", "ist", "\u00fcmb", "dei\u00b7net", "wil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Schaw was f\u00fcr eine Seele wir", "tokens": ["Schaw", "was", "f\u00fcr", "ei\u00b7ne", "See\u00b7le", "wir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PRELS", "APPR", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus diesem Leben senden,", "tokens": ["Aus", "die\u00b7sem", "Le\u00b7ben", "sen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Sinn und Hoffnung war nach dir,", "tokens": ["Ihr", "Sinn", "und", "Hoff\u00b7nung", "war", "nach", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd selig anzul\u00e4nden.", "tokens": ["Vnd", "se\u00b7lig", "an\u00b7zu\u00b7l\u00e4n\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Sie k\u00f6mpt von hier aus grosser Quaal", "tokens": ["Sie", "k\u00f6mpt", "von", "hier", "aus", "gros\u00b7ser", "Qua\u00b7al"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd wie aus schweren Banden,", "tokens": ["Vnd", "wie", "aus", "schwe\u00b7ren", "Ban\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat manchen Drang in diesem Thal", "tokens": ["Hat", "man\u00b7chen", "Drang", "in", "die\u00b7sem", "Thal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIAT", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Thr\u00e4nen au\u00dfgestanden.", "tokens": ["Der", "Thr\u00e4\u00b7nen", "au\u00df\u00b7ge\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Kein reiner Schnee wird also weis", "tokens": ["Kein", "rei\u00b7ner", "Schnee", "wird", "al\u00b7so", "weis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als zwar ihr Kleid befunden,", "tokens": ["Als", "zwar", "ihr", "Kleid", "be\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das r\u00fchret von dem rohten Schwei\u00df", "tokens": ["Das", "r\u00fch\u00b7ret", "von", "dem", "roh\u00b7ten", "Schwei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd von des Lammes Wunden:", "tokens": ["Vnd", "von", "des", "Lam\u00b7mes", "Wun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "In welchen sie es hell gemacht,", "tokens": ["In", "wel\u00b7chen", "sie", "es", "hell", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPER", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein purpurrohtes Leiden", "tokens": ["Sein", "pur\u00b7pur\u00b7roh\u00b7tes", "Lei\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ist ihre K\u00f6nigliche Tracht,", "tokens": ["Ist", "ih\u00b7re", "K\u00f6\u00b7nig\u00b7li\u00b7che", "Tracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst kennt sie keine Seiden.", "tokens": ["Sonst", "kennt", "sie", "kei\u00b7ne", "Sei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Sie floh' hie f\u00fcr der S\u00fcnden Pfuel,", "tokens": ["Sie", "floh'", "hie", "f\u00fcr", "der", "S\u00fcn\u00b7den", "Pfu\u00b7el", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat allzeit liecht geschienen,", "tokens": ["Hat", "all\u00b7zeit", "liecht", "ge\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Jtzt sucht sie Gott vor seinem Stuel", "tokens": ["Jtzt", "sucht", "sie", "Gott", "vor", "sei\u00b7nem", "Stu\u00b7el"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ohn unterla\u00df zu dienen.", "tokens": ["Ohn", "un\u00b7ter\u00b7la\u00df", "zu", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Nimm sie geneigt und freundlich an,", "tokens": ["Nimm", "sie", "ge\u00b7neigt", "und", "freund\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "VVPP", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was Menschen hie beleiden", "tokens": ["Was", "Men\u00b7schen", "hie", "be\u00b7lei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "NN", "ADV", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd K\u00fcmmerni\u00df erwecken kan", "tokens": ["Vnd", "K\u00fcm\u00b7mer\u00b7ni\u00df", "er\u00b7we\u00b7cken", "kan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "M\u00fcss' ewig von ihr scheiden.", "tokens": ["M\u00fcss'", "e\u00b7wig", "von", "ihr", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Der auff dem Stuel sitzt liebe sie,", "tokens": ["Der", "auff", "dem", "Stu\u00b7el", "sitzt", "lie\u00b7be", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "VVFIN", "PPER", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sey ihre Hut und Pflege,", "tokens": ["Sey", "ih\u00b7re", "Hut", "und", "Pfle\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df kein Verdru\u00df und keine M\u00fch", "tokens": ["Da\u00df", "kein", "Ver\u00b7dru\u00df", "und", "kei\u00b7ne", "M\u00fch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich irgends \u00fcmb sie rege.", "tokens": ["Sich", "ir\u00b7gends", "\u00fcmb", "sie", "re\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Das Lamm im Stuel nehm' ihrer war", "tokens": ["Das", "Lamm", "im", "Stu\u00b7el", "nehm'", "ih\u00b7rer", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PPER", "VAFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vnd weide sie f\u00fcr allen,", "tokens": ["Vnd", "wei\u00b7de", "sie", "f\u00fcr", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PIAT", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df keine Tr\u00fcbsal und Gefahr", "tokens": ["Da\u00df", "kei\u00b7ne", "Tr\u00fcb\u00b7sal", "und", "Ge\u00b7fahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "M\u00f6g' ewig auff sie fallen.", "tokens": ["M\u00f6g'", "e\u00b7wig", "auff", "sie", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Er wolle Leben, Geist und Liecht", "tokens": ["Er", "wol\u00b7le", "Le\u00b7ben", ",", "Geist", "und", "Liecht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu trincken sie gewehnen,", "tokens": ["Zu", "trin\u00b7cken", "sie", "ge\u00b7weh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd Gott wisch' ab jhr vom Gesicht", "tokens": ["Vnd", "Gott", "wisch'", "ab", "jhr", "vom", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "APPR", "PPER", "APPRART", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Den Vnmuht aller Thr\u00e4nen.", "tokens": ["Den", "Vn\u00b7muht", "al\u00b7ler", "Thr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Vnd irr' ich, oder hat sie schon", "tokens": ["Vnd", "irr'", "ich", ",", "o\u00b7der", "hat", "sie", "schon"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KON", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wornach sie trug verlangen?", "tokens": ["Wor\u00b7nach", "sie", "trug", "ver\u00b7lan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich sehe sie vor Gottes Thron", "tokens": ["Ich", "se\u00b7he", "sie", "vor", "Got\u00b7tes", "Thron"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was sie gew\u00fcnscht empfangen.", "tokens": ["Was", "sie", "ge\u00b7w\u00fcnscht", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Weg ist ihr Schmertz, weg ihre Pein,", "tokens": ["Weg", "ist", "ihr", "Schmertz", ",", "weg", "ih\u00b7re", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weg ihrer Kranckheit Plagen,", "tokens": ["Weg", "ih\u00b7rer", "Kran\u00b7ck\u00b7heit", "Pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Der sie must' unterw\u00fcrffig seyn", "tokens": ["Der", "sie", "must'", "un\u00b7ter\u00b7w\u00fcrf\u00b7fig", "seyn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VMFIN", "ADJD", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In ihren Lebens-Tagen.", "tokens": ["In", "ih\u00b7ren", "Le\u00b7bens\u00b7Ta\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Sie weis von keiner Arbeit Last,", "tokens": ["Sie", "weis", "von", "kei\u00b7ner", "Ar\u00b7beit", "Last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "APPR", "PIAT", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vergn\u00fcgung, Frewde, St\u00e4rcke,", "tokens": ["Ver\u00b7gn\u00fc\u00b7gung", ",", "Frew\u00b7de", ",", "St\u00e4r\u00b7cke", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Heil, Leben, Danck sampt Fried und Rast", "tokens": ["Heil", ",", "Le\u00b7ben", ",", "Danck", "sampt", "Fried", "und", "Rast"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sind ewig ihre Wercke.", "tokens": ["Sind", "e\u00b7wig", "ih\u00b7re", "Wer\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Herr Fischer, diese Seligkeit", "tokens": ["Herr", "Fi\u00b7scher", ",", "die\u00b7se", "Se\u00b7lig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NE", "$,", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ertragt als Christen sollen,", "tokens": ["Er\u00b7tragt", "als", "Chris\u00b7ten", "sol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "NN", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die\u00df w\u00e4r' ein unerh\u00f6rter Neid", "tokens": ["Die\u00df", "w\u00e4r'", "ein", "un\u00b7er\u00b7h\u00f6r\u00b7ter", "Neid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ihr mi\u00dfg\u00f6nnen wollen.", "tokens": ["Sie", "ihr", "mi\u00df\u00b7g\u00f6n\u00b7nen", "wol\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "VVINF", "VMINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Sonst g\u00f6nnt ihr jedermann sein Gl\u00fcck,", "tokens": ["Sonst", "g\u00f6nnt", "ihr", "je\u00b7der\u00b7mann", "sein", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ja habt daran ergetzen,", "tokens": ["Ja", "habt", "da\u00b7ran", "er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PAV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So da\u00df ich euch in diesem St\u00fcck", "tokens": ["So", "da\u00df", "ich", "euch", "in", "die\u00b7sem", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PRF", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weis wenig vor zu setzen.", "tokens": ["Weis", "we\u00b7nig", "vor", "zu", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wie manchem bietet ihr die Hand,", "tokens": ["Wie", "man\u00b7chem", "bie\u00b7tet", "ihr", "die", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er ein Mann kan bleiben,", "tokens": ["Da\u00df", "er", "ein", "Mann", "kan", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vnd gr\u00fcndet also seinen Stand", "tokens": ["Vnd", "gr\u00fcn\u00b7det", "al\u00b7so", "sei\u00b7nen", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenig werden gl\u00e4uben.", "tokens": ["Als", "we\u00b7nig", "wer\u00b7den", "gl\u00e4u\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Ihr sch\u00e4tzt es auch f\u00fcr ewre Pflicht", "tokens": ["Ihr", "sch\u00e4tzt", "es", "auch", "f\u00fcr", "ew\u00b7re", "Pflicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Musen bey zu springen,", "tokens": ["Den", "Mu\u00b7sen", "bey", "zu", "sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn hievon geben viel bericht", "tokens": ["Denn", "hie\u00b7von", "ge\u00b7ben", "viel", "be\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd Kisch f\u00fcr allen dingen.", "tokens": ["Vnd", "Kisch", "f\u00fcr", "al\u00b7len", "din\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Jtzt woltet ihr ein Vnhold seyn,", "tokens": ["Jtzt", "wol\u00b7tet", "ihr", "ein", "Vn\u00b7hold", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd ewre Liebste neiden", "tokens": ["Vnd", "ew\u00b7re", "Liebs\u00b7te", "nei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df ihr ein selig St\u00fcndelein", "tokens": ["Da\u00df", "ihr", "ein", "se\u00b7lig", "St\u00fcn\u00b7del\u00b7ein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJD", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Geendet alles Leiden?", "tokens": ["Ge\u00b7en\u00b7det", "al\u00b7les", "Lei\u00b7den", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Thut wie ihr angefangen habt,", "tokens": ["Thut", "wie", "ihr", "an\u00b7ge\u00b7fan\u00b7gen", "habt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PWAV", "PPER", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Strewt aus mit reichen H\u00e4nden,", "tokens": ["Strewt", "aus", "mit", "rei\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Kunst werd' also fort begabt,", "tokens": ["Die", "Kunst", "werd'", "al\u00b7so", "fort", "be\u00b7gabt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lasst ewren Sinn nicht wenden.", "tokens": ["Lasst", "ew\u00b7ren", "Sinn", "nicht", "wen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Wer Armuht f\u00fchlt, der m\u00fcsse nicht", "tokens": ["Wer", "Ar\u00b7muht", "f\u00fchlt", ",", "der", "m\u00fcs\u00b7se", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "NN", "VVFIN", "$,", "PRELS", "VMFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr ewren Augen weinen,", "tokens": ["F\u00fcr", "ew\u00b7ren", "Au\u00b7gen", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nein, sondern lasset ewer Licht", "tokens": ["Nein", ",", "son\u00b7dern", "las\u00b7set", "e\u00b7wer", "Licht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcr allen Menschen scheinen.", "tokens": ["F\u00fcr", "al\u00b7len", "Men\u00b7schen", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "So werdet ihr zu seiner Zeit,", "tokens": ["So", "wer\u00b7det", "ihr", "zu", "sei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Satt dieser eiteln Erden,", "tokens": ["Satt", "die\u00b7ser", "ei\u00b7teln", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr in der ewign Herrligkeit", "tokens": ["Ihr", "in", "der", "e\u00b7wign", "Herr\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dort beygesellet werden.", "tokens": ["Dort", "bey\u00b7ge\u00b7sel\u00b7let", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Vnd s\u00e4etet ihr hie F\u00fcrsten gleich,", "tokens": ["Vnd", "s\u00e4e\u00b7tet", "ihr", "hie", "F\u00fcrs\u00b7ten", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch sind es schn\u00f6de Gaben,", "tokens": ["Doch", "sind", "es", "schn\u00f6\u00b7de", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dort sollet ihr das Himmel-reich", "tokens": ["Dort", "sol\u00b7let", "ihr", "das", "Him\u00b7mel\u00b7reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Daf\u00fcr zu erndten haben.", "tokens": ["Da\u00b7f\u00fcr", "zu", "ernd\u00b7ten", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}