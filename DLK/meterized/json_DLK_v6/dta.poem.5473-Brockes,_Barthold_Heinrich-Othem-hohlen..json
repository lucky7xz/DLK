{"dta.poem.5473": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Othem-hohlen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Mein GOtt, ich habe lang auf dieser Welt gelebet,", "tokens": ["Mein", "Gott", ",", "ich", "ha\u00b7be", "lang", "auf", "die\u00b7ser", "Welt", "ge\u00b7le\u00b7bet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VAFIN", "ADJD", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich hab\u2019 auch in der Welt auf deiner Wercke", "tokens": ["Ich", "hab'", "auch", "in", "der", "Welt", "auf", "dei\u00b7ner", "Wer\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Freuden dann und wann gedacht,", "tokens": ["Mit", "Freu\u00b7den", "dann", "und", "wann", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "KON", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und, in Verwunderung, dich zu erh\u00f6hn gestrebet;", "tokens": ["Und", ",", "in", "Ver\u00b7wun\u00b7de\u00b7rung", ",", "dich", "zu", "er\u00b7h\u00f6hn", "ge\u00b7stre\u00b7bet", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "NN", "$,", "PPER", "PTKZU", "VVINF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein", "tokens": ["Al\u00b7lein"], "token_info": ["word"], "pos": ["ADV"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Wie hab ich doch so unempfindlich, ja", "tokens": ["Wie", "hab", "ich", "doch", "so", "un\u00b7emp\u00b7find\u00b7lich", ",", "ja"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Unf\u00fchl- und folglich auch undanckbar k\u00f6nnen seyn,", "tokens": ["Un\u00b7f\u00fchl", "und", "folg\u00b7lich", "auch", "un\u00b7dan\u00b7ck\u00b7bar", "k\u00f6n\u00b7nen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "ADV", "ADV", "ADJD", "VMFIN", "VAINF", "$,"], "meter": "+--+--++--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "F\u00fcr eins, das, da ichs jetzt bemercke,", "tokens": ["F\u00fcr", "eins", ",", "das", ",", "da", "ichs", "jetzt", "be\u00b7mer\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PDS", "$,", "KOUS", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Der allergr\u00f6sten Wunder-Wercke", "tokens": ["Der", "al\u00b7ler\u00b7gr\u00f6s\u00b7ten", "Wun\u00b7der\u00b7\u00b7Wer\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ohn allen Zweifel eins. Es ist mir die\u00df so nah,", "tokens": ["Ohn", "al\u00b7len", "Zwei\u00b7fel", "eins", ".", "Es", "ist", "mir", "die\u00df", "so", "nah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PIS", "$.", "PPER", "VAFIN", "PPER", "PDS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Als sonst fast keines ist,", "tokens": ["Als", "sonst", "fast", "kei\u00b7nes", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIS", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Es wird kein Augenblick", "tokens": ["Es", "wird", "kein", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Von mir zur\u00fcck geleget,", "tokens": ["Von", "mir", "zu\u00b7r\u00fcck", "ge\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Da\u00df es nicht meine gantze Brust,", "tokens": ["Da\u00df", "es", "nicht", "mei\u00b7ne", "gant\u00b7ze", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und zwar zugleich voll Nutz und Lust,", "tokens": ["Und", "zwar", "zu\u00b7gleich", "voll", "Nutz", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit einer sanften Macht beweget.", "tokens": ["Mit", "ei\u00b7ner", "sanf\u00b7ten", "Macht", "be\u00b7we\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Mein Leben selbst besteht in diesem Wunder blo\u00df;", "tokens": ["Mein", "Le\u00b7ben", "selbst", "be\u00b7steht", "in", "die\u00b7sem", "Wun\u00b7der", "blo\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "APPR", "PDAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Je mehr es mich betrift, je \u00f6fter ich es brauche,", "tokens": ["Je", "mehr", "es", "mich", "be\u00b7trift", ",", "je", "\u00f6f\u00b7ter", "ich", "es", "brau\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PRF", "VVFIN", "$,", "ADV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wenn ich den Othem zieh\u2019 und stets ihn von mir hauche.", "tokens": ["Wenn", "ich", "den", "O\u00b7them", "zieh'", "und", "stets", "ihn", "von", "mir", "hau\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "KON", "VVFIN", "PPER", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Je mehr es wunderbar und gro\u00df:", "tokens": ["Je", "mehr", "es", "wun\u00b7der\u00b7bar", "und", "gro\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Je mehr und \u00f6fter sollt\u2019 auch ich daran gedencken,", "tokens": ["Je", "mehr", "und", "\u00f6f\u00b7ter", "sollt'", "auch", "ich", "da\u00b7ran", "ge\u00b7den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADV", "VMFIN", "ADV", "PPER", "PAV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und dem, der es mich w\u00fcrdigt, mir zu schencken,", "tokens": ["Und", "dem", ",", "der", "es", "mich", "w\u00fcr\u00b7digt", ",", "mir", "zu", "schen\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "PPER", "PRF", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Und der es mir erh\u00e4lt, mit recht ger\u00fchrter Seelen,", "tokens": ["Und", "der", "es", "mir", "er\u00b7h\u00e4lt", ",", "mit", "recht", "ge\u00b7r\u00fchr\u00b7ter", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "PPER", "VVFIN", "$,", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Lobsingen, ihn erh\u00f6hn, und auf besondre Weise,", "tokens": ["Lob\u00b7sin\u00b7gen", ",", "ihn", "er\u00b7h\u00f6hn", ",", "und", "auf", "be\u00b7sond\u00b7re", "Wei\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVINF", "$,", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Zu seiner Weisheit, Lieb\u2019 und Allmacht Preise,", "tokens": ["Zu", "sei\u00b7ner", "Weis\u00b7heit", ",", "Lieb'", "und", "All\u00b7macht", "Prei\u00b7se", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Der Wunder Meng\u2019 und Gr\u00f6\u00df\u2019 erwegen und erzehlen.", "tokens": ["Der", "Wun\u00b7der", "Meng'", "und", "Gr\u00f6\u00df'", "er\u00b7we\u00b7gen", "und", "er\u00b7zeh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "KON", "NN", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es ist zwar unsers C\u00f6rpers Bau,", "tokens": ["Es", "ist", "zwar", "un\u00b7sers", "C\u00f6r\u00b7pers", "Bau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und alles, was ich an ihm schan,", "tokens": ["Und", "al\u00b7les", ",", "was", "ich", "an", "ihm", "schan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "APPR", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erstaunens-w\u00fcrdig, wunderbar;", "tokens": ["Er\u00b7stau\u00b7nens\u00b7w\u00fcr\u00b7dig", ",", "wun\u00b7der\u00b7bar", ";"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch welcher Kiel und welche Zunge", "tokens": ["Doch", "wel\u00b7cher", "Kiel", "und", "wel\u00b7che", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "KON", "PWAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist, die das Wunder-Werck der Lunge", "tokens": ["Ist", ",", "die", "das", "Wun\u00b7der\u00b7\u00b7Werck", "der", "Lun\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "PRELS", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auf eine solche Art besunge,", "tokens": ["Auf", "ei\u00b7ne", "sol\u00b7che", "Art", "be\u00b7sun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wie es die W\u00fcrdigkeit, wie es derselben Wehrt", "tokens": ["Wie", "es", "die", "W\u00fcr\u00b7dig\u00b7keit", ",", "wie", "es", "der\u00b7sel\u00b7ben", "Wehrt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "$,", "PWAV", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erfodert und begehrt:", "tokens": ["Er\u00b7fo\u00b7dert", "und", "be\u00b7gehrt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Jhr Wesen, ihre Lag\u2019, ihr Ampt, ihr Nutz, den wir", "tokens": ["Ihr", "We\u00b7sen", ",", "ih\u00b7re", "Lag'", ",", "ihr", "Ampt", ",", "ihr", "Nutz", ",", "den", "wir"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In unserm C\u00f6rper stets von ihr", "tokens": ["In", "un\u00b7serm", "C\u00f6r\u00b7per", "stets", "von", "ihr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Empfinden k\u00f6nnen und versp\u00fchren,", "tokens": ["Emp\u00b7fin\u00b7den", "k\u00f6n\u00b7nen", "und", "ver\u00b7sp\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mu\u00df uns zu n\u00e4herer Betrachtung billig f\u00fchren.", "tokens": ["Mu\u00df", "uns", "zu", "n\u00e4\u00b7he\u00b7rer", "Be\u00b7trach\u00b7tung", "bil\u00b7lig", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer das k\u00fcnstliche Gew\u00e4chs unsrer Lungen recht", "tokens": ["Wer", "das", "k\u00fcnst\u00b7li\u00b7che", "Ge\u00b7w\u00e4chs", "uns\u00b7rer", "Lun\u00b7gen", "recht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN", "PPOSAT", "NN", "ADJD"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Wird, wo er ein Mensch, sich wundern, wie es zube-", "tokens": ["Wird", ",", "wo", "er", "ein", "Mensch", ",", "sich", "wun\u00b7dern", ",", "wie", "es", "zu\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "PWAV", "PPER", "ART", "NN", "$,", "PRF", "VVINF", "$,", "PWAV", "PPER", "TRUNC"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Aus viel tausend kleinen Blasen, die geschickt sind Luft zu", "tokens": ["Aus", "viel", "tau\u00b7send", "klei\u00b7nen", "Bla\u00b7sen", ",", "die", "ge\u00b7schickt", "sind", "Luft", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "CARD", "ADJA", "NN", "$,", "PRELS", "VVPP", "VAFIN", "NN", "PTKZU"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.4": {"text": "Und sich von derselben willig aus einander dehnen lassen,", "tokens": ["Und", "sich", "von", "der\u00b7sel\u00b7ben", "wil\u00b7lig", "aus", "ein\u00b7an\u00b7der", "deh\u00b7nen", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PDAT", "ADJD", "APPR", "PRF", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.5": {"text": "Aber die, wenn jene weicht, alsbald sich zusammen ziehn,", "tokens": ["A\u00b7ber", "die", ",", "wenn", "je\u00b7ne", "weicht", ",", "als\u00b7bald", "sich", "zu\u00b7sam\u00b7men", "ziehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "KOUS", "PDS", "VVFIN", "$,", "KOUS", "PRF", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+--+-+", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Ist ihr Wesen zugericht! und die Luft-R\u00f6hr\u2019 liegt in ihr", "tokens": ["Ist", "ihr", "We\u00b7sen", "zu\u00b7ge\u00b7richt", "!", "und", "die", "Luft\u00b7R\u00f6hr'", "liegt", "in", "ihr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "VVPP", "$.", "KON", "ART", "NN", "VVFIN", "APPR", "PPOSAT"], "meter": "+-+-+-+--++-++", "measure": "trochaic.octa.plus.relaxed"}, "line.7": {"text": "Wunderbarlich eingesenckt,", "tokens": ["Wun\u00b7der\u00b7bar\u00b7lich", "ein\u00b7ge\u00b7senckt", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und zuerst mit grossen Adern = = = aber, was beschreib ich hier?", "tokens": ["Und", "zu\u00b7erst", "mit", "gros\u00b7sen", "A\u00b7dern", "=", "=", "=", "a\u00b7ber", ",", "was", "be\u00b7schreib", "ich", "hier", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "XY", "XY", "XY", "ADV", "$,", "PWS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}, "line.9": {"text": "Weil man es unm\u00f6glich besser, als es ", "tokens": ["Weil", "man", "es", "un\u00b7m\u00f6g\u00b7lich", "bes\u00b7ser", ",", "als", "es"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "ADJD", "ADJD", "$,", "KOUS", "PPER"], "meter": "+---+-+-+-", "measure": "dactylic.init"}, "line.10": {"text": "Abzubilden f\u00e4hig ist, und sie besser schildern kann,", "tokens": ["Ab\u00b7zu\u00b7bil\u00b7den", "f\u00e4\u00b7hig", "ist", ",", "und", "sie", "bes\u00b7ser", "schil\u00b7dern", "kann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VAFIN", "$,", "KON", "PPER", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.11": {"text": "F\u00fchr\u2019 ich diese sch\u00f6ne Stelle, aus desselben Schriften an:", "tokens": ["F\u00fchr'", "ich", "die\u00b7se", "sch\u00f6\u00b7ne", "Stel\u00b7le", ",", "aus", "des\u00b7sel\u00b7ben", "Schrif\u00b7ten", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PDAT", "ADJA", "NN", "$,", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+-+-+-+-+", "measure": "trochaic.octa.plus"}}, "stanza.5": {"line.1": {"text": "\u201enunmehr auch zu dem andern Theile,", "tokens": ["\u201e", "nun\u00b7mehr", "auch", "zu", "dem", "an\u00b7dern", "Thei\u00b7le", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eder sanft ums Hertz herumgelegt,", "tokens": ["\u201e", "der", "sanft", "ums", "Hertz", "her\u00b7um\u00b7ge\u00b7legt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJD", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eund, zu des C\u00f6rpers gr\u00f6stem Heile,", "tokens": ["\u201e", "und", ",", "zu", "des", "C\u00f6r\u00b7pers", "gr\u00f6s\u00b7tem", "Hei\u00b7le", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "$,", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201esich, wie dasselbe, stets bewegt!", "tokens": ["\u201e", "sich", ",", "wie", "das\u00b7sel\u00b7be", ",", "stets", "be\u00b7wegt", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PRF", "$,", "PWAV", "PDAT", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u201edie Lungen sinds, die wir verstehen,", "tokens": ["\u201e", "die", "Lun\u00b7gen", "sinds", ",", "die", "wir", "ver\u00b7ste\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u201edie immer auf- und niedergehen,", "tokens": ["\u201e", "die", "im\u00b7mer", "auf", "und", "nie\u00b7der\u00b7ge\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADV", "TRUNC", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u201eund, durch die\u00df stetige Bem\u00fchn,", "tokens": ["\u201e", "und", ",", "durch", "die\u00df", "ste\u00b7ti\u00b7ge", "Be\u00b7m\u00fchn", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "$,", "APPR", "PDS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u201ebest\u00e4ndig frischen Othem ziehn.", "tokens": ["\u201e", "be\u00b7st\u00e4n\u00b7dig", "fri\u00b7schen", "O\u00b7them", "ziehn", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "\u201esie, gleichend einem Huf der Pferde,", "tokens": ["\u201e", "sie", ",", "glei\u00b7chend", "ei\u00b7nem", "Huf", "der", "Pfer\u00b7de", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "ADJD", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edoch mehr noch einer Klau der Kuh,", "tokens": ["\u201e", "doch", "mehr", "noch", "ei\u00b7ner", "Klau", "der", "Kuh", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eweh\u2019n, als ein Blasebalg, dem Heerde", "tokens": ["\u201e", "weh'n", ",", "als", "ein", "Bla\u00b7se\u00b7balg", ",", "dem", "Heer\u00b7de"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVINF", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edes Hertzens Luft und Nahrung zu.", "tokens": ["\u201e", "des", "Hert\u00b7zens", "Luft", "und", "Nah\u00b7rung", "zu", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u201edoch, da sie diesen Zweck erzielen,", "tokens": ["\u201e", "doch", ",", "da", "sie", "die\u00b7sen", "Zweck", "er\u00b7zie\u00b7len", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "KOUS", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eso pflegen sie zugleich zu k\u00fchlen;", "tokens": ["\u201e", "so", "pfle\u00b7gen", "sie", "zu\u00b7gleich", "zu", "k\u00fch\u00b7len", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u201egleich wie, bey Titans heisser Glut,", "tokens": ["\u201e", "gleich", "wie", ",", "bey", "Ti\u00b7tans", "heis\u00b7ser", "Glut", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "KOKOM", "$,", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u201eein ausgespanter Fecher thut.", "tokens": ["\u201e", "ein", "aus\u00b7ge\u00b7span\u00b7ter", "Fe\u00b7cher", "thut", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u201edie Kraft, so starck sich aufzutreiben,", "tokens": ["\u201e", "die", "Kraft", ",", "so", "starck", "sich", "auf\u00b7zu\u00b7trei\u00b7ben", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ADV", "ADJD", "PRF", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund unaufh\u00f6rlich aufzublehn,", "tokens": ["\u201e", "und", "un\u00b7auf\u00b7h\u00f6r\u00b7lich", "auf\u00b7zu\u00b7blehn", ","], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eist denen Bl\u00e4sgen zuzuschreiben,", "tokens": ["\u201e", "ist", "de\u00b7nen", "Bl\u00e4s\u00b7gen", "zu\u00b7zu\u00b7schrei\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PDS", "NN", "VVIZU", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u201eworaus sie eigentlich bestehn;", "tokens": ["\u201e", "wo\u00b7raus", "sie", "ei\u00b7gent\u00b7lich", "be\u00b7stehn", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u201eals welche f\u00fcglich mit den Zellen", "tokens": ["\u201e", "als", "wel\u00b7che", "f\u00fcg\u00b7lich", "mit", "den", "Zel\u00b7len"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u201eder Bienen in Vergleich zu stellen:", "tokens": ["\u201e", "der", "Bie\u00b7nen", "in", "Ver\u00b7gleich", "zu", "stel\u00b7len", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u201ewie schon Hippocrates erkannt,", "tokens": ["\u201e", "wie", "schon", "Hip\u00b7po\u00b7cra\u00b7tes", "er\u00b7kannt", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADV", "NN", "VVPP", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "\u201eeh\u2019 es Malpighius erfand.", "tokens": ["\u201e", "eh'", "es", "Mal\u00b7pig\u00b7hius", "er\u00b7fand", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "NE", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u201eaus diesen Luft-erf\u00fcllten H\u00f6len", "tokens": ["\u201e", "aus", "die\u00b7sen", "Luft\u00b7er\u00b7f\u00fcll\u00b7ten", "H\u00f6\u00b7len"], "token_info": ["punct", "word", "word", "word", "word"], "pos": ["$(", "APPR", "PDAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201epflegt sich das schw\u00e4rtzliche Gebl\u00fct", "tokens": ["\u201e", "pflegt", "sich", "das", "schw\u00e4rtz\u00b7li\u00b7che", "Ge\u00b7bl\u00fct"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PRF", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "\u201eaufs neue gleichsam zu beseelen,", "tokens": ["\u201e", "aufs", "neu\u00b7e", "gleich\u00b7sam", "zu", "be\u00b7see\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "ADJA", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eda\u00df es in frischem Purpur gl\u00fcht.", "tokens": ["\u201e", "da\u00df", "es", "in", "fri\u00b7schem", "Pur\u00b7pur", "gl\u00fcht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u201edenn wenn es matt zur\u00fccke kehret,", "tokens": ["\u201e", "denn", "wenn", "es", "matt", "zu\u00b7r\u00fc\u00b7cke", "keh\u00b7ret", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ADJD", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "\u201enachdem es jedes Glied ern\u00e4hret,", "tokens": ["\u201e", "nach\u00b7dem", "es", "je\u00b7des", "Glied", "er\u00b7n\u00e4h\u00b7ret", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u201eso wird ihm die verlohrne Kraft", "tokens": ["\u201e", "so", "wird", "ihm", "die", "ver\u00b7lohr\u00b7ne", "Kraft"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u201ehier wiederum herbey geschafft.", "tokens": ["\u201e", "hier", "wie\u00b7de\u00b7rum", "her\u00b7bey", "ge\u00b7schafft", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u201eweil Hertz und Lunge nun vor allen", "tokens": ["\u201e", "weil", "Hertz", "und", "Lun\u00b7ge", "nun", "vor", "al\u00b7len"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KOUS", "NN", "KON", "NN", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eregenten unsers Lebens seyn;", "tokens": ["\u201e", "re\u00b7gen\u00b7ten", "un\u00b7sers", "Le\u00b7bens", "seyn", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eso machen sie mit den Vasallen", "tokens": ["\u201e", "so", "ma\u00b7chen", "sie", "mit", "den", "Va\u00b7sal\u00b7len"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201eund Dienern sich nicht zu gemein.", "tokens": ["\u201e", "und", "Die\u00b7nern", "sich", "nicht", "zu", "ge\u00b7mein", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "NN", "PRF", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "\u201edahero h\u00e4ngt vor ihrer St\u00e4dte", "tokens": ["\u201e", "da\u00b7he\u00b7ro", "h\u00e4ngt", "vor", "ih\u00b7rer", "St\u00e4d\u00b7te"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PAV", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u201egar eine k\u00fcnstliche Tapete,", "tokens": ["\u201e", "gar", "ei\u00b7ne", "k\u00fcnst\u00b7li\u00b7che", "Ta\u00b7pe\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u201edie, als im alten Testament,", "tokens": ["\u201e", "die", ",", "als", "im", "al\u00b7ten", "Tes\u00b7ta\u00b7ment", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "$,", "KOUS", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201edas Heiligste vom Heil\u2019gen trennt. ", "tokens": ["\u201e", "das", "Hei\u00b7ligs\u00b7te", "vom", "Heil'\u00b7gen", "trennt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "APPRART", "NN", "VVFIN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.11": {"line.1": {"text": "Wobey ich zum Beschlu\u00df", "tokens": ["Wo\u00b7bey", "ich", "zum", "Be\u00b7schlu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Noch die Betrachtung f\u00fchren mu\u00df:", "tokens": ["Noch", "die", "Be\u00b7trach\u00b7tung", "f\u00fch\u00b7ren", "mu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Erwege, deinem GOtt und Sch\u00f6pfer doch zur Ehre,", "tokens": ["Er\u00b7we\u00b7ge", ",", "dei\u00b7nem", "Gott", "und", "Sch\u00f6p\u00b7fer", "doch", "zur", "Eh\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "KON", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn nur allein die Lung\u2019 in dir nicht richtig w\u00e4re,", "tokens": ["Wenn", "nur", "al\u00b7lein", "die", "Lung'", "in", "dir", "nicht", "rich\u00b7tig", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "ART", "NN", "APPR", "PPER", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie elend w\u00fcrde doch dein armes Leben seyn!", "tokens": ["Wie", "e\u00b7lend", "w\u00fcr\u00b7de", "doch", "dein", "ar\u00b7mes", "Le\u00b7ben", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein jeder Augenblick w\u00fcrd\u2019 immer neue Pein,", "tokens": ["Ein", "je\u00b7der", "Au\u00b7gen\u00b7blick", "w\u00fcrd'", "im\u00b7mer", "neu\u00b7e", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit Husten, Keichen, Seiten-Stechen,", "tokens": ["Mit", "Hus\u00b7ten", ",", "Kei\u00b7chen", ",", "Sei\u00b7ten\u00b7Ste\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In deiner fast zerfleischten Brust,", "tokens": ["In", "dei\u00b7ner", "fast", "zer\u00b7fleischten", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Die voller Schleim und Wust,", "tokens": ["Die", "vol\u00b7ler", "Schleim", "und", "Wust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Als wenn sie immer wolte brechen,", "tokens": ["Als", "wenn", "sie", "im\u00b7mer", "wol\u00b7te", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Erregen; da du jetzt, wenn du\u2019s erwegst, mit Lust", "tokens": ["Er\u00b7re\u00b7gen", ";", "da", "du", "jetzt", ",", "wenn", "du's", "er\u00b7wegst", ",", "mit", "Lust"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPER", "ADV", "$,", "KOUS", "PIS", "VVFIN", "$,", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Athen in dich ziehst, dein heisses Blut erfrischest,", "tokens": ["Den", "A\u00b7then", "in", "dich", "ziehst", ",", "dein", "heis\u00b7ses", "Blut", "er\u00b7fri\u00b7schest", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "PPER", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Luft gesunde Theil\u2019 in deinem C\u00f6rper mischest,", "tokens": ["Der", "Luft", "ge\u00b7sun\u00b7de", "Theil'", "in", "dei\u00b7nem", "C\u00f6r\u00b7per", "mi\u00b7schest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.12": {"text": "Und fr\u00f6lich leben kannst; wenn du nur selber wilt", "tokens": ["Und", "fr\u00f6\u00b7lich", "le\u00b7ben", "kannst", ";", "wenn", "du", "nur", "sel\u00b7ber", "wilt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVINF", "VMFIN", "$.", "KOUS", "PPER", "ADV", "ADV", "VMFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Kr\u00e4fte deiner Seel\u2019 auf dieses Wunder lencken,", "tokens": ["Die", "Kr\u00e4f\u00b7te", "dei\u00b7ner", "Seel'", "auf", "die\u00b7ses", "Wun\u00b7der", "len\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und, da\u00df du sanfte lebst,", "tokens": ["Und", ",", "da\u00df", "du", "sanf\u00b7te", "lebst", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Beym sanften Athen-ziehn,", "tokens": ["Beym", "sanf\u00b7ten", "A\u00b7then\u00b7ziehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Doch \u00f6fters als du thust, bem\u00fcht bist zu bedencken.", "tokens": ["Doch", "\u00f6f\u00b7ters", "als", "du", "thust", ",", "be\u00b7m\u00fcht", "bist", "zu", "be\u00b7den\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ach m\u00f6gten wir die\u00df Wunder oft betrachten", "tokens": ["Ach", "m\u00f6g\u00b7ten", "wir", "die\u00df", "Wun\u00b7der", "oft", "be\u00b7trach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PDS", "NN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und, wie es in der That, es f\u00fcr ein Wunder achten,", "tokens": ["Und", ",", "wie", "es", "in", "der", "That", ",", "es", "f\u00fcr", "ein", "Wun\u00b7der", "ach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "$,", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So w\u00fcrden wir bey jedem Athem-ziehn,", "tokens": ["So", "w\u00fcr\u00b7den", "wir", "bey", "je\u00b7dem", "A\u00b7them\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dem grossen GOtt zu dancken uns bem\u00fchn,", "tokens": ["Dem", "gros\u00b7sen", "Gott", "zu", "dan\u00b7cken", "uns", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und uns zu gleicher Zeit bestreben,", "tokens": ["Und", "uns", "zu", "glei\u00b7cher", "Zeit", "be\u00b7stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In unsrer Lust zu seiner Ehr\u2019 zu leben!", "tokens": ["In", "uns\u00b7rer", "Lust", "zu", "sei\u00b7ner", "Ehr'", "zu", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}