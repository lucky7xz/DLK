{"textgrid.poem.26569": {"metadata": {"author": {"name": "Saar, Ferdinand von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wir werden uns, ich wei\u00df es, wiederseh'n \u2013", "genre": "verse", "period": "N.A.", "pub_year": 1869, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir werden uns, ich wei\u00df es, wiederseh'n \u2013", "tokens": ["Wir", "wer\u00b7den", "uns", ",", "ich", "wei\u00df", "es", ",", "wie\u00b7der\u00b7seh'n", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "$,", "PWAV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ob mancher Lenz erbl\u00fcht noch und verbl\u00fcht;", "tokens": ["Ob", "man\u00b7cher", "Lenz", "er\u00b7bl\u00fcht", "noch", "und", "ver\u00b7bl\u00fcht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVFIN", "ADV", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wir werden pl\u00f6tzlich vor einander steh'n,", "tokens": ["Wir", "wer\u00b7den", "pl\u00f6tz\u00b7lich", "vor", "ein\u00b7an\u00b7der", "steh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ob wir, uns ", "tokens": ["Ob", "wir", ",", "uns"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "$,", "PPER"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Dann ist vielleicht dein Haar schon silberwei\u00df,", "tokens": ["Dann", "ist", "viel\u00b7leicht", "dein", "Haar", "schon", "sil\u00b7ber\u00b7wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und kahler w\u00f6lbet sich der Scheitel mir,", "tokens": ["Und", "kah\u00b7ler", "w\u00f6l\u00b7bet", "sich", "der", "Schei\u00b7tel", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PRF", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch jung und blond erscheinst du noch dem Greis,", "tokens": ["Doch", "jung", "und", "blond", "er\u00b7scheinst", "du", "noch", "dem", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und braungelockt und jung erscheint er dir.", "tokens": ["Und", "braun\u00b7ge\u00b7lockt", "und", "jung", "er\u00b7scheint", "er", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "ADJD", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Denn was die Zeit auch Beiden abgestreift:", "tokens": ["Denn", "was", "die", "Zeit", "auch", "Bei\u00b7den", "ab\u00b7ge\u00b7streift", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie r\u00fchrte nicht an uns'rer Herzen Gluth,", "tokens": ["Sie", "r\u00fchr\u00b7te", "nicht", "an", "un\u00b7s'\u00b7rer", "Her\u00b7zen", "Gluth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die, \u00fcberdauernd, neu zum Leben reift,", "tokens": ["Die", ",", "\u00fc\u00b7berd\u00b7au\u00b7ernd", ",", "neu", "zum", "Le\u00b7ben", "reift", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVPP", "$,", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Was lang in der Erinn'rung Grab geruht.", "tokens": ["Was", "lang", "in", "der", "Er\u00b7inn'\u00b7rung", "Grab", "ge\u00b7ruht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Noch einmal zuckt es in uns m\u00e4chtig auf,", "tokens": ["Noch", "ein\u00b7mal", "zuckt", "es", "in", "uns", "m\u00e4ch\u00b7tig", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Es ist der Lebenskr\u00e4fte letzter Schu\u00df;", "tokens": ["Es", "ist", "der", "Le\u00b7bens\u00b7kr\u00e4f\u00b7te", "letz\u00b7ter", "Schu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Noch einmal wallt das Blut mit raschem Lauf \u2013", "tokens": ["Noch", "ein\u00b7mal", "wallt", "das", "Blut", "mit", "ra\u00b7schem", "Lauf", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir k\u00fcssen hei\u00df wie einst den letzten Ku\u00df.", "tokens": ["Wir", "k\u00fcs\u00b7sen", "hei\u00df", "wie", "einst", "den", "letz\u00b7ten", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KOKOM", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Dann aber lassen wir uns wieder still", "tokens": ["Dann", "a\u00b7ber", "las\u00b7sen", "wir", "uns", "wie\u00b7der", "still"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und f\u00fchlen leise, Hand in Hand gelegt,", "tokens": ["Und", "f\u00fch\u00b7len", "lei\u00b7se", ",", "Hand", "in", "Hand", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df jeder Keim zur Frucht gedeihen will,", "tokens": ["Da\u00df", "je\u00b7der", "Keim", "zur", "Frucht", "ge\u00b7dei\u00b7hen", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den einmal wahrhaft tief das Herz gehegt.", "tokens": ["Den", "ein\u00b7mal", "wahr\u00b7haft", "tief", "das", "Herz", "ge\u00b7hegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wir fassen's nicht, da\u00df wir so lang gelebt,", "tokens": ["Wir", "fas\u00b7sen's", "nicht", ",", "da\u00df", "wir", "so", "lang", "ge\u00b7lebt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Einander fern \u2013 und doch die Brust voll Drang;", "tokens": ["Ein\u00b7an\u00b7der", "fern", "\u2013", "und", "doch", "die", "Brust", "voll", "Drang", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KON", "ADV", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df wir, trotz allen Sehnens, nicht gestrebt", "tokens": ["Da\u00df", "wir", ",", "trotz", "al\u00b7len", "Seh\u00b7nens", ",", "nicht", "ge\u00b7strebt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "PIAT", "NN", "$,", "PTKNEG", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Uns aufzusuchen \u2013 ach schon lang, schon lang!", "tokens": ["Uns", "auf\u00b7zu\u00b7su\u00b7chen", "\u2013", "ach", "schon", "lang", ",", "schon", "lang", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVIZU", "$(", "ITJ", "ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Wir fassen's nicht, da\u00df von einander je", "tokens": ["Wir", "fas\u00b7sen's", "nicht", ",", "da\u00df", "von", "ein\u00b7an\u00b7der", "je"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "APPR", "PRF", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wir scheiden konnten, z\u00fcrnend und mit Groll,", "tokens": ["Wir", "schei\u00b7den", "konn\u00b7ten", ",", "z\u00fcr\u00b7nend", "und", "mit", "Groll", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VMFIN", "$,", "VVPP", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und selbst uns schaffen jenes herbe Weh',", "tokens": ["Und", "selbst", "uns", "schaf\u00b7fen", "je\u00b7nes", "her\u00b7be", "Weh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das hei\u00df in Thr\u00e4nen durch die Wimper quoll.", "tokens": ["Das", "hei\u00df", "in", "Thr\u00e4\u00b7nen", "durch", "die", "Wim\u00b7per", "quoll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Auch uns'ren Fehlern sinnen wir dann nach \u2013", "tokens": ["Auch", "un\u00b7s'\u00b7ren", "Feh\u00b7lern", "sin\u00b7nen", "wir", "dann", "nach", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "APPR", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und finden doch die Summen gleichgesetzt,", "tokens": ["Und", "fin\u00b7den", "doch", "die", "Sum\u00b7men", "gleich\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da Jedes das nur an sich selbst verbrach,", "tokens": ["Da", "Je\u00b7des", "das", "nur", "an", "sich", "selbst", "ver\u00b7brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "PDS", "ADV", "APPR", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Womit es oft das And're schwer verletzt. \u2013", "tokens": ["Wo\u00b7mit", "es", "oft", "das", "An\u00b7d'\u00b7re", "schwer", "ver\u00b7letzt", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "So weilen wir mit Blicken, tief und mild;", "tokens": ["So", "wei\u00b7len", "wir", "mit", "Bli\u00b7cken", ",", "tief", "und", "mild", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich streichle dir, wie einst, das schlichte Haar,", "tokens": ["Ich", "streich\u00b7le", "dir", ",", "wie", "einst", ",", "das", "schlich\u00b7te", "Haar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und uns'rer Jugend lang getr\u00fcbtes Bild,", "tokens": ["Und", "un\u00b7s'\u00b7rer", "Ju\u00b7gend", "lang", "ge\u00b7tr\u00fcb\u00b7tes", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Vor uns'rem Geiste wird es hell und klar.", "tokens": ["Vor", "un\u00b7s'\u00b7rem", "Geis\u00b7te", "wird", "es", "hell", "und", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Und all' der Kampf, die selbstgeschaff'ne Qual", "tokens": ["Und", "all'", "der", "Kampf", ",", "die", "selbst\u00b7ge\u00b7schaff'\u00b7ne", "Qual"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zerstieben, so wie Nebel sanft zerstiebt \u2013", "tokens": ["Zer\u00b7stie\u00b7ben", ",", "so", "wie", "Ne\u00b7bel", "sanft", "zer\u00b7stiebt", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "KOKOM", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und nieder f\u00e4llt auf uns der reinste Strahl:", "tokens": ["Und", "nie\u00b7der", "f\u00e4llt", "auf", "uns", "der", "reins\u00b7te", "Strahl", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}