{"textgrid.poem.53332": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "[ihr Seiten greifft euch wieder an]", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Seiten greifft euch wieder an,", "tokens": ["Ihr", "Sei\u00b7ten", "greifft", "euch", "wie\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00dft sehn was ewer Meister kan,", "tokens": ["La\u00dft", "sehn", "was", "e\u00b7wer", "Meis\u00b7ter", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVINF", "PWS", "PPOSAT", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der zimlich nun hat still geschwiegen,", "tokens": ["Der", "zim\u00b7lich", "nun", "hat", "still", "ge\u00b7schwie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd euch fast m\u00fcssig lassen liegen", "tokens": ["Vnd", "euch", "fast", "m\u00fcs\u00b7sig", "las\u00b7sen", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ADJD", "VVINF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Seit her die All' vnd Inster Ihn", "tokens": ["Seit", "her", "die", "All'", "vnd", "Ins\u00b7ter", "Ihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "NN", "KON", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vmb jhren Rand gesehen ziehn,", "tokens": ["Vmb", "jhren", "Rand", "ge\u00b7se\u00b7hen", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVPP", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da wo die Fluht der Angerappen", "tokens": ["Da", "wo", "die", "Fluht", "der", "An\u00b7ge\u00b7rap\u00b7pen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich von dem Pregel l\u00e4\u00dft betappen.", "tokens": ["Sich", "von", "dem", "Pre\u00b7gel", "l\u00e4\u00dft", "be\u00b7tap\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "In dessen hat der Sonnen Pracht", "tokens": ["In", "des\u00b7sen", "hat", "der", "Son\u00b7nen", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur neunmahl vns den Tag gebracht,", "tokens": ["Nur", "neun\u00b7mahl", "vns", "den", "Tag", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd eben so viel mahl auff Erden", "tokens": ["Vnd", "e\u00b7ben", "so", "viel", "mahl", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ADV", "ADV", "APPR", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Es lassen bey vns finster werden.", "tokens": ["Es", "las\u00b7sen", "bey", "vns", "fins\u00b7ter", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch hat der Tod in dieser Zeit", "tokens": ["Doch", "hat", "der", "Tod", "in", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So wehrte M\u00e4nner abgemeyt,", "tokens": ["So", "wehr\u00b7te", "M\u00e4n\u00b7ner", "ab\u00b7ge\u00b7meyt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die ich durch ewre pflicht, jhr Seiten,", "tokens": ["Die", "ich", "durch", "ew\u00b7re", "pflicht", ",", "jhr", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht k\u00f6nnen an jhr Grab begleiten.", "tokens": ["Nicht", "k\u00f6n\u00b7nen", "an", "jhr", "Grab", "be\u00b7glei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Pouchenius, der Gottes Wort", "tokens": ["Pou\u00b7che\u00b7ni\u00b7us", ",", "der", "Got\u00b7tes", "Wort"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "NN", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "So trewlich hat gelehrt, ist fort,", "tokens": ["So", "trew\u00b7lich", "hat", "ge\u00b7lehrt", ",", "ist", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "VVPP", "$,", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der billich erst recht sollen alten,", "tokens": ["Der", "bil\u00b7lich", "erst", "recht", "sol\u00b7len", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "ADV", "PIAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00e4tt' vnser Wunsch nur k\u00f6nnen walten.", "tokens": ["H\u00e4tt'", "vn\u00b7ser", "Wunsch", "nur", "k\u00f6n\u00b7nen", "wal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Nach jhm f\u00e4hrt auch Herr Heuschkel hin,", "tokens": ["Nach", "jhm", "f\u00e4hrt", "auch", "Herr", "Heuschkel", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ADV", "NN", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der recht war nach der Frommheit Sinn,", "tokens": ["Der", "recht", "war", "nach", "der", "Fromm\u00b7heit", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der so viel Freundschafft mir erwiesen", "tokens": ["Der", "so", "viel", "Freund\u00b7schafft", "mir", "er\u00b7wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "PIAT", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Stirbt, vnd von mir zwar vngepriesen.", "tokens": ["Stirbt", ",", "vnd", "von", "mir", "zwar", "vn\u00b7ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "APPR", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Gew\u00fcnschte Seelen, welches Zelt", "tokens": ["Ge\u00b7w\u00fcnschte", "See\u00b7len", ",", "wel\u00b7ches", "Zelt"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Des Himmels ietzund Euch enth\u00e4lt,", "tokens": ["Des", "Him\u00b7mels", "ie\u00b7tzund", "Euch", "ent\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit was f\u00fcr au\u00dferwehlten dingen", "tokens": ["Mit", "was", "f\u00fcr", "au\u00b7\u00dfer\u00b7wehl\u00b7ten", "din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr dort die weile zu-m\u00f6gt-bringen,", "tokens": ["Ihr", "dort", "die", "wei\u00b7le", "zu\u00b7m\u00f6g\u00b7tbrin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was jhr besitzt f\u00fcr theure Rhu,", "tokens": ["Was", "jhr", "be\u00b7sitzt", "f\u00fcr", "theu\u00b7re", "Rhu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "M\u00e4\u00dft di\u00dffals mir die Schuld nicht zu,", "tokens": ["M\u00e4\u00dft", "di\u00df\u00b7fals", "mir", "die", "Schuld", "nicht", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPER", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr seyd mir vnverhofft verblichen,", "tokens": ["Ihr", "seyd", "mir", "vn\u00b7ver\u00b7hofft", "ver\u00b7bli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil ich in etwas war entwichen.", "tokens": ["Weil", "ich", "in", "et\u00b7was", "war", "ent\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Nehmt, bitt' ich, nehmt von mir f\u00fcr gut", "tokens": ["Nehmt", ",", "bitt'", "ich", ",", "nehmt", "von", "mir", "f\u00fcr", "gut"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "APPR", "PPER", "APPR", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der trewen Seufftzer heisse Glut,", "tokens": ["Der", "tre\u00b7wen", "Seufft\u00b7zer", "heis\u00b7se", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die strenge Bache bittrer Zehren,", "tokens": ["Die", "stren\u00b7ge", "Ba\u00b7che", "bit\u00b7trer", "Zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mehr wei\u00df ich euch nicht zugewehren.", "tokens": ["Mehr", "wei\u00df", "ich", "euch", "nicht", "zu\u00b7ge\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Insonderheit weil ewer Prei\u00df", "tokens": ["In\u00b7son\u00b7der\u00b7heit", "weil", "e\u00b7wer", "Prei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steigt \u00fcber aller Lieder flei\u00df,", "tokens": ["Steigt", "\u00fc\u00b7ber", "al\u00b7ler", "Lie\u00b7der", "flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd hat ietzt g\u00e4ntzlich nicht von n\u00f6then", "tokens": ["Vnd", "hat", "ietzt", "g\u00e4ntz\u00b7lich", "nicht", "von", "n\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "PTKNEG", "APPR", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Kehlen sterblicher Poeten.", "tokens": ["Der", "Keh\u00b7len", "sterb\u00b7li\u00b7cher", "Po\u00b7et\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Vieleicht (wer kennt des Himmels Raht?)", "tokens": ["Vie\u00b7leicht", "(", "wer", "kennt", "des", "Him\u00b7mels", "Raht", "?", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$(", "PWS", "VVFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sol mein Gesang nicht haben stat", "tokens": ["Sol", "mein", "Ge\u00b7sang", "nicht", "ha\u00b7ben", "stat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "PTKNEG", "VAINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verkn\u00fcpfft mit vnverr\u00fcckten Liedern,", "tokens": ["Ver\u00b7kn\u00fcpfft", "mit", "vn\u00b7ver\u00b7r\u00fcck\u00b7ten", "Lie\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ohn hie bey diesen zweyen Br\u00fcdern.", "tokens": ["Ohn", "hie", "bey", "die\u00b7sen", "zwe\u00b7yen", "Br\u00fc\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Herr Doctor Behm war es zuletzt", "tokens": ["Herr", "Doc\u00b7tor", "Behm", "war", "es", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "ADJD", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem ich ein Leich-Lied auffgesetzt,", "tokens": ["Dem", "ich", "ein", "Leich\u00b7Lied", "auff\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein Bruder wird nach Ihm besungen", "tokens": ["Sein", "Bru\u00b7der", "wird", "nach", "Ihm", "be\u00b7sun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Zuerst verm\u00f6ge meiner Zungen.", "tokens": ["Zu\u00b7erst", "ver\u00b7m\u00f6\u00b7ge", "mei\u00b7ner", "Zun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Die, so Geburt vnd Ankunfft bindt,", "tokens": ["Die", ",", "so", "Ge\u00b7burt", "vnd", "An\u00b7kunfft", "bindt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die fast zugleich verblichen sind,", "tokens": ["Die", "fast", "zu\u00b7gleich", "ver\u00b7bli\u00b7chen", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich hertzen dort in heilgen Flammen,", "tokens": ["Sich", "hert\u00b7zen", "dort", "in", "heil\u00b7gen", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kn\u00fcpfft auch mein schlechtes Lied zusammen.", "tokens": ["Kn\u00fcpfft", "auch", "mein", "schlech\u00b7tes", "Lied", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "So komm, du wehrter Grei\u00df, vnd sey", "tokens": ["So", "komm", ",", "du", "wehr\u00b7ter", "Grei\u00df", ",", "vnd", "sey"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PPER", "ADJA", "NN", "$,", "KON", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Inhalt meiner Melodey,", "tokens": ["Der", "In\u00b7halt", "mei\u00b7ner", "Me\u00b7lo\u00b7dey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich bin bem\u00fcht nach deinem Leben", "tokens": ["Ich", "bin", "be\u00b7m\u00fcht", "nach", "dei\u00b7nem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dich, wie mir m\u00f6glich, zu erheben.", "tokens": ["Dich", ",", "wie", "mir", "m\u00f6g\u00b7lich", ",", "zu", "er\u00b7he\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PWAV", "PPER", "ADJD", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Wiewol du lebst in Gottes Reich", "tokens": ["Wie\u00b7wol", "du", "lebst", "in", "Got\u00b7tes", "Reich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd bist den lieben Engeln gleich,", "tokens": ["Vnd", "bist", "den", "lie\u00b7ben", "En\u00b7geln", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Rein, heilig, ewig, au\u00dferkohren,", "tokens": ["Rein", ",", "hei\u00b7lig", ",", "e\u00b7wig", ",", "au\u00b7\u00dfer\u00b7koh\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJD", "$,", "ADJD", "$,", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Begn\u00fcgt, belebt vnd new gebohren,", "tokens": ["Be\u00b7gn\u00fcgt", ",", "be\u00b7lebt", "vnd", "new", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Kein Tod hat mehr Gewalt an dir,", "tokens": ["Kein", "Tod", "hat", "mehr", "Ge\u00b7walt", "an", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PIAT", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jedennoch bleibet etwas hier,", "tokens": ["Je\u00b7den\u00b7noch", "blei\u00b7bet", "et\u00b7was", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das, wie der Leichnam, wird begraben", "tokens": ["Das", ",", "wie", "der", "Leich\u00b7nam", ",", "wird", "be\u00b7gra\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "$,", "PWAV", "ART", "NN", "$,", "VAFIN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Im fall es nicht kan Tichter haben.", "tokens": ["Im", "fall", "es", "nicht", "kan", "Tich\u00b7ter", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKNEG", "VMFIN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Dein Name, wird er nicht befreyt,", "tokens": ["Dein", "Na\u00b7me", ",", "wird", "er", "nicht", "be\u00b7freyt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00e4hrt stracks in die Vergessenheit,", "tokens": ["F\u00e4hrt", "stracks", "in", "die", "Ver\u00b7ges\u00b7sen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn Zeit vnd Fall rei\u00dft alles nieder,", "tokens": ["Denn", "Zeit", "vnd", "Fall", "rei\u00dft", "al\u00b7les", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ohn der Poeten weise Lieder.", "tokens": ["Ohn", "der", "Po\u00b7et\u00b7en", "wei\u00b7se", "Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Du warst kein Leib ohn Hertz vnd Muth,", "tokens": ["Du", "warst", "kein", "Leib", "ohn", "Hertz", "vnd", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der H\u00f6chste gab dir Gl\u00fcck vnd Gut,", "tokens": ["Der", "H\u00f6chs\u00b7te", "gab", "dir", "Gl\u00fcck", "vnd", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch auch die edle Kunst daneben", "tokens": ["Doch", "auch", "die", "ed\u00b7le", "Kunst", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den G\u00fctern jhren schein zu geben.", "tokens": ["Den", "G\u00fc\u00b7tern", "jhren", "schein", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Es haben deine milde Hand", "tokens": ["Es", "ha\u00b7ben", "dei\u00b7ne", "mil\u00b7de", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die deinen damals schon erkant,", "tokens": ["Die", "dei\u00b7nen", "da\u00b7mals", "schon", "er\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Deiner Jugend Flei\u00df mit Segen", "tokens": ["Als", "Dei\u00b7ner", "Ju\u00b7gend", "Flei\u00df", "mit", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dich mercklich anhub zu belegen.", "tokens": ["Dich", "merck\u00b7lich", "an\u00b7hub", "zu", "be\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Dein Alter wuchs, doch auch die Gunst", "tokens": ["Dein", "Al\u00b7ter", "wuchs", ",", "doch", "auch", "die", "Gunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu guter Wissenschafft vnd Kunst,", "tokens": ["Zu", "gu\u00b7ter", "Wis\u00b7sen\u00b7schafft", "vnd", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die s\u00fcsse Musica f\u00fcr allen", "tokens": ["Die", "s\u00fcs\u00b7se", "Mu\u00b7si\u00b7ca", "f\u00fcr", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Pflag dir im Hertzen zu gefallen.", "tokens": ["Pflag", "dir", "im", "Hert\u00b7zen", "zu", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Stobeus hat dich offt ergetzt", "tokens": ["Sto\u00b7beus", "hat", "dich", "offt", "er\u00b7getzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit dem was seine Kunst gesetzt,", "tokens": ["Mit", "dem", "was", "sei\u00b7ne", "Kunst", "ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da hat man dich gesehn mit singen", "tokens": ["Da", "hat", "man", "dich", "ge\u00b7sehn", "mit", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PRF", "VVPP", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So manchen lieben Tag verbringen.", "tokens": ["So", "man\u00b7chen", "lie\u00b7ben", "Tag", "ver\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Der, dem die Music nicht gef\u00e4llt,", "tokens": ["Der", ",", "dem", "die", "Mu\u00b7sic", "nicht", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lebt warlich vnwehrt auff der Welt,", "tokens": ["Lebt", "war\u00b7lich", "vn\u00b7wehrt", "auff", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Natura scheint jhn nicht zu kennen,", "tokens": ["Na\u00b7tu\u00b7ra", "scheint", "jhn", "nicht", "zu", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd mu\u00df jhn nur jhr Stieffkind nennen,", "tokens": ["Vnd", "mu\u00df", "jhn", "nur", "jhr", "Stieff\u00b7kind", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Er ist vnd bleibt ein Midas-Ohr,", "tokens": ["Er", "ist", "vnd", "bleibt", "ein", "Mi\u00b7das\u00b7Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was n\u00fctzt er in der Engel Chor,", "tokens": ["Was", "n\u00fctzt", "er", "in", "der", "En\u00b7gel", "Chor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da erst die Music an-wird-gehen,", "tokens": ["Da", "erst", "die", "Mu\u00b7sic", "an\u00b7wird\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch die wir werden Gott erh\u00f6hen?", "tokens": ["Durch", "die", "wir", "wer\u00b7den", "Gott", "er\u00b7h\u00f6\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Hast du nur diesen Rhum allein,", "tokens": ["Hast", "du", "nur", "die\u00b7sen", "Rhum", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PDAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sonst aber nichts gestifftet? Nein.", "tokens": ["Sonst", "a\u00b7ber", "nichts", "ge\u00b7stiff\u00b7tet", "?", "Nein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVPP", "$.", "PTKANT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du gibst auch der gelehrten Jugend", "tokens": ["Du", "gibst", "auch", "der", "ge\u00b7lehr\u00b7ten", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch fug zu Wissenschafft vnd Tugend.", "tokens": ["Noch", "fug", "zu", "Wis\u00b7sen\u00b7schafft", "vnd", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Mit guttem Raht und wolbedacht", "tokens": ["Mit", "gut\u00b7tem", "Raht", "und", "wol\u00b7be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hast du ein Ansehnliches vermacht,", "tokens": ["Hast", "du", "ein", "An\u00b7sehn\u00b7li\u00b7ches", "ver\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dadurch der Gottesdienst auff Erden", "tokens": ["Da\u00b7durch", "der", "Got\u00b7tes\u00b7dienst", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd auch das Recht gepflantzt kan werden.", "tokens": ["Vnd", "auch", "das", "Recht", "ge\u00b7pflantzt", "kan", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVPP", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Die\u00df macht die G\u00fctter erst recht gut,", "tokens": ["Die\u00df", "macht", "die", "G\u00fct\u00b7ter", "erst", "recht", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht Stoltz nicht Pracht nicht Vbermuth,", "tokens": ["Nicht", "Stoltz", "nicht", "Pracht", "nicht", "Vber\u00b7muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "PTKNEG", "NN", "PTKNEG", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nicht das sie liegen in dem Kasten,", "tokens": ["Nicht", "das", "sie", "lie\u00b7gen", "in", "dem", "Kas\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PRELS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Trotz einem, der sie an-sol-tasten.", "tokens": ["Trotz", "ei\u00b7nem", ",", "der", "sie", "an\u00b7sol\u00b7tas\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Was h\u00e4tte Gott an mir erkant", "tokens": ["Was", "h\u00e4t\u00b7te", "Gott", "an", "mir", "er\u00b7kant"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "NN", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4tt' er mir Reichthumb zugewandt?", "tokens": ["H\u00e4tt'", "er", "mir", "Reicht\u00b7humb", "zu\u00b7ge\u00b7wandt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "L\u00e4sst er mich mir allein gedeyen,", "tokens": ["L\u00e4sst", "er", "mich", "mir", "al\u00b7lein", "ge\u00b7de\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Weis ich nicht reichlich aus zu strewen?", "tokens": ["Weis", "ich", "nicht", "reich\u00b7lich", "aus", "zu", "stre\u00b7wen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.28": {"line.1": {"text": "Es schreyet hie der arme Mann,", "tokens": ["Es", "schre\u00b7yet", "hie", "der", "ar\u00b7me", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da Schul vnd Gottes Hau\u00df dich an,", "tokens": ["Da", "Schul", "vnd", "Got\u00b7tes", "Hau\u00df", "dich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "La\u00df hieher deine Str\u00f6me fliessen,", "tokens": ["La\u00df", "hie\u00b7her", "dei\u00b7ne", "Str\u00f6\u00b7me", "flies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PAV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wilst du jhr anders recht geniessen.", "tokens": ["Wilst", "du", "jhr", "an\u00b7ders", "recht", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Nur dieser Mammon macht, da\u00df wir,", "tokens": ["Nur", "die\u00b7ser", "Mam\u00b7mon", "macht", ",", "da\u00df", "wir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVFIN", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Reisst vns der Todt gantz nackt von hier,", "tokens": ["Reisst", "vns", "der", "Todt", "gantz", "nackt", "von", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "APPR", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir lassen alles doch dahinden,", "tokens": ["Wir", "las\u00b7sen", "al\u00b7les", "doch", "da\u00b7hin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die wahre Gn\u00fcg im Himmel finden.", "tokens": ["Die", "wah\u00b7re", "Gn\u00fcg", "im", "Him\u00b7mel", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Wol dir, du edle Seele, wol,", "tokens": ["Wol", "dir", ",", "du", "ed\u00b7le", "See\u00b7le", ",", "wol", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPER", "ADJA", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jetzt bist du alles Reichthums voll", "tokens": ["Jetzt", "bist", "du", "al\u00b7les", "Reicht\u00b7hums", "voll"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dort wo dich in den ewign H\u00fctten", "tokens": ["Dort", "wo", "dich", "in", "den", "e\u00b7wign", "H\u00fct\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lust, Lieb vnd Leben \u00fcbersch\u00fctten.", "tokens": ["Lust", ",", "Lieb", "vnd", "Le\u00b7ben", "\u00fc\u00b7ber\u00b7sch\u00fct\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Dein Same wird nach langer Zeit", "tokens": ["Dein", "Sa\u00b7me", "wird", "nach", "lan\u00b7ger", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch deines Segens seyn erfrewt,", "tokens": ["Noch", "dei\u00b7nes", "Se\u00b7gens", "seyn", "er\u00b7frewt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VAINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn was du jhm hast hinter lassen", "tokens": ["Denn", "was", "du", "jhm", "hast", "hin\u00b7ter", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "PPER", "VAFIN", "APPR", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wird Gott vermehren aller massen.", "tokens": ["Wird", "Gott", "ver\u00b7meh\u00b7ren", "al\u00b7ler", "mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVINF", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Schaw, wie er so be\u00e4ngstigt steht,", "tokens": ["Schaw", ",", "wie", "er", "so", "be\u00b7\u00e4ngs\u00b7tigt", "steht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Betr\u00fcbt vmb deinen Sargk her geht", "tokens": ["Be\u00b7tr\u00fcbt", "vmb", "dei\u00b7nen", "Sargk", "her", "geht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "APZR", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd mit was schmertzlichen Geberden", "tokens": ["Vnd", "mit", "was", "schmertz\u00b7li\u00b7chen", "Ge\u00b7ber\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PRELS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er dein Gebein vertrawt der Erden.", "tokens": ["Er", "dein", "Ge\u00b7bein", "ver\u00b7trawt", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Wol dir! du stirbest Lebens satt,", "tokens": ["Wol", "dir", "!", "du", "stir\u00b7best", "Le\u00b7bens", "satt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$.", "PPER", "VVFIN", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So bald Gott abgefordert hat", "tokens": ["So", "bald", "Gott", "ab\u00b7ge\u00b7for\u00b7dert", "hat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "NN", "VVPP", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Bruder, eilst auch du von hinnen", "tokens": ["Den", "Bru\u00b7der", ",", "eilst", "auch", "du", "von", "hin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "ADV", "PPER", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Best\u00e4ndig, froh, mit Wunsch vnd Sinnen.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", ",", "froh", ",", "mit", "Wunsch", "vnd", "Sin\u00b7nen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Beschickst dein Hau\u00df, verh\u00fctest Streit,", "tokens": ["Be\u00b7schickst", "dein", "Hau\u00df", ",", "ver\u00b7h\u00fc\u00b7test", "Streit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mahnst alles an zur Einigkeit,", "tokens": ["Mahnst", "al\u00b7les", "an", "zur", "Ei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Stirbst (selig hierin auch nicht minder)", "tokens": ["Stirbst", "(", "se\u00b7lig", "hie\u00b7rin", "auch", "nicht", "min\u00b7der", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "ADV", "ADV", "PTKNEG", "ADV", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Sanfft in den Armen deiner Kinder.", "tokens": ["Sanfft", "in", "den", "Ar\u00b7men", "dei\u00b7ner", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "++-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Leb ewig wol, als wie du thust!", "tokens": ["Leb", "e\u00b7wig", "wol", ",", "als", "wie", "du", "thust", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJD", "ADV", "$,", "KOUS", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir haben hie nicht Rhu noch Lust,", "tokens": ["Wir", "ha\u00b7ben", "hie", "nicht", "Rhu", "noch", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "NE", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind stets von Furcht vnd Noht durchnommen,", "tokens": ["Sind", "stets", "von", "Furcht", "vnd", "Noht", "durc\u00b7hnom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bi\u00df da\u00df wir selig zu dir kommen.", "tokens": ["Bi\u00df", "da\u00df", "wir", "se\u00b7lig", "zu", "dir", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}