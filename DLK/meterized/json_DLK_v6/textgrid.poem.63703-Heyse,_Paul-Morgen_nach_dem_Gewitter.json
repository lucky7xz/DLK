{"textgrid.poem.63703": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "Morgen nach dem Gewitter", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Sturm hat \u00fcber Nacht gebraust,", "tokens": ["Der", "Sturm", "hat", "\u00fc\u00b7ber", "Nacht", "ge\u00b7braust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie der wilde Feind im Wald gehaust", "tokens": ["Wie", "der", "wil\u00b7de", "Feind", "im", "Wald", "ge\u00b7haust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPRART", "NN", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mit frechem Hohn und Ungeb\u00fchr, \u2013", "tokens": ["Mit", "fre\u00b7chem", "Hohn", "und", "Un\u00b7ge\u00b7b\u00fchr", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein H\u00fcndlein jagte man vor die T\u00fcr.", "tokens": ["Kein", "H\u00fcnd\u00b7lein", "jag\u00b7te", "man", "vor", "die", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Wie sch\u00e4umt der Bach so wild geschwellt,", "tokens": ["Wie", "sch\u00e4umt", "der", "Bach", "so", "wild", "ge\u00b7schwellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Morgenzwielicht bleich erhellt!", "tokens": ["Vom", "Mor\u00b7gen\u00b7zwie\u00b7licht", "bleich", "er\u00b7hellt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er murrt, wie schlecht Gewissen tut;", "tokens": ["Er", "murrt", ",", "wie", "schlecht", "Ge\u00b7wis\u00b7sen", "tut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was treibt dort auf der tr\u00fcben Flut?", "tokens": ["Was", "treibt", "dort", "auf", "der", "tr\u00fc\u00b7ben", "Flut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ein schwarzes Kl\u00fcmplein \u2013 nur ein Hund;", "tokens": ["Ein", "schwar\u00b7zes", "Kl\u00fcm\u00b7plein", "\u2013", "nur", "ein", "Hund", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ri\u00df der Sturm vom festen Grund.", "tokens": ["Den", "ri\u00df", "der", "Sturm", "vom", "fes\u00b7ten", "Grund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er kl\u00e4fft' ein Weilchen, ward dann stumm,", "tokens": ["Er", "kl\u00e4fft'", "ein", "Weil\u00b7chen", ",", "ward", "dann", "stumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lie\u00df alles treiben um und um.", "tokens": ["Lie\u00df", "al\u00b7les", "trei\u00b7ben", "um", "und", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVINF", "APPR", "KON", "KOUI", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Er war noch jung, die Z\u00e4hne blank,", "tokens": ["Er", "war", "noch", "jung", ",", "die", "Z\u00e4h\u00b7ne", "blank", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die dichte Rute schwarz und schwank.", "tokens": ["Die", "dich\u00b7te", "Ru\u00b7te", "schwarz", "und", "schwank", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der J\u00e4ger wohl im Waldrevier", "tokens": ["Der", "J\u00e4\u00b7ger", "wohl", "im", "Wald\u00b7re\u00b7vier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird dich nun missen, wackres Tier!", "tokens": ["Wird", "dich", "nun", "mis\u00b7sen", ",", "wack\u00b7res", "Tier", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Des Weges wankt ein Greis daher,", "tokens": ["Des", "We\u00b7ges", "wankt", "ein", "Greis", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An Holz und Jahren tr\u00e4gt er schwer,", "tokens": ["An", "Holz", "und", "Jah\u00b7ren", "tr\u00e4gt", "er", "schwer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bleibt stehn, wie er das Tier erschaut,", "tokens": ["Bleibt", "stehn", ",", "wie", "er", "das", "Tier", "er\u00b7schaut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$,", "PWAV", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und spricht: \u00bbGibst auch mehr keinen Laut?", "tokens": ["Und", "spricht", ":", "\u00bb", "Gibst", "auch", "mehr", "kei\u00b7nen", "Laut", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "VVIMP", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ha, dir ist wohl! Nicht alt, nicht krank,", "tokens": ["Ha", ",", "dir", "ist", "wohl", "!", "Nicht", "alt", ",", "nicht", "krank", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VAFIN", "ADV", "$.", "PTKNEG", "ADJD", "$,", "PTKNEG", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und schon erl\u00f6st! Dem Sturm sag Dank.", "tokens": ["Und", "schon", "er\u00b7l\u00f6st", "!", "Dem", "Sturm", "sag", "Dank", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "$.", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gut' Nacht! Wollt' auch, 's w\u00e4r' Schlafenszeit!\u00ab", "tokens": ["Gut'", "Nacht", "!", "Wollt'", "auch", ",", "'", "s", "w\u00e4r", "'", "Schla\u00b7fens\u00b7zeit", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "VMFIN", "ADV", "$,", "$(", "PPER", "VAFIN", "$(", "NN", "$.", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "So sch\u00f6nen Grabspruch h\u00e4lt der Neid.", "tokens": ["So", "sch\u00f6\u00b7nen", "Grabs\u00b7pruch", "h\u00e4lt", "der", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}