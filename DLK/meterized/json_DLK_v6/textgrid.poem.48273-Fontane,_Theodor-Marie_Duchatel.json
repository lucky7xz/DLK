{"textgrid.poem.48273": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Marie Duchatel", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbwelchen Hofstaat bringt unsre K\u00f6nigin mit?\u00ab", "tokens": ["\u00bb", "wel\u00b7chen", "Hof\u00b7staat", "bringt", "uns\u00b7re", "K\u00f6\u00b7ni\u00b7gin", "mit", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAT", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "\u00bbsie bringt mit ihre vier Marien,", "tokens": ["\u00bb", "sie", "bringt", "mit", "ih\u00b7re", "vier", "Ma\u00b7ri\u00b7en", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PPOSAT", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihre vier Marien von Frankreich her,", "tokens": ["Ih\u00b7re", "vier", "Ma\u00b7ri\u00b7en", "von", "Fran\u00b7kreich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "CARD", "NN", "APPR", "NE", "PTKVZ", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die m\u00fcssen mit ihr ziehn.", "tokens": ["Die", "m\u00fcs\u00b7sen", "mit", "ihr", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die m\u00fcssen ihr pl\u00e4tten und gl\u00e4tten das Bett", "tokens": ["Die", "m\u00fcs\u00b7sen", "ihr", "pl\u00e4t\u00b7ten", "und", "gl\u00e4t\u00b7ten", "das", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und warten auf der Schwell',", "tokens": ["Und", "war\u00b7ten", "auf", "der", "Schwell'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich kenne die j\u00fcngste, die sch\u00f6nste,", "tokens": ["Ich", "ken\u00b7ne", "die", "j\u00fcngs\u00b7te", ",", "die", "sch\u00f6ns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "$,", "ART", "ADJA", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Das ist Marie Duchatel.\u00ab", "tokens": ["Das", "ist", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "NE", "NE", "$.", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.3": {"line.1": {"text": "Marie Duchatel sprang ans Ufer,", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "sprang", "ans", "U\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Im Winde flog ihr Haar,", "tokens": ["Im", "Win\u00b7de", "flog", "ihr", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der K\u00f6nig sah Marie Duchatel", "tokens": ["Der", "K\u00f6\u00b7nig", "sah", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NE", "NE"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und wie sch\u00f6n und wie schlank sie war.", "tokens": ["Und", "wie", "sch\u00f6n", "und", "wie", "schlank", "sie", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "KON", "PWAV", "VVFIN", "PPER", "VAFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Marie Duchatel sprang in den B\u00fcgel,", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "sprang", "in", "den", "B\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ihr Haar war blond und licht,", "tokens": ["Ihr", "Haar", "war", "blond", "und", "licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der K\u00f6nig sah Marie Duchatel,", "tokens": ["Der", "K\u00f6\u00b7nig", "sah", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die andern sah er nicht.", "tokens": ["Die", "an\u00b7dern", "sah", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Marie Duchatel sprang aus dem Sattel,", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "sprang", "aus", "dem", "Sat\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und zur Kirche schritten sie hin,", "tokens": ["Und", "zur", "Kir\u00b7che", "schrit\u00b7ten", "sie", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der K\u00f6nig sah Marie Duchatel,", "tokens": ["Der", "K\u00f6\u00b7nig", "sah", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Viel mehr als die K\u00f6nigin.", "tokens": ["Viel", "mehr", "als", "die", "K\u00f6\u00b7ni\u00b7gin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und eh' drei Wochen waren ins Land,", "tokens": ["Und", "eh'", "drei", "Wo\u00b7chen", "wa\u00b7ren", "ins", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "CARD", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da sangen sie laut und hell:", "tokens": ["Da", "san\u00b7gen", "sie", "laut", "und", "hell", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Was sind alle M\u00e4dchen am Hofe", "tokens": ["Was", "sind", "al\u00b7le", "M\u00e4d\u00b7chen", "am", "Ho\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PIAT", "NN", "APPRART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Gegen Marie Duchatel.", "tokens": ["Ge\u00b7gen", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.7": {"line.1": {"text": "Und eh' drei Monde waren ins Land,", "tokens": ["Und", "eh'", "drei", "Mon\u00b7de", "wa\u00b7ren", "ins", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "CARD", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da sangen sie, gro\u00df und klein:", "tokens": ["Da", "san\u00b7gen", "sie", ",", "gro\u00df", "und", "klein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ach, ohne Marie Duchatel", "tokens": ["Ach", ",", "oh\u00b7ne", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "KOUI", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "K\u00f6nnten wir gar nicht sein.", "tokens": ["K\u00f6nn\u00b7ten", "wir", "gar", "nicht", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Marie Duchatel, Marie Duchatel,", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", ",", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "NE", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Wolle nicht in den Garten gehn,", "tokens": ["Wol\u00b7le", "nicht", "in", "den", "Gar\u00b7ten", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Der K\u00f6nig ist da, und die Nacht ist nah,", "tokens": ["Der", "K\u00f6\u00b7nig", "ist", "da", ",", "und", "die", "Nacht", "ist", "nah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "KON", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und du kannst nicht widerstehn!", "tokens": ["Und", "du", "kannst", "nicht", "wi\u00b7der\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nun pfl\u00fccket sie heimlich vom Klosterbaum", "tokens": ["Nun", "pfl\u00fc\u00b7cket", "sie", "heim\u00b7lich", "vom", "Klos\u00b7ter\u00b7baum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und ringt ihre H\u00e4nde wund,", "tokens": ["Und", "ringt", "ih\u00b7re", "H\u00e4n\u00b7de", "wund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Doch das Leben unterm Herzen", "tokens": ["Doch", "das", "Le\u00b7ben", "un\u00b7term", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird lebendiger jede Stund'.", "tokens": ["Wird", "le\u00b7ben\u00b7di\u00b7ger", "je\u00b7de", "Stund'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PIAT", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Und endlich hinaus zum Strande", "tokens": ["Und", "end\u00b7lich", "hin\u00b7aus", "zum", "Stran\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APZR", "APPRART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Schleicht sie und tr\u00e4gt ihr Kind:", "tokens": ["Schleicht", "sie", "und", "tr\u00e4gt", "ihr", "Kind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbnun schwimme oder sinke!\u00ab", "tokens": ["\u00bb", "nun", "schwim\u00b7me", "o\u00b7der", "sin\u00b7ke", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "KON", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fl\u00fcstert sie in den Wind. \u2013", "tokens": ["Fl\u00fcs\u00b7tert", "sie", "in", "den", "Wind", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "+-++-+", "measure": "unknown.measure.tetra"}}, "stanza.11": {"line.1": {"text": "Am andern Morgen l\u00e4uft's auf und ab:", "tokens": ["Am", "an\u00b7dern", "Mor\u00b7gen", "l\u00e4uft's", "auf", "und", "ab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbwisset ihr, was geschah?", "tokens": ["\u00bb", "wis\u00b7set", "ihr", ",", "was", "ge\u00b7schah", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Marie Duchatel hat ein Kleines,", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "hat", "ein", "Klei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und das Kleine ist nicht da.\u00ab", "tokens": ["Und", "das", "Klei\u00b7ne", "ist", "nicht", "da", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "VAFIN", "PTKNEG", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Und die K\u00f6nigin ruft Marie Duchatel,", "tokens": ["Und", "die", "K\u00f6\u00b7ni\u00b7gin", "ruft", "Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "NE", "NE", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Die zittert und kommt geschwind:", "tokens": ["Die", "zit\u00b7tert", "und", "kommt", "ge\u00b7schwind", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbich h\u00f6rte zu Nacht was wimmern!", "tokens": ["\u00bb", "ich", "h\u00f6r\u00b7te", "zu", "Nacht", "was", "wim\u00b7mern", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "PIS", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sag an, wo ist dein Kind?\u00ab", "tokens": ["Sag", "an", ",", "wo", "ist", "dein", "Kind", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKVZ", "$,", "PWAV", "VAFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u00bbich habe kein Kind, Mylady,", "tokens": ["\u00bb", "ich", "ha\u00b7be", "kein", "Kind", ",", "My\u00b7la\u00b7dy", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denket nicht so schlecht von mir,", "tokens": ["Den\u00b7ket", "nicht", "so", "schlecht", "von", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "ADJD", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ich hatte Stiche und Schmerzen", "tokens": ["Ich", "hat\u00b7te", "Sti\u00b7che", "und", "Schmer\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Unterm Herzen hier.\u00ab", "tokens": ["Un\u00b7term", "Her\u00b7zen", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbund hattest du Stiche und Schmerzen,", "tokens": ["\u00bb", "und", "hat\u00b7test", "du", "Sti\u00b7che", "und", "Schmer\u00b7zen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Wohlan, heut bist du gesund,", "tokens": ["Wo\u00b7hlan", ",", "heut", "bist", "du", "ge\u00b7sund", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Bring mir meinen Mantel von Scharlach,", "tokens": ["Bring", "mir", "mei\u00b7nen", "Man\u00b7tel", "von", "Schar\u00b7lach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wir reiten noch diese Stund'.", "tokens": ["Wir", "rei\u00b7ten", "noch", "die\u00b7se", "Stund'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PDAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Wir reiten von Schlo\u00df Stirling", "tokens": ["Wir", "rei\u00b7ten", "von", "Schlo\u00df", "Stir\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "NN"], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bis Edinburg ohne M\u00fch,", "tokens": ["Bis", "E\u00b7din\u00b7burg", "oh\u00b7ne", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und in Edinburg gibt's Hochzeit", "tokens": ["Und", "in", "E\u00b7din\u00b7burg", "gibt's", "Hoch\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NE", "NE", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Morgen in aller Fr\u00fch.\u00ab", "tokens": ["Mor\u00b7gen", "in", "al\u00b7ler", "Fr\u00fch", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.16": {"line.1": {"text": "Die K\u00f6nigin stieg zu Rosse,", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7gin", "stieg", "zu", "Ros\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ihre Herren und Damen mit,", "tokens": ["Ih\u00b7re", "Her\u00b7ren", "und", "Da\u00b7men", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Sie ritten all im Trabe,", "tokens": ["Sie", "rit\u00b7ten", "all", "im", "Tra\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Marie Duchatel ritt im Schritt.", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "ritt", "im", "Schritt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPRART", "NN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.17": {"line.1": {"text": "\u00bbhaltet an, liebe Herren und Damen,", "tokens": ["\u00bb", "hal\u00b7tet", "an", ",", "lie\u00b7be", "Her\u00b7ren", "und", "Da\u00b7men", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKVZ", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ich kann nicht folgen mehr!\u00ab", "tokens": ["Ich", "kann", "nicht", "fol\u00b7gen", "mehr", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie h\u00f6rten's und sprengten weiter,", "tokens": ["Sie", "h\u00f6r\u00b7ten's", "und", "spreng\u00b7ten", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PTKVZ", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie ritt seufzend hinterher.", "tokens": ["Sie", "ritt", "seuf\u00b7zend", "hin\u00b7ter\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Und als sie kam zum Tore,", "tokens": ["Und", "als", "sie", "kam", "zum", "To\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da wu\u00dften sie's schon in der Stadt,", "tokens": ["Da", "wu\u00df\u00b7ten", "sie's", "schon", "in", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Alle M\u00e4dchen und Frauen schluchzten,", "tokens": ["Al\u00b7le", "M\u00e4d\u00b7chen", "und", "Frau\u00b7en", "schluchz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Sooft sie gegr\u00fc\u00dfet hat.", "tokens": ["Sooft", "sie", "ge\u00b7gr\u00fc\u00b7\u00dfet", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "VAFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.19": {"line.1": {"text": "\u00bbwas weinet ihr, liebe Frauen?", "tokens": ["\u00bb", "was", "wei\u00b7net", "ihr", ",", "lie\u00b7be", "Frau\u00b7en", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Kommt mit, es soll Hochzeit sein.\u00ab \u2013", "tokens": ["Kommt", "mit", ",", "es", "soll", "Hoch\u00b7zeit", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPER", "VMFIN", "NN", "VAINF", "$.", "$(", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie sch\u00fcttelten ihre K\u00f6pfe", "tokens": ["Sie", "sch\u00fct\u00b7tel\u00b7ten", "ih\u00b7re", "K\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und traten ins Haus hinein. \u2013", "tokens": ["Und", "tra\u00b7ten", "ins", "Haus", "hin\u00b7ein", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Am Nordertor, wo das Zollhaus steht,", "tokens": ["Am", "Nor\u00b7der\u00b7tor", ",", "wo", "das", "Zoll\u00b7haus", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da sa\u00dfen sie zu Gericht,", "tokens": ["Da", "sa\u00b7\u00dfen", "sie", "zu", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie war erst sechzehn Jahre,", "tokens": ["Sie", "war", "erst", "sech\u00b7zehn", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es konnte sie retten nicht.", "tokens": ["Es", "konn\u00b7te", "sie", "ret\u00b7ten", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Durchs S\u00fcdertor, am andren Tag,", "tokens": ["Durchs", "S\u00fc\u00b7der\u00b7tor", ",", "am", "an\u00b7dren", "Tag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Zug und ein Karren schlich,", "tokens": ["Ein", "Zug", "und", "ein", "Kar\u00b7ren", "schlich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Marie Duchatel wollte l\u00e4cheln", "tokens": ["Ma\u00b7rie", "Duc\u00b7ha\u00b7tel", "woll\u00b7te", "l\u00e4\u00b7cheln"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und weinte doch bitterlich.", "tokens": ["Und", "wein\u00b7te", "doch", "bit\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Sie kamen an den H\u00fcgel:", "tokens": ["Sie", "ka\u00b7men", "an", "den", "H\u00fc\u00b7gel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbleb wohl, liebe K\u00f6nigin,", "tokens": ["\u00bb", "leb", "wohl", ",", "lie\u00b7be", "K\u00f6\u00b7ni\u00b7gin", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVIMP", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Von deinen vier Marien", "tokens": ["Von", "dei\u00b7nen", "vier", "Ma\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geht eine nun dahin.", "tokens": ["Geht", "ei\u00b7ne", "nun", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Oft hab' ich dich angekleidet", "tokens": ["Oft", "hab'", "ich", "dich", "an\u00b7ge\u00b7klei\u00b7det"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "VVPP"], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und dir das Bett gemacht,", "tokens": ["Und", "dir", "das", "Bett", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df es so kommen w\u00fcrde,", "tokens": ["Da\u00df", "es", "so", "kom\u00b7men", "w\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das hab' ich nie gedacht.", "tokens": ["Das", "hab'", "ich", "nie", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Oft hab' ich dir mit Goldband", "tokens": ["Oft", "hab'", "ich", "dir", "mit", "Gold\u00b7band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein Scharlachmieder ges\u00e4umt,", "tokens": ["Dein", "Schar\u00b7lach\u00b7mie\u00b7der", "ge\u00b7s\u00e4umt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Von diesem Tag und dieser Stund',", "tokens": ["Von", "die\u00b7sem", "Tag", "und", "die\u00b7ser", "Stund'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach, hab' ich nie getr\u00e4umt.", "tokens": ["Ach", ",", "hab'", "ich", "nie", "ge\u00b7tr\u00e4umt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Ihr Schiffer und ihr Matrosen,", "tokens": ["Ihr", "Schif\u00b7fer", "und", "ihr", "Mat\u00b7ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wenn ihr zu Schiffe geht,", "tokens": ["Wenn", "ihr", "zu", "Schif\u00b7fe", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erz\u00e4hlt kein Wort in Frankreich", "tokens": ["Er\u00b7z\u00e4hlt", "kein", "Wort", "in", "Fran\u00b7kreich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Von allem, was ihr nun seht.", "tokens": ["Von", "al\u00b7lem", ",", "was", "ihr", "nun", "seht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Erz\u00e4hlt nicht meiner Mutter", "tokens": ["Er\u00b7z\u00e4hlt", "nicht", "mei\u00b7ner", "Mut\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Von dem Brett, auf dem ich stand,", "tokens": ["Von", "dem", "Brett", ",", "auf", "dem", "ich", "stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nichts von meinem Tode", "tokens": ["Und", "nichts", "von", "mei\u00b7nem", "To\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und nichts von meiner Schand'.", "tokens": ["Und", "nichts", "von", "mei\u00b7ner", "Schand'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Ach, meine arme Mutter,", "tokens": ["Ach", ",", "mei\u00b7ne", "ar\u00b7me", "Mut\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als in der Wieg' ich lag", "tokens": ["Als", "in", "der", "Wieg'", "ich", "lag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "PPER", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und du mich herztest und k\u00fc\u00dftest,", "tokens": ["Und", "du", "mich", "herz\u00b7test", "und", "k\u00fc\u00df\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie fern war ", "tokens": ["Wie", "fern", "war"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}}}}}