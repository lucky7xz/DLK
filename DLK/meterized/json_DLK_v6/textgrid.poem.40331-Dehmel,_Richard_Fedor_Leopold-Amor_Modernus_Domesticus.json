{"textgrid.poem.40331": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Amor Modernus Domesticus", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Er ritt ein dunkelgraues Eselchen,", "tokens": ["Er", "ritt", "ein", "dun\u00b7kel\u00b7grau\u00b7es", "E\u00b7sel\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "zwei bunte Tiere liefen vor ihm her,", "tokens": ["zwei", "bun\u00b7te", "Tie\u00b7re", "lie\u00b7fen", "vor", "ihm", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wir konnten sie von ferne nicht erkennen.", "tokens": ["wir", "konn\u00b7ten", "sie", "von", "fer\u00b7ne", "nicht", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir gingen still durch eine stille Flur,", "tokens": ["Wir", "gin\u00b7gen", "still", "durch", "ei\u00b7ne", "stil\u00b7le", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "ich und die Frau, die mir aus Liebe treu blieb,", "tokens": ["ich", "und", "die", "Frau", ",", "die", "mir", "aus", "Lie\u00b7be", "treu", "blieb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "wir gingen langsam eine lange Stra\u00dfe.", "tokens": ["wir", "gin\u00b7gen", "lang\u00b7sam", "ei\u00b7ne", "lan\u00b7ge", "Stra\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Pappeln zeigten schon vergilbte Bl\u00e4tter,", "tokens": ["Die", "Pap\u00b7peln", "zeig\u00b7ten", "schon", "ver\u00b7gilb\u00b7te", "Bl\u00e4t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ein Dornbusch setzte neue Bl\u00fcten an,", "tokens": ["ein", "Dorn\u00b7busch", "setz\u00b7te", "neu\u00b7e", "Bl\u00fc\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der Himmel schien auf abgem\u00e4hte Wiesen", "tokens": ["der", "Him\u00b7mel", "schien", "auf", "ab\u00b7ge\u00b7m\u00e4h\u00b7te", "Wie\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und streute Schatten auf die bunten Tiere;", "tokens": ["und", "streu\u00b7te", "Schat\u00b7ten", "auf", "die", "bun\u00b7ten", "Tie\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dorfkinder trabten um das Wunder mit.", "tokens": ["Dorf\u00b7kin\u00b7der", "trab\u00b7ten", "um", "das", "Wun\u00b7der", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "Als nun aus ihrem Schwarm das Ohrensch\u00fctteln", "tokens": ["Als", "nun", "aus", "ih\u00b7rem", "Schwarm", "das", "Oh\u00b7ren\u00b7sch\u00fct\u00b7teln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "des Eselchens allm\u00e4hlich mehr hervortrat,", "tokens": ["des", "E\u00b7sel\u00b7chens", "all\u00b7m\u00e4h\u00b7lich", "mehr", "her\u00b7vor\u00b7trat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "VVFIN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.8": {"text": "erkannten wir: die Tiere hatten H\u00f6rner", "tokens": ["er\u00b7kann\u00b7ten", "wir", ":", "die", "Tie\u00b7re", "hat\u00b7ten", "H\u00f6r\u00b7ner"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "ART", "NN", "VAFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "und ihre Farben waren nicht Natur:", "tokens": ["und", "ih\u00b7re", "Far\u00b7ben", "wa\u00b7ren", "nicht", "Na\u00b7tur", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "vor einem blauget\u00fcnchten Ziegenbock", "tokens": ["vor", "ei\u00b7nem", "blau\u00b7ge\u00b7t\u00fcnch\u00b7ten", "Zie\u00b7gen\u00b7bock"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "lief eine schwarz und rot gefleckte Ziege.", "tokens": ["lief", "ei\u00b7ne", "schwarz", "und", "rot", "ge\u00b7fleck\u00b7te", "Zie\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "KON", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Der Reiter aber auf dem Eselchen", "tokens": ["Der", "Rei\u00b7ter", "a\u00b7ber", "auf", "dem", "E\u00b7sel\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "war ein entz\u00fcckend wilder schwarzer Krauskopf,", "tokens": ["war", "ein", "ent\u00b7z\u00fc\u00b7ckend", "wil\u00b7der", "schwar\u00b7zer", "Kraus\u00b7kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJD", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "und l\u00e4chelte mit jungen roten Lippen,", "tokens": ["und", "l\u00e4\u00b7chel\u00b7te", "mit", "jun\u00b7gen", "ro\u00b7ten", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "und seine blauen Augen r\u00fchrten mich.", "tokens": ["und", "sei\u00b7ne", "blau\u00b7en", "Au\u00b7gen", "r\u00fchr\u00b7ten", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Vor ihm und hinter ihm auf seinem Grauchen", "tokens": ["Vor", "ihm", "und", "hin\u00b7ter", "ihm", "auf", "sei\u00b7nem", "Grau\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "KON", "APPR", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "hing allerlei unn\u00fctzer T\u00e4ndelkram,", "tokens": ["hing", "al\u00b7ler\u00b7lei", "un\u00b7n\u00fct\u00b7zer", "T\u00e4n\u00b7del\u00b7kram", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "wie Liebesleute sich zu schenken pflegen;", "tokens": ["wie", "Lie\u00b7bes\u00b7leu\u00b7te", "sich", "zu", "schen\u00b7ken", "pfle\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PRF", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "und jedes St\u00fcck war grell in Rot und Blau", "tokens": ["und", "je\u00b7des", "St\u00fcck", "war", "grell", "in", "Rot", "und", "Blau"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADJD", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "und Schwarz mit einem Heiligenbild bemalt,", "tokens": ["und", "Schwarz", "mit", "ei\u00b7nem", "Hei\u00b7li\u00b7gen\u00b7bild", "be\u00b7malt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "ich dacht an H\u00f6lle, Himmel und den Tod.", "tokens": ["ich", "dacht", "an", "H\u00f6l\u00b7le", ",", "Him\u00b7mel", "und", "den", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Der sch\u00f6ne Junge aber nickte hold", "tokens": ["Der", "sch\u00f6\u00b7ne", "Jun\u00b7ge", "a\u00b7ber", "nick\u00b7te", "hold"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "und rief uns beiden zu: \u00bbkauft, liebe Leute!\u00ab", "tokens": ["und", "rief", "uns", "bei\u00b7den", "zu", ":", "\u00bb", "kauft", ",", "lie\u00b7be", "Leu\u00b7te", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "PTKVZ", "$.", "$(", "VVFIN", "$,", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "und hob gl\u00fcckselig seine Waare hoch.", "tokens": ["und", "hob", "gl\u00fcck\u00b7se\u00b7lig", "sei\u00b7ne", "Waa\u00b7re", "hoch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Auf einmal kam das bunte Ziegenpaar", "tokens": ["Auf", "ein\u00b7mal", "kam", "das", "bun\u00b7te", "Zie\u00b7gen\u00b7paar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit kl\u00e4glichem Gemecker angesprungen,", "tokens": ["mit", "kl\u00e4g\u00b7li\u00b7chem", "Ge\u00b7me\u00b7cker", "an\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "da\u00df sich der Kinderschwarm bei Seite dr\u00fcckte,", "tokens": ["da\u00df", "sich", "der", "Kin\u00b7der\u00b7schwarm", "bei", "Sei\u00b7te", "dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und ich erschrak bis in die Eingeweide:", "tokens": ["und", "ich", "er\u00b7schrak", "bis", "in", "die", "Ein\u00b7ge\u00b7wei\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ich sah, der sch\u00f6ne Junge war verkr\u00fcppelt.", "tokens": ["ich", "sah", ",", "der", "sch\u00f6\u00b7ne", "Jun\u00b7ge", "war", "ver\u00b7kr\u00fcp\u00b7pelt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Beine h\u00f6rten mit den Knieen auf,", "tokens": ["Die", "Bei\u00b7ne", "h\u00f6r\u00b7ten", "mit", "den", "Kni\u00b7e\u00b7en", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "die linke Hand war nur ein spitzer Stumpf,", "tokens": ["die", "lin\u00b7ke", "Hand", "war", "nur", "ein", "spit\u00b7zer", "Stumpf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "der rechten mangelte der Zeigefinger.", "tokens": ["der", "rech\u00b7ten", "man\u00b7gel\u00b7te", "der", "Zei\u00b7ge\u00b7fin\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "So sa\u00df er z\u00fcgellos auf seinem Grauchen", "tokens": ["So", "sa\u00df", "er", "z\u00fc\u00b7gel\u00b7los", "auf", "sei\u00b7nem", "Grau\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "und sch\u00fcttelte den schwarzen wilden Krauskopf", "tokens": ["und", "sch\u00fct\u00b7tel\u00b7te", "den", "schwar\u00b7zen", "wil\u00b7den", "Kraus\u00b7kopf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und hob gl\u00fcckselig seinen Kram noch h\u00f6her", "tokens": ["und", "hob", "gl\u00fcck\u00b7se\u00b7lig", "sei\u00b7nen", "Kram", "noch", "h\u00f6\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "PPOSAT", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "und sah uns r\u00fchrend und entz\u00fcckend an.", "tokens": ["und", "sah", "uns", "r\u00fch\u00b7rend", "und", "ent\u00b7z\u00fc\u00b7ckend", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Und w\u00e4hrend ich noch stand und schauderte,", "tokens": ["Und", "w\u00e4h\u00b7rend", "ich", "noch", "stand", "und", "schau\u00b7der\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "durch welch ein Unheil so entstellt sein mochte", "tokens": ["durch", "welch", "ein", "Un\u00b7heil", "so", "ent\u00b7stellt", "sein", "moch\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "ART", "NN", "ADV", "VVPP", "VAINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die Lieblichkeit und Leiblichkeit des Lebens,", "tokens": ["die", "Lieb\u00b7lich\u00b7keit", "und", "Leib\u00b7lich\u00b7keit", "des", "Le\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "sagte die Frau, die mir aus Liebe treu blieb:", "tokens": ["sag\u00b7te", "die", "Frau", ",", "die", "mir", "aus", "Lie\u00b7be", "treu", "blieb", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "ADJD", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "\u00bbder arme Bursche! wie er sich verstellt!\u00ab", "tokens": ["\u00bb", "der", "ar\u00b7me", "Bur\u00b7sche", "!", "wie", "er", "sich", "ver\u00b7stellt", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "PWAV", "PPER", "PRF", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der sch\u00f6ne Kr\u00fcppel aber l\u00e4chelte", "tokens": ["Der", "sch\u00f6\u00b7ne", "Kr\u00fcp\u00b7pel", "a\u00b7ber", "l\u00e4\u00b7chel\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und sprach: \u00bbSo wenig wie mein Eselchen!", "tokens": ["und", "sprach", ":", "\u00bb", "So", "we\u00b7nig", "wie", "mein", "E\u00b7sel\u00b7chen", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "ADV", "PIS", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "nur meine beiden Ziegen tun mir leid.\u00ab", "tokens": ["nur", "mei\u00b7ne", "bei\u00b7den", "Zie\u00b7gen", "tun", "mir", "leid", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPOSAT", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Sie fragte: \u00bbWarum dann bemalst du sie?", "tokens": ["Sie", "frag\u00b7te", ":", "\u00bb", "Wa\u00b7rum", "dann", "be\u00b7malst", "du", "sie", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWAV", "ADV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "das mu\u00df dir doch sehr gro\u00dfe M\u00fche machen;", "tokens": ["das", "mu\u00df", "dir", "doch", "sehr", "gro\u00b7\u00dfe", "M\u00fc\u00b7he", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "durch welch ein Unheil bist du so entstellt?\u00ab", "tokens": ["durch", "welch", "ein", "Un\u00b7heil", "bist", "du", "so", "ent\u00b7stellt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PWAT", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Da wurden seine roten Lippen traurig,", "tokens": ["Da", "wur\u00b7den", "sei\u00b7ne", "ro\u00b7ten", "Lip\u00b7pen", "trau\u00b7rig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "er blickte scheu auf seine Heiligenbilder", "tokens": ["er", "blick\u00b7te", "scheu", "auf", "sei\u00b7ne", "Hei\u00b7li\u00b7gen\u00b7bil\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "und sagte leise vor sich hin: \u00bb", "tokens": ["und", "sag\u00b7te", "lei\u00b7se", "vor", "sich", "hin", ":", "\u00bb"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PRF", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "die blauen Augen winkten uns Lebwohl.", "tokens": ["die", "blau\u00b7en", "Au\u00b7gen", "wink\u00b7ten", "uns", "Leb\u00b7wohl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Noch lange sahn wir in der langen Stra\u00dfe", "tokens": ["Noch", "lan\u00b7ge", "sahn", "wir", "in", "der", "lan\u00b7gen", "Stra\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "zwischen den Pappeln die Dorfkinder traben,", "tokens": ["zwi\u00b7schen", "den", "Pap\u00b7peln", "die", "Dorf\u00b7kin\u00b7der", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "und sahn sein dunkelgraues Eselchen", "tokens": ["und", "sahn", "sein", "dun\u00b7kel\u00b7grau\u00b7es", "E\u00b7sel\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und ab und zu sein buntes Ziegenpaar;", "tokens": ["und", "ab", "und", "zu", "sein", "bun\u00b7tes", "Zie\u00b7gen\u00b7paar", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKVZ", "KON", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der Himmel schien auf abgem\u00e4hte Wiesen.", "tokens": ["der", "Him\u00b7mel", "schien", "auf", "ab\u00b7ge\u00b7m\u00e4h\u00b7te", "Wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.7": {"line.1": {"text": "\u00bbpflicht\u00ab \u2013 o Schreckwort jeden \u00dcbermuts \u2013", "tokens": ["\u00bb", "pflicht", "\u00ab", "\u2013", "o", "Schreck\u00b7wort", "je\u00b7den", "\u00dc\u00b7ber\u00b7muts", "\u2013"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "$(", "FM", "NN", "PIAT", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "spukhaft fuhr mir's durch die Knochen.", "tokens": ["spuk\u00b7haft", "fuhr", "mir's", "durch", "die", "Kno\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "NE", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Stockte nicht vor lauter Pflicht mein Blut?", "tokens": ["Stock\u00b7te", "nicht", "vor", "lau\u00b7ter", "Pflicht", "mein", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Sollt ich selbst mich unterjochen?", "tokens": ["Sollt", "ich", "selbst", "mich", "un\u00b7ter\u00b7jo\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Treue \u2013 ah! du Deckwort jeder Knechtschaft \u2013", "tokens": ["Treu\u00b7e", "\u2013", "ah", "!", "du", "Deck\u00b7wort", "je\u00b7der", "Knecht\u00b7schaft", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ITJ", "$.", "PPER", "NN", "PIAT", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "w\u00fctend schlug ich's in den Wind.", "tokens": ["w\u00fc\u00b7tend", "schlug", "ich's", "in", "den", "Wind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PIS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gab mir meine Qual nicht Rechenschaft,", "tokens": ["Gab", "mir", "mei\u00b7ne", "Qual", "nicht", "Re\u00b7chen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "was f\u00fcr \u00dcbel alle Tugenden sind?!", "tokens": ["was", "f\u00fcr", "\u00dc\u00b7bel", "al\u00b7le", "Tu\u00b7gen\u00b7den", "sind", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "PIAT", "NN", "VAFIN", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.9": {"line.1": {"text": "Noch auf meinem stillen Lager heute", "tokens": ["Noch", "auf", "mei\u00b7nem", "stil\u00b7len", "La\u00b7ger", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "mahnt mich all mein reuiges Ringen", "tokens": ["mahnt", "mich", "all", "mein", "reu\u00b7i\u00b7ges", "Rin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIAT", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "an die W\u00fcstheit jener Rittersleute,", "tokens": ["an", "die", "W\u00fcst\u00b7heit", "je\u00b7ner", "Rit\u00b7ters\u00b7leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "die vor Gottgier meist zum Teufel gingen.", "tokens": ["die", "vor", "Gott\u00b7gier", "meist", "zum", "Teu\u00b7fel", "gin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Wie entraff ich mich dem heiligen Greuel?", "tokens": ["Wie", "en\u00b7traff", "ich", "mich", "dem", "hei\u00b7li\u00b7gen", "Greu\u00b7el", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Infernalisch wie ein blitzegeschw\u00e4nzter", "tokens": ["In\u00b7fer\u00b7na\u00b7lisch", "wie", "ein", "blit\u00b7ze\u00b7ge\u00b7schw\u00e4nz\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "ADJA"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Drache lockt mich meiner Zweifel Kn\u00e4uel \u2013", "tokens": ["Dra\u00b7che", "lockt", "mich", "mei\u00b7ner", "Zwei\u00b7fel", "Kn\u00e4u\u00b7el", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN", "NE", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "niemals sah ich die Nacht begl\u00e4nzter!", "tokens": ["nie\u00b7mals", "sah", "ich", "die", "Nacht", "be\u00b7gl\u00e4nz\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Glei\u00dfner ich! mit was f\u00fcr Reizen", "tokens": ["Glei\u00df\u00b7ner", "ich", "!", "mit", "was", "f\u00fcr", "Rei\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$.", "APPR", "PRELS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hab ich stets mein Bestienpack bedacht,", "tokens": ["hab", "ich", "stets", "mein", "Be\u00b7sti\u00b7en\u00b7pack", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "vor mir selber mich als Priester spreizend,", "tokens": ["vor", "mir", "sel\u00b7ber", "mich", "als", "Pries\u00b7ter", "sprei\u00b7zend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PPER", "KOUS", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "der gewaltige S\u00fcndenb\u00f6cke schlachtet!", "tokens": ["der", "ge\u00b7wal\u00b7ti\u00b7ge", "S\u00fcn\u00b7den\u00b7b\u00f6\u00b7cke", "schlach\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.12": {"line.1": {"text": "Wie empfand ich mich als Sittenr\u00e4cher,", "tokens": ["Wie", "emp\u00b7fand", "ich", "mich", "als", "Sit\u00b7ten\u00b7r\u00e4\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "KOUS", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "der den D\u00e4mon seines Bluts befriedigte,", "tokens": ["der", "den", "D\u00e4\u00b7mon", "sei\u00b7nes", "Bluts", "be\u00b7frie\u00b7dig\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "w\u00e4hrend ich, ein simpler Ehebrecher,", "tokens": ["w\u00e4h\u00b7rend", "ich", ",", "ein", "sim\u00b7pler", "E\u00b7heb\u00b7re\u00b7cher", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "mich zu dir erniedrigte,", "tokens": ["mich", "zu", "dir", "er\u00b7nied\u00b7rig\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}