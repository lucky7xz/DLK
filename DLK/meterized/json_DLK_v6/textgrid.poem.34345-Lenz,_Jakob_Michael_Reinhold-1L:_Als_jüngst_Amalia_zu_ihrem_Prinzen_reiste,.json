{"textgrid.poem.34345": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als j\u00fcngst Amalia zu ihrem Prinzen reiste,", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als j\u00fcngst Amalia zu ihrem Prinzen reiste,", "tokens": ["Als", "j\u00fcngst", "A\u00b7ma\u00b7lia", "zu", "ih\u00b7rem", "Prin\u00b7zen", "reis\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Und Vater Zevs vernahm, da\u00df sie die Nacht dort speiste:", "tokens": ["Und", "Va\u00b7ter", "Zevs", "ver\u00b7nahm", ",", "da\u00df", "sie", "die", "Nacht", "dort", "speis\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gab er dem Sonnengott, und dieser seinem Sohn", "tokens": ["Gab", "er", "dem", "Son\u00b7nen\u00b7gott", ",", "und", "die\u00b7ser", "sei\u00b7nem", "Sohn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "KON", "PDS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Ordre zur Illumination,", "tokens": ["Die", "Ord\u00b7re", "zur", "Il\u00b7lu\u00b7mi\u00b7na\u00b7ti\u00b7on", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zwar, wie man denken kann, Apoll nach langem Plagen,", "tokens": ["Zwar", ",", "wie", "man", "den\u00b7ken", "kann", ",", "A\u00b7poll", "nach", "lan\u00b7gem", "Pla\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch er war einmal nicht gemacht was abzuschlagen.", "tokens": ["Doch", "er", "war", "ein\u00b7mal", "nicht", "ge\u00b7macht", "was", "ab\u00b7zu\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKNEG", "VVPP", "PWS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Junker Pha\u00ebton versprach auf Ehre nun", "tokens": ["Und", "Jun\u00b7ker", "Pha\u00ebton", "ver\u00b7sprach", "auf", "Eh\u00b7re", "nun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Zur Rettung seines Ruhms sein Aeu\u00dferstes zu thun.", "tokens": ["Zur", "Ret\u00b7tung", "sei\u00b7nes", "Ruhms", "sein", "A\u00b7e\u00b7u\u00b7\u00dfers\u00b7tes", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Der klettert denn herum, packt Wolken aufeinander", "tokens": ["Der", "klet\u00b7tert", "denn", "he\u00b7rum", ",", "packt", "Wol\u00b7ken", "auf\u00b7ein\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "PTKVZ", "$,", "VVFIN", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df einem bang wird, kr\u00e4ngelt wie M\u00e4ander", "tokens": ["Da\u00df", "ei\u00b7nem", "bang", "wird", ",", "kr\u00e4n\u00b7gelt", "wie", "M\u00e4\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "VAFIN", "$,", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Wurst zu seinem Blitz voll Colofonium", "tokens": ["Die", "Wurst", "zu", "sei\u00b7nem", "Blitz", "voll", "Co\u00b7lo\u00b7fo\u00b7ni\u00b7um"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Um seine Donnerf\u00e4\u00dfer rum.", "tokens": ["Um", "sei\u00b7ne", "Don\u00b7ner\u00b7f\u00e4\u00b7\u00dfer", "rum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dann strich er sich das Kinn, und lehnte", "tokens": ["Dann", "strich", "er", "sich", "das", "Kinn", ",", "und", "lehn\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf eine Wolke sich voll Selbstgenu\u00df und dehnte", "tokens": ["Auf", "ei\u00b7ne", "Wol\u00b7ke", "sich", "voll", "Selbst\u00b7ge\u00b7nu\u00df", "und", "dehn\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PRF", "ADJD", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich \u00fcberm ganzen Himmelssaal,", "tokens": ["Sich", "\u00fc\u00b7berm", "gan\u00b7zen", "Him\u00b7mels\u00b7saal", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Stolz wie Apollo selbst auf Zeuxes Piedestal.", "tokens": ["Stolz", "wie", "A\u00b7pol\u00b7lo", "selbst", "auf", "Zeu\u00b7xes", "Pie\u00b7de\u00b7stal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "NE", "ADV", "APPR", "NE", "NE", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "In beiden H\u00e4nden Donnerlunten", "tokens": ["In", "bei\u00b7den", "H\u00e4n\u00b7den", "Don\u00b7ner\u00b7lun\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Guckt sorglos das Original", "tokens": ["Guckt", "sorg\u00b7los", "das", "O\u00b7rig\u00b7i\u00b7nal"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "ART", "NN"], "meter": "-+--+---", "measure": "iambic.di.relaxed"}, "line.7": {"text": "Nach der Prinzessin Wagen drunten,", "tokens": ["Nach", "der", "Prin\u00b7zes\u00b7sin", "Wa\u00b7gen", "drun\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Der L\u00e4uffer klatscht ihm das Signal.", "tokens": ["Der", "L\u00e4uf\u00b7fer", "klatscht", "ihm", "das", "Sig\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie kommt \u2013 er sieht \u2013 sie kommt \u2013 nur wieder aufzustehen", "tokens": ["Sie", "kommt", "\u2013", "er", "sieht", "\u2013", "sie", "kommt", "\u2013", "nur", "wie\u00b7der", "auf\u00b7zu\u00b7ste\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "ADV", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vergi\u00dft er als er sie gesehen,", "tokens": ["Ver\u00b7gi\u00dft", "er", "als", "er", "sie", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Er h\u00e4lt die Lunten hinterr\u00fccks", "tokens": ["Er", "h\u00e4lt", "die", "Lun\u00b7ten", "hin\u00b7ter\u00b7r\u00fccks"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An einem Blitz, und augenblicks", "tokens": ["An", "ei\u00b7nem", "Blitz", ",", "und", "au\u00b7gen\u00b7blicks"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Geht \u2013 ha mit einem erbaulichen Sto\u00df", "tokens": ["Geht", "\u2013", "ha", "mit", "ei\u00b7nem", "er\u00b7bau\u00b7li\u00b7chen", "Sto\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "NE", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Raketen, Feuerr\u00e4der und T\u00f6pfe,", "tokens": ["Ra\u00b7ke\u00b7ten", ",", "Feu\u00b7er\u00b7r\u00e4\u00b7der", "und", "T\u00f6p\u00b7fe", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Und Pulverw\u00fcrste und Katzenk\u00f6pfe,", "tokens": ["Und", "Pul\u00b7ver\u00b7w\u00fcrs\u00b7te", "und", "Kat\u00b7zen\u00b7k\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Der ganze Plunder mit einemmal lo\u00df,", "tokens": ["Der", "gan\u00b7ze", "Plun\u00b7der", "mit", "ei\u00b7nem\u00b7mal", "lo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Und schr\u00f6ckte Sch\u00f6pfer und Gesch\u00f6pfe.", "tokens": ["Und", "schr\u00f6ck\u00b7te", "Sch\u00f6p\u00b7fer", "und", "Ge\u00b7sch\u00f6p\u00b7fe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nun stelle man Vater Zevs sich vor,", "tokens": ["Nun", "stel\u00b7le", "man", "Va\u00b7ter", "Zevs", "sich", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "NE", "PRF", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem dies zum zweitenmal arrivirte,", "tokens": ["Dem", "dies", "zum", "zwei\u00b7ten\u00b7mal", "ar\u00b7ri\u00b7vir\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDS", "APPRART", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da\u00df solch ein Geck ihn kompromittirte,", "tokens": ["Da\u00df", "solch", "ein", "Geck", "ihn", "kom\u00b7pro\u00b7mit\u00b7tir\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und doch nicht die Geduld verlor.", "tokens": ["Und", "doch", "nicht", "die", "Ge\u00b7duld", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was war zu thun? die tollen Flammen", "tokens": ["Was", "war", "zu", "thun", "?", "die", "tol\u00b7len", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PTKZU", "VVINF", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Er regnete sie all zusammen,", "tokens": ["Er", "reg\u00b7ne\u00b7te", "sie", "all", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Befahl dem Junker aufzustehn,", "tokens": ["Be\u00b7fahl", "dem", "Jun\u00b7ker", "auf\u00b7zu\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Auf tausend Jahre in Arrest zu gehn,", "tokens": ["Auf", "tau\u00b7send", "Jah\u00b7re", "in", "Ar\u00b7rest", "zu", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Und gab die Consigne den himmlischen Wachen:", "tokens": ["Und", "gab", "die", "Con\u00b7sig\u00b7ne", "den", "himm\u00b7li\u00b7schen", "Wa\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-----+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Insk\u00fcnftige, wenn die Herzogin her", "tokens": ["Ins\u00b7k\u00fcnf\u00b7ti\u00b7ge", ",", "wenn", "die", "Her\u00b7zo\u00b7gin", "her"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ART", "NN", "APZR"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Von Tibur f\u00fchre, wolle Er", "tokens": ["Von", "Ti\u00b7bur", "f\u00fch\u00b7re", ",", "wol\u00b7le", "Er"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "$,", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Allzeit das Feuerwerk selber machen.", "tokens": ["All\u00b7zeit", "das", "Feu\u00b7er\u00b7werk", "sel\u00b7ber", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}