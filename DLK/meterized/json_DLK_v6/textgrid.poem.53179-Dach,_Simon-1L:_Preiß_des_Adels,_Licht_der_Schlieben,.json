{"textgrid.poem.53179": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Prei\u00df des Adels, Licht der Schlieben,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Prei\u00df des Adels, Licht der Schlieben,", "tokens": ["Prei\u00df", "des", "A\u00b7dels", ",", "Licht", "der", "Schlie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr, den meine K\u00fcnste lieben,", "tokens": ["Herr", ",", "den", "mei\u00b7ne", "K\u00fcns\u00b7te", "lie\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Al\u00df der reichlich sie begabt,", "tokens": ["Al\u00df", "der", "reich\u00b7lich", "sie", "be\u00b7gabt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "PPER", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der vnd jener wil ich heissen,", "tokens": ["Der", "vnd", "je\u00b7ner", "wil", "ich", "heis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KON", "PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo ich diesen Herbst in Preussen", "tokens": ["Wo", "ich", "die\u00b7sen", "Herbst", "in", "Preus\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PDAT", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Solchen Freund al\u00df dich gehabt.", "tokens": ["Sol\u00b7chen", "Freund", "al\u00df", "dich", "ge\u00b7habt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KOUS", "PPER", "VAPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Welchen wust ich vnter allen", "tokens": ["Wel\u00b7chen", "wust", "ich", "vn\u00b7ter", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vmb ein Rindst\u00fcck anzufallen?", "tokens": ["Vmb", "ein", "Rind\u00b7st\u00fcck", "an\u00b7zu\u00b7fal\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Abermahl kam ich zu dir,", "tokens": ["A\u00b7ber\u00b7mahl", "kam", "ich", "zu", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Liessest du nach manches Sitten", "tokens": ["Lies\u00b7sest", "du", "nach", "man\u00b7ches", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Dich nicht finden, mich lang bitten?", "tokens": ["Dich", "nicht", "fin\u00b7den", ",", "mich", "lang", "bit\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVINF", "$,", "PPER", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nein, du schickest eines mir.", "tokens": ["Nein", ",", "du", "schi\u00b7ckest", "ei\u00b7nes", "mir", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ART", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Eines, da\u00df sich seinen Klawen,", "tokens": ["Ei\u00b7nes", ",", "da\u00df", "sich", "sei\u00b7nen", "Kla\u00b7wen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PRF", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seinen H\u00f6rnern kunte trawen.", "tokens": ["Sei\u00b7nen", "H\u00f6r\u00b7nern", "kun\u00b7te", "tra\u00b7wen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.3": {"text": "O wie grewlich ging es an!", "tokens": ["O", "wie", "grew\u00b7lich", "ging", "es", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn es lie\u00df sich keinen fassen,", "tokens": ["Denn", "es", "lie\u00df", "sich", "kei\u00b7nen", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PIAT", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Tobt vnd br\u00fclte solcher massen,", "tokens": ["Tobt", "vnd", "br\u00fcl\u00b7te", "sol\u00b7cher", "mas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df ich es nicht sagen kan.", "tokens": ["Da\u00df", "ich", "es", "nicht", "sa\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.4": {"line.1": {"text": "Man hat bey den Hinterf\u00fcssen", "tokens": ["Man", "hat", "bey", "den", "Hin\u00b7ter\u00b7f\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Es mit M\u00fch emporziehn m\u00fcssen,", "tokens": ["Es", "mit", "M\u00fch", "em\u00b7por\u00b7ziehn", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVINF", "VMINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihm gegeben manchen Schlag,", "tokens": ["Ihm", "ge\u00b7ge\u00b7ben", "man\u00b7chen", "Schlag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bi\u00df da\u00df Blut herau\u00dfgesprungen,", "tokens": ["Bi\u00df", "da\u00df", "Blut", "her\u00b7au\u00df\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Eh es endlich wurd bezwungen,", "tokens": ["Eh", "es", "end\u00b7lich", "wurd", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df der Schl\u00e4chter selbst erschrack.", "tokens": ["Da\u00df", "der", "Schl\u00e4ch\u00b7ter", "selbst", "er\u00b7schrack", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Aber fett vnd au\u00dferlesen", "tokens": ["A\u00b7ber", "fett", "vnd", "au\u00b7\u00dfer\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist darnach sein Fleisch gewesen.", "tokens": ["Ist", "dar\u00b7nach", "sein", "Fleisch", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "PPOSAT", "NN", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ich, Herr, dir dancken soll,", "tokens": ["Weil", "ich", ",", "Herr", ",", "dir", "dan\u00b7cken", "soll", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "NN", "$,", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil ich werde sein geniessen,", "tokens": ["Weil", "ich", "wer\u00b7de", "sein", "ge\u00b7nies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "PPOSAT", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Heb ich an bey iedem Bissen:", "tokens": ["Heb", "ich", "an", "bey", "ie\u00b7dem", "Bis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "APPR", "PIAT", "NN", "$."], "meter": "+-+++-+-", "measure": "unknown.measure.penta"}, "line.6": {"text": "Vnserm Hauptmann geh es wol!", "tokens": ["Vn\u00b7serm", "Haupt\u00b7mann", "geh", "es", "wol", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}