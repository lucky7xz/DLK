{"textgrid.poem.42803": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Meditation", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wolleball hie\u00df ein kleiner Hund,", "tokens": ["Wol\u00b7le\u00b7ball", "hie\u00df", "ein", "klei\u00b7ner", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "\u00dcber den ein jeder lachte,", "tokens": ["\u00dc\u00b7ber", "den", "ein", "je\u00b7der", "lach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er keine Beine hatte und", "tokens": ["Weil", "er", "kei\u00b7ne", "Bei\u00b7ne", "hat\u00b7te", "und"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "KON"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "So viel s\u00fc\u00dfe Schweinereien machte.", "tokens": ["So", "viel", "s\u00fc\u00b7\u00dfe", "Schwei\u00b7ne\u00b7rei\u00b7en", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Warum ist man \u00fcberall geniert?", "tokens": ["Wa\u00b7rum", "ist", "man", "\u00fc\u00b7be\u00b7rall", "ge\u00b7niert", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Warum darf man nicht die Wahrheit sagen?", "tokens": ["Wa\u00b7rum", "darf", "man", "nicht", "die", "Wahr\u00b7heit", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Warum reden Menschen so geziert,", "tokens": ["Wa\u00b7rum", "re\u00b7den", "Men\u00b7schen", "so", "ge\u00b7ziert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NN", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn sie ein Bein \u00fcbers andre schlagen?", "tokens": ["Wenn", "sie", "ein", "Bein", "\u00fc\u00b7bers", "and\u00b7re", "schla\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "PIS", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Um dies \u00fcbersch\u00e4tzte homo sum", "tokens": ["Um", "dies", "\u00fc\u00b7bersc\u00b7h\u00e4tz\u00b7te", "ho\u00b7mo", "sum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "PDS", "VVFIN", "NE", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Werd' ich t\u00e4glich wirrer und bezechter.", "tokens": ["Werd'", "ich", "t\u00e4g\u00b7lich", "wir\u00b7rer", "und", "be\u00b7zech\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Ach, die Schlechtigkeit ist gar zu dumm,", "tokens": ["Ach", ",", "die", "Schlech\u00b7tig\u00b7keit", "ist", "gar", "zu", "dumm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Doch die Dummheit ist noch zehnmal schlechter.", "tokens": ["Doch", "die", "Dumm\u00b7heit", "ist", "noch", "zehn\u00b7mal", "schlech\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Hat der Wolleball von seinem Herrn", "tokens": ["Hat", "der", "Wol\u00b7le\u00b7ball", "von", "sei\u00b7nem", "Herrn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Nichts gewu\u00dft, nur Launen mitempfunden,", "tokens": ["Nichts", "ge\u00b7wu\u00dft", ",", "nur", "Lau\u00b7nen", "mi\u00b7temp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "$,", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Hatte der ihn andrerseits sehr gern", "tokens": ["Hat\u00b7te", "der", "ihn", "an\u00b7drer\u00b7seits", "sehr", "gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "PPER", "ADV", "ADV", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und verstand im Grunde nichts von Hunden.", "tokens": ["Und", "ver\u00b7stand", "im", "Grun\u00b7de", "nichts", "von", "Hun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PIS", "APPR", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Er ist tot, auf den ich solches dichte.", "tokens": ["Er", "ist", "tot", ",", "auf", "den", "ich", "sol\u00b7ches", "dich\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "$,", "APPR", "PRELS", "PPER", "PIAT", "ADJA", "$."], "meter": "---+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mir ist Wurscht, wo sein Gebein jetzt ruht.", "tokens": ["Mir", "ist", "Wurscht", ",", "wo", "sein", "Ge\u00b7bein", "jetzt", "ruht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "PWAV", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Aber die Pointe der Geschichte", "tokens": ["A\u00b7ber", "die", "Poin\u00b7te", "der", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Mu\u00df ich sagen: Er war herzensgut.", "tokens": ["Mu\u00df", "ich", "sa\u00b7gen", ":", "Er", "war", "her\u00b7zens\u00b7gut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$.", "PPER", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Und sein Wolleball war gut. Er grollte", "tokens": ["Und", "sein", "Wol\u00b7le\u00b7ball", "war", "gut", ".", "Er", "groll\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "$.", "PPER", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Nie. Ein einzig Mal nur bi\u00df", "tokens": ["Nie", ".", "Ein", "ein\u00b7zig", "Mal", "nur", "bi\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ART", "ADJD", "NN", "ADV", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er nach mir, als ich verhindern wollte,", "tokens": ["Er", "nach", "mir", ",", "als", "ich", "ver\u00b7hin\u00b7dern", "woll\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Da\u00df er wieder in die Hausschuh schi\u00df.", "tokens": ["Da\u00df", "er", "wie\u00b7der", "in", "die", "Haus\u00b7schuh", "schi\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}