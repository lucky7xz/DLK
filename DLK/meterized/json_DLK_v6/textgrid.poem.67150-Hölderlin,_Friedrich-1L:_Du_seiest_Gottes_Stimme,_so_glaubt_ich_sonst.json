{"textgrid.poem.67150": {"metadata": {"author": {"name": "H\u00f6lderlin, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du seiest Gottes Stimme, so glaubt ich sonst", "genre": "verse", "period": "N.A.", "pub_year": 1801, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du seiest Gottes Stimme, so glaubt ich sonst", "tokens": ["Du", "sei\u00b7est", "Got\u00b7tes", "Stim\u00b7me", ",", "so", "glaubt", "ich", "sonst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "NN", "$,", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In heilger Jugend; ja, und ich sag es noch!", "tokens": ["In", "heil\u00b7ger", "Ju\u00b7gend", ";", "ja", ",", "und", "ich", "sag", "es", "noch", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "PTKANT", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Um unsre Weisheit unbek\u00fcmmert", "tokens": ["Um", "uns\u00b7re", "Weis\u00b7heit", "un\u00b7be\u00b7k\u00fcm\u00b7mert"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Rauschen die Str\u00f6me doch auch, und dennoch,", "tokens": ["Rau\u00b7schen", "die", "Str\u00f6\u00b7me", "doch", "auch", ",", "und", "den\u00b7noch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "ADV", "$,", "KON", "ADV", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.2": {"line.1": {"text": "Wer liebt sie nicht? und immer bewegen sie", "tokens": ["Wer", "liebt", "sie", "nicht", "?", "und", "im\u00b7mer", "be\u00b7we\u00b7gen", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PTKNEG", "$.", "KON", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Herz mir, h\u00f6r ich ferne die Schwindenden,", "tokens": ["Das", "Herz", "mir", ",", "h\u00f6r", "ich", "fer\u00b7ne", "die", "Schwin\u00b7den\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "$,", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Ahnungsvollen meine Bahn nicht,", "tokens": ["Die", "Ah\u00b7nungs\u00b7vol\u00b7len", "mei\u00b7ne", "Bahn", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aber gewisser ins Meer hin eilen.", "tokens": ["A\u00b7ber", "ge\u00b7wis\u00b7ser", "ins", "Meer", "hin", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Denn selbstvergessen, allzubereit, den Wunsch", "tokens": ["Denn", "selbst\u00b7ver\u00b7ges\u00b7sen", ",", "all\u00b7zu\u00b7be\u00b7reit", ",", "den", "Wunsch"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVINF", "$,", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der G\u00f6tter zu erf\u00fcllen, ergreift zu gern,", "tokens": ["Der", "G\u00f6t\u00b7ter", "zu", "er\u00b7f\u00fcl\u00b7len", ",", "er\u00b7greift", "zu", "gern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "VVFIN", "APPR", "ADV", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was sterblich ist, wenn offnen Augs auf", "tokens": ["Was", "sterb\u00b7lich", "ist", ",", "wenn", "off\u00b7nen", "Augs", "auf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "KOUS", "ADJA", "NN", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Eigenen Pfaden es einmal wandelt,", "tokens": ["Ei\u00b7ge\u00b7nen", "Pfa\u00b7den", "es", "ein\u00b7mal", "wan\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Ins All zur\u00fcck die k\u00fcrzeste Bahn; so st\u00fcrzt", "tokens": ["Ins", "All", "zu\u00b7r\u00fcck", "die", "k\u00fcr\u00b7zes\u00b7te", "Bahn", ";", "so", "st\u00fcrzt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "ART", "ADJA", "NN", "$.", "ADV", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Strom hinab, er suchet die Ruh, es rei\u00dft,", "tokens": ["Der", "Strom", "hin\u00b7ab", ",", "er", "su\u00b7chet", "die", "Ruh", ",", "es", "rei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Es ziehet wider Willen ihn, von", "tokens": ["Es", "zie\u00b7het", "wi\u00b7der", "Wil\u00b7len", "ihn", ",", "von"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PPER", "$,", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Klippe zu Klippe, den Steuerlosen,", "tokens": ["Klip\u00b7pe", "zu", "Klip\u00b7pe", ",", "den", "Steu\u00b7er\u00b7lo\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ART", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Das wunderbare Sehnen dem Abgrund zu;", "tokens": ["Das", "wun\u00b7der\u00b7ba\u00b7re", "Seh\u00b7nen", "dem", "Ab\u00b7grund", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Ungebundne reizet und V\u00f6lker auch", "tokens": ["Das", "Un\u00b7ge\u00b7bund\u00b7ne", "rei\u00b7zet", "und", "V\u00f6l\u00b7ker", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KON", "NN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ergreift die Todeslust und k\u00fchne", "tokens": ["Er\u00b7greift", "die", "To\u00b7des\u00b7lust", "und", "k\u00fch\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "St\u00e4dte, nachdem sie versucht das Beste,", "tokens": ["St\u00e4d\u00b7te", ",", "nach\u00b7dem", "sie", "ver\u00b7sucht", "das", "Bes\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Von Jahr zu Jahr forttreibend das Werk, sie hat", "tokens": ["Von", "Jahr", "zu", "Jahr", "fort\u00b7trei\u00b7bend", "das", "Werk", ",", "sie", "hat"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN", "VVPP", "ART", "NN", "$,", "PPER", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ein heilig Ende troffen; die Erde gr\u00fcnt", "tokens": ["Ein", "hei\u00b7lig", "En\u00b7de", "trof\u00b7fen", ";", "die", "Er\u00b7de", "gr\u00fcnt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und stille vor den Sternen liegt, den", "tokens": ["Und", "stil\u00b7le", "vor", "den", "Ster\u00b7nen", "liegt", ",", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$,", "ART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Betenden gleich, in den Sand geworfen,", "tokens": ["Be\u00b7ten\u00b7den", "gleich", ",", "in", "den", "Sand", "ge\u00b7wor\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Freiwillig \u00fcberwunden die lange Kunst", "tokens": ["Frei\u00b7wil\u00b7lig", "\u00fc\u00b7berw\u00b7un\u00b7den", "die", "lan\u00b7ge", "Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVPP", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vor jenen Unnachahmbaren da; er selbst,", "tokens": ["Vor", "je\u00b7nen", "Un\u00b7nac\u00b7hahm\u00b7ba\u00b7ren", "da", ";", "er", "selbst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$.", "PPER", "ADV", "$,"], "meter": "-+----+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Der Mensch, mit eigner Hand zerbrach, die", "tokens": ["Der", "Mensch", ",", "mit", "eig\u00b7ner", "Hand", "zer\u00b7brach", ",", "die"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,", "PRELS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hohen zu ehren, sein Werk, der K\u00fcnstler.", "tokens": ["Ho\u00b7hen", "zu", "eh\u00b7ren", ",", "sein", "Werk", ",", "der", "K\u00fcnst\u00b7ler", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "PTKZU", "VVINF", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Doch minder nicht sind jene den Menschen hold,", "tokens": ["Doch", "min\u00b7der", "nicht", "sind", "je\u00b7ne", "den", "Men\u00b7schen", "hold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "VAFIN", "PDS", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sie lieben wieder, so wie geliebt sie sind,", "tokens": ["Sie", "lie\u00b7ben", "wie\u00b7der", ",", "so", "wie", "ge\u00b7liebt", "sie", "sind", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "KOKOM", "VVPP", "PPER", "VAFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und hemmen \u00f6fters, da\u00df er lang im", "tokens": ["Und", "hem\u00b7men", "\u00f6f\u00b7ters", ",", "da\u00df", "er", "lang", "im"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "ADJD", "APPRART"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lichte sich freue, die Bahn des Menschen.", "tokens": ["Lich\u00b7te", "sich", "freu\u00b7e", ",", "die", "Bahn", "des", "Men\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "VVFIN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Und, nicht des Adlers Jungen allein, sie wirft", "tokens": ["Und", ",", "nicht", "des", "Ad\u00b7lers", "Jun\u00b7gen", "al\u00b7lein", ",", "sie", "wirft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "PTKNEG", "ART", "ADJA", "NN", "ADV", "$,", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Vater aus dem Neste, damit sie nicht", "tokens": ["Der", "Va\u00b7ter", "aus", "dem", "Nes\u00b7te", ",", "da\u00b7mit", "sie", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "PTKNEG"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Zu lang ihm bleiben, uns auch treibt mit", "tokens": ["Zu", "lang", "ihm", "blei\u00b7ben", ",", "uns", "auch", "treibt", "mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKA", "ADJD", "PPER", "VVINF", "$,", "PPER", "ADV", "VVFIN", "APPR"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Richtigem Stachel hinaus der Herrscher.", "tokens": ["Rich\u00b7ti\u00b7gem", "Sta\u00b7chel", "hin\u00b7aus", "der", "Herr\u00b7scher", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APZR", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.10": {"line.1": {"text": "Wohl jenen, die zur Ruhe gegangen sind,", "tokens": ["Wohl", "je\u00b7nen", ",", "die", "zur", "Ru\u00b7he", "ge\u00b7gan\u00b7gen", "sind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "$,", "PRELS", "APPRART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und vor der Zeit gefallen, auch die, auch die", "tokens": ["Und", "vor", "der", "Zeit", "ge\u00b7fal\u00b7len", ",", "auch", "die", ",", "auch", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "ADV", "ART", "$,", "ADV", "ART"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geopfert, gleich den Erstlingen der", "tokens": ["Ge\u00b7o\u00b7pfert", ",", "gleich", "den", "Erst\u00b7lin\u00b7gen", "der"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "ADV", "ART", "NN", "ART"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ernte, sie haben ein Teil gefunden.", "tokens": ["Ern\u00b7te", ",", "sie", "ha\u00b7ben", "ein", "Teil", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.11": {"line.1": {"text": "Am Xanthos lag, in griechischer Zeit, die Stadt,", "tokens": ["Am", "Xan\u00b7thos", "lag", ",", "in", "grie\u00b7chi\u00b7scher", "Zeit", ",", "die", "Stadt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NE", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Jetzt aber, gleich den gr\u00f6\u00dferen, die dort ruhn,", "tokens": ["Jetzt", "a\u00b7ber", ",", "gleich", "den", "gr\u00f6\u00b7\u00dfe\u00b7ren", ",", "die", "dort", "ruhn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "ART", "ADJA", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Ist durch ein Schicksal sie dem heilgen", "tokens": ["Ist", "durch", "ein", "Schick\u00b7sal", "sie", "dem", "heil\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Lichte des Tages hinweggekommen.", "tokens": ["Lich\u00b7te", "des", "Ta\u00b7ges", "hin\u00b7weg\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.12": {"line.1": {"text": "Sie kamen aber, nicht in der offnen Schlacht,", "tokens": ["Sie", "ka\u00b7men", "a\u00b7ber", ",", "nicht", "in", "der", "off\u00b7nen", "Schlacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch eigne Hand um. F\u00fcrchterlich ist davon,", "tokens": ["Durch", "eig\u00b7ne", "Hand", "um", ".", "F\u00fcrch\u00b7ter\u00b7lich", "ist", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$.", "ADJD", "VAFIN", "PAV", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Was dort geschehn, die wunderbare", "tokens": ["Was", "dort", "ge\u00b7schehn", ",", "die", "wun\u00b7der\u00b7ba\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ADV", "VVPP", "$,", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sage von Osten zu uns gelanget.", "tokens": ["Sa\u00b7ge", "von", "Os\u00b7ten", "zu", "uns", "ge\u00b7lan\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.13": {"line.1": {"text": "Es reizte sie die G\u00fcte von Brutus. Denn", "tokens": ["Es", "reiz\u00b7te", "sie", "die", "G\u00fc\u00b7te", "von", "Bru\u00b7tus", ".", "Denn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "NE", "$.", "KON"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als Feuer ausgegangen, so bot er sich,", "tokens": ["Als", "Feu\u00b7er", "aus\u00b7ge\u00b7gan\u00b7gen", ",", "so", "bot", "er", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,", "ADV", "VVFIN", "PPER", "PRF", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Zu helfen ihnen, ob er gleich, als Feldherr,", "tokens": ["Zu", "hel\u00b7fen", "ih\u00b7nen", ",", "ob", "er", "gleich", ",", "als", "Feld\u00b7herr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "$,", "KOUS", "PPER", "ADV", "$,", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Stand in Belagerung vor den Toren.", "tokens": ["Stand", "in", "Be\u00b7la\u00b7ge\u00b7rung", "vor", "den", "To\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Doch von den Mauern warfen die Diener sie,", "tokens": ["Doch", "von", "den", "Mau\u00b7ern", "war\u00b7fen", "die", "Die\u00b7ner", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die er gesandt. Lebendiger ward darauf", "tokens": ["Die", "er", "ge\u00b7sandt", ".", "Le\u00b7ben\u00b7di\u00b7ger", "ward", "da\u00b7rauf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "VVPP", "$.", "NN", "VAFIN", "PAV"], "meter": "+--++-+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Das Feuer und sie freuten sich und ihnen", "tokens": ["Das", "Feu\u00b7er", "und", "sie", "freu\u00b7ten", "sich", "und", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "PPER", "VVFIN", "PRF", "KON", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Strecket' entgegen die H\u00e4nde Brutus", "tokens": ["Stre\u00b7cket'", "ent\u00b7ge\u00b7gen", "die", "H\u00e4n\u00b7de", "Bru\u00b7tus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "NE"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.15": {"line.1": {"text": "Und alle waren au\u00dfer sich selbst. Geschrei", "tokens": ["Und", "al\u00b7le", "wa\u00b7ren", "au\u00b7\u00dfer", "sich", "selbst", ".", "Ge\u00b7schrei"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "VAFIN", "APPR", "PRF", "ADV", "$.", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Entstand und Jauchzen. Drauf in die Flamme warf", "tokens": ["Ent\u00b7stand", "und", "Jauch\u00b7zen", ".", "Drauf", "in", "die", "Flam\u00b7me", "warf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "PAV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sich Mann und Weib, von Knaben st\u00fcrzt' auch", "tokens": ["Sich", "Mann", "und", "Weib", ",", "von", "Kna\u00b7ben", "st\u00fcrzt'", "auch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "NN", "KON", "NN", "$,", "APPR", "NN", "VVFIN", "ADV"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "Der von dem Dach, in der V\u00e4ter Schwert der.", "tokens": ["Der", "von", "dem", "Dach", ",", "in", "der", "V\u00e4\u00b7ter", "Schwert", "der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "NN", "ART", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.16": {"line.1": {"text": "Nicht r\u00e4tlich ist es, Helden zu trotzen. L\u00e4ngst", "tokens": ["Nicht", "r\u00e4t\u00b7lich", "ist", "es", ",", "Hel\u00b7den", "zu", "trot\u00b7zen", ".", "L\u00e4ngst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PTKNEG", "ADJD", "VAFIN", "PPER", "$,", "NN", "PTKZU", "VVINF", "$.", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wars aber vorbereitet. Die V\u00e4ter auch,", "tokens": ["Wars", "a\u00b7ber", "vor\u00b7be\u00b7rei\u00b7tet", ".", "Die", "V\u00e4\u00b7ter", "auch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "$.", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Da sie ergriffen waren, einst, und", "tokens": ["Da", "sie", "er\u00b7grif\u00b7fen", "wa\u00b7ren", ",", "einst", ",", "und"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "ADV", "$,", "KON"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Heftig die persischen Feinde dr\u00e4ngten,", "tokens": ["Hef\u00b7tig", "die", "per\u00b7si\u00b7schen", "Fein\u00b7de", "dr\u00e4ng\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.17": {"line.1": {"text": "Entz\u00fcndeten, ergreifend des Stromes Rohr,", "tokens": ["Ent\u00b7z\u00fcn\u00b7de\u00b7ten", ",", "er\u00b7grei\u00b7fend", "des", "Stro\u00b7mes", "Rohr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJD", "ART", "NN", "NN", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df sie das Freie f\u00e4nden, die Stadt. Und Haus", "tokens": ["Da\u00df", "sie", "das", "Frei\u00b7e", "f\u00e4n\u00b7den", ",", "die", "Stadt", ".", "Und", "Haus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "ART", "NN", "$.", "KON", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und Tempel nahm, zum heilgen Aether", "tokens": ["Und", "Tem\u00b7pel", "nahm", ",", "zum", "heil\u00b7gen", "A\u00b7e\u00b7ther"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.4": {"text": "Fliegend, und Menschen hinweg die Flamme.", "tokens": ["Flie\u00b7gend", ",", "und", "Men\u00b7schen", "hin\u00b7weg", "die", "Flam\u00b7me", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KON", "NN", "APZR", "ART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.18": {"line.1": {"text": "So hatten es die Kinder geh\u00f6rt, und wohl", "tokens": ["So", "hat\u00b7ten", "es", "die", "Kin\u00b7der", "ge\u00b7h\u00f6rt", ",", "und", "wohl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVFIN", "$,", "KON", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sind gut die Sagen, denn ein Ged\u00e4chtnis sind", "tokens": ["Sind", "gut", "die", "Sa\u00b7gen", ",", "denn", "ein", "Ge\u00b7d\u00e4cht\u00b7nis", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "ART", "NN", "$,", "KON", "ART", "NN", "VAFIN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Dem H\u00f6chsten sie, doch auch bedarf es", "tokens": ["Dem", "H\u00f6chs\u00b7ten", "sie", ",", "doch", "auch", "be\u00b7darf", "es"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "$,", "ADV", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Eines, die heiligen auszulegen.", "tokens": ["Ei\u00b7nes", ",", "die", "hei\u00b7li\u00b7gen", "aus\u00b7zu\u00b7le\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "ART", "ADJA", "VVIZU", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}}}}