{"textgrid.poem.37135": {"metadata": {"author": {"name": "Boie, Heinrich Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das Magisterexamen", "genre": "verse", "period": "N.A.", "pub_year": 1775, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Zier der Universit\u00e4t,", "tokens": ["Die", "Zier", "der", "U\u00b7niv\u00b7er\u00b7si\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob an der Sal', ob an der Leine?", "tokens": ["Ob", "an", "der", "Sal'", ",", "ob", "an", "der", "Lei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Trat aus der Weisheit Lorbeerhaine", "tokens": ["Trat", "aus", "der", "Weis\u00b7heit", "Lor\u00b7beer\u00b7hai\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vor eine weise Fakult\u00e4t,", "tokens": ["Vor", "ei\u00b7ne", "wei\u00b7se", "Fa\u00b7kul\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df sie sein Geld geh\u00f6rig w\u00e4ge", "tokens": ["Da\u00df", "sie", "sein", "Geld", "ge\u00b7h\u00f6\u00b7rig", "w\u00e4\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und zum Magister dann ihn pr\u00e4ge.", "tokens": ["Und", "zum", "Ma\u00b7gis\u00b7ter", "dann", "ihn", "pr\u00e4\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gepr\u00fcft nun in Philosophie,", "tokens": ["Ge\u00b7pr\u00fcft", "nun", "in", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Humanit\u00e4t, Statistik, Ethik,", "tokens": ["Hu\u00b7ma\u00b7ni\u00b7t\u00e4t", ",", "Sta\u00b7tis\u00b7tik", ",", "E\u00b7thik", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Heraldik, Kunstgeschicht', Aesthetik,", "tokens": ["Her\u00b7al\u00b7dik", ",", "Kunst\u00b7ge\u00b7schicht'", ",", "A\u00b7e\u00b7sthe\u00b7tik", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Und Algebra und Alchymie", "tokens": ["Und", "Al\u00b7ge\u00b7bra", "und", "Al\u00b7chy\u00b7mie"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Wi\u00dfenschaften aller Klassen,", "tokens": ["Und", "Wi\u00b7\u00dfen\u00b7schaf\u00b7ten", "al\u00b7ler", "Klas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ward er mit gro\u00dfem Ruhm entla\u00dfen;", "tokens": ["Ward", "er", "mit", "gro\u00b7\u00dfem", "Ruhm", "ent\u00b7la\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Als mit der Frag ein Schalk ihm naht:", "tokens": ["Als", "mit", "der", "Frag", "ein", "Schalk", "ihm", "naht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbsag uns, der alles wei\u00df und kennet,", "tokens": ["\u00bb", "sag", "uns", ",", "der", "al\u00b7les", "wei\u00df", "und", "ken\u00b7net", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "$,", "PRELS", "PIS", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Woran wird attisch Salz erkennet?\u00ab", "tokens": ["Wo\u00b7ran", "wird", "at\u00b7tisch", "Salz", "er\u00b7ken\u00b7net", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "ADJD", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit L\u00e4cheln drauf der Kanditat:", "tokens": ["Mit", "L\u00e4\u00b7cheln", "drauf", "der", "Kan\u00b7di\u00b7tat", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u00bbach dessen fiel mir in die Feder", "tokens": ["\u00bb", "ach", "des\u00b7sen", "fiel", "mir", "in", "die", "Fe\u00b7der"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "XY", "PDS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kein Wort von keinerlei Katheder.\u00ab", "tokens": ["Kein", "Wort", "von", "kei\u00b7ner\u00b7lei", "Ka\u00b7the\u00b7der", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}