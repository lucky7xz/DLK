{"textgrid.poem.53416": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Herr deine Treu und G\u00fcte reicht,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herr deine Treu und G\u00fcte reicht,", "tokens": ["Herr", "dei\u00b7ne", "Treu", "und", "G\u00fc\u00b7te", "reicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So weit des Himmels Umbfang streicht,", "tokens": ["So", "weit", "des", "Him\u00b7mels", "Umb\u00b7fang", "streicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer kan sie gnug erheben?", "tokens": ["Wer", "kan", "sie", "gnug", "er\u00b7he\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hat uns an di\u00df Licht gebracht", "tokens": ["Sie", "hat", "uns", "an", "di\u00df", "Licht", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "PDS", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und gnug mit alle dem bedacht,", "tokens": ["Und", "gnug", "mit", "al\u00b7le", "dem", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was n\u00f6thig ist dem Leben.", "tokens": ["Was", "n\u00f6\u00b7thig", "ist", "dem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Sie decket unsre S\u00fcnden zu,", "tokens": ["Sie", "de\u00b7cket", "uns\u00b7re", "S\u00fcn\u00b7den", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hat die s\u00fcsse Seelen-Ruh", "tokens": ["Sie", "hat", "die", "s\u00fcs\u00b7se", "See\u00b7len\u00b7Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Christo uns ertheilet:", "tokens": ["In", "Chris\u00b7to", "uns", "er\u00b7thei\u00b7let", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wer an ihn gl\u00e4ubt in wahrer Reu,", "tokens": ["Wer", "an", "ihn", "gl\u00e4ubt", "in", "wah\u00b7rer", "Reu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "VVFIN", "APPR", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bek\u00f6mmt die kr\u00e4fftig Artzeney,", "tokens": ["Be\u00b7k\u00f6mmt", "die", "kr\u00e4ff\u00b7tig", "Art\u00b7ze\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die sein Gewissen heilet.", "tokens": ["Die", "sein", "Ge\u00b7wis\u00b7sen", "hei\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Durch die getrieben hast du mich", "tokens": ["Durch", "die", "ge\u00b7trie\u00b7ben", "hast", "du", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "VVPP", "VAFIN", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Leib und Seele V\u00e4terlich", "tokens": ["Mit", "Leib", "und", "See\u00b7le", "V\u00e4\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch diese Nacht beh\u00fctet,", "tokens": ["Auch", "die\u00b7se", "Nacht", "be\u00b7h\u00fc\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die b\u00f6sen Zuf\u00e4ll abgekehrt", "tokens": ["Die", "b\u00f6\u00b7sen", "Zu\u00b7f\u00e4ll", "ab\u00b7ge\u00b7kehrt"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und aller H\u00f6llen Sturm gewehrt,", "tokens": ["Und", "al\u00b7ler", "H\u00f6l\u00b7len", "Sturm", "ge\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie grausam er gew\u00fctet.", "tokens": ["Wie", "grau\u00b7sam", "er", "ge\u00b7w\u00fc\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Dieweil doch ja der arge Feind", "tokens": ["Die\u00b7weil", "doch", "ja", "der", "ar\u00b7ge", "Feind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns einig zu verschlingen meint,", "tokens": ["Uns", "ei\u00b7nig", "zu", "ver\u00b7schlin\u00b7gen", "meint", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer k\u00e4m ihm au\u00df den Klauen,", "tokens": ["Wer", "k\u00e4m", "ihm", "au\u00df", "den", "Klau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Au\u00df seiner List und gro\u00dfen Macht,", "tokens": ["Au\u00df", "sei\u00b7ner", "List", "und", "gro\u00b7\u00dfen", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn du nicht in genauer Acht", "tokens": ["Wenn", "du", "nicht", "in", "ge\u00b7nau\u00b7er", "Acht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auff uns, Herr, soltest schauen.", "tokens": ["Auff", "uns", ",", "Herr", ",", "sol\u00b7test", "schau\u00b7en", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "NN", "$,", "VMFIN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.5": {"line.1": {"text": "F\u00fcr solche Gutthat danck ich dir", "tokens": ["F\u00fcr", "sol\u00b7che", "Gut\u00b7that", "danck", "ich", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Au\u00df heisser Andacht und Begier,", "tokens": ["Au\u00df", "heis\u00b7ser", "An\u00b7dacht", "und", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wall' in tieffer H\u00f6len", "tokens": ["Ich", "wall'", "in", "tief\u00b7fer", "H\u00f6\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Des Hertzens gantz von deinem Ruhm,", "tokens": ["Des", "Hert\u00b7zens", "gantz", "von", "dei\u00b7nem", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und bringe vor dein Heiligthum", "tokens": ["Und", "brin\u00b7ge", "vor", "dein", "Hei\u00b7lig\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Abgrund meiner Seelen.", "tokens": ["Den", "Ab\u00b7grund", "mei\u00b7ner", "See\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Dich, Gott, erhebt des Himmels Heer,", "tokens": ["Dich", ",", "Gott", ",", "er\u00b7hebt", "des", "Him\u00b7mels", "Heer", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wolcken Zelt, Lufft, Erde, Meer,", "tokens": ["Der", "Wol\u00b7cken", "Zelt", ",", "Lufft", ",", "Er\u00b7de", ",", "Meer", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Feuers wilde Flammen,", "tokens": ["Des", "Feu\u00b7ers", "wil\u00b7de", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was Athem hat, mehr, Laub und Gra\u00df,", "tokens": ["Was", "A\u00b7them", "hat", ",", "mehr", ",", "Laub", "und", "Gra\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$,", "ADV", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die treten dir ohn unterla\u00df", "tokens": ["Die", "tre\u00b7ten", "dir", "ohn", "un\u00b7ter\u00b7la\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In deinen Dienst zusammen.", "tokens": ["In", "dei\u00b7nen", "Dienst", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und ich dein Bild und theures Gut,", "tokens": ["Und", "ich", "dein", "Bild", "und", "theu\u00b7res", "Gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erkaufft durch deines Sohnes Blut,", "tokens": ["Er\u00b7kaufft", "durch", "dei\u00b7nes", "Soh\u00b7nes", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich solte dich nicht preisen?", "tokens": ["Ich", "sol\u00b7te", "dich", "nicht", "prei\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schick das Verm\u00f6gen mir nur ein,", "tokens": ["Schick", "das", "Ver\u00b7m\u00f6\u00b7gen", "mir", "nur", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So solst nur du mein Dancklied seyn", "tokens": ["So", "solst", "nur", "du", "mein", "Danck\u00b7lied", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "PPER", "PPOSAT", "NN", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf den ber\u00fchmtsten Weisen.", "tokens": ["Auf", "den", "be\u00b7r\u00fchmts\u00b7ten", "Wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "F\u00fcr allem zeuch mein Hertz empor,", "tokens": ["F\u00fcr", "al\u00b7lem", "zeuch", "mein", "Hertz", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVIMP", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das sey dein bestes Lobe-Chor,", "tokens": ["Das", "sey", "dein", "bes\u00b7tes", "Lo\u00b7be\u00b7Chor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Stimm es nach deinem Willen,", "tokens": ["Stimm", "es", "nach", "dei\u00b7nem", "Wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Auff da\u00df es den zu aller Zeit,", "tokens": ["Auff", "da\u00df", "es", "den", "zu", "al\u00b7ler", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ART", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In strenger Zucht und Heiligkeit,", "tokens": ["In", "stren\u00b7ger", "Zucht", "und", "Hei\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Such eifrig zu erf\u00fcllen.", "tokens": ["Such", "eif\u00b7rig", "zu", "er\u00b7f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "La\u00df nichts mich \u00fcben diesen Tag,", "tokens": ["La\u00df", "nichts", "mich", "\u00fc\u00b7ben", "die\u00b7sen", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wider dich, Herr, lauffen mag", "tokens": ["Da\u00df", "wi\u00b7der", "dich", ",", "Herr", ",", "lauf\u00b7fen", "mag"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "$,", "NN", "$,", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wider mein Gewissen:", "tokens": ["Und", "wi\u00b7der", "mein", "Ge\u00b7wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Richt meinen Weg nach deinem Wort,", "tokens": ["Richt", "mei\u00b7nen", "Weg", "nach", "dei\u00b7nem", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit mein Nechster fort und fort", "tokens": ["Da\u00b7mit", "mein", "Nechs\u00b7ter", "fort", "und", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "NN", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein habe zu geniessen.", "tokens": ["Mein", "ha\u00b7be", "zu", "ge\u00b7nies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Mir schweb', Herr, immer vor Gesicht", "tokens": ["Mir", "schweb'", ",", "Herr", ",", "im\u00b7mer", "vor", "Ge\u00b7sicht"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "NN", "$,", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der j\u00fcngste Tag und dein Gericht,", "tokens": ["Der", "j\u00fcngs\u00b7te", "Tag", "und", "dein", "Ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Damit ich from mag leben.", "tokens": ["Da\u00b7mit", "ich", "from", "mag", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bild ein mir der Verdamten Lohn,", "tokens": ["Bild", "ein", "mir", "der", "Ver\u00b7dam\u00b7ten", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df was ich thu, ich dir davon", "tokens": ["Da\u00df", "was", "ich", "thu", ",", "ich", "dir", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PWS", "PPER", "VVFIN", "$,", "PPER", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "K\u00f6nn' allzeit Rechnung geben.", "tokens": ["K\u00f6nn'", "all\u00b7zeit", "Rech\u00b7nung", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}