{"textgrid.poem.42766": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Wettlauf", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Publikum ungeduldig scharrt \u2013", "tokens": ["Pub\u00b7li\u00b7kum", "un\u00b7ge\u00b7dul\u00b7dig", "scharrt", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Scharren lassen \u2013 hier Start \u2013", "tokens": ["Schar\u00b7ren", "las\u00b7sen", "\u2013", "hier", "Start", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$(", "ADV", "NN", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Taschentuch? keins \u2013", "tokens": ["Ta\u00b7schen\u00b7tuch", "?", "keins", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "PIAT", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Schwei\u00df \u2013", "tokens": ["Schwei\u00df", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Hei\u00df \u2013", "tokens": ["Hei\u00df", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Zum Beweis", "tokens": ["Zum", "Be\u00b7weis"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Des Nichtaufgeregtseins:", "tokens": ["Des", "Nich\u00b7tauf\u00b7ge\u00b7regt\u00b7seins", ":"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Billet Spucke kneten.", "tokens": ["Bil\u00b7let", "Spu\u00b7cke", "kne\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": "Achtung: eins!", "tokens": ["Ach\u00b7tung", ":", "eins", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "PIS", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Nicht mehr Zeit auszutreten \u2013", "tokens": ["Nicht", "mehr", "Zeit", "aus\u00b7zu\u00b7tre\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "VVFIN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Was? Rauchen verbeten? \u2013", "tokens": ["Was", "?", "Rau\u00b7chen", "ver\u00b7be\u00b7ten", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["PWS", "$.", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": "Sie da, der Dritte, weiter zur\u00fccktreten \u2013", "tokens": ["Sie", "da", ",", "der", "Drit\u00b7te", ",", "wei\u00b7ter", "zu\u00b7r\u00fcck\u00b7tre\u00b7ten", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ART", "ADJA", "$,", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Soo! \u2013 Endlich Musik \u2013", "tokens": ["Soo", "!", "\u2013", "End\u00b7lich", "Mu\u00b7sik", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "ADV", "NN", "$("], "meter": "-+---", "measure": "dactylic.init"}, "line.14": {"text": "Der bekannte", "tokens": ["Der", "be\u00b7kann\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "Augenblick,", "tokens": ["Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.16": {"text": "Wo \u2013", "tokens": ["Wo", "\u2013"], "token_info": ["word", "punct"], "pos": ["PWAV", "$("], "meter": "+", "measure": "single.up"}, "line.17": {"text": "Wenn der Trikot", "tokens": ["Wenn", "der", "Tri\u00b7kot"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.18": {"text": "Nur nicht so spannte \u2013", "tokens": ["Nur", "nicht", "so", "spann\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "VVFIN", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Schweinerei \u2013", "tokens": ["Schwei\u00b7ne\u00b7rei", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "W\u00e4re fatal \u2013", "tokens": ["W\u00e4\u00b7re", "fa\u00b7tal", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.21": {"text": "Achtung: Zwei!", "tokens": ["Ach\u00b7tung", ":", "Zwei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "CARD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.22": {"text": "Teufel nochmal!", "tokens": ["Teu\u00b7fel", "noch\u00b7mal", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "ADV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.23": {"text": "Heiliger Joseph, steh mir bei!", "tokens": ["Hei\u00b7li\u00b7ger", "Jo\u00b7se\u00b7ph", ",", "steh", "mir", "bei", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.24": {"text": "Achtung: Drei!", "tokens": ["Ach\u00b7tung", ":", "Drei", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "CARD", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.25": {"text": "Tapelti, tapelti, tapelti", "tokens": ["Ta\u00b7pel\u00b7ti", ",", "ta\u00b7pel\u00b7ti", ",", "ta\u00b7pel\u00b7ti"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "FM.la", "$,", "XY"], "meter": "-+--+----", "measure": "iambic.di.relaxed"}, "line.26": {"text": "Mut!", "tokens": ["Mut", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.27": {"text": "Gut!", "tokens": ["Gut", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+", "measure": "single.up"}, "line.28": {"text": "Kopf senken!", "tokens": ["Kopf", "sen\u00b7ken", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.29": {"text": "Arme vom Leib!", "tokens": ["Ar\u00b7me", "vom", "Leib", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.30": {"text": "Frieda denken!", "tokens": ["Frie\u00b7da", "den\u00b7ken", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.31": {"text": "Herrliches Weib!", "tokens": ["Herr\u00b7li\u00b7ches", "Weib", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.32": {"text": "Schade, da\u00df Mund stinkt!", "tokens": ["Scha\u00b7de", ",", "da\u00df", "Mund", "stinkt", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "NN", "VVFIN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.33": {"text": "Das war sie! \u2013 lacht! \u2013 winkt \u2013", "tokens": ["Das", "war", "sie", "!", "\u2013", "lacht", "!", "\u2013", "winkt", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "$.", "$(", "VVFIN", "$.", "$(", "VVFIN", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.34": {"text": "Oh, oh! Oh, oh!", "tokens": ["Oh", ",", "oh", "!", "Oh", ",", "oh", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ITJ", "$,", "FM", "$.", "ITJ", "$,", "FM", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.35": {"text": "Mein Trikot!", "tokens": ["Mein", "Tri\u00b7kot", "!"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.36": {"text": "Vorne gespalten.", "tokens": ["Vor\u00b7ne", "ge\u00b7spal\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.37": {"text": "Taschentuch vorhalten \u2013", "tokens": ["Ta\u00b7schen\u00b7tuch", "vor\u00b7hal\u00b7ten", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.38": {"text": "Jetzt Quark!", "tokens": ["Jetzt", "Quark", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.39": {"text": "Nur laufen!", "tokens": ["Nur", "lau\u00b7fen", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.40": {"text": "10 000 Mark \u2013", "tokens": ["000", "Mark", "\u2013"], "token_info": ["number", "word", "punct"], "pos": ["CARD", "NN", "$("], "meter": "+", "measure": "single.up"}, "line.41": {"text": "Wochenlang saufen \u2013", "tokens": ["Wo\u00b7chen\u00b7lang", "sau\u00b7fen", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.42": {"text": "Wenn's gl\u00fcckt \u2013", "tokens": ["Wenn's", "gl\u00fcckt", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.43": {"text": "Schulden bezahlen \u2013", "tokens": ["Schul\u00b7den", "be\u00b7zah\u00b7len", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.44": {"text": "Tante verr\u00fcckt \u2013", "tokens": ["Tan\u00b7te", "ver\u00b7r\u00fcckt", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.45": {"text": "Meyers prahlen \u2013", "tokens": ["Me\u00b7yers", "prah\u00b7len", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.46": {"text": "Sieger gratuliert \u2013", "tokens": ["Sie\u00b7ger", "gra\u00b7tu\u00b7liert", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.47": {"text": "Photographiert \u2013", "tokens": ["Pho\u00b7to\u00b7gra\u00b7phiert", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.48": {"text": "H\u00e4ndedruck \u2013", "tokens": ["H\u00e4n\u00b7de\u00b7druck", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.49": {"text": "Tun als ob schnuppe \u2013", "tokens": ["Tun", "als", "ob", "schnup\u00b7pe", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "KOUS", "VVFIN", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.50": {"text": "W\u00e4ndeschmuck \u2013", "tokens": ["W\u00e4n\u00b7de\u00b7schmuck", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.51": {"text": "Lorbeer-Suppe \u2013", "tokens": ["Lor\u00b7beer\u00b7Sup\u00b7pe", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.52": {"text": "Zeitungs-Reklame \u2013", "tokens": ["Zei\u00b7tungs\u00b7Re\u00b7kla\u00b7me", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.53": {"text": "Filmaufnahme \u2013", "tokens": ["Film\u00b7auf\u00b7nah\u00b7me", "\u2013"], "token_info": ["word", "punct"], "pos": ["NE", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.54": {"text": "Frieda seidenes Kleid \u2013", "tokens": ["Frie\u00b7da", "sei\u00b7de\u00b7nes", "Kleid", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.55": {"text": "Otto platzt Neid \u2013", "tokens": ["Ot\u00b7to", "platzt", "Neid", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.56": {"text": "Engelmann \u2013 Wut \u2013", "tokens": ["En\u00b7gel\u00b7mann", "\u2013", "Wut", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.57": {"text": "Anton \u2013 Pump \u2013", "tokens": ["An\u00b7ton", "\u2013", "Pump", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.58": {"text": "Aushalten! Mut!", "tokens": ["Aus\u00b7hal\u00b7ten", "!", "Mut", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.59": {"text": "Weg da! Lump! \u2013", "tokens": ["Weg", "da", "!", "Lump", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "PTKVZ", "$.", "NN", "$.", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.60": {"text": "Einer von beiden \u2013", "tokens": ["Ei\u00b7ner", "von", "bei\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PIAT", "$("], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.61": {"text": "Weg abschneiden \u2013", "tokens": ["Weg", "ab\u00b7schnei\u00b7den", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.62": {"text": "Puff!", "tokens": ["Puff", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+", "measure": "single.up"}, "line.63": {"text": "Was bild't sich \u2013", "tokens": ["Was", "bild't", "sich", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.64": {"text": "Uff!", "tokens": ["Uff", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.65": {"text": "Gilt nicht!", "tokens": ["Gilt", "nicht", "!"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$."], "meter": "-+", "measure": "iambic.single"}, "line.66": {"text": "Feste druff!", "tokens": ["Fes\u00b7te", "druff", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PAV", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.67": {"text": "Gar nicht k\u00fcmmern!", "tokens": ["Gar", "nicht", "k\u00fcm\u00b7mern", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.68": {"text": "Sch\u00e4del zertr\u00fcmmern!", "tokens": ["Sch\u00e4\u00b7del", "zer\u00b7tr\u00fcm\u00b7mern", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.69": {"text": "Zuchthaus \u2013", "tokens": ["Zucht\u00b7haus", "\u2013"], "token_info": ["word", "punct"], "pos": ["ADV", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.70": {"text": "Flucht \u2013 Haus \u2013", "tokens": ["Flucht", "\u2013", "Haus", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.71": {"text": "Schande \u2013", "tokens": ["Schan\u00b7de", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.72": {"text": "Tante \u2013", "tokens": ["Tan\u00b7te", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.73": {"text": "Sterben \u2013", "tokens": ["Ster\u00b7ben", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.74": {"text": "Beerben \u2013", "tokens": ["Be\u00b7er\u00b7ben", "\u2013"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.75": {"text": "Unsinn! Was Quatsch! Quatsch!", "tokens": ["Un\u00b7sinn", "!", "Was", "Quatsch", "!", "Quatsch", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "PWS", "NN", "$.", "NN", "$."], "meter": "+----", "measure": "dactylic.init"}, "line.76": {"text": "Teufel noch mal!", "tokens": ["Teu\u00b7fel", "noch", "mal", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.77": {"text": "Laternenpfahl.", "tokens": ["La\u00b7ter\u00b7nen\u00b7pfahl", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.78": {"text": "Mehr links, ach! ach!", "tokens": ["Mehr", "links", ",", "ach", "!", "ach", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ITJ", "$.", "XY", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.79": {"text": "Stopp! Frieda! Halt! Krach!", "tokens": ["Stopp", "!", "Frie\u00b7da", "!", "Halt", "!", "Krach", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$.", "NE", "$.", "NN", "$.", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.80": {"text": "Kladderadatsch!", "tokens": ["Klad\u00b7de\u00b7ra\u00b7datsch", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.81": {"text": "Kn\u00e4tsch daun! au! aus!", "tokens": ["Kn\u00e4tsch", "daun", "!", "au", "!", "aus", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVINF", "$.", "NE", "$.", "PTKVZ", "$."], "meter": "+---", "measure": "dactylic.init"}, "line.82": {"text": "Ohhhhhh! \u2013 Publikum Applaus.", "tokens": ["Ohhhhhh", "!", "\u2013", "Pub\u00b7li\u00b7kum", "Ap\u00b7plaus", "."], "token_info": ["word", "punct", "punct", "word", "word", "punct"], "pos": ["ITJ", "$.", "$(", "FM.la", "FM.la", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}