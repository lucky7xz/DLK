{"textgrid.poem.32953": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich hab getr\u00f6stet mich dar\u00fcber,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich hab getr\u00f6stet mich dar\u00fcber,", "tokens": ["Ich", "hab", "ge\u00b7tr\u00f6s\u00b7tet", "mich", "da\u00b7r\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "PRF", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ich hab's verwunden allgemach,", "tokens": ["ich", "hab's", "ver\u00b7wun\u00b7den", "all\u00b7ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und statt zu klagen, spott ich lieber ...", "tokens": ["und", "statt", "zu", "kla\u00b7gen", ",", "spott", "ich", "lie\u00b7ber", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VVINF", "$,", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "was tut es, da\u00df das Herz mir brach!", "tokens": ["was", "tut", "es", ",", "da\u00df", "das", "Herz", "mir", "brach", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich h\u00e4tt ja doch nicht halten k\u00f6nnen,", "tokens": ["Ich", "h\u00e4tt", "ja", "doch", "nicht", "hal\u00b7ten", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "was ich geglaubt, so gro\u00df es schien,", "tokens": ["was", "ich", "ge\u00b7glaubt", ",", "so", "gro\u00df", "es", "schien", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich h\u00e4tte doch mich m\u00fcssen trennen,", "tokens": ["ich", "h\u00e4t\u00b7te", "doch", "mich", "m\u00fcs\u00b7sen", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "es waren doch nur Phantasien!", "tokens": ["es", "wa\u00b7ren", "doch", "nur", "Phan\u00b7ta\u00b7si\u00b7en", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Die Augen sind mir aufgegangen,", "tokens": ["Die", "Au\u00b7gen", "sind", "mir", "auf\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und n\u00fcchterner blick ich in die Welt,", "tokens": ["und", "n\u00fcch\u00b7ter\u00b7ner", "blick", "ich", "in", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "von weniger Selbsttrug mehr befangen,", "tokens": ["von", "we\u00b7ni\u00b7ger", "Selbst\u00b7trug", "mehr", "be\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+--++--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "erkenn ich klar, was ich gefehlt:", "tokens": ["er\u00b7kenn", "ich", "klar", ",", "was", "ich", "ge\u00b7fehlt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Da\u00df Tr\u00e4ume eben doch nur Tr\u00e4ume", "tokens": ["Da\u00df", "Tr\u00e4u\u00b7me", "e\u00b7ben", "doch", "nur", "Tr\u00e4u\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "ADV", "ADV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und einzig eines Narren Gl\u00fcck! ...", "tokens": ["und", "ein\u00b7zig", "ei\u00b7nes", "Nar\u00b7ren", "Gl\u00fcck", "!", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und lachend putz in meine Reime", "tokens": ["und", "la\u00b7chend", "putz", "in", "mei\u00b7ne", "Rei\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die letzten Fetzen ich als Flick!", "tokens": ["die", "letz\u00b7ten", "Fet\u00b7zen", "ich", "als", "Flick", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "KOUS", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}