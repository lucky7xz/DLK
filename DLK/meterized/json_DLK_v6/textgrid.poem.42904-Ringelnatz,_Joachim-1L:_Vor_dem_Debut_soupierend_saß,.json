{"textgrid.poem.42904": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vor dem Debut soupierend sa\u00df,", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vor dem Debut soupierend sa\u00df,", "tokens": ["Vor", "dem", "De\u00b7but", "sou\u00b7pie\u00b7rend", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bei einer Frau, der S\u00e4nger.", "tokens": ["Bei", "ei\u00b7ner", "Frau", ",", "der", "S\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie staunte \u00fcber seinen Fra\u00df", "tokens": ["Sie", "staun\u00b7te", "\u00fc\u00b7ber", "sei\u00b7nen", "Fra\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wurde immer l\u00e4nger.", "tokens": ["Und", "wur\u00b7de", "im\u00b7mer", "l\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der S\u00e4nger auf die B\u00fchne trat,", "tokens": ["Der", "S\u00e4n\u00b7ger", "auf", "die", "B\u00fch\u00b7ne", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schlicht, ohne sich zu r\u00fchmen.", "tokens": ["Schlicht", ",", "oh\u00b7ne", "sich", "zu", "r\u00fch\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUI", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Hauch von Bier und Fleischsalat", "tokens": ["Ein", "Hauch", "von", "Bier", "und", "Fleischsa\u00b7lat"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verlor sich in Parf\u00fcmen.", "tokens": ["Ver\u00b7lor", "sich", "in", "Par\u00b7f\u00fc\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der S\u00e4nger sang das hohe C.", "tokens": ["Der", "S\u00e4n\u00b7ger", "sang", "das", "ho\u00b7he", "C."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Beifall wuchs und tobte.", "tokens": ["Der", "Bei\u00b7fall", "wuchs", "und", "tob\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Dame in der Loge B", "tokens": ["Die", "Da\u00b7me", "in", "der", "Lo\u00b7ge", "B"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Stand auf und garderobte.", "tokens": ["Stand", "auf", "und", "gar\u00b7der\u00b7ob\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der S\u00e4nger st\u00fcrzte aus dem Haus", "tokens": ["Der", "S\u00e4n\u00b7ger", "st\u00fcrz\u00b7te", "aus", "dem", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In den verschneiten Garten.", "tokens": ["In", "den", "ver\u00b7schnei\u00b7ten", "Gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Dame folgte, einen Strau\u00df", "tokens": ["Die", "Da\u00b7me", "folg\u00b7te", ",", "ei\u00b7nen", "Strau\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auspackend, voll Erwarten.", "tokens": ["Aus\u00b7pa\u00b7ckend", ",", "voll", "Er\u00b7war\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der S\u00e4nger l\u00fcpfte seinen Frack", "tokens": ["Der", "S\u00e4n\u00b7ger", "l\u00fcpf\u00b7te", "sei\u00b7nen", "Frack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und duckte sich im Garten.", "tokens": ["Und", "duck\u00b7te", "sich", "im", "Gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es klang wie \u00bbSchlacht am Skagerrak\u00ab.", "tokens": ["Es", "klang", "wie", "\u00bb", "Schlacht", "am", "Ska\u00b7ger\u00b7rak", "\u00ab", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "$(", "NN", "APPRART", "NN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Dame mu\u00dfte warten.", "tokens": ["Die", "Da\u00b7me", "mu\u00df\u00b7te", "war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Vom langen Stehn im nassen Schnee", "tokens": ["Vom", "lan\u00b7gen", "Stehn", "im", "nas\u00b7sen", "Schnee"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Holt man sich Rheumatismus. \u2013", "tokens": ["Holt", "man", "sich", "Rheu\u00b7ma\u00b7tis\u00b7mus", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "PRF", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der S\u00e4nger mit dem hohen C", "tokens": ["Der", "S\u00e4n\u00b7ger", "mit", "dem", "ho\u00b7hen", "C"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kennt seinen Mechanismus.", "tokens": ["Kennt", "sei\u00b7nen", "Me\u00b7cha\u00b7nis\u00b7mus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}