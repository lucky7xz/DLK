{"textgrid.poem.26388": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[nun will ich jene Nacht sch\u00f6n schildern]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun will ich jene Nacht sch\u00f6n schildern,", "tokens": ["Nun", "will", "ich", "je\u00b7ne", "Nacht", "sch\u00f6n", "schil\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PDAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die ich chim\u00e4risch seh' in Bildern.", "tokens": ["Die", "ich", "chi\u00b7m\u00e4\u00b7risch", "seh'", "in", "Bil\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Alles in einer Welt vergeht,", "tokens": ["Al\u00b7les", "in", "ei\u00b7ner", "Welt", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wo alles fein aus Nippes besteht.", "tokens": ["Wo", "al\u00b7les", "fein", "aus", "Nip\u00b7pes", "be\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Man wagt dort kaum daran zu r\u00fchren,", "tokens": ["Man", "wagt", "dort", "kaum", "da\u00b7ran", "zu", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcrchtend, die Dinge k\u00f6nnten's sp\u00fcren.", "tokens": ["F\u00fcrch\u00b7tend", ",", "die", "Din\u00b7ge", "k\u00f6nn\u00b7ten's", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Wie Rokokko aus Porzellan,", "tokens": ["Wie", "Ro\u00b7kok\u00b7ko", "aus", "Por\u00b7zel\u00b7lan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So zart sah sich das Mohrle an.", "tokens": ["So", "zart", "sah", "sich", "das", "Mohr\u00b7le", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und nach den weiten Globusfahrten", "tokens": ["Und", "nach", "den", "wei\u00b7ten", "Glo\u00b7bus\u00b7fahr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Trat ich ans Tor zum Spielzeuggarten.", "tokens": ["Trat", "ich", "ans", "Tor", "zum", "Spiel\u00b7zeug\u00b7gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Die Landschaft wurde Miniatur,", "tokens": ["Die", "Land\u00b7schaft", "wur\u00b7de", "Mi\u00b7ni\u00b7a\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Mond hing da als Ohrring nur.", "tokens": ["Der", "Mond", "hing", "da", "als", "Ohr\u00b7ring", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KOUS", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Gel\u00e4chter war wie Schlittenglocken,", "tokens": ["Ge\u00b7l\u00e4ch\u00b7ter", "war", "wie", "Schlit\u00b7ten\u00b7glo\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schnee war nur Puder f\u00fcr die Locken.", "tokens": ["Schnee", "war", "nur", "Pu\u00b7der", "f\u00fcr", "die", "Lo\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Sorg' wirkte nur als Sch\u00f6nheitsmouche,", "tokens": ["Sor\u00b7g'", "wirk\u00b7te", "nur", "als", "Sch\u00f6n\u00b7heits\u00b7mou\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "KOUS", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Ein P\u00fcnkilein, das sich leicht fortwusch;", "tokens": ["Ein", "P\u00fcn\u00b7ki\u00b7lein", ",", "das", "sich", "leicht", "fort\u00b7wusch", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "F\u00fcr Langweil' gab's Musik und Schuh,", "tokens": ["F\u00fcr", "Lang\u00b7weil'", "gab's", "Mu\u00b7sik", "und", "Schuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man drehte sich und sieht nicht zu;", "tokens": ["Man", "dreh\u00b7te", "sich", "und", "sieht", "nicht", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "KON", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Weltteile sind nicht, nur das Pl\u00e4tzlein,", "tokens": ["Welt\u00b7tei\u00b7le", "sind", "nicht", ",", "nur", "das", "Pl\u00e4tz\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das gut warmh\u00e4lt Kater und K\u00e4tzlein.", "tokens": ["Das", "gut", "warm\u00b7h\u00e4lt", "Ka\u00b7ter", "und", "K\u00e4tz\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "VVFIN", "NN", "KON", "NN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und au\u00dferdem man nichts vermi\u00dft,", "tokens": ["Und", "au\u00b7\u00dfer\u00b7dem", "man", "nichts", "ver\u00b7mi\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "PIS", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat man den Mund, der selig k\u00fc\u00dft.", "tokens": ["Hat", "man", "den", "Mund", ",", "der", "se\u00b7lig", "k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Mohrle spielte gern Maskerad',", "tokens": ["Mohr\u00b7le", "spiel\u00b7te", "gern", "Mas\u00b7ke\u00b7rad'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Weil's Lachen niemand wehe tat.", "tokens": ["Weil's", "La\u00b7chen", "nie\u00b7mand", "we\u00b7he", "tat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Als Kind schon liebte sie mit Bangen", "tokens": ["Als", "Kind", "schon", "lieb\u00b7te", "sie", "mit", "Ban\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz raffiniert das Spiel mit Schlangen.", "tokens": ["Ganz", "raf\u00b7fi\u00b7niert", "das", "Spiel", "mit", "Schlan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Natter und Blindschleich', wenn sie fand,", "tokens": ["Nat\u00b7ter", "und", "Blind\u00b7schleich'", ",", "wenn", "sie", "fand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So nahm sie flott die in die Hand", "tokens": ["So", "nahm", "sie", "flott", "die", "in", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und lie\u00df sie z\u00fcngeln sich zum Hohn.", "tokens": ["Und", "lie\u00df", "sie", "z\u00fcn\u00b7geln", "sich", "zum", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was tut's, man stirbt ja nur davon.", "tokens": ["Was", "tut's", ",", "man", "stirbt", "ja", "nur", "da\u00b7von", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PIS", "VVFIN", "ADV", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und sie verga\u00df sich dabei ganz", "tokens": ["Und", "sie", "ver\u00b7ga\u00df", "sich", "da\u00b7bei", "ganz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PRF", "PAV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und pfiff den Schlangen auf zum Tanz.", "tokens": ["Und", "pfiff", "den", "Schlan\u00b7gen", "auf", "zum", "Tanz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "\u00bbwarum soll nicht auch B\u00f6ses leben?\u00ab", "tokens": ["\u00bb", "wa\u00b7rum", "soll", "nicht", "auch", "B\u00f6\u00b7ses", "le\u00b7ben", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PTKNEG", "ADV", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach sie, \u00bbGott tat ja alles geben.\u00ab", "tokens": ["Sprach", "sie", ",", "\u00bb", "Gott", "tat", "ja", "al\u00b7les", "ge\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "$(", "NN", "VVFIN", "ADV", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "So wie der Schnee sanft niederf\u00e4llt,", "tokens": ["So", "wie", "der", "Schnee", "sanft", "nie\u00b7der\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat sie sich mir still zugesellt.", "tokens": ["Hat", "sie", "sich", "mir", "still", "zu\u00b7ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "PPER", "ADJD", "VVPP", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}}, "stanza.19": {"line.1": {"text": "So selbstverst\u00e4ndlich sah das aus", "tokens": ["So", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "sah", "das", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PDS", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Luft vom Garten in das Haus.", "tokens": ["Wie", "Luft", "vom", "Gar\u00b7ten", "in", "das", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Schwarz ist mein Haar, wei\u00df sind die Kissen,", "tokens": ["Schwarz", "ist", "mein", "Haar", ",", "wei\u00df", "sind", "die", "Kis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,", "VVFIN", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ich lieb' dich, rein ist mein Gewissen.", "tokens": ["Ich", "lieb'", "dich", ",", "rein", "ist", "mein", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADJD", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Ein Glasleuchter hing von der Decken,", "tokens": ["Ein", "Glas\u00b7leuch\u00b7ter", "hing", "von", "der", "De\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Gut roch Wachslicht in allen Ecken.", "tokens": ["Gut", "roch", "Wachs\u00b7licht", "in", "al\u00b7len", "E\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "Wachsduft ging um das Mohrle her,", "tokens": ["Wachs\u00b7duft", "ging", "um", "das", "Mohr\u00b7le", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als ob sein Herz zerschmelzend w\u00e4r'.", "tokens": ["Als", "ob", "sein", "Herz", "zer\u00b7schmel\u00b7zend", "w\u00e4r'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Und alle M\u00f6bel wurden stolz,", "tokens": ["Und", "al\u00b7le", "M\u00f6\u00b7bel", "wur\u00b7den", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und k\u00f6stlich roch ihr kostbar Holz.", "tokens": ["Und", "k\u00f6st\u00b7lich", "roch", "ihr", "kost\u00b7bar", "Holz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Auf meinem Bett, wo's Mohrle sa\u00df,", "tokens": ["Auf", "mei\u00b7nem", "Bett", ",", "wo's", "Mohr\u00b7le", "sa\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Wurm im Holz mehr weiterfra\u00df.", "tokens": ["Kein", "Wurm", "im", "Holz", "mehr", "wei\u00b7ter\u00b7fra\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Wachslicht tat jede Nacht austreiben,", "tokens": ["Wachs\u00b7licht", "tat", "je\u00b7de", "Nacht", "aus\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Nacht machte nur schwarz die Scheiben.", "tokens": ["Die", "Nacht", "mach\u00b7te", "nur", "schwarz", "die", "Schei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "ART", "NN", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}}, "stanza.26": {"line.1": {"text": "Und wie ein Wachslicht, s\u00fc\u00df entz\u00fcndet", "tokens": ["Und", "wie", "ein", "Wachs\u00b7licht", ",", "s\u00fc\u00df", "ent\u00b7z\u00fcn\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "$,", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat's Mohrle seinen Mund ger\u00fcndet.", "tokens": ["Hat's", "Mohr\u00b7le", "sei\u00b7nen", "Mund", "ge\u00b7r\u00fcn\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Sein Auge wurde hei\u00df und feuchter,", "tokens": ["Sein", "Au\u00b7ge", "wur\u00b7de", "hei\u00df", "und", "feuch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durchsichtig wie der Kronenleuchter.", "tokens": ["Durch\u00b7sich\u00b7tig", "wie", "der", "Kro\u00b7nen\u00b7leuch\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Haarnadeln gingen langsam auf,", "tokens": ["Haar\u00b7na\u00b7deln", "gin\u00b7gen", "lang\u00b7sam", "auf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Pech schlug's Haar an mir hinauf.", "tokens": ["Wie", "Pech", "schlug's", "Haar", "an", "mir", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADJA", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Es sch\u00fcttelte das Mohrle sich,", "tokens": ["Es", "sch\u00fct\u00b7tel\u00b7te", "das", "Mohr\u00b7le", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Locken krochen \u00fcber mich.", "tokens": ["Und", "Lo\u00b7cken", "kro\u00b7chen", "\u00fc\u00b7ber", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Und wie Korkzieher eine Flasche,", "tokens": ["Und", "wie", "Kork\u00b7zie\u00b7her", "ei\u00b7ne", "Fla\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zog sie mir's Herz auf in der Tasche.", "tokens": ["Zog", "sie", "mir's", "Herz", "auf", "in", "der", "Ta\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "NN", "APPR", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Das K\u00fcssen drang uns in die Rippen,", "tokens": ["Das", "K\u00fcs\u00b7sen", "drang", "uns", "in", "die", "Rip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Ku\u00df um Ku\u00df sprang von den Lippen.", "tokens": ["Und", "Ku\u00df", "um", "Ku\u00df", "sprang", "von", "den", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Und wie zwei Milcht\u00f6pf' \u00fcberlaufen,", "tokens": ["Und", "wie", "zwei", "Milcht\u00f6pf'", "\u00fc\u00b7berl\u00b7au\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "CARD", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So konnten unsre K\u00f6pf' kaum schnaufen.", "tokens": ["So", "konn\u00b7ten", "uns\u00b7re", "K\u00f6pf'", "kaum", "schnau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Mein Herz stand endlich an dem Ziel", "tokens": ["Mein", "Herz", "stand", "end\u00b7lich", "an", "dem", "Ziel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ein Rad hei\u00dfgelaufen still.", "tokens": ["Wie", "ein", "Rad", "hei\u00df\u00b7ge\u00b7lau\u00b7fen", "still", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.34": {"line.1": {"text": "Ich tat die Lippen etwas l\u00fcften,", "tokens": ["Ich", "tat", "die", "Lip\u00b7pen", "et\u00b7was", "l\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: \u00bbMohrle, mit den Kinderh\u00fcften,", "tokens": ["Sprach", ":", "\u00bb", "Mohr\u00b7le", ",", "mit", "den", "Kin\u00b7der\u00b7h\u00fcf\u00b7ten", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "F\u00fchlst wie ein Wickelkind dich an,", "tokens": ["F\u00fchlst", "wie", "ein", "Wi\u00b7ckel\u00b7kind", "dich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ganz erwachsen lieben kann;", "tokens": ["Das", "ganz", "er\u00b7wach\u00b7sen", "lie\u00b7ben", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Zart sind die F\u00fc\u00dflein dir bestellt", "tokens": ["Zart", "sind", "die", "F\u00fc\u00df\u00b7lein", "dir", "be\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "ART", "NN", "PPER", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und liefen trotzdem um die Welt.", "tokens": ["Und", "lie\u00b7fen", "trotz\u00b7dem", "um", "die", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Wer hat dein F\u00fc\u00dflein dir besohlt,", "tokens": ["Wer", "hat", "dein", "F\u00fc\u00df\u00b7lein", "dir", "be\u00b7sohlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPOSAT", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00dcberall hat's mich eingeholt?\u00ab", "tokens": ["\u00dc\u00b7be\u00b7rall", "hat's", "mich", "ein\u00b7ge\u00b7holt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.38": {"line.1": {"text": "Das Mohrle tat die Lippen runden,", "tokens": ["Das", "Mohr\u00b7le", "tat", "die", "Lip\u00b7pen", "run\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: \u00bbBalzer, stiehl nicht die Sekunden,", "tokens": ["Sprach", ":", "\u00bb", "Bal\u00b7zer", ",", "stiehl", "nicht", "die", "Se\u00b7kun\u00b7den", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "$,", "ADV", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "St\u00f6r nicht im K\u00fcssen diese Nacht,", "tokens": ["St\u00f6r", "nicht", "im", "K\u00fcs\u00b7sen", "die\u00b7se", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "APPRART", "NN", "PDAT", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sprechen ist jetzt nicht angebracht.", "tokens": ["Spre\u00b7chen", "ist", "jetzt", "nicht", "an\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.40": {"line.1": {"text": "Die Lippen tun mir Feuer schlagen,", "tokens": ["Die", "Lip\u00b7pen", "tun", "mir", "Feu\u00b7er", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und k\u00f6nnen nur noch: K\u00fcss' mich! sagen.\u00ab", "tokens": ["Und", "k\u00f6n\u00b7nen", "nur", "noch", ":", "K\u00fcss'", "mich", "!", "sa\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "$.", "VVIMP", "PPER", "$.", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Die Kerzen brannten feierlich,", "tokens": ["Die", "Ker\u00b7zen", "brann\u00b7ten", "fei\u00b7er\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Wachs tropfte ihr Herz in mich.", "tokens": ["Wie", "Wachs", "tropf\u00b7te", "ihr", "Herz", "in", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "PPER", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.42": {"line.1": {"text": "Wenn man zufrieden um sich sieht,", "tokens": ["Wenn", "man", "zu\u00b7frie\u00b7den", "um", "sich", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fragt man, wo S\u00fcnde hier geschieht.", "tokens": ["Fragt", "man", ",", "wo", "S\u00fcn\u00b7de", "hier", "ge\u00b7schieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWAV", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Wunschlos und still ich morgens sa\u00df,", "tokens": ["Wun\u00b7schlos", "und", "still", "ich", "mor\u00b7gens", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VMFIN", "PPER", "ADV", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wachsen h\u00f6rte ich 's Wintergras.", "tokens": ["Wach\u00b7sen", "h\u00f6r\u00b7te", "ich", "'s", "Win\u00b7ter\u00b7gras", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PPER", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.44": {"line.1": {"text": "Vorm Fenster fiel zuckriger Schnee,", "tokens": ["Vorm", "Fens\u00b7ter", "fiel", "zuck\u00b7ri\u00b7ger", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Zucker tut der Welt nicht weh.", "tokens": ["Und", "Zu\u00b7cker", "tut", "der", "Welt", "nicht", "weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Ein Liebesbett schien diese Welt,", "tokens": ["Ein", "Lie\u00b7bes\u00b7bett", "schien", "die\u00b7se", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das t\u00e4glich frisch vom Himmel f\u00e4llt.", "tokens": ["Das", "t\u00e4g\u00b7lich", "frisch", "vom", "Him\u00b7mel", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Da stie\u00df der Wind das Fenster ein,", "tokens": ["Da", "stie\u00df", "der", "Wind", "das", "Fens\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Zucker flog auch Salz herein.", "tokens": ["Im", "Zu\u00b7cker", "flog", "auch", "Salz", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Bitter wie nur k\u00f6rniges Salz", "tokens": ["Bit\u00b7ter", "wie", "nur", "k\u00f6r\u00b7ni\u00b7ges", "Salz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ADV", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Steckte die Zukunft mir im Hals.", "tokens": ["Steck\u00b7te", "die", "Zu\u00b7kunft", "mir", "im", "Hals", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.48": {"line.1": {"text": "Doch wenn ich was zu sorgen hatte,", "tokens": ["Doch", "wenn", "ich", "was", "zu", "sor\u00b7gen", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIS", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Steck' ich ins Ohr mir gerne Watte", "tokens": ["Steck'", "ich", "ins", "Ohr", "mir", "ger\u00b7ne", "Wat\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "APPRART", "NN", "PPER", "ADV", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Und horch aufs Leben nur ged\u00e4mpft,", "tokens": ["Und", "horch", "aufs", "Le\u00b7ben", "nur", "ge\u00b7d\u00e4mpft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "APPRART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil es ja doch von selber k\u00e4mpft.", "tokens": ["Weil", "es", "ja", "doch", "von", "sel\u00b7ber", "k\u00e4mpft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Das Leben wird es wissen m\u00fcssen,", "tokens": ["Das", "Le\u00b7ben", "wird", "es", "wis\u00b7sen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Darf ich zugleich zwei Frauen k\u00fcssen.", "tokens": ["Darf", "ich", "zu\u00b7gleich", "zwei", "Frau\u00b7en", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Zwei hat es sichtbar mir verehrt,", "tokens": ["Zwei", "hat", "es", "sicht\u00b7bar", "mir", "ver\u00b7ehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "VAFIN", "PPER", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch eine sich dagegen wehrt.", "tokens": ["Doch", "ei\u00b7ne", "sich", "da\u00b7ge\u00b7gen", "wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Zucker und Salz zusammenrann,", "tokens": ["Zu\u00b7cker", "und", "Salz", "zu\u00b7sam\u00b7men\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So da\u00df man keins mehr schrecken kann.", "tokens": ["So", "da\u00df", "man", "keins", "mehr", "schre\u00b7cken", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "PIAT", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Und als die Mittagssonne kam,", "tokens": ["Und", "als", "die", "Mit\u00b7tags\u00b7son\u00b7ne", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schnee sich fast wie Dreck benahm.", "tokens": ["Der", "Schnee", "sich", "fast", "wie", "Dreck", "be\u00b7nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "KOKOM", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Das Mohrle sa\u00df noch auf dem Bett", "tokens": ["Das", "Mohr\u00b7le", "sa\u00df", "noch", "auf", "dem", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und fragte, ob ich gern sie h\u00e4tt'.", "tokens": ["Und", "frag\u00b7te", ",", "ob", "ich", "gern", "sie", "h\u00e4tt'", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Der Abend stand bald vor der T\u00fcr.", "tokens": ["Der", "A\u00b7bend", "stand", "bald", "vor", "der", "T\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Antworten, dacht' ich, mu\u00df man hier.", "tokens": ["Ant\u00b7wor\u00b7ten", ",", "dacht'", "ich", ",", "mu\u00df", "man", "hier", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Ich streichelte ihr knatternd Haar,", "tokens": ["Ich", "strei\u00b7chel\u00b7te", "ihr", "knat\u00b7ternd", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das voll von Feuerwerk noch war.", "tokens": ["Das", "voll", "von", "Feu\u00b7er\u00b7werk", "noch", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Zwiebeln vor uns in Gl\u00e4sern standen,", "tokens": ["Zwie\u00b7beln", "vor", "uns", "in", "Gl\u00e4\u00b7sern", "stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dran heut sich offne Tulpen fanden;", "tokens": ["Dran", "heut", "sich", "off\u00b7ne", "Tul\u00b7pen", "fan\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PRF", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Ich machte sie aufmerksam drauf,", "tokens": ["Ich", "mach\u00b7te", "sie", "auf\u00b7merk\u00b7sam", "drauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr K\u00fcssen wecke Blumen auf.", "tokens": ["Ihr", "K\u00fcs\u00b7sen", "we\u00b7cke", "Blu\u00b7men", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Doch schien's mir nicht mehr recht geheuer,", "tokens": ["Doch", "schien's", "mir", "nicht", "mehr", "recht", "ge\u00b7heu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich streute Asche auf das Feuer.", "tokens": ["Ich", "streu\u00b7te", "A\u00b7sche", "auf", "das", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Und sie sprach: \u00bbImmer h\u00e4lt die Glut,", "tokens": ["Und", "sie", "sprach", ":", "\u00bb", "Im\u00b7mer", "h\u00e4lt", "die", "Glut", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die warmgesch\u00fctzt in Asche ruht.", "tokens": ["Die", "warm\u00b7ge\u00b7sch\u00fctzt", "in", "A\u00b7sche", "ruht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Lebst du am Pol, und ich leb' hier,", "tokens": ["Lebst", "du", "am", "Pol", ",", "und", "ich", "leb'", "hier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "KON", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr immer,\u00ab sprach sie, \u00bbleb' ich dir.\u00ab", "tokens": ["F\u00fcr", "im\u00b7mer", ",", "\u00ab", "sprach", "sie", ",", "\u00bb", "leb'", "ich", "dir", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Sollst nur im Traum dich manchmal zeigen,", "tokens": ["Sollst", "nur", "im", "Traum", "dich", "manch\u00b7mal", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPRART", "NN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das unterbricht das Todesschweigen.", "tokens": ["Das", "un\u00b7ter\u00b7bricht", "das", "To\u00b7des\u00b7schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Die Welt ist jetzt ein Edengarten.", "tokens": ["Die", "Welt", "ist", "jetzt", "ein", "E\u00b7den\u00b7gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und mu\u00df ich auf den Adam warten,", "tokens": ["Und", "mu\u00df", "ich", "auf", "den", "A\u00b7dam", "war\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Sch\u00f6n ist's im Garten zu spazieren,", "tokens": ["Sch\u00f6n", "ist's", "im", "Gar\u00b7ten", "zu", "spa\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die Schlang' tut mich nicht mehr genieren.", "tokens": ["Die", "Schlang'", "tut", "mich", "nicht", "mehr", "ge\u00b7nie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Wenn ich auch in den Apfel bi\u00df,", "tokens": ["Wenn", "ich", "auch", "in", "den", "Ap\u00b7fel", "bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bleib' erst recht im Paradies.", "tokens": ["Ich", "bleib'", "erst", "recht", "im", "Pa\u00b7ra\u00b7dies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Handle du immer nach Belieben,", "tokens": ["Hand\u00b7le", "du", "im\u00b7mer", "nach", "Be\u00b7lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ich lieb' dich und la\u00df mich verschieben.", "tokens": ["Ich", "lieb'", "dich", "und", "la\u00df", "mich", "ver\u00b7schie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVIMP", "PPER", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.67": {"line.1": {"text": "Und kriege ich ein Wickelkind,", "tokens": ["Und", "krie\u00b7ge", "ich", "ein", "Wi\u00b7ckel\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich mich als Mutter reizend find'.", "tokens": ["Ich", "mich", "als", "Mut\u00b7ter", "rei\u00b7zend", "find'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "KOUS", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Ein Kind von dir w\u00e4r' eine Freude,", "tokens": ["Ein", "Kind", "von", "dir", "w\u00e4r'", "ei\u00b7ne", "Freu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "M\u00f6cht's anstatt morgen gleich schon heute.", "tokens": ["M\u00f6cht's", "an\u00b7statt", "mor\u00b7gen", "gleich", "schon", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Doch bist du ein besch\u00e4mter Mann,", "tokens": ["Doch", "bist", "du", "ein", "be\u00b7sch\u00e4m\u00b7ter", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Siehst mich als Hausfriedensbruch an,", "tokens": ["Siehst", "mich", "als", "Haus\u00b7frie\u00b7dens\u00b7bruch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "NN", "PTKVZ", "$,"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}}, "stanza.70": {"line.1": {"text": "Will in Versenkung ich verschwinden,", "tokens": ["Will", "in", "Ver\u00b7sen\u00b7kung", "ich", "ver\u00b7schwin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sollst nicht ein H\u00e4rlein von mir finden.", "tokens": ["Sollst", "nicht", "ein", "H\u00e4r\u00b7lein", "von", "mir", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Ich dank' dir f\u00fcr die eine Nacht,", "tokens": ["Ich", "dank'", "dir", "f\u00fcr", "die", "ei\u00b7ne", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ich so gl\u00fccklich durchgemacht,", "tokens": ["Die", "ich", "so", "gl\u00fcck\u00b7lich", "durch\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Und willst du keine weiter schenken,", "tokens": ["Und", "willst", "du", "kei\u00b7ne", "wei\u00b7ter", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PIAT", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kann ich mir all die andern denken.\u00ab", "tokens": ["Kann", "ich", "mir", "all", "die", "an\u00b7dern", "den\u00b7ken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PIAT", "ART", "ADJA", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Mir war wie ein Gedankenstrich,", "tokens": ["Mir", "war", "wie", "ein", "Ge\u00b7dan\u00b7ken\u00b7strich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Je l\u00e4nger dieser Tag entwich.", "tokens": ["Je", "l\u00e4n\u00b7ger", "die\u00b7ser", "Tag", "ent\u00b7wich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Wir sagten uns auf Wiedersehn,", "tokens": ["Wir", "sag\u00b7ten", "uns", "auf", "Wie\u00b7der\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich fragte: Was soll jetzt geschehn?", "tokens": ["Ich", "frag\u00b7te", ":", "Was", "soll", "jetzt", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWS", "VMFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Zwei Frauen waren lebend mein,", "tokens": ["Zwei", "Frau\u00b7en", "wa\u00b7ren", "le\u00b7bend", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ADJD", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Welche soll jetzt versto\u00dfen sein?", "tokens": ["Wel\u00b7che", "soll", "jetzt", "ver\u00b7sto\u00b7\u00dfen", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.76": {"line.1": {"text": "Trost in meinem Extra-Geschick", "tokens": ["Trost", "in", "mei\u00b7nem", "Ex\u00b7tra\u00b7Ge\u00b7schick"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Bewirkte mir die Statistik.", "tokens": ["Be\u00b7wirk\u00b7te", "mir", "die", "Sta\u00b7tis\u00b7tik", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Vielbeweibt liegt selbst im Gebet", "tokens": ["Viel\u00b7be\u00b7weibt", "liegt", "selbst", "im", "Ge\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Halb Asien, wo die Sonn' aufgeht.", "tokens": ["Halb", "A\u00b7sien", ",", "wo", "die", "Sonn'", "auf\u00b7geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Auch Afrika sich so anstellt,", "tokens": ["Auch", "Af\u00b7ri\u00b7ka", "sich", "so", "an\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Wo dutzendweis' die Frau sich h\u00e4lt.", "tokens": ["Wo", "dut\u00b7zend\u00b7weis'", "die", "Frau", "sich", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Auch mir hat's Schicksal vorgeschrieben,", "tokens": ["Auch", "mir", "hat's", "Schick\u00b7sal", "vor\u00b7ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sollte unbescheiden lieben.", "tokens": ["Ich", "soll\u00b7te", "un\u00b7be\u00b7schei\u00b7den", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}