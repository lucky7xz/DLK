{"textgrid.poem.53597": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Wenn die Flocken fallen . . .", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gr\u00fcbelnd ging ich heut in meinen Laden.", "tokens": ["Gr\u00fc\u00b7belnd", "ging", "ich", "heut", "in", "mei\u00b7nen", "La\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und ich dachte mir: Es kann nichts schaden \u2013", "tokens": ["Und", "ich", "dach\u00b7te", "mir", ":", "Es", "kann", "nichts", "scha\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Mach mal Inventur!", "tokens": ["Mach", "mal", "In\u00b7ven\u00b7tur", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Oh, Matthias, wird das Leben aber teuer!", "tokens": ["Oh", ",", "Mat\u00b7thi\u00b7as", ",", "wird", "das", "Le\u00b7ben", "a\u00b7ber", "teu\u00b7er", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NE", "$,", "VAFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Jetzt kommt, Gott beh\u00fcte, eine Umsatzsteuer \u2013", "tokens": ["Jetzt", "kommt", ",", "Gott", "be\u00b7h\u00fc\u00b7te", ",", "ei\u00b7ne", "Um\u00b7satz\u00b7steu\u00b7er", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "NN", "VVFIN", "$,", "ART", "NN", "$("], "meter": "-++-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.6": {"text": "Wer bezahlt die nur?", "tokens": ["Wer", "be\u00b7zahlt", "die", "nur", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Und ich frag mich: Mitten in Berlin?", "tokens": ["Und", "ich", "frag", "mich", ":", "Mit\u00b7ten", "in", "Ber\u00b7lin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$.", "ADV", "APPR", "NE", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Kann der Mensch da Steuern hinterziehn?", "tokens": ["Kann", "der", "Mensch", "da", "Steu\u00b7ern", "hin\u00b7ter\u00b7ziehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Eben wars noch trocken.", "tokens": ["E\u00b7ben", "wars", "noch", "tro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Pl\u00f6tzlich schneit es dichte, dichte Flocken . . .", "tokens": ["Pl\u00f6tz\u00b7lich", "schneit", "es", "dich\u00b7te", ",", "dich\u00b7te", "Flo\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "VVFIN", "$,", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Und mir f\u00e4llt beim Wandern eine nach der andern", "tokens": ["Und", "mir", "f\u00e4llt", "beim", "Wan\u00b7dern", "ei\u00b7ne", "nach", "der", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "ART", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.12": {"text": "leise auf den Hut.", "tokens": ["lei\u00b7se", "auf", "den", "Hut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.13": {"text": "Denk im Schneegeriesel:", "tokens": ["Denk", "im", "Schnee\u00b7ge\u00b7rie\u00b7sel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.14": {"text": "Ich bin doch ein Stiesel \u2013", "tokens": ["Ich", "bin", "doch", "ein", "Stie\u00b7sel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "weil die ganze Welt dergleichen tut!", "tokens": ["weil", "die", "gan\u00b7ze", "Welt", "derg\u00b7lei\u00b7chen", "tut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Welch ein gutes Kind ist Eveline!", "tokens": ["Welch", "ein", "gu\u00b7tes", "Kind", "ist", "E\u00b7ve\u00b7li\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "ADJA", "NN", "VAFIN", "NE", "$."], "meter": "+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Tr\u00e4gt das Kind mit Recht die Unschuldsmiene?", "tokens": ["Tr\u00e4gt", "das", "Kind", "mit", "Recht", "die", "Un\u00b7schulds\u00b7mie\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Oder t\u00e4usch ich mich?", "tokens": ["O\u00b7der", "t\u00e4usch", "ich", "mich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "PRF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Nein, sie l\u00e4uft doch als verlobte Braut rum,", "tokens": ["Nein", ",", "sie", "l\u00e4uft", "doch", "als", "ver\u00b7lob\u00b7te", "Braut", "rum", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "ADV", "KOUS", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "und der brave Ehrenmann, er schaut drum", "tokens": ["und", "der", "bra\u00b7ve", "Eh\u00b7ren\u00b7mann", ",", "er", "schaut", "drum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "PAV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "weg und sch\u00e4met sich.", "tokens": ["weg", "und", "sch\u00e4\u00b7met", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "KON", "VVFIN", "PRF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Und er fragt sich: Mitten in Berlin?", "tokens": ["Und", "er", "fragt", "sich", ":", "Mit\u00b7ten", "in", "Ber\u00b7lin", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "$.", "ADV", "APPR", "NE", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Nah ich solchem M\u00e4dchen auf den Knien \u2013?", "tokens": ["Nah", "ich", "sol\u00b7chem", "M\u00e4d\u00b7chen", "auf", "den", "Kni\u00b7en", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "APPR", "ART", "NN", "$(", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Eben wars noch trocken.", "tokens": ["E\u00b7ben", "wars", "noch", "tro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Pl\u00f6tzlich schneit es dichte, dichte Flocken . . .", "tokens": ["Pl\u00f6tz\u00b7lich", "schneit", "es", "dich\u00b7te", ",", "dich\u00b7te", "Flo\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "VVFIN", "$,", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Und mir f\u00e4llt beim Wandern", "tokens": ["Und", "mir", "f\u00e4llt", "beim", "Wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.12": {"text": "eine nach der andern", "tokens": ["ei\u00b7ne", "nach", "der", "an\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "leise auf den Hut.", "tokens": ["lei\u00b7se", "auf", "den", "Hut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.14": {"text": "Denk im Schneegeriesel:", "tokens": ["Denk", "im", "Schnee\u00b7ge\u00b7rie\u00b7sel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.15": {"text": "Ich bin doch ein Stiesel \u2013", "tokens": ["Ich", "bin", "doch", "ein", "Stie\u00b7sel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "weil die ganze Welt dergleichen tut!", "tokens": ["weil", "die", "gan\u00b7ze", "Welt", "derg\u00b7lei\u00b7chen", "tut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PIS", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Als in M\u00fcnchen neulich Kommunisten", "tokens": ["Als", "in", "M\u00fcn\u00b7chen", "neu\u00b7lich", "Kom\u00b7mu\u00b7nis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NE", "ADV", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "schoben scheu\u00dflich-schauervolle Kisten,", "tokens": ["scho\u00b7ben", "scheu\u00df\u00b7lich\u00b7schau\u00b7e\u00b7rvol\u00b7le", "Kis\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "nannte man das: Mord.", "tokens": ["nann\u00b7te", "man", "das", ":", "Mord", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "PDS", "$.", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Aber l\u00e4\u00dft bei uns, ganz kalt und steinhart,", "tokens": ["A\u00b7ber", "l\u00e4\u00dft", "bei", "uns", ",", "ganz", "kalt", "und", "stein\u00b7hart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$,", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "drei\u00dfig Mann erschie\u00dfen Oberst Reinhard \u2013", "tokens": ["drei\u00b7\u00dfig", "Mann", "er\u00b7schie\u00b7\u00dfen", "O\u00b7berst", "Rein\u00b7hard", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJA", "NN", "NE", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "t\u00f6nt kein Wort.", "tokens": ["t\u00f6nt", "kein", "Wort", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Und ich frag mich: Mitten in Berlin \u2013", "tokens": ["Und", "ich", "frag", "mich", ":", "Mit\u00b7ten", "in", "Ber\u00b7lin", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$.", "ADV", "APPR", "NE", "$("], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Wann, o Gustav, wann belangst du ihn?", "tokens": ["Wann", ",", "o", "Gus\u00b7tav", ",", "wann", "be\u00b7langst", "du", "ihn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "FM", "NE", "$,", "PWAV", "VVFIN", "PPER", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Eben wars noch trocken.", "tokens": ["E\u00b7ben", "wars", "noch", "tro\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Pl\u00f6tzlich schneit es dichte, dichte Flocken . . .", "tokens": ["Pl\u00f6tz\u00b7lich", "schneit", "es", "dich\u00b7te", ",", "dich\u00b7te", "Flo\u00b7cken", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "VVFIN", "$,", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Und mir f\u00e4llt beim Wandern", "tokens": ["Und", "mir", "f\u00e4llt", "beim", "Wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.12": {"text": "eine nach der andern", "tokens": ["ei\u00b7ne", "nach", "der", "an\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "leis auf den Schapoh.", "tokens": ["leis", "auf", "den", "Scha\u00b7poh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.14": {"text": "Denk im Schneegeriesel:", "tokens": ["Denk", "im", "Schnee\u00b7ge\u00b7rie\u00b7sel", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.15": {"text": "Ich bin doch ein Stiesel \u2013", "tokens": ["Ich", "bin", "doch", "ein", "Stie\u00b7sel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "In der Republik, da ists mal so \u2013", "tokens": ["In", "der", "Re\u00b7pub\u00b7lik", ",", "da", "ists", "mal", "so", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADV", "VAFIN", "ADV", "ADV", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}