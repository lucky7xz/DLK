{"textgrid.poem.52765": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: In einer Nacht, einer finstern Nacht", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In einer Nacht, einer finstern Nacht", "tokens": ["In", "ei\u00b7ner", "Nacht", ",", "ei\u00b7ner", "fins\u00b7tern", "Nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hat eine arme Mutter", "tokens": ["Hat", "ei\u00b7ne", "ar\u00b7me", "Mut\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihren Buben umgebracht.", "tokens": ["Ih\u00b7ren", "Bu\u00b7ben", "um\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "In einem kalten, vielnassen See", "tokens": ["In", "ei\u00b7nem", "kal\u00b7ten", ",", "viel\u00b7nas\u00b7sen", "See"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das B\u00fcblein liegt begraben,", "tokens": ["Das", "B\u00fcb\u00b7lein", "liegt", "be\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Thut ihm kein Zahn mehr weh.", "tokens": ["Thut", "ihm", "kein", "Zahn", "mehr", "weh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PIAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Du armer Tropf, nun hast du's gut!", "tokens": ["Du", "ar\u00b7mer", "Tropf", ",", "nun", "hast", "du's", "gut", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "ADV", "VAFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Mutter dankt im Herzen", "tokens": ["Die", "Mut\u00b7ter", "dankt", "im", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.4": {"line.1": {"text": "Da war ein lauwarmer Wintertag,", "tokens": ["Da", "war", "ein", "lau\u00b7war\u00b7mer", "Win\u00b7ter\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Am tannengr\u00fcnen Ufer", "tokens": ["Am", "tan\u00b7nen\u00b7gr\u00fc\u00b7nen", "U\u00b7fer"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das B\u00fcblein oben lag.", "tokens": ["Das", "B\u00fcb\u00b7lein", "o\u00b7ben", "lag", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ein Waidmann strich im w\u00fcsten Wald,", "tokens": ["Ein", "Waid\u00b7mann", "strich", "im", "w\u00fcs\u00b7ten", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Hund begunn zu bellen,", "tokens": ["Sein", "Hund", "be\u00b7gunn", "zu", "bel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da sah er's B\u00fcblein bald.", "tokens": ["Da", "sah", "er's", "B\u00fcb\u00b7lein", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die Menschen liefen aus der Stadt,", "tokens": ["Die", "Men\u00b7schen", "lie\u00b7fen", "aus", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sahn sich die Guckaugen", "tokens": ["Sie", "sahn", "sich", "die", "Guc\u00b7kau\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Am B\u00fcblein nimmer satt.", "tokens": ["Am", "B\u00fcb\u00b7lein", "nim\u00b7mer", "satt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Das Weib erschrack: nun sag' mir an,", "tokens": ["Das", "Weib", "er\u00b7schrack", ":", "nun", "sag'", "mir", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Heimt\u00fcckisches Gew\u00e4sser,", "tokens": ["Heim\u00b7t\u00fc\u00b7cki\u00b7sches", "Ge\u00b7w\u00e4s\u00b7ser", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Was hast du mir gethan?", "tokens": ["Was", "hast", "du", "mir", "ge\u00b7than", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Die Mutter sperrten sie wohl ein.", "tokens": ["Die", "Mut\u00b7ter", "sperr\u00b7ten", "sie", "wohl", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der See, der hat ", "tokens": ["Der", "See", ",", "der", "hat"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Und es k\u00f6nnt' auch ", "tokens": ["Und", "es", "k\u00f6nnt'", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "ADV"], "meter": "+-+-", "measure": "trochaic.di"}}}}}