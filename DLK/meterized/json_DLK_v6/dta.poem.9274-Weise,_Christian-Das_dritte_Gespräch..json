{"dta.poem.9274": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das dritte Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Leipzger breuhahn schmeckt mir nie/", "tokens": ["Leipz\u00b7ger", "breu\u00b7hahn", "schmeckt", "mir", "nie", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "PPER", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der rastrum ist noch schlimmer/", "tokens": ["Und", "der", "rast\u00b7rum", "ist", "noch", "schlim\u00b7mer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "VAFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber Leipzger frauenzimmer/", "tokens": ["A\u00b7ber", "Leipz\u00b7ger", "frau\u00b7en\u00b7zim\u00b7mer", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das verlohnt sich noch der m\u00fch:", "tokens": ["Das", "ver\u00b7lohnt", "sich", "noch", "der", "m\u00fch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ART", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses macht auff meinem munde/", "tokens": ["Die\u00b7ses", "macht", "auff", "mei\u00b7nem", "mun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Manch vers\u00fcstes zucker-spiel/", "tokens": ["Manch", "ver\u00b7s\u00fcs\u00b7tes", "zu\u00b7cke\u00b7rspiel", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df ich es in einer stunde/", "tokens": ["Da\u00df", "ich", "es", "in", "ei\u00b7ner", "stun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "ART", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mehr als zehnmahl kosten will.", "tokens": ["Mehr", "als", "zehn\u00b7mahl", "kos\u00b7ten", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Braunschweig darff sich ferner nicht", "tokens": ["Braun\u00b7schweig", "darff", "sich", "fer\u00b7ner", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PRF", "ADV", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff die mumme so befleissen/", "tokens": ["Auff", "die", "mum\u00b7me", "so", "be\u00b7fleis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn die m\u00fchmgen hier in Meissen", "tokens": ["Denn", "die", "m\u00fchm\u00b7gen", "hier", "in", "Meis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sind was besser zugericht.", "tokens": ["Sind", "was", "bes\u00b7ser", "zu\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bre\u00dflau mag sich wohl befinden/", "tokens": ["Bre\u00df\u00b7lau", "mag", "sich", "wohl", "be\u00b7fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PRF", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und im sch\u00f6pse lustig seyn/", "tokens": ["Und", "im", "sch\u00f6p\u00b7se", "lus\u00b7tig", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "ADJD", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Doch die sch\u00e4fgen bey den Linden", "tokens": ["Doch", "die", "sch\u00e4f\u00b7gen", "bey", "den", "Lin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "APPR", "ART", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Gehen uns viel s\u00fcsser ein.", "tokens": ["Ge\u00b7hen", "uns", "viel", "s\u00fcs\u00b7ser", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Mord und todtschlag taug hier nicht/", "tokens": ["Mord", "und", "todt\u00b7schlag", "taug", "hier", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "ADV", "PTKNEG", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Denn wir st\u00fcrben sonsten alle:", "tokens": ["Denn", "wir", "st\u00fcr\u00b7ben", "sons\u00b7ten", "al\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "VMFIN", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und was taug der puff zu Halle/", "tokens": ["Und", "was", "taug", "der", "puff", "zu", "Hal\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "ART", "NN", "APPR", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo man liebes-p\u00fcffe kriegt.", "tokens": ["Wo", "man", "lie\u00b7bes\u00b7p\u00fcf\u00b7fe", "kriegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wittenberg mag guggug sauffen/", "tokens": ["Wit\u00b7ten\u00b7berg", "mag", "gug\u00b7gug", "sauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "ADJD", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn der guggug findt sich wol/", "tokens": ["Denn", "der", "gug\u00b7gug", "findt", "sich", "wol", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn sie uns in haber lauffen/", "tokens": ["Wenn", "sie", "uns", "in", "ha\u00b7ber", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "NE", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df man etwas werden soll.", "tokens": ["Da\u00df", "man", "et\u00b7was", "wer\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "VAINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Merseburg die liebe stadt/", "tokens": ["Mer\u00b7se\u00b7burg", "die", "lie\u00b7be", "stadt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit den weitber\u00fchmten spitzen/", "tokens": ["Mit", "den", "weit\u00b7be\u00b7r\u00fchm\u00b7ten", "spit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bleibt mit allen biere sitzen/", "tokens": ["Bleibt", "mit", "al\u00b7len", "bie\u00b7re", "sit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das so sch\u00f6ne nahmen hat.", "tokens": ["Das", "so", "sch\u00f6\u00b7ne", "nah\u00b7men", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJA", "VVFIN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Heidehecker schmeckt zu lose:", "tokens": ["Hei\u00b7de\u00b7he\u00b7cker", "schmeckt", "zu", "lo\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Kuhschwantz/ Zerbster/ Wurtzner bier/", "tokens": ["Kuh\u00b7schwantz", "/", "Zerbs\u00b7ter", "/", "Wurtz\u00b7ner", "bier", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Klatsche/ Duchstein/ Garley/ Gose/", "tokens": ["Klat\u00b7sche", "/", "Duchs\u00b7tein", "/", "Gar\u00b7ley", "/", "Go\u00b7se", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Bleiben alle weit von mir.", "tokens": ["Blei\u00b7ben", "al\u00b7le", "weit", "von", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Denn di\u00df ist mein steiffer sinn/", "tokens": ["Denn", "di\u00df", "ist", "mein", "steif\u00b7fer", "sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df ich itzt und k\u00fcnfftig immer/", "tokens": ["Da\u00df", "ich", "itzt", "und", "k\u00fcnff\u00b7tig", "im\u00b7mer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KON", "ADJD", "ADV", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Bey den Leipzger frauenzimmer", "tokens": ["Bey", "den", "Leipz\u00b7ger", "frau\u00b7en\u00b7zim\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Allermeist vergn\u00fcget bin.", "tokens": ["Al\u00b7ler\u00b7meist", "ver\u00b7gn\u00fc\u00b7get", "bin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hab ich di\u00df in allen ehren/", "tokens": ["Hab", "ich", "di\u00df", "in", "al\u00b7len", "eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PDS", "APPR", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Keiterling und Rheinschen wein/", "tokens": ["Kei\u00b7ter\u00b7ling", "und", "Rhein\u00b7schen", "wein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wil ich alles bier verschweren/", "tokens": ["Wil", "ich", "al\u00b7les", "bier", "ver\u00b7schwe\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIS", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Solt ich noch so durstig seyn.", "tokens": ["Solt", "ich", "noch", "so", "durs\u00b7tig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}