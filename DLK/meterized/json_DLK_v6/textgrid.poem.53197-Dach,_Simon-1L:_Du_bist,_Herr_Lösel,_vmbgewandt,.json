{"textgrid.poem.53197": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du bist, Herr L\u00f6sel, vmbgewandt,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du bist, Herr L\u00f6sel, vmbgewandt,", "tokens": ["Du", "bist", ",", "Herr", "L\u00f6\u00b7sel", ",", "vmb\u00b7ge\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "NN", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Lied wirdt mehr von dir geschrieben,", "tokens": ["Kein", "Lied", "wirdt", "mehr", "von", "dir", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wer z\u00e4hmt dir die gelehrte Hand?", "tokens": ["Wer", "z\u00e4hmt", "dir", "die", "ge\u00b7lehr\u00b7te", "Hand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wo ist dein grosser Flei\u00df geblieben?", "tokens": ["Wo", "ist", "dein", "gros\u00b7ser", "Flei\u00df", "ge\u00b7blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es hatten deinetwegen schon", "tokens": ["Es", "hat\u00b7ten", "dei\u00b7net\u00b7we\u00b7gen", "schon"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Musen Lieb vnd Frewd empfunden", "tokens": ["Die", "Mu\u00b7sen", "Lieb", "vnd", "Frewd", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vndt eine gr\u00fcne Lorbeer Krohn", "tokens": ["Vndt", "ei\u00b7ne", "gr\u00fc\u00b7ne", "Lor\u00b7beer", "Krohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vmb dein ber\u00fchmtes Haupt gewunden.", "tokens": ["Vmb", "dein", "be\u00b7r\u00fchm\u00b7tes", "Haupt", "ge\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun endern sie den gutten Sinn,", "tokens": ["Nun", "en\u00b7dern", "sie", "den", "gut\u00b7ten", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dem dein Vorsatz mu\u00df erkalten,", "tokens": ["Nach", "dem", "dein", "Vor\u00b7satz", "mu\u00df", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Gunst bey ihnen f\u00e4llt dahin,", "tokens": ["Die", "Gunst", "bey", "ih\u00b7nen", "f\u00e4llt", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Krantz wird andern vorbehalten.", "tokens": ["Der", "Krantz", "wird", "an\u00b7dern", "vor\u00b7be\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Du fragest auch darnach nicht viel", "tokens": ["Du", "fra\u00b7gest", "auch", "dar\u00b7nach", "nicht", "viel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vnd gehest vmb mit bessern Sachen,", "tokens": ["Vnd", "ge\u00b7hest", "vmb", "mit", "bes\u00b7sern", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wa\u00df kan ein armes Lautenspiel", "tokens": ["Wa\u00df", "kan", "ein", "ar\u00b7mes", "Lau\u00b7ten\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch gegen die Artzneykunst machen?", "tokens": ["Doch", "ge\u00b7gen", "die", "Artz\u00b7ney\u00b7kunst", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.5": {"line.1": {"text": "So viel Gesundheit besser ist", "tokens": ["So", "viel", "Ge\u00b7sund\u00b7heit", "bes\u00b7ser", "ist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Al\u00df Kranckheit, Leben al\u00df verbleichen,", "tokens": ["Al\u00df", "Kran\u00b7ck\u00b7heit", ",", "Le\u00b7ben", "al\u00df", "ver\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So wirdt ein Artzt weit mehr erkiest", "tokens": ["So", "wirdt", "ein", "Artzt", "weit", "mehr", "er\u00b7kiest"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Al\u00df Opitz, Ich vnd meinesgleichen.", "tokens": ["Al\u00df", "O\u00b7pitz", ",", "Ich", "vnd", "mei\u00b7nes\u00b7glei\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PPER", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Daher ein Sennert vnd Galen", "tokens": ["Da\u00b7her", "ein", "Sen\u00b7nert", "vnd", "Ga\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "KON", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Offt grosse G\u00fctter kan erwerben,", "tokens": ["Offt", "gros\u00b7se", "G\u00fct\u00b7ter", "kan", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da ein Poet mu\u00df betteln gehn", "tokens": ["Da", "ein", "Po\u00b7et", "mu\u00df", "bet\u00b7teln", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VMFIN", "VVINF", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd nur f\u00fcr Hungers Noht nicht sterben.", "tokens": ["Vnd", "nur", "f\u00fcr", "Hun\u00b7gers", "Noht", "nicht", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Drumb ich dich gar nicht schelten kan,", "tokens": ["Drumb", "ich", "dich", "gar", "nicht", "schel\u00b7ten", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Du vn\u00df andre l\u00e4ssest singen", "tokens": ["Da\u00df", "Du", "vn\u00df", "and\u00b7re", "l\u00e4s\u00b7sest", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PIS", "VVFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vnd nimst dich kl\u00fcglich dessen an,", "tokens": ["Vnd", "nimst", "dich", "kl\u00fcg\u00b7lich", "des\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PDS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df in die K\u00fcche wa\u00df kan bringen.", "tokens": ["Da\u00df", "in", "die", "K\u00fc\u00b7che", "wa\u00df", "kan", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wolan, thu fleissig wa\u00df du thust,", "tokens": ["Wo\u00b7lan", ",", "thu", "fleis\u00b7sig", "wa\u00df", "du", "thust", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "ADJD", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich aber mu\u00df nur mich beklagen,", "tokens": ["Ich", "a\u00b7ber", "mu\u00df", "nur", "mich", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df du nach vmbgekehrter Lust,", "tokens": ["Da\u00df", "du", "nach", "vmb\u00b7ge\u00b7kehr\u00b7ter", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nach meiner Noht wirst wenig fragen.", "tokens": ["Nach", "mei\u00b7ner", "Noht", "wirst", "we\u00b7nig", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Du weist, wa\u00df ich dich newlich baht,", "tokens": ["Du", "weist", ",", "wa\u00df", "ich", "dich", "new\u00b7lich", "baht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Thumthor stiessen wir zusammen,", "tokens": ["Im", "Thumt\u00b7hor", "sties\u00b7sen", "wir", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ach Bruder, sprach ich, schaff mir Raht", "tokens": ["Ach", "Bru\u00b7der", ",", "sprach", "ich", ",", "schaff", "mir", "Raht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "NN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd lindre meiner Zunge Flammen.", "tokens": ["Vnd", "lind\u00b7re", "mei\u00b7ner", "Zun\u00b7ge", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Antwort war: Hab gutten Muth,", "tokens": ["Die", "Ant\u00b7wort", "war", ":", "Hab", "gut\u00b7ten", "Muth", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In kurtzen wil ich zu dir kommen.", "tokens": ["In", "kurt\u00b7zen", "wil", "ich", "zu", "dir", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die\u00df ist vergessen, da die Glut", "tokens": ["Die\u00df", "ist", "ver\u00b7ges\u00b7sen", ",", "da", "die", "Glut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "VVPP", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Indessen Vberhand genommen.", "tokens": ["In\u00b7des\u00b7sen", "Vber\u00b7hand", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Chimaera w\u00fctet bey der Nacht", "tokens": ["Chi\u00b7mae\u00b7ra", "w\u00fc\u00b7tet", "bey", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht also sehr mit wildem Fewer,", "tokens": ["Nicht", "al\u00b7so", "sehr", "mit", "wil\u00b7dem", "Fe\u00b7wer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch Lipara hat minder Macht", "tokens": ["Auch", "Li\u00b7pa\u00b7ra", "hat", "min\u00b7der", "Macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VAFIN", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu brennen al\u00df mein Vngehewer.", "tokens": ["Zu", "bren\u00b7nen", "al\u00df", "mein", "Vn\u00b7ge\u00b7he\u00b7wer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Der Heckelsberg wird durch mein Weh,", "tokens": ["Der", "He\u00b7ckels\u00b7berg", "wird", "durch", "mein", "Weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der \u00c4tna durch mein Leid bezwungen,", "tokens": ["Der", "\u00c4t\u00b7na", "durch", "mein", "Leid", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Pyragmon, Brontes, Sterope,", "tokens": ["Py\u00b7rag\u00b7mon", ",", "Bron\u00b7tes", ",", "Ste\u00b7ro\u00b7pe", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Euch trag ich all auff meiner Zungen.", "tokens": ["Euch", "trag", "ich", "all", "auff", "mei\u00b7ner", "Zun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Hilff, Bruder, mir in dieser Pein,", "tokens": ["Hilff", ",", "Bru\u00b7der", ",", "mir", "in", "die\u00b7ser", "Pein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Fall sie anders noch zu heben,", "tokens": ["Im", "Fall", "sie", "an\u00b7ders", "noch", "zu", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gieb heut mir einen K\u00fchltranck ein,", "tokens": ["Gieb", "heut", "mir", "ei\u00b7nen", "K\u00fchl\u00b7tranck", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denn morgen m\u00f6cht ich nicht mehr leben,", "tokens": ["Denn", "mor\u00b7gen", "m\u00f6cht", "ich", "nicht", "mehr", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Gestehst du billich, da\u00df mein Mund", "tokens": ["Ge\u00b7stehst", "du", "bil\u00b7lich", ",", "da\u00df", "mein", "Mund"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich durch sein Fewer vmb sol bringen,", "tokens": ["Mich", "durch", "sein", "Fe\u00b7wer", "vmb", "sol", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PPOSAT", "NN", "APPR", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df meine Zung ist vngesund,", "tokens": ["Da\u00df", "mei\u00b7ne", "Zung", "ist", "vn\u00b7ge\u00b7sund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ewig deinen Ruhm wirdt singen.", "tokens": ["Die", "e\u00b7wig", "dei\u00b7nen", "Ruhm", "wirdt", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPOSAT", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}