{"textgrid.poem.60713": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Zwei Wandrer sahen einst im Sand", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zwei Wandrer sahen einst im Sand", "tokens": ["Zwei", "Wand\u00b7rer", "sa\u00b7hen", "einst", "im", "Sand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor ihren F\u00fc\u00dfen eine Auster liegen.", "tokens": ["Vor", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", "ei\u00b7ne", "Aus\u00b7ter", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihr Blick verschlingt die Beute, und die Hand", "tokens": ["Ihr", "Blick", "ver\u00b7schlingt", "die", "Beu\u00b7te", ",", "und", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Will wie der Blick so schnell zur Erde fliegen.", "tokens": ["Will", "wie", "der", "Blick", "so", "schnell", "zur", "Er\u00b7de", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "KOKOM", "ART", "NN", "ADV", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Schon b\u00fcckt der eine sich, die Muschel aufzuheben;", "tokens": ["Schon", "b\u00fcckt", "der", "ei\u00b7ne", "sich", ",", "die", "Mu\u00b7schel", "auf\u00b7zu\u00b7he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ART", "PRF", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der andre doch versetzt ihm einen Sto\u00df:", "tokens": ["Der", "and\u00b7re", "doch", "ver\u00b7setzt", "ihm", "ei\u00b7nen", "Sto\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbman mu\u00df erst zu ergr\u00fcnden streben,", "tokens": ["\u00bb", "man", "mu\u00df", "erst", "zu", "er\u00b7gr\u00fcn\u00b7den", "stre\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VMFIN", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wen von uns beiden trifft das Freudenlos.", "tokens": ["Wen", "von", "uns", "bei\u00b7den", "trifft", "das", "Freu\u00b7den\u00b7los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "PPER", "PIS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Derjenige von uns, der sie zuerst gesehen,", "tokens": ["Der\u00b7je\u00b7ni\u00b7ge", "von", "uns", ",", "der", "sie", "zu\u00b7erst", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Soll diese Auster schmausen.\u00ab", "tokens": ["Soll", "die\u00b7se", "Aus\u00b7ter", "schmau\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PDAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "\u00bboh,\u00ab rief der andere, \u00bbda kann ich gut bestehen,", "tokens": ["\u00bb", "oh", ",", "\u00ab", "rief", "der", "an\u00b7de\u00b7re", ",", "\u00bb", "da", "kann", "ich", "gut", "be\u00b7ste\u00b7hen", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "$,", "$(", "VVFIN", "ART", "ADJA", "$,", "$(", "ADV", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mein Auge ist vortrefflich, ohne Flausen.\u00ab", "tokens": ["Mein", "Au\u00b7ge", "ist", "vor\u00b7treff\u00b7lich", ",", "oh\u00b7ne", "Flau\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KOUI", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der erste drauf: \u00bbIch sah sie ehr als du,", "tokens": ["Der", "ers\u00b7te", "drauf", ":", "\u00bb", "Ich", "sah", "sie", "ehr", "als", "du", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Bei meinem Leben, mir geh\u00f6rt sie zu!\u00ab", "tokens": ["Bei", "mei\u00b7nem", "Le\u00b7ben", ",", "mir", "ge\u00b7h\u00f6rt", "sie", "zu", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "\u00bbich aber hatte sie vorher bereits gerochen.\u00ab", "tokens": ["\u00bb", "ich", "a\u00b7ber", "hat\u00b7te", "sie", "vor\u00b7her", "be\u00b7reits", "ge\u00b7ro\u00b7chen", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So wurde hin und her gesprochen,", "tokens": ["So", "wur\u00b7de", "hin", "und", "her", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Als Perrin Dandin sich hinzugesellt.", "tokens": ["Als", "Per\u00b7rin", "Dan\u00b7din", "sich", "hin\u00b7zu\u00b7ge\u00b7sellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NE", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Er wird als Richter aufgestellt.", "tokens": ["Er", "wird", "als", "Rich\u00b7ter", "auf\u00b7ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Perrin bricht stumm die Auster auf und schl\u00fcrft sie aus.", "tokens": ["Per\u00b7rin", "bricht", "stumm", "die", "Aus\u00b7ter", "auf", "und", "schl\u00fcrft", "sie", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "ART", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die beiden sehn verdutzt ihn an.", "tokens": ["Die", "bei\u00b7den", "sehn", "ver\u00b7dutzt", "ihn", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Pr\u00e4sident zieht seine Stirne kraus", "tokens": ["Der", "Pr\u00e4\u00b7si\u00b7dent", "zieht", "sei\u00b7ne", "Stir\u00b7ne", "kraus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und sagt sodann:", "tokens": ["Und", "sagt", "so\u00b7dann", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "\u00bbhier, das Gericht teilt jedem eine Schale zu,", "tokens": ["\u00bb", "hier", ",", "das", "Ge\u00b7richt", "teilt", "je\u00b7dem", "ei\u00b7ne", "Scha\u00b7le", "zu", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "ART", "NN", "VVFIN", "PIS", "ART", "NN", "PTKVZ", "$,"], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.5": {"text": "Nun geht nach Haus und gebet Ruh.\u00ab", "tokens": ["Nun", "geht", "nach", "Haus", "und", "ge\u00b7bet", "Ruh", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "VVFIN", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Bedenkt, was heute ein Proze\u00df verschluckt,", "tokens": ["Be\u00b7denkt", ",", "was", "heu\u00b7te", "ein", "Pro\u00b7ze\u00df", "ver\u00b7schluckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Berechnet auch, da\u00df manchem nichts mehr bleibt,", "tokens": ["Be\u00b7rech\u00b7net", "auch", ",", "da\u00df", "man\u00b7chem", "nichts", "mehr", "bleibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "PIAT", "PIS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "So seht ihr bald, wonach es Perrin juckt,", "tokens": ["So", "seht", "ihr", "bald", ",", "wo\u00b7nach", "es", "Per\u00b7rin", "juckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der euch mit leerem Sack nach Hause treibt,", "tokens": ["Der", "euch", "mit", "lee\u00b7rem", "Sack", "nach", "Hau\u00b7se", "treibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nachdem er alle Kosten eingezogen", "tokens": ["Nach\u00b7dem", "er", "al\u00b7le", "Kos\u00b7ten", "ein\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und bis aufs Blut euch ausgesogen.", "tokens": ["Und", "bis", "aufs", "Blut", "euch", "aus\u00b7ge\u00b7so\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum, beide, einigt euch, so gut es eben geht,", "tokens": ["Drum", ",", "bei\u00b7de", ",", "ei\u00b7nigt", "euch", ",", "so", "gut", "es", "e\u00b7ben", "geht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "PIS", "$,", "VVFIN", "PPER", "$,", "ADV", "ADJD", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Weil sonst ein Dritter euch die Nase dreht.", "tokens": ["Weil", "sonst", "ein", "Drit\u00b7ter", "euch", "die", "Na\u00b7se", "dreht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}