{"textgrid.poem.34917": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf dem Haupt trug er den Lorbeer,", "tokens": ["Auf", "dem", "Haupt", "trug", "er", "den", "Lor\u00b7beer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und an seinen Stiefeln gl\u00e4nzten", "tokens": ["Und", "an", "sei\u00b7nen", "Stie\u00b7feln", "gl\u00e4nz\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Goldne Sporen \u2013 dennoch war er", "tokens": ["Gold\u00b7ne", "Spo\u00b7ren", "\u2013", "den\u00b7noch", "war", "er"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$(", "ADV", "VAFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht ein Held und auch kein Ritter.", "tokens": ["Nicht", "ein", "Held", "und", "auch", "kein", "Rit\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "KON", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Nur ein R\u00e4uberhauptmann war er,", "tokens": ["Nur", "ein", "R\u00e4u\u00b7ber\u00b7haupt\u00b7mann", "war", "er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der ins Buch des Ruhmes einschrieb,", "tokens": ["Der", "ins", "Buch", "des", "Ruh\u00b7mes", "ein\u00b7schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mit der eignen frechen Faust,", "tokens": ["Mit", "der", "eig\u00b7nen", "fre\u00b7chen", "Faust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seinen frechen Namen: Cortez.", "tokens": ["Sei\u00b7nen", "fre\u00b7chen", "Na\u00b7men", ":", "Cor\u00b7tez", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.3": {"line.1": {"text": "Unter des Kolumbus Namen", "tokens": ["Un\u00b7ter", "des", "Ko\u00b7lum\u00b7bus", "Na\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schrieb er ihn, ja dicht darunter,", "tokens": ["Schrieb", "er", "ihn", ",", "ja", "dicht", "da\u00b7run\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADV", "ADJD", "PAV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der Schulbub' auf der Schulbank", "tokens": ["Und", "der", "Schul\u00b7bub'", "auf", "der", "Schul\u00b7bank"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lernt auswendig beide Namen \u2013", "tokens": ["Lernt", "aus\u00b7wen\u00b7dig", "bei\u00b7de", "Na\u00b7men", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PIAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Nach dem Christoval Kolumbus,", "tokens": ["Nach", "dem", "Chris\u00b7to\u00b7val", "Ko\u00b7lum\u00b7bus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "NE", "$,"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.2": {"text": "Nennt er jetzt Fernando Cortez", "tokens": ["Nennt", "er", "jetzt", "Fer\u00b7nan\u00b7do", "Cor\u00b7tez"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "NE", "NE"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Als den zweiten gro\u00dfen Mann", "tokens": ["Als", "den", "zwei\u00b7ten", "gro\u00b7\u00dfen", "Mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In dem Pantheon der Neuwelt.", "tokens": ["In", "dem", "Pan\u00b7the\u00b7on", "der", "Neu\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Heldenschicksals letzte T\u00fccke:", "tokens": ["Hel\u00b7den\u00b7schick\u00b7sals", "letz\u00b7te", "T\u00fc\u00b7cke", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Name wird verkoppelt", "tokens": ["Un\u00b7ser", "Na\u00b7me", "wird", "ver\u00b7kop\u00b7pelt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem Namen eines Sch\u00e4chers", "tokens": ["Mit", "dem", "Na\u00b7men", "ei\u00b7nes", "Sch\u00e4\u00b7chers"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der Menschen Angedenken.", "tokens": ["In", "der", "Men\u00b7schen", "An\u00b7ge\u00b7den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "W\u00e4r's nicht besser, ganz verhallen", "tokens": ["W\u00e4r's", "nicht", "bes\u00b7ser", ",", "ganz", "ver\u00b7hal\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADJD", "$,", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unbekannt, als mit sich schleppen", "tokens": ["Un\u00b7be\u00b7kannt", ",", "als", "mit", "sich", "schlep\u00b7pen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "KOUS", "APPR", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Durch die langen Ewigkeiten", "tokens": ["Durch", "die", "lan\u00b7gen", "E\u00b7wig\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Solche Namenskameradschaft?", "tokens": ["Sol\u00b7che", "Na\u00b7mens\u00b7ka\u00b7me\u00b7rad\u00b7schaft", "?"], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Messer Christoval Kolumbus", "tokens": ["Mes\u00b7ser", "Chris\u00b7to\u00b7val", "Ko\u00b7lum\u00b7bus"], "token_info": ["word", "word", "word"], "pos": ["NE", "NE", "NE"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.2": {"text": "War ein Held, und sein Gem\u00fcte,", "tokens": ["War", "ein", "Held", ",", "und", "sein", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das so lauter wie die Sonne,", "tokens": ["Das", "so", "lau\u00b7ter", "wie", "die", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PIAT", "KOKOM", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "War freigebig auch wie diese.", "tokens": ["War", "frei\u00b7ge\u00b7big", "auch", "wie", "die\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "KOKOM", "PDS", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Mancher hat schon viel gegeben,", "tokens": ["Man\u00b7cher", "hat", "schon", "viel", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber jener hat der Welt", "tokens": ["A\u00b7ber", "je\u00b7ner", "hat", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine ganze Welt geschenket,", "tokens": ["Ei\u00b7ne", "gan\u00b7ze", "Welt", "ge\u00b7schen\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und sie hei\u00dft Amerika.", "tokens": ["Und", "sie", "hei\u00dft", "A\u00b7me\u00b7ri\u00b7ka", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nicht befreien konnt er uns", "tokens": ["Nicht", "be\u00b7frei\u00b7en", "konnt", "er", "uns"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "VMFIN", "PPER", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus dem \u00f6den Erdenkerker,", "tokens": ["Aus", "dem", "\u00f6\u00b7den", "Er\u00b7den\u00b7ker\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch er wu\u00dft ihn zu erweitern", "tokens": ["Doch", "er", "wu\u00dft", "ihn", "zu", "er\u00b7wei\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die Kette zu verl\u00e4ngern.", "tokens": ["Und", "die", "Ket\u00b7te", "zu", "ver\u00b7l\u00e4n\u00b7gern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Dankbar huldigt ihm die Menschheit,", "tokens": ["Dank\u00b7bar", "hul\u00b7digt", "ihm", "die", "Menschheit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die nicht blo\u00df europam\u00fcde,", "tokens": ["Die", "nicht", "blo\u00df", "eu\u00b7ro\u00b7pa\u00b7m\u00fc\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern Afrikas und Asiens", "tokens": ["Son\u00b7dern", "Af\u00b7ri\u00b7kas", "und", "A\u00b7siens"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Endlich gleichfalls m\u00fcde worden \u2013 \u2013", "tokens": ["End\u00b7lich", "gleich\u00b7falls", "m\u00fc\u00b7de", "wor\u00b7den", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ADJD", "VAPP", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Einer nur, ein einz'ger Held,", "tokens": ["Ei\u00b7ner", "nur", ",", "ein", "einz'\u00b7ger", "Held", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gab uns mehr und gab uns Be\u00dfres", "tokens": ["Gab", "uns", "mehr", "und", "gab", "uns", "Be\u00df\u00b7res"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als Kolumbus, das ist jener,", "tokens": ["Als", "Ko\u00b7lum\u00b7bus", ",", "das", "ist", "je\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "$,", "PDS", "VAFIN", "PDS", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der uns einen Gott gegeben.", "tokens": ["Der", "uns", "ei\u00b7nen", "Gott", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Sein Herr Vater, der hie\u00df Amram,", "tokens": ["Sein", "Herr", "Va\u00b7ter", ",", "der", "hie\u00df", "Am\u00b7ram", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "PRELS", "VVFIN", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Seine Mutter hie\u00df Jochebeth,", "tokens": ["Sei\u00b7ne", "Mut\u00b7ter", "hie\u00df", "Jo\u00b7che\u00b7be\u00b7th", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NE", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Und er selber, Moses hei\u00dft er,", "tokens": ["Und", "er", "sel\u00b7ber", ",", "Mo\u00b7ses", "hei\u00dft", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "NE", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und er ist mein bester Heros.", "tokens": ["Und", "er", "ist", "mein", "bes\u00b7ter", "He\u00b7ros", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Doch, mein Pegasus, du weilest", "tokens": ["Doch", ",", "mein", "Pe\u00b7ga\u00b7sus", ",", "du", "wei\u00b7lest"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Viel zu lang bei dem Kolumbus \u2013", "tokens": ["Viel", "zu", "lang", "bei", "dem", "Ko\u00b7lum\u00b7bus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "APPR", "ART", "NN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Wisse, unser heut'ger Flugritt", "tokens": ["Wis\u00b7se", ",", "un\u00b7ser", "heut'\u00b7ger", "Flug\u00b7ritt"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gilt dem g'ringern Mann, dem Cortez.", "tokens": ["Gilt", "dem", "g'\u00b7rin\u00b7gern", "Mann", ",", "dem", "Cor\u00b7tez", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Breite aus den bunten Fittich,", "tokens": ["Brei\u00b7te", "aus", "den", "bun\u00b7ten", "Fit\u00b7tich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fl\u00fcgelro\u00df! und trage mich", "tokens": ["Fl\u00fc\u00b7gel\u00b7ro\u00df", "!", "und", "tra\u00b7ge", "mich"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "KON", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nach der Neuwelt sch\u00f6nem Lande,", "tokens": ["Nach", "der", "Neu\u00b7welt", "sch\u00f6\u00b7nem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches Mexiko gehei\u00dfen.", "tokens": ["Wel\u00b7ches", "Me\u00b7xi\u00b7ko", "ge\u00b7hei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "NE", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Trage mich nach jener Burg,", "tokens": ["Tra\u00b7ge", "mich", "nach", "je\u00b7ner", "Burg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die der K\u00f6nig Montezuma", "tokens": ["Die", "der", "K\u00f6\u00b7nig", "Mon\u00b7te\u00b7zu\u00b7ma"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NE"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Gastlich seinen span'schen G\u00e4sten", "tokens": ["Gast\u00b7lich", "sei\u00b7nen", "span'\u00b7schen", "G\u00e4s\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Angewiesen zur Behausung.", "tokens": ["An\u00b7ge\u00b7wie\u00b7sen", "zur", "Be\u00b7hau\u00b7sung", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Doch nicht Obdach blo\u00df und Atzung,", "tokens": ["Doch", "nicht", "Ob\u00b7dach", "blo\u00df", "und", "At\u00b7zung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "NN", "ADV", "KON", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "In verschwenderischer F\u00fclle,", "tokens": ["In", "ver\u00b7schwen\u00b7de\u00b7ri\u00b7scher", "F\u00fcl\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gab der F\u00fcrst den fremden Strolchen \u2013", "tokens": ["Gab", "der", "F\u00fcrst", "den", "frem\u00b7den", "Strol\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch Geschenke reich und pr\u00e4chtig,", "tokens": ["Auch", "Ge\u00b7schen\u00b7ke", "reich", "und", "pr\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Kostbarkeiten klug gedrechselt,", "tokens": ["Kost\u00b7bar\u00b7kei\u00b7ten", "klug", "ge\u00b7drech\u00b7selt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Von massivem Gold, Juwelen,", "tokens": ["Von", "mas\u00b7si\u00b7vem", "Gold", ",", "Ju\u00b7we\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zeugten gl\u00e4nzend von der Huld", "tokens": ["Zeug\u00b7ten", "gl\u00e4n\u00b7zend", "von", "der", "Huld"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und der Gro\u00dfmut des Monarchen.", "tokens": ["Und", "der", "Gro\u00df\u00b7mut", "des", "Mon\u00b7ar\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.18": {"line.1": {"text": "Dieser unzivilisierte,", "tokens": ["Die\u00b7ser", "un\u00b7zi\u00b7vi\u00b7li\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["PDAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Abergl\u00e4ubisch blinde Heide", "tokens": ["A\u00b7berg\u00b7l\u00e4u\u00b7bisch", "blin\u00b7de", "Hei\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Glaubte noch an Treu' und Ehre", "tokens": ["Glaub\u00b7te", "noch", "an", "Treu'", "und", "Eh\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und an Heiligkeit des Gastrechts.", "tokens": ["Und", "an", "Hei\u00b7lig\u00b7keit", "des", "Gast\u00b7rechts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Er willfahrte dem Gesuche,", "tokens": ["Er", "will\u00b7fahr\u00b7te", "dem", "Ge\u00b7su\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Beizuwohnen einem Feste,", "tokens": ["Bei\u00b7zu\u00b7woh\u00b7nen", "ei\u00b7nem", "Fes\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das in ihrer Burg die Spanier", "tokens": ["Das", "in", "ih\u00b7rer", "Burg", "die", "Spa\u00b7nier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "PPOSAT", "NN", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Ihm zu Ehren geben wollten \u2013", "tokens": ["Ihm", "zu", "Eh\u00b7ren", "ge\u00b7ben", "woll\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Und mit seinem Hofgesinde,", "tokens": ["Und", "mit", "sei\u00b7nem", "Hof\u00b7ge\u00b7sin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Arglos, huldreich, kam der K\u00f6nig", "tokens": ["Arg\u00b7los", ",", "huld\u00b7reich", ",", "kam", "der", "K\u00f6\u00b7nig"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ADJD", "$,", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In das spanische Quartier,", "tokens": ["In", "das", "spa\u00b7ni\u00b7sche", "Quar\u00b7tier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo Fanfaren ihn begr\u00fc\u00dften.", "tokens": ["Wo", "Fan\u00b7fa\u00b7ren", "ihn", "be\u00b7gr\u00fc\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Wie das Festspiel war betitelt,", "tokens": ["Wie", "das", "Fest\u00b7spiel", "war", "be\u00b7ti\u00b7telt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wei\u00df ich nicht. Es hie\u00df vielleicht:", "tokens": ["Wei\u00df", "ich", "nicht", ".", "Es", "hie\u00df", "viel\u00b7leicht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$.", "PPER", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbspan'sche Treue!\u00ab, doch der Autor", "tokens": ["\u00bb", "span'\u00b7sche", "Treu\u00b7e", "!", "\u00ab", ",", "doch", "der", "Au\u00b7tor"], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "$.", "$(", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nannt sich Don Fernando Cortez.", "tokens": ["Nannt", "sich", "Don", "Fer\u00b7nan\u00b7do", "Cor\u00b7tez", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "NE", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.22": {"line.1": {"text": "Dieser gab das Stichwort \u2013 pl\u00f6tzlich", "tokens": ["Die\u00b7ser", "gab", "das", "Stich\u00b7wort", "\u2013", "pl\u00f6tz\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$(", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward der K\u00f6nig \u00fcberfallen,", "tokens": ["Ward", "der", "K\u00f6\u00b7nig", "\u00fc\u00b7berf\u00b7al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und man band ihn und behielt ihn", "tokens": ["Und", "man", "band", "ihn", "und", "be\u00b7hielt", "ihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PPER", "KON", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In der Burg als eine Geisel.", "tokens": ["In", "der", "Burg", "als", "ei\u00b7ne", "Gei\u00b7sel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Aber Montezuma starb,", "tokens": ["A\u00b7ber", "Mon\u00b7te\u00b7zu\u00b7ma", "starb", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und da war der Damm gebrochen,", "tokens": ["Und", "da", "war", "der", "Damm", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Der die kecken Abenteurer", "tokens": ["Der", "die", "ke\u00b7cken", "A\u00b7bent\u00b7eu\u00b7rer"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sch\u00fctzte vor dem Zorn des Volkes.", "tokens": ["Sch\u00fctz\u00b7te", "vor", "dem", "Zorn", "des", "Vol\u00b7kes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Schrecklich jetzt begann die Brandung \u2013", "tokens": ["Schreck\u00b7lich", "jetzt", "be\u00b7gann", "die", "Bran\u00b7dung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie ein wild emp\u00f6rtes Meer", "tokens": ["Wie", "ein", "wild", "em\u00b7p\u00f6r\u00b7tes", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Tosten, rasten immer n\u00e4her", "tokens": ["Tos\u00b7ten", ",", "ras\u00b7ten", "im\u00b7mer", "n\u00e4\u00b7her"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "ADV", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die erz\u00fcrnten Menschenwellen.", "tokens": ["Die", "er\u00b7z\u00fcrn\u00b7ten", "Men\u00b7schen\u00b7wel\u00b7len", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Tapfer schlugen zwar die Spanier", "tokens": ["Tap\u00b7fer", "schlu\u00b7gen", "zwar", "die", "Spa\u00b7nier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "Jeden Sturm zur\u00fcck. Doch t\u00e4glich", "tokens": ["Je\u00b7den", "Sturm", "zu\u00b7r\u00fcck", ".", "Doch", "t\u00e4g\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "PTKVZ", "$.", "KON", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ward berennt die Burg aufs neue,", "tokens": ["Ward", "be\u00b7rennt", "die", "Burg", "aufs", "neu\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "NN", "APPRART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und erm\u00fcdend war das Kampfspiel.", "tokens": ["Und", "er\u00b7m\u00fc\u00b7dend", "war", "das", "Kampf\u00b7spiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Nach dem Tod des K\u00f6nigs stockte", "tokens": ["Nach", "dem", "Tod", "des", "K\u00f6\u00b7nigs", "stock\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch der Lebensmittel Zufuhr;", "tokens": ["Auch", "der", "Le\u00b7bens\u00b7mit\u00b7tel", "Zu\u00b7fuhr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "K\u00fcrzer wurden die Rationen,", "tokens": ["K\u00fcr\u00b7zer", "wur\u00b7den", "die", "Ra\u00b7ti\u00b7o\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Die Gesichter wurden l\u00e4nger.", "tokens": ["Die", "Ge\u00b7sich\u00b7ter", "wur\u00b7den", "l\u00e4n\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Und mit langen Angesichtern", "tokens": ["Und", "mit", "lan\u00b7gen", "An\u00b7ge\u00b7sich\u00b7tern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sahn sich an Hispaniens S\u00f6hne,", "tokens": ["Sahn", "sich", "an", "His\u00b7pa\u00b7ni\u00b7ens", "S\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NE", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und sie seufzten und sie dachten", "tokens": ["Und", "sie", "seufz\u00b7ten", "und", "sie", "dach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "KON", "PPER", "VVFIN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "An die traute Christenheimat,", "tokens": ["An", "die", "trau\u00b7te", "Chris\u00b7ten\u00b7hei\u00b7mat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}}, "stanza.28": {"line.1": {"text": "An das teure Vaterland,", "tokens": ["An", "das", "teu\u00b7re", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo die frommen Glocken l\u00e4uten", "tokens": ["Wo", "die", "from\u00b7men", "Glo\u00b7cken", "l\u00e4u\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und am Herde friedlich brodelt", "tokens": ["Und", "am", "Her\u00b7de", "fried\u00b7lich", "bro\u00b7delt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Ollea Potrida,", "tokens": ["Ei\u00b7ne", "Ol\u00b7lea", "Pot\u00b7ri\u00b7da", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Dick verschmoret mit Garbanzos,", "tokens": ["Dick", "ver\u00b7schmo\u00b7ret", "mit", "Gar\u00b7ban\u00b7zos", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unter welchen, schalkhaft duftend,", "tokens": ["Un\u00b7ter", "wel\u00b7chen", ",", "schalk\u00b7haft", "duf\u00b7tend", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PWAT", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch wohl kichernd, sich verbergen", "tokens": ["Auch", "wohl", "ki\u00b7chernd", ",", "sich", "ver\u00b7ber\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVPP", "$,", "PRF", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die geliebten Knoblauchw\u00fcrstchen.", "tokens": ["Die", "ge\u00b7lieb\u00b7ten", "Knob\u00b7lauch\u00b7w\u00fcrst\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Einen Kriegsrat hielt der Feldherr,", "tokens": ["Ei\u00b7nen", "Kriegs\u00b7rat", "hielt", "der", "Feld\u00b7herr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der R\u00fcckzug ward beschlossen;", "tokens": ["Und", "der", "R\u00fcck\u00b7zug", "ward", "be\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der n\u00e4chsten Tagesfr\u00fche", "tokens": ["In", "der", "n\u00e4chs\u00b7ten", "Ta\u00b7ges\u00b7fr\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Soll das Heer die Stadt verlassen.", "tokens": ["Soll", "das", "Heer", "die", "Stadt", "ver\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Leicht gelang's hineinzukommen", "tokens": ["Leicht", "ge\u00b7lang's", "hin\u00b7ein\u00b7zu\u00b7kom\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einst durch List dem klugen Cortez,", "tokens": ["Einst", "durch", "List", "dem", "klu\u00b7gen", "Cor\u00b7tez", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Doch die R\u00fcckkehr nach dem Festland", "tokens": ["Doch", "die", "R\u00fcck\u00b7kehr", "nach", "dem", "Fest\u00b7land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bot fatale Schwierigkeiten.", "tokens": ["Bot", "fa\u00b7ta\u00b7le", "Schwie\u00b7rig\u00b7kei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "Mexiko, die Inselstadt,", "tokens": ["Me\u00b7xi\u00b7ko", ",", "die", "In\u00b7sel\u00b7stadt", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Liegt in einem gro\u00dfen See,", "tokens": ["Liegt", "in", "ei\u00b7nem", "gro\u00b7\u00dfen", "See", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In der Mitte, flutumrauscht:", "tokens": ["In", "der", "Mit\u00b7te", ",", "flu\u00b7tum\u00b7rauscht", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine stolze Wasserfestung,", "tokens": ["Ei\u00b7ne", "stol\u00b7ze", "Was\u00b7ser\u00b7fes\u00b7tung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Mit dem Uferland verkehrend", "tokens": ["Mit", "dem", "U\u00b7fer\u00b7land", "ver\u00b7keh\u00b7rend"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur durch Schiffe, Fl\u00f6\u00dfe, Br\u00fccken,", "tokens": ["Nur", "durch", "Schif\u00b7fe", ",", "Fl\u00f6\u00b7\u00dfe", ",", "Br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die auf Riesenpf\u00e4hlen ruhen;", "tokens": ["Die", "auf", "Rie\u00b7sen\u00b7pf\u00e4h\u00b7len", "ru\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kleine Inseln bilden Furten.", "tokens": ["Klei\u00b7ne", "In\u00b7seln", "bil\u00b7den", "Fur\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Noch bevor die Sonne aufging,", "tokens": ["Noch", "be\u00b7vor", "die", "Son\u00b7ne", "auf\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Setzten sich in Marsch die Spanier;", "tokens": ["Setz\u00b7ten", "sich", "in", "Marsch", "die", "Spa\u00b7nier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NE", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Keine Trommel ward ger\u00fchret,", "tokens": ["Kei\u00b7ne", "Trom\u00b7mel", "ward", "ge\u00b7r\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kein Trompeter blies Reveille.", "tokens": ["Kein", "Trom\u00b7pe\u00b7ter", "blies", "Re\u00b7veil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.35": {"line.1": {"text": "Wollten ihre Wirte nicht", "tokens": ["Woll\u00b7ten", "ih\u00b7re", "Wir\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus dem s\u00fc\u00dfen Schlafe wecken \u2013", "tokens": ["Aus", "dem", "s\u00fc\u00b7\u00dfen", "Schla\u00b7fe", "we\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "(hunderttausend Indianer", "tokens": ["(", "hun\u00b7dert\u00b7tau\u00b7send", "In\u00b7di\u00b7a\u00b7ner"], "token_info": ["punct", "word", "word"], "pos": ["$(", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lagerten in Mexiko).", "tokens": ["La\u00b7ger\u00b7ten", "in", "Me\u00b7xi\u00b7ko", ")", "."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NE", "$(", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.36": {"line.1": {"text": "Doch der Spanier machte diesmal", "tokens": ["Doch", "der", "Spa\u00b7nier", "mach\u00b7te", "dies\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ohne seinen Wirt die Rechnung;", "tokens": ["Oh\u00b7ne", "sei\u00b7nen", "Wirt", "die", "Rech\u00b7nung", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Noch fr\u00fchzeit'ger aufgestanden", "tokens": ["Noch", "fr\u00fch\u00b7zeit'\u00b7ger", "auf\u00b7ge\u00b7stan\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Waren heut die Mexikaner.", "tokens": ["Wa\u00b7ren", "heut", "die", "Me\u00b7xi\u00b7ka\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "Auf den Br\u00fccken, auf den Fl\u00f6\u00dfen,", "tokens": ["Auf", "den", "Br\u00fc\u00b7cken", ",", "auf", "den", "Fl\u00f6\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf den Furten harrten sie,", "tokens": ["Auf", "den", "Fur\u00b7ten", "harr\u00b7ten", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Um den Abschiedstrunk alldorten", "tokens": ["Um", "den", "Ab\u00b7schieds\u00b7trunk", "all\u00b7dor\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihren G\u00e4sten zu kredenzen.", "tokens": ["Ih\u00b7ren", "G\u00e4s\u00b7ten", "zu", "kre\u00b7den\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}}, "stanza.38": {"line.1": {"text": "Auf den Br\u00fccken, Fl\u00f6\u00dfen, Furten,", "tokens": ["Auf", "den", "Br\u00fc\u00b7cken", ",", "Fl\u00f6\u00b7\u00dfen", ",", "Fur\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hei! da gab's ein toll Gelage!", "tokens": ["Hei", "!", "da", "gab's", "ein", "toll", "Ge\u00b7la\u00b7ge", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "ART", "ADJD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Rot in Str\u00f6men flo\u00df das Blut,", "tokens": ["Rot", "in", "Str\u00f6\u00b7men", "flo\u00df", "das", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die kecken Zecher rangen \u2013", "tokens": ["Und", "die", "ke\u00b7cken", "Ze\u00b7cher", "ran\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Rangen Leib an Leib gepre\u00dft,", "tokens": ["Ran\u00b7gen", "Leib", "an", "Leib", "ge\u00b7pre\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und wir sehn auf mancher nackten", "tokens": ["Und", "wir", "sehn", "auf", "man\u00b7cher", "nack\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Indianerbrust den Abdruck", "tokens": ["In\u00b7di\u00b7a\u00b7ner\u00b7brust", "den", "Ab\u00b7druck"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Span'scher R\u00fcstungsarabesken.", "tokens": ["Span'\u00b7scher", "R\u00fcs\u00b7tungs\u00b7a\u00b7ra\u00b7bes\u00b7ken", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Ein Erdrosseln war's, ein W\u00fcrgen,", "tokens": ["Ein", "Er\u00b7dros\u00b7seln", "wa\u00b7r's", ",", "ein", "W\u00fcr\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Ein Gemetzel, das sich langsam,", "tokens": ["Ein", "Ge\u00b7met\u00b7zel", ",", "das", "sich", "lang\u00b7sam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schaurig langsam, weiterw\u00e4lzte,", "tokens": ["Schau\u00b7rig", "lang\u00b7sam", ",", "wei\u00b7ter\u00b7w\u00e4lz\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ADJD", "ADJD", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00dcber Br\u00fccken, Fl\u00f6\u00dfe, Furten.", "tokens": ["\u00dc\u00b7ber", "Br\u00fc\u00b7cken", ",", "Fl\u00f6\u00b7\u00dfe", ",", "Fur\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Die Indianer sangen, br\u00fcllten,", "tokens": ["Die", "In\u00b7di\u00b7a\u00b7ner", "san\u00b7gen", ",", "br\u00fcll\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Doch die Spanier fochten schweigend;", "tokens": ["Doch", "die", "Spa\u00b7nier", "foch\u00b7ten", "schwei\u00b7gend", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00dften Schritt f\u00fcr Schritt erobern", "tokens": ["Mu\u00df\u00b7ten", "Schritt", "f\u00fcr", "Schritt", "er\u00b7o\u00b7bern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "NN", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Boden f\u00fcr die Flucht.", "tokens": ["Ei\u00b7nen", "Bo\u00b7den", "f\u00fcr", "die", "Flucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "In gedr\u00e4ngten Engpa\u00dfk\u00e4mpfen", "tokens": ["In", "ge\u00b7dr\u00e4ng\u00b7ten", "Eng\u00b7pa\u00df\u00b7k\u00e4mp\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Boten g'ringen Vorteil heute", "tokens": ["Bo\u00b7ten", "g'\u00b7rin\u00b7gen", "Vor\u00b7teil", "heu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "ADV"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Alteuropas strenge Kriegskunst,", "tokens": ["Al\u00b7teu\u00b7ro\u00b7pas", "stren\u00b7ge", "Kriegs\u00b7kunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Feuerschl\u00fcnde, Harnisch, Pferde.", "tokens": ["Feu\u00b7er\u00b7schl\u00fcn\u00b7de", ",", "Har\u00b7nisch", ",", "Pfer\u00b7de", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Viele Spanier waren gleichfalls", "tokens": ["Vie\u00b7le", "Spa\u00b7nier", "wa\u00b7ren", "gleich\u00b7falls"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwer bepackt mit jenem Golde,", "tokens": ["Schwer", "be\u00b7packt", "mit", "je\u00b7nem", "Gol\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Das sie j\u00fcngst erpre\u00dft, erbeutet \u2013", "tokens": ["Das", "sie", "j\u00fcngst", "er\u00b7pre\u00dft", ",", "er\u00b7beu\u00b7tet", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "VVFIN", "$,", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ach, die gelbe S\u00fcndenlast", "tokens": ["Ach", ",", "die", "gel\u00b7be", "S\u00fcn\u00b7den\u00b7last"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "L\u00e4hmte, hemmte sie im Kampfe,", "tokens": ["L\u00e4hm\u00b7te", ",", "hemm\u00b7te", "sie", "im", "Kamp\u00b7fe", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und das teuflische Metall", "tokens": ["Und", "das", "teuf\u00b7li\u00b7sche", "Me\u00b7tall"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ward nicht blo\u00df der armen Seele,", "tokens": ["Ward", "nicht", "blo\u00df", "der", "ar\u00b7men", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern auch dem Leib verderblich.", "tokens": ["Son\u00b7dern", "auch", "dem", "Leib", "ver\u00b7derb\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Mittlerweile ward der See", "tokens": ["Mitt\u00b7ler\u00b7wei\u00b7le", "ward", "der", "See"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ganz bedeckt von K\u00e4hnen, Barken;", "tokens": ["Ganz", "be\u00b7deckt", "von", "K\u00e4h\u00b7nen", ",", "Bar\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00fctzen sa\u00dfen drin und schossen", "tokens": ["Sch\u00fct\u00b7zen", "sa\u00b7\u00dfen", "drin", "und", "schos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach den Br\u00fccken, Fl\u00f6\u00dfen, Furten.", "tokens": ["Nach", "den", "Br\u00fc\u00b7cken", ",", "Fl\u00f6\u00b7\u00dfen", ",", "Fur\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "Trafen freilich im Get\u00fcmmel", "tokens": ["Tra\u00b7fen", "frei\u00b7lich", "im", "Ge\u00b7t\u00fcm\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Viele ihrer eignen Br\u00fcder,", "tokens": ["Vie\u00b7le", "ih\u00b7rer", "eig\u00b7nen", "Br\u00fc\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch sie trafen auch gar manchen", "tokens": ["Doch", "sie", "tra\u00b7fen", "auch", "gar", "man\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADV", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hochvortrefflichen Hidalgo.", "tokens": ["Hoch\u00b7vor\u00b7treff\u00b7li\u00b7chen", "Hi\u00b7dal\u00b7go", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.47": {"line.1": {"text": "Auf der dritten Br\u00fccke fiel", "tokens": ["Auf", "der", "drit\u00b7ten", "Br\u00fc\u00b7cke", "fiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Junker Gaston, der an jenem", "tokens": ["Jun\u00b7ker", "Gas\u00b7ton", ",", "der", "an", "je\u00b7nem"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "APPR", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Tag die Fahne trug, worauf", "tokens": ["Tag", "die", "Fah\u00b7ne", "trug", ",", "wo\u00b7rauf"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "ART", "NN", "VVFIN", "$,", "PWAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Konterfeit die heil'ge Jungfrau.", "tokens": ["Kon\u00b7ter\u00b7feit", "die", "heil'\u00b7ge", "Jung\u00b7frau", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Dieses Bildnis selber trafen", "tokens": ["Die\u00b7ses", "Bild\u00b7nis", "sel\u00b7ber", "tra\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Geschosse der Indianer;", "tokens": ["Die", "Ge\u00b7schos\u00b7se", "der", "In\u00b7di\u00b7a\u00b7ner", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Sechs Geschosse blieben stecken", "tokens": ["Sechs", "Ge\u00b7schos\u00b7se", "blie\u00b7ben", "ste\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["CARD", "NN", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Just im Herzen \u2013 blanke Pfeile,", "tokens": ["Just", "im", "Her\u00b7zen", "\u2013", "blan\u00b7ke", "Pfei\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$(", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.49": {"line.1": {"text": "\u00c4hnlich jenen g\u00fcldnen Schwertern,", "tokens": ["\u00c4hn\u00b7lich", "je\u00b7nen", "g\u00fcld\u00b7nen", "Schwer\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die der Mater dolorosa", "tokens": ["Die", "der", "Ma\u00b7ter", "do\u00b7lo\u00b7ro\u00b7sa"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schmerzenreiche Brust durchbohren", "tokens": ["Schmer\u00b7zen\u00b7rei\u00b7che", "Brust", "durch\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bei Karfreitagsprozessionen.", "tokens": ["Bei", "Kar\u00b7frei\u00b7tags\u00b7pro\u00b7zes\u00b7si\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Sterbend \u00fcbergab Don Gaston", "tokens": ["Ster\u00b7bend", "\u00fc\u00b7berg\u00b7ab", "Don", "Gas\u00b7ton"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "NE", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine Fahne dem Gonzalvo,", "tokens": ["Sei\u00b7ne", "Fah\u00b7ne", "dem", "Gon\u00b7zal\u00b7vo", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NE", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Der zu Tod getroffen gleichfalls", "tokens": ["Der", "zu", "Tod", "ge\u00b7trof\u00b7fen", "gleich\u00b7falls"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "VVPP", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bald dahinsank. \u2013 Jetzt ergriff", "tokens": ["Bald", "da\u00b7hin\u00b7sank", ".", "\u2013", "Jetzt", "er\u00b7griff"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$.", "$(", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Cortez selbst das teure Banner,", "tokens": ["Cor\u00b7tez", "selbst", "das", "teu\u00b7re", "Ban\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Er, der Feldherr, und er trug es", "tokens": ["Er", ",", "der", "Feld\u00b7herr", ",", "und", "er", "trug", "es"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "ART", "NN", "$,", "KON", "PPER", "VVFIN", "PPER"], "meter": "--++--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Hoch zu Ro\u00df bis gegen Abend,", "tokens": ["Hoch", "zu", "Ro\u00df", "bis", "ge\u00b7gen", "A\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "APPR", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wo die Schlacht ein Ende nahm.", "tokens": ["Wo", "die", "Schlacht", "ein", "En\u00b7de", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Hundertsechzig Spanier fanden", "tokens": ["Hun\u00b7dert\u00b7sech\u00b7zig", "Spa\u00b7nier", "fan\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["CARD", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihren Tod an jenem Tage;", "tokens": ["Ih\u00b7ren", "Tod", "an", "je\u00b7nem", "Ta\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00dcber achtzig fielen lebend", "tokens": ["\u00dc\u00b7ber", "acht\u00b7zig", "fie\u00b7len", "le\u00b7bend"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "CARD", "VVFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In die H\u00e4nde der Indianer.", "tokens": ["In", "die", "H\u00e4n\u00b7de", "der", "In\u00b7di\u00b7a\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.53": {"line.1": {"text": "Schwer verwundet wurden viele,", "tokens": ["Schwer", "ver\u00b7wun\u00b7det", "wur\u00b7den", "vie\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "PIS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die erst sp\u00e4ter unterlagen.", "tokens": ["Die", "erst", "sp\u00e4\u00b7ter", "un\u00b7ter\u00b7la\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schier ein Dutzend Pferde wurde", "tokens": ["Schier", "ein", "Dut\u00b7zend", "Pfer\u00b7de", "wur\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "NN", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Teils get\u00f6tet, teils erbeutet.", "tokens": ["Teils", "ge\u00b7t\u00f6\u00b7tet", ",", "teils", "er\u00b7beu\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "Gegen Abend erst erreichten", "tokens": ["Ge\u00b7gen", "A\u00b7bend", "erst", "er\u00b7reich\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Cortez und sein Herr das sichre", "tokens": ["Cor\u00b7tez", "und", "sein", "Herr", "das", "sich\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "PPOSAT", "NN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Uferland, ein Seegestade,", "tokens": ["U\u00b7fer\u00b7land", ",", "ein", "See\u00b7ge\u00b7sta\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Karg bepflanzt mit Trauerweiden.", "tokens": ["Karg", "be\u00b7pflanzt", "mit", "Trau\u00b7er\u00b7wei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}