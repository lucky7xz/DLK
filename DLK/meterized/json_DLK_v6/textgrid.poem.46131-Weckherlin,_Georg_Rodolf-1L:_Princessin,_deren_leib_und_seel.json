{"textgrid.poem.46131": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Princessin, deren leib und seel", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Princessin, deren leib und seel", "tokens": ["Prin\u00b7ces\u00b7sin", ",", "de\u00b7ren", "leib", "und", "seel"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELAT", "NN", "KON", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "ganz himmelisch, ohn allen fehl,", "tokens": ["ganz", "him\u00b7me\u00b7lisch", ",", "ohn", "al\u00b7len", "fehl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein s\u00fc\u00dfes wunder hie auf erden:", "tokens": ["ein", "s\u00fc\u00b7\u00dfes", "wun\u00b7der", "hie", "auf", "er\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "nach eures sch\u00f6nen leibs gestalt", "tokens": ["nach", "eu\u00b7res", "sch\u00f6\u00b7nen", "leibs", "ge\u00b7stalt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und eurer lieblichkeit gewalt", "tokens": ["und", "eu\u00b7rer", "lieb\u00b7lich\u00b7keit", "ge\u00b7walt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "k\u00f6nt ihr wol Venus genant werden.", "tokens": ["k\u00f6nt", "ihr", "wol", "Ve\u00b7nus", "ge\u00b7nant", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NE", "VVPP", "VAINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Ihr habt, wie sie, braunlechte haar", "tokens": ["Ihr", "habt", ",", "wie", "sie", ",", "braun\u00b7lech\u00b7te", "haar"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "$,", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und augen braunlecht leuchtend klar", "tokens": ["und", "au\u00b7gen", "braun\u00b7lecht", "leuch\u00b7tend", "klar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und alles was sch\u00f6n zu vermehren", "tokens": ["und", "al\u00b7les", "was", "sch\u00f6n", "zu", "ver\u00b7meh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "PWS", "ADJD", "PTKZU", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "und ihr k\u00f6nt mit dem reinen strick", "tokens": ["und", "ihr", "k\u00f6nt", "mit", "dem", "rei\u00b7nen", "strick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "des haars und mit der augen blick", "tokens": ["des", "haars", "und", "mit", "der", "au\u00b7gen", "blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mehr dan sie fangen und versehren.", "tokens": ["mehr", "dan", "sie", "fan\u00b7gen", "und", "ver\u00b7seh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wird aber euer glatte stirn", "tokens": ["Wird", "a\u00b7ber", "eu\u00b7er", "glat\u00b7te", "stirn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und der, aus dessen weisen hirn", "tokens": ["und", "der", ",", "aus", "des\u00b7sen", "wei\u00b7sen", "hirn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ihr in die welt gebracht betrachtet:", "tokens": ["ihr", "in", "die", "welt", "ge\u00b7bracht", "be\u00b7trach\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVPP", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so werdet ihr mit gr\u00f6\u00dferm preis", "tokens": ["so", "wer\u00b7det", "ihr", "mit", "gr\u00f6\u00b7\u00dferm", "preis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "von denen, die gelehrt und weis,", "tokens": ["von", "de\u00b7nen", ",", "die", "ge\u00b7lehrt", "und", "weis", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "$,", "PRELS", "VVPP", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Minerva selbs zu sein geachtet.", "tokens": ["Mi\u00b7ner\u00b7va", "selbs", "zu", "sein", "ge\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "PPOSAT", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.4": {"line.1": {"text": "Und euer k\u00fchnes angesicht", "tokens": ["Und", "eu\u00b7er", "k\u00fch\u00b7nes", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gibt einen ernstlichen bericht", "tokens": ["gibt", "ei\u00b7nen", "ernst\u00b7li\u00b7chen", "be\u00b7richt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "von eurer keuschen lieb gedanken;", "tokens": ["von", "eu\u00b7rer", "keu\u00b7schen", "lieb", "ge\u00b7dan\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "gotsforcht, die euer schild und wehr,", "tokens": ["gots\u00b7forcht", ",", "die", "eu\u00b7er", "schild", "und", "wehr", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PRELS", "PPOSAT", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und fromkeit euer scharfes speer", "tokens": ["und", "from\u00b7keit", "eu\u00b7er", "schar\u00b7fes", "speer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "versperren den lust in den schranken.", "tokens": ["ver\u00b7sper\u00b7ren", "den", "lust", "in", "den", "schran\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wan, s\u00fc\u00df und sch\u00f6ne heldin, ihr", "tokens": ["Wan", ",", "s\u00fc\u00df", "und", "sch\u00f6\u00b7ne", "hel\u00b7din", ",", "ihr"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PWAV", "$,", "ADJD", "KON", "ADJA", "NN", "$,", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "reh, hirsch und andre wilde thier", "tokens": ["reh", ",", "hirsch", "und", "and\u00b7re", "wil\u00b7de", "thier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADJD", "KON", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "zu f\u00e4llen, wolt die w\u00e4ld durchziehen;", "tokens": ["zu", "f\u00e4l\u00b7len", ",", "wolt", "die", "w\u00e4ld", "durch\u00b7zie\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so sicht man, da\u00df die Nymfen euch", "tokens": ["so", "sicht", "man", ",", "da\u00df", "die", "Nym\u00b7fen", "euch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KOUS", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wie Ph\u00f6be folgen, und zugleich", "tokens": ["wie", "Ph\u00f6\u00b7be", "fol\u00b7gen", ",", "und", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "NN", "VVINF", "$,", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die \u00fcppige waldg\u00f6tter fliehen.", "tokens": ["die", "\u00fcp\u00b7pi\u00b7ge", "wald\u00b7g\u00f6t\u00b7ter", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar k\u00f6nt ihr wol Diana sein,", "tokens": ["Zwar", "k\u00f6nt", "ihr", "wol", "Di\u00b7a\u00b7na", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NE", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "als deren stetiger vollschein", "tokens": ["als", "de\u00b7ren", "ste\u00b7ti\u00b7ger", "voll\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PRELAT", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "kan die nacht in den tag verkehren,", "tokens": ["kan", "die", "nacht", "in", "den", "tag", "ver\u00b7keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "und deren zuckt ihr k\u00f6cher ist", "tokens": ["und", "de\u00b7ren", "zuckt", "ihr", "k\u00f6\u00b7cher", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und deren blick zu jeder frist", "tokens": ["und", "de\u00b7ren", "blick", "zu", "je\u00b7der", "frist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRELAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die g\u00f6tter stralen gleich versehren.", "tokens": ["die", "g\u00f6t\u00b7ter", "stra\u00b7len", "gleich", "ver\u00b7seh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Demnach dan eurer sch\u00f6nheit pracht", "tokens": ["Dem\u00b7nach", "dan", "eu\u00b7rer", "sch\u00f6n\u00b7heit", "pracht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und eurer tugend hohe macht", "tokens": ["und", "eu\u00b7rer", "tu\u00b7gend", "ho\u00b7he", "macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der sterblichen gesicht durchdringen,", "tokens": ["der", "sterb\u00b7li\u00b7chen", "ge\u00b7sicht", "durch\u00b7drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "so will sie alsbald die vernunft,", "tokens": ["so", "will", "sie", "als\u00b7bald", "die", "ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df Juno sie durch ihre kunft", "tokens": ["da\u00df", "Ju\u00b7no", "sie", "durch", "ih\u00b7re", "kunft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "erquicke, zu bekennen zwingen.", "tokens": ["er\u00b7qui\u00b7cke", ",", "zu", "be\u00b7ken\u00b7nen", "zwin\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Zwar eure zierliche person", "tokens": ["Zwar", "eu\u00b7re", "zier\u00b7li\u00b7che", "per\u00b7son"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(vil w\u00fcrdiger der h\u00f6chsten kron", "tokens": ["(", "vil", "w\u00fcr\u00b7di\u00b7ger", "der", "h\u00f6chs\u00b7ten", "kron"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dan Juno) kan sich wol bereichen", "tokens": ["dan", "Ju\u00b7no", ")", "kan", "sich", "wol", "be\u00b7rei\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "$(", "VMFIN", "PRF", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mit solchem schmuck nach ihrem stand,", "tokens": ["mit", "sol\u00b7chem", "schmuck", "nach", "ih\u00b7rem", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "da\u00df euch an k\u00f6stlichem gewand", "tokens": ["da\u00df", "euch", "an", "k\u00f6st\u00b7li\u00b7chem", "ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und kleinoten mu\u00df Juno weichen.", "tokens": ["und", "klei\u00b7no\u00b7ten", "mu\u00df", "Ju\u00b7no", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "NE", "VVINF", "$."], "meter": "-+---+-+-", "measure": "dactylic.init"}}, "stanza.9": {"line.1": {"text": "Also k\u00f6nt, g\u00f6ttin, ihr allein", "tokens": ["Al\u00b7so", "k\u00f6nt", ",", "g\u00f6t\u00b7tin", ",", "ihr", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "NE", "$,", "PPER", "ADV"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "mit keuschem unbeflecktem schein", "tokens": ["mit", "keu\u00b7schem", "un\u00b7be\u00b7fleck\u00b7tem", "schein"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mehr dan Diana; und mit lehren", "tokens": ["mehr", "dan", "Di\u00b7a\u00b7na", ";", "und", "mit", "leh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "NE", "$.", "KON", "APPR", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "mehr dan Pallas; mit lieblichkeit", "tokens": ["mehr", "dan", "Pal\u00b7las", ";", "mit", "lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "NN", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "mehr dan Cypris; mit k\u00f6stlichkeit", "tokens": ["mehr", "dan", "Cyp\u00b7ris", ";", "mit", "k\u00f6st\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "NE", "$.", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mehr dan Juno die welt gewehren.", "tokens": ["mehr", "dan", "Ju\u00b7no", "die", "welt", "ge\u00b7weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}