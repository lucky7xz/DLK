{"textgrid.poem.44195": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[der Bothe mit der Schlangenruthe]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Bothe mit der Schlangenruthe", "tokens": ["Der", "Bo\u00b7the", "mit", "der", "Schlan\u00b7gen\u00b7ru\u00b7the"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kam wieder auf dem Pindus an", "tokens": ["Kam", "wie\u00b7der", "auf", "dem", "Pin\u00b7dus", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und schwizt in seinem Fl\u00fcgelhute,", "tokens": ["Und", "schwizt", "in", "sei\u00b7nem", "Fl\u00fc\u00b7gel\u00b7hu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit dem er manche Fahrt gethan;", "tokens": ["Mit", "dem", "er", "man\u00b7che", "Fahrt", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn Phoebus hatt es ihm befohlen,", "tokens": ["Denn", "Phoe\u00b7bus", "hatt", "es", "ihm", "be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die hohen Schulen zu besehn", "tokens": ["Die", "ho\u00b7hen", "Schu\u00b7len", "zu", "be\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und frische Nachricht einzuholen,", "tokens": ["Und", "fri\u00b7sche", "Nach\u00b7richt", "ein\u00b7zu\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was etwan hier und dar geschehn.", "tokens": ["Was", "et\u00b7wan", "hier", "und", "dar", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "KON", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Jezt kehrt er, wie gesagt, zur\u00fccke,", "tokens": ["Jezt", "kehrt", "er", ",", "wie", "ge\u00b7sagt", ",", "zu\u00b7r\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Trug Busen, Maul und Schiebsack voll", "tokens": ["Trug", "Bu\u00b7sen", ",", "Maul", "und", "Schie\u00b7bsack", "voll"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und war von Zeitung fast so dicke", "tokens": ["Und", "war", "von", "Zei\u00b7tung", "fast", "so", "di\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als Gretchens Liebesprotocoll.", "tokens": ["Als", "Gret\u00b7chens", "Lie\u00b7be\u00b7spro\u00b7to\u00b7coll", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Musen eilten, ihn zu sprechen,", "tokens": ["Die", "Mu\u00b7sen", "eil\u00b7ten", ",", "ihn", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So neubegierig und geschwind,", "tokens": ["So", "neu\u00b7be\u00b7gie\u00b7rig", "und", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wie viel Schmarozer in die Zechen,", "tokens": ["Wie", "viel", "Schma\u00b7ro\u00b7zer", "in", "die", "Ze\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wo Pursch und Gl\u00e4ser gastfrey sind.", "tokens": ["Wo", "Pursch", "und", "Gl\u00e4\u00b7ser", "gast\u00b7frey", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "KON", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was machen denn nun unsre Leute?", "tokens": ["Was", "ma\u00b7chen", "denn", "nun", "uns\u00b7re", "Leu\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So fragt Apollo den Mercur,", "tokens": ["So", "fragt", "A\u00b7pol\u00b7lo", "den", "Mer\u00b7cur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Der anfangs Red und Antwort scheute,", "tokens": ["Der", "an\u00b7fangs", "Red", "und", "Ant\u00b7wort", "scheu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Indem er nichts als Leid erfuhr;", "tokens": ["In\u00b7dem", "er", "nichts", "als", "Leid", "er\u00b7fuhr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch, sprach er, darf ich nicht verheelen", "tokens": ["Doch", ",", "sprach", "er", ",", "darf", "ich", "nicht", "ver\u00b7hee\u00b7len"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "(weil Phoebus scharf zu forschen pflegt),", "tokens": ["(", "weil", "Phoe\u00b7bus", "scharf", "zu", "for\u00b7schen", "pflegt", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "NE", "ADJD", "PTKZU", "VVINF", "VVFIN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was Deutschland jezt vor theure Seelen", "tokens": ["Was", "Deutschland", "jezt", "vor", "theu\u00b7re", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "NE", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Und eure Schoos vor Kinder tr\u00e4gt.", "tokens": ["Und", "eu\u00b7re", "Schoos", "vor", "Kin\u00b7der", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O s\u00e4ht ihr selbst, wie sie studiren,", "tokens": ["O", "s\u00e4ht", "ihr", "selbst", ",", "wie", "sie", "stu\u00b7di\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr g\u00e4bt die sch\u00f6nste Leyer drum", "tokens": ["Ihr", "g\u00e4bt", "die", "sch\u00f6ns\u00b7te", "Le\u00b7yer", "drum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lachtet \u00fcber solchen Thieren", "tokens": ["Und", "lach\u00b7tet", "\u00fc\u00b7ber", "sol\u00b7chen", "Thie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den allerlezten Backzahn krumm.", "tokens": ["Den", "al\u00b7ler\u00b7lez\u00b7ten", "Back\u00b7zahn", "krumm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es brachte mich die erste Reise", "tokens": ["Es", "brach\u00b7te", "mich", "die", "ers\u00b7te", "Rei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bey hoher Nacht in ihren Schwarm;", "tokens": ["Bey", "ho\u00b7her", "Nacht", "in", "ih\u00b7ren", "Schwarm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hier sezt ich mich verstellter Weise", "tokens": ["Hier", "sezt", "ich", "mich", "ver\u00b7stell\u00b7ter", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem ersten an den rechten Arm.", "tokens": ["Dem", "ers\u00b7ten", "an", "den", "rech\u00b7ten", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Da sof man nun mit ganzen P\u00e4\u00dfen", "tokens": ["Da", "sof", "man", "nun", "mit", "gan\u00b7zen", "P\u00e4\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf aller Huren Wohlseyn los,", "tokens": ["Auf", "al\u00b7ler", "Hu\u00b7ren", "Wohl\u00b7seyn", "los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da gab sich der, so viel gege\u00dfen,", "tokens": ["Da", "gab", "sich", "der", ",", "so", "viel", "ge\u00b7ge\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "$,", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit starck- und fetten K\u00e4lbern blos;", "tokens": ["Mit", "sta\u00b7rck", "und", "fet\u00b7ten", "K\u00e4l\u00b7bern", "blos", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "ADJA", "NN", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Den andern d\u00e4mpft es aus dem Munde", "tokens": ["Den", "an\u00b7dern", "d\u00e4mpft", "es", "aus", "dem", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie um den Schlund bey Taenara,", "tokens": ["Wie", "um", "den", "Schlund", "bey", "Tae\u00b7na\u00b7ra", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.7": {"text": "Bis ohngefehr die zw\u00f6lfte Stunde", "tokens": ["Bis", "ohn\u00b7ge\u00b7fehr", "die", "zw\u00f6lf\u00b7te", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den vollen Haufen taumeln sah.", "tokens": ["Den", "vol\u00b7len", "Hau\u00b7fen", "tau\u00b7meln", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier, dacht ich, mag der Hencker bleiben,", "tokens": ["Hier", ",", "dacht", "ich", ",", "mag", "der", "Hen\u00b7cker", "blei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und schlich mich in ein andres Nest;", "tokens": ["Und", "schlich", "mich", "in", "ein", "and\u00b7res", "Nest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da fand ich so ein Zeitvertreiben,", "tokens": ["Da", "fand", "ich", "so", "ein", "Zeit\u00b7ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bey dem sich Mars belachen l\u00e4st.", "tokens": ["Bey", "dem", "sich", "Mars", "be\u00b7la\u00b7chen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "NN", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Der gute Graukopf stund von ferne", "tokens": ["Der", "gu\u00b7te", "Grau\u00b7kopf", "stund", "von", "fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und hielt geduldig Licht und Wacht,", "tokens": ["Und", "hielt", "ge\u00b7dul\u00b7dig", "Licht", "und", "Wacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als h\u00e4tten ihm die holden Sterne", "tokens": ["Als", "h\u00e4t\u00b7ten", "ihm", "die", "hol\u00b7den", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Des Gl\u00fcckes F\u00fcllhorn zugedacht.", "tokens": ["Des", "Gl\u00fc\u00b7ckes", "F\u00fcll\u00b7horn", "zu\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "So bald Aurorens Rosenfinger", "tokens": ["So", "bald", "Au\u00b7ro\u00b7rens", "Ro\u00b7sen\u00b7fin\u00b7ger"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "NE", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der blinden Nacht die Augen schlo\u00df,", "tokens": ["Der", "blin\u00b7den", "Nacht", "die", "Au\u00b7gen", "schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erblickt ich zween lateinsche Ringer,", "tokens": ["Er\u00b7blickt", "ich", "zween", "la\u00b7tein\u00b7sche", "Rin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die irgend nur ein Wort verdro\u00df;", "tokens": ["Die", "ir\u00b7gend", "nur", "ein", "Wort", "ver\u00b7dro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie schlugen sich mit Stahl und Fl\u00fcchen,", "tokens": ["Sie", "schlu\u00b7gen", "sich", "mit", "Stahl", "und", "Fl\u00fc\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der eine brach die lincke Zeh", "tokens": ["Der", "ei\u00b7ne", "brach", "die", "lin\u00b7cke", "Zeh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und schrie, da jener schon gewichen:", "tokens": ["Und", "schrie", ",", "da", "je\u00b7ner", "schon", "ge\u00b7wi\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PDS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Halt, Bruder, halt, das Ding thut weh.", "tokens": ["Halt", ",", "Bru\u00b7der", ",", "halt", ",", "das", "Ding", "thut", "weh", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVFIN", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Nach diesem sah ich einen Prahler,", "tokens": ["Nach", "die\u00b7sem", "sah", "ich", "ei\u00b7nen", "Prah\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Marckt und Weg zu enge schien,", "tokens": ["Dem", "Marckt", "und", "Weg", "zu", "en\u00b7ge", "schien", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er lies die alten Mutterthaler", "tokens": ["Er", "lies", "die", "al\u00b7ten", "Mut\u00b7ter\u00b7tha\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Hochmuth aus dem Beuthel ziehn;", "tokens": ["Mit", "Hoch\u00b7muth", "aus", "dem", "Beut\u00b7hel", "ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da, wo er Groschen zehlen muste,", "tokens": ["Da", ",", "wo", "er", "Gro\u00b7schen", "zeh\u00b7len", "mus\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durchsucht er stets die Hand voll Geld,", "tokens": ["Durch\u00b7sucht", "er", "stets", "die", "Hand", "voll", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Woraus man leicht zu schlie\u00dfen wuste,", "tokens": ["Wo\u00b7raus", "man", "leicht", "zu", "schlie\u00b7\u00dfen", "wus\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie pr\u00e4chtig sich ein Juncker h\u00e4lt.", "tokens": ["Wie", "pr\u00e4ch\u00b7tig", "sich", "ein", "Jun\u00b7cker", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Er grif wohl zehnmahl in die Ficken", "tokens": ["Er", "grif", "wohl", "zehn\u00b7mahl", "in", "die", "Fi\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und guckte nach der Taschenuhr", "tokens": ["Und", "guck\u00b7te", "nach", "der", "Ta\u00b7sche\u00b7nuhr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und konte sich so k\u00fcnstlich r\u00fccken,", "tokens": ["Und", "kon\u00b7te", "sich", "so", "k\u00fcnst\u00b7lich", "r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df jeder ihren Werth erfuhr.", "tokens": ["Da\u00df", "je\u00b7der", "ih\u00b7ren", "Werth", "er\u00b7fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Hand kam niemahls von dem Degen,", "tokens": ["Die", "Hand", "kam", "nie\u00b7mahls", "von", "dem", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als wenn er es vor n\u00f6thig hielt,", "tokens": ["Als", "wenn", "er", "es", "vor", "n\u00f6\u00b7thig", "hielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die g\u00fcldne Krause gleich zu legen,", "tokens": ["Die", "g\u00fcld\u00b7ne", "Krau\u00b7se", "gleich", "zu", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mit der der Wind zu grob gespielt.", "tokens": ["Mit", "der", "der", "Wind", "zu", "grob", "ge\u00b7spielt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Es plagt ihn der gelehrte Nabel", "tokens": ["Es", "plagt", "ihn", "der", "ge\u00b7lehr\u00b7te", "Na\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Von vieler Kunst und Wi\u00dfenschaft,", "tokens": ["Von", "vie\u00b7ler", "Kunst", "und", "Wi\u00b7\u00dfen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und der noch etwas gr\u00fcne Schnabel", "tokens": ["Und", "der", "noch", "et\u00b7was", "gr\u00fc\u00b7ne", "Schna\u00b7bel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gab jeder Silbe Thon und Kraft.", "tokens": ["Gab", "je\u00b7der", "Sil\u00b7be", "Thon", "und", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich wollte seinen Stand erfahren,", "tokens": ["Ich", "woll\u00b7te", "sei\u00b7nen", "Stand", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Doch als die Balsamb\u00fcchse stanck,", "tokens": ["Doch", "als", "die", "Bal\u00b7sam\u00b7b\u00fcch\u00b7se", "stanck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So roch und sah ichs aus den Haaren", "tokens": ["So", "roch", "und", "sah", "ichs", "aus", "den", "Haa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "VVFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und sprach: Dem ist der Schwanz noch lang.", "tokens": ["Und", "sprach", ":", "Dem", "ist", "der", "Schwanz", "noch", "lang", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VAFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Drauf h\u00f6rt ich einen, der im Zimmer", "tokens": ["Drauf", "h\u00f6rt", "ich", "ei\u00b7nen", ",", "der", "im", "Zim\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ART", "$,", "PRELS", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Manich\u00e4er wiederlegt;", "tokens": ["Die", "Ma\u00b7nic\u00b7h\u00e4\u00b7er", "wie\u00b7der\u00b7legt", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ach Himmel, grunzt er, wirds noch schlimmer,", "tokens": ["Ach", "Him\u00b7mel", ",", "grunzt", "er", ",", "wirds", "noch", "schlim\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So weis ich, was der Seiger schl\u00e4gt.", "tokens": ["So", "weis", "ich", ",", "was", "der", "Sei\u00b7ger", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PPER", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Stiefel lauft schon von den F\u00fc\u00dfen", "tokens": ["Der", "Stie\u00b7fel", "lauft", "schon", "von", "den", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und mu\u00df nun zu Gevattern stehn;", "tokens": ["Und", "mu\u00df", "nun", "zu", "Ge\u00b7vat\u00b7tern", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Was aber werd ich singen m\u00fc\u00dfen,", "tokens": ["Was", "a\u00b7ber", "werd", "ich", "sin\u00b7gen", "m\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wenn auch die lieben Str\u00fcmpfe gehn?", "tokens": ["Wenn", "auch", "die", "lie\u00b7ben", "Str\u00fcmp\u00b7fe", "gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ich lies den armen Stuzer sizen", "tokens": ["Ich", "lies", "den", "ar\u00b7men", "Stu\u00b7zer", "si\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und kam an einen Jungfernknecht,", "tokens": ["Und", "kam", "an", "ei\u00b7nen", "Jung\u00b7fern\u00b7knecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem waren Leinwand, Hut und Spizen", "tokens": ["Dem", "wa\u00b7ren", "Lein\u00b7wand", ",", "Hut", "und", "Spi\u00b7zen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und alle Moden noch zu schlecht;", "tokens": ["Und", "al\u00b7le", "Mo\u00b7den", "noch", "zu", "schlecht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er brachte vor dem Spiegelglase", "tokens": ["Er", "brach\u00b7te", "vor", "dem", "Spie\u00b7gel\u00b7gla\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den Tag mit Complimenten zu", "tokens": ["Den", "Tag", "mit", "Com\u00b7pli\u00b7men\u00b7ten", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und sprach: Du ungeschickte Nase,", "tokens": ["Und", "sprach", ":", "Du", "un\u00b7ge\u00b7schick\u00b7te", "Na\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich weis nicht, was ich dir noch thu.", "tokens": ["Ich", "weis", "nicht", ",", "was", "ich", "dir", "noch", "thu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "PTKNEG", "$,", "PWS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Mein Vorwiz gieng inde\u00dfen weiter,", "tokens": ["Mein", "Vor\u00b7wiz", "gieng", "in\u00b7de\u00b7\u00dfen", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Da rief ein z\u00e4nckisches Geschrey:", "tokens": ["Da", "rief", "ein", "z\u00e4n\u00b7cki\u00b7sches", "Ge\u00b7schrey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du Funfzehnhut, du B\u00e4renh\u00e4uter,", "tokens": ["Du", "Funf\u00b7zehn\u00b7hut", ",", "du", "B\u00e4\u00b7ren\u00b7h\u00e4u\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Verstehst nicht, was das Spielrecht sey;", "tokens": ["Ver\u00b7stehst", "nicht", ",", "was", "das", "Spiel\u00b7recht", "sey", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PRELS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich h\u00e4tt es ofenbahr gewonnen,", "tokens": ["Ich", "h\u00e4tt", "es", "o\u00b7fen\u00b7bahr", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jezt schnellt mich dein verfluchter Stich;", "tokens": ["Jezt", "schnellt", "mich", "dein", "ver\u00b7fluch\u00b7ter", "Stich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O Schande vor der lieben Sonnen!", "tokens": ["O", "Schan\u00b7de", "vor", "der", "lie\u00b7ben", "Son\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Es darf nicht viel, so w\u00fcrg ich dich.", "tokens": ["Es", "darf", "nicht", "viel", ",", "so", "w\u00fcrg", "ich", "dich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "$,", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "So machens, Phoebus, deine Leute,", "tokens": ["So", "ma\u00b7chens", ",", "Phoe\u00b7bus", ",", "dei\u00b7ne", "Leu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "NE", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So f\u00fchren sich die meisten auf.", "tokens": ["So", "f\u00fch\u00b7ren", "sich", "die", "meis\u00b7ten", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die beste Post ist nur von heute", "tokens": ["Die", "bes\u00b7te", "Post", "ist", "nur", "von", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "APPR", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und tr\u00f6stet meinen schweren Lauf:", "tokens": ["Und", "tr\u00f6s\u00b7tet", "mei\u00b7nen", "schwe\u00b7ren", "Lauf", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich komme gleich von jenen Linden,", "tokens": ["Ich", "kom\u00b7me", "gleich", "von", "je\u00b7nen", "Lin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDAT", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wo Pallas be\u00dfre Kinder zieht;", "tokens": ["Wo", "Pal\u00b7las", "be\u00df\u00b7re", "Kin\u00b7der", "zieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hier l\u00e4st die Wei\u00dfheit Kr\u00e4nze winden", "tokens": ["Hier", "l\u00e4st", "die", "Wei\u00df\u00b7heit", "Kr\u00e4n\u00b7ze", "win\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und ist ums Violet bem\u00fcht.", "tokens": ["Und", "ist", "ums", "Vi\u00b7o\u00b7let", "be\u00b7m\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Sie cr\u00f6nt die Scheiteln ihrer S\u00f6hne", "tokens": ["Sie", "cr\u00f6nt", "die", "Schei\u00b7teln", "ih\u00b7rer", "S\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und theilet des Verdienstes Preis", "tokens": ["Und", "thei\u00b7let", "des", "Ver\u00b7diens\u00b7tes", "Preis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey solchem Lob- und Lustgeth\u00f6ne,", "tokens": ["Bey", "sol\u00b7chem", "Lob", "und", "Lust\u00b7ge\u00b7th\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als Orpheus kaum zu machen weis.", "tokens": ["Als", "Or\u00b7pheus", "kaum", "zu", "ma\u00b7chen", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Haupt von seltnen Klugheitsgaben", "tokens": ["Ein", "Haupt", "von", "selt\u00b7nen", "Klug\u00b7heits\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bekommt vor andern ihren Ku\u00df", "tokens": ["Be\u00b7kommt", "vor", "an\u00b7dern", "ih\u00b7ren", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und soll dadurch den Vorzug haben,", "tokens": ["Und", "soll", "da\u00b7durch", "den", "Vor\u00b7zug", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PAV", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den Ha\u00df und Faulheit darben mu\u00df.", "tokens": ["Den", "Ha\u00df", "und", "Faul\u00b7heit", "dar\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Hier sprach der F\u00fcrst der Pierinnen:", "tokens": ["Hier", "sprach", "der", "F\u00fcrst", "der", "Pie\u00b7rin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ich kenne schon den werthen Mann,", "tokens": ["Ich", "ken\u00b7ne", "schon", "den", "wert\u00b7hen", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der dermahleins auf Zions Zinnen", "tokens": ["Der", "der\u00b7mah\u00b7leins", "auf", "Zi\u00b7ons", "Zin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NE", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ein Licht der Kirchen werden kan.", "tokens": ["Ein", "Licht", "der", "Kir\u00b7chen", "wer\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es ist mein schriftge\u00fcbter Schneider,", "tokens": ["Es", "ist", "mein", "schrift\u00b7ge\u00b7\u00fcb\u00b7ter", "Schnei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der unsern Pindus l\u00e4ngst geziert", "tokens": ["Der", "un\u00b7sern", "Pin\u00b7dus", "l\u00e4ngst", "ge\u00b7ziert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und mit Verachtung geiler Neider", "tokens": ["Und", "mit", "Ver\u00b7ach\u00b7tung", "gei\u00b7ler", "Nei\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den Wandel fromm und klug gef\u00fchrt.", "tokens": ["Den", "Wan\u00b7del", "fromm", "und", "klug", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Jezt schick ich ihn dem Vaterlande", "tokens": ["Jezt", "schick", "ich", "ihn", "dem", "Va\u00b7ter\u00b7lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Ehr und Seegen wieder zu", "tokens": ["Mit", "Ehr", "und", "See\u00b7gen", "wie\u00b7der", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "ADV", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und w\u00fcntsche, da\u00df er jedem Stande", "tokens": ["Und", "w\u00fcnt\u00b7sche", ",", "da\u00df", "er", "je\u00b7dem", "Stan\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein l\u00f6bliches Gen\u00fcgen thu.", "tokens": ["Ein", "l\u00f6b\u00b7li\u00b7ches", "Ge\u00b7n\u00fc\u00b7gen", "thu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich w\u00fcntsch und hof es, weil die Jugend", "tokens": ["Ich", "w\u00fcnt\u00b7sch", "und", "hof", "es", ",", "weil", "die", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJD", "KON", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "An ihm des Alters Fr\u00fcchte sieht", "tokens": ["An", "ihm", "des", "Al\u00b7ters", "Fr\u00fcch\u00b7te", "sieht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und der Besiz der wahren Tugend", "tokens": ["Und", "der", "Be\u00b7siz", "der", "wah\u00b7ren", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem rechten Lobe nie entflieht.", "tokens": ["Dem", "rech\u00b7ten", "Lo\u00b7be", "nie", "ent\u00b7flieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Die Musen stimmten drauf die Saythen", "tokens": ["Die", "Mu\u00b7sen", "stimm\u00b7ten", "drauf", "die", "Say\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PAV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sungen dir, bescheidner Freund;", "tokens": ["Und", "sun\u00b7gen", "dir", ",", "be\u00b7scheid\u00b7ner", "Freund", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Gl\u00fccke zeigt das Tuch von weiten,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "zeigt", "das", "Tuch", "von", "wei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Womit es dich zu haschen meint:", "tokens": ["Wo\u00b7mit", "es", "dich", "zu", "ha\u00b7schen", "meint", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zeuch hin, es wird dich das Verlangen", "tokens": ["Zeuch", "hin", ",", "es", "wird", "dich", "das", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "PPER", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der Eltern br\u00fcnstig wiedersehn", "tokens": ["Der", "El\u00b7tern", "br\u00fcns\u00b7tig", "wie\u00b7der\u00b7sehn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und mit bethr\u00e4nter Hand empfangen,", "tokens": ["Und", "mit", "be\u00b7thr\u00e4n\u00b7ter", "Hand", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil ihrer Hofnung gnug geschehn.", "tokens": ["Weil", "ih\u00b7rer", "Hof\u00b7nung", "gnug", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}