{"dta.poem.12261": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Liebesprobe .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1806", "urn": "urn:nbn:de:kobv:b4-20090519157", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es sah eine Linde ins tiefe Thal,               ", "tokens": ["Es", "sah", "ei\u00b7ne", "Lin\u00b7de", "ins", "tie\u00b7fe", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NE", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "War unten breit und oben schmal,", "tokens": ["War", "un\u00b7ten", "breit", "und", "o\u00b7ben", "schmal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "KON", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Worunter zwey Verliebte sa\u00dfen,", "tokens": ["Wo\u00b7run\u00b7ter", "zwey", "Ver\u00b7lieb\u00b7te", "sa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vor Lieb' ihr Leid verga\u00dfen.", "tokens": ["Vor", "Lieb'", "ihr", "Leid", "ver\u00b7ga\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "\u201efeins Liebchen wir m\u00fcssen von einander,", "tokens": ["\u201e", "feins", "Lieb\u00b7chen", "wir", "m\u00fcs\u00b7sen", "von", "ein\u00b7an\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "PPER", "VMFIN", "APPR", "ADV", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u201eich mu\u00df noch sieben Jahre wandern;\u201c", "tokens": ["\u201e", "ich", "mu\u00df", "noch", "sie\u00b7ben", "Jah\u00b7re", "wan\u00b7dern", ";", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "CARD", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u201emu\u00dft du noch sieben Jahr wandern,", "tokens": ["\u201e", "mu\u00dft", "du", "noch", "sie\u00b7ben", "Jahr", "wan\u00b7dern", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPER", "ADV", "CARD", "NN", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "\u201eso heurath ich mir keinen andern.\u201c", "tokens": ["\u201e", "so", "heu\u00b7rath", "ich", "mir", "kei\u00b7nen", "an\u00b7dern", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PPER", "PIAT", "ADJA", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und als nun die sieben Jahr um waren,", "tokens": ["Und", "als", "nun", "die", "sie\u00b7ben", "Jahr", "um", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ART", "CARD", "NN", "APPR", "VAFIN", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Sie meinte ihr Liebchen k\u00e4me bald,", "tokens": ["Sie", "mein\u00b7te", "ihr", "Lieb\u00b7chen", "k\u00e4\u00b7me", "bald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie ging wohl in den Garten,", "tokens": ["Sie", "ging", "wohl", "in", "den", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ihr feines Liebchen zu erwarten.", "tokens": ["Ihr", "fei\u00b7nes", "Lieb\u00b7chen", "zu", "er\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie ging wohl in das gr\u00fcne Holz,", "tokens": ["Sie", "ging", "wohl", "in", "das", "gr\u00fc\u00b7ne", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da kam ein Reuter geritten stolz;", "tokens": ["Da", "kam", "ein", "Reu\u00b7ter", "ge\u00b7rit\u00b7ten", "stolz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "VVFIN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201egott gr\u00fc\u00dfe dich M\u00e4gdlein feine,", "tokens": ["\u201e", "gott", "gr\u00fc\u00b7\u00dfe", "dich", "M\u00e4gd\u00b7lein", "fei\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "NN", "ADJA", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201ewas machst du hier alleine.", "tokens": ["\u201e", "was", "machst", "du", "hier", "al\u00b7lei\u00b7ne", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u201eist dir dein Vater oder Mutter gram,", "tokens": ["\u201e", "ist", "dir", "dein", "Va\u00b7ter", "o\u00b7der", "Mut\u00b7ter", "gram", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPOSAT", "NN", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u201eoder hast du heimlich einen Mann?\u201c", "tokens": ["\u201e", "o\u00b7der", "hast", "du", "heim\u00b7lich", "ei\u00b7nen", "Mann", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "ADJD", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u201emein Vater und Mutter sind mir nicht gram,", "tokens": ["\u201e", "mein", "Va\u00b7ter", "und", "Mut\u00b7ter", "sind", "mir", "nicht", "gram", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "KON", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "\u201eich hab' auch heimlich keinen Mann.", "tokens": ["\u201e", "ich", "hab'", "auch", "heim\u00b7lich", "kei\u00b7nen", "Mann", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "\u201egestern wars drey Wochen \u00fcber sieben Jahr,", "tokens": ["\u201e", "ge\u00b7stern", "wars", "drey", "Wo\u00b7chen", "\u00fc\u00b7ber", "sie\u00b7ben", "Jahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "CARD", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u201eda mein feines Liebchen ausgewandert war.\u201c", "tokens": ["\u201e", "da", "mein", "fei\u00b7nes", "Lieb\u00b7chen", "aus\u00b7ge\u00b7wan\u00b7dert", "war", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "PPOSAT", "ADJA", "NN", "VVPP", "VAFIN", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "\u201egestern bin ich geritten durch eine Stadt,", "tokens": ["\u201e", "ge\u00b7stern", "bin", "ich", "ge\u00b7rit\u00b7ten", "durch", "ei\u00b7ne", "Stadt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "\u201eda dein feins Liebchen hat Hochzeit gehabt.", "tokens": ["\u201e", "da", "dein", "feins", "Lieb\u00b7chen", "hat", "Hoch\u00b7zeit", "ge\u00b7habt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPOSAT", "ADJA", "NN", "VAFIN", "NN", "VAPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "\u201ewas thust du ihm denn w\u00fcnschen,", "tokens": ["\u201e", "was", "thust", "du", "ihm", "denn", "w\u00fcn\u00b7schen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u201eda\u00df er nicht gehalten seine Treu?\u201c", "tokens": ["\u201e", "da\u00df", "er", "nicht", "ge\u00b7hal\u00b7ten", "sei\u00b7ne", "Treu", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PPER", "PTKNEG", "VVPP", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u201eich w\u00fcnsch ihm so viel gute Zeit,", "tokens": ["\u201e", "ich", "w\u00fcnsch", "ihm", "so", "viel", "gu\u00b7te", "Zeit", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eso viel wie Sand am Meere breit.\u201c", "tokens": ["\u201e", "so", "viel", "wie", "Sand", "am", "Mee\u00b7re", "breit", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "PIAT", "KOKOM", "NN", "APPRART", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was zog er von seinem Finger?", "tokens": ["Was", "zog", "er", "von", "sei\u00b7nem", "Fin\u00b7ger", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein'n Ring von reinem Gold gar fein.", "tokens": ["Ein'n", "Ring", "von", "rei\u00b7nem", "Gold", "gar", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er warf den Ring in ihren Schoo\u00df,", "tokens": ["Er", "warf", "den", "Ring", "in", "ih\u00b7ren", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie weinte, da\u00df der Ring gar flo\u00df.", "tokens": ["Sie", "wein\u00b7te", ",", "da\u00df", "der", "Ring", "gar", "flo\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Was zog er aus seiner Taschen?", "tokens": ["Was", "zog", "er", "aus", "sei\u00b7ner", "Ta\u00b7schen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ein Tuch sehr wei\u00df gewaschen.", "tokens": ["Ein", "Tuch", "sehr", "wei\u00df", "ge\u00b7wa\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201etrockne ab, trockne ab dein Aeugelein,", "tokens": ["\u201e", "trock\u00b7ne", "ab", ",", "trock\u00b7ne", "ab", "dein", "A\u00b7e\u00b7u\u00b7ge\u00b7lein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "PTKVZ", "$,", "ADJA", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "\u201edu sollst hinfort mein eigen seyn.", "tokens": ["\u201e", "du", "sollst", "hin\u00b7fort", "mein", "ei\u00b7gen", "seyn", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "PPOSAT", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "\u201eich thu dich nur versuchen,", "tokens": ["\u201e", "ich", "thu", "dich", "nur", "ver\u00b7su\u00b7chen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u201eob du w\u00fcrd'st schw\u00f6ren oder fluchen;", "tokens": ["\u201e", "ob", "du", "w\u00fcrd'st", "schw\u00f6\u00b7ren", "o\u00b7der", "flu\u00b7chen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VAFIN", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u201eh\u00e4tt'st du einen Fluch oder Schwur gethan,", "tokens": ["\u201e", "h\u00e4tt'st", "du", "ei\u00b7nen", "Fluch", "o\u00b7der", "Schwur", "ge\u00b7than", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ART", "NN", "KON", "VVFIN", "VVPP", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "\u201eso w\u00e4r ich gleich geritten davon.\u201c", "tokens": ["\u201e", "so", "w\u00e4r", "ich", "gleich", "ge\u00b7rit\u00b7ten", "da\u00b7von", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "PAV", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}}}}