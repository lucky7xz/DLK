{"textgrid.poem.34413": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "1", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "... Als ich dann wieder in die Heimath kam \u2013", "tokens": ["...", "Als", "ich", "dann", "wie\u00b7der", "in", "die", "Hei\u00b7math", "kam", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "im Fr\u00fchling wars, die Hyacinthen bl\u00fchten \u2013", "tokens": ["im", "Fr\u00fch\u00b7ling", "wars", ",", "die", "Hya\u00b7cin\u00b7then", "bl\u00fch\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "$,", "ART", "NN", "VVFIN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "da war sie tot, von fremden, kalten Menschen", "tokens": ["da", "war", "sie", "tot", ",", "von", "frem\u00b7den", ",", "kal\u00b7ten", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "hinausgetragen in ein kahles Grab. \u2013 \u2013", "tokens": ["hin\u00b7aus\u00b7ge\u00b7tra\u00b7gen", "in", "ein", "kah\u00b7les", "Grab", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich fand es nicht. Langsam ging ich zur\u00fcck", "tokens": ["Ich", "fand", "es", "nicht", ".", "Lang\u00b7sam", "ging", "ich", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "ADJD", "VVFIN", "PPER", "PTKVZ"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "in ihre Wohnung. Ihre feiste Wirthin", "tokens": ["in", "ih\u00b7re", "Woh\u00b7nung", ".", "Ih\u00b7re", "feis\u00b7te", "Wirt\u00b7hin"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sprach schmunzelnd: Gott, die Menschen sind nicht rar!", "tokens": ["sprach", "schmun\u00b7zelnd", ":", "Gott", ",", "die", "Men\u00b7schen", "sind", "nicht", "rar", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$.", "NN", "$,", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Nicht eine Woche stand ihr Zimmer leer.", "tokens": ["Nicht", "ei\u00b7ne", "Wo\u00b7che", "stand", "ihr", "Zim\u00b7mer", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Jetzt wohnt ein allerliebstes Chansonnettlein", "tokens": ["Jetzt", "wohnt", "ein", "al\u00b7ler\u00b7liebs\u00b7tes", "Chan\u00b7son\u00b7net\u00b7tlein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "darin, ganz jung noch, mit so lustigen F\u00fcssen!", "tokens": ["da\u00b7rin", ",", "ganz", "jung", "noch", ",", "mit", "so", "lus\u00b7ti\u00b7gen", "F\u00fcs\u00b7sen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADV", "ADJD", "ADV", "$,", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Wolln Sie sie sehn?", "tokens": ["Wolln", "Sie", "sie", "sehn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.9": {"text": "Und ich erfuhr, ", "tokens": ["Und", "ich", "er\u00b7fuhr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Vor ihren Augen, w\u00e4hrend sie in Qualen", "tokens": ["Vor", "ih\u00b7ren", "Au\u00b7gen", ",", "w\u00e4h\u00b7rend", "sie", "in", "Qua\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "und Fieber dalag, hatten \u2013 ihre Schwestern", "tokens": ["und", "Fie\u00b7ber", "da\u00b7lag", ",", "hat\u00b7ten", "\u2013", "ih\u00b7re", "Schwes\u00b7tern"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "NN", "VVFIN", "$,", "VAFIN", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "begierig ihrer Habe sich bem\u00e4chtigt:", "tokens": ["be\u00b7gie\u00b7rig", "ih\u00b7rer", "Ha\u00b7be", "sich", "be\u00b7m\u00e4ch\u00b7tigt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "NN", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sparkassenb\u00fccher, Kleider, Schmuck und W\u00e4sche", "tokens": ["Spar\u00b7kas\u00b7sen\u00b7b\u00fc\u00b7cher", ",", "Klei\u00b7der", ",", "Schmuck", "und", "W\u00e4\u00b7sche"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "aus allen K\u00e4sten sich hervorgesucht", "tokens": ["aus", "al\u00b7len", "K\u00e4s\u00b7ten", "sich", "her\u00b7vor\u00b7ge\u00b7sucht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PRF", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und \u2013 umgepackt in einen grossen Korb.", "tokens": ["und", "\u2013", "um\u00b7ge\u00b7packt", "in", "ei\u00b7nen", "gros\u00b7sen", "Korb", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVPP", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Da .. hatte sie den bleichen Kopf erhoben", "tokens": ["Da", "..", "hat\u00b7te", "sie", "den", "blei\u00b7chen", "Kopf", "er\u00b7ho\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$(", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "von ihrem Kissen, hatte sich verwundert", "tokens": ["von", "ih\u00b7rem", "Kis\u00b7sen", ",", "hat\u00b7te", "sich", "ver\u00b7wun\u00b7dert"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VAFIN", "PRF", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mit grossen, schwarzen Augen umgeschaut", "tokens": ["mit", "gros\u00b7sen", ",", "schwar\u00b7zen", "Au\u00b7gen", "um\u00b7ge\u00b7schaut"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und hatte .. gel\u00e4chelt ...", "tokens": ["und", "hat\u00b7te", "..", "ge\u00b7l\u00e4\u00b7chelt", "..."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "$.", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.6": {"text": "Mir ist .. als ob ich dieses L\u00e4cheln s\u00e4he!", "tokens": ["Mir", "ist", "..", "als", "ob", "ich", "die\u00b7ses", "L\u00e4\u00b7cheln", "s\u00e4\u00b7he", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$.", "KOKOM", "KOUS", "PPER", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}