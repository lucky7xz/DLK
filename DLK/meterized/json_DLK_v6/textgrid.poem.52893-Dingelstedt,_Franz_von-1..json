{"textgrid.poem.52893": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbnun das haben Sie getroffen,", "tokens": ["\u00bb", "nun", "das", "ha\u00b7ben", "Sie", "ge\u00b7trof\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PDS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eben ist die Messe offen,", "tokens": ["E\u00b7ben", "ist", "die", "Mes\u00b7se", "of\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Werden blaue Wunder sehen,", "tokens": ["Wer\u00b7den", "blau\u00b7e", "Wun\u00b7der", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn Sie durch die Gassen gehen.\u00ab", "tokens": ["Wenn", "Sie", "durch", "die", "Gas\u00b7sen", "ge\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.2": {"line.1": {"text": "Und ich suchte nach dem Wunder,", "tokens": ["Und", "ich", "such\u00b7te", "nach", "dem", "Wun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fand aber nur Waren-Plunder,", "tokens": ["Fand", "a\u00b7ber", "nur", "Wa\u00b7ren\u00b7P\u00b7lun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Lange Waren, kurze Waren,", "tokens": ["Lan\u00b7ge", "Wa\u00b7ren", ",", "kur\u00b7ze", "Wa\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Verk\u00e4ufer, ganze Scharen.", "tokens": ["Und", "Ver\u00b7k\u00e4u\u00b7fer", ",", "gan\u00b7ze", "Scha\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Alle H\u00e4user voll Affichen,", "tokens": ["Al\u00b7le", "H\u00e4u\u00b7ser", "voll", "Af\u00b7fi\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Geld auf allen Wechslertischen,", "tokens": ["Geld", "auf", "al\u00b7len", "Wechs\u00b7ler\u00b7ti\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jeder Winkel ein Bude,", "tokens": ["Je\u00b7der", "Win\u00b7kel", "ein", "Bu\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und die dritte Nas' ein Jude.", "tokens": ["Und", "die", "drit\u00b7te", "Nas'", "ein", "Ju\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Schreien h\u00f6rt' ich, keuchen, laufen:", "tokens": ["Schrei\u00b7en", "h\u00f6rt'", "ich", ",", "keu\u00b7chen", ",", "lau\u00b7fen", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "VVFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herr, hier k\u00f6nn'n Sie alles kaufen,", "tokens": ["Herr", ",", "hier", "k\u00f6nn'n", "Sie", "al\u00b7les", "kau\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VMFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Gontard bietet seidne T\u00fccher,", "tokens": ["Gon\u00b7tard", "bie\u00b7tet", "seid\u00b7ne", "T\u00fc\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "J\u00fcgel abgestandne B\u00fccher,", "tokens": ["J\u00fc\u00b7gel", "ab\u00b7ge\u00b7stand\u00b7ne", "B\u00fc\u00b7cher", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Bing Kristalle, Gl\u00e4ser, Lacke,", "tokens": ["Bing", "Kris\u00b7tal\u00b7le", ",", "Gl\u00e4\u00b7ser", ",", "La\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Breul so Rauch- wie Schnupf-Tabacke,", "tokens": ["Breul", "so", "Rauch", "wie", "Schnupf\u00b7Ta\u00b7ba\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "TRUNC", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kriegesfelder Rock und Hosen,", "tokens": ["Krie\u00b7ges\u00b7fel\u00b7der", "Rock", "und", "Ho\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und Frau ** die Franzosen.", "tokens": ["Und", "Frau", "*", "*", "die", "Fran\u00b7zo\u00b7sen", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "XY", "XY", "ART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Hol der Teufel solch ein Schachern,", "tokens": ["Hol", "der", "Teu\u00b7fel", "solch", "ein", "Scha\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PIAT", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Feilschen, Mauscheln, M\u00e4keln, Prachern,", "tokens": ["Feil\u00b7schen", ",", "Mau\u00b7scheln", ",", "M\u00e4\u00b7keln", ",", "Pra\u00b7chern", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kurze Waren, lange Waren", "tokens": ["Kur\u00b7ze", "Wa\u00b7ren", ",", "lan\u00b7ge", "Wa\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "M\u00f6gen sie zum Henker fahren!", "tokens": ["M\u00f6\u00b7gen", "sie", "zum", "Hen\u00b7ker", "fah\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wahrlich, hier kann wieder gelten", "tokens": ["Wahr\u00b7lich", ",", "hier", "kann", "wie\u00b7der", "gel\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "VMFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jenes Afrikaners Schelten:", "tokens": ["Je\u00b7nes", "Af\u00b7ri\u00b7ka\u00b7ners", "Schel\u00b7ten", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Feiles Nest, wenn nur zur Stunden", "tokens": ["Fei\u00b7les", "Nest", ",", "wenn", "nur", "zur", "Stun\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "KOUS", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich ein K\u00e4ufer eingefunden!", "tokens": ["Sich", "ein", "K\u00e4u\u00b7fer", "ein\u00b7ge\u00b7fun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Deutschland, ja auch Du hast dein Rom;", "tokens": ["Deutschland", ",", "ja", "auch", "Du", "hast", "dein", "Rom", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADV", "PPER", "VAFIN", "PPOSAT", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Diese freie Stadt am Mainstrom", "tokens": ["Die\u00b7se", "frei\u00b7e", "Stadt", "am", "Ma\u00b7ins\u00b7trom"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "APPRART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ist, beschnitten und getauft,", "tokens": ["Ist", ",", "be\u00b7schnit\u00b7ten", "und", "ge\u00b7tauft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "VVFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "L\u00e4ngst lebendig ausverkauft!", "tokens": ["L\u00e4ngst", "le\u00b7ben\u00b7dig", "aus\u00b7ver\u00b7kauft", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}