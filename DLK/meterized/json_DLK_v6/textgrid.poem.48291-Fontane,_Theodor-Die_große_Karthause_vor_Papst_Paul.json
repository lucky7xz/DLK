{"textgrid.poem.48291": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Die gro\u00dfe Karthause vor Papst Paul", "genre": "verse", "period": "N.A.", "pub_year": 1885, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und es sprach Papst Paul: \u00bbDie gro\u00dfe Karthaus", "tokens": ["Und", "es", "sprach", "Papst", "Paul", ":", "\u00bb", "Die", "gro\u00b7\u00dfe", "Kar\u00b7thaus"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "NN", "NE", "$.", "$(", "ART", "ADJA", "NN"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "In der Freigrafschaft treibt es mir zu kraus;", "tokens": ["In", "der", "Frei\u00b7graf\u00b7schaft", "treibt", "es", "mir", "zu", "kraus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "PTKA", "ADJD", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Auch Frommsein tr\u00e4gt Gefahren im Scho\u00df,", "tokens": ["Auch", "Fromm\u00b7sein", "tr\u00e4gt", "Ge\u00b7fah\u00b7ren", "im", "Scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Kasteien zieht den Hochmut gro\u00df,", "tokens": ["Kas\u00b7tei\u00b7en", "zieht", "den", "Hoch\u00b7mut", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kasteien ist ihnen Zweck und Ziel,", "tokens": ["Kas\u00b7tei\u00b7en", "ist", "ih\u00b7nen", "Zweck", "und", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ewiges Fasten, das ist zu viel.", "tokens": ["E\u00b7wi\u00b7ges", "Fas\u00b7ten", ",", "das", "ist", "zu", "viel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PDS", "VAFIN", "PTKA", "PIS", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.7": {"text": "Ich sehe kommen der Dinge Lauf:", "tokens": ["Ich", "se\u00b7he", "kom\u00b7men", "der", "Din\u00b7ge", "Lauf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ohne Zehrung zehren sie ", "tokens": ["Oh\u00b7ne", "Zeh\u00b7rung", "zeh\u00b7ren", "sie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Und ihr Orden wird ein schw\u00e4chlicher Schaft,", "tokens": ["Und", "ihr", "Or\u00b7den", "wird", "ein", "schw\u00e4ch\u00b7li\u00b7cher", "Schaft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Morsch und m\u00fcrb' ohne Saft und Kraft.\u00ab", "tokens": ["Morsch", "und", "m\u00fcrb'", "oh\u00b7ne", "Saft", "und", "Kraft", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "VMFIN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "Des kam ihnen Kund' in einem Brief.", "tokens": ["Des", "kam", "ih\u00b7nen", "Kund'", "in", "ei\u00b7nem", "Brief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Abt die M\u00f6nche zusammenrief;", "tokens": ["Der", "Abt", "die", "M\u00f6n\u00b7che", "zu\u00b7sam\u00b7men\u00b7rief", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und es sprach der Abt: \u00bbFrei sei's gesagt,", "tokens": ["Und", "es", "sprach", "der", "Abt", ":", "\u00bb", "Frei", "sei's", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "$(", "NN", "NE", "VVPP", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Es haben uns unsre Feinde verklagt,", "tokens": ["Es", "ha\u00b7ben", "uns", "uns\u00b7re", "Fein\u00b7de", "ver\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ein Neider oder ein Leckerling", "tokens": ["Ein", "Nei\u00b7der", "o\u00b7der", "ein", "Le\u00b7cker\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Den heiligen Vater hinterging,", "tokens": ["Den", "hei\u00b7li\u00b7gen", "Va\u00b7ter", "hin\u00b7ter\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Der sieht nun die Dinge von Grund aus schief,", "tokens": ["Der", "sieht", "nun", "die", "Din\u00b7ge", "von", "Grund", "aus", "schief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "APPR", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Sonst schrieb' er uns nicht einen solchen Brief.", "tokens": ["Sonst", "schrieb'", "er", "uns", "nicht", "ei\u00b7nen", "sol\u00b7chen", "Brief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKNEG", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ich aber schick' Antwort. Bruder Gregor", "tokens": ["Ich", "a\u00b7ber", "schick'", "Ant\u00b7wort", ".", "Bru\u00b7der", "Gre\u00b7gor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "NN", "$.", "NN", "NE"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und Eustach und Rollo, tretet vor,", "tokens": ["Und", "Eu\u00b7stach", "und", "Rol\u00b7lo", ",", "tre\u00b7tet", "vor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NE", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.11": {"text": "Und Cyrill und Gaston und du, Bruder Hugh \u2013", "tokens": ["Und", "Cy\u00b7rill", "und", "Gas\u00b7ton", "und", "du", ",", "Bru\u00b7der", "Hugh", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NN", "KON", "PPER", "$,", "NN", "NE", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Hugh, du bist neunzig, du f\u00fchrst den Zug.\u00ab", "tokens": ["Hugh", ",", "du", "bist", "neun\u00b7zig", ",", "du", "f\u00fchrst", "den", "Zug", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Da traten die Sechs zum Zuge zusamm;", "tokens": ["Da", "tra\u00b7ten", "die", "Sechs", "zum", "Zu\u00b7ge", "zu\u00b7samm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und winters, \u00fcber den Gotthard-Kamm,", "tokens": ["Und", "win\u00b7ters", ",", "\u00fc\u00b7ber", "den", "Gott\u00b7hard\u00b7Kamm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Einzeln und nebeneinanderher,", "tokens": ["Ein\u00b7zeln", "und", "ne\u00b7ben\u00b7ein\u00b7an\u00b7der\u00b7her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJA", "$,"], "meter": "+-----+-+", "measure": "dactylic.init"}, "line.4": {"text": "Ein jeder achtzig oder mehr,", "tokens": ["Ein", "je\u00b7der", "acht\u00b7zig", "o\u00b7der", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "CARD", "KON", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So passierten sie Gletscher und Wald und Strom,", "tokens": ["So", "pas\u00b7sier\u00b7ten", "sie", "Glet\u00b7scher", "und", "Wald", "und", "Strom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Bis da\u00df sie hielten vorm ewigen Rom.", "tokens": ["Bis", "da\u00df", "sie", "hiel\u00b7ten", "vorm", "e\u00b7wi\u00b7gen", "Rom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Und der Papst empfing sie. \u00bbWas euer Begehr?\u00ab", "tokens": ["Und", "der", "Papst", "emp\u00b7fing", "sie", ".", "\u00bb", "Was", "eu\u00b7er", "Be\u00b7gehr", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$.", "$(", "PWS", "PPOSAT", "NN", "$.", "$("], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbdie gro\u00dfe Karthause schickt uns her.", "tokens": ["\u00bb", "die", "gro\u00b7\u00dfe", "Kar\u00b7thau\u00b7se", "schickt", "uns", "her", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die gro\u00dfe Karthaus' ist, was sie war,", "tokens": ["Die", "gro\u00b7\u00dfe", "Kart\u00b7haus'", "ist", ",", "was", "sie", "war", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$,", "PRELS", "PPER", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zusammen sind wir f\u00fcnfhundert Jahr;", "tokens": ["Zu\u00b7sam\u00b7men", "sind", "wir", "f\u00fcnf\u00b7hun\u00b7dert", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "CARD", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Was gab uns die Jahre? Was lie\u00df uns gedeihn?", "tokens": ["Was", "gab", "uns", "die", "Jah\u00b7re", "?", "Was", "lie\u00df", "uns", "ge\u00b7deihn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ART", "NN", "$.", "PWS", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+---+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Fasten war es und Kastein;", "tokens": ["Fas\u00b7ten", "war", "es", "und", "Kas\u00b7tein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Dem Leib gehorchen, zehrt auf das Mark,", "tokens": ["Dem", "Leib", "ge\u00b7hor\u00b7chen", ",", "zehrt", "auf", "das", "Mark", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Den Leib bez\u00e4hmen, macht st\u00e4hlern und stark.", "tokens": ["Den", "Leib", "be\u00b7z\u00e4h\u00b7men", ",", "macht", "st\u00e4h\u00b7lern", "und", "stark", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "VVFIN", "VVINF", "KON", "ADJD", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Im Schneesturm, \u00fcber die Berge hin,", "tokens": ["Im", "Schnee\u00b7sturm", ",", "\u00fc\u00b7ber", "die", "Ber\u00b7ge", "hin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zogen wir; wende deinen Sinn;", "tokens": ["Zo\u00b7gen", "wir", ";", "wen\u00b7de", "dei\u00b7nen", "Sinn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Da\u00df morsch wir w\u00fcrden, noch hat es nicht Not,", "tokens": ["Da\u00df", "morsch", "wir", "w\u00fcr\u00b7den", ",", "noch", "hat", "es", "nicht", "Not", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "VAFIN", "$,", "ADV", "VAFIN", "PPER", "PTKNEG", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Heil'ger Vater, nimm von uns dein Gebot.\u00ab", "tokens": ["Heil'\u00b7ger", "Va\u00b7ter", ",", "nimm", "von", "uns", "dein", "Ge\u00b7bot", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$,", "VVIMP", "APPR", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Da l\u00e4chelt Papst Paul: \u00bbIhr meidet den Wein,", "tokens": ["Da", "l\u00e4\u00b7chelt", "Papst", "Paul", ":", "\u00bb", "Ihr", "mei\u00b7det", "den", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "An meinen Tisch sonst l\u00fcd' ich euch ein.", "tokens": ["An", "mei\u00b7nen", "Tisch", "sonst", "l\u00fcd'", "ich", "euch", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Doch kenn' ich ein andres, das gilt euch mehr:", "tokens": ["Doch", "kenn'", "ich", "ein", "and\u00b7res", ",", "das", "gilt", "euch", "mehr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "PIS", "$,", "PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "In eure Karthause die Wiederkehr.", "tokens": ["In", "eu\u00b7re", "Kar\u00b7thau\u00b7se", "die", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Ihr habt mich besiegt: aller Gr\u00f6\u00dfe Keim,", "tokens": ["Ihr", "habt", "mich", "be\u00b7siegt", ":", "al\u00b7ler", "Gr\u00f6\u00b7\u00dfe", "Keim", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$.", "PIAT", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Er hei\u00dft Entsagung ... Zieht heim, zieht heim.\u00ab", "tokens": ["Er", "hei\u00dft", "Ent\u00b7sa\u00b7gung", "...", "Zieht", "heim", ",", "zieht", "heim", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "NN", "$(", "VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}