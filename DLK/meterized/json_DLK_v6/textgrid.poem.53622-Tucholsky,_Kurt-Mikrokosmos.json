{"textgrid.poem.53622": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Mikrokosmos", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da\u00df man nicht alle haben kann \u2013!", "tokens": ["Da\u00df", "man", "nicht", "al\u00b7le", "ha\u00b7ben", "kann", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "PIS", "VAINF", "VMFIN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie gerne m\u00f6cht ich Ernestinen", "tokens": ["Wie", "ger\u00b7ne", "m\u00f6cht", "ich", "Er\u00b7nes\u00b7ti\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VMFIN", "PPER", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "als Schemel ihrer L\u00fcste dienen!", "tokens": ["als", "Sche\u00b7mel", "ih\u00b7rer", "L\u00fcs\u00b7te", "die\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und warum macht mir Magdalene,", "tokens": ["Und", "wa\u00b7rum", "macht", "mir", "Mag\u00b7da\u00b7le\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wenn ich sie frage, eine Szene?", "tokens": ["wenn", "ich", "sie", "fra\u00b7ge", ",", "ei\u00b7ne", "Sze\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Von jener Lotte ganz zu schweigen \u2013", "tokens": ["Von", "je\u00b7ner", "Lot\u00b7te", "ganz", "zu", "schwei\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "ich t\u00e4t mich ihr als Halbgott zeigen.", "tokens": ["ich", "t\u00e4t", "mich", "ihr", "als", "Halb\u00b7gott", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch bin ich schlie\u00dflich 1 St\u00fcck Mann . . .", "tokens": ["Doch", "bin", "ich", "schlie\u00df\u00b7lich", "1", "St\u00fcck", "Mann", ".", ".", "."], "token_info": ["word", "word", "word", "word", "number", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "CARD", "NN", "NN", "$.", "$.", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Da\u00df man nicht alle haben kann \u2013!", "tokens": ["Da\u00df", "man", "nicht", "al\u00b7le", "ha\u00b7ben", "kann", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "PIS", "VAINF", "VMFIN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Gewi\u00df: das Spiel ist etwas alt.", "tokens": ["Ge\u00b7wi\u00df", ":", "das", "Spiel", "ist", "et\u00b7was", "alt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wei\u00df, da\u00df zwischen Spree und Elbe", "tokens": ["Ich", "wei\u00df", ",", "da\u00df", "zwi\u00b7schen", "Spree", "und", "El\u00b7be"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "NE", "KON", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "das Dramolet ja stets dasselbe,", "tokens": ["das", "Dra\u00b7mo\u00b7let", "ja", "stets", "das\u00b7sel\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "PDAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch denk ich alle, alle Male:", "tokens": ["doch", "denk", "ich", "al\u00b7le", ",", "al\u00b7le", "Ma\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "entfern ich diesmal nur die Schale \u2013", "tokens": ["ent\u00b7fern", "ich", "dies\u00b7mal", "nur", "die", "Scha\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "was wird sich deinen Blicken zeigen?", "tokens": ["was", "wird", "sich", "dei\u00b7nen", "Bli\u00b7cken", "zei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PRF", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Was ist, wenn diese Lippen schweigen?", "tokens": ["Was", "ist", ",", "wenn", "die\u00b7se", "Lip\u00b7pen", "schwei\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "KOUS", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Nur diesmal greifts mich mit Gewalt . . .", "tokens": ["Nur", "dies\u00b7mal", "greifts", "mich", "mit", "Ge\u00b7walt", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "APPR", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "(gewi\u00df: das Spiel ist etwas alt.)", "tokens": ["(", "ge\u00b7wi\u00df", ":", "das", "Spiel", "ist", "et\u00b7was", "alt", ".", ")"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$.", "ART", "NN", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Da\u00df man nicht alle haben kann \u2013!", "tokens": ["Da\u00df", "man", "nicht", "al\u00b7le", "ha\u00b7ben", "kann", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "PIS", "VAINF", "VMFIN", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das l\u00e4\u00dft sich zeitlich auch nicht machen . . .", "tokens": ["Das", "l\u00e4\u00dft", "sich", "zeit\u00b7lich", "auch", "nicht", "ma\u00b7chen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "ADV", "PTKNEG", "VVINF", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wei\u00df, jetzt wirst du wieder lachen!", "tokens": ["Ich", "wei\u00df", ",", "jetzt", "wirst", "du", "wie\u00b7der", "la\u00b7chen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich komm doch stets nach den Exzessen", "tokens": ["Ich", "komm", "doch", "stets", "nach", "den", "Ex\u00b7zes\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+--+--", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "zu dir und kann dich nicht vergessen.", "tokens": ["zu", "dir", "und", "kann", "dich", "nicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KON", "VMFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So gib mir denn nach langem Wandern", "tokens": ["So", "gib", "mir", "denn", "nach", "lan\u00b7gem", "Wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die Summe aller jener andern.", "tokens": ["die", "Sum\u00b7me", "al\u00b7ler", "je\u00b7ner", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "PDAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sei du die Welt f\u00fcr einen Mann . . .", "tokens": ["Sei", "du", "die", "Welt", "f\u00fcr", "ei\u00b7nen", "Mann", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "weil er nicht alle haben kann.", "tokens": ["weil", "er", "nicht", "al\u00b7le", "ha\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PIS", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}