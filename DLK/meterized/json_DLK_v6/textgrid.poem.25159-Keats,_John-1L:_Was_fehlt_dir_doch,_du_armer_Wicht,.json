{"textgrid.poem.25159": {"metadata": {"author": {"name": "Keats, John", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was fehlt dir doch, du armer Wicht,", "genre": "verse", "period": "N.A.", "pub_year": 1819, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was fehlt dir doch, du armer Wicht,", "tokens": ["Was", "fehlt", "dir", "doch", ",", "du", "ar\u00b7mer", "Wicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was schweifst du einsam bleich umher?", "tokens": ["Was", "schweifst", "du", "ein\u00b7sam", "bleich", "um\u00b7her", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADJD", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Schilf ist l\u00e4ngst schon welk, es singt", "tokens": ["Das", "Schilf", "ist", "l\u00e4ngst", "schon", "welk", ",", "es", "singt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein V\u00f6glein mehr.", "tokens": ["Kein", "V\u00f6\u00b7glein", "mehr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Was fehlt dir doch, du armer Wicht;", "tokens": ["Was", "fehlt", "dir", "doch", ",", "du", "ar\u00b7mer", "Wicht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was bist du so verh\u00e4rmt und krank?", "tokens": ["Was", "bist", "du", "so", "ver\u00b7h\u00e4rmt", "und", "krank", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Eichhorns Speicher ist gef\u00fcllt,", "tokens": ["Des", "Eich\u00b7horns", "Spei\u00b7cher", "ist", "ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die \u00c4hre sank.", "tokens": ["Die", "\u00c4h\u00b7re", "sank", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Eine Lilie bl\u00fcht auf deiner Stirn,", "tokens": ["Ei\u00b7ne", "Li\u00b7lie", "bl\u00fcht", "auf", "dei\u00b7ner", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Betaut von Fieber, Not und Qual,", "tokens": ["Be\u00b7taut", "von", "Fie\u00b7ber", ",", "Not", "und", "Qual", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Rosen deiner Wangen sind", "tokens": ["Die", "Ro\u00b7sen", "dei\u00b7ner", "Wan\u00b7gen", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verwelkt und fahl.", "tokens": ["Ver\u00b7welkt", "und", "fahl", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "\u00bbein Fr\u00e4ulein traf im Hag ich an,", "tokens": ["\u00bb", "ein", "Fr\u00e4u\u00b7lein", "traf", "im", "Hag", "ich", "an", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "APPRART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War sch\u00f6n, wie nur ein Feenbild,", "tokens": ["War", "sch\u00f6n", ",", "wie", "nur", "ein", "Feen\u00b7bild", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PWAV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Haar war lang, ihr Schritt war leicht,", "tokens": ["Ihr", "Haar", "war", "lang", ",", "ihr", "Schritt", "war", "leicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Blick war wild.", "tokens": ["Ihr", "Blick", "war", "wild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Ich hob sie auf mein schreitend Ro\u00df,", "tokens": ["Ich", "hob", "sie", "auf", "mein", "schrei\u00b7tend", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und seitw\u00e4rts lehnte sie und sang;", "tokens": ["Und", "seit\u00b7w\u00e4rts", "lehn\u00b7te", "sie", "und", "sang", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun sah ich nichts als sie im Tag \u2013", "tokens": ["Nun", "sah", "ich", "nichts", "als", "sie", "im", "Tag", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "KOKOM", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Stunden lang.", "tokens": ["Viel", "Stun\u00b7den", "lang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Ich flocht ihr einen Kranz aufs Haupt", "tokens": ["Ich", "flocht", "ihr", "ei\u00b7nen", "Kranz", "aufs", "Haupt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und duftigen Kranz um Brust und Arm,", "tokens": ["Und", "duf\u00b7ti\u00b7gen", "Kranz", "um", "Brust", "und", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sie dankte mir mit Blick und Wort", "tokens": ["Sie", "dank\u00b7te", "mir", "mit", "Blick", "und", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So s\u00fc\u00df und warm.", "tokens": ["So", "s\u00fc\u00df", "und", "warm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Sie suchte saftiges Wurzelwerk,", "tokens": ["Sie", "such\u00b7te", "saf\u00b7ti\u00b7ges", "Wur\u00b7zel\u00b7werk", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wildhonig, Manna-Tau f\u00fcr mich", "tokens": ["Wild\u00b7ho\u00b7nig", ",", "Man\u00b7na\u00b7Tau", "f\u00fcr", "mich"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "NN", "APPR", "PPER"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und sagte mir in fremdem Laut:", "tokens": ["Und", "sag\u00b7te", "mir", "in", "frem\u00b7dem", "Laut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich liebe dich.", "tokens": ["Ich", "lie\u00b7be", "dich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Sie nahm mich in ihr Grottenschlo\u00df", "tokens": ["Sie", "nahm", "mich", "in", "ihr", "Grot\u00b7ten\u00b7schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sah mich an und seufzte tief.", "tokens": ["Und", "sah", "mich", "an", "und", "seufz\u00b7te", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich k\u00fc\u00dfte ihr die Augen zu,", "tokens": ["Ich", "k\u00fc\u00df\u00b7te", "ihr", "die", "Au\u00b7gen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie lag und schlief.", "tokens": ["Sie", "lag", "und", "schlief", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Dort schlief auch ich im Moose ein,", "tokens": ["Dort", "schlief", "auch", "ich", "im", "Moo\u00b7se", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da tr\u00e4umte mir ein Traum so bang,", "tokens": ["Da", "tr\u00e4um\u00b7te", "mir", "ein", "Traum", "so", "bang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der letzte Traum, den ich getr\u00e4umt", "tokens": ["Der", "letz\u00b7te", "Traum", ",", "den", "ich", "ge\u00b7tr\u00e4umt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am H\u00fcgelhang.", "tokens": ["Am", "H\u00fc\u00b7gel\u00b7hang", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Sah K\u00f6nige, F\u00fcrsten, Ritter stehn \u2013", "tokens": ["Sah", "K\u00f6\u00b7ni\u00b7ge", ",", "F\u00fcrs\u00b7ten", ",", "Rit\u00b7ter", "stehn", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "$,", "NN", "VVINF", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So bleich, wie Tod nur bleich sein kann \u2013", "tokens": ["So", "bleich", ",", "wie", "Tod", "nur", "bleich", "sein", "kann", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "NN", "ADV", "ADJD", "VAINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie schrien: La belle dame sans merci", "tokens": ["Sie", "schri\u00b7en", ":", "La", "bel\u00b7le", "da\u00b7me", "sans", "mer\u00b7ci"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "FM", "FM", "FM", "FM", "FM"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Hat dich im Bann!", "tokens": ["Hat", "dich", "im", "Bann", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Aus klaffend offnem Totenmund", "tokens": ["Aus", "klaf\u00b7fend", "off\u00b7nem", "To\u00b7ten\u00b7mund"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der schauerliche Warnruf drang.", "tokens": ["Der", "schau\u00b7er\u00b7li\u00b7che", "Warn\u00b7ruf", "drang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich wachte auf und fand mich hier", "tokens": ["Ich", "wach\u00b7te", "auf", "und", "fand", "mich", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am H\u00fcgelhang.", "tokens": ["Am", "H\u00fc\u00b7gel\u00b7hang", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Und darum irr ich einsam hier", "tokens": ["Und", "da\u00b7rum", "irr", "ich", "ein\u00b7sam", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bleich im welken Schilf umher,", "tokens": ["Und", "bleich", "im", "wel\u00b7ken", "Schilf", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPRART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Obgleich ich wei\u00df, es singt schon l\u00e4ngst", "tokens": ["Ob\u00b7gleich", "ich", "wei\u00df", ",", "es", "singt", "schon", "l\u00e4ngst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein V\u00f6glein mehr.\u00ab", "tokens": ["Kein", "V\u00f6\u00b7glein", "mehr", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "ADV", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}}}}}