{"dta.poem.7265": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Die Vogelh\u00fctte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-20090519994", "language": ["de:0.99"], "booktitle": "Droste-H\u00fclshoff, Annette von: Gedichte. Stuttgart u. a., 1844."}, "poem": {"stanza.1": {"line.1": {"text": "Ich habe mich gesetzt in Gottes Namen;", "tokens": ["Ich", "ha\u00b7be", "mich", "ge\u00b7setzt", "in", "Got\u00b7tes", "Na\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es hilft doch alles nicht, und mein Gedicht", "tokens": ["Es", "hilft", "doch", "al\u00b7les", "nicht", ",", "und", "mein", "Ge\u00b7dicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "PTKNEG", "$,", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ist l\u00e4ngst gelesen und im Schlo\u00df die Damen,", "tokens": ["Ist", "l\u00e4ngst", "ge\u00b7le\u00b7sen", "und", "im", "Schlo\u00df", "die", "Da\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie sa\u00dfen lange zu Gericht.", "tokens": ["Sie", "sa\u00b7\u00dfen", "lan\u00b7ge", "zu", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Statt einen neuen Lorbeerkranz zu dr\u00fccken", "tokens": ["Statt", "ei\u00b7nen", "neu\u00b7en", "Lor\u00b7beer\u00b7kranz", "zu", "dr\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In meine Ph\u00f6boslocken, hat man sacht", "tokens": ["In", "mei\u00b7ne", "Ph\u00f6\u00b7bos\u00b7lo\u00b7cken", ",", "hat", "man", "sacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "VAFIN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den alten losgezupft und hinter'm R\u00fccken", "tokens": ["Den", "al\u00b7ten", "los\u00b7ge\u00b7zupft", "und", "hin\u00b7ter'm", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVPP", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wohl Eselsohren mir gemacht.", "tokens": ["Wohl", "E\u00b7sel\u00b7soh\u00b7ren", "mir", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Verkannte Seele, fasse dich im Leiden,", "tokens": ["Ver\u00b7kann\u00b7te", "See\u00b7le", ",", "fas\u00b7se", "dich", "im", "Lei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sey stark, sey nobel, denk, der Ruhm ist leer,", "tokens": ["Sey", "stark", ",", "sey", "no\u00b7bel", ",", "denk", ",", "der", "Ruhm", "ist", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "VAFIN", "ADJD", "$,", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das Leben kurz, es wechseln Schmerz und Freuden,", "tokens": ["Das", "Le\u00b7ben", "kurz", ",", "es", "wech\u00b7seln", "Schmerz", "und", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und was dergleichen Neugedachtes mehr!", "tokens": ["Und", "was", "derg\u00b7lei\u00b7chen", "Neu\u00b7ge\u00b7dach\u00b7tes", "mehr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PIS", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich schau mich um in meiner kleinen Zelle:", "tokens": ["Ich", "schau", "mich", "um", "in", "mei\u00b7ner", "klei\u00b7nen", "Zel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr einen Klausner w\u00e4r's ein h\u00fcbscher Ort;", "tokens": ["F\u00fcr", "ei\u00b7nen", "Klaus\u00b7ner", "w\u00e4r's", "ein", "h\u00fcb\u00b7scher", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Bank, der Tisch, das h\u00f6lzerne Gestelle,", "tokens": ["Die", "Bank", ",", "der", "Tisch", ",", "das", "h\u00f6l\u00b7zer\u00b7ne", "Ge\u00b7stel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und an der Wand die Tasche dort;", "tokens": ["Und", "an", "der", "Wand", "die", "Ta\u00b7sche", "dort", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ein Netz im Winkelchen, ein Rechen, Spaten \u2014", "tokens": ["Ein", "Netz", "im", "Win\u00b7kel\u00b7chen", ",", "ein", "Re\u00b7chen", ",", "Spa\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN", "$,", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und Betten? nun, das macht sich einfach hier;", "tokens": ["Und", "Bet\u00b7ten", "?", "nun", ",", "das", "macht", "sich", "ein\u00b7fach", "hier", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "ADV", "$,", "PDS", "VVFIN", "PRF", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Thimian ist heuer gut gerathen,", "tokens": ["Der", "Thi\u00b7mi\u00b7an", "ist", "heu\u00b7er", "gut", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und bl\u00fcht mir grade vor der Th\u00fcr.", "tokens": ["Und", "bl\u00fcht", "mir", "gra\u00b7de", "vor", "der", "Th\u00fcr."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die Waldung dr\u00fcben \u2014 und das Quellgew\u00e4sser \u2014", "tokens": ["Die", "Wal\u00b7dung", "dr\u00fc\u00b7ben", "und", "das", "Quell\u00b7ge\u00b7w\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "KON", "ART", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Hier m\u00f6cht ich Haidebilder schreiben, zum Exempel:", "tokens": ["Hier", "m\u00f6cht", "ich", "Hai\u00b7de\u00b7bil\u00b7der", "schrei\u00b7ben", ",", "zum", "Ex\u00b7em\u00b7pel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NN", "VVINF", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u201edie Vogelh\u00fctte\u201c, nein \u2014 \u201eder Heerd\u201c, nein besser:", "tokens": ["\u201e", "die", "Vo\u00b7gel\u00b7h\u00fct\u00b7te", "\u201c", ",", "nein", "\u201e", "der", "Heerd", "\u201c", ",", "nein", "bes\u00b7ser", ":"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$,", "PTKANT", "$(", "$(", "ART", "NN", "$(", "$,", "PTKANT", "ADJD", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "\u201eder Knieende in Gottes weitem Tempel.\u201c", "tokens": ["\u201e", "der", "Kni\u00b7e\u00b7en\u00b7de", "in", "Got\u00b7tes", "wei\u00b7tem", "Tem\u00b7pel", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "'s ist doch romantisch, wenn ein zart Geriesel", "tokens": ["'s", "ist", "doch", "ro\u00b7man\u00b7tisch", ",", "wenn", "ein", "zart", "Ge\u00b7rie\u00b7sel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "KOUS", "ART", "ADJD", "NN"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Durch Immortellen und Wachholderstrauch", "tokens": ["Durch", "Im\u00b7mor\u00b7tel\u00b7len", "und", "Wach\u00b7hol\u00b7der\u00b7strauch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "+-----+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Umzieht und gleitet, wie ein schl\u00fcpfend Wiesel,", "tokens": ["Um\u00b7zieht", "und", "glei\u00b7tet", ",", "wie", "ein", "schl\u00fcp\u00b7fend", "Wie\u00b7sel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PWAV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und dr\u00fcber flirrt der St\u00f6berrauch;", "tokens": ["Und", "dr\u00fc\u00b7ber", "flirrt", "der", "St\u00f6\u00b7berr\u00b7auch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wenn Schimmer wechseln, wei\u00df und seladonen;", "tokens": ["Wenn", "Schim\u00b7mer", "wech\u00b7seln", ",", "wei\u00df", "und", "se\u00b7la\u00b7do\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$,", "VVFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die weite Eb'ne schaukelt wie ein Schiff,", "tokens": ["Die", "wei\u00b7te", "Eb'\u00b7ne", "schau\u00b7kelt", "wie", "ein", "Schiff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Hindurch der Kibitz schrillt, wie Halcyonen", "tokens": ["Hin\u00b7durch", "der", "Ki\u00b7bitz", "schrillt", ",", "wie", "Hal\u00b7cy\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "PWAV", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wehklagend ziehen um das Riff.", "tokens": ["Weh\u00b7kla\u00b7gend", "zie\u00b7hen", "um", "das", "Riff", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Am Horizont die kolossalen Br\u00fccken \u2014", "tokens": ["Am", "Ho\u00b7ri\u00b7zont", "die", "ko\u00b7los\u00b7sa\u00b7len", "Br\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sind's Wolken oder ist's ein ferner Wald?", "tokens": ["Sin\u00b7d's", "Wol\u00b7ken", "o\u00b7der", "ist's", "ein", "fer\u00b7ner", "Wald", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Ich will den Schemel an die Luke r\u00fccken,", "tokens": ["Ich", "will", "den", "Sche\u00b7mel", "an", "die", "Lu\u00b7ke", "r\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da liegt mein Hut, mein Hammer, \u2014 halt:", "tokens": ["Da", "liegt", "mein", "Hut", ",", "mein", "Ham\u00b7mer", ",", "halt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "$(", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ein Teller am Gestell! \u2014 was mag er bieten?", "tokens": ["Ein", "Tel\u00b7ler", "am", "Ge\u00b7stell", "!", "was", "mag", "er", "bie\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Fundus! bei Gott, ein Fund das Backwerk drin!", "tokens": ["Fun\u00b7dus", "!", "bei", "Gott", ",", "ein", "Fund", "das", "Back\u00b7werk", "drin", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "APPR", "NN", "$,", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "F\u00fcr einen armen Hund von Eremiten,", "tokens": ["F\u00fcr", "ei\u00b7nen", "ar\u00b7men", "Hund", "von", "E\u00b7re\u00b7mi\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie ich es leider heute bin!", "tokens": ["Wie", "ich", "es", "lei\u00b7der", "heu\u00b7te", "bin", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ein seid'ner Beutel noch \u2014 am Bort zerrissen;", "tokens": ["Ein", "sei\u00b7d'\u00b7ner", "Beu\u00b7tel", "noch", "am", "Bort", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "$(", "APPRART", "NN", "VVPP", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich greife, greife Rundes mit der Hand;", "tokens": ["Ich", "grei\u00b7fe", ",", "grei\u00b7fe", "Run\u00b7des", "mit", "der", "Hand", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Weh! in die d\u00fcrre Erbs' hab ich gebissen \u2014", "tokens": ["Weh", "!", "in", "die", "d\u00fcr\u00b7re", "Erbs'", "hab", "ich", "ge\u00b7bis\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "APPR", "ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich dacht', es seye Zuckerkand.", "tokens": ["Ich", "dacht'", ",", "es", "se\u00b7ye", "Zu\u00b7cker\u00b7kand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und nun die Tasche! he, wir m\u00fcssen klopfen \u2014", "tokens": ["Und", "nun", "die", "Ta\u00b7sche", "!", "he", ",", "wir", "m\u00fcs\u00b7sen", "klop\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "NE", "$,", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vielleicht liegt ein Gefang'ner hier in Haft;", "tokens": ["Viel\u00b7leicht", "liegt", "ein", "Ge\u00b7fang'\u00b7ner", "hier", "in", "Haft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da \u2014 eine Flasche! schnell herab den Pfropfen \u2014", "tokens": ["Da", "ei\u00b7ne", "Fla\u00b7sche", "!", "schnell", "her\u00b7ab", "den", "Pfrop\u00b7fen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "ART", "NN", "$.", "ADJD", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist's Wasser? Wasser? \u2014 edler Rebensaft!", "tokens": ["Ist's", "Was\u00b7ser", "?", "Was\u00b7ser", "?", "ed\u00b7ler", "Re\u00b7ben\u00b7saft", "!"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "NN", "$.", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und Edlerer, der ihn dem Sack vertraute,", "tokens": ["Und", "Ed\u00b7le\u00b7rer", ",", "der", "ihn", "dem", "Sack", "ver\u00b7trau\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Splendid barmherziger Wildh\u00fcter du,", "tokens": ["Splen\u00b7did", "barm\u00b7her\u00b7zi\u00b7ger", "Wild\u00b7h\u00fc\u00b7ter", "du", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PPER", "$,"], "meter": "+--+--++-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "F\u00fcr einen armen Schelm, der Erbsen kaute,", "tokens": ["F\u00fcr", "ei\u00b7nen", "ar\u00b7men", "Schelm", ",", "der", "Erb\u00b7sen", "kau\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Den frommen Bruder Tuck im Ivanhoe!", "tokens": ["Den", "from\u00b7men", "Bru\u00b7der", "Tuck", "im", "I\u00b7van\u00b7hoe", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Mit dem Gek\u00f6rn will ich den Kibitz letzen,", "tokens": ["Mit", "dem", "Ge\u00b7k\u00f6rn", "will", "ich", "den", "Ki\u00b7bitz", "let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Es aus der L\u00fccke streun, wenn er im Flug", "tokens": ["Es", "aus", "der", "L\u00fc\u00b7cke", "streun", ",", "wenn", "er", "im", "Flug"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "VVINF", "$,", "KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Herschwirrt, mir auf die Schulter sich zu setzen,", "tokens": ["Her\u00b7schwirrt", ",", "mir", "auf", "die", "Schul\u00b7ter", "sich", "zu", "set\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "APPR", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wie man es lies't in manchem Buch.", "tokens": ["Wie", "man", "es", "lies't", "in", "man\u00b7chem", "Buch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Mir ist ganz wohl in meiner armen Zelle;", "tokens": ["Mir", "ist", "ganz", "wohl", "in", "mei\u00b7ner", "ar\u00b7men", "Zel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie mir das Klausnerleben so gef\u00e4llt!", "tokens": ["Wie", "mir", "das", "Klaus\u00b7ner\u00b7le\u00b7ben", "so", "ge\u00b7f\u00e4llt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich bleibe hier, ich geh nicht von der Stelle,", "tokens": ["Ich", "blei\u00b7be", "hier", ",", "ich", "geh", "nicht", "von", "der", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bevor der letzte Tropfen f\u00e4llt.", "tokens": ["Be\u00b7vor", "der", "letz\u00b7te", "Trop\u00b7fen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}