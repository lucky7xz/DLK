{"dta.poem.7361": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "IiI .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1844", "urn": "urn:nbn:de:kobv:b4-20090519994", "language": ["de:0.99"], "booktitle": "Droste-H\u00fclshoff, Annette von: Gedichte. Stuttgart u. a., 1844."}, "poem": {"stanza.1": {"line.1": {"text": "Von heut am siebenten Tag'", "tokens": ["Von", "heut", "am", "sie\u00b7ben\u00b7ten", "Tag'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Das war eine schwere Stund',", "tokens": ["Das", "war", "ei\u00b7ne", "schwe\u00b7re", "Stund'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Als am Balkone lag", "tokens": ["Als", "am", "Bal\u00b7ko\u00b7ne", "lag"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "VVFIN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Auf ihren Knien Allgund.", "tokens": ["Auf", "ih\u00b7ren", "Kni\u00b7en", "All\u00b7gund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Laut waren des Herzens Schl\u00e4ge:", "tokens": ["Laut", "wa\u00b7ren", "des", "Her\u00b7zens", "Schl\u00e4\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "ART", "NN", "NN", "$."], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "\u201eo Herr! erbarme dich mein,", "tokens": ["\u201e", "o", "Herr", "!", "er\u00b7bar\u00b7me", "dich", "mein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$.", "VVFIN", "PPER", "PPOSAT", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201eund bracht' ich B\u00f6ses zuwege,", "tokens": ["\u201e", "und", "bracht'", "ich", "B\u00f6\u00b7ses", "zu\u00b7we\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201emein sey die Bu\u00df' allein.\u201c", "tokens": ["\u201e", "mein", "sey", "die", "Bu\u00df'", "al\u00b7lein", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "VAFIN", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Dann beugt sie tief hinab,", "tokens": ["Dann", "beugt", "sie", "tief", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sie horcht und horcht und lauscht:", "tokens": ["Sie", "horcht", "und", "horcht", "und", "lauscht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom Wehre tos't es herab,", "tokens": ["Vom", "Weh\u00b7re", "to\u00b7s't", "es", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Forste drunten es rauscht.", "tokens": ["Vom", "Fors\u00b7te", "drun\u00b7ten", "es", "rauscht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "War das ein Fu\u00dftritt? nein!", "tokens": ["War", "das", "ein", "Fu\u00df\u00b7tritt", "?", "nein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der Hirsch setzt \u00fcber die Kluft.", "tokens": ["Der", "Hirsch", "setzt", "\u00fc\u00b7ber", "die", "Kluft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sollt' ein Signal das seyn?", "tokens": ["Sollt'", "ein", "Sig\u00b7nal", "das", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ART", "VAINF", "$."], "meter": "-----+", "measure": "unknown.measure.single"}, "line.4": {"text": "Doch nein, der Auerhahn ruft.", "tokens": ["Doch", "nein", ",", "der", "Au\u00b7er\u00b7hahn", "ruft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "\u201eo mein Erl\u00f6ser, mein Hort!", "tokens": ["\u201e", "o", "mein", "Er\u00b7l\u00f6\u00b7ser", ",", "mein", "Hort", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "\u201eich bin mit S\u00fcnde beschwert,", "tokens": ["\u201e", "ich", "bin", "mit", "S\u00fcn\u00b7de", "be\u00b7schwert", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "\u201esey gn\u00e4dig und nimm mich fort,", "tokens": ["\u201e", "sey", "gn\u00e4\u00b7dig", "und", "nimm", "mich", "fort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADJD", "KON", "VVIMP", "PPER", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201eeh' heim mein Gatte gekehrt.\u201c", "tokens": ["\u201e", "eh'", "heim", "mein", "Gat\u00b7te", "ge\u00b7kehrt", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "NE", "PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "\u201each, wen der B\u00f6se umgarnt,", "tokens": ["\u201e", "ach", ",", "wen", "der", "B\u00f6\u00b7se", "um\u00b7garnt", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "PWS", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "\u201edem alle Kraft er bricht!", "tokens": ["\u201e", "dem", "al\u00b7le", "Kraft", "er", "bricht", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u201edoch hab' ich ja nur gewarnt,", "tokens": ["\u201e", "doch", "hab'", "ich", "ja", "nur", "ge\u00b7warnt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "\u201everrathen, verrathen ja nicht!\u201c", "tokens": ["\u201e", "ver\u00b7ra\u00b7then", ",", "ver\u00b7ra\u00b7then", "ja", "nicht", "!", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "$,", "VVFIN", "ADV", "PTKNEG", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.7": {"line.1": {"text": "\u201eweh! das sind Rossestritte.\u201c", "tokens": ["\u201e", "weh", "!", "das", "sind", "Ros\u00b7se\u00b7strit\u00b7te", ".", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKVZ", "$.", "PDS", "VAFIN", "NN", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Sie sah sie fliegen durch's Thal", "tokens": ["Sie", "sah", "sie", "flie\u00b7gen", "durch's", "Thal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Mit wildem grimmigen Ritte,", "tokens": ["Mit", "wil\u00b7dem", "grim\u00b7mi\u00b7gen", "Rit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie sah auch ihren Gemahl.", "tokens": ["Sie", "sah", "auch", "ih\u00b7ren", "Ge\u00b7mahl", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Sie sah ihn dr\u00e4uen, genau,", "tokens": ["Sie", "sah", "ihn", "dr\u00e4u\u00b7en", ",", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Sie sah ihn ballen die Hand:", "tokens": ["Sie", "sah", "ihn", "bal\u00b7len", "die", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da sanken die Knie der Frau,", "tokens": ["Da", "san\u00b7ken", "die", "Knie", "der", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da rollte sie \u00fcber den Rand.", "tokens": ["Da", "roll\u00b7te", "sie", "\u00fc\u00b7ber", "den", "Rand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.9": {"line.1": {"text": "Und als zum Schlimmen entschlossen", "tokens": ["Und", "als", "zum", "Schlim\u00b7men", "ent\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPRART", "NN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Der Graf sprengt' in das Thor,", "tokens": ["Der", "Graf", "sprengt'", "in", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kam Blut entgegen geflossen,", "tokens": ["Kam", "Blut", "ent\u00b7ge\u00b7gen", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKVZ", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Drang unter'm Gitter hervor.", "tokens": ["Drang", "un\u00b7ter'm", "Git\u00b7ter", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.10": {"line.1": {"text": "Und als er die H\u00e4nde sah falten", "tokens": ["Und", "als", "er", "die", "H\u00e4n\u00b7de", "sah", "fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "VVINF"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sein Weib in letzter Noth,", "tokens": ["Sein", "Weib", "in", "letz\u00b7ter", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da konnt' er den Zorn nicht halten,", "tokens": ["Da", "konnt'", "er", "den", "Zorn", "nicht", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Bleich ward sein Gesicht so roth.", "tokens": ["Bleich", "ward", "sein", "Ge\u00b7sicht", "so", "roth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "\u201eweib, das den Tod sich erkor!\u201c \u2014", "tokens": ["\u201e", "weib", ",", "das", "den", "Tod", "sich", "er\u00b7kor", "!", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "PRELS", "ART", "NN", "PRF", "NE", "$.", "$(", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "\u201e'S war nicht mein Wille\u201c sie sprach,", "tokens": ["\u201e", "'s", "war", "nicht", "mein", "Wil\u00b7le", "\u201c", "sie", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "NE", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$(", "PPER", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Noch eben bracht' sie's hervor.", "tokens": ["Noch", "e\u00b7ben", "bracht'", "sie's", "her\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "\u201eweib, das seine Schw\u00fcre brach!\u201c", "tokens": ["\u201e", "weib", ",", "das", "sei\u00b7ne", "Schw\u00fc\u00b7re", "brach", "!", "\u201c"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wie Abendl\u00fcfte verwehen", "tokens": ["Wie", "A\u00b7ben\u00b7dl\u00fcf\u00b7te", "ver\u00b7we\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NN", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Noch einmal haucht sie ihn an:", "tokens": ["Noch", "ein\u00b7mal", "haucht", "sie", "ihn", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u201ees mu\u00dft' eine S\u00fcnde geschehen \u2014", "tokens": ["\u201e", "es", "mu\u00dft'", "ei\u00b7ne", "S\u00fcn\u00b7de", "ge\u00b7sche\u00b7hen"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ART", "NN", "VVPP", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "\u201eich hab' sie f\u00fcr dich gethan!\u201c", "tokens": ["\u201e", "ich", "hab'", "sie", "f\u00fcr", "dich", "ge\u00b7than", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}