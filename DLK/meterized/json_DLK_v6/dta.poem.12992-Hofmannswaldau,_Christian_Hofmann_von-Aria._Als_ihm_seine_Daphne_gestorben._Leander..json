{"dta.poem.12992": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Aria.  \n Als ihm seine Daphne gestorben.  \n Leander.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Jhr vergn\u00fcgten stunden!", "tokens": ["Ihr", "ver\u00b7gn\u00fcg\u00b7ten", "stun\u00b7den", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wo seyd, wo seyd ihr hin?", "tokens": ["Wo", "seyd", ",", "wo", "seyd", "ihr", "hin", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "$,", "PWAV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ach ihr bleibt verschwunden,", "tokens": ["Ach", "ihr", "bleibt", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ITJ", "PPER", "VVFIN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nun ich verlassen bin.", "tokens": ["Nun", "ich", "ver\u00b7las\u00b7sen", "bin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Meinen Schatz, ach herbe noth!", "tokens": ["Mei\u00b7nen", "Schatz", ",", "ach", "her\u00b7be", "noth", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "XY", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Umfa\u00dft der kalte tod.", "tokens": ["Um\u00b7fa\u00dft", "der", "kal\u00b7te", "tod", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Flie\u00dft, ihr milden thr\u00e4nen!", "tokens": ["Flie\u00dft", ",", "ihr", "mil\u00b7den", "thr\u00e4\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mein Schatz ist ihrer werth.", "tokens": ["Mein", "Schatz", "ist", "ih\u00b7rer", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zeigt das bange sehnen,", "tokens": ["Zeigt", "das", "ban\u00b7ge", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "So mich itzund verzehrt:", "tokens": ["So", "mich", "it\u00b7zund", "ver\u00b7zehrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Zeigt, da\u00df meine lieb\u2019 und tren", "tokens": ["Zeigt", ",", "da\u00df", "mei\u00b7ne", "lieb'", "und", "tren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PPOSAT", "NN", "KON", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Noch ungestorben sey.", "tokens": ["Noch", "un\u00b7ge\u00b7stor\u00b7ben", "sey", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Was mich nie betr\u00fcbet,", "tokens": ["Was", "mich", "nie", "be\u00b7tr\u00fc\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Macht mich nun stets betr\u00fcbt,", "tokens": ["Macht", "mich", "nun", "stets", "be\u00b7tr\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Was mich treu geliebet,", "tokens": ["Was", "mich", "treu", "ge\u00b7lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und ich auch treu geliebt,", "tokens": ["Und", "ich", "auch", "treu", "ge\u00b7liebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Stirbt dahin, und meine lust", "tokens": ["Stirbt", "da\u00b7hin", ",", "und", "mei\u00b7ne", "lust"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PAV", "$,", "KON", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zugleich in meiner brust.", "tokens": ["Zu\u00b7gleich", "in", "mei\u00b7ner", "brust", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Flieht, ach flieht, ihr stunden!", "tokens": ["Flieht", ",", "ach", "flieht", ",", "ihr", "stun\u00b7den", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ITJ", "VVFIN", "$,", "PPOSAT", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ich bin des lebens satt,", "tokens": ["Ich", "bin", "des", "le\u00b7bens", "satt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil vor meine wunden", "tokens": ["Weil", "vor", "mei\u00b7ne", "wun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Es hier kein pflaster hat.", "tokens": ["Es", "hier", "kein", "pflas\u00b7ter", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn der trost, so mir gef\u00e4llt,", "tokens": ["Denn", "der", "trost", ",", "so", "mir", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADV", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ist nicht mehr in der welt.", "tokens": ["Ist", "nicht", "mehr", "in", "der", "welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Daphne kommt nicht wieder,", "tokens": ["Daph\u00b7ne", "kommt", "nicht", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Drum eil\u2019 ich itzt zu ihr.", "tokens": ["Drum", "eil'", "ich", "itzt", "zu", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Tragt, betr\u00fcbte lieder!", "tokens": ["Tragt", ",", "be\u00b7tr\u00fcb\u00b7te", "lie\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Jhr diesen vorsatz f\u00fcr.", "tokens": ["Ihr", "die\u00b7sen", "vor\u00b7satz", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PDAT", "NN", "APPR", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Macht, da\u00df sie aus ihrer grufft", "tokens": ["Macht", ",", "da\u00df", "sie", "aus", "ih\u00b7rer", "grufft"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dem treuen Damon rufft.", "tokens": ["Dem", "treu\u00b7en", "Da\u00b7mon", "rufft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Liebste grabes-h\u00f6le,", "tokens": ["Liebs\u00b7te", "gra\u00b7bes\u00b7h\u00f6le", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Er\u00f6ffne dich vor mich!", "tokens": ["Er\u00b7\u00f6ff\u00b7ne", "dich", "vor", "mich", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So zieht Daphnens seele", "tokens": ["So", "zieht", "Daph\u00b7nens", "see\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die meinige zu sich.", "tokens": ["Die", "mei\u00b7ni\u00b7ge", "zu", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSS", "APPR", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Durch den tod kan ich allein", "tokens": ["Durch", "den", "tod", "kan", "ich", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Bald wieder bey ihr seyn.", "tokens": ["Bald", "wie\u00b7der", "bey", "ihr", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}