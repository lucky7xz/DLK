{"textgrid.poem.53210": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Elias Geiseler und Elisabeth Scolius", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mey, du Herr der Vorjahrs-Zeit,", "tokens": ["Mey", ",", "du", "Herr", "der", "Vor\u00b7jahr\u00b7sZeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vater aller Fruchtbarkeit,", "tokens": ["Va\u00b7ter", "al\u00b7ler", "Frucht\u00b7bar\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Du bebl\u00fcmest Thal und Felder", "tokens": ["Du", "be\u00b7bl\u00fc\u00b7mest", "Thal", "und", "Fel\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd belaubst Gep\u00fcsch und W\u00e4lder.", "tokens": ["Vnd", "be\u00b7laubst", "Ge\u00b7p\u00fcsch", "und", "W\u00e4l\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Aller Erden Lust und Zier,", "tokens": ["Al\u00b7ler", "Er\u00b7den", "Lust", "und", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Liebe huldigt dir,", "tokens": ["Al\u00b7le", "Lie\u00b7be", "hul\u00b7digt", "dir", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df die Welt nicht mu\u00df vergehen,", "tokens": ["Da\u00df", "die", "Welt", "nicht", "mu\u00df", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Scheint allein bey dir zu stehen.", "tokens": ["Scheint", "al\u00b7lein", "bey", "dir", "zu", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Schaw auch dieses liebe Paar,", "tokens": ["Schaw", "auch", "die\u00b7ses", "lie\u00b7be", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das nimmt deiner Anmuth war", "tokens": ["Das", "nimmt", "dei\u00b7ner", "An\u00b7muth", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "VAFIN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Vnd tr\u00e4gt seiner Liebe Flammen", "tokens": ["Vnd", "tr\u00e4gt", "sei\u00b7ner", "Lie\u00b7be", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Jetzt, weil du noch wehrst, zusammen.", "tokens": ["Jetzt", ",", "weil", "du", "noch", "wehrst", ",", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "$,", "PTKVZ", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "Halt dich wol, stimm ihnen ein", "tokens": ["Halt", "dich", "wol", ",", "stimm", "ih\u00b7nen", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "$,", "VVIMP", "PPER", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit gew\u00fcnschtem Sonnen-schein,", "tokens": ["Mit", "ge\u00b7w\u00fcnschtem", "Son\u00b7nen\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "La\u00df die K\u00e4lt' einmal sich legen", "tokens": ["La\u00df", "die", "K\u00e4lt'", "ein\u00b7mal", "sich", "le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "NN", "ADV", "PRF", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd die warme Lufft sich regen.", "tokens": ["Vnd", "die", "war\u00b7me", "Lufft", "sich", "re\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PRF", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Sonderlich weh' ihnen Ruh,", "tokens": ["Son\u00b7der\u00b7lich", "weh'", "ih\u00b7nen", "Ruh", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Anmuth und Begn\u00fcgen zu,", "tokens": ["An\u00b7muth", "und", "Be\u00b7gn\u00fc\u00b7gen", "zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df sie allzeit dich erhalten", "tokens": ["Da\u00df", "sie", "all\u00b7zeit", "dich", "er\u00b7hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd in Liebe nie erkalten.", "tokens": ["Vnd", "in", "Lie\u00b7be", "nie", "er\u00b7kal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Aber was ruff ich dich an?", "tokens": ["A\u00b7ber", "was", "ruff", "ich", "dich", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "PRF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gott der ist allein der Mann,", "tokens": ["Gott", "der", "ist", "al\u00b7lein", "der", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der im Himmel und auff Erden", "tokens": ["Der", "im", "Him\u00b7mel", "und", "auff", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df umb H\u00fclff ersuchet werden.", "tokens": ["Mu\u00df", "umb", "H\u00fclff", "er\u00b7su\u00b7chet", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Er hat erst der Sonnen Pracht,", "tokens": ["Er", "hat", "erst", "der", "Son\u00b7nen", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sie hat nachmals dich gemacht.", "tokens": ["Sie", "hat", "nach\u00b7mals", "dich", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er gebeut den Jahres-Zeiten,", "tokens": ["Er", "ge\u00b7beut", "den", "Jah\u00b7res\u00b7Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie nacheinander schreiten.", "tokens": ["Da\u00df", "sie", "na\u00b7ch\u00b7ein\u00b7an\u00b7der", "schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Er verschaffet, da\u00df die Welt", "tokens": ["Er", "ver\u00b7schaf\u00b7fet", ",", "da\u00df", "die", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Richtig ihren Wechsel h\u00e4lt", "tokens": ["Rich\u00b7tig", "ih\u00b7ren", "Wech\u00b7sel", "h\u00e4lt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd ohn' Ende sich mu\u00df jagen", "tokens": ["Vnd", "ohn'", "En\u00b7de", "sich", "mu\u00df", "ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "PRF", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den N\u00e4chten und den Tagen.", "tokens": ["Mit", "den", "N\u00e4ch\u00b7ten", "und", "den", "Ta\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Der wohn' ewrer Liebe bey,", "tokens": ["Der", "wohn'", "ew\u00b7rer", "Lie\u00b7be", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Da\u00df sie stets gesegnet sey", "tokens": ["Da\u00df", "sie", "stets", "ge\u00b7seg\u00b7net", "sey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd ohn abla\u00df m\u00f6ge gl\u00e4ntzen", "tokens": ["Vnd", "ohn", "ab\u00b7la\u00df", "m\u00f6\u00b7ge", "gl\u00e4nt\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Trotz dem Meyen oder Lentzen.", "tokens": ["Trotz", "dem", "Me\u00b7yen", "o\u00b7der", "Lent\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.10": {"line.1": {"text": "Die\u00df zu thun ist seine Lust,", "tokens": ["Die\u00df", "zu", "thun", "ist", "sei\u00b7ne", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKZU", "VVINF", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Seine Trew ist euch bewust,", "tokens": ["Sei\u00b7ne", "Trew", "ist", "euch", "be\u00b7wust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn jhr jhm nur hertzlich bleibet", "tokens": ["Wenn", "jhr", "jhm", "nur", "hertz\u00b7lich", "blei\u00b7bet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADJD", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Stets in Furchten eingeleibet.", "tokens": ["Stets", "in", "Furch\u00b7ten", "ein\u00b7ge\u00b7lei\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Seht auff dieses Wetter nicht,", "tokens": ["Seht", "auff", "die\u00b7ses", "Wet\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PDAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das zwar viel vom Friede spricht,", "tokens": ["Das", "zwar", "viel", "vom", "Frie\u00b7de", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber darzu umb und an", "tokens": ["A\u00b7ber", "dar\u00b7zu", "umb", "und", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "PTKVZ", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vns kein Mittel zeigen kan.", "tokens": ["Vns", "kein", "Mit\u00b7tel", "zei\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Sondern seht in aller Noht", "tokens": ["Son\u00b7dern", "seht", "in", "al\u00b7ler", "Noht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff sein Wort und sein Geboht,", "tokens": ["Auff", "sein", "Wort", "und", "sein", "Ge\u00b7boht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das wil euch mit Gn\u00fcg' und Segen,", "tokens": ["Das", "wil", "euch", "mit", "Gn\u00fcg'", "und", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wenn jhr jhm vertrawt, belegen.", "tokens": ["Wenn", "jhr", "jhm", "ver\u00b7trawt", ",", "be\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Ich, Herr Br\u00e4utgam, weis vorhin", "tokens": ["Ich", ",", "Herr", "Br\u00e4ut\u00b7gam", ",", "weis", "vor\u00b7hin"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "NN", "NE", "$,", "PTKVZ", "ADV"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Gnug umb ewren gutten Sinn,", "tokens": ["Gnug", "umb", "ew\u00b7ren", "gut\u00b7ten", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn ich selbst hab' ewre Jugend", "tokens": ["Denn", "ich", "selbst", "hab'", "ew\u00b7re", "Ju\u00b7gend"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Erst gef\u00fchrt auff Kunst und Tugend.", "tokens": ["Erst", "ge\u00b7f\u00fchrt", "auff", "Kunst", "und", "Tu\u00b7gend", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ewer ungez\u00e4hmter Flei\u00df", "tokens": ["E\u00b7wer", "un\u00b7ge\u00b7z\u00e4hm\u00b7ter", "Flei\u00df"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Kriegt' ohn untterla\u00df den Prei\u00df,", "tokens": ["Kriegt'", "ohn", "unt\u00b7ter\u00b7la\u00df", "den", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der auch Roberthin getrieben,", "tokens": ["Der", "auch", "Ro\u00b7bert\u00b7hin", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er annahm euch zu lieben.", "tokens": ["Da\u00df", "er", "an\u00b7nahm", "euch", "zu", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Bleibt dabey, f\u00fchrt aus und ein", "tokens": ["Bleibt", "da\u00b7bey", ",", "f\u00fchrt", "aus", "und", "ein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PAV", "$,", "VVFIN", "PTKVZ", "KON", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ewre wenig Sch\u00e4ffelein,", "tokens": ["Ew\u00b7re", "we\u00b7nig", "Sch\u00e4f\u00b7fe\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seht, da\u00df keine b\u00f6se Weyde", "tokens": ["Seht", ",", "da\u00df", "kei\u00b7ne", "b\u00f6\u00b7se", "Wey\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd kein Vnfall sie beleide.", "tokens": ["Vnd", "kein", "Vn\u00b7fall", "sie", "be\u00b7lei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Flieht den Stoltz und Eigen Sinn,", "tokens": ["Flieht", "den", "Stoltz", "und", "Ei\u00b7gen", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Strebt nicht \u00e4ngstig nach Gewinn,", "tokens": ["Strebt", "nicht", "\u00e4ngs\u00b7tig", "nach", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADJD", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die der Geitz hat eingenommen", "tokens": ["Die", "der", "Geitz", "hat", "ein\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Suchen nicht der Heerde Frommen.", "tokens": ["Su\u00b7chen", "nicht", "der", "Heer\u00b7de", "From\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ewer Vorfahr Scolius,", "tokens": ["E\u00b7wer", "Vor\u00b7fahr", "Sco\u00b7lius", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Dessen Kind euch werden mu\u00df,", "tokens": ["Des\u00b7sen", "Kind", "euch", "wer\u00b7den", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPER", "VAINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "War mit Jesaw wol zufrieden,", "tokens": ["War", "mit", "Je\u00b7saw", "wol", "zu\u00b7frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weit von Stoltz und Geitz geschieden.", "tokens": ["Weit", "von", "Stoltz", "und", "Geitz", "ge\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Eiffert seinem Leben nach,", "tokens": ["Eif\u00b7fert", "sei\u00b7nem", "Le\u00b7ben", "nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gott wird ewer Vngemach", "tokens": ["Gott", "wird", "e\u00b7wer", "Vn\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd das Wasser ewrer Z\u00e4hren", "tokens": ["Vnd", "das", "Was\u00b7ser", "ew\u00b7rer", "Z\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stets in Freuden-Wein verkehren.", "tokens": ["Stets", "in", "Freu\u00b7den\u00b7Wein", "ver\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}