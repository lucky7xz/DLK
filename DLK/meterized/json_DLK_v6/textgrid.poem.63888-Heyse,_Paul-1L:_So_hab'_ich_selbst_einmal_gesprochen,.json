{"textgrid.poem.63888": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "1L: So hab' ich selbst einmal gesprochen,", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So hab' ich selbst einmal gesprochen,", "tokens": ["So", "hab'", "ich", "selbst", "ein\u00b7mal", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Aller Pfuscherei den Stab gebrochen,", "tokens": ["Al\u00b7ler", "Pfu\u00b7sche\u00b7rei", "den", "Stab", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Und war doch selber unter der Hand", "tokens": ["Und", "war", "doch", "sel\u00b7ber", "un\u00b7ter", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein gottvergn\u00fcgter Dilettant,", "tokens": ["Ein", "gott\u00b7ver\u00b7gn\u00fcg\u00b7ter", "Di\u00b7let\u00b7tant", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.5": {"text": "Den's h\u00f6chlich auferbaut, zuzeiten", "tokens": ["Den's", "h\u00f6ch\u00b7lich", "au\u00b7fer\u00b7baut", ",", "zu\u00b7zei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NE", "ADJD", "VVPP", "$,", "VVIZU"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Steckenpferdlein frisch zu reiten.", "tokens": ["Sein", "Ste\u00b7cken\u00b7pferd\u00b7lein", "frisch", "zu", "rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Noch denkst du wohl der Tage, Freund,", "tokens": ["Noch", "denkst", "du", "wohl", "der", "Ta\u00b7ge", ",", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da wir selbander umhergestreunt", "tokens": ["Da", "wir", "sel\u00b7ban\u00b7der", "um\u00b7her\u00b7ge\u00b7streunt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "In Th\u00fcrings Berg- und Waldgeheg,", "tokens": ["In", "Th\u00fc\u00b7rings", "Ber\u00b7g", "und", "Wald\u00b7ge\u00b7heg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Allwo dir kund sind Weg und Steg,", "tokens": ["All\u00b7wo", "dir", "kund", "sind", "Weg", "und", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PTKVZ", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Und wie wir oft im Gr\u00fcnen sa\u00dfen,", "tokens": ["Und", "wie", "wir", "oft", "im", "Gr\u00fc\u00b7nen", "sa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "\u00dcberm Kritzeln Speis' und Trank verga\u00dfen,", "tokens": ["\u00dc\u00b7berm", "Krit\u00b7zeln", "Speis'", "und", "Trank", "ver\u00b7ga\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Ein Br\u00f6ckchen Fels, ein alt Gem\u00e4uer", "tokens": ["Ein", "Br\u00f6ck\u00b7chen", "Fels", ",", "ein", "alt", "Ge\u00b7m\u00e4u\u00b7er"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Hinstrichelten mit heil'gem Feuer", "tokens": ["Hin\u00b7stri\u00b7chel\u00b7ten", "mit", "heil'\u00b7gem", "Feu\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.15": {"text": "In jenes B\u00fcchlein schlank und schm\u00e4chtig,", "tokens": ["In", "je\u00b7nes", "B\u00fcch\u00b7lein", "schlank", "und", "schm\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Das du erstanden wohlbed\u00e4chtig", "tokens": ["Das", "du", "er\u00b7stan\u00b7den", "wohl\u00b7be\u00b7d\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "In Jena neben Frommanns Haus,", "tokens": ["In", "Je\u00b7na", "ne\u00b7ben", "From\u00b7manns", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "(sah wie ein Sch\u00fclerschreibheft aus,", "tokens": ["(", "sah", "wie", "ein", "Sch\u00fc\u00b7ler\u00b7schreib\u00b7heft", "aus", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "KOKOM", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Blau der Umschlag und d\u00fcnn die Bl\u00e4tter).", "tokens": ["Blau", "der", "Um\u00b7schlag", "und", "d\u00fcnn", "die", "Bl\u00e4t\u00b7ter", ")", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ART", "NN", "KON", "ADJD", "ART", "NN", "$(", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.20": {"text": "Doch wir in gut' und schlechtem Wetter", "tokens": ["Doch", "wir", "in", "gut'", "und", "schlech\u00b7tem", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Erprobten darin mit Leidenschaft", "tokens": ["Er\u00b7prob\u00b7ten", "da\u00b7rin", "mit", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PAV", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Unsre verstohlne K\u00fcnstlerkraft,", "tokens": ["Uns\u00b7re", "ver\u00b7stohl\u00b7ne", "K\u00fcnst\u00b7ler\u00b7kraft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Fanden auch nichts Kurioses dran,", "tokens": ["Fan\u00b7den", "auch", "nichts", "Ku\u00b7ri\u00b7o\u00b7ses", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Da\u00df einer macht, was er nicht kann.", "tokens": ["Da\u00df", "ei\u00b7ner", "macht", ",", "was", "er", "nicht", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "PWS", "PPER", "PTKNEG", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach, wenn in Ferien dann und wann,", "tokens": ["Ach", ",", "wenn", "in", "Fe\u00b7ri\u00b7en", "dann", "und", "wann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "KOUS", "APPR", "NE", "ADV", "KON", "PWAV", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wer einer Kunst sich zugeschworen,", "tokens": ["Wer", "ei\u00b7ner", "Kunst", "sich", "zu\u00b7ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Oder sonst ein schwer Gesch\u00e4ft erkoren,", "tokens": ["O\u00b7der", "sonst", "ein", "schwer", "Ge\u00b7sch\u00e4ft", "er\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "In andern freien K\u00fcnsten pfuscht,", "tokens": ["In", "an\u00b7dern", "frei\u00b7en", "K\u00fcns\u00b7ten", "pfuscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Fl\u00f6te bl\u00e4st oder Bildlein tuscht,", "tokens": ["Fl\u00f6\u00b7te", "bl\u00e4st", "o\u00b7der", "Bild\u00b7lein", "tuscht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Niemand zur Last, sich zum Vergn\u00fcgen,", "tokens": ["Nie\u00b7mand", "zur", "Last", ",", "sich", "zum", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "APPRART", "NN", "$,", "PRF", "APPRART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Zumal auf einsamen Wanderz\u00fcgen,", "tokens": ["Zu\u00b7mal", "auf", "ein\u00b7sa\u00b7men", "Wan\u00b7der\u00b7z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Soll man nicht gleich so hitzig l\u00e4stern.", "tokens": ["Soll", "man", "nicht", "gleich", "so", "hit\u00b7zig", "l\u00e4s\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKNEG", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Sind doch die Musen liebe Schwestern:", "tokens": ["Sind", "doch", "die", "Mu\u00b7sen", "lie\u00b7be", "Schwes\u00b7tern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "F\u00fchrt man die eine heim als Frau,", "tokens": ["F\u00fchrt", "man", "die", "ei\u00b7ne", "heim", "als", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ART", "PTKVZ", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sie nimmt's wohl einmal nicht genau,", "tokens": ["Sie", "nimmt's", "wohl", "ein\u00b7mal", "nicht", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wird l\u00e4chelnd durch die Finger sehn,", "tokens": ["Wird", "l\u00e4\u00b7chelnd", "durch", "die", "Fin\u00b7ger", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Tut man mit einer Schw\u00e4gerin sch\u00f6n,", "tokens": ["Tut", "man", "mit", "ei\u00b7ner", "Schw\u00e4\u00b7ge\u00b7rin", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Da es ja in der Familie bleibt;", "tokens": ["Da", "es", "ja", "in", "der", "Fa\u00b7mi\u00b7lie", "bleibt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.15": {"text": "Dafern man's nur in Z\u00fcchten treibt,", "tokens": ["Da\u00b7fern", "man's", "nur", "in", "Z\u00fcch\u00b7ten", "treibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit seinem stillen Dilettieren", "tokens": ["Mit", "sei\u00b7nem", "stil\u00b7len", "Di\u00b7let\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Nicht vor den Leuten will renommieren.", "tokens": ["Nicht", "vor", "den", "Leu\u00b7ten", "will", "re\u00b7nom\u00b7mie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "So hab' ich's all mein' Tag' getrieben,", "tokens": ["So", "hab'", "ich's", "all", "mein'", "Tag'", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PIAT", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist mir darum auch fern geblieben", "tokens": ["Ist", "mir", "da\u00b7rum", "auch", "fern", "ge\u00b7blie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PAV", "ADV", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Naser\u00fcmpfen und h\u00f6hnisch Lachen,", "tokens": ["Das", "Na\u00b7se\u00b7r\u00fcmp\u00b7fen", "und", "h\u00f6h\u00b7nisch", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn's andre eben nicht anders machen.", "tokens": ["Wenn's", "and\u00b7re", "e\u00b7ben", "nicht", "an\u00b7ders", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ja, oft empfand ich einen Neid,", "tokens": ["Ja", ",", "oft", "emp\u00b7fand", "ich", "ei\u00b7nen", "Neid", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sah ich die Himmelsseligkeit,", "tokens": ["Sah", "ich", "die", "Him\u00b7mels\u00b7se\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Womit ein unbefugt Talent", "tokens": ["Wo\u00b7mit", "ein", "un\u00b7be\u00b7fugt", "Ta\u00b7lent"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von hoher Sch\u00f6pferlust entbrennt,", "tokens": ["Von", "ho\u00b7her", "Sch\u00f6p\u00b7fer\u00b7lust", "ent\u00b7brennt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Skizzenb\u00fccher zusammenschichtet,", "tokens": ["Skiz\u00b7zen\u00b7b\u00fc\u00b7cher", "zu\u00b7sam\u00b7men\u00b7schich\u00b7tet", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "Dicke Hefte voll Lieder dichtet", "tokens": ["Di\u00b7cke", "Hef\u00b7te", "voll", "Lie\u00b7der", "dich\u00b7tet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "ADJD", "NN", "VVFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Und wie ein Geiziger, wenn es nachtet,", "tokens": ["Und", "wie", "ein", "Gei\u00b7zi\u00b7ger", ",", "wenn", "es", "nach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "$,", "KOUS", "PPER", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Den angeh\u00e4uften Schatz betrachtet.", "tokens": ["Den", "an\u00b7ge\u00b7h\u00e4uf\u00b7ten", "Schatz", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Blieb's nur dabei! Doch leider rei\u00dft", "tokens": ["Blie\u00b7b's", "nur", "da\u00b7bei", "!", "Doch", "lei\u00b7der", "rei\u00dft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "PAV", "$.", "KON", "ADV", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Die Guten hin ein b\u00f6ser Geist,", "tokens": ["Die", "Gu\u00b7ten", "hin", "ein", "b\u00f6\u00b7ser", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dem Licht auch endlich zu offenbaren,", "tokens": ["Dem", "Licht", "auch", "end\u00b7lich", "zu", "of\u00b7fen\u00b7ba\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Wie vergn\u00fcgt sie im Dunkeln waren,", "tokens": ["Wie", "ver\u00b7gn\u00fcgt", "sie", "im", "Dun\u00b7keln", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Da dann am kalten Blick der Welt", "tokens": ["Da", "dann", "am", "kal\u00b7ten", "Blick", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Ihr Reichtum nicht die Probe h\u00e4lt.", "tokens": ["Ihr", "Reich\u00b7tum", "nicht", "die", "Pro\u00b7be", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Dann wird der Segen sch\u00f6nster Stunden", "tokens": ["Dann", "wird", "der", "Se\u00b7gen", "sch\u00f6ns\u00b7ter", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Gez\u00e4hlt, gewogen, zu leicht erfunden.", "tokens": ["Ge\u00b7z\u00e4hlt", ",", "ge\u00b7wo\u00b7gen", ",", "zu", "leicht", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "PTKA", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "So hat in Rom mich ungescheut", "tokens": ["So", "hat", "in", "Rom", "mich", "un\u00b7ge\u00b7scheut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "NE", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein bi\u00dfchen Pfuscherei erfreut,", "tokens": ["Mein", "bi\u00df\u00b7chen", "Pfu\u00b7sche\u00b7rei", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wo sich hinlenkt unser Schritt,", "tokens": ["Und", "wo", "sich", "hin\u00b7lenkt", "un\u00b7ser", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wandert das Zeichenb\u00fcchlein mit,", "tokens": ["Wan\u00b7dert", "das", "Zei\u00b7chen\u00b7b\u00fcch\u00b7lein", "mit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "(nicht wie in junger Zeit f\u00fcrwahr,", "tokens": ["(", "nicht", "wie", "in", "jun\u00b7ger", "Zeit", "f\u00fcr\u00b7wahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "KOKOM", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.6": {"text": "Wo's manchmal ein Galeotto war", "tokens": ["Wo's", "manch\u00b7mal", "ein", "Ga\u00b7leot\u00b7to", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und etwa mir bei sch\u00f6nen Augen", "tokens": ["Und", "et\u00b7wa", "mir", "bei", "sch\u00f6\u00b7nen", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Mu\u00dfte die T\u00fcr zu \u00f6ffnen taugen,", "tokens": ["Mu\u00df\u00b7te", "die", "T\u00fcr", "zu", "\u00f6ff\u00b7nen", "tau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Da ein ", "tokens": ["Da", "ein"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "-+", "measure": "iambic.single"}, "line.10": {"text": "Stets unverd\u00e4chtigen Zutritt hat.)", "tokens": ["Stets", "un\u00b7ver\u00b7d\u00e4ch\u00b7ti\u00b7gen", "Zu\u00b7tritt", "hat", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "$.", "$("], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Heut ging's hinunter nach dem Tore", "tokens": ["Heut", "ging's", "hin\u00b7un\u00b7ter", "nach", "dem", "To\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Vor\u00fcber an Marie Maggiore", "tokens": ["Vor\u00b7\u00fc\u00b7ber", "an", "Ma\u00b7rie", "Mag\u00b7gio\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "NE", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Da w\u00e4chst empor eine neue Stadt,", "tokens": ["Da", "w\u00e4chst", "em\u00b7por", "ei\u00b7ne", "neu\u00b7e", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Sechs Stock hoch, wei\u00dfget\u00fcncht und glatt,", "tokens": ["Sechs", "Stock", "hoch", ",", "wei\u00df\u00b7ge\u00b7t\u00fcncht", "und", "glatt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Gem\u00fctlos widerw\u00e4rtige Kasten,", "tokens": ["Ge\u00b7m\u00fct\u00b7los", "wi\u00b7der\u00b7w\u00e4r\u00b7ti\u00b7ge", "Kas\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Die ba\u00df zum K\u00f6pnickerfelde pa\u00dften.", "tokens": ["Die", "ba\u00df", "zum", "K\u00f6p\u00b7ni\u00b7cker\u00b7fel\u00b7de", "pa\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Dazwischen schaut ein Ruinentrumm", "tokens": ["Da\u00b7zwi\u00b7schen", "schaut", "ein", "Ru\u00b7i\u00b7nen\u00b7trumm"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Verlegen und betr\u00fcbt sich um", "tokens": ["Ver\u00b7le\u00b7gen", "und", "be\u00b7tr\u00fcbt", "sich", "um"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "PRF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und scheint von naher Zeit zu tr\u00e4umen,", "tokens": ["Und", "scheint", "von", "na\u00b7her", "Zeit", "zu", "tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Wo es denn auch den Platz soll r\u00e4umen.", "tokens": ["Wo", "es", "denn", "auch", "den", "Platz", "soll", "r\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Wir sahn das braune Gem\u00e4uer winken,", "tokens": ["Wir", "sahn", "das", "brau\u00b7ne", "Ge\u00b7m\u00e4u\u00b7er", "win\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Einen hohlen Zahn mit schartigen Zinken;", "tokens": ["Ei\u00b7nen", "hoh\u00b7len", "Zahn", "mit", "schar\u00b7ti\u00b7gen", "Zin\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.23": {"text": "Unweit dahinter her\u00fcbersah", "tokens": ["Un\u00b7weit", "da\u00b7hin\u00b7ter", "her\u00b7\u00fc\u00b7ber\u00b7sah"], "token_info": ["word", "word", "word"], "pos": ["NN", "PAV", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Die alte Minerva medica,", "tokens": ["Die", "al\u00b7te", "Mi\u00b7ner\u00b7va", "me\u00b7di\u00b7ca", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Auch ein St\u00fcck eines Aqu\u00e4dukts,", "tokens": ["Auch", "ein", "St\u00fcck", "ei\u00b7nes", "A\u00b7qu\u00e4d\u00b7ukts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.26": {"text": "Und gleich mir in den Fingern zuckt's,", "tokens": ["Und", "gleich", "mir", "in", "den", "Fin\u00b7gern", "zuckt's", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Als ob hier was zu holen sei.", "tokens": ["Als", "ob", "hier", "was", "zu", "ho\u00b7len", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Nun lag ein H\u00fcttlein nebenbei,", "tokens": ["Nun", "lag", "ein", "H\u00fctt\u00b7lein", "ne\u00b7ben\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Dem Altertum just gegen\u00fcber;", "tokens": ["Dem", "Al\u00b7ter\u00b7tum", "just", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Der niedren T\u00fcr, und aus der K\u00fcche", "tokens": ["Der", "nied\u00b7ren", "T\u00fcr", ",", "und", "aus", "der", "K\u00fc\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Kamen Zwiebel- und Weinger\u00fcche,", "tokens": ["Ka\u00b7men", "Zwie\u00b7bel", "und", "Wein\u00b7ge\u00b7r\u00fc\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "TRUNC", "KON", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.32": {"text": "Wie man's wohl kennt in r\u00f6mischen Schenken.", "tokens": ["Wie", "man's", "wohl", "kennt", "in", "r\u00f6\u00b7mi\u00b7schen", "Schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Dahin wir flugs die Schritte lenken", "tokens": ["Da\u00b7hin", "wir", "flugs", "die", "Schrit\u00b7te", "len\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Und bitten, da\u00df man vor die T\u00fcr", "tokens": ["Und", "bit\u00b7ten", ",", "da\u00df", "man", "vor", "die", "T\u00fcr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "$,", "KOUS", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Uns ein paar Sitze tr\u00fcg' herf\u00fcr,", "tokens": ["Uns", "ein", "paar", "Sit\u00b7ze", "tr\u00fcg'", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "PIAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Mein Pfuschwerk eilig zu beginnen.", "tokens": ["Mein", "Pfu\u00b7schwerk", "ei\u00b7lig", "zu", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Ein junges Ehpaar hauste drinnen,", "tokens": ["Ein", "jun\u00b7ges", "Eh\u00b7paar", "haus\u00b7te", "drin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Das eben sein ", "tokens": ["Das", "e\u00b7ben", "sein"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "PPOSAT"], "meter": "-+-+", "measure": "iambic.di"}, "line.39": {"text": "Und Brot und Wein vollendet hat.", "tokens": ["Und", "Brot", "und", "Wein", "voll\u00b7en\u00b7det", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Die trugen zwei Sessel vor das Haus,", "tokens": ["Die", "tru\u00b7gen", "zwei", "Ses\u00b7sel", "vor", "das", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.41": {"text": "Sa\u00dfen dann selbst zu uns hinaus,", "tokens": ["Sa\u00b7\u00dfen", "dann", "selbst", "zu", "uns", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PRF", "APZR", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.42": {"text": "Und w\u00e4hrend flink mein Stift sich r\u00fchrte,", "tokens": ["Und", "w\u00e4h\u00b7rend", "flink", "mein", "Stift", "sich", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "Man eine Zwiesprach zusammen f\u00fchrte.", "tokens": ["Man", "ei\u00b7ne", "Zwie\u00b7sprach", "zu\u00b7sam\u00b7men", "f\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.44": {"text": "Ein Jahr erst waren sie verm\u00e4hlt,", "tokens": ["Ein", "Jahr", "erst", "wa\u00b7ren", "sie", "ver\u00b7m\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Hatten dies arme Nest erw\u00e4hlt,", "tokens": ["Hat\u00b7ten", "dies", "ar\u00b7me", "Nest", "er\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADJA", "NN", "VVPP", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.46": {"text": "Weil niemand sonst dazu sich fand,", "tokens": ["Weil", "nie\u00b7mand", "sonst", "da\u00b7zu", "sich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PAV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "Da es l\u00e4ngst auf dem Abbruch stand.", "tokens": ["Da", "es", "l\u00e4ngst", "auf", "dem", "Ab\u00b7bruch", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.48": {"text": "Die Frau, ein harmlos muntres Wesen,", "tokens": ["Die", "Frau", ",", "ein", "harm\u00b7los", "mun\u00b7tres", "We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "W\u00e4r' gar so \u00fcbel nicht gewesen,", "tokens": ["W\u00e4r'", "gar", "so", "\u00fc\u00b7bel", "nicht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "PTKNEG", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.50": {"text": "H\u00e4tt' nur ein wenig Waschen gebraucht,", "tokens": ["H\u00e4tt'", "nur", "ein", "we\u00b7nig", "Wa\u00b7schen", "ge\u00b7braucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "PIAT", "NN", "VVPP", "$,"], "meter": "---+-+--+", "measure": "iambic.tri.chol"}, "line.51": {"text": "So war sie staubig und angeraucht.", "tokens": ["So", "war", "sie", "stau\u00b7big", "und", "an\u00b7ge\u00b7raucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.52": {"text": "Ihr Gatte gr\u00fc\u00dfte mich als Kollegen:", "tokens": ["Ihr", "Gat\u00b7te", "gr\u00fc\u00df\u00b7te", "mich", "als", "Kol\u00b7le\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "Er t\u00e4t' einst selber der Malkunst pflegen.", "tokens": ["Er", "t\u00e4t'", "einst", "sel\u00b7ber", "der", "Mal\u00b7kunst", "pfle\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.54": {"text": "Nach Solferino hab' er einmal", "tokens": ["Nach", "Sol\u00b7fe\u00b7ri\u00b7no", "hab'", "er", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.55": {"text": "Wund m\u00fcssen liegen im Spital", "tokens": ["Wund", "m\u00fcs\u00b7sen", "lie\u00b7gen", "im", "Spi\u00b7tal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "Viel \u00f6de Wochen und Monden lang,", "tokens": ["Viel", "\u00f6\u00b7de", "Wo\u00b7chen", "und", "Mon\u00b7den", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KON", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.57": {"text": "Da hab' er so aus Herzensdrang", "tokens": ["Da", "hab'", "er", "so", "aus", "Her\u00b7zens\u00b7drang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Mit Zeichnen sich die Zeit vertrieben,", "tokens": ["Mit", "Zeich\u00b7nen", "sich", "die", "Zeit", "ver\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "Nun sei ihm nur die Lust geblieben.", "tokens": ["Nun", "sei", "ihm", "nur", "die", "Lust", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.60": {"text": "Er k\u00f6nn' an Berg' und Mauern dort", "tokens": ["Er", "k\u00f6nn'", "an", "Ber\u00b7g'", "und", "Mau\u00b7ern", "dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.61": {"text": "Sich nimmer satt sehn fort und fort.", "tokens": ["Sich", "nim\u00b7mer", "satt", "sehn", "fort", "und", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVINF", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Ich sollt' auch fein die zwei Zypressen", "tokens": ["Ich", "sollt'", "auch", "fein", "die", "zwei", "Zyp\u00b7res\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "ART", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.63": {"text": "Dort auf dem H\u00fcgel nicht vergessen,", "tokens": ["Dort", "auf", "dem", "H\u00fc\u00b7gel", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.64": {"text": "Auf da\u00df doch immer ein Abbild bliebe,", "tokens": ["Auf", "da\u00df", "doch", "im\u00b7mer", "ein", "Ab\u00b7bild", "blie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.65": {"text": "Wenn hier der Neubau sie vertriebe.", "tokens": ["Wenn", "hier", "der", "Neu\u00b7bau", "sie", "ver\u00b7trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.66": {"text": "Er selber hab's versucht; doch sei", "tokens": ["Er", "sel\u00b7ber", "hab's", "ver\u00b7sucht", ";", "doch", "sei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "VVPP", "$.", "ADV", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Es ihm zu schwer, er sag' es frei.", "tokens": ["Es", "ihm", "zu", "schwer", ",", "er", "sag'", "es", "frei", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "PTKA", "ADJD", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "So plauderten ein St\u00fcndlein wir", "tokens": ["So", "plau\u00b7der\u00b7ten", "ein", "St\u00fcnd\u00b7lein", "wir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In guter Freundschaft alle vier.", "tokens": ["In", "gu\u00b7ter", "Freund\u00b7schaft", "al\u00b7le", "vier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PIAT", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So still und lieblich war der Ort,", "tokens": ["So", "still", "und", "lieb\u00b7lich", "war", "der", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lenzhaft schien die Sonne dort", "tokens": ["So", "lenz\u00b7haft", "schien", "die", "Son\u00b7ne", "dort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon in des Februars Beginne \u2013", "tokens": ["Schon", "in", "des", "Feb\u00b7ru\u00b7ars", "Be\u00b7gin\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Es ward uns wunderwohl zu Sinne.", "tokens": ["Es", "ward", "uns", "wun\u00b7der\u00b7wohl", "zu", "Sin\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und als mein Skizzchen nun vollbracht \u2013", "tokens": ["Und", "als", "mein", "Skizz\u00b7chen", "nun", "voll\u00b7bracht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Eilfertig, wie's ein St\u00fcmper macht \u2013", "tokens": ["Eil\u00b7fer\u00b7tig", ",", "wie's", "ein", "St\u00fcm\u00b7per", "macht", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mu\u00dft' ich mit meiner lieben Frauen", "tokens": ["Mu\u00dft'", "ich", "mit", "mei\u00b7ner", "lie\u00b7ben", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Das H\u00fcttlein auch von innen schauen.", "tokens": ["Das", "H\u00fctt\u00b7lein", "auch", "von", "in\u00b7nen", "schau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Da war nun alles nach Landesbrauch", "tokens": ["Da", "war", "nun", "al\u00b7les", "nach", "Lan\u00b7des\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Gar d\u00fcrftig, kahl, voll Ru\u00df und Rauch,", "tokens": ["Gar", "d\u00fcrf\u00b7tig", ",", "kahl", ",", "voll", "Ru\u00df", "und", "Rauch", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADJD", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Der Tisch am Herde schlecht und recht,", "tokens": ["Der", "Tisch", "am", "Her\u00b7de", "schlecht", "und", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Ein Riesenfiasko in Strohgeflecht,", "tokens": ["Ein", "Rie\u00b7sen\u00b7fi\u00b7as\u00b7ko", "in", "Stroh\u00b7ge\u00b7flecht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Nur wenig Hausrat ringsumher,", "tokens": ["Nur", "we\u00b7nig", "Haus\u00b7rat", "rings\u00b7um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Als stammt' er noch von den Tagen her,", "tokens": ["Als", "stammt'", "er", "noch", "von", "den", "Ta\u00b7gen", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Da Hannibal vor den Toren stand.", "tokens": ["Da", "Han\u00b7ni\u00b7bal", "vor", "den", "To\u00b7ren", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Doch hinter der schwarzen Bretterwand", "tokens": ["Doch", "hin\u00b7ter", "der", "schwar\u00b7zen", "Bret\u00b7ter\u00b7wand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Tat sich noch auf ein K\u00e4mmerlein,", "tokens": ["Tat", "sich", "noch", "auf", "ein", "K\u00e4m\u00b7mer\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Da f\u00fchrt das Paar uns stolz hinein.", "tokens": ["Da", "f\u00fchrt", "das", "Paar", "uns", "stolz", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "War zwar nichts K\u00f6stlichs dran zu sehn,", "tokens": ["War", "zwar", "nichts", "K\u00f6st\u00b7lichs", "dran", "zu", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "PIS", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Kaum Platz, sich eben umzudrehn,", "tokens": ["Kaum", "Platz", ",", "sich", "e\u00b7ben", "um\u00b7zu\u00b7drehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PRF", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Ein Bett mit Strohsack, vielgeflickt,", "tokens": ["Ein", "Bett", "mit", "Stroh\u00b7sack", ",", "viel\u00b7ge\u00b7flickt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Doch wie wir forschend umgeblickt,", "tokens": ["Doch", "wie", "wir", "for\u00b7schend", "um\u00b7ge\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Sahn wir die niedren W\u00e4nde rings,", "tokens": ["Sahn", "wir", "die", "nied\u00b7ren", "W\u00e4n\u00b7de", "rings", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Die schiefe Decke rechts und links", "tokens": ["Die", "schie\u00b7fe", "De\u00b7cke", "rechts", "und", "links"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Tapeziert mit Bildern allerhand,", "tokens": ["Ta\u00b7pe\u00b7ziert", "mit", "Bil\u00b7dern", "al\u00b7ler\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PIAT", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.28": {"text": "S\u00e4mtlich von einer schweren Hand", "tokens": ["S\u00e4mt\u00b7lich", "von", "ei\u00b7ner", "schwe\u00b7ren", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.29": {"text": "Mit bunten Stiften \u00fcbermalt.", "tokens": ["Mit", "bun\u00b7ten", "Stif\u00b7ten", "\u00fc\u00b7ber\u00b7malt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Unseres Wirtes Auge strahlt,", "tokens": ["Un\u00b7se\u00b7res", "Wir\u00b7tes", "Au\u00b7ge", "strahlt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.31": {"text": "Da er uns seine Werke wies.", "tokens": ["Da", "er", "uns", "sei\u00b7ne", "Wer\u00b7ke", "wies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.33": {"text": "Und dies der Hafen von Triest;", "tokens": ["Und", "dies", "der", "Ha\u00b7fen", "von", "Triest", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.34": {"text": "Auch dies sich wohl erkennen l\u00e4\u00dft;", "tokens": ["Auch", "dies", "sich", "wohl", "er\u00b7ken\u00b7nen", "l\u00e4\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "PRF", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Die spanische Treppe stellt es vor,", "tokens": ["Die", "spa\u00b7ni\u00b7sche", "Trep\u00b7pe", "stellt", "es", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.36": {"text": "Und dies den Lateran, Signor,", "tokens": ["Und", "dies", "den", "La\u00b7te\u00b7ran", ",", "Sig\u00b7nor", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PDS", "ART", "NN", "$,", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Und dies \u2013 und dies \u2013 \u2013 sind arme Sachen,", "tokens": ["Und", "dies", "\u2013", "und", "dies", "\u2013", "\u2013", "sind", "ar\u00b7me", "Sa\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$(", "KON", "PDS", "$(", "$(", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Und war doch lustig, sie zu machen.\u00ab", "tokens": ["Und", "war", "doch", "lus\u00b7tig", ",", "sie", "zu", "ma\u00b7chen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wir aber standen und staunten m\u00e4chtig,", "tokens": ["Wir", "a\u00b7ber", "stan\u00b7den", "und", "staun\u00b7ten", "m\u00e4ch\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Belobten alles gar and\u00e4chtig", "tokens": ["Be\u00b7lob\u00b7ten", "al\u00b7les", "gar", "an\u00b7d\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und sprachen unter uns: Es hei\u00dft", "tokens": ["Und", "spra\u00b7chen", "un\u00b7ter", "uns", ":", "Es", "hei\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Wahrheit \u00bbSelig, die arm an Geist\u00ab.", "tokens": ["In", "Wahr\u00b7heit", "\u00bb", "Se\u00b7lig", ",", "die", "arm", "an", "Geist", "\u00ab", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$(", "NE", "$,", "PRELS", "ADJD", "APPR", "NN", "$(", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der biedre K\u00fcnstler hier, ich wette,", "tokens": ["Der", "bied\u00b7re", "K\u00fcnst\u00b7ler", "hier", ",", "ich", "wet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Erwacht er fr\u00fch in seinem Bette", "tokens": ["Er\u00b7wacht", "er", "fr\u00fch", "in", "sei\u00b7nem", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und sieht ringsum an Deck' und Wand", "tokens": ["Und", "sieht", "ring\u00b7sum", "an", "Deck'", "und", "Wand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die bunte Sch\u00f6pfung seiner Hand,", "tokens": ["Die", "bun\u00b7te", "Sch\u00f6p\u00b7fung", "sei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nicht Raffael war so selig, da", "tokens": ["Nicht", "Raf\u00b7fael", "war", "so", "se\u00b7lig", ",", "da"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["PTKNEG", "NE", "VAFIN", "ADV", "ADJD", "$,", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ihm vorgeschwebt die Disputa.", "tokens": ["Ihm", "vor\u00b7ge\u00b7schwebt", "die", "Dis\u00b7pu\u00b7ta", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und also schieden wir. Der Gute", "tokens": ["Und", "al\u00b7so", "schie\u00b7den", "wir", ".", "Der", "Gu\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00fcnscht' meinem Weib ", "tokens": ["W\u00fcnscht'", "mei\u00b7nem", "Weib"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Seitdem, seh' ich mein B\u00fcchlein an,", "tokens": ["Seit\u00b7dem", ",", "seh'", "ich", "mein", "B\u00fcch\u00b7lein", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Hab' ich auch meine Freude dran", "tokens": ["Hab'", "ich", "auch", "mei\u00b7ne", "Freu\u00b7de", "dran"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und spreche getrost: sind arme Sachen,", "tokens": ["Und", "spre\u00b7che", "ge\u00b7trost", ":", "sind", "ar\u00b7me", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVPP", "$.", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und war doch lustig, sie zu machen.", "tokens": ["Und", "war", "doch", "lus\u00b7tig", ",", "sie", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}