{"textgrid.poem.38270": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Ein h\u00fcbsch Lied, genannt der Striegel,", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Constanz sa\u00df ein Kaufmann reich,", "tokens": ["Zu", "Con\u00b7stanz", "sa\u00df", "ein", "Kauf\u00b7mann", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der hat ein Fr\u00e4ulein war wonnigleich,", "tokens": ["Der", "hat", "ein", "Fr\u00e4u\u00b7lein", "war", "won\u00b7ni\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Denn sie war h\u00fcbsch und kluge,", "tokens": ["Denn", "sie", "war", "h\u00fcbsch", "und", "klu\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "KON", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hatt' ein Doktor gar zu lieb,", "tokens": ["Sie", "hatt'", "ein", "Dok\u00b7tor", "gar", "zu", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gro\u00df Lieb sie zammen trugen.", "tokens": ["Gro\u00df", "Lieb", "sie", "zam\u00b7men", "tru\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Liebe, die war offenbar,", "tokens": ["Die", "Lie\u00b7be", ",", "die", "war", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und w\u00e4hrt gar noch wohl sieben Jahr,", "tokens": ["Und", "w\u00e4hrt", "gar", "noch", "wohl", "sie\u00b7ben", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Kaufmann ward ihr innen;", "tokens": ["Der", "Kauf\u00b7mann", "ward", "ihr", "in\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erfahr ich dann die rechte M\u00e4hr,", "tokens": ["Er\u00b7fahr", "ich", "dann", "die", "rech\u00b7te", "M\u00e4hr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du magst mir nit entrinnen.", "tokens": ["Du", "magst", "mir", "nit", "ent\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "O Fr\u00e4ulein, mir ist Botschaft kommen,", "tokens": ["O", "Fr\u00e4u\u00b7lein", ",", "mir", "ist", "Bot\u00b7schaft", "kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPER", "VAFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich darf mich auch nit l\u00e4nger s\u00e4umen,", "tokens": ["Ich", "darf", "mich", "auch", "nit", "l\u00e4n\u00b7ger", "s\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df reiten in fremde Lande;", "tokens": ["Mu\u00df", "rei\u00b7ten", "in", "frem\u00b7de", "Lan\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nun halt dich wohl, und halt dich recht,", "tokens": ["Nun", "halt", "dich", "wohl", ",", "und", "halt", "dich", "recht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df wir nicht kommen zu Schande.", "tokens": ["Da\u00df", "wir", "nicht", "kom\u00b7men", "zu", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "APPR", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Nun halt dich wohl und halt dich recht,", "tokens": ["Nun", "halt", "dich", "wohl", "und", "halt", "dich", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gedenk an unser beider Geschlecht,", "tokens": ["Ge\u00b7denk", "an", "un\u00b7ser", "bei\u00b7der", "Ge\u00b7schlecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "PIAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Wir haben fromm Vater und Mutter,", "tokens": ["Wir", "ha\u00b7ben", "fromm", "Va\u00b7ter", "und", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Dazu ein kleines Schwesterlein,", "tokens": ["Da\u00b7zu", "ein", "klei\u00b7nes", "Schwes\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Halt mirs in guter Hute.", "tokens": ["Halt", "mirs", "in", "gu\u00b7ter", "Hu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er reit zum obern Thor hinaus,", "tokens": ["Er", "reit", "zum", "o\u00b7bern", "Thor", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "APZR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum untern reit er wieder hinein zu Haus,", "tokens": ["Zum", "un\u00b7tern", "reit", "er", "wie\u00b7der", "hin\u00b7ein", "zu", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Des Abends also spate;", "tokens": ["Des", "A\u00b7bends", "al\u00b7so", "spa\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er reit vor seiner Freunde Haus:", "tokens": ["Er", "reit", "vor", "sei\u00b7ner", "Freun\u00b7de", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gebt mir ein guten Rathe.", "tokens": ["Gebt", "mir", "ein", "gu\u00b7ten", "Ra\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ein guten Rath, den geben wir,", "tokens": ["Ein", "gu\u00b7ten", "Rath", ",", "den", "ge\u00b7ben", "wir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bleib hier, bis an den Morgen fr\u00fch,", "tokens": ["Bleib", "hier", ",", "bis", "an", "den", "Mor\u00b7gen", "fr\u00fch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KOUS", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du hast ein eigen Hause;", "tokens": ["Du", "hast", "ein", "ei\u00b7gen", "Hau\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Drinn hast du ein Badst\u00fcblein warm,", "tokens": ["Drinn", "hast", "du", "ein", "Bad\u00b7st\u00fcb\u00b7lein", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Da lebt der Doktor im Schmause.", "tokens": ["Da", "lebt", "der", "Dok\u00b7tor", "im", "Schmau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Der Kaufmann trat f\u00fcrs Schlossers Haus,", "tokens": ["Der", "Kauf\u00b7mann", "trat", "f\u00fcrs", "Schlos\u00b7sers", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und bist du drinn, so tritt heraus,", "tokens": ["Und", "bist", "du", "drinn", ",", "so", "tritt", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "$,", "ADV", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Striegel gut ich m\u00f6chte;", "tokens": ["Ein", "Strie\u00b7gel", "gut", "ich", "m\u00f6ch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PPER", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er bracht daher wohl zehen Paar,", "tokens": ["Er", "bracht", "da\u00b7her", "wohl", "ze\u00b7hen", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es war ihm keiner rechte.", "tokens": ["Es", "war", "ihm", "kei\u00b7ner", "rech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIAT", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Mach mir ein Striegel in einer Stund,", "tokens": ["Mach", "mir", "ein", "Strie\u00b7gel", "in", "ei\u00b7ner", "Stund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich geb dir drum ein baares Pfund,", "tokens": ["Ich", "geb", "dir", "drum", "ein", "baa\u00b7res", "Pfund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mach mir ihn scharf und h\u00e4rte;", "tokens": ["Mach", "mir", "ihn", "scharf", "und", "h\u00e4r\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mach Z\u00e4hn dran eines Fingers lang,", "tokens": ["Mach", "Z\u00e4hn", "dran", "ei\u00b7nes", "Fin\u00b7gers", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PAV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich hab zwei freche Pferde.", "tokens": ["Ich", "hab", "zwei", "fre\u00b7che", "Pfer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Der Schlosser dacht in seinem Muth,", "tokens": ["Der", "Schlos\u00b7ser", "dacht", "in", "sei\u00b7nem", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was meint er mit dem Striegel gut,", "tokens": ["Was", "meint", "er", "mit", "dem", "Strie\u00b7gel", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er hub ihn an zu machen;", "tokens": ["Er", "hub", "ihn", "an", "zu", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Manch B\u00fcrger vor sein Laden trat,", "tokens": ["Manch", "B\u00fcr\u00b7ger", "vor", "sein", "La\u00b7den", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und th\u00e4t des Striegels lachen.", "tokens": ["Und", "th\u00e4t", "des", "Strie\u00b7gels", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Der Kaufmann war ein weiser Mann,", "tokens": ["Der", "Kauf\u00b7mann", "war", "ein", "wei\u00b7ser", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Sachen griff er weislich an,", "tokens": ["Sein", "Sa\u00b7chen", "griff", "er", "weis\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ging ins Badst\u00fcblein warme,", "tokens": ["Ging", "ins", "Bad\u00b7st\u00fcb\u00b7lein", "war\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Sein ehlich Fr\u00e4ulein fand er da,", "tokens": ["Sein", "eh\u00b7lich", "Fr\u00e4u\u00b7lein", "fand", "er", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem Doktor in seim Arme.", "tokens": ["Dem", "Dok\u00b7tor", "in", "seim", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da er schritt in das Badst\u00fcblein,", "tokens": ["Da", "er", "schritt", "in", "das", "Bad\u00b7st\u00fcb\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "War da bereit gut Brod und Wein,", "tokens": ["War", "da", "be\u00b7reit", "gut", "Brod", "und", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit andern guten Dingen;", "tokens": ["Mit", "an\u00b7dern", "gu\u00b7ten", "Din\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die zwei, die sassen im Wasserbad,", "tokens": ["Die", "zwei", ",", "die", "sas\u00b7sen", "im", "Was\u00b7ser\u00b7bad", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "$,", "PRELS", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Das Fr\u00e4ulein th\u00e4t entrinnen.", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "th\u00e4t", "ent\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Er striegelt den Doktor also hart,", "tokens": ["Er", "strie\u00b7gelt", "den", "Dok\u00b7tor", "al\u00b7so", "hart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Von unten an bis auf den Bart,", "tokens": ["Von", "un\u00b7ten", "an", "bis", "auf", "den", "Bart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Blut th\u00e4t ihm abflie\u00dfen;", "tokens": ["Das", "Blut", "th\u00e4t", "ihm", "ab\u00b7flie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "H\u00f6r auf mein lieber Kaufmann gut,", "tokens": ["H\u00f6r", "auf", "mein", "lie\u00b7ber", "Kauf\u00b7mann", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00df mich mein S\u00fcnd hie b\u00fc\u00dfen.", "tokens": ["La\u00df", "mich", "mein", "S\u00fcnd", "hie", "b\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Es w\u00e4hrt wohl auf ein halben Tag,", "tokens": ["Es", "w\u00e4hrt", "wohl", "auf", "ein", "hal\u00b7ben", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man legt den Doktor in das Grab,", "tokens": ["Man", "legt", "den", "Dok\u00b7tor", "in", "das", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Rauchfa\u00df th\u00e4t man ihm bieten;", "tokens": ["Das", "Rauch\u00b7fa\u00df", "th\u00e4t", "man", "ihm", "bie\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein Fr\u00e4ulein zu dem andern sprach,", "tokens": ["Ein", "Fr\u00e4u\u00b7lein", "zu", "dem", "an\u00b7dern", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vor dem Striegel wolln wir uns h\u00fcten.", "tokens": ["Vor", "dem", "Strie\u00b7gel", "wolln", "wir", "uns", "h\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Die\u00df Lied ist gemacht mit hohem Flei\u00df,", "tokens": ["Die\u00df", "Lied", "ist", "ge\u00b7macht", "mit", "ho\u00b7hem", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vorm Striegel h\u00fct dich, bist du wei\u00df!", "tokens": ["Vorm", "Strie\u00b7gel", "h\u00fct", "dich", ",", "bist", "du", "wei\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df dir nicht misselinge;", "tokens": ["Da\u00df", "dir", "nicht", "mis\u00b7se\u00b7lin\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es sangs ein freier Schreiber gut,", "tokens": ["Es", "sangs", "ein", "frei\u00b7er", "Schrei\u00b7ber", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vor Freud th\u00e4t er aufspringen.", "tokens": ["Vor", "Freud", "th\u00e4t", "er", "auf\u00b7sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "VVINF", "$."], "meter": "-++-++-", "measure": "unknown.measure.tetra"}}, "stanza.15": {"line.1": {"text": "Ein Striegel f\u00fcr den Kritikus,", "tokens": ["Ein", "Strie\u00b7gel", "f\u00fcr", "den", "Kri\u00b7ti\u00b7kus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der diesem Buch giebt falschen Ku\u00df,", "tokens": ["Der", "die\u00b7sem", "Buch", "giebt", "fal\u00b7schen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PDAT", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der liegt bei meinem Zimmer;", "tokens": ["Der", "liegt", "bei", "mei\u00b7nem", "Zim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er ist gemacht mit hohem Flei\u00df,", "tokens": ["Er", "ist", "ge\u00b7macht", "mit", "ho\u00b7hem", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Vorm Striegel h\u00fct dich, bist du weis.", "tokens": ["Vorm", "Strie\u00b7gel", "h\u00fct", "dich", ",", "bist", "du", "weis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "$,", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}