{"textgrid.poem.55524": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Kunst, die Spr\u00f6den zu fangen", "genre": "verse", "period": "N.A.", "pub_year": 1790, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich seh's, du kennst sie nicht, die Liebe, dacht ich,", "tokens": ["Ich", "seh's", ",", "du", "kennst", "sie", "nicht", ",", "die", "Lie\u00b7be", ",", "dacht", "ich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NE", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "ART", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn wer sie kennt, der flieht sie nicht.", "tokens": ["Denn", "wer", "sie", "kennt", ",", "der", "flieht", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie leicht wird's sein, dich zu entz\u00fcnden,", "tokens": ["Wie", "leicht", "wird's", "sein", ",", "dich", "zu", "ent\u00b7z\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "VAINF", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da du so unerfahren bist?", "tokens": ["Da", "du", "so", "un\u00b7er\u00b7fah\u00b7ren", "bist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Liebe sollst du bald empfinden,", "tokens": ["Die", "Lie\u00b7be", "sollst", "du", "bald", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und sollst nicht wissen, da\u00df sie's ist.", "tokens": ["Und", "sollst", "nicht", "wis\u00b7sen", ",", "da\u00df", "sie's", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "VVINF", "$,", "KOUS", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Dem M\u00e4dchen ward nebst andern Gaben", "tokens": ["Dem", "M\u00e4d\u00b7chen", "ward", "nebst", "an\u00b7dern", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Viel feuriges Gef\u00fchl geschenkt,", "tokens": ["Viel", "feu\u00b7ri\u00b7ges", "Ge\u00b7f\u00fchl", "ge\u00b7schenkt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da meint's, es denke gleich erhaben,", "tokens": ["Da", "meint's", ",", "es", "den\u00b7ke", "gleich", "er\u00b7ha\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da es doch nichts als feurig denkt.", "tokens": ["Da", "es", "doch", "nichts", "als", "feu\u00b7rig", "denkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "KOKOM", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was bei des J\u00fcnglings Blicken", "tokens": ["Was", "bei", "des", "J\u00fcng\u00b7lings", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein jedes M\u00e4dchen f\u00fchlt,", "tokens": ["Ein", "je\u00b7des", "M\u00e4d\u00b7chen", "f\u00fchlt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "War das, was mit Entz\u00fccken", "tokens": ["War", "das", ",", "was", "mit", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDS", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie nur f\u00fcr Freundschaft hielt.", "tokens": ["Sie", "nur", "f\u00fcr", "Freund\u00b7schaft", "hielt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Einst sa\u00df sie, meinen Lehren", "tokens": ["Einst", "sa\u00df", "sie", ",", "mei\u00b7nen", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aufmerksam zuzuh\u00f6ren;", "tokens": ["Auf\u00b7merk\u00b7sam", "zu\u00b7zu\u00b7h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da sprach ich: \u00bbDu mu\u00dft wissen,", "tokens": ["Da", "sprach", "ich", ":", "\u00bb", "Du", "mu\u00dft", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df auch die Freunde k\u00fcssen,", "tokens": ["Da\u00df", "auch", "die", "Freun\u00b7de", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Freunde so wie ich und du \u2013\u00ab", "tokens": ["Die", "Freun\u00b7de", "so", "wie", "ich", "und", "du", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ADV", "KOKOM", "PPER", "KON", "PPER", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich wagt es \u2013 und sie lie\u00df es zu.", "tokens": ["Ich", "wagt", "es", "\u2013", "und", "sie", "lie\u00df", "es", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "KON", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Da ich den ersten so leicht erhalten hatte, konnte ich noch eher auf den zweeten hoffen.", "tokens": ["Da", "ich", "den", "ers\u00b7ten", "so", "leicht", "er\u00b7hal\u00b7ten", "hat\u00b7te", ",", "konn\u00b7te", "ich", "noch", "e\u00b7her", "auf", "den", "zwee\u00b7ten", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "ADV", "ADJD", "VVPP", "VAFIN", "$,", "VMFIN", "PPER", "ADV", "ADV", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+--+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}}, "stanza.6": {"line.1": {"text": "Nie schmeckt ein M\u00e4dchen einen Ku\u00df,", "tokens": ["Nie", "schmeckt", "ein", "M\u00e4d\u00b7chen", "ei\u00b7nen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sich nicht nach dem zweeten sehnte.", "tokens": ["Die", "sich", "nicht", "nach", "dem", "zwee\u00b7ten", "sehn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKNEG", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Oft wiederholt ich meinen Ku\u00df,", "tokens": ["Oft", "wie\u00b7der\u00b7holt", "ich", "mei\u00b7nen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df sie sich bald daran gew\u00f6hnte.", "tokens": ["Da\u00df", "sie", "sich", "bald", "da\u00b7ran", "ge\u00b7w\u00f6hn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn ich sie sah und sie nicht k\u00fc\u00dfte,", "tokens": ["Wenn", "ich", "sie", "sah", "und", "sie", "nicht", "k\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "KON", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sprach gleich ihr Blick, da\u00df sie etwas vermi\u00dfte.", "tokens": ["Sprach", "gleich", "ihr", "Blick", ",", "da\u00df", "sie", "et\u00b7was", "ver\u00b7mi\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Der gl\u00fcckliche Fortgang meiner Eroberungen machte mich stolz, und wer stolz ist, ist k\u00fchn.", "tokens": ["Der", "gl\u00fcck\u00b7li\u00b7che", "Fort\u00b7gang", "mei\u00b7ner", "Er\u00b7o\u00b7be\u00b7run\u00b7gen", "mach\u00b7te", "mich", "stolz", ",", "und", "wer", "stolz", "ist", ",", "ist", "k\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,", "KON", "PWS", "ADJD", "VAFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+--+-+-+--+-+--+-+++-+", "measure": "iambic.octa.plus.relaxed"}}, "stanza.8": {"line.1": {"text": "So schwer ist's nicht, wie ich geglaubt,", "tokens": ["So", "schwer", "ist's", "nicht", ",", "wie", "ich", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem M\u00e4dchen eine Gunst zu rauben;", "tokens": ["Dem", "M\u00e4d\u00b7chen", "ei\u00b7ne", "Gunst", "zu", "rau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hat sie uns nur erst eins erlaubt,", "tokens": ["Hat", "sie", "uns", "nur", "erst", "eins", "er\u00b7laubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das andre wird sie schon erlauben.", "tokens": ["Das", "and\u00b7re", "wird", "sie", "schon", "er\u00b7lau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Da wagt's mein Arm, sie zu umschlie\u00dfen.", "tokens": ["Da", "wagt's", "mein", "Arm", ",", "sie", "zu", "um\u00b7schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie lie\u00df es zu.", "tokens": ["Sie", "lie\u00df", "es", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Da wagt's mein Mund, die wei\u00dfe Brust zu k\u00fcssen.", "tokens": ["Da", "wagt's", "mein", "Mund", ",", "die", "wei\u00b7\u00dfe", "Brust", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie lie\u00df es zu.", "tokens": ["Sie", "lie\u00df", "es", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Doch eilends sprang sie auf. \u00bbDich werd ich fliehen m\u00fcssen,", "tokens": ["Doch", "ei\u00b7lends", "sprang", "sie", "auf", ".", "\u00bb", "Dich", "werd", "ich", "flie\u00b7hen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "PPER", "VAFIN", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gef\u00e4hrlicher!\u00ab rief sie und lie\u00df nichts weiter zu", "tokens": ["Ge\u00b7f\u00e4hr\u00b7li\u00b7cher", "!", "\u00ab", "rief", "sie", "und", "lie\u00df", "nichts", "wei\u00b7ter", "zu"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "$(", "VVFIN", "PPER", "KON", "VVFIN", "PIS", "ADV", "APPR"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Und floh. Soweit gelang mir mein Bem\u00fchen.", "tokens": ["Und", "floh", ".", "So\u00b7weit", "ge\u00b7lang", "mir", "mein", "Be\u00b7m\u00fc\u00b7hen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ich folg ihr langsam, da sie flieht;", "tokens": ["Ich", "folg", "ihr", "lang\u00b7sam", ",", "da", "sie", "flieht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Denn eher wird sie bei dem Fliehen", "tokens": ["Denn", "e\u00b7her", "wird", "sie", "bei", "dem", "Flie\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Als ich bei dem Verfolgen m\u00fcd.", "tokens": ["Als", "ich", "bei", "dem", "Ver\u00b7fol\u00b7gen", "m\u00fcd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}}}}