{"textgrid.poem.54338": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: So bald sich nur der Himmel th\u00fcrmt;", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So bald sich nur der Himmel th\u00fcrmt;", "tokens": ["So", "bald", "sich", "nur", "der", "Him\u00b7mel", "th\u00fcrmt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Wind aus Ost und Westen st\u00fcrmt,", "tokens": ["Der", "Wind", "aus", "Ost", "und", "Wes\u00b7ten", "st\u00fcrmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So f\u00fchlt die bange Brust ein ganz geheimes Schrecken.", "tokens": ["So", "f\u00fchlt", "die", "ban\u00b7ge", "Brust", "ein", "ganz", "ge\u00b7hei\u00b7mes", "Schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der sonst so aufgekl\u00e4rte Sinn", "tokens": ["Der", "sonst", "so", "auf\u00b7ge\u00b7kl\u00e4r\u00b7te", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Entf\u00e4llt, und weis selbst nicht wohin,", "tokens": ["Ent\u00b7f\u00e4llt", ",", "und", "weis", "selbst", "nicht", "wo\u00b7hin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "PTKVZ", "ADV", "PTKNEG", "PWAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sucht sich in der Zeit mit Sicherheit zu decken.", "tokens": ["Und", "sucht", "sich", "in", "der", "Zeit", "mit", "Si\u00b7cher\u00b7heit", "zu", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Er h\u00f6rt wie stark der Donner knallt", "tokens": ["Er", "h\u00f6rt", "wie", "stark", "der", "Don\u00b7ner", "knallt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "ADJD", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und durch die finstern Wolken schallt,", "tokens": ["Und", "durch", "die", "fins\u00b7tern", "Wol\u00b7ken", "schallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie heftig Blitz und Strahl in tiefsten Abgrund schiessen.", "tokens": ["Wie", "hef\u00b7tig", "Blitz", "und", "Strahl", "in", "tiefs\u00b7ten", "Ab\u00b7grund", "schies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df jede Creatur vermeynt,", "tokens": ["Da\u00df", "je\u00b7de", "Crea\u00b7tur", "ver\u00b7meynt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da\u00df heut ihr letzter Tag erscheint,", "tokens": ["Da\u00df", "heut", "ihr", "letz\u00b7ter", "Tag", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An dem sie soll die Schuld begangner Fehler b\u00fcssen.", "tokens": ["An", "dem", "sie", "soll", "die", "Schuld", "be\u00b7gang\u00b7ner", "Feh\u00b7ler", "b\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VMFIN", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Das Erdreich zittert, und dem Land", "tokens": ["Das", "Er\u00b7dreich", "zit\u00b7tert", ",", "und", "dem", "Land"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bleibt noch sein Schicksal unbekannt;", "tokens": ["Bleibt", "noch", "sein", "Schick\u00b7sal", "un\u00b7be\u00b7kannt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bi\u00df da\u00df sie nach der Fluth, die Fruchtbarkeit empfinden.", "tokens": ["Bi\u00df", "da\u00df", "sie", "nach", "der", "Fluth", ",", "die", "Frucht\u00b7bar\u00b7keit", "emp\u00b7fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn bey stets heiterm Sonnenschein", "tokens": ["Denn", "bey", "stets", "hei\u00b7term", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kann keine reiche Erndte seyn;", "tokens": ["Kann", "kei\u00b7ne", "rei\u00b7che", "Ernd\u00b7te", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum mu\u00df der Regen auch sich oft mit ihm verbinden.", "tokens": ["Drum", "mu\u00df", "der", "Re\u00b7gen", "auch", "sich", "oft", "mit", "ihm", "ver\u00b7bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "ART", "NN", "ADV", "PRF", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ist endlich nun der Sturm vorbey,", "tokens": ["Ist", "end\u00b7lich", "nun", "der", "Sturm", "vor\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird alles lustig, munter, frey,", "tokens": ["Wird", "al\u00b7les", "lus\u00b7tig", ",", "mun\u00b7ter", ",", "frey", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und jedermann vergn\u00fcgt, als w\u00e4r er neu gebohren.", "tokens": ["Und", "je\u00b7der\u00b7mann", "ver\u00b7gn\u00fcgt", ",", "als", "w\u00e4r", "er", "neu", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVPP", "$,", "KOKOM", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da lebt das Herz, da lacht der Mund,", "tokens": ["Da", "lebt", "das", "Herz", ",", "da", "lacht", "der", "Mund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da thun die frohen Blicke kund,", "tokens": ["Da", "thun", "die", "fro\u00b7hen", "Bli\u00b7cke", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df man die Lust erst schmeckt wenn sich der Schmerz verlohren.", "tokens": ["Da\u00df", "man", "die", "Lust", "erst", "schmeckt", "wenn", "sich", "der", "Schmerz", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "VVFIN", "KOUS", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ein Uebel baut oft unser Wohl,", "tokens": ["Ein", "Ue\u00b7bel", "baut", "oft", "un\u00b7ser", "Wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur der, der sich drein schicken soll,", "tokens": ["Nur", "der", ",", "der", "sich", "drein", "schi\u00b7cken", "soll", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PRF", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kann diesen Grund so leicht, so sicher nicht ergr\u00fcnden.", "tokens": ["Kann", "die\u00b7sen", "Grund", "so", "leicht", ",", "so", "si\u00b7cher", "nicht", "er\u00b7gr\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PDAT", "NN", "ADV", "ADJD", "$,", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Ausgang zeigt dem Kl\u00fcgsten an,", "tokens": ["Der", "Aus\u00b7gang", "zeigt", "dem", "Kl\u00fcgs\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df da sein Gl\u00fcck nicht steigen kann,", "tokens": ["Da\u00df", "da", "sein", "Gl\u00fcck", "nicht", "stei\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo nicht die Eris auch kann ihren Antheil finden.", "tokens": ["Wo", "nicht", "die", "E\u00b7ris", "auch", "kann", "ih\u00b7ren", "An\u00b7theil", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ART", "NE", "ADV", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der Ha\u00df, die Schm\u00e4hsucht, und der Neid", "tokens": ["Der", "Ha\u00df", ",", "die", "Schm\u00e4h\u00b7sucht", ",", "und", "der", "Neid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erschrecken uns zu mancher Zeit;", "tokens": ["Er\u00b7schre\u00b7cken", "uns", "zu", "man\u00b7cher", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wie des Donners Knall, die Flamme schneller Blitze.", "tokens": ["So", "wie", "des", "Don\u00b7ners", "Knall", ",", "die", "Flam\u00b7me", "schnel\u00b7ler", "Blit\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn uns ein Grosser wiederspricht,", "tokens": ["Wenn", "uns", "ein", "Gros\u00b7ser", "wie\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So \u00e4ndert man auch das Gesicht", "tokens": ["So", "\u00e4n\u00b7dert", "man", "auch", "das", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Man scheut, und f\u00fcrchtet ihn bey allem seinen Witze.", "tokens": ["Man", "scheut", ",", "und", "f\u00fcrch\u00b7tet", "ihn", "bey", "al\u00b7lem", "sei\u00b7nen", "Wit\u00b7ze", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KON", "VVFIN", "PPER", "APPR", "PIS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wenn man die Rachsucht drohen h\u00f6rt,", "tokens": ["Wenn", "man", "die", "Rach\u00b7sucht", "dro\u00b7hen", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die uns in unsrer Wohlfahrt st\u00f6rt,", "tokens": ["Die", "uns", "in", "uns\u00b7rer", "Wohl\u00b7fahrt", "st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So kann man sich nicht leicht bey der Verfolgung fassen.", "tokens": ["So", "kann", "man", "sich", "nicht", "leicht", "bey", "der", "Ver\u00b7fol\u00b7gung", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PRF", "PTKNEG", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wenn sich ein kleiner Mann vergeht,", "tokens": ["Wenn", "sich", "ein", "klei\u00b7ner", "Mann", "ver\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So weis man da\u00df er nicht versteht,", "tokens": ["So", "weis", "man", "da\u00df", "er", "nicht", "ver\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PIS", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Warum er diesen liebt und jenen sucht zu hassen.", "tokens": ["Wa\u00b7rum", "er", "die\u00b7sen", "liebt", "und", "je\u00b7nen", "sucht", "zu", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "VVFIN", "KON", "PDS", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Der kleine Name macht sich gro\u00df;", "tokens": ["Der", "klei\u00b7ne", "Na\u00b7me", "macht", "sich", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sitzet er dem Gl\u00fcck im Schoo\u00df,", "tokens": ["Und", "sit\u00b7zet", "er", "dem", "Gl\u00fcck", "im", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit seiner L\u00e4sterkunst der Weisheit trotz zu bieten:", "tokens": ["Mit", "sei\u00b7ner", "L\u00e4s\u00b7ter\u00b7kunst", "der", "Weis\u00b7heit", "trotz", "zu", "bie\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verg\u00f6nnt sein Vorurtheil ihm nicht,", "tokens": ["Ver\u00b7g\u00f6nnt", "sein", "Vor\u00b7urt\u00b7heil", "ihm", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er was gutes von uns spricht,", "tokens": ["Da\u00df", "er", "was", "gu\u00b7tes", "von", "uns", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "ADJA", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er kann nichts anders thun, er mu\u00df best\u00e4ndig w\u00fcten.", "tokens": ["Er", "kann", "nichts", "an\u00b7ders", "thun", ",", "er", "mu\u00df", "be\u00b7st\u00e4n\u00b7dig", "w\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "VVINF", "$,", "PPER", "VMFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der Neid bem\u00fcht sich auch zugleich,", "tokens": ["Der", "Neid", "be\u00b7m\u00fcht", "sich", "auch", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ist stets an Erfindung reich", "tokens": ["Und", "ist", "stets", "an", "Er\u00b7fin\u00b7dung", "reich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "APPR", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da gilt kein wehren nicht, kein heftig wiederstreben,", "tokens": ["Da", "gilt", "kein", "weh\u00b7ren", "nicht", ",", "kein", "hef\u00b7tig", "wie\u00b7der\u00b7stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "PTKNEG", "$,", "PIAT", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da wagt sich oft der schlechtste Mann,", "tokens": ["Da", "wagt", "sich", "oft", "der", "schlechts\u00b7te", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der kaum recht decliniren kann;", "tokens": ["Der", "kaum", "recht", "de\u00b7cli\u00b7ni\u00b7ren", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Er will aus Amt und Pflicht sein W\u00f6rtchen auch drein geben.", "tokens": ["Er", "will", "aus", "Amt", "und", "Pflicht", "sein", "W\u00f6rt\u00b7chen", "auch", "drein", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN", "PPOSAT", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Was soll nun da ein Weiser thun?", "tokens": ["Was", "soll", "nun", "da", "ein", "Wei\u00b7ser", "thun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er mu\u00df nur in sich selbst beruhn,", "tokens": ["Er", "mu\u00df", "nur", "in", "sich", "selbst", "be\u00b7ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mu\u00df der Thorheit Wahn, die L\u00e4sterung belachen.", "tokens": ["Und", "mu\u00df", "der", "Thor\u00b7heit", "Wahn", ",", "die", "L\u00e4s\u00b7te\u00b7rung", "be\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er geht fort auf der Klugen Pfad;", "tokens": ["Er", "geht", "fort", "auf", "der", "Klu\u00b7gen", "Pfad", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zuletzt, so zeiget doch die That;", "tokens": ["Zu\u00b7letzt", ",", "so", "zei\u00b7get", "doch", "die", "That", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Neider k\u00f6nnen nur ein blindes Lermen machen.", "tokens": ["Die", "Nei\u00b7der", "k\u00f6n\u00b7nen", "nur", "ein", "blin\u00b7des", "Ler\u00b7men", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Es w\u00fcrde mancher nicht bekannt,", "tokens": ["Es", "w\u00fcr\u00b7de", "man\u00b7cher", "nicht", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den reine Tugend und Verstand,", "tokens": ["Den", "rei\u00b7ne", "Tu\u00b7gend", "und", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verdienst und Redlichkeit im h\u00f6chsten Grade schm\u00fccken.", "tokens": ["Ver\u00b7dienst", "und", "Red\u00b7lich\u00b7keit", "im", "h\u00f6chs\u00b7ten", "Gra\u00b7de", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn nicht des Sp\u00f6tters heisse Wuth", "tokens": ["Wenn", "nicht", "des", "Sp\u00f6t\u00b7ters", "heis\u00b7se", "Wuth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihn oftmahls kr\u00e4nkte bis aufs Blut,", "tokens": ["Ihn", "oft\u00b7mahls", "kr\u00e4nk\u00b7te", "bis", "aufs", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und suchte \u00f6ffentlich die Fehler vorzur\u00fccken.", "tokens": ["Und", "such\u00b7te", "\u00f6f\u00b7fent\u00b7lich", "die", "Feh\u00b7ler", "vor\u00b7zu\u00b7r\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Und also trifft es richtig ein:", "tokens": ["Und", "al\u00b7so", "trifft", "es", "rich\u00b7tig", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Uebel mu\u00df die Quelle seyn", "tokens": ["Das", "Ue\u00b7bel", "mu\u00df", "die", "Quel\u00b7le", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Daraus oft unser Wohl, und unsre Ruh entstehet.", "tokens": ["Da\u00b7raus", "oft", "un\u00b7ser", "Wohl", ",", "und", "uns\u00b7re", "Ruh", "ent\u00b7ste\u00b7het", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PPOSAT", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein grosser Geist belacht den Grimm,", "tokens": ["Ein", "gros\u00b7ser", "Geist", "be\u00b7lacht", "den", "Grimm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und weis da\u00df bey dem Ungest\u00fcm", "tokens": ["Und", "weis", "da\u00df", "bey", "dem", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Name, Ruf und Ruhm, so leicht nicht untergehet.", "tokens": ["Sein", "Na\u00b7me", ",", "Ruf", "und", "Ruhm", ",", "so", "leicht", "nicht", "un\u00b7ter\u00b7ge\u00b7het", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,", "ADV", "ADJD", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Die Bosheit kriegt zuletzt zum Lohn", "tokens": ["Die", "Bos\u00b7heit", "kriegt", "zu\u00b7letzt", "zum", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verachtung, Schmach, des P\u00f6bels Hohn,", "tokens": ["Ver\u00b7ach\u00b7tung", ",", "Schmach", ",", "des", "P\u00f6\u00b7bels", "Hohn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem sie sich bem\u00fcht, den kl\u00fcgsten Mann zu f\u00e4llen.", "tokens": ["In\u00b7dem", "sie", "sich", "be\u00b7m\u00fcht", ",", "den", "kl\u00fcgs\u00b7ten", "Mann", "zu", "f\u00e4l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVPP", "$,", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Hof und auch dem ganzen Land", "tokens": ["Dem", "Hof", "und", "auch", "dem", "gan\u00b7zen", "Land"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wird dann so mancher Streich bekannt", "tokens": ["Wird", "dann", "so", "man\u00b7cher", "Streich", "be\u00b7kannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der sich nicht weiter l\u00e4\u00dft durch Glei\u00dfnerey verstellen.", "tokens": ["Der", "sich", "nicht", "wei\u00b7ter", "l\u00e4\u00dft", "durch", "Glei\u00df\u00b7ne\u00b7rey", "ver\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "PTKNEG", "ADV", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Was macht alsdann ein solcher Tropf?", "tokens": ["Was", "macht", "als\u00b7dann", "ein", "sol\u00b7cher", "Tropf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er hengt das Maul, er st\u00fctzt den Kopf,", "tokens": ["Er", "hengt", "das", "Maul", ",", "er", "st\u00fctzt", "den", "Kopf", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mu\u00df sich ingeheim vor seiner Thorheit sch\u00e4men.", "tokens": ["Und", "mu\u00df", "sich", "in\u00b7ge\u00b7heim", "vor", "sei\u00b7ner", "Thor\u00b7heit", "sch\u00e4\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihm wiederspricht die kluge Welt", "tokens": ["Ihm", "wie\u00b7der\u00b7spricht", "die", "klu\u00b7ge", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die nichts auf seinen Vortrag h\u00e4lt.", "tokens": ["Die", "nichts", "auf", "sei\u00b7nen", "Vor\u00b7trag", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zuletzt mu\u00df er sich doch zum Schweigen noch bequemen.", "tokens": ["Zu\u00b7letzt", "mu\u00df", "er", "sich", "doch", "zum", "Schwei\u00b7gen", "noch", "be\u00b7que\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}