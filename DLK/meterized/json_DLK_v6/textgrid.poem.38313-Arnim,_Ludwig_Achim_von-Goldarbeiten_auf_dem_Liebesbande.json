{"textgrid.poem.38313": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Goldarbeiten auf dem Liebesbande", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wollt um meines Herren Haupt,", "tokens": ["Ich", "wollt", "um", "mei\u00b7nes", "Her\u00b7ren", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ganz von Dornen war umschraubt,", "tokens": ["Das", "ganz", "von", "Dor\u00b7nen", "war", "um\u00b7schraubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Kronenband von Golde binden;", "tokens": ["Ein", "Kro\u00b7nen\u00b7band", "von", "Gol\u00b7de", "bin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das sollte meine Liebe seyn,", "tokens": ["Das", "soll\u00b7te", "mei\u00b7ne", "Lie\u00b7be", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da braucht ich nun ein Schmelzwerk drein,", "tokens": ["Da", "braucht", "ich", "nun", "ein", "Schmel\u00b7zwerk", "drein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das wu\u00dft ich nirgends aufzufinden;", "tokens": ["Das", "wu\u00dft", "ich", "nir\u00b7gends", "auf\u00b7zu\u00b7fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch traf mein Geist auf guter Bahn", "tokens": ["Doch", "traf", "mein", "Geist", "auf", "gu\u00b7ter", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Noch endlich einen Goldschmied an.", "tokens": ["Noch", "end\u00b7lich", "ei\u00b7nen", "Gold\u00b7schmied", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der legte mir zu dieser Zier", "tokens": ["Der", "leg\u00b7te", "mir", "zu", "die\u00b7ser", "Zier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Muster eine Menge f\u00fcr;", "tokens": ["Der", "Mus\u00b7ter", "ei\u00b7ne", "Men\u00b7ge", "f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich w\u00e4hlt und wei\u00df es noch zu nennen,", "tokens": ["Ich", "w\u00e4hlt", "und", "wei\u00df", "es", "noch", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Haupt, darauf man Balsam go\u00df,", "tokens": ["Ein", "Haupt", ",", "da\u00b7rauf", "man", "Bal\u00b7sam", "go\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "PIS", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der auch davon herunter flo\u00df,", "tokens": ["Der", "auch", "da\u00b7von", "her\u00b7un\u00b7ter", "flo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PAV", "APZR", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch, da\u00df der Leib nicht wohl zu kennen;", "tokens": ["Doch", ",", "da\u00df", "der", "Leib", "nicht", "wohl", "zu", "ken\u00b7nen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dabei war dies die Nebenschrift:", "tokens": ["Da\u00b7bei", "war", "dies", "die", "Ne\u00b7ben\u00b7schrift", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl dem, den dieser Balsam trift.", "tokens": ["Wohl", "dem", ",", "den", "die\u00b7ser", "Bal\u00b7sam", "trift", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Zum andern ward mir vorgelegt", "tokens": ["Zum", "an\u00b7dern", "ward", "mir", "vor\u00b7ge\u00b7legt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Oehlbaum, den man abges\u00e4gt,", "tokens": ["Ein", "O\u00b7ehl\u00b7baum", ",", "den", "man", "ab\u00b7ge\u00b7s\u00e4gt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und frisch mit Reisern \u00fcbersetzet;", "tokens": ["Und", "frisch", "mit", "Rei\u00b7sern", "\u00fc\u00b7bers\u00b7et\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dabei ein alter G\u00e4rtner stund,", "tokens": ["Da\u00b7bei", "ein", "al\u00b7ter", "G\u00e4rt\u00b7ner", "stund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von dem der ungehackte Grund", "tokens": ["Von", "dem", "der", "un\u00b7ge\u00b7hack\u00b7te", "Grund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Wasser ward umher benetzet;", "tokens": ["Mit", "Was\u00b7ser", "ward", "um\u00b7her", "be\u00b7net\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und schiens, als sagte dieser Greis:", "tokens": ["Und", "schiens", ",", "als", "sag\u00b7te", "die\u00b7ser", "Greis", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl dem, der hier steht, wie ein Reis.", "tokens": ["Wohl", "dem", ",", "der", "hier", "steht", ",", "wie", "ein", "Reis", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ADV", "VVFIN", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.4": {"line.1": {"text": "Drauf legt er einen Weinstock dar,", "tokens": ["Drauf", "legt", "er", "ei\u00b7nen", "Wein\u00b7stock", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der voller gr\u00fcner Reben war,", "tokens": ["Der", "vol\u00b7ler", "gr\u00fc\u00b7ner", "Re\u00b7ben", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die theils mit Trauben angef\u00fcllet,", "tokens": ["Die", "theils", "mit", "Trau\u00b7ben", "an\u00b7ge\u00b7f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Theils aber stunden nur zum Schein,", "tokens": ["Theils", "a\u00b7ber", "stun\u00b7den", "nur", "zum", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und schnitt der G\u00e4rtner frisch darein,", "tokens": ["Und", "schnitt", "der", "G\u00e4rt\u00b7ner", "frisch", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo solches Laub den Stock verh\u00fcllet;", "tokens": ["Wo", "sol\u00b7ches", "Laub", "den", "Stock", "ver\u00b7h\u00fcl\u00b7let", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Wort schien dies zu jeder Frist:", "tokens": ["Sein", "Wort", "schien", "dies", "zu", "je\u00b7der", "Frist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PDS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weg, was kein fruchtbar Reben ist.", "tokens": ["Weg", ",", "was", "kein", "frucht\u00b7bar", "Re\u00b7ben", "ist", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIAT", "ADJD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Das vierte war ein weisses Kleid,", "tokens": ["Das", "vier\u00b7te", "war", "ein", "weis\u00b7ses", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Sinnbild der Gerechtigkeit,", "tokens": ["Ein", "Sinn\u00b7bild", "der", "Ge\u00b7rech\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Christi Werken ausgesticket;", "tokens": ["Mit", "Chris\u00b7ti", "Wer\u00b7ken", "aus\u00b7ge\u00b7sti\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das gab ein Vater anzuziehn,", "tokens": ["Das", "gab", "ein", "Va\u00b7ter", "an\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Sohn warf seinen Kittel hin,", "tokens": ["Der", "Sohn", "warf", "sei\u00b7nen", "Kit\u00b7tel", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der ganz mit Flicken zugest\u00fccket;", "tokens": ["Der", "ganz", "mit", "Fli\u00b7cken", "zu\u00b7ge\u00b7st\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und wie es schien, fing dieser an:", "tokens": ["Und", "wie", "es", "schien", ",", "fing", "die\u00b7ser", "an", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "VVFIN", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl, wenn ich mich so kleiden kann.", "tokens": ["Wohl", ",", "wenn", "ich", "mich", "so", "klei\u00b7den", "kann", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Drauf kam mir vor ein Waizenfeld,", "tokens": ["Drauf", "kam", "mir", "vor", "ein", "Wai\u00b7zen\u00b7feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das gro\u00dfe Bild der Christenwelt,", "tokens": ["Das", "gro\u00b7\u00dfe", "Bild", "der", "Chris\u00b7ten\u00b7welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Unkraut hin und her besprenget;", "tokens": ["Mit", "Un\u00b7kraut", "hin", "und", "her", "be\u00b7spren\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da stand ein hurtger Ackermann,", "tokens": ["Da", "stand", "ein", "hurt\u00b7ger", "A\u00b7cker\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und schlug mit seiner Sichel an,", "tokens": ["Und", "schlug", "mit", "sei\u00b7ner", "Si\u00b7chel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wiewohl der Acker so gemenget;", "tokens": ["Wie\u00b7wohl", "der", "A\u00b7cker", "so", "ge\u00b7men\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Doch schiens, als spr\u00e4ch er dies darein:", "tokens": ["Doch", "schiens", ",", "als", "spr\u00e4ch", "er", "dies", "da\u00b7rein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "VVFIN", "PPER", "PDS", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl dem, der hier kann Waizen s\u00e4'n.", "tokens": ["Wohl", "dem", ",", "der", "hier", "kann", "Wai\u00b7zen", "s\u00e4'", "n."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "ART", "$,", "PRELS", "ADV", "VMFIN", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und was zum sechsten vor uns kam,", "tokens": ["Und", "was", "zum", "sechs\u00b7ten", "vor", "uns", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPRART", "ADJA", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das war ein edler Br\u00e4utigam,", "tokens": ["Das", "war", "ein", "ed\u00b7ler", "Br\u00e4u\u00b7ti\u00b7gam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Hochzeitkleidern ausgeschm\u00fccket;", "tokens": ["Mit", "Hoch\u00b7zeit\u00b7klei\u00b7dern", "aus\u00b7ge\u00b7schm\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der bot der Braut die Liebeshand,", "tokens": ["Der", "bot", "der", "Braut", "die", "Lie\u00b7bes\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die war in reiner Lieb entbrannt,", "tokens": ["Die", "war", "in", "rei\u00b7ner", "Lieb", "ent\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und schaut auf ihn, wie halb entz\u00fccket;", "tokens": ["Und", "schaut", "auf", "ihn", ",", "wie", "halb", "ent\u00b7z\u00fc\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$,", "PWAV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vom Himmel gab es diesen Laut:", "tokens": ["Vom", "Him\u00b7mel", "gab", "es", "die\u00b7sen", "Laut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PDAT", "APPR", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wie selig ist des H\u00f6chsten Braut.", "tokens": ["Wie", "se\u00b7lig", "ist", "des", "H\u00f6chs\u00b7ten", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Darauf kam mir ein Sch\u00e4fer f\u00fcr,", "tokens": ["Da\u00b7rauf", "kam", "mir", "ein", "Sch\u00e4\u00b7fer", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zwar schlecht von Kleid und sonder Zier,", "tokens": ["Zwar", "schlecht", "von", "Kleid", "und", "son\u00b7der", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch lag ein Schaf auf seinem R\u00fccken;", "tokens": ["Doch", "lag", "ein", "Schaf", "auf", "sei\u00b7nem", "R\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das schien, als h\u00e4tt ers aus der Nacht", "tokens": ["Das", "schien", ",", "als", "h\u00e4tt", "ers", "aus", "der", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOKOM", "VAFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Und aus der Irr auch heimgebracht,", "tokens": ["Und", "aus", "der", "Irr", "auch", "heim\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wollt es bei der Heerd erquicken;", "tokens": ["Und", "wollt", "es", "bei", "der", "Heerd", "er\u00b7qui\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dabei dies Wort gelesen ward:", "tokens": ["Da\u00b7bei", "dies", "Wort", "ge\u00b7le\u00b7sen", "ward", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PDS", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl, wenn man hat des Sch\u00e4fleins Art.", "tokens": ["Wohl", ",", "wenn", "man", "hat", "des", "Sch\u00e4f\u00b7leins", "Art", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Zum achten zog in einem Kahn", "tokens": ["Zum", "ach\u00b7ten", "zog", "in", "ei\u00b7nem", "Kahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Schiffer seinen Zug heran,", "tokens": ["Ein", "Schif\u00b7fer", "sei\u00b7nen", "Zug", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als wollt er nun das Netz ausleeren;", "tokens": ["Als", "wollt", "er", "nun", "das", "Netz", "aus\u00b7lee\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da sah man Fisch und Koth und Stein", "tokens": ["Da", "sah", "man", "Fisch", "und", "Koth", "und", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "In einem Garn ergriffen seyn,", "tokens": ["In", "ei\u00b7nem", "Garn", "er\u00b7grif\u00b7fen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das fing er gleich an umzukehren;", "tokens": ["Das", "fing", "er", "gleich", "an", "um\u00b7zu\u00b7keh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und mischte diesen Spruch darein:", "tokens": ["Und", "mischte", "die\u00b7sen", "Spruch", "da\u00b7rein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "NN", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Wohl dem, der wie ein Fisch kann seyn.", "tokens": ["Wohl", "dem", ",", "der", "wie", "ein", "Fisch", "kann", "seyn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "KOKOM", "ART", "NN", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Drauf sah ich, wie Metall da flo\u00df,", "tokens": ["Drauf", "sah", "ich", ",", "wie", "Me\u00b7tall", "da", "flo\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "PWAV", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das einer in die Forme go\u00df,", "tokens": ["Das", "ei\u00b7ner", "in", "die", "For\u00b7me", "go\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Crucifix daraus zu giessen,", "tokens": ["Ein", "Cru\u00b7ci\u00b7fix", "da\u00b7raus", "zu", "gies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das im Modell darneben stund;", "tokens": ["Das", "im", "Mo\u00b7dell", "dar\u00b7ne\u00b7ben", "stund", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPRART", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie da der Herr f\u00fcr unsern Bund", "tokens": ["Wie", "da", "der", "Herr", "f\u00fcr", "un\u00b7sern", "Bund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sein Blut lie\u00df, wie die Str\u00f6me fliessen;", "tokens": ["Sein", "Blut", "lie\u00df", ",", "wie", "die", "Str\u00f6\u00b7me", "flies\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PWAV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dar\u00fcber stand dies Wort erh\u00f6ht:", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "stand", "dies", "Wort", "er\u00b7h\u00f6ht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PDS", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl, wer in dieser Forme steht.", "tokens": ["Wohl", ",", "wer", "in", "die\u00b7ser", "For\u00b7me", "steht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Zum zehnten war da ein Spital,", "tokens": ["Zum", "zehn\u00b7ten", "war", "da", "ein", "Spi\u00b7tal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Kranken drinnen ohne Zahl,", "tokens": ["Und", "Kran\u00b7ken", "drin\u00b7nen", "oh\u00b7ne", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wollt ein Arzt zu ihnen treten,", "tokens": ["Und", "wollt", "ein", "Arzt", "zu", "ih\u00b7nen", "tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Den liessen viel von ferne stehn,", "tokens": ["Den", "lies\u00b7sen", "viel", "von", "fer\u00b7ne", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zu einem schien er hinzugehn,", "tokens": ["Zu", "ei\u00b7nem", "schien", "er", "hin\u00b7zu\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der ihn zuvor mit Ernst gebeten;", "tokens": ["Der", "ihn", "zu\u00b7vor", "mit", "Ernst", "ge\u00b7be\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Dabei ward dies mit angef\u00fchrt:", "tokens": ["Da\u00b7bei", "ward", "dies", "mit", "an\u00b7ge\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDS", "APPR", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wohl dem, den dieser Arzt kurirt.", "tokens": ["Wohl", "dem", ",", "den", "die\u00b7ser", "Arzt", "ku\u00b7rirt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Daraus mach ich mein Liebesband,", "tokens": ["Da\u00b7raus", "mach", "ich", "mein", "Lie\u00b7bes\u00b7band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und bring es als mein Seelenpfand,", "tokens": ["Und", "bring", "es", "als", "mein", "See\u00b7len\u00b7pfand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ehre dich mit diesem Namen:", "tokens": ["Und", "eh\u00b7re", "dich", "mit", "die\u00b7sem", "Na\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Herr, dessen Schrift dies selbst erdacht,", "tokens": ["Herr", ",", "des\u00b7sen", "Schrift", "dies", "selbst", "er\u00b7dacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELAT", "NN", "PDS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sey dies f\u00fcr mich, was ich dir bracht,", "tokens": ["Sey", "dies", "f\u00fcr", "mich", ",", "was", "ich", "dir", "bracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "APPR", "PPER", "$,", "PWS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sprich zu allem selbst das Amen;", "tokens": ["Und", "sprich", "zu", "al\u00b7lem", "selbst", "das", "A\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "So werd ich sonder Bild und Schein", "tokens": ["So", "werd", "ich", "son\u00b7der", "Bild", "und", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In dir wahrhaftig selig seyn.", "tokens": ["In", "dir", "wahr\u00b7haf\u00b7tig", "se\u00b7lig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}