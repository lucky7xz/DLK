{"textgrid.poem.37783": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Bibliothek", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da sitz ich nun so manchen Tag", "tokens": ["Da", "sitz", "ich", "nun", "so", "man\u00b7chen", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz m\u00fcssig vor den Schr\u00e4ncken,", "tokens": ["Ganz", "m\u00fcs\u00b7sig", "vor", "den", "Schr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Weil ich kein Buch mehr lesen mag,", "tokens": ["Weil", "ich", "kein", "Buch", "mehr", "le\u00b7sen", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil mich die Worte kr\u00e4ncken.", "tokens": ["Weil", "mich", "die", "Wor\u00b7te", "kr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich h\u00f6r kein Wort von Ihm und Ihr,", "tokens": ["Ich", "h\u00f6r", "kein", "Wort", "von", "Ihm", "und", "Ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "PPER", "KON", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verschlossen ist die Kerkerth\u00fcr.", "tokens": ["Ver\u00b7schlos\u00b7sen", "ist", "die", "Ker\u00b7kert\u00b7h\u00fcr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich sehe voll Bewundrung an", "tokens": ["Ich", "se\u00b7he", "voll", "Be\u00b7wund\u00b7rung", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies schlechte Buch mit Schw\u00e4ncken", "tokens": ["Dies", "schlech\u00b7te", "Buch", "mit", "Schw\u00e4n\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wie einer sowas schreiben kann", "tokens": ["Wie", "ei\u00b7ner", "so\u00b7was", "schrei\u00b7ben", "kann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "PIS", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich kann's nicht \u00fcberdencken", "tokens": ["Ich", "kann's", "nicht", "\u00fc\u00b7ber\u00b7den\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich denck und schreib' an ihn an Sie,", "tokens": ["Ich", "denck", "und", "schreib'", "an", "ihn", "an", "Sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.6": {"text": "Und beug' zum Beten meine Knie.", "tokens": ["Und", "beug'", "zum", "Be\u00b7ten", "mei\u00b7ne", "Knie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wie soll ich Ordnung bringen hier", "tokens": ["Wie", "soll", "ich", "Ord\u00b7nung", "brin\u00b7gen", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PPER", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In so viel tausend B\u00e4nde?", "tokens": ["In", "so", "viel", "tau\u00b7send", "B\u00e4n\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des Feuers Ungeduld in mir", "tokens": ["Des", "Feu\u00b7ers", "Un\u00b7ge\u00b7duld", "in", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wirft Blicke hin wie Br\u00e4nde;", "tokens": ["Wirft", "Bli\u00b7cke", "hin", "wie", "Br\u00e4n\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "KOKOM", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es brennt in mir nach Ihm nach Ihr,", "tokens": ["Es", "brennt", "in", "mir", "nach", "Ihm", "nach", "Ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "PPER", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Verbrennen m\u00f6cht ich alles hier!", "tokens": ["Ver\u00b7bren\u00b7nen", "m\u00f6cht", "ich", "al\u00b7les", "hier", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich sprech' wie jener Muselmann", "tokens": ["Ich", "sprech'", "wie", "je\u00b7ner", "Mu\u00b7sel\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "PDAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von den Bibliothecken:", "tokens": ["Von", "den", "Bib\u00b7liot\u00b7hec\u00b7ken", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbwas ", "tokens": ["\u00bb", "was"], "token_info": ["punct", "word"], "pos": ["$(", "PWS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Das andre sind Schartecken,\u00ab", "tokens": ["Das", "and\u00b7re", "sind", "Schar\u00b7te\u00b7cken", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "VAFIN", "NN", "$,", "$("], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.5": {"text": "Was ich nicht find in Ihm in Ihr", "tokens": ["Was", "ich", "nicht", "find", "in", "Ihm", "in", "Ihr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "VVFIN", "APPR", "PPER", "APPR", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ist unwerth das ichs registrir.", "tokens": ["Ist", "un\u00b7werth", "das", "ichs", "re\u00b7gist\u00b7rir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "PIS", "VVFIN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}}}}