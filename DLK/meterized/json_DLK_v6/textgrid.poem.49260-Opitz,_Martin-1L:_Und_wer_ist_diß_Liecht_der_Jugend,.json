{"textgrid.poem.49260": {"metadata": {"author": {"name": "Opitz, Martin", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und wer ist di\u00df Liecht der Jugend,", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und wer ist di\u00df Liecht der Jugend,", "tokens": ["Und", "wer", "ist", "di\u00df", "Liecht", "der", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "PDS", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer doch ist sie, die sich hier", "tokens": ["Wer", "doch", "ist", "sie", ",", "die", "sich", "hier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADV", "VAFIN", "PPER", "$,", "PRELS", "PRF", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Lest begleyten, an der Tugend", "tokens": ["Lest", "be\u00b7gley\u00b7ten", ",", "an", "der", "Tu\u00b7gend"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Minder nicht als an der Ziehr,", "tokens": ["Min\u00b7der", "nicht", "als", "an", "der", "Ziehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wie die sch\u00f6ne R\u00f6hte zeigt,", "tokens": ["Wie", "die", "sch\u00f6\u00b7ne", "R\u00f6h\u00b7te", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die ihr in das Antlitz steigt?", "tokens": ["Die", "ihr", "in", "das", "Ant\u00b7litz", "steigt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ist es nicht dein neues Leben,", "tokens": ["Ist", "es", "nicht", "dein", "neu\u00b7es", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Erquickung deiner Brunst,", "tokens": ["Die", "Er\u00b7quic\u00b7kung", "dei\u00b7ner", "Brunst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welche dir wird \u00fcbergeben", "tokens": ["Wel\u00b7che", "dir", "wird", "\u00fc\u00b7ber\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PPER", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von de\u00df milten Himmels Gunst,", "tokens": ["Von", "de\u00df", "mil\u00b7ten", "Him\u00b7mels", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dessen Spruch kein Witz noch Wahn,", "tokens": ["Des\u00b7sen", "Spruch", "kein", "Witz", "noch", "Wahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PIAT", "NN", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Herr Flandrin, verrucken kan?", "tokens": ["Herr", "Fland\u00b7rin", ",", "ver\u00b7ru\u00b7cken", "kan", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ja sie ist es, deine Wonne,", "tokens": ["Ja", "sie", "ist", "es", ",", "dei\u00b7ne", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die so lieblich zu dir geht,", "tokens": ["Die", "so", "lieb\u00b7lich", "zu", "dir", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als Aurora f\u00fcr der Sonne", "tokens": ["Als", "Au\u00b7ro\u00b7ra", "f\u00fcr", "der", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "APPR", "ART", "NN"], "meter": "-++-+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Au\u00df der bleichen Nacht entsteht,", "tokens": ["Au\u00df", "der", "blei\u00b7chen", "Nacht", "ent\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Bruder, au\u00df der bleichen Nacht,", "tokens": ["Bru\u00b7der", ",", "au\u00df", "der", "blei\u00b7chen", "Nacht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Die dein Lieb doch schamroht macht.", "tokens": ["Die", "dein", "Lieb", "doch", "scham\u00b7roht", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Schaue, wie sie sich entferbet,", "tokens": ["Schau\u00b7e", ",", "wie", "sie", "sich", "ent\u00b7fer\u00b7bet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie die Mahlerin, die Zucht,", "tokens": ["Wie", "die", "Mah\u00b7le\u00b7rin", ",", "die", "Zucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was kein Br\u00e4utigam recht erbet,", "tokens": ["Was", "kein", "Br\u00e4u\u00b7ti\u00b7gam", "recht", "er\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Au\u00df den vollen Wangen sucht,", "tokens": ["Au\u00df", "den", "vol\u00b7len", "Wan\u00b7gen", "sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der nicht solche Tugend freyt", "tokens": ["Der", "nicht", "sol\u00b7che", "Tu\u00b7gend", "freyt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PTKNEG", "PIAT", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Als das Gl\u00fccke dir verleyt.", "tokens": ["Als", "das", "Gl\u00fc\u00b7cke", "dir", "ver\u00b7leyt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hier nun sihest du die Schrancken,", "tokens": ["Hier", "nun", "si\u00b7hest", "du", "die", "Schran\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses Ziehl nach welchem dir", "tokens": ["Die\u00b7ses", "Ziehl", "nach", "wel\u00b7chem", "dir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPR", "PRELS", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stehen mu\u00df Hertz und Gedancken", "tokens": ["Ste\u00b7hen", "mu\u00df", "Hertz", "und", "Ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "NN", "KON", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Unverwand und f\u00fcr und f\u00fcr;", "tokens": ["Un\u00b7ver\u00b7wand", "und", "f\u00fcr", "und", "f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "APPR", "KON", "APPR", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hier sol einig und allein", "tokens": ["Hier", "sol", "ei\u00b7nig", "und", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADJD", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Deine Ruh und Sorge seyn.", "tokens": ["Dei\u00b7ne", "Ruh", "und", "Sor\u00b7ge", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Solch Liebe fellt und weichet,", "tokens": ["Solch", "Lie\u00b7be", "fellt", "und", "wei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die nicht angeleget ist;", "tokens": ["Die", "nicht", "an\u00b7ge\u00b7le\u00b7get", "ist", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eine Seele die dir gleichet", "tokens": ["Ei\u00b7ne", "See\u00b7le", "die", "dir", "glei\u00b7chet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hastu aber dir erkiest,", "tokens": ["Has\u00b7tu", "a\u00b7ber", "dir", "er\u00b7kiest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die durch Urtheil und Verstand", "tokens": ["Die", "durch", "Ur\u00b7theil", "und", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Ihren Sinn auff dich gewand.", "tokens": ["Ih\u00b7ren", "Sinn", "auff", "dich", "ge\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Soll sie viel von Liebe sagen?", "tokens": ["Soll", "sie", "viel", "von", "Lie\u00b7be", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nein; die Augen reden dir,", "tokens": ["Nein", ";", "die", "Au\u00b7gen", "re\u00b7den", "dir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ART", "NN", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die sie nieder hat geschlagen", "tokens": ["Die", "sie", "nie\u00b7der", "hat", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "PTKVZ", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit so angenehmer Ziehr,", "tokens": ["Mit", "so", "an\u00b7ge\u00b7neh\u00b7mer", "Ziehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und verheischen eine Lust", "tokens": ["Und", "ver\u00b7hei\u00b7schen", "ei\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So dir mehr als ihr bewust.", "tokens": ["So", "dir", "mehr", "als", "ihr", "be\u00b7wust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "KOUS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Sch\u00f6nes Kind, ihr m\u00fcst euch geben;", "tokens": ["Sch\u00f6\u00b7nes", "Kind", ",", "ihr", "m\u00fcst", "euch", "ge\u00b7ben", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo schon Geist und Hertze wohnt", "tokens": ["Wo", "schon", "Geist", "und", "Hert\u00b7ze", "wohnt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "NN", "KON", "VVFIN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ist nicht Zeit zu widerstreben,", "tokens": ["Ist", "nicht", "Zeit", "zu", "wi\u00b7der\u00b7stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weiter wird da nicht geschont,", "tokens": ["Wei\u00b7ter", "wird", "da", "nicht", "ge\u00b7schont", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Soll nicht Zartes Fleisch und Bein", "tokens": ["Soll", "nicht", "Zar\u00b7tes", "Fleisch", "und", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "ADJA", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Seines Geistes Meister seyn.", "tokens": ["Sei\u00b7nes", "Geis\u00b7tes", "Meis\u00b7ter", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Diese Bl\u00fcthe, diese Gaben,", "tokens": ["Die\u00b7se", "Bl\u00fc\u00b7the", ",", "die\u00b7se", "Ga\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eures sch\u00f6nen Leibes Pracht,", "tokens": ["Eu\u00b7res", "sch\u00f6\u00b7nen", "Lei\u00b7bes", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die sich erwiesen haben,", "tokens": ["Und", "die", "sich", "er\u00b7wie\u00b7sen", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eures Liebsten Muth und Macht,", "tokens": ["Eu\u00b7res", "Liebs\u00b7ten", "Muth", "und", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die erfodern, was ich wol", "tokens": ["Die", "er\u00b7fo\u00b7dern", ",", "was", "ich", "wol"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PWS", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Dencken mehr als sagen soll.", "tokens": ["Den\u00b7cken", "mehr", "als", "sa\u00b7gen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "KOKOM", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ruhet dann, jedoch erweget,", "tokens": ["Ru\u00b7het", "dann", ",", "je\u00b7doch", "er\u00b7we\u00b7get", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ADV", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Liebes Par, es sey die Nacht", "tokens": ["Lie\u00b7bes", "Par", ",", "es", "sey", "die", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eh es morgen sieben schl\u00e4get", "tokens": ["Eh", "es", "mor\u00b7gen", "sie\u00b7ben", "schl\u00e4\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "CARD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht zum Schnarchen nur gemacht.", "tokens": ["Nicht", "zum", "Schnar\u00b7chen", "nur", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Zwey die m\u00fcssen Wache seyn;", "tokens": ["Zwey", "die", "m\u00fcs\u00b7sen", "Wa\u00b7che", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schlaffen kan man wol allein.", "tokens": ["Schlaf\u00b7fen", "kan", "man", "wol", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PIS", "ADV", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}