{"textgrid.poem.26369": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "[doch eh dies Buch begonnen hat]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Doch eh dies Buch begonnen hat,", "tokens": ["Doch", "eh", "dies", "Buch", "be\u00b7gon\u00b7nen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort hat noch ein Kapitel statt.", "tokens": ["Dort", "hat", "noch", "ein", "Ka\u00b7pi\u00b7tel", "statt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Bevor den \u00dcbermensch ich fand,", "tokens": ["Be\u00b7vor", "den", "\u00dc\u00b7ber\u00b7mensch", "ich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zog ich zuerst versch\u00e4mt aufs Land,", "tokens": ["Zog", "ich", "zu\u00b7erst", "ver\u00b7sch\u00e4mt", "aufs", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Lebte als J\u00fcngling herzlos sehr,", "tokens": ["Leb\u00b7te", "als", "J\u00fcng\u00b7ling", "herz\u00b7los", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOUS", "NN", "ADJD", "ADV", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und dieses war besonders schwer.", "tokens": ["Und", "die\u00b7ses", "war", "be\u00b7son\u00b7ders", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Welt erschien mir noch als Fluch,", "tokens": ["Die", "Welt", "er\u00b7schien", "mir", "noch", "als", "Fluch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich floh gar gern in jedes Buch,", "tokens": ["Ich", "floh", "gar", "gern", "in", "je\u00b7des", "Buch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Klappte nach mir den Deckel zu,", "tokens": ["Klapp\u00b7te", "nach", "mir", "den", "De\u00b7ckel", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Nur zwischen Zeilen fand ich Ruh.", "tokens": ["Nur", "zwi\u00b7schen", "Zei\u00b7len", "fand", "ich", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Neben dem Druck liebte ich Land,", "tokens": ["Ne\u00b7ben", "dem", "Druck", "lieb\u00b7te", "ich", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Viel Landschaft, wo kein Mensch dort stand.", "tokens": ["Viel", "Land\u00b7schaft", ",", "wo", "kein", "Mensch", "dort", "stand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PWAV", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was von der Menschheit da noch war,", "tokens": ["Was", "von", "der", "Menschheit", "da", "noch", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Das Weib, schien im Gehirn nicht klar,", "tokens": ["Das", "Weib", ",", "schien", "im", "Ge\u00b7hirn", "nicht", "klar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "APPRART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Konnte die holde L\u00fcg' nicht lieben,", "tokens": ["Konn\u00b7te", "die", "hol\u00b7de", "L\u00fcg'", "nicht", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Mit der die Frauen leben blieben,", "tokens": ["Mit", "der", "die", "Frau\u00b7en", "le\u00b7ben", "blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Hatte das Weib nicht in der Nas',", "tokens": ["Hat\u00b7te", "das", "Weib", "nicht", "in", "der", "Nas'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "War duftlos noch ein J\u00fcnglingshas'.", "tokens": ["War", "duft\u00b7los", "noch", "ein", "J\u00fcng\u00b7lings\u00b7has'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich suchte, was fast \u00fcberall", "tokens": ["Ich", "such\u00b7te", ",", "was", "fast", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stand fortger\u00fcckt im Sennerstall.", "tokens": ["Stand", "fort\u00b7ge\u00b7r\u00fcckt", "im", "Sen\u00b7ner\u00b7stall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und machten brave K\u00fche: Muh,", "tokens": ["Und", "mach\u00b7ten", "bra\u00b7ve", "K\u00fc\u00b7he", ":", "Muh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$.", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fragte ich sie: \u00bbAch, Kuh, wozu?\u00ab", "tokens": ["Frag\u00b7te", "ich", "sie", ":", "\u00bb", "Ach", ",", "Kuh", ",", "wo\u00b7zu", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$.", "$(", "ITJ", "$,", "NN", "$,", "PWAV", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Ich sah's der Welt nicht lachend an,", "tokens": ["Ich", "sah's", "der", "Welt", "nicht", "la\u00b7chend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sie auch \u00bbMuh\u00ab mal machen kann.", "tokens": ["Da\u00df", "sie", "auch", "\u00bb", "Muh", "\u00ab", "mal", "ma\u00b7chen", "kann", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$(", "NN", "$(", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ich wollte Wildnis, ging nach Schweden,", "tokens": ["Ich", "woll\u00b7te", "Wild\u00b7nis", ",", "ging", "nach", "Schwe\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "$,", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hielt dort im Urwald an mich Reden,", "tokens": ["Hielt", "dort", "im", "Ur\u00b7wald", "an", "mich", "Re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "APPR", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Sa\u00df bei einem ganz alten Mann,", "tokens": ["Sa\u00df", "bei", "ei\u00b7nem", "ganz", "al\u00b7ten", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Der seinen Flachs sich selber spann.", "tokens": ["Der", "sei\u00b7nen", "Flachs", "sich", "sel\u00b7ber", "spann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Hier sah nicht Weisheit nasweis aus,", "tokens": ["Hier", "sah", "nicht", "Weis\u00b7heit", "nas\u00b7weis", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn keine Frau sprach in dem Haus.", "tokens": ["Denn", "kei\u00b7ne", "Frau", "sprach", "in", "dem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "H\u00f6rte nur diebisch Elstern lachen,", "tokens": ["H\u00f6r\u00b7te", "nur", "die\u00b7bisch", "Els\u00b7tern", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die wenig Kopfzerbrechen machen.", "tokens": ["Die", "we\u00b7nig", "Kopf\u00b7zer\u00b7bre\u00b7chen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ich lebte wie in einer Wolk',", "tokens": ["Ich", "leb\u00b7te", "wie", "in", "ei\u00b7ner", "Wol\u00b7k'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War Redner und auch zugleich Volk.", "tokens": ["War", "Red\u00b7ner", "und", "auch", "zu\u00b7gleich", "Volk", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Das Haus just vor dem Urwald stand,", "tokens": ["Das", "Haus", "just", "vor", "dem", "Ur\u00b7wald", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Liebe ich bei B\u00e4umen fand.", "tokens": ["Wo", "Lie\u00b7be", "ich", "bei", "B\u00e4u\u00b7men", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Ich liebte sehr die schmale Birke,", "tokens": ["Ich", "lieb\u00b7te", "sehr", "die", "schma\u00b7le", "Bir\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Findend, da\u00df sie als Jungfrau wirke;", "tokens": ["Fin\u00b7dend", ",", "da\u00df", "sie", "als", "Jung\u00b7frau", "wir\u00b7ke", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "KOUS", "PPER", "KOUS", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.20": {"line.1": {"text": "In ihren H\u00fcften war sie fein.", "tokens": ["In", "ih\u00b7ren", "H\u00fcf\u00b7ten", "war", "sie", "fein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich zapfte ihren Birkenwein,", "tokens": ["Ich", "zapf\u00b7te", "ih\u00b7ren", "Bir\u00b7ken\u00b7wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "H\u00f6rte die Bl\u00e4tter buhlend summen", "tokens": ["H\u00f6r\u00b7te", "die", "Bl\u00e4t\u00b7ter", "buh\u00b7lend", "sum\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJD", "VVINF"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und lebte stumm mit all dem Stummen.", "tokens": ["Und", "leb\u00b7te", "stumm", "mit", "all", "dem", "Stum\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PIAT", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Blumen standen sinnlich um mich,", "tokens": ["Blu\u00b7men", "stan\u00b7den", "sinn\u00b7lich", "um", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "APPR", "PPER", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und nur ganz sinnlos lebte ich,", "tokens": ["Und", "nur", "ganz", "sinn\u00b7los", "leb\u00b7te", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "H\u00f6rte das Elchtier br\u00fcnstig schreien,", "tokens": ["H\u00f6r\u00b7te", "das", "E\u00b7lchtier", "br\u00fcns\u00b7tig", "schrei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "F\u00fchlte so gl\u00fccklich mich im Freien,", "tokens": ["F\u00fchl\u00b7te", "so", "gl\u00fcck\u00b7lich", "mich", "im", "Frei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "PPER", "APPRART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.24": {"line.1": {"text": "Sah nachts im Tau die D\u00e4chsin \u00e4sen", "tokens": ["Sah", "nachts", "im", "Tau", "die", "D\u00e4ch\u00b7sin", "\u00e4\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und d\u00fcnkte mich ein bess'res Wesen.", "tokens": ["Und", "d\u00fcnk\u00b7te", "mich", "ein", "bess'\u00b7res", "We\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Stieg dann der Mond gesund herauf,", "tokens": ["Stieg", "dann", "der", "Mond", "ge\u00b7sund", "her\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sah ich ganz ungesund hinauf.", "tokens": ["Sah", "ich", "ganz", "un\u00b7ge\u00b7sund", "hin\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Zu sterben schien mir ein Genu\u00df,", "tokens": ["Zu", "ster\u00b7ben", "schien", "mir", "ein", "Ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Leben war nur Todesku\u00df.", "tokens": ["Das", "Le\u00b7ben", "war", "nur", "To\u00b7des\u00b7ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Denn nichts siehst du, wie's freundlich ist,", "tokens": ["Denn", "nichts", "siehst", "du", ",", "wie's", "freund\u00b7lich", "ist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "$,", "VVFIN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn du dem Weibe feind noch bist.", "tokens": ["Wenn", "du", "dem", "Wei\u00b7be", "feind", "noch", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Mein wei\u00dfes Bett war kalte Gruft,", "tokens": ["Mein", "wei\u00b7\u00dfes", "Bett", "war", "kal\u00b7te", "Gruft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ringsdarum nur Zimmerluft.", "tokens": ["Und", "rings\u00b7da\u00b7rum", "nur", "Zim\u00b7mer\u00b7luft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Im Schwedenhaus waren alt alle,", "tokens": ["Im", "Schwe\u00b7den\u00b7haus", "wa\u00b7ren", "alt", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADJD", "PIS", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Vom Vater bis zum G\u00e4nsestalle.", "tokens": ["Vom", "Va\u00b7ter", "bis", "zum", "G\u00e4n\u00b7se\u00b7stal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Die Gans war f\u00fcnfunddrei\u00dfig Jahr,", "tokens": ["Die", "Gans", "war", "f\u00fcn\u00b7fund\u00b7drei\u00b7\u00dfig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Pferd auch ganz verbogen war,", "tokens": ["Das", "Pferd", "auch", "ganz", "ver\u00b7bo\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Katzen am Dach zum Himmel schlichen,", "tokens": ["Kat\u00b7zen", "am", "Dach", "zum", "Him\u00b7mel", "schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Wie Mumien alt und angestrichen,", "tokens": ["Wie", "Mu\u00b7mi\u00b7en", "alt", "und", "an\u00b7ge\u00b7stri\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "KON", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Die alte gro\u00dfe Riegelt\u00fcr", "tokens": ["Die", "al\u00b7te", "gro\u00b7\u00dfe", "Rie\u00b7gel\u00b7t\u00fcr"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erschlug vor Schw\u00e4ch' den Menschen schier.", "tokens": ["Er\u00b7schlug", "vor", "Schw\u00e4ch'", "den", "Men\u00b7schen", "schier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Erh\u00e4ngt ging um im Dachgeb\u00e4lk", "tokens": ["Er\u00b7h\u00e4ngt", "ging", "um", "im", "Dach\u00b7ge\u00b7b\u00e4lk"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Geist, wie alte W\u00e4sche welk,", "tokens": ["Ein", "Geist", ",", "wie", "al\u00b7te", "W\u00e4\u00b7sche", "welk", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Auf Schnecken schlich der Tag vorbei", "tokens": ["Auf", "Schne\u00b7cken", "schlich", "der", "Tag", "vor\u00b7bei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und war erst sch\u00f6n, ging er entzwei.", "tokens": ["Und", "war", "erst", "sch\u00f6n", ",", "ging", "er", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Vor Stille von den Haufen Tagen", "tokens": ["Vor", "Stil\u00b7le", "von", "den", "Hau\u00b7fen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Konnte das Haus nur \u00bbPst\u00ab noch sagen.", "tokens": ["Konn\u00b7te", "das", "Haus", "nur", "\u00bb", "Pst", "\u00ab", "noch", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "$(", "NN", "$(", "ADV", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.36": {"line.1": {"text": "Elastisch war nicht mal ein Floh,", "tokens": ["E\u00b7las\u00b7tisch", "war", "nicht", "mal", "ein", "Floh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn altes Blut macht niemand froh,", "tokens": ["Denn", "al\u00b7tes", "Blut", "macht", "nie\u00b7mand", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Ich ging allein zu jung umher,", "tokens": ["Ich", "ging", "al\u00b7lein", "zu", "jung", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKA", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00fcnschend, wenn ich doch grau erst w\u00e4r'.", "tokens": ["W\u00fcn\u00b7schend", ",", "wenn", "ich", "doch", "grau", "erst", "w\u00e4r'", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "PPER", "ADV", "ADJD", "ADV", "VAFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.38": {"line.1": {"text": "Vorwurfsvoll ist es, das was \u00e4lter,", "tokens": ["Vor\u00b7wurfs\u00b7voll", "ist", "es", ",", "das", "was", "\u00e4l\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$,", "PDS", "PRELS", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und edel darum, weil's gequ\u00e4lter.", "tokens": ["Und", "e\u00b7del", "da\u00b7rum", ",", "weil's", "ge\u00b7qu\u00e4l\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "PAV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Ich neidete dem Pferd, dem alten,", "tokens": ["Ich", "nei\u00b7de\u00b7te", "dem", "Pferd", ",", "dem", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df rippig es mit H\u00e4ngefalten.", "tokens": ["Da\u00df", "rip\u00b7pig", "es", "mit", "H\u00e4n\u00b7ge\u00b7fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Das Alter schien mir wie ein Segen,", "tokens": ["Das", "Al\u00b7ter", "schien", "mir", "wie", "ein", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es sagt zu allem: meinetwegen, \u2013", "tokens": ["Es", "sagt", "zu", "al\u00b7lem", ":", "mei\u00b7net\u00b7we\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "$.", "ADV", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Spricht stets mit sich zum Zeitvertreib", "tokens": ["Spricht", "stets", "mit", "sich", "zum", "Zeit\u00b7ver\u00b7treib"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und kennt's und h\u00e4lt sich fern vom Weib.", "tokens": ["Und", "kennt's", "und", "h\u00e4lt", "sich", "fern", "vom", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PRF", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Denn ach, das Weib, das war der Knoten,", "tokens": ["Denn", "ach", ",", "das", "Weib", ",", "das", "war", "der", "Kno\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$,", "ART", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Empfohlen war es und verboten.", "tokens": ["Emp\u00b7foh\u00b7len", "war", "es", "und", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Kam man ihm n\u00e4mlich mal zu nah,", "tokens": ["Kam", "man", "ihm", "n\u00e4m\u00b7lich", "mal", "zu", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PPER", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War S\u00fcnd' oder Verlobung da.", "tokens": ["War", "S\u00fcnd'", "o\u00b7der", "Ver\u00b7lo\u00b7bung", "da", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "So tat ich mich an B\u00e4ume halten", "tokens": ["So", "tat", "ich", "mich", "an", "B\u00e4u\u00b7me", "hal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und H\u00e4nde hei\u00df um Birken falten,", "tokens": ["Und", "H\u00e4n\u00b7de", "hei\u00df", "um", "Bir\u00b7ken", "fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Weil uns die Angst oft tr\u00f6stend sagt,", "tokens": ["Weil", "uns", "die", "Angst", "oft", "tr\u00f6s\u00b7tend", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man stirbt nicht dran, was man nicht wagt.", "tokens": ["Man", "stirbt", "nicht", "dran", ",", "was", "man", "nicht", "wagt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "PAV", "$,", "PRELS", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Doch w\u00fc\u00dft' ich einmal nur von fern,", "tokens": ["Doch", "w\u00fc\u00dft'", "ich", "ein\u00b7mal", "nur", "von", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie tut's, hat man die Frau mal gern.", "tokens": ["Wie", "tut's", ",", "hat", "man", "die", "Frau", "mal", "gern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "VAFIN", "PIS", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Die Frau der Kontrapunkt dir ist,", "tokens": ["Die", "Frau", "der", "Kon\u00b7tra\u00b7punkt", "dir", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schlimm geht's dem, der das vergi\u00dft.", "tokens": ["Und", "schlimm", "geht's", "dem", ",", "der", "das", "ver\u00b7gi\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "$,", "PRELS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Klag' nicht, da\u00df Leben kl\u00e4glich sei,", "tokens": ["Klag'", "nicht", ",", "da\u00df", "Le\u00b7ben", "kl\u00e4g\u00b7lich", "sei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ohn' Weib gibt's keine Melodei.", "tokens": ["Ohn'", "Weib", "gibt's", "kei\u00b7ne", "Me\u00b7lo\u00b7dei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Wenn Eul' und Kauz verliebt nachts schrie,", "tokens": ["Wenn", "Eul'", "und", "Kauz", "ver\u00b7liebt", "nachts", "schrie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Trieb ich statt Lieb' Philosophie,", "tokens": ["Trieb", "ich", "statt", "Lieb'", "Phi\u00b7lo\u00b7so\u00b7phie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "NN", "NE", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.50": {"line.1": {"text": "Welt ohne Will', nur Vorstellung,", "tokens": ["Welt", "oh\u00b7ne", "Will'", ",", "nur", "Vor\u00b7stel\u00b7lung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADV", "NN", "$,"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "Gab meinen armen N\u00e4chten Schwung.", "tokens": ["Gab", "mei\u00b7nen", "ar\u00b7men", "N\u00e4ch\u00b7ten", "Schwung", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Stark war beim Kopf mein Haarwuchs nur,", "tokens": ["Stark", "war", "beim", "Kopf", "mein", "Haar\u00b7wuchs", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPRART", "NN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wolle und Geist brauchten Schafschur.", "tokens": ["Wol\u00b7le", "und", "Geist", "brauch\u00b7ten", "Schaf\u00b7schur", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "NE", "$."], "meter": "+--++-+-", "measure": "dactylic.init"}}, "stanza.52": {"line.1": {"text": "Die Schur kam pl\u00f6tzlich unerwartet,", "tokens": ["Die", "Schur", "kam", "pl\u00f6tz\u00b7lich", "un\u00b7er\u00b7war\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Eh ich im Z\u00f6libat erhartet.", "tokens": ["Eh", "ich", "im", "Z\u00f6\u00b7li\u00b7bat", "er\u00b7har\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Beim Baden kam ein Todeskampf", "tokens": ["Beim", "Ba\u00b7den", "kam", "ein", "To\u00b7des\u00b7kampf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In der Gestalt vom Wadenkrampf.", "tokens": ["In", "der", "Ge\u00b7stalt", "vom", "Wa\u00b7den\u00b7krampf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Das Wasser lie\u00df mich sanft versinken,", "tokens": ["Das", "Was\u00b7ser", "lie\u00df", "mich", "sanft", "ver\u00b7sin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Tod war nicht mehr abzuwinken.", "tokens": ["Dem", "Tod", "war", "nicht", "mehr", "ab\u00b7zu\u00b7win\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "So sch\u00f6n real war just der Tag,", "tokens": ["So", "sch\u00f6n", "re\u00b7al", "war", "just", "der", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo man kein Bodenloses mag.", "tokens": ["Wo", "man", "kein", "Bo\u00b7den\u00b7lo\u00b7ses", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PWAV", "PIS", "PIAT", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.56": {"line.1": {"text": "Primelein gelb wie Narrenschellen", "tokens": ["Pri\u00b7mel\u00b7ein", "gelb", "wie", "Nar\u00b7ren\u00b7schel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "KOKOM", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Steckten kokett bei Uferwellen,", "tokens": ["Steck\u00b7ten", "ko\u00b7kett", "bei", "U\u00b7fer\u00b7wel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.57": {"line.1": {"text": "Der Amsel Musikantenlachen", "tokens": ["Der", "Am\u00b7sel", "Mu\u00b7si\u00b7kan\u00b7ten\u00b7la\u00b7chen"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Belachte alle Fr\u00fchlingsachen.", "tokens": ["Be\u00b7lach\u00b7te", "al\u00b7le", "Fr\u00fch\u00b7lings\u00b7a\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Wie Essig schmeckte heut der Tod,", "tokens": ["Wie", "Es\u00b7sig", "schmeck\u00b7te", "heut", "der", "Tod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sonst schien er mir ein Butterbrot.", "tokens": ["Sonst", "schien", "er", "mir", "ein", "But\u00b7ter\u00b7brot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Ich dacht': Ach, lie\u00df er sich vertreiben!", "tokens": ["Ich", "dacht'", ":", "Ach", ",", "lie\u00df", "er", "sich", "ver\u00b7trei\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ITJ", "$,", "VVFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hast du vielleicht noch Briefzuschreiben?", "tokens": ["Hast", "du", "viel\u00b7leicht", "noch", "Brief\u00b7zu\u00b7schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Vielleicht, da\u00df sich die Wade streckt,", "tokens": ["Viel\u00b7leicht", ",", "da\u00df", "sich", "die", "Wa\u00b7de", "streckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PRF", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sie Notwendigkeit entdeckt.", "tokens": ["Wenn", "sie", "Not\u00b7wen\u00b7dig\u00b7keit", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVPP", "$."], "meter": "--++-+-+", "measure": "anapaest.init"}}, "stanza.61": {"line.1": {"text": "Auf einmal war es mir s\u00fc\u00df klar,", "tokens": ["Auf", "ein\u00b7mal", "war", "es", "mir", "s\u00fc\u00df", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "PPER", "PPER", "ADJD", "ADJD", "$,"], "meter": "-+-+-+++", "measure": "unknown.measure.penta"}, "line.2": {"text": "H\u00f6chste Notwendigkeit da war:", "tokens": ["H\u00f6chs\u00b7te", "Not\u00b7wen\u00b7dig\u00b7keit", "da", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VAFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.62": {"line.1": {"text": "Das Weib, die mir sonst Kleinigkeit,", "tokens": ["Das", "Weib", ",", "die", "mir", "sonst", "Klei\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War allerh\u00f6chst' Notwendigkeit.", "tokens": ["War", "al\u00b7ler\u00b7h\u00f6chst'", "Not\u00b7wen\u00b7dig\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Ich kenn' vom Weib noch keine Spur,", "tokens": ["Ich", "kenn'", "vom", "Weib", "noch", "kei\u00b7ne", "Spur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Drum, Wade, la\u00df mich leben nur;", "tokens": ["Drum", ",", "Wa\u00b7de", ",", "la\u00df", "mich", "le\u00b7ben", "nur", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,", "VVIMP", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "So sch\u00f6n ist's heut, hab doch Erbarmen,", "tokens": ["So", "sch\u00f6n", "ist's", "heut", ",", "hab", "doch", "Er\u00b7bar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "$,", "VAFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Will keine Birke mehr umarmen.", "tokens": ["Will", "kei\u00b7ne", "Bir\u00b7ke", "mehr", "um\u00b7ar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Mann, lieb' das Weib, so wie es ist,", "tokens": ["Mann", ",", "lieb'", "das", "Weib", ",", "so", "wie", "es", "ist", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "$,", "ADV", "KOKOM", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du vom Krampf erl\u00f6set bist.", "tokens": ["Da\u00df", "du", "vom", "Krampf", "er\u00b7l\u00f6\u00b7set", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Selbst Wadenkrampf tut dann vergehn,", "tokens": ["Selbst", "Wa\u00b7den\u00b7krampf", "tut", "dann", "ver\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tust du schon unter Wasser stehn;", "tokens": ["Tust", "du", "schon", "un\u00b7ter", "Was\u00b7ser", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Denn aufgetaucht bin ich still wieder,", "tokens": ["Denn", "auf\u00b7ge\u00b7taucht", "bin", "ich", "still", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "VAFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Widmend dem Weibe meine Glieder.", "tokens": ["Wid\u00b7mend", "dem", "Wei\u00b7be", "mei\u00b7ne", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.68": {"line.1": {"text": "Wahrlich, es w\u00e4r' mein Tod gewesen,", "tokens": ["Wahr\u00b7lich", ",", "es", "w\u00e4r'", "mein", "Tod", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "VAPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "H\u00e4tt' ich nicht mal vom Weib gelesen.", "tokens": ["H\u00e4tt'", "ich", "nicht", "mal", "vom", "Weib", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Und da\u00df sie Leben viel verleiht,", "tokens": ["Und", "da\u00df", "sie", "Le\u00b7ben", "viel", "ver\u00b7leiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Davon bin ich die Wirklichkeit.", "tokens": ["Da\u00b7von", "bin", "ich", "die", "Wirk\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}