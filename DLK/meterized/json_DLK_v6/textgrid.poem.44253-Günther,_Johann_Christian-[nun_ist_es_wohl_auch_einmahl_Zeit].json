{"textgrid.poem.44253": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[nun ist es wohl auch einmahl Zeit]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun ist es wohl auch einmahl Zeit,", "tokens": ["Nun", "ist", "es", "wohl", "auch", "ein\u00b7mahl", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Zeugn\u00fc\u00df frommer Redligkeit", "tokens": ["Ein", "Zeug\u00b7n\u00fc\u00df", "from\u00b7mer", "Red\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit schlechten Worten darzubringen", "tokens": ["Mit", "schlech\u00b7ten", "Wor\u00b7ten", "dar\u00b7zu\u00b7brin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PAV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, da ich weiter doch nichts kan,", "tokens": ["Und", ",", "da", "ich", "wei\u00b7ter", "doch", "nichts", "kan", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "ADV", "PIS", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dir jezo, wohlerfahrner Mann,", "tokens": ["Dir", "je\u00b7zo", ",", "woh\u00b7ler\u00b7fahr\u00b7ner", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein kurzes Dancklied abzusingen.", "tokens": ["Ein", "kur\u00b7zes", "Danck\u00b7lied", "ab\u00b7zu\u00b7sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich bin ein Schuldner, de\u00dfen Hand", "tokens": ["Ich", "bin", "ein", "Schuld\u00b7ner", ",", "de\u00b7\u00dfen", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zeither schon manch gewi\u00dfes Pfand", "tokens": ["Zeit\u00b7her", "schon", "manch", "ge\u00b7wi\u00b7\u00dfes", "Pfand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von deiner G\u00fctigkeit bekommen,", "tokens": ["Von", "dei\u00b7ner", "G\u00fc\u00b7tig\u00b7keit", "be\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die mich als einen fremden Gast,", "tokens": ["Die", "mich", "als", "ei\u00b7nen", "frem\u00b7den", "Gast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von dem du nichts als Unruh hast,", "tokens": ["Von", "dem", "du", "nichts", "als", "Un\u00b7ruh", "hast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PIS", "KOKOM", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Stets werth und liebreich aufgenommen.", "tokens": ["Stets", "werth", "und", "lieb\u00b7reich", "auf\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dein ehrlich und dein deutsches Herz", "tokens": ["Dein", "ehr\u00b7lich", "und", "dein", "deut\u00b7sches", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erweckt mir oft nicht wenig Schmerz", "tokens": ["Er\u00b7weckt", "mir", "oft", "nicht", "we\u00b7nig", "Schmerz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und plagt bisweilen mein Gewi\u00dfen.", "tokens": ["Und", "plagt", "bis\u00b7wei\u00b7len", "mein", "Ge\u00b7wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Warum? Ich weis kein Wiedergelt", "tokens": ["Wa\u00b7rum", "?", "Ich", "weis", "kein", "Wie\u00b7der\u00b7gelt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$.", "PPER", "PTKVZ", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und mag von niemand auf der Welt", "tokens": ["Und", "mag", "von", "nie\u00b7mand", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "APPR", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht gern etwas umsonst genie\u00dfen.", "tokens": ["Nicht", "gern", "et\u00b7was", "um\u00b7sonst", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Das sag ich mit Bedacht heraus:", "tokens": ["Das", "sag", "ich", "mit", "Be\u00b7dacht", "he\u00b7raus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kommst du und dein geneigtes Haus", "tokens": ["Kommst", "du", "und", "dein", "ge\u00b7neig\u00b7tes", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mir jemahls aus Gem\u00fcth und Sinnen,", "tokens": ["Mir", "je\u00b7mahls", "aus", "Ge\u00b7m\u00fcth", "und", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So will ich als ein Musenfreund", "tokens": ["So", "will", "ich", "als", "ein", "Mu\u00b7sen\u00b7freund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von keinem, der es ehrlich meint,", "tokens": ["Von", "kei\u00b7nem", ",", "der", "es", "ehr\u00b7lich", "meint", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von nun an weiter Trost gewinnen.", "tokens": ["Von", "nun", "an", "wei\u00b7ter", "Trost", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nein, glaub es ein- vor allemahl:", "tokens": ["Nein", ",", "glaub", "es", "ein", "vor", "al\u00b7le\u00b7mahl", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "TRUNC", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erhebt mich einst des Gl\u00fcckes Strahl", "tokens": ["Er\u00b7hebt", "mich", "einst", "des", "Gl\u00fc\u00b7ckes", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kan ich deinen Kindern n\u00fczen,", "tokens": ["Und", "kan", "ich", "dei\u00b7nen", "Kin\u00b7dern", "n\u00fc\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So will ich nach Verm\u00f6gen thun", "tokens": ["So", "will", "ich", "nach", "Ver\u00b7m\u00f6\u00b7gen", "thun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und bey Gelegenheit nicht ruhn,", "tokens": ["Und", "bey", "Ge\u00b7le\u00b7gen\u00b7heit", "nicht", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie noch mit Rath und That zu sch\u00fczen.", "tokens": ["Sie", "noch", "mit", "Rath", "und", "That", "zu", "sch\u00fc\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wer weis, welch Land mir meinen Herd", "tokens": ["Wer", "weis", ",", "welch", "Land", "mir", "mei\u00b7nen", "Herd"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKVZ", "$,", "PWAT", "NN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und meinem Flei\u00dfe Brodt bescheert,", "tokens": ["Und", "mei\u00b7nem", "Flei\u00b7\u00dfe", "Brodt", "be\u00b7scheert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Gl\u00fccke scheint mich weit zu schlagen;", "tokens": ["Das", "Gl\u00fc\u00b7cke", "scheint", "mich", "weit", "zu", "schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es sey, wohin es immer will,", "tokens": ["Es", "sey", ",", "wo\u00b7hin", "es", "im\u00b7mer", "will", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PPER", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So will ich doch vertraut und still", "tokens": ["So", "will", "ich", "doch", "ver\u00b7traut", "und", "still"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein Lob noch manchem Freunde sagen,", "tokens": ["Dein", "Lob", "noch", "man\u00b7chem", "Freun\u00b7de", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Dein Lob von Kunst, Verstand und Flei\u00df,", "tokens": ["Dein", "Lob", "von", "Kunst", ",", "Ver\u00b7stand", "und", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als de\u00dfen Ruhm und Ehrenpreis", "tokens": ["Als", "de\u00b7\u00dfen", "Ruhm", "und", "Eh\u00b7ren\u00b7preis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch so viel Blut und Wunden gr\u00fcnet,", "tokens": ["Durch", "so", "viel", "Blut", "und", "Wun\u00b7den", "gr\u00fc\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Nachdem die Cur von deiner Hand", "tokens": ["Nach\u00b7dem", "die", "Cur", "von", "dei\u00b7ner", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Manch Opfer schon dem Tod entwand", "tokens": ["Manch", "Op\u00b7fer", "schon", "dem", "Tod", "ent\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und so viel Krancken treu gedienet.", "tokens": ["Und", "so", "viel", "Kran\u00b7cken", "treu", "ge\u00b7die\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Was ist nun wohl davor dein Lohn?", "tokens": ["Was", "ist", "nun", "wohl", "da\u00b7vor", "dein", "Lohn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "PAV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zehn M\u00e4nner gehn gesund davon,", "tokens": ["Zehn", "M\u00e4n\u00b7ner", "gehn", "ge\u00b7sund", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Noth kehrt einer danckbar wieder.", "tokens": ["Mit", "Noth", "kehrt", "ei\u00b7ner", "dan\u00b7ck\u00b7bar", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJD", "ADV", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "So gehts im Evangelio,", "tokens": ["So", "gehts", "im", "E\u00b7van\u00b7ge\u00b7lio", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Es geht auch unter uns noch so,", "tokens": ["Es", "geht", "auch", "un\u00b7ter", "uns", "noch", "so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Neune haben tausend Br\u00fcder.", "tokens": ["Die", "Neu\u00b7ne", "ha\u00b7ben", "tau\u00b7send", "Br\u00fc\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "CARD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Erkennt man gleich nicht deine M\u00fch,", "tokens": ["Er\u00b7kennt", "man", "gleich", "nicht", "dei\u00b7ne", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So tr\u00f6ste dich und las es die,", "tokens": ["So", "tr\u00f6s\u00b7te", "dich", "und", "las", "es", "die", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "ART", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So H\u00fclfe brauchen, nicht entgelten;", "tokens": ["So", "H\u00fcl\u00b7fe", "brau\u00b7chen", ",", "nicht", "ent\u00b7gel\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$,", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Trost ist schon des Nechsten Heil,", "tokens": ["Dein", "Trost", "ist", "schon", "des", "Nechs\u00b7ten", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Himmel zahlt dir vor sein Theil", "tokens": ["Der", "Him\u00b7mel", "zahlt", "dir", "vor", "sein", "Theil"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wird den Undanck kr\u00e4ftig schelten.", "tokens": ["Und", "wird", "den", "Un\u00b7danck", "kr\u00e4f\u00b7tig", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dein Haus mu\u00df doch an Gl\u00fccke bl\u00fchn", "tokens": ["Dein", "Haus", "mu\u00df", "doch", "an", "Gl\u00fc\u00b7cke", "bl\u00fchn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "ADV", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und durch dein heilsames Bem\u00fchn", "tokens": ["Und", "durch", "dein", "heil\u00b7sa\u00b7mes", "Be\u00b7m\u00fchn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mehr Seegen und mehr Wachsthum finden", "tokens": ["Mehr", "See\u00b7gen", "und", "mehr", "Wach\u00b7sthum", "fin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als M\u00e4ckler, die aus \u00dcbermuth", "tokens": ["Als", "M\u00e4ck\u00b7ler", ",", "die", "aus", "\u00dc\u00b7ber\u00b7muth"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und durch ihr schlimm erworbnes Gut", "tokens": ["Und", "durch", "ihr", "schlimm", "er\u00b7worb\u00b7nes", "Gut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So pl\u00f6zlich steigen als verschwinden.", "tokens": ["So", "pl\u00f6z\u00b7lich", "stei\u00b7gen", "als", "ver\u00b7schwin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "KOKOM", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die Vorsicht werfe deiner Ruh", "tokens": ["Die", "Vor\u00b7sicht", "wer\u00b7fe", "dei\u00b7ner", "Ruh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch andrer Wohlseyn Fr\u00fcchte zu", "tokens": ["Durch", "an\u00b7drer", "Wohl\u00b7seyn", "Fr\u00fcch\u00b7te", "zu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und las es deiner Kunst gelingen", "tokens": ["Und", "las", "es", "dei\u00b7ner", "Kunst", "ge\u00b7lin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und la\u00dfe dies dein Nahmenslicht,", "tokens": ["Und", "la\u00b7\u00dfe", "dies", "dein", "Nah\u00b7mens\u00b7licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So sehr die Misgunst wiederspricht,", "tokens": ["So", "sehr", "die", "Mis\u00b7gunst", "wie\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dir j\u00e4hrlich neue Kr\u00e4fte bringen.", "tokens": ["Dir", "j\u00e4hr\u00b7lich", "neu\u00b7e", "Kr\u00e4f\u00b7te", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Sie f\u00fchr auch deinen starcken Fu\u00df", "tokens": ["Sie", "f\u00fchr", "auch", "dei\u00b7nen", "star\u00b7cken", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ohn Ansto\u00df, Fall und \u00dcberdru\u00df", "tokens": ["Ohn", "An\u00b7sto\u00df", ",", "Fall", "und", "\u00dc\u00b7berd\u00b7ru\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bis in des Alters sp\u00e4ten Winter;", "tokens": ["Bis", "in", "des", "Al\u00b7ters", "sp\u00e4\u00b7ten", "Win\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und kommstu einst an deinen Ort,", "tokens": ["Und", "komms\u00b7tu", "einst", "an", "dei\u00b7nen", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So bl\u00fch dein Ruhm in Kindern fort.", "tokens": ["So", "bl\u00fch", "dein", "Ruhm", "in", "Kin\u00b7dern", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dies w\u00fcntschen Eydam, Sohn und G\u00fcnther.", "tokens": ["Dies", "w\u00fcnt\u00b7schen", "Ey\u00b7dam", ",", "Sohn", "und", "G\u00fcn\u00b7ther", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "$,", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}