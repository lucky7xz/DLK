{"textgrid.poem.24647": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: So legest du nun ab die lang getragne B\u00fcrde;", "genre": "verse", "period": "N.A.", "pub_year": 1701, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So legest du nun ab die lang getragne B\u00fcrde;", "tokens": ["So", "le\u00b7gest", "du", "nun", "ab", "die", "lang", "ge\u00b7trag\u00b7ne", "B\u00fcr\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein graues Haupt verlangt mit allem Recht die Ruh;", "tokens": ["Dein", "grau\u00b7es", "Haupt", "ver\u00b7langt", "mit", "al\u00b7lem", "Recht", "die", "Ruh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "PIS", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nach sechtzig Jahren schlie\u00dft sich deiner Aemter W\u00fcrde/", "tokens": ["Nach", "secht\u00b7zig", "Jah\u00b7ren", "schlie\u00dft", "sich", "dei\u00b7ner", "A\u00b7em\u00b7ter", "W\u00fcr\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVFIN", "PRF", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und in dem achtzigsten dein Lebens-Umkrey\u00df zu.", "tokens": ["Und", "in", "dem", "acht\u00b7zigs\u00b7ten", "dein", "Le\u00b7bens\u00b7Um\u00b7krey\u00df", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Der tausende erreicht nicht deines Alters L\u00e4nge:", "tokens": ["Der", "tau\u00b7sen\u00b7de", "er\u00b7reicht", "nicht", "dei\u00b7nes", "Al\u00b7ters", "L\u00e4n\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch noch viel weniger bey solcher Amtes-Last/", "tokens": ["Doch", "noch", "viel", "we\u00b7ni\u00b7ger", "bey", "sol\u00b7cher", "Am\u00b7tes\u00b7Last", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Jugend sauren Schwei\u00df und deiner Thaten M\u00e4nge/", "tokens": ["Der", "Ju\u00b7gend", "sau\u00b7ren", "Schwei\u00df", "und", "dei\u00b7ner", "Tha\u00b7ten", "M\u00e4n\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Womit du/ Mann und Grei\u00df/ die Welt erf\u00fcllet hast.", "tokens": ["Wo\u00b7mit", "du", "/", "Mann", "und", "Grei\u00df", "/", "die", "Welt", "er\u00b7f\u00fcl\u00b7let", "hast", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$(", "NN", "KON", "NN", "$(", "ART", "NN", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dein Leben ist beqvem/ da\u00df es die Jugend lehre/", "tokens": ["Dein", "Le\u00b7ben", "ist", "be\u00b7qvem", "/", "da\u00df", "es", "die", "Ju\u00b7gend", "leh\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und eine Schule/ die recht aus Erfahrung zeugt/", "tokens": ["Und", "ei\u00b7ne", "Schu\u00b7le", "/", "die", "recht", "aus", "Er\u00b7fah\u00b7rung", "zeugt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$(", "ART", "ADJD", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie man das Buch so wohl/ als einen Degen ehre/", "tokens": ["Wie", "man", "das", "Buch", "so", "wohl", "/", "als", "ei\u00b7nen", "De\u00b7gen", "eh\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "ADV", "ADV", "$(", "KOUS", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Weil sich das volle Gl\u00fcck nach deinem Wissen neigt/", "tokens": ["Weil", "sich", "das", "vol\u00b7le", "Gl\u00fcck", "nach", "dei\u00b7nem", "Wis\u00b7sen", "neigt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das nicht so ohne M\u00fch wie Schw\u00e4mme aufgeschossen/", "tokens": ["Das", "nicht", "so", "oh\u00b7ne", "M\u00fch", "wie", "Schw\u00e4m\u00b7me", "auf\u00b7ge\u00b7schos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ADV", "APPR", "NN", "KOKOM", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und nur an einem Dunst von F\u00fcrsten Gnade hieng:", "tokens": ["Und", "nur", "an", "ei\u00b7nem", "Dunst", "von", "F\u00fcrs\u00b7ten", "Gna\u00b7de", "hieng", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPR", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Es kostete was mehr/ du zehltest manche Sprossen/", "tokens": ["Es", "kos\u00b7te\u00b7te", "was", "mehr", "/", "du", "zehl\u00b7test", "man\u00b7che", "Spros\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWS", "ADV", "$(", "PPER", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bi\u00df dein ge\u00fcbter Fu\u00df auf diesen Stuffen gieng.", "tokens": ["Bi\u00df", "dein", "ge\u00b7\u00fcb\u00b7ter", "Fu\u00df", "auf", "die\u00b7sen", "Stuf\u00b7fen", "gieng", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Du sogst den Adel nicht aus deiner Mutter Br\u00fcsten/", "tokens": ["Du", "sogst", "den", "A\u00b7del", "nicht", "aus", "dei\u00b7ner", "Mut\u00b7ter", "Br\u00fcs\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vergebens theilt man auch nicht neue Schilde aus:", "tokens": ["Ver\u00b7ge\u00b7bens", "theilt", "man", "auch", "nicht", "neu\u00b7e", "Schil\u00b7de", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PTKNEG", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Kein solcher Zierraht k\u00f6mmt von M\u00fc\u00dfiggang und L\u00fcsten/", "tokens": ["Kein", "sol\u00b7cher", "Zier\u00b7raht", "k\u00f6mmt", "von", "M\u00fc\u00b7\u00dfig\u00b7gang", "und", "L\u00fcs\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIAT", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die Arbeit kr\u00f6nte dich/ und adelte dein Haus.", "tokens": ["Die", "Ar\u00b7beit", "kr\u00f6n\u00b7te", "dich", "/", "und", "a\u00b7del\u00b7te", "dein", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$(", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der neue Adel k\u00f6mmt durch edele Gem\u00fcther/", "tokens": ["Der", "neu\u00b7e", "A\u00b7del", "k\u00f6mmt", "durch", "e\u00b7de\u00b7le", "Ge\u00b7m\u00fc\u00b7ther", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Den alten erbet anch gar offt ein Tauge nicht.", "tokens": ["Den", "al\u00b7ten", "er\u00b7bet", "anch", "gar", "offt", "ein", "Tau\u00b7ge", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ADV", "ADV", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Dann jenes heist Verdienst/ und di\u00df sind fremde G\u00fcter/", "tokens": ["Dann", "je\u00b7nes", "heist", "Ver\u00b7dienst", "/", "und", "di\u00df", "sind", "frem\u00b7de", "G\u00fc\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "NN", "$(", "KON", "PDS", "VAFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und Lorbern/ die man leicht vom Stamm der Ahnen bricht.", "tokens": ["Und", "Lor\u00b7bern", "/", "die", "man", "leicht", "vom", "Stamm", "der", "Ah\u00b7nen", "bricht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "PRELS", "PIS", "ADJD", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Dort zeigt die Tugend sich und eigenes Geschicke/", "tokens": ["Dort", "zeigt", "die", "Tu\u00b7gend", "sich", "und", "ei\u00b7ge\u00b7nes", "Ge\u00b7schi\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PRF", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das auch der blasse Neid f\u00fcr was besonders h\u00e4lt;", "tokens": ["Das", "auch", "der", "blas\u00b7se", "Neid", "f\u00fcr", "was", "be\u00b7son\u00b7ders", "h\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "APPR", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Hier herrschet die Natur/ hier spielt das blinde Gl\u00fccke/", "tokens": ["Hier", "herr\u00b7schet", "die", "Na\u00b7tur", "/", "hier", "spielt", "das", "blin\u00b7de", "Gl\u00fc\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da offt von ungefehr der W\u00fcrffel h\u00f6her f\u00e4llt.", "tokens": ["Da", "offt", "von", "un\u00b7ge\u00b7fehr", "der", "W\u00fcrf\u00b7fel", "h\u00f6\u00b7her", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJD", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Ihr Musen-Kinder lernt den Adel so erwerben/", "tokens": ["Ihr", "Mu\u00b7sen\u00b7Kin\u00b7der", "lernt", "den", "A\u00b7del", "so", "er\u00b7wer\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und greifft die Mittel an/ die unser Grei\u00df bewehrt/", "tokens": ["Und", "greifft", "die", "Mit\u00b7tel", "an", "/", "die", "un\u00b7ser", "Grei\u00df", "be\u00b7wehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ART", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und die ihr Adlich seyd/ la\u00dft nicht die Tugend sterben;", "tokens": ["Und", "die", "ihr", "Ad\u00b7lich", "seyd", "/", "la\u00dft", "nicht", "die", "Tu\u00b7gend", "ster\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "VAFIN", "$(", "VVIMP", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dadurch der Ahnen Glantz wird immer aufgekl\u00e4hrt.", "tokens": ["Da\u00b7durch", "der", "Ah\u00b7nen", "Glantz", "wird", "im\u00b7mer", "auf\u00b7ge\u00b7kl\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ihr d\u00f6rfft ja sonst gar nicht auf fremde Federn pochen/", "tokens": ["Ihr", "d\u00f6rfft", "ja", "sonst", "gar", "nicht", "auf", "frem\u00b7de", "Fe\u00b7dern", "po\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "PTKNEG", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Die eurer Ahnen Heim auch noch so lang geziert.", "tokens": ["Die", "eu\u00b7rer", "Ah\u00b7nen", "Heim", "auch", "noch", "so", "lang", "ge\u00b7ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NE", "ADV", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Seht hie/ wie mancher wird von diesem abgestochen/", "tokens": ["Seht", "hie", "/", "wie", "man\u00b7cher", "wird", "von", "die\u00b7sem", "ab\u00b7ge\u00b7sto\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$(", "PWAV", "PIS", "VAFIN", "APPR", "PDAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Der sie nur in der Hand/ nicht auf dem Hut/ gef\u00fchrt.", "tokens": ["Der", "sie", "nur", "in", "der", "Hand", "/", "nicht", "auf", "dem", "Hut", "/", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPR", "ART", "NN", "$(", "PTKNEG", "APPR", "ART", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Zwar kan es dem Geschlecht von Jena hier nicht fehlen/", "tokens": ["Zwar", "kan", "es", "dem", "Ge\u00b7schlecht", "von", "Je\u00b7na", "hier", "nicht", "feh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "APPR", "NE", "ADV", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Es truge lang vorher/ des Adels Lorber-Blat", "tokens": ["Es", "tru\u00b7ge", "lang", "vor\u00b7her", "/", "des", "A\u00b7dels", "Lor\u00b7ber\u00b7Blat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ADV", "$(", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Nur vom Hochseeligen mu\u00df man den Adel zehlen/", "tokens": ["Nur", "vom", "Hoch\u00b7see\u00b7li\u00b7gen", "mu\u00df", "man", "den", "A\u00b7del", "zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VMFIN", "PIS", "ART", "NN", "VVINF", "$("], "meter": "+-+---+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.40": {"text": "Der auff den alten Stamm auffs neu gepfropffet hat.", "tokens": ["Der", "auff", "den", "al\u00b7ten", "Stamm", "auffs", "neu", "ge\u00b7pfropf\u00b7fet", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "APPRART", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Was durch das Schicksaal schon hat allen Safft verlohren/", "tokens": ["Was", "durch", "das", "Schick\u00b7saal", "schon", "hat", "al\u00b7len", "Safft", "ver\u00b7loh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Dem fl\u00f6st er wiederum ein neues Leben ein:", "tokens": ["Dem", "fl\u00f6st", "er", "wie\u00b7de\u00b7rum", "ein", "neu\u00b7es", "Le\u00b7ben", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Die Eltern werden selbst hiedurch wie neu gebohren/", "tokens": ["Die", "El\u00b7tern", "wer\u00b7den", "selbst", "hie\u00b7durch", "wie", "neu", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PAV", "PWAV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Die alle auch mit Ihm aufs neu gebohren seyn.", "tokens": ["Die", "al\u00b7le", "auch", "mit", "Ihm", "aufs", "neu", "ge\u00b7boh\u00b7ren", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "APPR", "PPER", "APPRART", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Die Stuffe/ worauff er sich erstens hat geschwungen/", "tokens": ["Die", "Stuf\u00b7fe", "/", "wo\u00b7rauff", "er", "sich", "ers\u00b7tens", "hat", "ge\u00b7schwun\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PWAV", "PPER", "PRF", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.46": {"text": "War ein beredter Mund/ der Sprachen Fertigkeit/", "tokens": ["War", "ein", "be\u00b7red\u00b7ter", "Mund", "/", "der", "Spra\u00b7chen", "Fer\u00b7tig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Und solche trieb er auch noch in so manchen Zungen", "tokens": ["Und", "sol\u00b7che", "trieb", "er", "auch", "noch", "in", "so", "man\u00b7chen", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Als kaum zureichen will des Menschen Lebens-Zeit.", "tokens": ["Als", "kaum", "zu\u00b7rei\u00b7chen", "will", "des", "Men\u00b7schen", "Le\u00b7bens\u00b7Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVINF", "VMFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Was Gott durch seinen Geist zu unserm Heyl geschrieben/", "tokens": ["Was", "Gott", "durch", "sei\u00b7nen", "Geist", "zu", "un\u00b7serm", "Heyl", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "APPR", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Lag Ihm ohn \u00fcbersetzt gantz unverschlossen dar:", "tokens": ["Lag", "Ihm", "ohn", "\u00fc\u00b7bers\u00b7etzt", "gantz", "un\u00b7ver\u00b7schlos\u00b7sen", "dar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Und so manch fremdes Wort hat er dabey getrieben/", "tokens": ["Und", "so", "manch", "frem\u00b7des", "Wort", "hat", "er", "da\u00b7bey", "ge\u00b7trie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "ADJA", "NN", "VAFIN", "PPER", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Das auch zu seiner Zeit fast nicht erh\u00f6ret war.", "tokens": ["Das", "auch", "zu", "sei\u00b7ner", "Zeit", "fast", "nicht", "er\u00b7h\u00f6\u00b7ret", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PPOSAT", "NN", "ADV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Frantzosen; Spanier; die R\u00f6mer und die Britten/", "tokens": ["Frant\u00b7zo\u00b7sen", ";", "Spa\u00b7nier", ";", "die", "R\u00f6\u00b7mer", "und", "die", "Brit\u00b7ten", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+----+-+-+-", "measure": "dactylic.init"}, "line.54": {"text": "Die h\u00f6rten seinen Spruch in ihren Zungen an/", "tokens": ["Die", "h\u00f6r\u00b7ten", "sei\u00b7nen", "Spruch", "in", "ih\u00b7ren", "Zun\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Den Thon/ die Artigkeit nach eines jeden Sitten/", "tokens": ["Den", "Thon", "/", "die", "Ar\u00b7tig\u00b7keit", "nach", "ei\u00b7nes", "je\u00b7den", "Sit\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "APPR", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Davon uns Regenspurg am besten zeugen kan.", "tokens": ["Da\u00b7von", "uns", "Re\u00b7gen\u00b7spurg", "am", "bes\u00b7ten", "zeu\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "NN", "PTKA", "ADJD", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und so viel L\u00e4nder hat er selbsten noch durchzogen/", "tokens": ["Und", "so", "viel", "L\u00e4n\u00b7der", "hat", "er", "selbs\u00b7ten", "noch", "durch\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Er hohlte alles/ so wie aus der ersten Hand.", "tokens": ["Er", "hohl\u00b7te", "al\u00b7les", "/", "so", "wie", "aus", "der", "ers\u00b7ten", "Hand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$(", "ADV", "KOKOM", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Er hat/ was irgend gut/ von Jedem eingesogen/", "tokens": ["Er", "hat", "/", "was", "ir\u00b7gend", "gut", "/", "von", "Je\u00b7dem", "ein\u00b7ge\u00b7so\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "PWS", "ADV", "ADJD", "$(", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Denn halb Europa war fast wie sein Vater-land.", "tokens": ["Denn", "halb", "Eu\u00b7ro\u00b7pa", "war", "fast", "wie", "sein", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NE", "VAFIN", "ADV", "KOKOM", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Doch wuste Er auch wohl/ da\u00df aller V\u00f6lcker Sprachen", "tokens": ["Doch", "wus\u00b7te", "Er", "auch", "wohl", "/", "da\u00df", "al\u00b7ler", "V\u00f6l\u00b7cker", "Spra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "$(", "KOUS", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Nur leere Zeichen seyn/ und Schalen ohne Safft/", "tokens": ["Nur", "lee\u00b7re", "Zei\u00b7chen", "seyn", "/", "und", "Scha\u00b7len", "oh\u00b7ne", "Safft", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAINF", "$(", "KON", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Die K\u00fcnste k\u00f6nnen erst geschickte Leute machen/", "tokens": ["Die", "K\u00fcns\u00b7te", "k\u00f6n\u00b7nen", "erst", "ge\u00b7schick\u00b7te", "Leu\u00b7te", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Er strebte auch darum nach solcher Wissenschafft.", "tokens": ["Er", "streb\u00b7te", "auch", "da\u00b7rum", "nach", "sol\u00b7cher", "Wis\u00b7sen\u00b7schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Geschickligkeit zum Staat beruht auf zweyen St\u00fctzen/", "tokens": ["Ge\u00b7schick\u00b7lig\u00b7keit", "zum", "Staat", "be\u00b7ruht", "auf", "zwe\u00b7yen", "St\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VVFIN", "APPR", "VVFIN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Historie und das Recht/ die machen da gelehrt:", "tokens": ["His\u00b7to\u00b7rie", "und", "das", "Recht", "/", "die", "ma\u00b7chen", "da", "ge\u00b7lehrt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "$(", "ART", "VVFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Der kan wohl sicher am geheimen Ruder sitzen/", "tokens": ["Der", "kan", "wohl", "si\u00b7cher", "am", "ge\u00b7hei\u00b7men", "Ru\u00b7der", "sit\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "ADJD", "APPRART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Der beyde innen hat/ mit zweyen Anckern f\u00e4hrt.", "tokens": ["Der", "bey\u00b7de", "in\u00b7nen", "hat", "/", "mit", "zwe\u00b7yen", "An\u00b7ckern", "f\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VAFIN", "$(", "APPR", "VVFIN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Von unserm Cantzler mu\u00df man eben dieses sagen/", "tokens": ["Von", "un\u00b7serm", "Cantz\u00b7ler", "mu\u00df", "man", "e\u00b7ben", "die\u00b7ses", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PIS", "ADV", "PDAT", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Da\u00df beyde gleich in Ihm verschwestert worden sind/", "tokens": ["Da\u00df", "bey\u00b7de", "gleich", "in", "Ihm", "ver\u00b7schwes\u00b7tert", "wor\u00b7den", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PPER", "VVPP", "VAPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Die Er wie Licht und Recht auf seiner Brust getragen/", "tokens": ["Die", "Er", "wie", "Licht", "und", "Recht", "auf", "sei\u00b7ner", "Brust", "ge\u00b7tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "KOKOM", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Darum man auch so leicht nicht seines gleichen sindt.", "tokens": ["Da\u00b7rum", "man", "auch", "so", "leicht", "nicht", "sei\u00b7nes", "glei\u00b7chen", "sindt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "ADV", "ADV", "ADJD", "PTKNEG", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Die Welt-geschichte", "tokens": ["Die", "Welt\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.74": {"text": "Der nicht im Teutschen Reich allein zu Hause war:", "tokens": ["Der", "nicht", "im", "Teut\u00b7schen", "Reich", "al\u00b7lein", "zu", "Hau\u00b7se", "war", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "APPRART", "ADJA", "NN", "ADV", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Natur und V\u00f6lcker-Recht", "tokens": ["Na\u00b7tur", "und", "V\u00f6lcker\u00b7Recht"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.76": {"text": "Das Ihm die erste Frucht zu seinem Gl\u00fcck gebahr.", "tokens": ["Das", "Ihm", "die", "ers\u00b7te", "Frucht", "zu", "sei\u00b7nem", "Gl\u00fcck", "ge\u00b7bahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Die K\u00fcnsten hatten lang schon aus der Pfaltz gefl\u00fcchtet/", "tokens": ["Die", "K\u00fcns\u00b7ten", "hat\u00b7ten", "lang", "schon", "aus", "der", "Pfaltz", "ge\u00b7fl\u00fcch\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Die Wuth gieng drey\u00dfig Jahr allein an solchem Ort.", "tokens": ["Die", "Wuth", "gieng", "drey\u00b7\u00dfig", "Jahr", "al\u00b7lein", "an", "sol\u00b7chem", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "CARD", "NN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Carl Ludwig/ Landes-F\u00fcrst/ ein Ausbund weiser Helden/", "tokens": ["Carl", "Lud\u00b7wig", "/", "Lan\u00b7des\u00b7F\u00fcrst", "/", "ein", "Aus\u00b7bund", "wei\u00b7ser", "Hel\u00b7den", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "NN", "$(", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Der sahe den Verlust mit nassen Augen an.", "tokens": ["Der", "sa\u00b7he", "den", "Ver\u00b7lust", "mit", "nas\u00b7sen", "Au\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Wenn seinen Nahmen nur uns die Geschichte melden/", "tokens": ["Wenn", "sei\u00b7nen", "Nah\u00b7men", "nur", "uns", "die", "Ge\u00b7schich\u00b7te", "mel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.82": {"text": "So wei\u00df die gantze Welt/ was dieser F\u00fcrst gethan.", "tokens": ["So", "wei\u00df", "die", "gant\u00b7ze", "Welt", "/", "was", "die\u00b7ser", "F\u00fcrst", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$(", "PWS", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Er hat die Fl\u00fcchtigen vom Elend hergeruffen/", "tokens": ["Er", "hat", "die", "Fl\u00fcch\u00b7ti\u00b7gen", "vom", "E\u00b7lend", "her\u00b7ge\u00b7ruf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Er suchte \u00fcberall gelehrte Leute auff/", "tokens": ["Er", "such\u00b7te", "\u00fc\u00b7be\u00b7rall", "ge\u00b7lehr\u00b7te", "Leu\u00b7te", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Und hierzu baute Er die alte Ehren-Stuffen/", "tokens": ["Und", "hier\u00b7zu", "bau\u00b7te", "Er", "die", "al\u00b7te", "Eh\u00b7ren\u00b7Stuf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Und gab den K\u00fcnsten auch bald wieder ihren Lauff.", "tokens": ["Und", "gab", "den", "K\u00fcns\u00b7ten", "auch", "bald", "wie\u00b7der", "ih\u00b7ren", "Lauff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Der muntre Jena war auch dahin ausersehen/", "tokens": ["Der", "mun\u00b7tre", "Je\u00b7na", "war", "auch", "da\u00b7hin", "au\u00b7ser\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "ADV", "PAV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Und zum Geschickligkeit zu solchem Werck erw\u00e4hlt/", "tokens": ["Und", "zum", "Ge\u00b7schick\u00b7lig\u00b7keit", "zu", "sol\u00b7chem", "Werck", "er\u00b7w\u00e4hlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "APPR", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Der edlen Jugend wohl in Rechten vorzustehen/", "tokens": ["Der", "ed\u00b7len", "Ju\u00b7gend", "wohl", "in", "Rech\u00b7ten", "vor\u00b7zu\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Und auch noch \u00fcber das im F\u00fcrsten-Rath gezehlt.", "tokens": ["Und", "auch", "noch", "\u00fc\u00b7ber", "das", "im", "F\u00fcrs\u00b7ten\u00b7Rath", "ge\u00b7zehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PRELS", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Er halff den ", "tokens": ["Er", "halff", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.92": {"text": "Derselben funden sich viel hundert wieder ein.", "tokens": ["Der\u00b7sel\u00b7ben", "fun\u00b7den", "sich", "viel", "hun\u00b7dert", "wie\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "CARD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Man kan mit allem Recht auch dieses von Ihm sagen/", "tokens": ["Man", "kan", "mit", "al\u00b7lem", "Recht", "auch", "die\u00b7ses", "von", "Ihm", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "APPR", "PIS", "NN", "ADV", "PDAT", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Da\u00df seiner Lehre bald viel nachgegangen seyn.", "tokens": ["Da\u00df", "sei\u00b7ner", "Leh\u00b7re", "bald", "viel", "nach\u00b7ge\u00b7gan\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Und wenn Er selbsten auch so \u00f6ffters folgen wollen/", "tokens": ["Und", "wenn", "Er", "selbs\u00b7ten", "auch", "so", "\u00f6ff\u00b7ters", "fol\u00b7gen", "wol\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ADV", "ADV", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Als man durch neuen Ruff hat seinen Dienst begehrt;", "tokens": ["Als", "man", "durch", "neu\u00b7en", "Ruff", "hat", "sei\u00b7nen", "Dienst", "be\u00b7gehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Er h\u00e4tte zehen mahl sich selber theilen sollen/", "tokens": ["Er", "h\u00e4t\u00b7te", "ze\u00b7hen", "mahl", "sich", "sel\u00b7ber", "thei\u00b7len", "sol\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "ADV", "PRF", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "So hoch war sein Geschick in Schul und Staat geehrt.", "tokens": ["So", "hoch", "war", "sein", "Ge\u00b7schick", "in", "Schul", "und", "Staat", "ge\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Nur Friedrich Wilhelm kam mit einem starcken Triebe/", "tokens": ["Nur", "Fried\u00b7rich", "Wil\u00b7helm", "kam", "mit", "ei\u00b7nem", "star\u00b7cken", "Trie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Und diesem gab Er gleich fast ohn Bedencken statt/", "tokens": ["Und", "die\u00b7sem", "gab", "Er", "gleich", "fast", "ohn", "Be\u00b7den\u00b7cken", "statt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Ihn trung des F\u00fcrsten Gnad/ Ihn trung die Bruder-liebe/", "tokens": ["Ihn", "trung", "des", "F\u00fcrs\u00b7ten", "Gnad", "/", "Ihn", "trung", "die", "Bru\u00b7der\u00b7lie\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "NN", "$(", "PPER", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Als dessen Stelle Er dadurch bekleidet hat", "tokens": ["Als", "des\u00b7sen", "Stel\u00b7le", "Er", "da\u00b7durch", "be\u00b7klei\u00b7det", "hat"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "NN", "PPER", "PAV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Und dorten ist sein Ruhm noch immer h\u00f6her kommen/", "tokens": ["Und", "dor\u00b7ten", "ist", "sein", "Ruhm", "noch", "im\u00b7mer", "h\u00f6\u00b7her", "kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Die Stelle wurde Ihm bald weiter fortger\u00fcckt;", "tokens": ["Die", "Stel\u00b7le", "wur\u00b7de", "Ihm", "bald", "wei\u00b7ter", "fort\u00b7ge\u00b7r\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Er wurde von der Schul gar in den Staat genommen/", "tokens": ["Er", "wur\u00b7de", "von", "der", "Schul", "gar", "in", "den", "Staat", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Und mit der Vollmacht sort nach Regenspurg geschickt.", "tokens": ["Und", "mit", "der", "Voll\u00b7macht", "sort", "nach", "Re\u00b7gen\u00b7spurg", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Und da fieng eben erst sein Gl\u00fccks-stern an zu steigen/", "tokens": ["Und", "da", "fi\u00b7eng", "e\u00b7ben", "erst", "sein", "Gl\u00fccks\u00b7stern", "an", "zu", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "--+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.108": {"text": "Er gab den Aeltesten auch nichts in Stimmen nach:", "tokens": ["Er", "gab", "den", "A\u00b7el\u00b7tes\u00b7ten", "auch", "nichts", "in", "Stim\u00b7men", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PIS", "APPR", "NN", "APPR", "$."], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.109": {"text": "Da kont Er sein Talent in vollen Kr\u00e4fften zeigen/", "tokens": ["Da", "kont", "Er", "sein", "Ta\u00b7lent", "in", "vol\u00b7len", "Kr\u00e4ff\u00b7ten", "zei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Das offt der andern Schlu\u00df durch guten Grund zerbrach.", "tokens": ["Das", "offt", "der", "an\u00b7dern", "Schlu\u00df", "durch", "gu\u00b7ten", "Grund", "zer\u00b7brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Er durffte nicht erst lang die W\u00f6rter Rade brechen/", "tokens": ["Er", "durff\u00b7te", "nicht", "erst", "lang", "die", "W\u00f6r\u00b7ter", "Ra\u00b7de", "bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "ADJD", "ART", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Ihm flossen Str\u00f6hme wei\u00df die Reden aus dem Mund.", "tokens": ["Ihm", "flos\u00b7sen", "Str\u00f6h\u00b7me", "wei\u00df", "die", "Re\u00b7den", "aus", "dem", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Mit jedem konte Er in seiner Zungen sprechen/", "tokens": ["Mit", "je\u00b7dem", "kon\u00b7te", "Er", "in", "sei\u00b7ner", "Zun\u00b7gen", "spre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Und stifftete damit so manch vertrauten Bund.", "tokens": ["Und", "stiff\u00b7te\u00b7te", "da\u00b7mit", "so", "manch", "ver\u00b7trau\u00b7ten", "Bund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Und was Er schrifftlich in dem Rath nur eingegeben/", "tokens": ["Und", "was", "Er", "schrifft\u00b7lich", "in", "dem", "Rath", "nur", "ein\u00b7ge\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADJD", "APPR", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Das sah f\u00fcr Rennligkeit wie ausgemahlet aus/", "tokens": ["Das", "sah", "f\u00fcr", "Renn\u00b7lig\u00b7keit", "wie", "aus\u00b7ge\u00b7mah\u00b7let", "aus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "KOKOM", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Die Sachen; W\u00f6rter; Schrifft und alles hatte Leben/", "tokens": ["Die", "Sa\u00b7chen", ";", "W\u00f6r\u00b7ter", ";", "Schrifft", "und", "al\u00b7les", "hat\u00b7te", "Le\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "NN", "$.", "NN", "KON", "PIS", "VAFIN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Er brachte darum auch so manchen Schlu\u00df nach Hau\u00df/", "tokens": ["Er", "brach\u00b7te", "da\u00b7rum", "auch", "so", "man\u00b7chen", "Schlu\u00df", "nach", "Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "ADV", "PIAT", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Der sonst unm\u00f6glich schien/ die allerschwerste Sachen/", "tokens": ["Der", "sonst", "un\u00b7m\u00f6g\u00b7lich", "schien", "/", "die", "al\u00b7ler\u00b7schwers\u00b7te", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Die man vorhero schon f\u00fcr halb verlohren gab/", "tokens": ["Die", "man", "vor\u00b7he\u00b7ro", "schon", "f\u00fcr", "halb", "ver\u00b7loh\u00b7ren", "gab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADV", "APPR", "ADJD", "VVPP", "VVFIN", "$("], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.121": {"text": "Die kunten doch sein Mund und Feder m\u00f6glich machen/", "tokens": ["Die", "kun\u00b7ten", "doch", "sein", "Mund", "und", "Fe\u00b7der", "m\u00f6g\u00b7lich", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PPOSAT", "NN", "KON", "NN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Er that in kurtzer Zeit die gr\u00f6sten Dinge ab.", "tokens": ["Er", "that", "in", "kurt\u00b7zer", "Zeit", "die", "gr\u00f6s\u00b7ten", "Din\u00b7ge", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Er hat auch nicht allein da eine Stell gezieret/", "tokens": ["Er", "hat", "auch", "nicht", "al\u00b7lein", "da", "ei\u00b7ne", "Stell", "ge\u00b7zie\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADV", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Von D\u00e4nnemarck; Chur-Pfaltz; Chur-Sachsen und Bayreuth;", "tokens": ["Von", "D\u00e4n\u00b7ne\u00b7marck", ";", "Chur\u00b7Pfaltz", ";", "Chur\u00b7Sach\u00b7sen", "und", "Bay\u00b7reuth", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$.", "NE", "$.", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.125": {"text": "Von Anspach; Nassau hatt Er auch die Stimm gef\u00fchret", "tokens": ["Von", "An\u00b7spach", ";", "Nas\u00b7sau", "hatt", "Er", "auch", "die", "Stimm", "ge\u00b7f\u00fch\u00b7ret"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$.", "NE", "VAFIN", "PPER", "ADV", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Daf\u00fcr nicht mir ein Land Ihm Lorbern hat gestreut.", "tokens": ["Da\u00b7f\u00fcr", "nicht", "mir", "ein", "Land", "Ihm", "Lor\u00b7bern", "hat", "ge\u00b7streut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKNEG", "PPER", "ART", "NN", "PPER", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Ja seine Klugheit gab von sich so starcke Blicke/", "tokens": ["Ja", "sei\u00b7ne", "Klug\u00b7heit", "gab", "von", "sich", "so", "star\u00b7cke", "Bli\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPOSAT", "NN", "VVFIN", "APPR", "PRF", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Von Franckreich selbsten war di\u00df Urtheil dort gef\u00e4lt/", "tokens": ["Von", "Fran\u00b7ck\u00b7reich", "selbs\u00b7ten", "war", "di\u00df", "Ur\u00b7theil", "dort", "ge\u00b7f\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VAFIN", "PDS", "NN", "ADV", "VVPP", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.129": {"text": "Es h\u00e4tte Jena weit f\u00fcr anderen Geschicke/", "tokens": ["Es", "h\u00e4t\u00b7te", "Je\u00b7na", "weit", "f\u00fcr", "an\u00b7de\u00b7ren", "Ge\u00b7schi\u00b7cke", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "ADJD", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "Die man zum Reichs-", "tokens": ["Die", "man", "zum", "Reichs"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIS", "APPRART", "TRUNC"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.131": {"text": "Noch Spanien und ja auch selbst der gro\u00dfe K\u00e4yser/", "tokens": ["Noch", "Spa\u00b7ni\u00b7en", "und", "ja", "auch", "selbst", "der", "gro\u00b7\u00dfe", "K\u00e4y\u00b7ser", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KON", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Die seine Redligkeit erst nach der Zeit erkant", "tokens": ["Die", "sei\u00b7ne", "Red\u00b7lig\u00b7keit", "erst", "nach", "der", "Zeit", "er\u00b7kant"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Die g\u00f6nnen Ihm den Ruhm und alle Ehren-Reiser", "tokens": ["Die", "g\u00f6n\u00b7nen", "Ihm", "den", "Ruhm", "und", "al\u00b7le", "Eh\u00b7ren\u00b7Rei\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "PPER", "ART", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Der Dienste/ welche Er f\u00fcr Teutschland angewandt.", "tokens": ["Der", "Diens\u00b7te", "/", "wel\u00b7che", "Er", "f\u00fcr", "Teutschland", "an\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "APPR", "NE", "VVPP", "$."], "meter": "-+-+----+-+", "measure": "unknown.measure.tetra"}, "line.135": {"text": "Er h\u00f6rte damahls schon am Rhein den Himmel blitzen;", "tokens": ["Er", "h\u00f6r\u00b7te", "da\u00b7mahls", "schon", "am", "Rhein", "den", "Him\u00b7mel", "blit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NE", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Das Wetter/ das hernach erst ausgebrochen ist:", "tokens": ["Das", "Wet\u00b7ter", "/", "das", "her\u00b7nach", "erst", "aus\u00b7ge\u00b7bro\u00b7chen", "ist", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PDS", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Sein Rath war: wenn uns nicht daf\u00fcr Armeen sch\u00fctzen/", "tokens": ["Sein", "Rath", "war", ":", "wenn", "uns", "nicht", "da\u00b7f\u00fcr", "Ar\u00b7me\u00b7en", "sch\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "$.", "KOUS", "PPER", "PTKNEG", "PAV", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.138": {"text": "So kriegt kein Kluger nicht. Der sucht des Feindes List", "tokens": ["So", "kriegt", "kein", "Klu\u00b7ger", "nicht", ".", "Der", "sucht", "des", "Fein\u00b7des", "List"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "PTKNEG", "$.", "ART", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Vielmehr durch Frieden und durch Unschuld zu besch\u00e4men;", "tokens": ["Viel\u00b7mehr", "durch", "Frie\u00b7den", "und", "durch", "Un\u00b7schuld", "zu", "be\u00b7sch\u00e4\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Und f\u00e4llt das Land denn weg; bleibt doch das Recht darauf.", "tokens": ["Und", "f\u00e4llt", "das", "Land", "denn", "weg", ";", "bleibt", "doch", "das", "Recht", "da\u00b7rauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "PTKVZ", "$.", "VVFIN", "ADV", "ART", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Auch den wir itzo nicht verm\u00f6gend sind zu z\u00e4hmen/", "tokens": ["Auch", "den", "wir", "it\u00b7zo", "nicht", "ver\u00b7m\u00f6\u00b7gend", "sind", "zu", "z\u00e4h\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "ADV", "PTKNEG", "VVPP", "VAFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Dem \u00e4ndert sich das Gl\u00fcck offt mit der Zeiten Lauff.", "tokens": ["Dem", "\u00e4n\u00b7dert", "sich", "das", "Gl\u00fcck", "offt", "mit", "der", "Zei\u00b7ten", "Lauff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "NN", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Und was ists? Teutschland ach! du hast es ja erfahren/", "tokens": ["Und", "was", "ists", "?", "Teutschland", "ach", "!", "du", "hast", "es", "ja", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "$.", "NN", "ITJ", "$.", "PPER", "VAFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.144": {"text": "Was dein gerechter Krieg vor Nutzen hat gebracht.", "tokens": ["Was", "dein", "ge\u00b7rech\u00b7ter", "Krieg", "vor", "Nut\u00b7zen", "hat", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Du kuntest nicht einmahl das \u00fcbrige bewahren/", "tokens": ["Du", "kun\u00b7test", "nicht", "ein\u00b7mahl", "das", "\u00fcb\u00b7ri\u00b7ge", "be\u00b7wah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "ART", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Worauf den Anspruch dir kein Feind je hat gemacht.", "tokens": ["Wo\u00b7rauf", "den", "An\u00b7spruch", "dir", "kein", "Feind", "je", "hat", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "PIAT", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Du hast vor St\u00e4dte ietzt viel tausend Aschen-hauffen;", "tokens": ["Du", "hast", "vor", "St\u00e4d\u00b7te", "ietzt", "viel", "tau\u00b7send", "A\u00b7schen\u00b7hauf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "ADV", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Vor so viel tausend Mann so manche Leiche stehn.", "tokens": ["Vor", "so", "viel", "tau\u00b7send", "Mann", "so", "man\u00b7che", "Lei\u00b7che", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "CARD", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Di\u00df hei\u00dft den Frieden ja zur Unzeit theuer kauffen.", "tokens": ["Di\u00df", "hei\u00dft", "den", "Frie\u00b7den", "ja", "zur", "Un\u00b7zeit", "theu\u00b7er", "kauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "Sag jetzt/ ob Jena nicht di\u00df schon vorher gesehn?", "tokens": ["Sag", "jetzt", "/", "ob", "Je\u00b7na", "nicht", "di\u00df", "schon", "vor\u00b7her", "ge\u00b7sehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$(", "KOUS", "NE", "PTKNEG", "PDS", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Nur Neid und Unverstand pflag seinen Rath zu schelten/", "tokens": ["Nur", "Neid", "und", "Un\u00b7ver\u00b7stand", "pflag", "sei\u00b7nen", "Rath", "zu", "schel\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Von jenem war auch wohl ein Argwohn noch erregt:", "tokens": ["Von", "je\u00b7nem", "war", "auch", "wohl", "ein", "Arg\u00b7wohn", "noch", "er\u00b7regt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VAFIN", "ADV", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "Jetzt last ihr solchen gern mit euren Schaden gelten/", "tokens": ["Jetzt", "last", "ihr", "sol\u00b7chen", "gern", "mit", "eu\u00b7ren", "Scha\u00b7den", "gel\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIAT", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Seht/ wie Verl\u00e4umdung sich nun selbsten niederschl\u00e4gt.", "tokens": ["Seht", "/", "wie", "Ver\u00b7l\u00e4um\u00b7dung", "sich", "nun", "selbs\u00b7ten", "nie\u00b7der\u00b7schl\u00e4gt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "NN", "PRF", "ADV", "ADV", "VVFIN", "$."], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.155": {"text": "Indessen wird dein Ruhm/ Hochseeliger verj\u00fcnget/", "tokens": ["In\u00b7des\u00b7sen", "wird", "dein", "Ruhm", "/", "Hoch\u00b7see\u00b7li\u00b7ger", "ver\u00b7j\u00fcn\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "$(", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Da\u00df dich kein feines Gold jemahlen hatt verblendt:", "tokens": ["Da\u00df", "dich", "kein", "fei\u00b7nes", "Gold", "je\u00b7mah\u00b7len", "hatt", "ver\u00b7blendt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJA", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Da dieser Ausgang schon f\u00fcr deine Unschuld ringet/", "tokens": ["Da", "die\u00b7ser", "Aus\u00b7gang", "schon", "f\u00fcr", "dei\u00b7ne", "Un\u00b7schuld", "rin\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Der solchen Vorwurff nun auch f\u00fcr Verl\u00e4umdung sch\u00e4ndt.", "tokens": ["Der", "sol\u00b7chen", "Vor\u00b7wurff", "nun", "auch", "f\u00fcr", "Ver\u00b7l\u00e4um\u00b7dung", "sch\u00e4ndt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "Die Nachwelt wird dich stets f\u00fcr deine Treue loben;", "tokens": ["Die", "Nach\u00b7welt", "wird", "dich", "stets", "f\u00fcr", "dei\u00b7ne", "Treu\u00b7e", "lo\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Und Brandenburg wei\u00df wohl/ wie du Ihm hast gedient.", "tokens": ["Und", "Bran\u00b7den\u00b7burg", "wei\u00df", "wohl", "/", "wie", "du", "Ihm", "hast", "ge\u00b7dient", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "$(", "PWAV", "PPER", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Es hat ja viertzig Jahr gantz unverr\u00fcckte Proben;", "tokens": ["Es", "hat", "ja", "viert\u00b7zig", "Jahr", "gantz", "un\u00b7ver\u00b7r\u00fcck\u00b7te", "Pro\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "CARD", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.162": {"text": "Seit dir an diesem Hoff die erste Frucht gegr\u00fcnt.", "tokens": ["Seit", "dir", "an", "die\u00b7sem", "Hoff", "die", "ers\u00b7te", "Frucht", "ge\u00b7gr\u00fcnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "PDAT", "VVFIN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Nur Magdeburg du bist am meisten Dem verbunden;", "tokens": ["Nur", "Mag\u00b7de\u00b7burg", "du", "bist", "am", "meis\u00b7ten", "Dem", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PPER", "VAFIN", "PTKA", "PIAT", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Der sich f\u00fcr deinen Staat auch lang vorher bem\u00fcht.", "tokens": ["Der", "sich", "f\u00fcr", "dei\u00b7nen", "Staat", "auch", "lang", "vor\u00b7her", "be\u00b7m\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "PPOSAT", "NN", "ADV", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Eh Jena noch bey dir sich w\u00fcrcklich eingefunden?", "tokens": ["Eh", "Je\u00b7na", "noch", "bey", "dir", "sich", "w\u00fcrck\u00b7lich", "ein\u00b7ge\u00b7fun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "APPR", "PPER", "PRF", "ADJD", "VVPP", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.166": {"text": "Eh Er die Cantzeley als Oberhaupt bezieht:", "tokens": ["Eh", "Er", "die", "Cant\u00b7ze\u00b7ley", "als", "O\u00b7ber\u00b7haupt", "be\u00b7zieht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "KOUS", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.167": {"text": "So muste Er dich schon in einer Sache sch\u00fctzen/", "tokens": ["So", "mus\u00b7te", "Er", "dich", "schon", "in", "ei\u00b7ner", "Sa\u00b7che", "sch\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Daran die W\u00fcrdigkeit des gantzen Landes hieng.", "tokens": ["Da\u00b7ran", "die", "W\u00fcr\u00b7dig\u00b7keit", "des", "gant\u00b7zen", "Lan\u00b7des", "hieng", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Man glaubte/ da\u00df du noch solltst auff der Over-Banck sitzen;", "tokens": ["Man", "glaub\u00b7te", "/", "da\u00df", "du", "noch", "solltst", "auff", "der", "O\u00b7ver\u00b7Banck", "sit\u00b7zen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "KOUS", "PPER", "ADV", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-++-", "measure": "unknown.measure.septa"}, "line.170": {"text": "Als schon Chur-Brandenburg von dir Pflicht empfieng.", "tokens": ["Als", "schon", "Chur\u00b7Bran\u00b7den\u00b7burg", "von", "dir", "Pflicht", "emp\u00b7fi\u00b7eng", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "APPR", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.171": {"text": "Die meiste fiengen an schon hin und her zu wancken;", "tokens": ["Die", "meis\u00b7te", "fi\u00b7en\u00b7gen", "an", "schon", "hin", "und", "her", "zu", "wan\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "APPR", "ADV", "PTKVZ", "KON", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.172": {"text": "Nur Jena war behertzt/ und st\u00fctzte solche Last/", "tokens": ["Nur", "Je\u00b7na", "war", "be\u00b7hertzt", "/", "und", "st\u00fctz\u00b7te", "sol\u00b7che", "Last", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "ADJD", "$(", "KON", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Dem hast du es auch noch in seiner Grufft zu dancken/", "tokens": ["Dem", "hast", "du", "es", "auch", "noch", "in", "sei\u00b7ner", "Grufft", "zu", "dan\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Da\u00df Er die Oberstell mit tapffrer Faust gefast", "tokens": ["Da\u00df", "Er", "die", "O\u00b7bers\u00b7tell", "mit", "tapf\u00b7frer", "Faust", "ge\u00b7fast"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Und als Er einmahl sich da mit Gewalt gesetzet;", "tokens": ["Und", "als", "Er", "ein\u00b7mahl", "sich", "da", "mit", "Ge\u00b7walt", "ge\u00b7set\u00b7zet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PRF", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "So stellte Er sein Recht mit solchen Kr\u00e4fften vor/", "tokens": ["So", "stell\u00b7te", "Er", "sein", "Recht", "mit", "sol\u00b7chen", "Kr\u00e4ff\u00b7ten", "vor", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Da\u00df jeder diesen Grei\u00df der Stelle werth gesch\u00e4tzet/", "tokens": ["Da\u00df", "je\u00b7der", "die\u00b7sen", "Grei\u00df", "der", "Stel\u00b7le", "werth", "ge\u00b7sch\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PDAT", "NN", "ART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Und sich der Gegentheil auch nach und nach verlohr.", "tokens": ["Und", "sich", "der", "Ge\u00b7gen\u00b7theil", "auch", "nach", "und", "nach", "ver\u00b7lohr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "NN", "ADV", "APPR", "KON", "APPR", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Und dieses heist im Sturm mit klugem Ruder schiffen/", "tokens": ["Und", "die\u00b7ses", "heist", "im", "Sturm", "mit", "klu\u00b7gem", "Ru\u00b7der", "schif\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "APPRART", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Wenn man der Winde schon und Klippen ist gewohnt:", "tokens": ["Wenn", "man", "der", "Win\u00b7de", "schon", "und", "Klip\u00b7pen", "ist", "ge\u00b7wohnt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "KON", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Die\u00df hei\u00dft den Rathschlag aus dem Stegereiff ergriffen;", "tokens": ["Die\u00df", "hei\u00dft", "den", "Rath\u00b7schlag", "aus", "dem", "Ste\u00b7ge\u00b7reiff", "er\u00b7grif\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Und bey dem klaren Recht der Menschen nicht geschont.", "tokens": ["Und", "bey", "dem", "kla\u00b7ren", "Recht", "der", "Men\u00b7schen", "nicht", "ge\u00b7schont", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.183": {"text": "Ein andrer h\u00e4tte sich hier zehen mahl verlauffen/", "tokens": ["Ein", "an\u00b7drer", "h\u00e4t\u00b7te", "sich", "hier", "ze\u00b7hen", "mahl", "ver\u00b7lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "PRF", "ADV", "CARD", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Und seine Seiten erst so viele Jahr gestimmt/", "tokens": ["Und", "sei\u00b7ne", "Sei\u00b7ten", "erst", "so", "vie\u00b7le", "Jahr", "ge\u00b7stimmt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "ADV", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Ein andrer seinen Rath zu Hoffe m\u00fcsse kauffen;", "tokens": ["Ein", "an\u00b7drer", "sei\u00b7nen", "Rath", "zu", "Hof\u00b7fe", "m\u00fcs\u00b7se", "kauf\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPOSAT", "NN", "APPR", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Nur Er ists/ der den Pfeil aus eignem K\u00f6cher nimmt.", "tokens": ["Nur", "Er", "ists", "/", "der", "den", "Pfeil", "aus", "eig\u00b7nem", "K\u00f6\u00b7cher", "nimmt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "$(", "ART", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Noch/ als den Wohnplatz Er in dieses Land verleget/", "tokens": ["Noch", "/", "als", "den", "Wohn\u00b7platz", "Er", "in", "die\u00b7ses", "Land", "ver\u00b7le\u00b7get", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "ART", "NN", "PPER", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.188": {"text": "Das nun durch Ihn so hoch f\u00fcr vielen H\u00e4usern sitzt/", "tokens": ["Das", "nun", "durch", "Ihn", "so", "hoch", "f\u00fcr", "vie\u00b7len", "H\u00e4u\u00b7sern", "sitzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PPER", "ADV", "ADJD", "APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.189": {"text": "Mit was f\u00fcr Liebe hat Er gro\u00df und klein geheget/", "tokens": ["Mit", "was", "f\u00fcr", "Lie\u00b7be", "hat", "Er", "gro\u00df", "und", "klein", "ge\u00b7he\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.190": {"text": "Und die Bedr\u00e4ngete in ihrer Noth gesch\u00fctzt.", "tokens": ["Und", "die", "Be\u00b7dr\u00e4n\u00b7ge\u00b7te", "in", "ih\u00b7rer", "Noth", "ge\u00b7sch\u00fctzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.191": {"text": "Die Aendrung schiene zwar fast ungleich auszusehen;", "tokens": ["Die", "A\u00b7en\u00b7drung", "schie\u00b7ne", "zwar", "fast", "un\u00b7gleich", "aus\u00b7zu\u00b7se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.192": {"text": "Dort war ein Theil der Welt/ und hier ein eintzig Land;", "tokens": ["Dort", "war", "ein", "Theil", "der", "Welt", "/", "und", "hier", "ein", "eint\u00b7zig", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$(", "KON", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Dort stritten K\u00f6nige/ hier sah Er B\u00fcrger stehen;", "tokens": ["Dort", "strit\u00b7ten", "K\u00f6\u00b7ni\u00b7ge", "/", "hier", "sah", "Er", "B\u00fcr\u00b7ger", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$(", "ADV", "VVFIN", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Dort galte die Vernunfft/ hier offt des Sch\u00f6pffen Hand.", "tokens": ["Dort", "gal\u00b7te", "die", "Ver\u00b7nunfft", "/", "hier", "offt", "des", "Sch\u00f6pf\u00b7fen", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Jedoch Ihn mochte nicht Wechsel irre machen/", "tokens": ["Je\u00b7doch", "Ihn", "moch\u00b7te", "nicht", "Wech\u00b7sel", "ir\u00b7re", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "PTKNEG", "NN", "NN", "VVINF", "$("], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.196": {"text": "Die Tugend wurde auch durch die Gesch\u00e4fften kund.", "tokens": ["Die", "Tu\u00b7gend", "wur\u00b7de", "auch", "durch", "die", "Ge\u00b7sch\u00e4ff\u00b7ten", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Denn wer ein Schiff regiert/ f\u00fchrt leichtlich auch den Nachen:", "tokens": ["Denn", "wer", "ein", "Schiff", "re\u00b7giert", "/", "f\u00fchrt", "leicht\u00b7lich", "auch", "den", "Na\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$(", "VVFIN", "ADJD", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer einen Zentner tr\u00e4gt/ der h\u00e4lt auch wohl ein Pfund.", "tokens": ["Wer", "ei\u00b7nen", "Zent\u00b7ner", "tr\u00e4gt", "/", "der", "h\u00e4lt", "auch", "wohl", "ein", "Pfund", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$(", "ART", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Land war Brandenburg so gleich nur angestorben/", "tokens": ["Das", "Land", "war", "Bran\u00b7den\u00b7burg", "so", "gleich", "nur", "an\u00b7ge\u00b7stor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "ADV", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und Er am ersten gleich demselben f\u00fcrgesetzt.", "tokens": ["Und", "Er", "am", "ers\u00b7ten", "gleich", "dem\u00b7sel\u00b7ben", "f\u00fcr\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "ADJA", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Offt wird auch selbsten/ was man noch so leicht erworben/", "tokens": ["Offt", "wird", "auch", "selbs\u00b7ten", "/", "was", "man", "noch", "so", "leicht", "er\u00b7wor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "$(", "PWS", "PIS", "ADV", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Durch \u00fcbles Regiment im Amfang gleich verletzt.", "tokens": ["Durch", "\u00fcb\u00b7les", "Re\u00b7gi\u00b7ment", "im", "Am\u00b7fang", "gleich", "ver\u00b7letzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es kostet manchen Rath/ bi\u00df man die Unterthanen", "tokens": ["Es", "kos\u00b7tet", "man\u00b7chen", "Rath", "/", "bi\u00df", "man", "die", "Un\u00b7ter\u00b7tha\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$(", "KOUS", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dein neuen Landes Herrn nach seinem Staat gewehnt/", "tokens": ["Dein", "neu\u00b7en", "Lan\u00b7des", "Herrn", "nach", "sei\u00b7nem", "Staat", "ge\u00b7wehnt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Wege lassen sich durch Ungest\u00fcm nicht bahnen/", "tokens": ["Die", "We\u00b7ge", "las\u00b7sen", "sich", "durch", "Un\u00b7ge\u00b7st\u00fcm", "nicht", "bah\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil sonst der B\u00fcrger sich nach alter Herrschafft sehnt.", "tokens": ["Weil", "sonst", "der", "B\u00fcr\u00b7ger", "sich", "nach", "al\u00b7ter", "Herr\u00b7schafft", "sehnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Drum solte Jena auch zuerst das Ruder halten;", "tokens": ["Drum", "sol\u00b7te", "Je\u00b7na", "auch", "zu\u00b7erst", "das", "Ru\u00b7der", "hal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "NE", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bi\u00df sich das gantze Werck in Fug und Band geschickt.", "tokens": ["Bi\u00df", "sich", "das", "gant\u00b7ze", "Werck", "in", "Fug", "und", "Band", "ge\u00b7schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hernach l\u00e4\u00dft sich der Staat mit halber M\u00fch verwalten/", "tokens": ["Her\u00b7nach", "l\u00e4\u00dft", "sich", "der", "Staat", "mit", "hal\u00b7ber", "M\u00fch", "ver\u00b7wal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wie man ein Uhrwerck leicht auff andre Stunden r\u00fcckt.", "tokens": ["Wie", "man", "ein", "Uhr\u00b7werck", "leicht", "auff", "and\u00b7re", "Stun\u00b7den", "r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wer will dem Seeligen doch diese Ehre streiten/", "tokens": ["Wer", "will", "dem", "See\u00b7li\u00b7gen", "doch", "die\u00b7se", "Eh\u00b7re", "strei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "ADV", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df Er die St\u00e4be mit Behutsamkeit gef\u00fchrt/", "tokens": ["Da\u00df", "Er", "die", "St\u00e4\u00b7be", "mit", "Be\u00b7hut\u00b7sam\u00b7keit", "ge\u00b7f\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Flei\u00df; Treue; Freundlichkeit die stehen Ihm zur Seiten/", "tokens": ["Flei\u00df", ";", "Treu\u00b7e", ";", "Freund\u00b7lich\u00b7keit", "die", "ste\u00b7hen", "Ihm", "zur", "Sei\u00b7ten", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "$.", "NN", "ART", "VVFIN", "PPER", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dadurch jetzt mancher wird durch seinen Tod ger\u00fchrt.", "tokens": ["Da\u00b7durch", "jetzt", "man\u00b7cher", "wird", "durch", "sei\u00b7nen", "Tod", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "PIS", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "In funffzehn Jahren hat er keinen Tag vers\u00e4umet/", "tokens": ["In", "funff\u00b7zehn", "Jah\u00b7ren", "hat", "er", "kei\u00b7nen", "Tag", "ver\u00b7s\u00e4u\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "PPER", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Er kam nie eine Stund zu sp\u00e4th ins Regiment:", "tokens": ["Er", "kam", "nie", "ei\u00b7ne", "Stund", "zu", "sp\u00e4th", "ins", "Re\u00b7gi\u00b7ment", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PTKZU", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Zu seiner Arbeit hat er t\u00e4glich auffger\u00e4umet/", "tokens": ["Zu", "sei\u00b7ner", "Ar\u00b7beit", "hat", "er", "t\u00e4g\u00b7lich", "auff\u00b7ge\u00b7r\u00e4u\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und keine Uberschrifft von ihrer Zeit getrennt.", "tokens": ["Und", "kei\u00b7ne", "U\u00b7ber\u00b7schrifft", "von", "ih\u00b7rer", "Zeit", "ge\u00b7trennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Bey vielem Uberlauff war er doch unverdrossen;", "tokens": ["Bey", "vie\u00b7lem", "U\u00b7berl\u00b7auff", "war", "er", "doch", "un\u00b7ver\u00b7dros\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und jederman bekam von Ihm ein gutes Wort:", "tokens": ["Und", "je\u00b7der\u00b7man", "be\u00b7kam", "von", "Ihm", "ein", "gu\u00b7tes", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Er hat dem Aermsten auch die Th\u00fcre nicht verschlossen/", "tokens": ["Er", "hat", "dem", "A\u00b7erms\u00b7ten", "auch", "die", "Th\u00fc\u00b7re", "nicht", "ver\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Es war sein gantzes Hau\u00df ein allgemeiner Port/", "tokens": ["Es", "war", "sein", "gant\u00b7zes", "Hau\u00df", "ein", "all\u00b7ge\u00b7mei\u00b7ner", "Port", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Da Schiffe hin und her frey durch einander lauffen/", "tokens": ["Da", "Schif\u00b7fe", "hin", "und", "her", "frey", "durch", "ein\u00b7an\u00b7der", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKVZ", "KON", "ADV", "ADJD", "APPR", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Da sich der Zollstock nicht an einer Ecken zeigt.", "tokens": ["Da", "sich", "der", "Zoll\u00b7stock", "nicht", "an", "ei\u00b7ner", "E\u00b7cken", "zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Man durfft den Zutritt nicht von seinen Dienern kauffen/", "tokens": ["Man", "durfft", "den", "Zu\u00b7tritt", "nicht", "von", "sei\u00b7nen", "Die\u00b7nern", "kauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Dann anzumelden war ein jeder schon geneigt.", "tokens": ["Dann", "an\u00b7zu\u00b7mel\u00b7den", "war", "ein", "je\u00b7der", "schon", "ge\u00b7neigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIZU", "VAFIN", "ART", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Er selbsten hielt die Hand von Gaben unbeflecket/", "tokens": ["Er", "selbs\u00b7ten", "hielt", "die", "Hand", "von", "Ga\u00b7ben", "un\u00b7be\u00b7fle\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und seine treue Brust war von Geschencken frey;", "tokens": ["Und", "sei\u00b7ne", "treu\u00b7e", "Brust", "war", "von", "Ge\u00b7schen\u00b7cken", "frey", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VAFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Auff seinem Lager hatt Ihm dieses Trost erwecket;", "tokens": ["Auff", "sei\u00b7nem", "La\u00b7ger", "hatt", "Ihm", "die\u00b7ses", "Trost", "er\u00b7we\u00b7cket", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Da\u00df unter seinem Gut nichts ungerechtes sey.", "tokens": ["Da\u00df", "un\u00b7ter", "sei\u00b7nem", "Gut", "nichts", "un\u00b7ge\u00b7rech\u00b7tes", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PIS", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Sein Seegen kam allein nur durch des Herren G\u00fcte/", "tokens": ["Sein", "See\u00b7gen", "kam", "al\u00b7lein", "nur", "durch", "des", "Her\u00b7ren", "G\u00fc\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Der H\u00f6chste legte Ihm noch gr\u00f6\u00dfre Gnade zu;", "tokens": ["Der", "H\u00f6chs\u00b7te", "leg\u00b7te", "Ihm", "noch", "gr\u00f6\u00df\u00b7re", "Gna\u00b7de", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ein hohes Alterthum; ein fr\u00f6liches Gem\u00fcthe;", "tokens": ["Ein", "ho\u00b7hes", "Al\u00b7ter\u00b7thum", ";", "ein", "fr\u00f6\u00b7li\u00b7ches", "Ge\u00b7m\u00fc\u00b7the", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Gesunde Leibes-Krafft und die Gewissens-Ruh.", "tokens": ["Ge\u00b7sun\u00b7de", "Lei\u00b7bes\u00b7Krafft", "und", "die", "Ge\u00b7wis\u00b7sens\u00b7Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "In Sechzig Jahren ist der Meisten Zeit vergangen/", "tokens": ["In", "Sech\u00b7zig", "Jah\u00b7ren", "ist", "der", "Meis\u00b7ten", "Zeit", "ver\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Und Siebenzig wird kaum von tausenden erreicht;", "tokens": ["Und", "Sie\u00b7ben\u00b7zig", "wird", "kaum", "von", "tau\u00b7sen\u00b7den", "er\u00b7reicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADV", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Er hatt das Achtzigste auch w\u00fcrcklich angefangen/", "tokens": ["Er", "hatt", "das", "Acht\u00b7zigs\u00b7te", "auch", "w\u00fcrck\u00b7lich", "an\u00b7ge\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Und bi\u00df in seine Grufft dem J\u00fcngling fast gegleicht.", "tokens": ["Und", "bi\u00df", "in", "sei\u00b7ne", "Grufft", "dem", "J\u00fcng\u00b7ling", "fast", "ge\u00b7gleicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Die Haare waren dicht; die Augen Sonnen helle", "tokens": ["Die", "Haa\u00b7re", "wa\u00b7ren", "dicht", ";", "die", "Au\u00b7gen", "Son\u00b7nen", "hel\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "ART", "NN", "NN", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Die Wangen Rosen roth; die Adern noch voll Blut;", "tokens": ["Die", "Wan\u00b7gen", "Ro\u00b7sen", "roth", ";", "die", "A\u00b7dern", "noch", "voll", "Blut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "$.", "ART", "NN", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Die Beine gar nicht steiff; der Fu\u00df an seiner Stelle;", "tokens": ["Die", "Bei\u00b7ne", "gar", "nicht", "steiff", ";", "der", "Fu\u00df", "an", "sei\u00b7ner", "Stel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "VVFIN", "$.", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Der R\u00fccken nicht gekr\u00fcmmt; die Knochen fest und gut;", "tokens": ["Der", "R\u00fc\u00b7cken", "nicht", "ge\u00b7kr\u00fcmmt", ";", "die", "Kno\u00b7chen", "fest", "und", "gut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVPP", "$.", "ART", "NN", "PTKVZ", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Die Brust gieng nicht beklemmt; der Athem ohne Keichen;", "tokens": ["Die", "Brust", "gieng", "nicht", "be\u00b7klemmt", ";", "der", "A\u00b7them", "oh\u00b7ne", "Kei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "VVFIN", "$.", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Der Pul\u00df hielt seinen Schlag; der Lebens-Geist war frey;", "tokens": ["Der", "Pul\u00df", "hielt", "sei\u00b7nen", "Schlag", ";", "der", "Le\u00b7bens\u00b7Geist", "war", "frey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Die Sinnen stets bey sich: man sahe nicht ein Zeichen/", "tokens": ["Die", "Sin\u00b7nen", "stets", "bey", "sich", ":", "man", "sa\u00b7he", "nicht", "ein", "Zei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PRF", "$.", "PIS", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Da\u00df dieser muntre Leib bey achtzig Jahren sey.", "tokens": ["Da\u00df", "die\u00b7ser", "mun\u00b7tre", "Leib", "bey", "acht\u00b7zig", "Jah\u00b7ren", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "ADJA", "NN", "APPR", "CARD", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Sein Hertz hat Ihm kein Wurm vor Unmuth abgezehret/", "tokens": ["Sein", "Hertz", "hat", "Ihm", "kein", "Wurm", "vor", "Un\u00b7muth", "ab\u00b7ge\u00b7zeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PIAT", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Er f\u00fchlte keine Last auf seiner lincken Brust:", "tokens": ["Er", "f\u00fchl\u00b7te", "kei\u00b7ne", "Last", "auf", "sei\u00b7ner", "lin\u00b7cken", "Brust", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Zu Nachtes hat kein Grahm Ihm seine Ruh gest\u00f6hret;", "tokens": ["Zu", "Nach\u00b7tes", "hat", "kein", "Grahm", "Ihm", "sei\u00b7ne", "Ruh", "ge\u00b7st\u00f6h\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PIAT", "NN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Er h\u00e4uffte nicht bey sich den alten S\u00fcnden-Wust.", "tokens": ["Er", "h\u00e4uff\u00b7te", "nicht", "bey", "sich", "den", "al\u00b7ten", "S\u00fcn\u00b7den\u00b7Wust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "APPR", "PRF", "ART", "ADJA", "NN", "$."], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.55": {"text": "Sein meistes Sprechen war; die Wunder Gottes loben", "tokens": ["Sein", "meis\u00b7tes", "Spre\u00b7chen", "war", ";", "die", "Wun\u00b7der", "Got\u00b7tes", "lo\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$.", "ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Wie dieser Ihn gef\u00fchrt von erster Jugend an:", "tokens": ["Wie", "die\u00b7ser", "Ihn", "ge\u00b7f\u00fchrt", "von", "ers\u00b7ter", "Ju\u00b7gend", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "PPER", "VVPP", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Wie V\u00e4terlich er ihn zum Ehren-Sitz erhoben;", "tokens": ["Wie", "V\u00e4\u00b7ter\u00b7lich", "er", "ihn", "zum", "Eh\u00b7ren\u00b7Sitz", "er\u00b7ho\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und wie viel gutes noch an Leib und Seel gethan;", "tokens": ["Und", "wie", "viel", "gu\u00b7tes", "noch", "an", "Leib", "und", "Seel", "ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIAT", "ADJA", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Wie manchen Gl\u00fcckes er ihn w\u00fcrdig h\u00e4tt gesch\u00e4tzet/", "tokens": ["Wie", "man\u00b7chen", "Gl\u00fc\u00b7ckes", "er", "ihn", "w\u00fcr\u00b7dig", "h\u00e4tt", "ge\u00b7sch\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "PPER", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Wie viele G\u00fcter er von dessen milder Hand;", "tokens": ["Wie", "vie\u00b7le", "G\u00fc\u00b7ter", "er", "von", "des\u00b7sen", "mil\u00b7der", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "APPR", "PRELAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "In was f\u00fcr Alter Ihn und Jahre er gesetzet/", "tokens": ["In", "was", "f\u00fcr", "Al\u00b7ter", "Ihn", "und", "Jah\u00b7re", "er", "ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "APPR", "NN", "PPER", "KON", "NN", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Und wie er ihn gemacht zum Ersten in dem Land.", "tokens": ["Und", "wie", "er", "ihn", "ge\u00b7macht", "zum", "Ers\u00b7ten", "in", "dem", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PPER", "VVPP", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "In solchen Reden ist er selbsten auch verschieden/", "tokens": ["In", "sol\u00b7chen", "Re\u00b7den", "ist", "er", "selbs\u00b7ten", "auch", "ver\u00b7schie\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Dann sein beredter Mund schlo\u00df sich kaum davon zu.", "tokens": ["Dann", "sein", "be\u00b7red\u00b7ter", "Mund", "schlo\u00df", "sich", "kaum", "da\u00b7von", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "PRF", "ADV", "PAV", "PTKVZ", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.65": {"text": "So fuhr wie Simeon der Geist in vollem Frieden/", "tokens": ["So", "fuhr", "wie", "Si\u00b7me\u00b7on", "der", "Geist", "in", "vol\u00b7lem", "Frie\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "NE", "ART", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Von seiner H\u00fctten aus/ in die erw\u00fcnschte Ruh.", "tokens": ["Von", "sei\u00b7ner", "H\u00fct\u00b7ten", "aus", "/", "in", "die", "er\u00b7w\u00fcnschte", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.67": {"text": "Sagt Menschen! saget mir! hei\u00dft di\u00df nicht ein Gef\u00e4sse", "tokens": ["Sagt", "Men\u00b7schen", "!", "sa\u00b7get", "mir", "!", "hei\u00dft", "di\u00df", "nicht", "ein", "Ge\u00b7f\u00e4s\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "$.", "VVFIN", "PPER", "$.", "VVFIN", "PDS", "PTKNEG", "ART", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.68": {"text": "Von Gottes Gnaden seyn", "tokens": ["Von", "Got\u00b7tes", "Gna\u00b7den", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "NN", "VAINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.69": {"text": "In Ehren; bey Verstand; in Ruh auch noch in Gr\u00f6sse/", "tokens": ["In", "Eh\u00b7ren", ";", "bey", "Ver\u00b7stand", ";", "in", "Ruh", "auch", "noch", "in", "Gr\u00f6s\u00b7se", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "APPR", "NN", "$.", "APPR", "NN", "ADV", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Des Alters/ des Verdiensts/ das nicht mit Ihm verdirbt.", "tokens": ["Des", "Al\u00b7ters", "/", "des", "Ver\u00b7diensts", "/", "das", "nicht", "mit", "Ihm", "ver\u00b7dirbt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "$(", "PDS", "PTKNEG", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Dadurch wird Jena noch in den Geschichten leben;", "tokens": ["Da\u00b7durch", "wird", "Je\u00b7na", "noch", "in", "den", "Ge\u00b7schich\u00b7ten", "le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "NE", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.72": {"text": "So lang nur eine Schrifft von diesen \u00fcbrig bleibt:", "tokens": ["So", "lang", "nur", "ei\u00b7ne", "Schrifft", "von", "die\u00b7sen", "\u00fcb\u00b7rig", "bleibt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ART", "NN", "APPR", "PDAT", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Dann wer will Ihm den Ruhm mit zweyen Bl\u00e4ttern geben;", "tokens": ["Dann", "wer", "will", "Ihm", "den", "Ruhm", "mit", "zwe\u00b7yen", "Bl\u00e4t\u00b7tern", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VMFIN", "PPER", "ART", "NN", "APPR", "VVFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Davon mit allem Recht man gantze B\u00fccher schreibt.", "tokens": ["Da\u00b7von", "mit", "al\u00b7lem", "Recht", "man", "gant\u00b7ze", "B\u00fc\u00b7cher", "schreibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "PIS", "NN", "PIS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Es ist auch gar nicht Noth/ da\u00df man hier Ver\u00dfe dichtet/", "tokens": ["Es", "ist", "auch", "gar", "nicht", "Noth", "/", "da\u00df", "man", "hier", "Ver\u00b7\u00dfe", "dich\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "NN", "$(", "KOUS", "PIS", "ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Dann seine Thaten schon des Lesens w\u00fcrdig sind/", "tokens": ["Dann", "sei\u00b7ne", "Tha\u00b7ten", "schon", "des", "Le\u00b7sens", "w\u00fcr\u00b7dig", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADV", "ART", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Man schreibe/ was er nur zu Regenspurg verrichtet/", "tokens": ["Man", "schrei\u00b7be", "/", "was", "er", "nur", "zu", "Re\u00b7gen\u00b7spurg", "ver\u00b7rich\u00b7tet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$(", "PWS", "PPER", "ADV", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Und was man selbst von Ihm schon aufgezeichnet findt", "tokens": ["Und", "was", "man", "selbst", "von", "Ihm", "schon", "auf\u00b7ge\u00b7zeich\u00b7net", "findt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PIS", "ADV", "APPR", "PPER", "ADV", "VVPP", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Was Wunder ists es dann? da\u00df Ihm nicht wolte grauen/", "tokens": ["Was", "Wun\u00b7der", "ists", "es", "dann", "?", "da\u00df", "Ihm", "nicht", "wol\u00b7te", "grau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "PPER", "ADV", "$.", "KOUS", "PPER", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Vor dem/ was der Natur sonst so entsetzlich f\u00e4llt:", "tokens": ["Vor", "dem", "/", "was", "der", "Na\u00b7tur", "sonst", "so", "ent\u00b7setz\u00b7lich", "f\u00e4llt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PWS", "ART", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.81": {"text": "Das letzte Viertel kunt er auch am Zeiger schauen/", "tokens": ["Das", "letz\u00b7te", "Vier\u00b7tel", "kunt", "er", "auch", "am", "Zei\u00b7ger", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "PPER", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Den Gottes weise Hand auf seinen Tod gestellt.", "tokens": ["Den", "Got\u00b7tes", "wei\u00b7se", "Hand", "auf", "sei\u00b7nen", "Tod", "ge\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Man solte seinen Leib in weisser Leinwand n\u00e4hen/", "tokens": ["Man", "sol\u00b7te", "sei\u00b7nen", "Leib", "in", "weis\u00b7ser", "Lein\u00b7wand", "n\u00e4\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Und reines Wachs dabey noch dessen Decke seyn", "tokens": ["Und", "rei\u00b7nes", "Wachs", "da\u00b7bey", "noch", "des\u00b7sen", "De\u00b7cke", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "PAV", "ADV", "PRELAT", "NN", "VAINF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Doch ist auch dieses nicht von ungefehr geschehen/", "tokens": ["Doch", "ist", "auch", "die\u00b7ses", "nicht", "von", "un\u00b7ge\u00b7fehr", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PDS", "PTKNEG", "APPR", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Der Bienen Arbeit trifft mit seinem Leben ein", "tokens": ["Der", "Bie\u00b7nen", "Ar\u00b7beit", "trifft", "mit", "sei\u00b7nem", "Le\u00b7ben", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Nur eines will vielleicht dem Seeligen hie fehlen/", "tokens": ["Nur", "ei\u00b7nes", "will", "viel\u00b7leicht", "dem", "See\u00b7li\u00b7gen", "hie", "feh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "ADV", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Weil seine Leiche ja noch Sohn/ noch Tochter trifft:", "tokens": ["Weil", "sei\u00b7ne", "Lei\u00b7che", "ja", "noch", "Sohn", "/", "noch", "Toch\u00b7ter", "trifft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ADV", "NN", "$(", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Allein den Erben mu\u00df man ja f\u00fcr jenen zehlen", "tokens": ["Al\u00b7lein", "den", "Er\u00b7ben", "mu\u00df", "man", "ja", "f\u00fcr", "je\u00b7nen", "zeh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VMFIN", "PIS", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Und T\u00f6chter nennen sich die Fr\u00e4ulein in dem Stifft", "tokens": ["Und", "T\u00f6ch\u00b7ter", "nen\u00b7nen", "sich", "die", "Fr\u00e4u\u00b7lein", "in", "dem", "Stifft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "So ist er dieses Orts auch gar nicht unvollkommen/", "tokens": ["So", "ist", "er", "die\u00b7ses", "Orts", "auch", "gar", "nicht", "un\u00b7voll\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDAT", "NN", "ADV", "ADV", "PTKNEG", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Was wir vorher gesagt/ das bleibt noch jetzt dabey/", "tokens": ["Was", "wir", "vor\u00b7her", "ge\u00b7sagt", "/", "das", "bleibt", "noch", "jetzt", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$(", "PDS", "VVFIN", "ADV", "ADV", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Wer seinen Abtritt so aus seiner Seen genommen/", "tokens": ["Wer", "sei\u00b7nen", "Ab\u00b7tritt", "so", "aus", "sei\u00b7ner", "Seen", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Da spricht man/ da\u00df das Spiel gar wohl geschlossen sey.", "tokens": ["Da", "spricht", "man", "/", "da\u00df", "das", "Spiel", "gar", "wohl", "ge\u00b7schlos\u00b7sen", "sey", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$(", "KOUS", "ART", "NN", "ADV", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Doch Musen! was ists/ das auf eure Br\u00fcste schl\u00e4get?", "tokens": ["Doch", "Mu\u00b7sen", "!", "was", "ists", "/", "das", "auf", "eu\u00b7re", "Br\u00fcs\u00b7te", "schl\u00e4\u00b7get", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$.", "PWS", "VAFIN", "$(", "PDS", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Aus was Ursachen folgt ihr dieser Leiche nach?", "tokens": ["Aus", "was", "Ur\u00b7sa\u00b7chen", "folgt", "ihr", "die\u00b7ser", "Lei\u00b7che", "nach", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "VVFIN", "PPER", "PDAT", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.97": {"text": "Es ist nicht euer Haupt/ das man itzt dahin tr\u00e4get;", "tokens": ["Es", "ist", "nicht", "eu\u00b7er", "Haupt", "/", "das", "man", "itzt", "da\u00b7hin", "tr\u00e4\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$(", "PRELS", "PIS", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Er sa\u00df im Regiment/ was \u00e4ngstet euch die Sach?", "tokens": ["Er", "sa\u00df", "im", "Re\u00b7gi\u00b7ment", "/", "was", "\u00e4ngs\u00b7tet", "euch", "die", "Sach", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$(", "PWS", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Nur ach! ich kan euch wohl aus dem Gesichte lesen/", "tokens": ["Nur", "ach", "!", "ich", "kan", "euch", "wohl", "aus", "dem", "Ge\u00b7sich\u00b7te", "le\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "PPER", "VMFIN", "PPER", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Ihr findt an diesem Tod zugleich auch euren Theil;", "tokens": ["Ihr", "findt", "an", "die\u00b7sem", "Tod", "zu\u00b7gleich", "auch", "eu\u00b7ren", "Theil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Denn Jena ist euch stets vor andern hold gewesen;", "tokens": ["Denn", "Je\u00b7na", "ist", "euch", "stets", "vor", "an\u00b7dern", "hold", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PPER", "ADV", "APPR", "PIS", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Ihm kam von eurem Kram sein gantzes Gl\u00fcck und Heyl.", "tokens": ["Ihm", "kam", "von", "eu\u00b7rem", "Kram", "sein", "gant\u00b7zes", "Gl\u00fcck", "und", "Heyl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PPOSAT", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Er h\u00f6rte lieber euch/ als ", "tokens": ["Er", "h\u00f6r\u00b7te", "lie\u00b7ber", "euch", "/", "als"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "$(", "KOKOM"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.104": {"text": "Und euren Kriegen hat er manchmahl beygewohnt.", "tokens": ["Und", "eu\u00b7ren", "Krie\u00b7gen", "hat", "er", "manch\u00b7mahl", "bey\u00b7ge\u00b7wohnt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Offt sa\u00df er selbst bey euch/ und drung euch in die Seiten;", "tokens": ["Offt", "sa\u00df", "er", "selbst", "bey", "euch", "/", "und", "drung", "euch", "in", "die", "Sei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$(", "KON", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Zu weisen/ da die Kunst noch seinem Alter frohnt.", "tokens": ["Zu", "wei\u00b7sen", "/", "da", "die", "Kunst", "noch", "sei\u00b7nem", "Al\u00b7ter", "frohnt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "KOUS", "ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Auff eure Freyheit war er gar nicht mi\u00dfvergn\u00fcget/", "tokens": ["Auff", "eu\u00b7re", "Frey\u00b7heit", "war", "er", "gar", "nicht", "mi\u00df\u00b7ver\u00b7gn\u00fc\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Er lie\u00df euch gern bey dem/ was eures K\u00f6nigs Hand", "tokens": ["Er", "lie\u00df", "euch", "gern", "bey", "dem", "/", "was", "eu\u00b7res", "K\u00f6\u00b7nigs", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "$(", "PWS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "F\u00fcr euer gantzes Volck an diesem Ort verf\u00fcget/", "tokens": ["F\u00fcr", "eu\u00b7er", "gant\u00b7zes", "Volck", "an", "die\u00b7sem", "Ort", "ver\u00b7f\u00fc\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "APPR", "PDAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Und hielte solches auch sehr n\u00fctzlich angewandt.", "tokens": ["Und", "hiel\u00b7te", "sol\u00b7ches", "auch", "sehr", "n\u00fctz\u00b7lich", "an\u00b7ge\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Er sahe euren Flei\u00df in viel Schrifften bl\u00fchen;", "tokens": ["Er", "sa\u00b7he", "eu\u00b7ren", "Flei\u00df", "in", "viel", "Schriff\u00b7ten", "bl\u00fc\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.112": {"text": "Auch eure Bl\u00e4tter hielt er seiner Augen werth.", "tokens": ["Auch", "eu\u00b7re", "Bl\u00e4t\u00b7ter", "hielt", "er", "sei\u00b7ner", "Au\u00b7gen", "werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Und wenn er h\u00f6rte/ euch von Ost und West herziehen;", "tokens": ["Und", "wenn", "er", "h\u00f6r\u00b7te", "/", "euch", "von", "Ost", "und", "West", "her\u00b7zie\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$(", "PPER", "APPR", "NE", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Und wie sich euer Sitz mit tausenden vermehrt:", "tokens": ["Und", "wie", "sich", "eu\u00b7er", "Sitz", "mit", "tau\u00b7sen\u00b7den", "ver\u00b7mehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "PPOSAT", "NN", "APPR", "ADJA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "So kunte a sein Mund di\u00df Gottes Wercke nennen/", "tokens": ["So", "kun\u00b7te", "a", "sein", "Mund", "di\u00df", "Got\u00b7tes", "Wer\u00b7cke", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "PPOSAT", "NN", "PDS", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Er f\u00fchrte di\u00df vom Herrn und dessen G\u00fcte her.", "tokens": ["Er", "f\u00fchr\u00b7te", "di\u00df", "vom", "Herrn", "und", "des\u00b7sen", "G\u00fc\u00b7te", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "APPRART", "NN", "KON", "PRELAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Da Neid und Unverstand euch kaum die Stelle g\u00f6nnen/", "tokens": ["Da", "Neid", "und", "Un\u00b7ver\u00b7stand", "euch", "kaum", "die", "Stel\u00b7le", "g\u00f6n\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.118": {"text": "Und halten alles di\u00df auch nur f\u00fcr ungef\u00e4hr.", "tokens": ["Und", "hal\u00b7ten", "al\u00b7les", "di\u00df", "auch", "nur", "f\u00fcr", "un\u00b7ge\u00b7f\u00e4hr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PDS", "ADV", "ADV", "APPR", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}