{"textgrid.poem.37479": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Der Eispeter", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als Anno 12 das Holz so rar,", "tokens": ["Als", "An\u00b7no", "12", "das", "Holz", "so", "rar", ","], "token_info": ["word", "word", "number", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "CARD", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und als der kalte Winter war,", "tokens": ["Und", "als", "der", "kal\u00b7te", "Win\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Da blieb ein jeder gern zu Haus;", "tokens": ["Da", "blieb", "ein", "je\u00b7der", "gern", "zu", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIS", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nur Peter mu\u00df aufs Eis hinaus.", "tokens": ["Nur", "Pe\u00b7ter", "mu\u00df", "aufs", "Eis", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VMFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Da drau\u00dfen, ja, man glaubt es kaum,", "tokens": ["Da", "drau\u00b7\u00dfen", ",", "ja", ",", "man", "glaubt", "es", "kaum", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PTKANT", "$,", "PIS", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fiel manche Kr\u00e4he tot vom Baum.", "tokens": ["Fiel", "man\u00b7che", "Kr\u00e4\u00b7he", "tot", "vom", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Onkel F\u00f6rster warnt und spricht:", "tokens": ["Der", "On\u00b7kel", "F\u00f6rs\u00b7ter", "warnt", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbmein Peter, heute geht es nicht!\u00ab", "tokens": ["\u00bb", "mein", "Pe\u00b7ter", ",", "heu\u00b7te", "geht", "es", "nicht", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NE", "$,", "ADV", "VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch ist ein Hase bei den Ohren", "tokens": ["Auch", "ist", "ein", "Ha\u00b7se", "bei", "den", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz dicht am Wege festgefroren.", "tokens": ["Ganz", "dicht", "am", "We\u00b7ge", "fest\u00b7ge\u00b7fro\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch Peter denkt: Tralitrala!", "tokens": ["Doch", "Pe\u00b7ter", "denkt", ":", "Tra\u00b7li\u00b7tra\u00b7la", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sitzt auf einem Steine da.", "tokens": ["Und", "sitzt", "auf", "ei\u00b7nem", "Stei\u00b7ne", "da", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Nun m\u00f6chte Peter sich erheben,", "tokens": ["Nun", "m\u00f6ch\u00b7te", "Pe\u00b7ter", "sich", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Hose bleibt am Steine kleben.", "tokens": ["Die", "Ho\u00b7se", "bleibt", "am", "Stei\u00b7ne", "kle\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Stoff ist alt, die Lust ist gro\u00df,", "tokens": ["Der", "Stoff", "ist", "alt", ",", "die", "Lust", "ist", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Peter rei\u00dft sich wieder los.", "tokens": ["Der", "Pe\u00b7ter", "rei\u00dft", "sich", "wie\u00b7der", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Na, richtig! Ja, ich dacht es doch!", "tokens": ["Na", ",", "rich\u00b7tig", "!", "Ja", ",", "ich", "dacht", "es", "doch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJD", "$.", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da f\u00e4llt er schon ins tiefe Loch.", "tokens": ["Da", "f\u00e4llt", "er", "schon", "ins", "tie\u00b7fe", "Loch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Mit Hinterlassung seiner M\u00fctze", "tokens": ["Mit", "Hin\u00b7ter\u00b7las\u00b7sung", "sei\u00b7ner", "M\u00fct\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Steigt Peter wieder aus der Pf\u00fctze.", "tokens": ["Steigt", "Pe\u00b7ter", "wie\u00b7der", "aus", "der", "Pf\u00fct\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Bald schie\u00dft hervor, obschon noch klein,", "tokens": ["Bald", "schie\u00dft", "her\u00b7vor", ",", "ob\u00b7schon", "noch", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "KOUS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Zacken Eis am Nasenbein.", "tokens": ["Ein", "Za\u00b7cken", "Eis", "am", "Na\u00b7sen\u00b7bein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der Zacken wird noch immer besser", "tokens": ["Der", "Za\u00b7cken", "wird", "noch", "im\u00b7mer", "bes\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und scharf als wie ein Schlachtermesser.", "tokens": ["Und", "scharf", "als", "wie", "ein", "Schlach\u00b7ter\u00b7mes\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Der Zacken werden immer mehr,", "tokens": ["Der", "Za\u00b7cken", "wer\u00b7den", "im\u00b7mer", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Nasenzacken wird ein Speer.", "tokens": ["Der", "Na\u00b7sen\u00b7za\u00b7cken", "wird", "ein", "Speer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Und jeder fragt: Was mag das sein?", "tokens": ["Und", "je\u00b7der", "fragt", ":", "Was", "mag", "das", "sein", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$.", "PWS", "VMFIN", "PDS", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist ja wie ein Stachelschwein!", "tokens": ["Das", "ist", "ja", "wie", "ein", "Sta\u00b7chel\u00b7schwein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Die Eltern sehen nach der Uhr:", "tokens": ["Die", "El\u00b7tern", "se\u00b7hen", "nach", "der", "Uhr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbach, ach! wo bleibt denn Peter nur?\u00ab", "tokens": ["\u00bb", "ach", ",", "ach", "!", "wo", "bleibt", "denn", "Pe\u00b7ter", "nur", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ITJ", "$.", "PWAV", "VVFIN", "ADV", "NE", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Da ruft der Onkel in das Haus:", "tokens": ["Da", "ruft", "der", "On\u00b7kel", "in", "das", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbder Schlingel ist aufs Eis hinaus!\u00ab", "tokens": ["\u00bb", "der", "Schlin\u00b7gel", "ist", "aufs", "Eis", "hin\u00b7aus", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "APPRART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Mit einer Axt und stillem Weh", "tokens": ["Mit", "ei\u00b7ner", "Axt", "und", "stil\u00b7lem", "Weh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sucht man den Peter hier im Schnee.", "tokens": ["Sucht", "man", "den", "Pe\u00b7ter", "hier", "im", "Schnee", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NE", "ADV", "APPRART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.18": {"line.1": {"text": "Schon sieht man mit besorgtem Blick", "tokens": ["Schon", "sieht", "man", "mit", "be\u00b7sorg\u00b7tem", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Teil von Peters Kleidungsst\u00fcck.", "tokens": ["Ein", "Teil", "von", "Pe\u00b7ters", "Klei\u00b7dungs\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Doch gr\u00f6\u00dfer war die Trauer da,", "tokens": ["Doch", "gr\u00f6\u00b7\u00dfer", "war", "die", "Trau\u00b7er", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als man den Peter selber sah.", "tokens": ["Als", "man", "den", "Pe\u00b7ter", "sel\u00b7ber", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NE", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Hier wird der Peter transportiert,", "tokens": ["Hier", "wird", "der", "Pe\u00b7ter", "trans\u00b7por\u00b7tiert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vater weint, die Tr\u00e4ne friert.", "tokens": ["Der", "Va\u00b7ter", "weint", ",", "die", "Tr\u00e4\u00b7ne", "friert", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Behutsam l\u00e4\u00dft man Peters Glieder", "tokens": ["Be\u00b7hut\u00b7sam", "l\u00e4\u00dft", "man", "Pe\u00b7ters", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PIS", "NE", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Haus am warmen Ofen nieder.", "tokens": ["Zu", "Haus", "am", "war\u00b7men", "O\u00b7fen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Juchhe! Die Freudigkeit ist gro\u00df;", "tokens": ["Juch\u00b7he", "!", "Die", "Freu\u00b7dig\u00b7keit", "ist", "gro\u00df", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Das Wasser rinnt, das Eis geht los.", "tokens": ["Das", "Was\u00b7ser", "rinnt", ",", "das", "Eis", "geht", "los", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Ach, aber ach! Nun ist's vorbei!", "tokens": ["Ach", ",", "a\u00b7ber", "ach", "!", "Nun", "ist's", "vor\u00b7bei", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADV", "$.", "ADV", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der ganze Kerl zerrinnt zu Brei.", "tokens": ["Der", "gan\u00b7ze", "Kerl", "zer\u00b7rinnt", "zu", "Brei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Hier wird in einen Topf gef\u00fcllt", "tokens": ["Hier", "wird", "in", "ei\u00b7nen", "Topf", "ge\u00b7f\u00fcllt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Peters traurig Ebenbild.", "tokens": ["Des", "Pe\u00b7ters", "trau\u00b7rig", "E\u00b7ben\u00b7bild", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ja, ja! In diesen Topf von Stein,", "tokens": ["Ja", ",", "ja", "!", "In", "die\u00b7sen", "Topf", "von", "Stein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "APPR", "PDAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da machte man den Peter ein,", "tokens": ["Da", "mach\u00b7te", "man", "den", "Pe\u00b7ter", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Der, nachdem er anfangs hart,", "tokens": ["Der", ",", "nach\u00b7dem", "er", "an\u00b7fangs", "hart", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sp\u00e4ter weich wie Butter ward.", "tokens": ["Sp\u00e4\u00b7ter", "weich", "wie", "But\u00b7ter", "ward", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KOKOM", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}