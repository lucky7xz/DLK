{"textgrid.poem.32829": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als Junker Hanns in den Alleen", "genre": "verse", "period": "N.A.", "pub_year": 1765, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als Junker Hanns in den Alleen", "tokens": ["Als", "Jun\u00b7ker", "Hanns", "in", "den", "Al\u00b7leen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An seinem Schlo\u00df spatzieren gieng;", "tokens": ["An", "sei\u00b7nem", "Schlo\u00df", "spat\u00b7zie\u00b7ren", "gieng", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sah er den G\u00e4rtner, Lukas, stehen,", "tokens": ["Sah", "er", "den", "G\u00e4rt\u00b7ner", ",", "Lu\u00b7kas", ",", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NE", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "(es war ein Fest,) geputzt und flink.", "tokens": ["(", "es", "war", "ein", "Fest", ",", ")", "ge\u00b7putzt", "und", "flink", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "$(", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sah: geth\u00fcrmt, von seinem Ohr", "tokens": ["Er", "sah", ":", "ge\u00b7th\u00fcrmt", ",", "von", "sei\u00b7nem", "Ohr"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "VVPP", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Stieg eine steife M\u00fctz empor.", "tokens": ["Stieg", "ei\u00b7ne", "stei\u00b7fe", "M\u00fctz", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie k\u00f6mmst du zu der Hahnreym\u00fctze?", "tokens": ["Wie", "k\u00f6mmst", "du", "zu", "der", "Hahn\u00b7rey\u00b7m\u00fct\u00b7ze", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Junker Hanns, die\u00df ist zu fr\u00fch!", "tokens": ["Sprach", "Jun\u00b7ker", "Hanns", ",", "die\u00df", "ist", "zu", "fr\u00fch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$,", "PDS", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbmein, kennen sie die goldne Spitze,", "tokens": ["\u00bb", "mein", ",", "ken\u00b7nen", "sie", "die", "gold\u00b7ne", "Spit\u00b7ze", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sprach Lukas, nicht? sie kennen sie?", "tokens": ["Sprach", "Lu\u00b7kas", ",", "nicht", "?", "sie", "ken\u00b7nen", "sie", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PTKNEG", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es gab mir sie die gn\u00e4dge Frau,", "tokens": ["Es", "gab", "mir", "sie", "die", "gn\u00e4d\u00b7ge", "Frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie ist nicht so, wie sie, genau.\u00ab", "tokens": ["Sie", "ist", "nicht", "so", ",", "wie", "sie", ",", "ge\u00b7nau", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "$,", "PWAV", "PPER", "$,", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}