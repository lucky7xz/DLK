{"textgrid.poem.24315": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "7.", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In Monte Cassino sagte mir einmal", "tokens": ["In", "Mon\u00b7te", "Cas\u00b7si\u00b7no", "sag\u00b7te", "mir", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ein feiner Benediktiner: Ihr Deutschen", "tokens": ["Ein", "fei\u00b7ner", "Be\u00b7ne\u00b7dik\u00b7ti\u00b7ner", ":", "Ihr", "Deut\u00b7schen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "H\u00e4ttet nie aufh\u00f6ren sollen, katholisch", "tokens": ["H\u00e4t\u00b7tet", "nie", "auf\u00b7h\u00f6\u00b7ren", "sol\u00b7len", ",", "ka\u00b7tho\u00b7lisch"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "VVINF", "VMFIN", "$,", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Zu sein.", "tokens": ["Zu", "sein", "."], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VAINF", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.2": {"line.1": {"text": "Ich machte die sch\u00f6nste meiner Verbeugungen und fragte:", "tokens": ["Ich", "mach\u00b7te", "die", "sch\u00f6ns\u00b7te", "mei\u00b7ner", "Ver\u00b7beu\u00b7gun\u00b7gen", "und", "frag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+--++--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Warum?", "tokens": ["Wa\u00b7rum", "?"], "token_info": ["word", "punct"], "pos": ["PWAV", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.3": {"line.1": {"text": "Mein Herr! entgegnete er, ihr Deutschen seid", "tokens": ["Mein", "Herr", "!", "ent\u00b7geg\u00b7ne\u00b7te", "er", ",", "ihr", "Deut\u00b7schen", "seid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Romantiker, Schw\u00e4rmer im Grunde des Herzens.", "tokens": ["Ro\u00b7man\u00b7ti\u00b7ker", ",", "Schw\u00e4r\u00b7mer", "im", "Grun\u00b7de", "des", "Her\u00b7zens", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Ich sah euern Kaiser. Ich sprach ihn. Dio mio!", "tokens": ["Ich", "sah", "eu\u00b7ern", "Kai\u00b7ser", ".", "Ich", "sprach", "ihn", ".", "Dio", "mio", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PPER", "$.", "NE", "NE", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Niemals noch h\u00f6rte ich so ritterlich reden", "tokens": ["Nie\u00b7mals", "noch", "h\u00f6r\u00b7te", "ich", "so", "rit\u00b7ter\u00b7lich", "re\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "VVINF"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "Vom heiligen Benedikt und seiner Inbrunst", "tokens": ["Vom", "hei\u00b7li\u00b7gen", "Be\u00b7ne\u00b7dikt", "und", "sei\u00b7ner", "In\u00b7brunst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NE", "KON", "PPOSAT", "NN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "In diesen Gew\u00f6lben: vom Kreuz; vom Licht", "tokens": ["In", "die\u00b7sen", "Ge\u00b7w\u00f6l\u00b7ben", ":", "vom", "Kreuz", ";", "vom", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "NN", "$.", "APPRART", "NN", "$.", "APPRART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Des Glaubens und der Liebe; von der Wonne,", "tokens": ["Des", "Glau\u00b7bens", "und", "der", "Lie\u00b7be", ";", "von", "der", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Ein Christ zu sein.", "tokens": ["Ein", "Christ", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Das nennen Sie Romantik? fragte ich. Er l\u00e4chelte", "tokens": ["Das", "nen\u00b7nen", "Sie", "Ro\u00b7man\u00b7tik", "?", "frag\u00b7te", "ich", ".", "Er", "l\u00e4\u00b7chel\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "NN", "$.", "VVFIN", "PPER", "$.", "PPER", "VVFIN"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und sprach:", "tokens": ["Und", "sprach", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Bei euch. Ihr sprecht von diesen gro\u00dfen Dingen,", "tokens": ["Bei", "euch", ".", "Ihr", "sprecht", "von", "die\u00b7sen", "gro\u00b7\u00dfen", "Din\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$.", "PPER", "VVFIN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die uns zwar heilig, doch gewisserma\u00dfen", "tokens": ["Die", "uns", "zwar", "hei\u00b7lig", ",", "doch", "ge\u00b7wis\u00b7ser\u00b7ma\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPER", "ADV", "ADJD", "$,", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gew\u00f6hnlich sind, so, wie die Dichter von Geliebten sprechen,", "tokens": ["Ge\u00b7w\u00f6hn\u00b7lich", "sind", ",", "so", ",", "wie", "die", "Dich\u00b7ter", "von", "Ge\u00b7lieb\u00b7ten", "spre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$,", "ADV", "$,", "PWAV", "ART", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.4": {"text": "Die sie verloren haben:", "tokens": ["Die", "sie", "ver\u00b7lo\u00b7ren", "ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit banger Z\u00e4rtlichkeit, erinnerungsbegl\u00fcckt,", "tokens": ["Mit", "ban\u00b7ger", "Z\u00e4rt\u00b7lich\u00b7keit", ",", "e\u00b7rin\u00b7ne\u00b7rungs\u00b7be\u00b7gl\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Scheu hoffend, kummervoll und tr\u00e4umerisch.", "tokens": ["Scheu", "hof\u00b7fend", ",", "kum\u00b7mer\u00b7voll", "und", "tr\u00e4u\u00b7me\u00b7risch", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.7": {"text": "Wie M\u00e4nner von der ersten Liebe reden,", "tokens": ["Wie", "M\u00e4n\u00b7ner", "von", "der", "ers\u00b7ten", "Lie\u00b7be", "re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die sie versto\u00dfen haben, redet ihr,", "tokens": ["Die", "sie", "ver\u00b7sto\u00b7\u00dfen", "ha\u00b7ben", ",", "re\u00b7det", "ihr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "VAINF", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Dem Anschein nach nicht gl\u00fccklich in der Ehe,", "tokens": ["Dem", "An\u00b7schein", "nach", "nicht", "gl\u00fcck\u00b7lich", "in", "der", "E\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PTKNEG", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Die euch \u00bbVernunft\u00ab gebot, von den Geheimnissen", "tokens": ["Die", "euch", "\u00bb", "Ver\u00b7nunft", "\u00ab", "ge\u00b7bot", ",", "von", "den", "Ge\u00b7heim\u00b7nis\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "$(", "NN", "$(", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.11": {"text": "Des wahren Glaubens.", "tokens": ["Des", "wah\u00b7ren", "Glau\u00b7bens", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Was schlie\u00dfen Sie daraus? war meine Frage nun.", "tokens": ["Was", "schlie\u00b7\u00dfen", "Sie", "da\u00b7raus", "?", "war", "mei\u00b7ne", "Fra\u00b7ge", "nun", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PAV", "$.", "VAFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er sprach:", "tokens": ["Er", "sprach", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Was ich schon sagte: Euer deutsches Herz", "tokens": ["Was", "ich", "schon", "sag\u00b7te", ":", "Eu\u00b7er", "deut\u00b7sches", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "VVFIN", "$.", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ist grundkatholisch. Jener Wittenberger,", "tokens": ["Ist", "grund\u00b7ka\u00b7tho\u00b7lisch", ".", "Je\u00b7ner", "Wit\u00b7ten\u00b7ber\u00b7ger", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Oh, da\u00df er Papst geworden w\u00e4re! Glauben Sie", "tokens": ["Oh", ",", "da\u00df", "er", "Papst", "ge\u00b7wor\u00b7den", "w\u00e4\u00b7re", "!", "Glau\u00b7ben", "Sie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ITJ", "$,", "KOUS", "PPER", "NN", "VAPP", "VAFIN", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es einem, der den Doktor Martin kennt:", "tokens": ["Es", "ei\u00b7nem", ",", "der", "den", "Dok\u00b7tor", "Mar\u00b7tin", "kennt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "$,", "PRELS", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}}, "stanza.8": {"line.1": {"text": "Ich war der Gast des heiligen Benedikt und schwieg.", "tokens": ["Ich", "war", "der", "Gast", "des", "hei\u00b7li\u00b7gen", "Be\u00b7ne\u00b7dikt", "und", "schwieg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NE", "KON", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch revidiert ich in der Nacht mein deutsches Herz und fand", "tokens": ["Doch", "re\u00b7vi\u00b7diert", "ich", "in", "der", "Nacht", "mein", "deut\u00b7sches", "Herz", "und", "fand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Es zwar romantisch und voll Schw\u00e4rmerei,", "tokens": ["Es", "zwar", "ro\u00b7man\u00b7tisch", "und", "voll", "Schw\u00e4r\u00b7me\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "KON", "ADJD", "NN", "$,"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.4": {"text": "Doch weder protestantisch noch katholisch.", "tokens": ["Doch", "we\u00b7der", "pro\u00b7tes\u00b7tan\u00b7tisch", "noch", "ka\u00b7tho\u00b7lisch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KON", "ADJD", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Christus war drin, doch Aphrodite auch.", "tokens": ["Chris\u00b7tus", "war", "drin", ",", "doch", "A\u00b7phro\u00b7di\u00b7te", "auch", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "$,", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ich fand den heiligen Franz, fand Luther, fand", "tokens": ["Ich", "fand", "den", "hei\u00b7li\u00b7gen", "Franz", ",", "fand", "Lu\u00b7ther", ",", "fand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NE", "$,", "VVFIN", "NE", "$,", "VVFIN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Sogar ein St\u00fcckchen Herrenhut: doch das", "tokens": ["So\u00b7gar", "ein", "St\u00fcck\u00b7chen", "Her\u00b7ren\u00b7hut", ":", "doch", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "NN", "NN", "$.", "ADV", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Lag alles tief im Schatten. Hell stand, hoch,", "tokens": ["Lag", "al\u00b7les", "tief", "im", "Schat\u00b7ten", ".", "Hell", "stand", ",", "hoch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "APPRART", "NN", "$.", "NE", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Geh\u00e4mmertes Gold, der stolze Eremit", "tokens": ["Ge\u00b7h\u00e4m\u00b7mer\u00b7tes", "Gold", ",", "der", "stol\u00b7ze", "E\u00b7re\u00b7mit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Von Sils-Maria.", "tokens": ["Von", "Sils\u00b7Ma\u00b7ria", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}