{"textgrid.poem.43043": {"metadata": {"author": {"name": "Jacoby, Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es war im M\u00e4rz ein wolkiger Wintertag,", "genre": "verse", "period": "N.A.", "pub_year": 1867, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war im M\u00e4rz ein wolkiger Wintertag,", "tokens": ["Es", "war", "im", "M\u00e4rz", "ein", "wol\u00b7ki\u00b7ger", "Win\u00b7ter\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Denn \u00fcberall hart der Schnee noch lag,", "tokens": ["Denn", "\u00fc\u00b7be\u00b7rall", "hart", "der", "Schnee", "noch", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da quoll es in der Stadt herf\u00fcr und hervor", "tokens": ["Da", "quoll", "es", "in", "der", "Stadt", "her\u00b7f\u00fcr", "und", "her\u00b7vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "KON", "PTKVZ"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Aus Th\u00fcr und Thor", "tokens": ["Aus", "Th\u00fcr", "und", "Thor"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und seit morgens fruh", "tokens": ["Und", "seit", "mor\u00b7gens", "fruh"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADV", "ADJD"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Ergo\u00df sich ein Menschenstrom nach Westen zu.", "tokens": ["Er\u00b7go\u00df", "sich", "ein", "Men\u00b7schen\u00b7strom", "nach", "Wes\u00b7ten", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Dort vor dem Weichbild bald", "tokens": ["Dort", "vor", "dem", "Weich\u00b7bild", "bald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "ADV"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Begann ein hoher, dichter Wald,", "tokens": ["Be\u00b7gann", "ein", "ho\u00b7her", ",", "dich\u00b7ter", "Wald", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und die breite Allee, die durch ihn f\u00fchrt,", "tokens": ["Und", "die", "brei\u00b7te", "Al\u00b7lee", ",", "die", "durch", "ihn", "f\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "War heute geschm\u00fcckt und ausgeziert", "tokens": ["War", "heu\u00b7te", "ge\u00b7schm\u00fcckt", "und", "aus\u00b7ge\u00b7ziert"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "VVPP", "KON", "VVPP"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Mit bunten Flaggenstangen, die sich verbanden", "tokens": ["Mit", "bun\u00b7ten", "Flag\u00b7gen\u00b7stan\u00b7gen", ",", "die", "sich", "ver\u00b7ban\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PRF", "VVINF"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "L\u00e4ngs und quer durch Fichtenguirlanden.", "tokens": ["L\u00e4ngs", "und", "quer", "durch", "Fich\u00b7ten\u00b7gu\u00b7ir\u00b7lan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJD", "APPR", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Dort aber, wo h\u00f6her die Flaggen ragen,", "tokens": ["Dort", "a\u00b7ber", ",", "wo", "h\u00f6\u00b7her", "die", "Flag\u00b7gen", "ra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "War ein Rondell mit Sitzb\u00e4nken aufgeschlagen", "tokens": ["War", "ein", "Ron\u00b7dell", "mit", "Sitz\u00b7b\u00e4n\u00b7ken", "auf\u00b7ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "APPR", "NN", "VVINF"], "meter": "+-+--++-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "In einem Halbkreis, bunt ausstaffirt", "tokens": ["In", "ei\u00b7nem", "Halb\u00b7kreis", ",", "bunt", "aus\u00b7staf\u00b7firt"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und austapeziert", "tokens": ["Und", "aus\u00b7ta\u00b7pe\u00b7ziert"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Mit Wappen und Schi ldern und Draperien", "tokens": ["Mit", "Wap\u00b7pen", "und", "Schi", "ldern", "und", "Dra\u00b7pe\u00b7ri\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "KON", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.12": {"text": "Mit Sinnbildern und Spruchphantasieen.", "tokens": ["Mit", "Sinn\u00b7bil\u00b7dern", "und", "Spruch\u00b7phan\u00b7ta\u00b7si\u00b7e\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Schon stand hier", "tokens": ["Schon", "stand", "hier"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV"], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Die Allee entlang ein Menschenspalier", "tokens": ["Die", "Al\u00b7lee", "ent\u00b7lang", "ein", "Men\u00b7schen\u00b7spa\u00b7lier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPO", "ART", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und vor dem Rondell in dichtem Gedr\u00e4nge", "tokens": ["Und", "vor", "dem", "Ron\u00b7dell", "in", "dich\u00b7tem", "Ge\u00b7dr\u00e4n\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Eine unz\u00e4hlige Menschenmenge.", "tokens": ["Ei\u00b7ne", "un\u00b7z\u00e4h\u00b7li\u00b7ge", "Men\u00b7schen\u00b7men\u00b7ge", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Sie harrten seit morgens mit Ausdauer friedlich,", "tokens": ["Sie", "harr\u00b7ten", "seit", "mor\u00b7gens", "mit", "Aus\u00b7dau\u00b7er", "fried\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Im Warten geduldig und unerm\u00fcdlich;", "tokens": ["Im", "War\u00b7ten", "ge\u00b7dul\u00b7dig", "und", "un\u00b7er\u00b7m\u00fcd\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Denn es waren \u00fcberneugierig die Leute", "tokens": ["Denn", "es", "wa\u00b7ren", "\u00fc\u00b7bern\u00b7eu\u00b7gie\u00b7rig", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "ART", "NN"], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Damals gerade so wie heute.", "tokens": ["Da\u00b7mals", "ge\u00b7ra\u00b7de", "so", "wie", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Auf dem Rondell allm\u00e4hlig f\u00fcllten sich", "tokens": ["Auf", "dem", "Ron\u00b7dell", "all\u00b7m\u00e4h\u00b7lig", "f\u00fcll\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "PRF"], "meter": "+-++-+-+-+", "measure": "zehnsilber"}, "line.2": {"text": "Die Pl\u00e4tze fraulich und m\u00e4nniglich.", "tokens": ["Die", "Pl\u00e4t\u00b7ze", "frau\u00b7lich", "und", "m\u00e4n\u00b7nig\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zur Rechten waren zu schauen fein", "tokens": ["Zur", "Rech\u00b7ten", "wa\u00b7ren", "zu", "schau\u00b7en", "fein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Holde Frauen und M\u00e4gdelein,", "tokens": ["Hol\u00b7de", "Frau\u00b7en", "und", "M\u00e4g\u00b7del\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Zur linken Werkm\u00e4nner, in der Mitte der Rath,", "tokens": ["Zur", "lin\u00b7ken", "Werk\u00b7m\u00e4n\u00b7ner", ",", "in", "der", "Mit\u00b7te", "der", "Rath", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Der kam zuletzt. \u2013 Es war schon spat,", "tokens": ["Der", "kam", "zu\u00b7letzt", ".", "\u2013", "Es", "war", "schon", "spat", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$.", "$(", "PPER", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Als endlich durch die L\u00fcfte drang", "tokens": ["Als", "end\u00b7lich", "durch", "die", "L\u00fcf\u00b7te", "drang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein feierlicher Trompetenklang,", "tokens": ["Ein", "fei\u00b7er\u00b7li\u00b7cher", "Trom\u00b7pe\u00b7ten\u00b7klang", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Von der Menge begr\u00fc\u00dft mit lautem ah!", "tokens": ["Von", "der", "Men\u00b7ge", "be\u00b7gr\u00fc\u00dft", "mit", "lau\u00b7tem", "ah", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.10": {"text": "Denn der geschah,", "tokens": ["Denn", "der", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "$,"], "meter": "++-+", "measure": "iambic.di"}, "line.11": {"text": "Das Erscheinen des Bischofs anzuzeigen;", "tokens": ["Das", "Er\u00b7schei\u00b7nen", "des", "Bi\u00b7schofs", "an\u00b7zu\u00b7zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Und schon sah man ihn die Stufen aufsteigen", "tokens": ["Und", "schon", "sah", "man", "ihn", "die", "Stu\u00b7fen", "auf\u00b7stei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PPER", "ART", "NN", "VVINF"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Und den Rath und die Frauen vor ihm sich neigen.", "tokens": ["Und", "den", "Rath", "und", "die", "Frau\u00b7en", "vor", "ihm", "sich", "nei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KON", "ART", "NN", "APPR", "PPER", "PRF", "VVFIN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Es war, wie man alsbald murmelnd spricht,", "tokens": ["Es", "war", ",", "wie", "man", "als\u00b7bald", "mur\u00b7melnd", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "PIS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Und sich im Volke verhehlte nicht", "tokens": ["Und", "sich", "im", "Vol\u00b7ke", "ver\u00b7hehl\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PRF", "APPRART", "NN", "VVFIN", "PTKNEG"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Ein Mann von Gewicht", "tokens": ["Ein", "Mann", "von", "Ge\u00b7wicht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.17": {"text": "Mit rundgl\u00e4nzendem Angesicht,", "tokens": ["Mit", "rund\u00b7gl\u00e4n\u00b7zen\u00b7dem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "Das herniedersah wie ein Vollmondlicht.", "tokens": ["Das", "her\u00b7nie\u00b7der\u00b7sah", "wie", "ein", "Voll\u00b7mond\u00b7licht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Wie er jetzt", "tokens": ["Wie", "er", "jetzt"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Neben dem Rathe sich niedersetzt,", "tokens": ["Ne\u00b7ben", "dem", "Ra\u00b7the", "sich", "nie\u00b7der\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PRF", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Und allm\u00e4hlig umher ward Ruh,", "tokens": ["Und", "all\u00b7m\u00e4h\u00b7lig", "um\u00b7her", "ward", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKVZ", "VAFIN", "NN", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da winkt er einem Trompeter zu;", "tokens": ["Da", "winkt", "er", "ei\u00b7nem", "Trom\u00b7pe\u00b7ter", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Der gab ein Zeichen mit hellem Trara.", "tokens": ["Der", "gab", "ein", "Zei\u00b7chen", "mit", "hel\u00b7lem", "Tra\u00b7ra", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da \u2013", "tokens": ["Da", "\u2013"], "token_info": ["word", "punct"], "pos": ["KOUS", "$("], "meter": "+", "measure": "single.up"}}, "stanza.6": {"line.1": {"text": "Lustig wie ein Feuer im Kamine knattert,", "tokens": ["Lus\u00b7tig", "wie", "ein", "Feu\u00b7er", "im", "Ka\u00b7mi\u00b7ne", "knat\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Und wie im Wind eine Fahne flattert,", "tokens": ["Und", "wie", "im", "Wind", "ei\u00b7ne", "Fah\u00b7ne", "flat\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Risch und frisch", "tokens": ["Risch", "und", "frisch"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "ADJD"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wie im Wasser ein Fisch,", "tokens": ["Wie", "im", "Was\u00b7ser", "ein", "Fisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Wie ein Vogel im Geb\u00fcsch,", "tokens": ["Wie", "ein", "Vo\u00b7gel", "im", "Ge\u00b7b\u00fcsch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "So kamen zwei Reiter, die Z\u00fcgel verh\u00e4ngt,", "tokens": ["So", "ka\u00b7men", "zwei", "Rei\u00b7ter", ",", "die", "Z\u00fc\u00b7gel", "ver\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "CARD", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.7": {"text": "Auf der harten Allee heraufgesprengt,", "tokens": ["Auf", "der", "har\u00b7ten", "Al\u00b7lee", "her\u00b7auf\u00b7ge\u00b7sprengt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Im Galopp ein Fuchs, im Galopp ein Schimmel,", "tokens": ["Im", "Ga\u00b7lopp", "ein", "Fuchs", ",", "im", "Ga\u00b7lopp", "ein", "Schim\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "$,", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Mit Jubel begr\u00fc\u00dft von dem Menschengewimmel.", "tokens": ["Mit", "Ju\u00b7bel", "be\u00b7gr\u00fc\u00dft", "von", "dem", "Men\u00b7schen\u00b7ge\u00b7wim\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Zum Rondell galoppirt in vollem Lauf,", "tokens": ["Zum", "Ron\u00b7dell", "ga\u00b7lop\u00b7pirt", "in", "vol\u00b7lem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Stellten sie gegen einander sich auf", "tokens": ["Stell\u00b7ten", "sie", "ge\u00b7gen", "ein\u00b7an\u00b7der", "sich", "auf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PRF", "PRF", "APPR"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.12": {"text": "Und gr\u00fc\u00dften fein zu dem Rath und dem Bischof hinauf", "tokens": ["Und", "gr\u00fc\u00df\u00b7ten", "fein", "zu", "dem", "Rath", "und", "dem", "Bi\u00b7schof", "hin\u00b7auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "KON", "ART", "NN", "PTKVZ"], "meter": "-+-+--+--++-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Und gr\u00fc\u00dften munter", "tokens": ["Und", "gr\u00fc\u00df\u00b7ten", "mun\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "Zum ganzen Publikum hinunter.", "tokens": ["Zum", "gan\u00b7zen", "Pub\u00b7li\u00b7kum", "hin\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch wie man sie n\u00e4her erschaut und gewahrt,", "tokens": ["Doch", "wie", "man", "sie", "n\u00e4\u00b7her", "er\u00b7schaut", "und", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "PPER", "ADJD", "VVPP", "KON", "VVPP", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sie erschienen gar wunderlicher Art:", "tokens": ["Sie", "er\u00b7schie\u00b7nen", "gar", "wun\u00b7der\u00b7li\u00b7cher", "Art", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Der auf dem Schimmel trug ein streif'ges Gewand,", "tokens": ["Der", "auf", "dem", "Schim\u00b7mel", "trug", "ein", "streif'\u00b7ges", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Das schwarz, wei\u00df und roth mit einander verband,", "tokens": ["Das", "schwarz", ",", "wei\u00df", "und", "roth", "mit", "ein\u00b7an\u00b7der", "ver\u00b7band", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "$,", "VVFIN", "KON", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Auf der linken Brust,", "tokens": ["Auf", "der", "lin\u00b7ken", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.6": {"text": "Stolz bewu\u00dft,", "tokens": ["Stolz", "be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Als Orden von verschiedenen R\u00e4ngen,", "tokens": ["Als", "Or\u00b7den", "von", "ver\u00b7schie\u00b7de\u00b7nen", "R\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Hat er drei todte Spatzen h\u00e4ngen,", "tokens": ["Hat", "er", "drei", "tod\u00b7te", "Spat\u00b7zen", "h\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "CARD", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Aber sein Haupt", "tokens": ["A\u00b7ber", "sein", "Haupt"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "War ganz von k\u00fcnstlichen Wein umlaubt.", "tokens": ["War", "ganz", "von", "k\u00fcnst\u00b7li\u00b7chen", "Wein", "um\u00b7laubt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Sein Gegner diesen Anblick bot:", "tokens": ["Sein", "Geg\u00b7ner", "die\u00b7sen", "An\u00b7blick", "bot", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War von Kopf bis F\u00fc\u00dfen feuerroth.", "tokens": ["War", "von", "Kopf", "bis", "F\u00fc\u00b7\u00dfen", "feu\u00b7er\u00b7roth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "APPR", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mitten auf der Brust drei goldene Sterne", "tokens": ["Mit\u00b7ten", "auf", "der", "Brust", "drei", "gol\u00b7de\u00b7ne", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "CARD", "ADJA", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Leuchteten ihm schon von ferne;", "tokens": ["Leuch\u00b7te\u00b7ten", "ihm", "schon", "von", "fer\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Auf dem Kopf aber trug der Gesell", "tokens": ["Auf", "dem", "Kopf", "a\u00b7ber", "trug", "der", "Ge\u00b7sell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "ART", "NN"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Ein nat\u00fcrliches B\u00e4renfell. \u2013", "tokens": ["Ein", "na\u00b7t\u00fcr\u00b7li\u00b7ches", "B\u00e4\u00b7ren\u00b7fell", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Dazu jeder von beiden schwenkte stolz", "tokens": ["Da\u00b7zu", "je\u00b7der", "von", "bei\u00b7den", "schwenk\u00b7te", "stolz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PIS", "APPR", "PIAT", "ADJA", "NN"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "In der Hand eine Pritsche von klatschendem Holz.", "tokens": ["In", "der", "Hand", "ei\u00b7ne", "Prit\u00b7sche", "von", "klat\u00b7schen\u00b7dem", "Holz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.9": {"line.1": {"text": "Und jetzt der Rothe den Kampf anbrach", "tokens": ["Und", "jetzt", "der", "Ro\u00b7the", "den", "Kampf", "an\u00b7brach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und zum Schimmelgestreiften also sprach:", "tokens": ["Und", "zum", "Schim\u00b7mel\u00b7ge\u00b7streif\u00b7ten", "al\u00b7so", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "VVFIN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Wohledler Ritter mit Rappen und Speer,", "tokens": ["Woh\u00b7led\u00b7ler", "Rit\u00b7ter", "mit", "Rap\u00b7pen", "und", "Speer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit Wappen und Wehr,", "tokens": ["Mit", "Wap\u00b7pen", "und", "Wehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Wo kommt ihr her?", "tokens": ["Wo", "kommt", "ihr", "her", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Drauf jener \u00f6ffnete den Mund", "tokens": ["Drauf", "je\u00b7ner", "\u00f6ff\u00b7ne\u00b7te", "den", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "PDS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und mit heller Stimme Rede stund:", "tokens": ["Und", "mit", "hel\u00b7ler", "Stim\u00b7me", "Re\u00b7de", "stund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "So gesegnet wie mein Land,", "tokens": ["So", "ge\u00b7seg\u00b7net", "wie", "mein", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das Rheinland,", "tokens": ["Das", "Rhein\u00b7land", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Das Weinland,", "tokens": ["Das", "Wein\u00b7land", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Ist kein Land!", "tokens": ["Ist", "kein", "Land", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Ich bin aus dem Bann von Bonn zu Haus,", "tokens": ["Ich", "bin", "aus", "dem", "Bann", "von", "Bonn", "zu", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "NE", "APPR", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Auf den goldigen Bergen da kenn' ich mich aus,", "tokens": ["Auf", "den", "gol\u00b7di\u00b7gen", "Ber\u00b7gen", "da", "kenn'", "ich", "mich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}, "line.7": {"text": "Und meine Wiege stand neben dem Wein,", "tokens": ["Und", "mei\u00b7ne", "Wie\u00b7ge", "stand", "ne\u00b7ben", "dem", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "War rings umgl\u00e4nzt vom Sonnenschein? \u2013", "tokens": ["War", "rings", "um\u00b7gl\u00e4nzt", "vom", "Son\u00b7nen\u00b7schein", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "VVPP", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So la\u00df mich nach deiner Herkunft fragen.", "tokens": ["So", "la\u00df", "mich", "nach", "dei\u00b7ner", "Her\u00b7kunft", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Was kannst du mir dagegen sagen?", "tokens": ["Was", "kannst", "du", "mir", "da\u00b7ge\u00b7gen", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PRF", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und der Rothe, ruhig und gelassen,", "tokens": ["Und", "der", "Ro\u00b7the", ",", "ru\u00b7hig", "und", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ADJD", "KON", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Antwortete folgenderma\u00dfen:", "tokens": ["Ant\u00b7wor\u00b7te\u00b7te", "fol\u00b7gen\u00b7der\u00b7ma\u00b7\u00dfen", ":"], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "++--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Wo meine Wiege stand, wei\u00df ich kaum,", "tokens": ["Wo", "mei\u00b7ne", "Wie\u00b7ge", "stand", ",", "wei\u00df", "ich", "kaum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Kann mich nicht besinnen auf den Raum,", "tokens": ["Kann", "mich", "nicht", "be\u00b7sin\u00b7nen", "auf", "den", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "War es ein d\u00fcsterer, oder ein heller,", "tokens": ["War", "es", "ein", "d\u00fcs\u00b7te\u00b7rer", ",", "o\u00b7der", "ein", "hel\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJD", "$,", "KON", "ART", "ADJA", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.6": {"text": "War's unterm Dach, oder war es im Keller;", "tokens": ["Wa\u00b7r's", "un\u00b7term", "Dach", ",", "o\u00b7der", "war", "es", "im", "Kel\u00b7ler", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "$,", "KON", "VAFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "Nur so viel wei\u00df ich, es war in Berlin,", "tokens": ["Nur", "so", "viel", "wei\u00df", "ich", ",", "es", "war", "in", "Ber\u00b7lin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "APPR", "NE", "$,"], "meter": "+-+-+-+-++", "measure": "unknown.measure.hexa"}, "line.8": {"text": "Und mit dem Bewu\u00dftsein sag' ich k\u00fchn:", "tokens": ["Und", "mit", "dem", "Be\u00b7wu\u00df\u00b7tsein", "sag'", "ich", "k\u00fchn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Was du nur Sch\u00f6nes findest bei dir,", "tokens": ["Was", "du", "nur", "Sch\u00f6\u00b7nes", "fin\u00b7dest", "bei", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "NN", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Das find' ich hundertmal sch\u00f6ner hier! \u2013", "tokens": ["Das", "find'", "ich", "hun\u00b7dert\u00b7mal", "sch\u00f6\u00b7ner", "hier", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Jetzt aber sag' mir an,", "tokens": ["Jetzt", "a\u00b7ber", "sag'", "mir", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Was bist du f\u00fcr ein Mann?", "tokens": ["Was", "bist", "du", "f\u00fcr", "ein", "Mann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Welch Weges streifst du?", "tokens": ["Welch", "We\u00b7ges", "streifst", "du", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "Welch Liedlein pfeifst du? \u2013", "tokens": ["Welch", "Lied\u00b7lein", "pfeifst", "du", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-", "measure": "iambic.di"}, "line.15": {"text": "Von mir will ich's dir also sagen:", "tokens": ["Von", "mir", "will", "ich's", "dir", "al\u00b7so", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VMFIN", "PIS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "In tr\u00fcben Tagen", "tokens": ["In", "tr\u00fc\u00b7ben", "Ta\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Ohne Zagen", "tokens": ["Oh\u00b7ne", "Za\u00b7gen"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.18": {"text": "Aller Welt entgegenschlagen", "tokens": ["Al\u00b7ler", "Welt", "ent\u00b7ge\u00b7gen\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "Und just das Allerkeckste wagen,", "tokens": ["Und", "just", "das", "Al\u00b7ler\u00b7kecks\u00b7te", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Das wird bei mir sein gang und gebe,", "tokens": ["Das", "wird", "bei", "mir", "sein", "gang", "und", "ge\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "PPOSAT", "NN", "KON", "VVFIN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.21": {"text": "So lang ich lebe.", "tokens": ["So", "lang", "ich", "le\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.14": {"line.1": {"text": "Darauf der Bonner also sprach:", "tokens": ["Da\u00b7rauf", "der", "Bon\u00b7ner", "al\u00b7so", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Wohl jauchzten die Kinder Israel und sangen Hosianna,", "tokens": ["Wohl", "jauchz\u00b7ten", "die", "Kin\u00b7der", "Is\u00b7rael", "und", "san\u00b7gen", "Ho\u00b7si\u00b7an\u00b7na", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NE", "KON", "VVFIN", "NE", "$,"], "meter": "-+--+--+-+-+--+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Als sie endlich in der W\u00fcste gefunden das Manna;", "tokens": ["Als", "sie", "end\u00b7lich", "in", "der", "W\u00fcs\u00b7te", "ge\u00b7fun\u00b7den", "das", "Man\u00b7na", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVPP", "ART", "NN", "$."], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Aber vorher lie\u00dfen sie das Singen fein bleiben,", "tokens": ["A\u00b7ber", "vor\u00b7her", "lie\u00b7\u00dfen", "sie", "das", "Sin\u00b7gen", "fein", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Und nicht anders kann ich es treiben.", "tokens": ["Und", "nicht", "an\u00b7ders", "kann", "ich", "es", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Wenn mein Gem\u00fcth murrt, kann mein Lied nicht klingen,", "tokens": ["Wenn", "mein", "Ge\u00b7m\u00fcth", "murrt", ",", "kann", "mein", "Lied", "nicht", "klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wenn mein Magen knurrt, kann mein Mund nicht singen.", "tokens": ["Wenn", "mein", "Ma\u00b7gen", "knurrt", ",", "kann", "mein", "Mund", "nicht", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Ich bin einer, der bei dem Vollen lieber blieb,", "tokens": ["Ich", "bin", "ei\u00b7ner", ",", "der", "bei", "dem", "Vol\u00b7len", "lie\u00b7ber", "blieb", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$,", "PRELS", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Als bei dem, was \u00fcberblieb.", "tokens": ["Als", "bei", "dem", ",", "was", "\u00fc\u00b7berb\u00b7lieb", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "$,", "PWS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Wie der Waldmeister lieblichen Duft nur spr\u00fcht,", "tokens": ["Wie", "der", "Wald\u00b7meis\u00b7ter", "lieb\u00b7li\u00b7chen", "Duft", "nur", "spr\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Wenn er vom Weine gl\u00fcht,", "tokens": ["Wenn", "er", "vom", "Wei\u00b7ne", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "So auch ert\u00f6net beim Wein mein Lied;", "tokens": ["So", "auch", "er\u00b7t\u00f6\u00b7net", "beim", "Wein", "mein", "Lied", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Aber wie wenn im Regen die Amsel", "tokens": ["A\u00b7ber", "wie", "wenn", "im", "Re\u00b7gen", "die", "Am\u00b7sel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOKOM", "KOUS", "APPRART", "NN", "ART", "NN"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.13": {"text": "Aufsch\u00fcttelt ihr flockiges Wamsel", "tokens": ["Auf\u00b7sch\u00fct\u00b7telt", "ihr", "flo\u00b7cki\u00b7ges", "Wam\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und ihr Schn\u00e4blein unter den Fl\u00fcgel steckt,", "tokens": ["Und", "ihr", "Schn\u00e4b\u00b7lein", "un\u00b7ter", "den", "Fl\u00fc\u00b7gel", "steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "So warm geduckt und warm gedeckt", "tokens": ["So", "warm", "ge\u00b7duckt", "und", "warm", "ge\u00b7deckt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "KON", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mu\u00df mein Haupt sein, wann St\u00fcrme kommen,", "tokens": ["Mu\u00df", "mein", "Haupt", "sein", ",", "wann", "St\u00fcr\u00b7me", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "VAINF", "$,", "PWAV", "NN", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Anders kann mein Gesang nicht frommen.", "tokens": ["An\u00b7ders", "kann", "mein", "Ge\u00b7sang", "nicht", "from\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Darum bei einem hohen Herrn", "tokens": ["Da\u00b7rum", "bei", "ei\u00b7nem", "ho\u00b7hen", "Herrn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Da-weil' ich gern,", "tokens": ["Da\u00b7weil'", "ich", "gern", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.20": {"text": "Zu dem will ich sagen: O Herr, sieh her!", "tokens": ["Zu", "dem", "will", "ich", "sa\u00b7gen", ":", "O", "Herr", ",", "sieh", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "VMFIN", "PPER", "VVINF", "$.", "NE", "NN", "$,", "VVIMP", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Mein Becher und mein Beutel sind beide leer.", "tokens": ["Mein", "Be\u00b7cher", "und", "mein", "Beu\u00b7tel", "sind", "bei\u00b7de", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "VAFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Wirst du sie nicht f\u00fcllen, mu\u00df mich Finsterni\u00df umnachten,", "tokens": ["Wirst", "du", "sie", "nicht", "f\u00fcl\u00b7len", ",", "mu\u00df", "mich", "Fins\u00b7ter\u00b7ni\u00df", "um\u00b7nach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,", "VMFIN", "PPER", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.23": {"text": "Wirst du den Durst nicht stillen, so mu\u00df ich verschmachten.", "tokens": ["Wirst", "du", "den", "Durst", "nicht", "stil\u00b7len", ",", "so", "mu\u00df", "ich", "ver\u00b7schmach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Ich sch\u00e4tz' aber auch den Spruch nicht wenig:", "tokens": ["Ich", "sch\u00e4tz'", "a\u00b7ber", "auch", "den", "Spruch", "nicht", "we\u00b7nig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Wer lieblich redet, de\u00df Freund ist der K\u00f6nig.", "tokens": ["Wer", "lieb\u00b7lich", "re\u00b7det", ",", "de\u00df", "Freund", "ist", "der", "K\u00f6\u00b7nig", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVFIN", "$,", "ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Dann stehet er da auf der H\u00f6he,", "tokens": ["Dann", "ste\u00b7het", "er", "da", "auf", "der", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Unber\u00fchrt von der Sorgen Ach und Wehe,", "tokens": ["Un\u00b7be\u00b7r\u00fchrt", "von", "der", "Sor\u00b7gen", "Ach", "und", "We\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.28": {"text": "In reinerem Klang kann da sein Sang ert\u00f6nen", "tokens": ["In", "rei\u00b7ne\u00b7rem", "Klang", "kann", "da", "sein", "Sang", "er\u00b7t\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Zu allem Lieblichen, allem Sch\u00f6nen,", "tokens": ["Zu", "al\u00b7lem", "Lieb\u00b7li\u00b7chen", ",", "al\u00b7lem", "Sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "$,", "PIS", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Und wie ein Gott von seinem Himmel", "tokens": ["Und", "wie", "ein", "Gott", "von", "sei\u00b7nem", "Him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Schaut er herab auf alles niedere Gewimmel!", "tokens": ["Schaut", "er", "her\u00b7ab", "auf", "al\u00b7les", "nie\u00b7de\u00b7re", "Ge\u00b7wim\u00b7mel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Da klatschten Viele Beifall; von den Frauen jede. \u2013", "tokens": ["Da", "klatschten", "Vie\u00b7le", "Bei\u00b7fall", ";", "von", "den", "Frau\u00b7en", "je\u00b7de", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$.", "APPR", "ART", "NN", "PIAT", "$.", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und der Berliner hub so an die Gegenrede:", "tokens": ["Und", "der", "Ber\u00b7li\u00b7ner", "hub", "so", "an", "die", "Ge\u00b7gen\u00b7re\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Es giebt H\u00e4hne, die auf der Erde kr\u00e4hn,", "tokens": ["Es", "giebt", "H\u00e4h\u00b7ne", ",", "die", "auf", "der", "Er\u00b7de", "kr\u00e4hn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und H\u00e4hne, die auf dem Dach sich drehn.", "tokens": ["Und", "H\u00e4h\u00b7ne", ",", "die", "auf", "dem", "Dach", "sich", "drehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPR", "ART", "NN", "PRF", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Der eine zu seinem Vergn\u00fcgen kr\u00e4ht,", "tokens": ["Der", "ei\u00b7ne", "zu", "sei\u00b7nem", "Ver\u00b7gn\u00fc\u00b7gen", "kr\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Der andere, weil der Wind ihn dreht.", "tokens": ["Der", "an\u00b7de\u00b7re", ",", "weil", "der", "Wind", "ihn", "dreht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Der eine steht unten, der andere oben,", "tokens": ["Der", "ei\u00b7ne", "steht", "un\u00b7ten", ",", "der", "an\u00b7de\u00b7re", "o\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ADV", "$,", "PRELS", "PIS", "ADV", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Wen von beiden willst ", "tokens": ["Wen", "von", "bei\u00b7den", "willst"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "PIAT", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Den einen nenn' ich einen G\u00f6tterhahn,", "tokens": ["Den", "ei\u00b7nen", "nenn'", "ich", "ei\u00b7nen", "G\u00f6t\u00b7ter\u00b7hahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Der andere ist nur ein Wetterhahn! \u2013", "tokens": ["Der", "an\u00b7de\u00b7re", "ist", "nur", "ein", "Wet\u00b7ter\u00b7hahn", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PIS", "VAFIN", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Ein Beifallssturm erscholl bei diesem Wort,", "tokens": ["Ein", "Bei\u00b7falls\u00b7sturm", "er\u00b7scholl", "bei", "die\u00b7sem", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und er fuhr fort:", "tokens": ["Und", "er", "fuhr", "fort", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.18": {"line.1": {"text": "Bl\u00e4st der Wind nach Osten,", "tokens": ["Bl\u00e4st", "der", "Wind", "nach", "Os\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00df er sich drehn nach Osten,", "tokens": ["Mu\u00df", "er", "sich", "drehn", "nach", "Os\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "CARD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bl\u00e4st er nordw\u00e4rts, kann er nordw\u00e4rts verrosten.", "tokens": ["Bl\u00e4st", "er", "nord\u00b7w\u00e4rts", ",", "kann", "er", "nord\u00b7w\u00e4rts", "ver\u00b7ros\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "VMFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Also du suchst einen hohen Herrn?", "tokens": ["Al\u00b7so", "du", "suchst", "ei\u00b7nen", "ho\u00b7hen", "Herrn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Ihn dir zu mi\u00dfg\u00f6nnen liegt mir fern.", "tokens": ["Ihn", "dir", "zu", "mi\u00df\u00b7g\u00f6n\u00b7nen", "liegt", "mir", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "PTKZU", "VVINF", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Siehe, Saul zog aus,", "tokens": ["Sie\u00b7he", ",", "Saul", "zog", "aus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Aus niederem Haus,", "tokens": ["Aus", "nie\u00b7de\u00b7rem", "Haus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Suchte zwei Esel und fand zugleich", "tokens": ["Such\u00b7te", "zwei", "E\u00b7sel", "und", "fand", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "CARD", "NN", "KON", "VVFIN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Ein K\u00f6nigreich.", "tokens": ["Ein", "K\u00f6\u00b7nig\u00b7reich", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Warum solltest du auch dein Gl\u00fcck nicht gr\u00fcnden?", "tokens": ["Wa\u00b7rum", "soll\u00b7test", "du", "auch", "dein", "Gl\u00fcck", "nicht", "gr\u00fcn\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Warum solltest du was du suchst nicht finden?", "tokens": ["Wa\u00b7rum", "soll\u00b7test", "du", "was", "du", "suchst", "nicht", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PWS", "PPER", "VVFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Willst du ein Hofpoetlein werden?", "tokens": ["Willst", "du", "ein", "Hof\u00b7poet\u00b7lein", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Der Himmel segne dein Streben auf Erden.", "tokens": ["Der", "Him\u00b7mel", "seg\u00b7ne", "dein", "Stre\u00b7ben", "auf", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Ich glaub' es freilich, es ist ihr Amt", "tokens": ["Ich", "glaub'", "es", "frei\u00b7lich", ",", "es", "ist", "ihr", "Amt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Zu den sch\u00f6nsten Annehmlichkeiten verdammt,", "tokens": ["Zu", "den", "sch\u00f6ns\u00b7ten", "An\u00b7nehm\u00b7lich\u00b7kei\u00b7ten", "ver\u00b7dammt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Behaglich wie einer Katze Schnurren", "tokens": ["Be\u00b7hag\u00b7lich", "wie", "ei\u00b7ner", "Kat\u00b7ze", "Schnur\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und lieblich wie des Taubers Gurren,", "tokens": ["Und", "lieb\u00b7lich", "wie", "des", "Tau\u00b7bers", "Gur\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "So angenehm wie Geld in der Truhe", "tokens": ["So", "an\u00b7ge\u00b7nehm", "wie", "Geld", "in", "der", "Tru\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Und so bequem wie Morgenschuhe.", "tokens": ["Und", "so", "be\u00b7quem", "wie", "Mor\u00b7gen\u00b7schu\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Sie gehn so stolz daher in ihrem Narrenkleid,", "tokens": ["Sie", "gehn", "so", "stolz", "da\u00b7her", "in", "ih\u00b7rem", "Nar\u00b7ren\u00b7kleid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PAV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Mit Kreuzlein beh\u00e4ngt und Ordensgeschmeid,", "tokens": ["Mit", "Kreuz\u00b7lein", "be\u00b7h\u00e4ngt", "und", "Or\u00b7dens\u00b7ge\u00b7schmeid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Aber ein Gesunder hohnlacht", "tokens": ["A\u00b7ber", "ein", "Ge\u00b7sun\u00b7der", "hohn\u00b7lacht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.23": {"text": "Ihrer Ohnmacht", "tokens": ["Ih\u00b7rer", "Ohn\u00b7macht"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.24": {"text": "Und ihrer ekeln Unmannbarkeit;", "tokens": ["Und", "ih\u00b7rer", "e\u00b7keln", "Un\u00b7mann\u00b7bar\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.25": {"text": "Denn ein kr\u00e4ftiges Wort zur rechten Zeit,", "tokens": ["Denn", "ein", "kr\u00e4f\u00b7ti\u00b7ges", "Wort", "zur", "rech\u00b7ten", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.26": {"text": "Das st\u00fcnd' ihnen ja so stattlich zu Leibe", "tokens": ["Das", "st\u00fcnd'", "ih\u00b7nen", "ja", "so", "statt\u00b7lich", "zu", "Lei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "APPR", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Wie ein Schnurrbart dem Weibe.", "tokens": ["Wie", "ein", "Schnurr\u00b7bart", "dem", "Wei\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.28": {"text": "Sie bleiber immerdar so erbaulich, beschaulich,", "tokens": ["Sie", "blei\u00b7ber", "im\u00b7mer\u00b7dar", "so", "er\u00b7bau\u00b7lich", ",", "be\u00b7schau\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADV", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Loben und erheben ihre Zeit gar graulich,", "tokens": ["Lo\u00b7ben", "und", "er\u00b7he\u00b7ben", "ih\u00b7re", "Zeit", "gar", "grau\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.30": {"text": "Besingen ihre G\u00f6tzen erg\u00f6tzlich,", "tokens": ["Be\u00b7sin\u00b7gen", "ih\u00b7re", "G\u00f6t\u00b7zen", "er\u00b7g\u00f6tz\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Entsetzlich,", "tokens": ["Ent\u00b7setz\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.32": {"text": "Bewedeln die Edlen so s\u00fc\u00dflich,", "tokens": ["Be\u00b7we\u00b7deln", "die", "Ed\u00b7len", "so", "s\u00fc\u00df\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.33": {"text": "Ersprie\u00dflich,", "tokens": ["Er\u00b7sprie\u00df\u00b7lich", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.34": {"text": "Oder auch sie werden zu singen verdrie\u00dflich.", "tokens": ["O\u00b7der", "auch", "sie", "wer\u00b7den", "zu", "sin\u00b7gen", "ver\u00b7drie\u00df\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VAINF", "PTKZU", "VVINF", "ADJD", "$."], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.35": {"text": "Und k\u00fcmmern sich schlie\u00dflich", "tokens": ["Und", "k\u00fcm\u00b7mern", "sich", "schlie\u00df\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.36": {"text": "Mehr um Mosen und die Propheten,", "tokens": ["Mehr", "um", "Mo\u00b7sen", "und", "die", "Pro\u00b7phe\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.37": {"text": "Als um die Musen und die Poeten.", "tokens": ["Als", "um", "die", "Mu\u00b7sen", "und", "die", "Po\u00b7et\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Lachen und Beifall rings erklang.", "tokens": ["La\u00b7chen", "und", "Bei\u00b7fall", "rings", "er\u00b7klang", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und der Bonner dagegen sang:", "tokens": ["Und", "der", "Bon\u00b7ner", "da\u00b7ge\u00b7gen", "sang", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PAV", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.20": {"line.1": {"text": "Du kriegst mit Gegnern, die du dir geschaffen", "tokens": ["Du", "kriegst", "mit", "Geg\u00b7nern", ",", "die", "du", "dir", "ge\u00b7schaf\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "PRELS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und siegst mit ungeschliff'nen Waffen,", "tokens": ["Und", "siegst", "mit", "un\u00b7ge\u00b7schliff'\u00b7nen", "Waf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Aber dein Krieg erliegt", "tokens": ["A\u00b7ber", "dein", "Krieg", "er\u00b7liegt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Und dein Sieg versiegt", "tokens": ["Und", "dein", "Sieg", "ver\u00b7siegt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Dein Schelten ist Schein,", "tokens": ["Dein", "Schel\u00b7ten", "ist", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Wer verst\u00e4ndig ist, sieht es ein.", "tokens": ["Wer", "ver\u00b7st\u00e4n\u00b7dig", "ist", ",", "sieht", "es", "ein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Statt gl\u00fccklich zu sein \u00fcber gl\u00fcckliche Saat,", "tokens": ["Statt", "gl\u00fcck\u00b7lich", "zu", "sein", "\u00fc\u00b7ber", "gl\u00fcck\u00b7li\u00b7che", "Saat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKZU", "VAINF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Willst du betreten den Dornenpfad,", "tokens": ["Willst", "du", "be\u00b7tre\u00b7ten", "den", "Dor\u00b7nen\u00b7pfad", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Auszuj\u00e4ten was faul ist im Staat?", "tokens": ["Aus\u00b7zu\u00b7j\u00e4\u00b7ten", "was", "faul", "ist", "im", "Staat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADJD", "VAFIN", "APPRART", "NN", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.10": {"text": "Leicht ist der Rath,", "tokens": ["Leicht", "ist", "der", "Rath", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.11": {"text": "Schwer die That.", "tokens": ["Schwer", "die", "That", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Wer sie will verrichten,", "tokens": ["Wer", "sie", "will", "ver\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.13": {"text": "Mu\u00df auf jede Freude verzichten.", "tokens": ["Mu\u00df", "auf", "je\u00b7de", "Freu\u00b7de", "ver\u00b7zich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.14": {"text": "Soll ich etwa Verdammungsurtheile singen", "tokens": ["Soll", "ich", "et\u00b7wa", "Ver\u00b7dam\u00b7mungs\u00b7urt\u00b7hei\u00b7le", "sin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Und von allen mit Unrecht geschehenen Dingen", "tokens": ["Und", "von", "al\u00b7len", "mit", "Un\u00b7recht", "ge\u00b7sche\u00b7he\u00b7nen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "APPR", "NN", "ADJA", "NN"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.16": {"text": "An die rechte Stelle Kunde bringen?", "tokens": ["An", "die", "rech\u00b7te", "Stel\u00b7le", "Kun\u00b7de", "brin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Ein warmer Auftrag, ein hei\u00df Gehei\u00df,", "tokens": ["Ein", "war\u00b7mer", "Auf\u00b7trag", ",", "ein", "hei\u00df", "Ge\u00b7hei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "An dem man den Mund verbrennt, eh' man's wei\u00df.", "tokens": ["An", "dem", "man", "den", "Mund", "ver\u00b7brennt", ",", "eh'", "man's", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "ART", "NN", "VVFIN", "$,", "KOUS", "PIS", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Meinst du etwa unverholen,", "tokens": ["Meinst", "du", "et\u00b7wa", "un\u00b7ver\u00b7ho\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Ich werde mich machen auf die Sohlen", "tokens": ["Ich", "wer\u00b7de", "mich", "ma\u00b7chen", "auf", "die", "Soh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Und die Kastanien f\u00fcr dich aus den Kohlen holen? \u2013", "tokens": ["Und", "die", "Kas\u00b7ta\u00b7ni\u00b7en", "f\u00fcr", "dich", "aus", "den", "Koh\u00b7len", "ho\u00b7len", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "APPR", "PRF", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.22": {"text": "Und dein Angriff thut des Guten zu viel", "tokens": ["Und", "dein", "An\u00b7griff", "thut", "des", "Gu\u00b7ten", "zu", "viel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "NN", "APPR", "PIAT"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.23": {"text": "Und dein Bogen schie\u00dft \u00fcber das Ziel.", "tokens": ["Und", "dein", "Bo\u00b7gen", "schie\u00dft", "\u00fc\u00b7ber", "das", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.24": {"text": "Giebt's nicht in unsern Landen zur Zeit", "tokens": ["Giebt's", "nicht", "in", "un\u00b7sern", "Lan\u00b7den", "zur", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "PTKNEG", "APPR", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.25": {"text": "M\u00e4nner, die wacker gestanden im Streit?", "tokens": ["M\u00e4n\u00b7ner", ",", "die", "wa\u00b7cker", "ge\u00b7stan\u00b7den", "im", "Streit", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVPP", "APPRART", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.26": {"text": "Ist nicht von ihren Zungen", "tokens": ["Ist", "nicht", "von", "ih\u00b7ren", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "Manch freiheitliches Lied erklungen?", "tokens": ["Manch", "frei\u00b7heit\u00b7li\u00b7ches", "Lied", "er\u00b7klun\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Da rief der Berliner:", "tokens": ["Da", "rief", "der", "Ber\u00b7li\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}}, "stanza.22": {"line.1": {"text": "Wetterwend'sch", "tokens": ["Wet\u00b7ter\u00b7wen\u00b7d'sch"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Ist der Mensch!", "tokens": ["Ist", "der", "Mensch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Unter hunderten findet sich einer kaum,", "tokens": ["Un\u00b7ter", "hun\u00b7der\u00b7ten", "fin\u00b7det", "sich", "ei\u00b7ner", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PRF", "ART", "ADV", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Der Wurzen hat wie ein Eichenbaum.", "tokens": ["Der", "Wur\u00b7zen", "hat", "wie", "ein", "Ei\u00b7chen\u00b7baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ich wei\u00df wohl, welche du meinst,", "tokens": ["Ich", "wei\u00df", "wohl", ",", "wel\u00b7che", "du", "meinst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PRELS", "PPER", "ADV", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Sie geh\u00f6rten zu den Bessern einst,", "tokens": ["Sie", "ge\u00b7h\u00f6r\u00b7ten", "zu", "den", "Bes\u00b7sern", "einst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Aber da sie nicht anders sich zu helfen wu\u00dften,", "tokens": ["A\u00b7ber", "da", "sie", "nicht", "an\u00b7ders", "sich", "zu", "hel\u00b7fen", "wu\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "ADV", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Als da\u00df sie mitheulen mit den W\u00f6lfen mu\u00dften,", "tokens": ["Als", "da\u00df", "sie", "mi\u00b7theu\u00b7len", "mit", "den", "W\u00f6l\u00b7fen", "mu\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "Anstatt die L\u00fcge auszuroden,", "tokens": ["An\u00b7statt", "die", "L\u00fc\u00b7ge", "aus\u00b7zu\u00b7ro\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Nun sind sie auch verdorben in Grund und Boden.", "tokens": ["Nun", "sind", "sie", "auch", "ver\u00b7dor\u00b7ben", "in", "Grund", "und", "Bo\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Sie glitzern noch immer", "tokens": ["Sie", "glit\u00b7zern", "noch", "im\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "In falschem Schimmer,", "tokens": ["In", "fal\u00b7schem", "Schim\u00b7mer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "Und da\u00df sie l\u00e4ngst todt sind, merken sie nimmer.", "tokens": ["Und", "da\u00df", "sie", "l\u00e4ngst", "todt", "sind", ",", "mer\u00b7ken", "sie", "nim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Wer zu seinem guten Gl\u00fccke", "tokens": ["Wer", "zu", "sei\u00b7nem", "gu\u00b7ten", "Gl\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "Fern ist geblieben ihrer Klique,", "tokens": ["Fern", "ist", "ge\u00b7blie\u00b7ben", "ih\u00b7rer", "Kli\u00b7que", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "Auf sich selber vertrauend in allem Leid,", "tokens": ["Auf", "sich", "sel\u00b7ber", "ver\u00b7trau\u00b7end", "in", "al\u00b7lem", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADV", "VVPP", "APPR", "PIS", "NN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "Keinen Herrn \u00fcber sich als die Zeit,", "tokens": ["Kei\u00b7nen", "Herrn", "\u00fc\u00b7ber", "sich", "als", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PRF", "KOUS", "ART", "NN", "$,"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.18": {"text": "Und von ihrem F\u00fchrerstab", "tokens": ["Und", "von", "ih\u00b7rem", "F\u00fch\u00b7rer\u00b7stab"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.19": {"text": "Keinen kennend, der ihm zu lernen gab,", "tokens": ["Kei\u00b7nen", "ken\u00b7nend", ",", "der", "ihm", "zu", "ler\u00b7nen", "gab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "$,", "PRELS", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "Der schaut nun lachend auf sie herab,", "tokens": ["Der", "schaut", "nun", "la\u00b7chend", "auf", "sie", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "APPR", "PPER", "ADV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.21": {"text": "Spielt mit ihrem Angstgeschrei", "tokens": ["Spielt", "mit", "ih\u00b7rem", "Angst\u00b7ge\u00b7schrei"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Und f\u00fchlt sich stark und frisch und frei", "tokens": ["Und", "f\u00fchlt", "sich", "stark", "und", "frisch", "und", "frei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Wie auf dem wilden Meer die M\u00f6ve,", "tokens": ["Wie", "auf", "dem", "wil\u00b7den", "Meer", "die", "M\u00f6\u00b7ve", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Wie in der W\u00fcste ein freudiger L\u00f6we.", "tokens": ["Wie", "in", "der", "W\u00fcs\u00b7te", "ein", "freu\u00b7di\u00b7ger", "L\u00f6\u00b7we", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ART", "ADJA", "NE", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}}, "stanza.23": {"line.1": {"text": "Der Bonner erwidert darauf und sprach:", "tokens": ["Der", "Bon\u00b7ner", "er\u00b7wi\u00b7dert", "da\u00b7rauf", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "KON", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.24": {"line.1": {"text": "Ja, da geh\u00f6rst du hin", "tokens": ["Ja", ",", "da", "ge\u00b7h\u00f6rst", "du", "hin"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Mit solchem Sinn,", "tokens": ["Mit", "sol\u00b7chem", "Sinn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "In die W\u00fcste, wo Niemand weilet,", "tokens": ["In", "die", "W\u00fcs\u00b7te", ",", "wo", "Nie\u00b7mand", "wei\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "In die Ein\u00f6de, da es heulet.", "tokens": ["In", "die", "Ein\u00b7\u00f6\u00b7de", ",", "da", "es", "heu\u00b7let", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bist du auch einer von jenen b\u00f6sen?", "tokens": ["Bist", "du", "auch", "ei\u00b7ner", "von", "je\u00b7nen", "b\u00f6\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "APPR", "PDAT", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ihr w\u00fcstes, wildes Wesen", "tokens": ["Ihr", "w\u00fcs\u00b7tes", ",", "wil\u00b7des", "We\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Wird uns vom Banne nicht erl\u00f6sen.", "tokens": ["Wird", "uns", "vom", "Ban\u00b7ne", "nicht", "er\u00b7l\u00f6\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Roh und ungeschlacht sind sie alle,", "tokens": ["Roh", "und", "un\u00b7ge\u00b7schlacht", "sind", "sie", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VAFIN", "PPER", "PIS", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.9": {"text": "Ihre Trauben sind Galle,", "tokens": ["Ih\u00b7re", "Trau\u00b7ben", "sind", "Gal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.10": {"text": "Sie haben bittere Beeren", "tokens": ["Sie", "ha\u00b7ben", "bit\u00b7te\u00b7re", "Bee\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Und k\u00f6nnen der Welt weder Trost gew\u00e4hren", "tokens": ["Und", "k\u00f6n\u00b7nen", "der", "Welt", "we\u00b7der", "Trost", "ge\u00b7w\u00e4h\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "KON", "NN", "VVINF"], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Noch Gutes geb\u00e4ren.", "tokens": ["Noch", "Gu\u00b7tes", "ge\u00b7b\u00e4\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVPP", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Sie sind wie ein Wild,", "tokens": ["Sie", "sind", "wie", "ein", "Wild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Das irre gegangen heult und br\u00fcllt.", "tokens": ["Das", "ir\u00b7re", "ge\u00b7gan\u00b7gen", "heult", "und", "br\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Das sind die f\u00fcr den Geist der Sch\u00f6nheit taugen", "tokens": ["Das", "sind", "die", "f\u00fcr", "den", "Geist", "der", "Sch\u00f6n\u00b7heit", "tau\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "APPR", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wie der Rauch f\u00fcr die Augen.", "tokens": ["Wie", "der", "Rauch", "f\u00fcr", "die", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.17": {"text": "Wie wenn im Wald in der Fr\u00fchlingsnacht", "tokens": ["Wie", "wenn", "im", "Wald", "in", "der", "Fr\u00fch\u00b7lings\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Bei des Mondlichts Pracht", "tokens": ["Bei", "des", "Mond\u00b7lichts", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Der Vogel fl\u00f6tet goldenen Klanges,", "tokens": ["Der", "Vo\u00b7gel", "fl\u00f6\u00b7tet", "gol\u00b7de\u00b7nen", "Klan\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Vor dem sich beugen alle T\u00f6chter des Gesanges,", "tokens": ["Vor", "dem", "sich", "beu\u00b7gen", "al\u00b7le", "T\u00f6ch\u00b7ter", "des", "Ge\u00b7san\u00b7ges", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "VVFIN", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und Blumen und B\u00e4ume sch\u00f6nheitstrunken", "tokens": ["Und", "Blu\u00b7men", "und", "B\u00e4u\u00b7me", "sch\u00f6n\u00b7heits\u00b7trun\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Sind and\u00e4chtig in stillem Schweigen versunken,", "tokens": ["Sind", "an\u00b7d\u00e4ch\u00b7tig", "in", "stil\u00b7lem", "Schwei\u00b7gen", "ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.23": {"text": "Da im Nu \u2013 hu!", "tokens": ["Da", "im", "Nu", "\u2013", "hu", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPRART", "ADV", "$(", "XY", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.24": {"text": "Rauschte daher ein Uhu", "tokens": ["Rauschte", "da\u00b7her", "ein", "U\u00b7hu"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PAV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.25": {"text": "Mit unheilbringendem Gesaus,", "tokens": ["Mit", "un\u00b7heil\u00b7brin\u00b7gen\u00b7dem", "Ge\u00b7saus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und alles Sch\u00f6ne ist aus \u2013", "tokens": ["Und", "al\u00b7les", "Sch\u00f6\u00b7ne", "ist", "aus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "APPR", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.27": {"text": "So kommen sie daher ungest\u00fcm", "tokens": ["So", "kom\u00b7men", "sie", "da\u00b7her", "un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PAV", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Wie ein Ungeth\u00fcm,", "tokens": ["Wie", "ein", "Un\u00b7ge\u00b7th\u00fcm", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.29": {"text": "Kennen keine Sch\u00f6nheit, keine Zierde,", "tokens": ["Ken\u00b7nen", "kei\u00b7ne", "Sch\u00f6n\u00b7heit", ",", "kei\u00b7ne", "Zier\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.30": {"text": "Haben nichts als wilde Begierde,", "tokens": ["Ha\u00b7ben", "nichts", "als", "wil\u00b7de", "Be\u00b7gier\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.31": {"text": "Und was wir bisher zu unserm Ruhme", "tokens": ["Und", "was", "wir", "bis\u00b7her", "zu", "un\u00b7serm", "Ruh\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.32": {"text": "Still verwahrt hielten im Heiligthume,", "tokens": ["Still", "ver\u00b7wahrt", "hiel\u00b7ten", "im", "Hei\u00b7lig\u00b7thu\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VVFIN", "APPRART", "NN", "$,"], "meter": "+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.33": {"text": "Sie wollen's aufessen mit Kruste und Krume.", "tokens": ["Sie", "wol\u00b7len's", "au\u00b7fes\u00b7sen", "mit", "Krus\u00b7te", "und", "Kru\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.34": {"text": "Manch Beifallsklatschen erscholl ringsum.", "tokens": ["Manch", "Bei\u00b7falls\u00b7klat\u00b7schen", "er\u00b7scholl", "ring\u00b7sum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "Und es sprach der Berliner wiederum:", "tokens": ["Und", "es", "sprach", "der", "Ber\u00b7li\u00b7ner", "wie\u00b7de\u00b7rum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "ADJA", "ADV", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.25": {"line.1": {"text": "So billig sind deine R\u00e4thsel", "tokens": ["So", "bil\u00b7lig", "sind", "dei\u00b7ne", "R\u00e4th\u00b7sel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie beim B\u00e4cker die Br\u00e4tzel.", "tokens": ["Wie", "beim", "B\u00e4\u00b7cker", "die", "Br\u00e4t\u00b7zel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Deiner Worte Sinn ist mir klar,", "tokens": ["Dei\u00b7ner", "Wor\u00b7te", "Sinn", "ist", "mir", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch was du darin thust offenbar,", "tokens": ["Doch", "was", "du", "da\u00b7rin", "thust", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PAV", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Das ist im tiefsten Grunde nicht wahr.", "tokens": ["Das", "ist", "im", "tiefs\u00b7ten", "Grun\u00b7de", "nicht", "wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPRART", "ADJA", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Sage mir vor Allem, ", "tokens": ["Sa\u00b7ge", "mir", "vor", "Al\u00b7lem", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PIS", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Ist der nicht besser als ein Scheinheiliger?", "tokens": ["Ist", "der", "nicht", "bes\u00b7ser", "als", "ein", "Schein\u00b7hei\u00b7li\u00b7ger", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PTKNEG", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Der L\u00fcge und der Heuchelei", "tokens": ["Der", "L\u00fc\u00b7ge", "und", "der", "Heu\u00b7che\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der tret' ich k\u00fchn den Kopf entzwei,", "tokens": ["Der", "tret'", "ich", "k\u00fchn", "den", "Kopf", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Oder ich rei\u00dfe ihr mindestens munter", "tokens": ["O\u00b7der", "ich", "rei\u00b7\u00dfe", "ihr", "min\u00b7des\u00b7tens", "mun\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.11": {"text": "Die Maske von dem Gesicht herunter,", "tokens": ["Die", "Mas\u00b7ke", "von", "dem", "Ge\u00b7sicht", "her\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.12": {"text": "Dein Hohlspiegel wird mich nicht schrecken.", "tokens": ["Dein", "Hohl\u00b7spie\u00b7gel", "wird", "mich", "nicht", "schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "Du willst vertuschen, so will ich aufdecken,", "tokens": ["Du", "willst", "ver\u00b7tu\u00b7schen", ",", "so", "will", "ich", "auf\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Du willst einlullen, ich will wecken.", "tokens": ["Du", "willst", "ein\u00b7lul\u00b7len", ",", "ich", "will", "we\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Ist es nicht hoch und hehr und sch\u00f6n und gro\u00df,", "tokens": ["Ist", "es", "nicht", "hoch", "und", "hehr", "und", "sch\u00f6n", "und", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "KON", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Zu lehren", "tokens": ["Zu", "leh\u00b7ren"], "token_info": ["word", "word"], "pos": ["PTKZU", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "Die da sind niedrig und elend und blind und blo\u00df?", "tokens": ["Die", "da", "sind", "nied\u00b7rig", "und", "e\u00b7lend", "und", "blind", "und", "blo\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ADJD", "KON", "ADJD", "KON", "ADJD", "KON", "ADV", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.18": {"text": "Ihnen die Augen aufzuthun?", "tokens": ["Ih\u00b7nen", "die", "Au\u00b7gen", "auf\u00b7zu\u00b7thun", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVIZU", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.19": {"text": "So woll'n wir darin nicht rasten noch ruhn.", "tokens": ["So", "woll'n", "wir", "da\u00b7rin", "nicht", "ras\u00b7ten", "noch", "ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PAV", "PTKNEG", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Und stehn wir auch wie in der W\u00fcste allein,", "tokens": ["Und", "stehn", "wir", "auch", "wie", "in", "der", "W\u00fcs\u00b7te", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "KOKOM", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.21": {"text": "Und ist auch der Anfang noch winzig und klein,", "tokens": ["Und", "ist", "auch", "der", "An\u00b7fang", "noch", "win\u00b7zig", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.22": {"text": "Wir d\u00fcrfen und wollen nicht muthlos sein.", "tokens": ["Wir", "d\u00fcr\u00b7fen", "und", "wol\u00b7len", "nicht", "muth\u00b7los", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "Und was winzig war, w\u00e4chst ungeheuer,", "tokens": ["Und", "was", "win\u00b7zig", "war", ",", "w\u00e4chst", "un\u00b7ge\u00b7heu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PWS", "ADJD", "VAFIN", "$,", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.24": {"text": "Aus Funken wird Feuer.", "tokens": ["Aus", "Fun\u00b7ken", "wird", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.26": {"line.1": {"text": "Der Bonner fiel ein:", "tokens": ["Der", "Bon\u00b7ner", "fiel", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.27": {"line.1": {"text": "Aber das Feuer spricht nicht, es ist genug;", "tokens": ["A\u00b7ber", "das", "Feu\u00b7er", "spricht", "nicht", ",", "es", "ist", "ge\u00b7nug", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKNEG", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Drum z\u00fcnd' es nicht an, so bleibst du klug.", "tokens": ["Drum", "z\u00fcnd'", "es", "nicht", "an", ",", "so", "bleibst", "du", "klug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auch dies la\u00df dir sagen,", "tokens": ["Auch", "dies", "la\u00df", "dir", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVIMP", "PPER", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Deine Ernte wird wenig Fr\u00fcchte tragen.", "tokens": ["Dei\u00b7ne", "Ern\u00b7te", "wird", "we\u00b7nig", "Fr\u00fcch\u00b7te", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Dem Esel sind drei K\u00f6rner Gerste in dem Magen", "tokens": ["Dem", "E\u00b7sel", "sind", "drei", "K\u00f6r\u00b7ner", "Gers\u00b7te", "in", "dem", "Ma\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "CARD", "NN", "NN", "APPR", "ART", "NN"], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Weit lieber als ein Zentner Golds, den er mu\u00df tragen.", "tokens": ["Weit", "lie\u00b7ber", "als", "ein", "Zent\u00b7ner", "Golds", ",", "den", "er", "mu\u00df", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "KOKOM", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Ein Murmeln und Murren die Menge durchlief.", "tokens": ["Ein", "Mur\u00b7meln", "und", "Mur\u00b7ren", "die", "Men\u00b7ge", "durch\u00b7lief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und der Berliner mit erregter Stimme rief:", "tokens": ["Und", "der", "Ber\u00b7li\u00b7ner", "mit", "er\u00b7reg\u00b7ter", "Stim\u00b7me", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}}, "stanza.29": {"line.1": {"text": "Wie die abgelebten Gesellen pl\u00e4rr'n,", "tokens": ["Wie", "die", "ab\u00b7ge\u00b7leb\u00b7ten", "Ge\u00b7sel\u00b7len", "pl\u00e4rr'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Mit solcher Weisheit bleib' mir fern!", "tokens": ["Mit", "sol\u00b7cher", "Weis\u00b7heit", "bleib'", "mir", "fern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Recht und die Wahrheit verk\u00fcnd' ich gern,", "tokens": ["Das", "Recht", "und", "die", "Wahr\u00b7heit", "ver\u00b7k\u00fcnd'", "ich", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Davor m\u00fcssen sich beugen die stolzen Herrn.", "tokens": ["Da\u00b7vor", "m\u00fcs\u00b7sen", "sich", "beu\u00b7gen", "die", "stol\u00b7zen", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PRF", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Die Wahrheit bleibt ewiglich bestehen", "tokens": ["Die", "Wahr\u00b7heit", "bleibt", "e\u00b7wig\u00b7lich", "be\u00b7ste\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "VVINF"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und reichet so weit die Welten gehen!", "tokens": ["Und", "rei\u00b7chet", "so", "weit", "die", "Wel\u00b7ten", "ge\u00b7hen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dies aber ist Wahrheit:", "tokens": ["Dies", "a\u00b7ber", "ist", "Wahr\u00b7heit", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "Von oben herab wird kein Haus gebauet,", "tokens": ["Von", "o\u00b7ben", "her\u00b7ab", "wird", "kein", "Haus", "ge\u00b7bau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Von unten herauf ist es gut gebauet. \u2013", "tokens": ["Von", "un\u00b7ten", "her\u00b7auf", "ist", "es", "gut", "ge\u00b7bau\u00b7et", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Was ich sagen will, mu\u00df ich sagen,", "tokens": ["Was", "ich", "sa\u00b7gen", "will", ",", "mu\u00df", "ich", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$,", "VMFIN", "PPER", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.11": {"text": "Wer kann Feuer im Busen tragen?", "tokens": ["Wer", "kann", "Feu\u00b7er", "im", "Bu\u00b7sen", "tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "Was bis heut in gl\u00e4nzender H\u00fclle sich barg,", "tokens": ["Was", "bis", "heut", "in", "gl\u00e4n\u00b7zen\u00b7der", "H\u00fcl\u00b7le", "sich", "barg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "APPR", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.13": {"text": "Das ist im tiefsten Innern b\u00f6s und arg", "tokens": ["Das", "ist", "im", "tiefs\u00b7ten", "In\u00b7nern", "b\u00f6s", "und", "arg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPRART", "ADJA", "NN", "ADJD", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und faul bis in's Mark.", "tokens": ["Und", "faul", "bis", "in's", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "APPRART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.15": {"text": "Weh' dem, der vom glei\u00dfenden Schein geblendet,", "tokens": ["Weh'", "dem", ",", "der", "vom", "glei\u00b7\u00dfen\u00b7den", "Schein", "ge\u00b7blen\u00b7det", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "----+--+-+-", "measure": "iambic.tri.relaxed"}, "line.16": {"text": "An die Geistesvertreter des Glanzes sich wendet", "tokens": ["An", "die", "Geis\u00b7tes\u00b7ver\u00b7tre\u00b7ter", "des", "Glan\u00b7zes", "sich", "wen\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PRF", "VVFIN"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.17": {"text": "Und sein wackeres Wort an sie verschwendet,", "tokens": ["Und", "sein", "wa\u00b7cke\u00b7res", "Wort", "an", "sie", "ver\u00b7schwen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.18": {"text": "Er findet bei Taubstummen eh'r", "tokens": ["Er", "fin\u00b7det", "bei", "Taub\u00b7stum\u00b7men", "eh'r"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Als bei ihnen Geh\u00f6r,", "tokens": ["Als", "bei", "ih\u00b7nen", "Ge\u00b7h\u00f6r", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.20": {"text": "Ich will von ihnen nichts wissen mehr.", "tokens": ["Ich", "will", "von", "ih\u00b7nen", "nichts", "wis\u00b7sen", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PIS", "VVFIN", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Wer giebt auch gesunde Kost f\u00fcr kranke B\u00e4uche?", "tokens": ["Wer", "giebt", "auch", "ge\u00b7sun\u00b7de", "Kost", "f\u00fcr", "kran\u00b7ke", "B\u00e4u\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Wer gie\u00dft auch Most in alte Schl\u00e4uche?", "tokens": ["Wer", "gie\u00dft", "auch", "Most", "in", "al\u00b7te", "Schl\u00e4u\u00b7che", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Aber es kommt ein Tag der Vergeltung auf Erden,", "tokens": ["A\u00b7ber", "es", "kommt", "ein", "Tag", "der", "Ver\u00b7gel\u00b7tung", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.24": {"text": "Noch sind nicht alle zu Bett,", "tokens": ["Noch", "sind", "nicht", "al\u00b7le", "zu", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "PIS", "APPR", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.25": {"text": "Die eine b\u00f6se Nacht haben werden!", "tokens": ["Die", "ei\u00b7ne", "b\u00f6\u00b7se", "Nacht", "ha\u00b7ben", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VAFIN", "VAINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.30": {"line.1": {"text": "Ein Beifall von drunten Bahn sich brach.", "tokens": ["Ein", "Bei\u00b7fall", "von", "drun\u00b7ten", "Bahn", "sich", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "PRF", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Bonner aber dagegen sprach:", "tokens": ["Der", "Bon\u00b7ner", "a\u00b7ber", "da\u00b7ge\u00b7gen", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Wenn der Krug auf den Stein f\u00e4llt,", "tokens": ["Wenn", "der", "Krug", "auf", "den", "Stein", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Der Krug zerschellt.", "tokens": ["Der", "Krug", "zer\u00b7schellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wenn der Stein auf den Krug f\u00e4llt,", "tokens": ["Wenn", "der", "Stein", "auf", "den", "Krug", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Der Krug zerschellt.", "tokens": ["Der", "Krug", "zer\u00b7schellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Jedesmal zerschellt der Krug,", "tokens": ["Je\u00b7des\u00b7mal", "zer\u00b7schellt", "der", "Krug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Und der Stein bleibt heil, der ihn zerschlug.", "tokens": ["Und", "der", "Stein", "bleibt", "heil", ",", "der", "ihn", "zer\u00b7schlug", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Drum sieh wohl zu, wohin dein Geist sich wende;", "tokens": ["Drum", "sieh", "wohl", "zu", ",", "wo\u00b7hin", "dein", "Geist", "sich", "wen\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "PTKVZ", "$,", "PWAV", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Du wei\u00dft wohl den Kampf aber nicht sein Ende,", "tokens": ["Du", "wei\u00dft", "wohl", "den", "Kampf", "a\u00b7ber", "nicht", "sein", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Wer Gewinner sein wird, wer Verlierer,", "tokens": ["Wer", "Ge\u00b7win\u00b7ner", "sein", "wird", ",", "wer", "Ver\u00b7lie\u00b7rer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "VAINF", "VAFIN", "$,", "PWS", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "Und so bist du ein Blinder der Blinden F\u00fchrer.", "tokens": ["Und", "so", "bist", "du", "ein", "Blin\u00b7der", "der", "Blin\u00b7den", "F\u00fch\u00b7rer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.11": {"text": "Die da nur sinnen k\u00f6nnen auf Emp\u00f6rung", "tokens": ["Die", "da", "nur", "sin\u00b7nen", "k\u00f6n\u00b7nen", "auf", "Em\u00b7p\u00f6\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "VVINF", "VMFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und auf Zerst\u00f6rung", "tokens": ["Und", "auf", "Zer\u00b7st\u00f6\u00b7rung"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "Und in die Welt wollen bringen Feuer statt Licht,", "tokens": ["Und", "in", "die", "Welt", "wol\u00b7len", "brin\u00b7gen", "Feu\u00b7er", "statt", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VMFIN", "VVINF", "NN", "APPR", "NN", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Aber den Weg des Friedens wissen sie nicht,", "tokens": ["A\u00b7ber", "den", "Weg", "des", "Frie\u00b7dens", "wis\u00b7sen", "sie", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.15": {"text": "Deren Tage m\u00fcssen einsam bleiben,", "tokens": ["De\u00b7ren", "Ta\u00b7ge", "m\u00fcs\u00b7sen", "ein\u00b7sam", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.16": {"text": "Und kein Jauchzen wird darinnen sein,", "tokens": ["Und", "kein", "Jauch\u00b7zen", "wird", "da\u00b7rin\u00b7nen", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VAFIN", "ADV", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Und ihre Nacht wird finster sein", "tokens": ["Und", "ih\u00b7re", "Nacht", "wird", "fins\u00b7ter", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADJD", "VAINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Und von Sternenleer! \u2013", "tokens": ["Und", "von", "Ster\u00b7nen\u00b7leer", "!", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "NN", "$.", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.19": {"text": "Die tr\u00fcben Gedanken, wie werd' ich sie los?", "tokens": ["Die", "tr\u00fc\u00b7ben", "Ge\u00b7dan\u00b7ken", ",", "wie", "werd'", "ich", "sie", "los", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "VAFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Es will Abend werden, und die Schatten werden gro\u00df.", "tokens": ["Es", "will", "A\u00b7bend", "wer\u00b7den", ",", "und", "die", "Schat\u00b7ten", "wer\u00b7den", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "VAINF", "$,", "KON", "ART", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.21": {"text": "An den Rhein will ich gehn, zur\u00fcck an den Rhein,", "tokens": ["An", "den", "Rhein", "will", "ich", "gehn", ",", "zu\u00b7r\u00fcck", "an", "den", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "VMFIN", "PPER", "VVINF", "$,", "PTKVZ", "APPR", "ART", "NE", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.22": {"text": "Da kann man noch jubeln und fr\u00f6hlich sein,", "tokens": ["Da", "kann", "man", "noch", "ju\u00b7beln", "und", "fr\u00f6h\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "VVINF", "KON", "ADJD", "VAINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "Da singen der Poesie die Leute", "tokens": ["Da", "sin\u00b7gen", "der", "Poe\u00b7sie", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.24": {"text": "Nicht wie du ein Grabgel\u00e4ute;", "tokens": ["Nicht", "wie", "du", "ein", "Grab\u00b7ge\u00b7l\u00e4u\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PWAV", "PPER", "ART", "NN", "$."], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.25": {"text": "Ihr Wein ist gut und ihr Muth kein kleiner,", "tokens": ["Ihr", "Wein", "ist", "gut", "und", "ihr", "Muth", "kein", "klei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "KON", "PPOSAT", "NN", "PIAT", "ADJA", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Und ihr Witz bleibt immer noch st\u00e4rker als deiner!", "tokens": ["Und", "ihr", "Witz", "bleibt", "im\u00b7mer", "noch", "st\u00e4r\u00b7ker", "als", "dei\u00b7ner", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "ADJD", "KOKOM", "PPOSAT", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "So rief er;", "tokens": ["So", "rief", "er", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Und eine Bewegung war auf der Trib\u00fcne zu schauen,", "tokens": ["Und", "ei\u00b7ne", "Be\u00b7we\u00b7gung", "war", "auf", "der", "Tri\u00b7b\u00fc\u00b7ne", "zu", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.3": {"text": "Und Beifall klatschten ihm Herren und Frauen.", "tokens": ["Und", "Bei\u00b7fall", "klatschten", "ihm", "Her\u00b7ren", "und", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.33": {"line.1": {"text": "Und die Menge sah mit besorgtem Sinn", "tokens": ["Und", "die", "Men\u00b7ge", "sah", "mit", "be\u00b7sorg\u00b7tem", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Auf den rothen Berliner hin.", "tokens": ["Auf", "den", "ro\u00b7then", "Ber\u00b7li\u00b7ner", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.34": {"line.1": {"text": "Aber der, \u2013", "tokens": ["A\u00b7ber", "der", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct"], "pos": ["KON", "ART", "$,", "$("], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Hast du schon einmal gesehen,", "tokens": ["Hast", "du", "schon", "ein\u00b7mal", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ein Huhn den Kopf beugt", "tokens": ["Wie", "ein", "Huhn", "den", "Kopf", "beugt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und dich von der Seite anschielt,", "tokens": ["Und", "dich", "von", "der", "Sei\u00b7te", "an\u00b7schielt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Da\u00df du laut auflachen mu\u00dft ob der philosophischen Dummheit,", "tokens": ["Da\u00df", "du", "laut", "auf\u00b7la\u00b7chen", "mu\u00dft", "ob", "der", "phi\u00b7lo\u00b7so\u00b7phi\u00b7schen", "Dumm\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVINF", "VMFIN", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus"}, "line.6": {"text": "Die in dem Blicke sitzt, \u2013", "tokens": ["Die", "in", "dem", "Bli\u00b7cke", "sitzt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "So verschmitzt", "tokens": ["So", "ver\u00b7schmitzt"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Sah der Berliner den Bonner an,", "tokens": ["Sah", "der", "Ber\u00b7li\u00b7ner", "den", "Bon\u00b7ner", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.9": {"text": "Und er begann:", "tokens": ["Und", "er", "be\u00b7gann", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.35": {"line.1": {"text": "Um von dem Ende zu kommen auf den Ursprung,", "tokens": ["Um", "von", "dem", "En\u00b7de", "zu", "kom\u00b7men", "auf", "den", "Ur\u00b7sprung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Machst du mehr einen Kunst- als einen Natursprung.", "tokens": ["Machst", "du", "mehr", "ei\u00b7nen", "Kunst", "als", "ei\u00b7nen", "Na\u00b7tur\u00b7sprung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "TRUNC", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Einem solchen Sprunge kann ich nicht folgen,", "tokens": ["Ei\u00b7nem", "sol\u00b7chen", "Sprun\u00b7ge", "kann", "ich", "nicht", "fol\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Einem so komischen, einem so droll'gen.", "tokens": ["Ei\u00b7nem", "so", "ko\u00b7mi\u00b7schen", ",", "ei\u00b7nem", "so", "droll'\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "VVINF", "$,", "ART", "ADV", "VVFIN", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Was ich gar nicht gesagt habe, schiebst du mir zu,", "tokens": ["Was", "ich", "gar", "nicht", "ge\u00b7sagt", "ha\u00b7be", ",", "schiebst", "du", "mir", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "PTKNEG", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Was ich gar nicht gefragt habe, antwortest du,", "tokens": ["Was", "ich", "gar", "nicht", "ge\u00b7fragt", "ha\u00b7be", ",", "ant\u00b7wor\u00b7test", "du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "PTKNEG", "VVPP", "VAFIN", "$,", "VVFIN", "PPER", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Was erst nicht krank war, das heilst du sp\u00e4ter,", "tokens": ["Was", "erst", "nicht", "krank", "war", ",", "das", "heilst", "du", "sp\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,", "PDS", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Du bist mir ein komischer Wunderth\u00e4ter.", "tokens": ["Du", "bist", "mir", "ein", "ko\u00b7mi\u00b7scher", "Wun\u00b7der\u00b7th\u00e4\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Du machst die Blinden gehend", "tokens": ["Du", "machst", "die", "Blin\u00b7den", "ge\u00b7hend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Und die Lahmen sehend", "tokens": ["Und", "die", "Lah\u00b7men", "se\u00b7hend"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.11": {"text": "Und du gebrauchst das Orakel", "tokens": ["Und", "du", "ge\u00b7brauchst", "das", "O\u00b7ra\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.12": {"text": "Wie der Schulmeister den Bakel;", "tokens": ["Wie", "der", "Schul\u00b7meis\u00b7ter", "den", "Ba\u00b7kel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "$."], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.13": {"text": "Malst mir da die Zukunft aus", "tokens": ["Malst", "mir", "da", "die", "Zu\u00b7kunft", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.14": {"text": "D\u00fcster wie ein Gespensterhaus.", "tokens": ["D\u00fcs\u00b7ter", "wie", "ein", "Ge\u00b7spens\u00b7ter\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.15": {"text": "Bist wohl auch einer, dessen Gesang", "tokens": ["Bist", "wohl", "auch", "ei\u00b7ner", ",", "des\u00b7sen", "Ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "$,", "PRELAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.16": {"text": "K\u00fcndet den Weltuntergang?", "tokens": ["K\u00fcn\u00b7det", "den", "Welt\u00b7un\u00b7ter\u00b7gang", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+--++-+", "measure": "dactylic.init"}, "line.17": {"text": "Ach und Wehe \u00e4chzt er", "tokens": ["Ach", "und", "We\u00b7he", "\u00e4chzt", "er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ITJ", "KON", "NN", "VVFIN", "PPER"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.18": {"text": "Und wie eine Kr\u00e4he kr\u00e4chzt er", "tokens": ["Und", "wie", "ei\u00b7ne", "Kr\u00e4\u00b7he", "kr\u00e4chzt", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VVFIN", "PPER"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.19": {"text": "Mit Geheul und Gewinsel,", "tokens": ["Mit", "Ge\u00b7heul", "und", "Ge\u00b7win\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.20": {"text": "Ein wahrer Pinsel!", "tokens": ["Ein", "wah\u00b7rer", "Pin\u00b7sel", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "Komme mir mit einem so schwarzen Bild nicht;", "tokens": ["Kom\u00b7me", "mir", "mit", "ei\u00b7nem", "so", "schwar\u00b7zen", "Bild", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADV", "ADJA", "NN", "PTKNEG", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.22": {"text": "Du wei\u00dft doch, Bange machen gilt nicht.", "tokens": ["Du", "wei\u00dft", "doch", ",", "Ban\u00b7ge", "ma\u00b7chen", "gilt", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "NN", "VVINF", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.36": {"line.1": {"text": "Bist du aber einmal ein Unheilverk\u00fcnder,", "tokens": ["Bist", "du", "a\u00b7ber", "ein\u00b7mal", "ein", "Un\u00b7heil\u00b7ver\u00b7k\u00fcn\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Warum kehrst du dich nicht an die ", "tokens": ["Wa\u00b7rum", "kehrst", "du", "dich", "nicht", "an", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PRF", "PTKNEG", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An den Quell, aus dem aller Jammer flie\u00dft,", "tokens": ["An", "den", "Quell", ",", "aus", "dem", "al\u00b7ler", "Jam\u00b7mer", "flie\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "An den Boden, auf dem alles Unkraut sprie\u00dft?", "tokens": ["An", "den", "Bo\u00b7den", ",", "auf", "dem", "al\u00b7les", "Un\u00b7kraut", "sprie\u00dft", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Horch wohl auf, was ich dir jetzt sage;", "tokens": ["Horch", "wohl", "auf", ",", "was", "ich", "dir", "jetzt", "sa\u00b7ge", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKVZ", "$,", "PWS", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "Du triffst wahrlich nicht aller Tage", "tokens": ["Du", "triffst", "wahr\u00b7lich", "nicht", "al\u00b7ler", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "PIAT", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Einen, der's laut zu sagen wage.", "tokens": ["Ei\u00b7nen", ",", "der's", "laut", "zu", "sa\u00b7gen", "wa\u00b7ge", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Der Blutegel hat zwei T\u00f6chter,", "tokens": ["Der", "Blu\u00b7te\u00b7gel", "hat", "zwei", "T\u00f6ch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "CARD", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Die hei\u00dfen: bring' her! bring' her!", "tokens": ["Die", "hei\u00b7\u00dfen", ":", "bring'", "her", "!", "bring'", "her", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "VVINF", "$.", "VVFIN", "PTKVZ", "$.", "VVFIN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Du siehst sie saugen rings umher.", "tokens": ["Du", "siehst", "sie", "sau\u00b7gen", "rings", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ihr Schmatzen \u00fcbert\u00f6net das Weltget\u00fcmmel,", "tokens": ["Ihr", "Schmat\u00b7zen", "\u00fc\u00b7ber\u00b7t\u00f6\u00b7net", "das", "Welt\u00b7ge\u00b7t\u00fcm\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Und das Geschrei der Gesogenen steigt zum Himmel.", "tokens": ["Und", "das", "Ge\u00b7schrei", "der", "Ge\u00b7so\u00b7ge\u00b7nen", "steigt", "zum", "Him\u00b7mel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Aber da ist keiner, der darauf will Antwort geben", "tokens": ["A\u00b7ber", "da", "ist", "kei\u00b7ner", ",", "der", "da\u00b7rauf", "will", "Ant\u00b7wort", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PIS", "$,", "PRELS", "PAV", "VMFIN", "NN", "VVINF"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.14": {"text": "Und die Hand aufheben,", "tokens": ["Und", "die", "Hand", "auf\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.15": {"text": "Da\u00df er das Gez\u00fcchte niederschl\u00fcge", "tokens": ["Da\u00df", "er", "das", "Ge\u00b7z\u00fcch\u00b7te", "nie\u00b7der\u00b7schl\u00fc\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.16": {"text": "Mit ihrem Thun und ihrer Heuchell\u00fcge.", "tokens": ["Mit", "ih\u00b7rem", "Thun", "und", "ih\u00b7rer", "Heu\u00b7chel\u00b7l\u00fc\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Deine Prophezeiung voll Nacht und Graus", "tokens": ["Dei\u00b7ne", "Pro\u00b7phe\u00b7zei\u00b7ung", "voll", "Nacht", "und", "Graus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJD", "NN", "KON", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Warum dehnst du sie nicht auf diese aus?", "tokens": ["Wa\u00b7rum", "dehnst", "du", "sie", "nicht", "auf", "die\u00b7se", "aus", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "PTKNEG", "APPR", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Was l\u00e4\u00dft du \u00fcber die deinen Eifer erkalten?", "tokens": ["Was", "l\u00e4\u00dft", "du", "\u00fc\u00b7ber", "die", "dei\u00b7nen", "Ei\u00b7fer", "er\u00b7kal\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Du liefest fein, wer hat dich aufgehalten? \u2013", "tokens": ["Du", "lie\u00b7fest", "fein", ",", "wer", "hat", "dich", "auf\u00b7ge\u00b7hal\u00b7ten", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PWS", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Wann sang ich der Poesie ein Grabgel\u00e4ute?", "tokens": ["Wann", "sang", "ich", "der", "Poe\u00b7sie", "ein", "Grab\u00b7ge\u00b7l\u00e4u\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Aber sage mir, was bl\u00fchet heute?", "tokens": ["A\u00b7ber", "sa\u00b7ge", "mir", ",", "was", "bl\u00fc\u00b7het", "heu\u00b7te", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWS", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Das sind die gezierten Versedrechsler", "tokens": ["Das", "sind", "die", "ge\u00b7zier\u00b7ten", "Ver\u00b7sed\u00b7rechs\u00b7ler"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+--+--++-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und Dintenklexler,", "tokens": ["Und", "Din\u00b7ten\u00b7klex\u00b7ler", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "Das sind die widerw\u00e4rtigen", "tokens": ["Das", "sind", "die", "wi\u00b7der\u00b7w\u00e4r\u00b7ti\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Immer liederfertigen,", "tokens": ["Im\u00b7mer", "lie\u00b7der\u00b7fer\u00b7ti\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Die den Erfolg besingen mit Gesangesb\u00fcndeln,", "tokens": ["Die", "den", "Er\u00b7folg", "be\u00b7sin\u00b7gen", "mit", "Ge\u00b7san\u00b7ges\u00b7b\u00fcn\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ihr Hauptgesch\u00e4ft ist das Anh\u00fcndeln,", "tokens": ["Und", "ihr", "Haupt\u00b7ge\u00b7sch\u00e4ft", "ist", "das", "An\u00b7h\u00fcn\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Wer thut sich heut auf? wer macht sich gro\u00df?", "tokens": ["Wer", "thut", "sich", "heut", "auf", "?", "wer", "macht", "sich", "gro\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "ADV", "PTKVZ", "$.", "PWS", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Das sind die,", "tokens": ["Das", "sind", "die", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "$,"], "meter": "++-", "measure": "unknown.measure.di"}, "line.11": {"text": "Deren Devise hei\u00dft: charakterlos!", "tokens": ["De\u00b7ren", "De\u00b7vi\u00b7se", "hei\u00dft", ":", "cha\u00b7rak\u00b7ter\u00b7los", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "$.", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.12": {"text": "Die stets im Geleise der Phrase getrabt", "tokens": ["Die", "stets", "im", "Ge\u00b7lei\u00b7se", "der", "Phra\u00b7se", "ge\u00b7trabt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "ART", "NN", "VVPP"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.13": {"text": "Und noch nie einen ei'gnen Gedanken gehabt,", "tokens": ["Und", "noch", "nie", "ei\u00b7nen", "ei'\u00b7gnen", "Ge\u00b7dan\u00b7ken", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "ADJA", "NN", "VAPP", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Heut sind sie mit allen Gottesgaben begabt.", "tokens": ["Heut", "sind", "sie", "mit", "al\u00b7len", "Got\u00b7tes\u00b7ga\u00b7ben", "be\u00b7gabt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.15": {"text": "Und wie es dann alle die Nullen noch wagen,", "tokens": ["Und", "wie", "es", "dann", "al\u00b7le", "die", "Nul\u00b7len", "noch", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "PIS", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.16": {"text": "Sich gegenseitig Lobhudeleien zu sagen,", "tokens": ["Sich", "ge\u00b7gen\u00b7sei\u00b7tig", "Lob\u00b7hu\u00b7de\u00b7lei\u00b7en", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Das ist nun gleich um drein zu schlagen.", "tokens": ["Das", "ist", "nun", "gleich", "um", "drein", "zu", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "CARD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Aber die Herrn Damen lesen es mit Behagen. \u2013", "tokens": ["A\u00b7ber", "die", "Herrn", "Da\u00b7men", "le\u00b7sen", "es", "mit", "Be\u00b7ha\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "NN", "VVFIN", "PPER", "APPR", "NN", "$.", "$("], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "Willst du,", "tokens": ["Willst", "du", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,"], "meter": "--", "measure": "unknown.measure.zero"}, "line.20": {"text": "Da\u00df ich dir erst lange das Spr\u00fcchlein geige:", "tokens": ["Da\u00df", "ich", "dir", "erst", "lan\u00b7ge", "das", "Spr\u00fcch\u00b7lein", "gei\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ART", "NN", "ADJA", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.21": {"text": "Ganz Philisterland ist feige!?", "tokens": ["Ganz", "Phi\u00b7lis\u00b7ter\u00b7land", "ist", "fei\u00b7ge", "!?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.22": {"text": "Ihre Erw\u00e4hlten lassen sich traktiren mit Schl\u00e4gen", "tokens": ["Ih\u00b7re", "Er\u00b7w\u00e4hl\u00b7ten", "las\u00b7sen", "sich", "trak\u00b7ti\u00b7ren", "mit", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "VVFIN", "APPR", "NN"], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.23": {"text": "Und winseln kaum ein wenig dagegen. \u2013", "tokens": ["Und", "win\u00b7seln", "kaum", "ein", "we\u00b7nig", "da\u00b7ge\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "PIS", "PAV", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Vor der Wahrheit Licht warum fliehest du?", "tokens": ["Vor", "der", "Wahr\u00b7heit", "Licht", "wa\u00b7rum", "flie\u00b7hest", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "PWAV", "VVFIN", "PPER", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.25": {"text": "Blicke doch um dich, was siehest du?", "tokens": ["Bli\u00b7cke", "doch", "um", "dich", ",", "was", "sie\u00b7hest", "du", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPER", "$,", "PWS", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.26": {"text": "Nur Spreu und kein Korn,", "tokens": ["Nur", "Spreu", "und", "kein", "Korn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "PIAT", "NN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.27": {"text": "Keine Rose, nur Dorn.", "tokens": ["Kei\u00b7ne", "Ro\u00b7se", ",", "nur", "Dorn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ADV", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.28": {"text": "Ihre Dichter und Schreiber und Weisen", "tokens": ["Ih\u00b7re", "Dich\u00b7ter", "und", "Schrei\u00b7ber", "und", "Wei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "KON", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.29": {"text": "Sie sind eitel verdorben Erz und Eisen.", "tokens": ["Sie", "sind", "ei\u00b7tel", "ver\u00b7dor\u00b7ben", "Erz", "und", "Ei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "NN", "KON", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.30": {"text": "Eine neue Zeit kommt heran mit Sausen", "tokens": ["Ei\u00b7ne", "neu\u00b7e", "Zeit", "kommt", "he\u00b7ran", "mit", "Sau\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "APPR", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.31": {"text": "Und bewegt das Meer, da\u00df die Wellen brausen.", "tokens": ["Und", "be\u00b7wegt", "das", "Meer", ",", "da\u00df", "die", "Wel\u00b7len", "brau\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.32": {"text": "Aber sie wollen nicht h\u00f6ren des Windes Wehen", "tokens": ["A\u00b7ber", "sie", "wol\u00b7len", "nicht", "h\u00f6\u00b7ren", "des", "Win\u00b7des", "We\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "PTKNEG", "VVINF", "ART", "NN", "NN"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.33": {"text": "Und k\u00f6nnen mit sehenden Augen nicht sehen,", "tokens": ["Und", "k\u00f6n\u00b7nen", "mit", "se\u00b7hen\u00b7den", "Au\u00b7gen", "nicht", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.34": {"text": "Und rufen: Friede! Friede!", "tokens": ["Und", "ru\u00b7fen", ":", "Frie\u00b7de", "!", "Frie\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "Und ist doch nicht Friede. \u2013", "tokens": ["Und", "ist", "doch", "nicht", "Frie\u00b7de", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.38": {"line.1": {"text": "Dies ist das Panier, das ich mir erw\u00e4hle", "tokens": ["Dies", "ist", "das", "Pa\u00b7nier", ",", "das", "ich", "mir", "er\u00b7w\u00e4h\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVFIN"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Von ganzem Herzen mit ganzer Seele:", "tokens": ["Von", "gan\u00b7zem", "Her\u00b7zen", "mit", "gan\u00b7zer", "See\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.39": {"line.1": {"text": "Eine junge Welt steigt auf aus Nebel und Dampf,", "tokens": ["Ei\u00b7ne", "jun\u00b7ge", "Welt", "steigt", "auf", "aus", "Ne\u00b7bel", "und", "Dampf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.2": {"text": "Mit Jauchzen gehen wir in den Kampf.", "tokens": ["Mit", "Jauch\u00b7zen", "ge\u00b7hen", "wir", "in", "den", "Kampf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Was morsch war, ihr haltet es nimmer!", "tokens": ["Was", "morsch", "war", ",", "ihr", "hal\u00b7tet", "es", "nim\u00b7mer", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Was verfault war, st\u00fcrzt in Tr\u00fcmmer.", "tokens": ["Was", "ver\u00b7fault", "war", ",", "st\u00fcrzt", "in", "Tr\u00fcm\u00b7mer", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "$,", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ich sehe ein Ziel vor mir so gro\u00df,", "tokens": ["Und", "ich", "se\u00b7he", "ein", "Ziel", "vor", "mir", "so", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "ADV", "ADJD", "$,"], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.6": {"text": "Wer's erreicht, der gewinnt ein G\u00f6tterloos! \u2013", "tokens": ["Wer's", "er\u00b7reicht", ",", "der", "ge\u00b7winnt", "ein", "G\u00f6t\u00b7ter\u00b7loos", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVPP", "$,", "PRELS", "VVFIN", "ART", "NN", "$.", "$("], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.40": {"line.1": {"text": "Da erhob sich wie Sturmgebraus und Getos", "tokens": ["Da", "er\u00b7hob", "sich", "wie", "Sturm\u00b7ge\u00b7braus", "und", "Ge\u00b7tos"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "KOKOM", "NN", "KON", "NN"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ein Beifall ringsum riesengro\u00df.", "tokens": ["Ein", "Bei\u00b7fall", "ring\u00b7sum", "rie\u00b7sen\u00b7gro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und er fuhr fort:", "tokens": ["Und", "er", "fuhr", "fort", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.41": {"line.1": {"text": "Nun f\u00e4llt dir mit einmal der Einfall ein:", "tokens": ["Nun", "f\u00e4llt", "dir", "mit", "ein\u00b7mal", "der", "Ein\u00b7fall", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Witz vom Rhein", "tokens": ["Der", "Witz", "vom", "Rhein"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Soll st\u00e4rker als der Berliner sein", "tokens": ["Soll", "st\u00e4r\u00b7ker", "als", "der", "Ber\u00b7li\u00b7ner", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "KOKOM", "ART", "ADJA", "VAINF"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und bleibe siegreich vor ihm bestehn;", "tokens": ["Und", "blei\u00b7be", "sieg\u00b7reich", "vor", "ihm", "be\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Das wollen wir doch gleich einmal sehn.", "tokens": ["Das", "wol\u00b7len", "wir", "doch", "gleich", "ein\u00b7mal", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Und er sprengte mit ", "tokens": ["Und", "er", "spreng\u00b7te", "mit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "An den Bonner heran, und eh' der sich's versah", "tokens": ["An", "den", "Bon\u00b7ner", "he\u00b7ran", ",", "und", "eh'", "der", "sich's", "ver\u00b7sah"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,", "KON", "KOUS", "ART", "PIS", "VVFIN"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Und wissen mochte, wie ihm geschah,", "tokens": ["Und", "wis\u00b7sen", "moch\u00b7te", ",", "wie", "ihm", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.9": {"text": "Packte er zu und zog mit einem Rucks", "tokens": ["Pack\u00b7te", "er", "zu", "und", "zog", "mit", "ei\u00b7nem", "Rucks"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.10": {"text": "Ihn herunter vom Schimmel auf seinen Fuchs", "tokens": ["Ihn", "her\u00b7un\u00b7ter", "vom", "Schim\u00b7mel", "auf", "sei\u00b7nen", "Fuchs"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "APPRART", "NN", "APPR", "PPOSAT", "NN"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.11": {"text": "Und hielt den armen", "tokens": ["Und", "hielt", "den", "ar\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.12": {"text": "Vor sich fest mit beiden Armen,", "tokens": ["Vor", "sich", "fest", "mit", "bei\u00b7den", "Ar\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.13": {"text": "Und so ritt er vor dem Rath und dem Bischof vor,", "tokens": ["Und", "so", "ritt", "er", "vor", "dem", "Rath", "und", "dem", "Bi\u00b7schof", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.14": {"text": "Und Jubel erscholl im ganzen Chor.", "tokens": ["Und", "Ju\u00b7bel", "er\u00b7scholl", "im", "gan\u00b7zen", "Chor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Aber mit h\u00f6flich sp\u00f6ttischem Diener", "tokens": ["A\u00b7ber", "mit", "h\u00f6f\u00b7lich", "sp\u00f6t\u00b7ti\u00b7schem", "Die\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJD", "ADJA", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "So zu dem Bischof sprach der Berliner:", "tokens": ["So", "zu", "dem", "Bi\u00b7schof", "sprach", "der", "Ber\u00b7li\u00b7ner", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}}, "stanza.42": {"line.1": {"text": "Hochw\u00fcrdiger Herrscher von Papstes Gnaden", "tokens": ["Hoch\u00b7w\u00fcr\u00b7di\u00b7ger", "Herr\u00b7scher", "von", "Paps\u00b7tes", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und Helfer f\u00fcr jeden Seelenschaden!", "tokens": ["Und", "Hel\u00b7fer", "f\u00fcr", "je\u00b7den", "See\u00b7len\u00b7scha\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sieh, wie ich dir hier meinen Bruder bringe,", "tokens": ["Sieh", ",", "wie", "ich", "dir", "hier", "mei\u00b7nen", "Bru\u00b7der", "brin\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit dem ich zusammen mein Liedlein singe.", "tokens": ["Mit", "dem", "ich", "zu\u00b7sam\u00b7men", "mein", "Lied\u00b7lein", "sin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.5": {"text": "Ein gut Theil davon hat er gemacht", "tokens": ["Ein", "gut", "Theil", "da\u00b7von", "hat", "er", "ge\u00b7macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "PAV", "VAFIN", "PPER", "VVPP"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Und er hat mir den Sieg gar schwer gemacht.", "tokens": ["Und", "er", "hat", "mir", "den", "Sieg", "gar", "schwer", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Siehe aber, wir sind verkleidete Narren;", "tokens": ["Sie\u00b7he", "a\u00b7ber", ",", "wir", "sind", "ver\u00b7klei\u00b7de\u00b7te", "Nar\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$,", "PPER", "VAFIN", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "Da doch Viele hier vor uns harren,", "tokens": ["Da", "doch", "Vie\u00b7le", "hier", "vor", "uns", "har\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.9": {"text": "Die zur Narrengilde beeidet sind", "tokens": ["Die", "zur", "Nar\u00b7ren\u00b7gil\u00b7de", "be\u00b7ei\u00b7det", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPRART", "NN", "VVPP", "VAFIN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Aber als Kluge verkleidet sind.", "tokens": ["A\u00b7ber", "als", "Klu\u00b7ge", "ver\u00b7klei\u00b7det", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "VVPP", "VAFIN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.11": {"text": "Du wei\u00dft wohl, was ein Spr\u00fcchlein spricht:", "tokens": ["Du", "wei\u00dft", "wohl", ",", "was", "ein", "Spr\u00fcch\u00b7lein", "spricht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die Thoren m\u00f6gen die Narren nicht,", "tokens": ["Die", "Tho\u00b7ren", "m\u00f6\u00b7gen", "die", "Nar\u00b7ren", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Die klugen Herrn", "tokens": ["Die", "klu\u00b7gen", "Herrn"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.14": {"text": "Vertragen die Narren gern.", "tokens": ["Ver\u00b7tra\u00b7gen", "die", "Nar\u00b7ren", "gern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Nun haben wir geh\u00f6rt von Gro\u00df und Klein,", "tokens": ["Nun", "ha\u00b7ben", "wir", "ge\u00b7h\u00f6rt", "von", "Gro\u00df", "und", "Klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Du wollest fein", "tokens": ["Du", "wol\u00b7lest", "fein"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Ein gerechter Narrenbischof sein,", "tokens": ["Ein", "ge\u00b7rech\u00b7ter", "Nar\u00b7ren\u00b7bi\u00b7schof", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.18": {"text": "Und also bitt' ich", "tokens": ["Und", "al\u00b7so", "bitt'", "ich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER"], "meter": "-+-+-", "measure": "iambic.di"}, "line.19": {"text": "Dich fromm und sittig,", "tokens": ["Dich", "fromm", "und", "sit\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.20": {"text": "Nimm uns unter deines Schutzes Fittich,", "tokens": ["Nimm", "uns", "un\u00b7ter", "dei\u00b7nes", "Schut\u00b7zes", "Fit\u00b7tich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.21": {"text": "Begegne uns g\u00fctig auf unsern Wegen", "tokens": ["Be\u00b7geg\u00b7ne", "uns", "g\u00fc\u00b7tig", "auf", "un\u00b7sern", "We\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.22": {"text": "Und segne uns mit deinem Segen.", "tokens": ["Und", "seg\u00b7ne", "uns", "mit", "dei\u00b7nem", "Se\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Der Bischof lachte und wurde ernst hernach,", "tokens": ["Der", "Bi\u00b7schof", "lach\u00b7te", "und", "wur\u00b7de", "ernst", "her\u00b7nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VAFIN", "ADJD", "ADV", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Und mit lauter Stimme also sprach:", "tokens": ["Und", "mit", "lau\u00b7ter", "Stim\u00b7me", "al\u00b7so", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.43": {"line.1": {"text": "Siehe die Weisheit l\u00e4\u00dft sich h\u00f6ren auf den Gassen,", "tokens": ["Sie\u00b7he", "die", "Weis\u00b7heit", "l\u00e4\u00dft", "sich", "h\u00f6\u00b7ren", "auf", "den", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "VVFIN", "PRF", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Niemand achtet ihrer.", "tokens": ["Und", "Nie\u00b7mand", "ach\u00b7tet", "ih\u00b7rer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "An den Thoren bei der Stadt,", "tokens": ["An", "den", "Tho\u00b7ren", "bei", "der", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da man zur Th\u00fcr' eingehet, schreiet sie.", "tokens": ["Da", "man", "zur", "Th\u00fcr'", "ein\u00b7ge\u00b7het", ",", "schrei\u00b7et", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wo aber die Narren weise reden,", "tokens": ["Wo", "a\u00b7ber", "die", "Nar\u00b7ren", "wei\u00b7se", "re\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Da, mein' ich, mu\u00df gut hausen sein.", "tokens": ["Da", ",", "mein'", "ich", ",", "mu\u00df", "gut", "hau\u00b7sen", "sein", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Wahrheit der Narren ist ein k\u00f6stlich Ding", "tokens": ["Die", "Wahr\u00b7heit", "der", "Nar\u00b7ren", "ist", "ein", "k\u00f6st\u00b7lich", "Ding"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "ART", "ADJD", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "In einer Zeit,", "tokens": ["In", "ei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Wo alle Weisen sind zu L\u00fcgnern geworden.", "tokens": ["Wo", "al\u00b7le", "Wei\u00b7sen", "sind", "zu", "L\u00fcg\u00b7nern", "ge\u00b7wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAFIN", "APPR", "NN", "VAPP", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Es rauschet aber, als wollte es sehr regnen.", "tokens": ["Es", "rau\u00b7schet", "a\u00b7ber", ",", "als", "woll\u00b7te", "es", "sehr", "reg\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Und somit segn' ich euch beide;", "tokens": ["Und", "so\u00b7mit", "segn'", "ich", "euch", "bei\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Denn es ist besser,", "tokens": ["Denn", "es", "ist", "bes\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADJD", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": "Da\u00df die Wahrheit gesegnet werde,", "tokens": ["Da\u00df", "die", "Wahr\u00b7heit", "ge\u00b7seg\u00b7net", "wer\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.14": {"text": "Als da\u00df die Schlechtigkeit geheiligt sei.", "tokens": ["Als", "da\u00df", "die", "Schlech\u00b7tig\u00b7keit", "ge\u00b7hei\u00b7ligt", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "Drauf hat er Gnad' und Heil gew\u00e4hrt", "tokens": ["Drauf", "hat", "er", "Gnad'", "und", "Heil", "ge\u00b7w\u00e4hrt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den beiden Reitern auf einem Pferd", "tokens": ["Den", "bei\u00b7den", "Rei\u00b7tern", "auf", "ei\u00b7nem", "Pferd"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und gab den Segen, wie sich's geb\u00fchrt,", "tokens": ["Und", "gab", "den", "Se\u00b7gen", ",", "wie", "sich's", "ge\u00b7b\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und beide zeigten sich tief ger\u00fchrt.", "tokens": ["Und", "bei\u00b7de", "zeig\u00b7ten", "sich", "tief", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PRF", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dann sprengten sie fort", "tokens": ["Dann", "spreng\u00b7ten", "sie", "fort"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Und wohin sie kamen, \u00fcberall", "tokens": ["Und", "wo\u00b7hin", "sie", "ka\u00b7men", ",", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "ADV"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.7": {"text": "Empfing man sie mit Jubelschall.", "tokens": ["Emp\u00b7fing", "man", "sie", "mit", "Ju\u00b7bel\u00b7schall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Lehrer aber, der unter den Werkmannen sa\u00df,", "tokens": ["Der", "Leh\u00b7rer", "a\u00b7ber", ",", "der", "un\u00b7ter", "den", "Werk\u00b7man\u00b7nen", "sa\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Ward gelobt ob der Sch\u00fcler im Ueberma\u00df.", "tokens": ["Ward", "ge\u00b7lobt", "ob", "der", "Sch\u00fc\u00b7ler", "im", "Ue\u00b7ber\u00b7ma\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KOUS", "ART", "NN", "APPRART", "NN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.10": {"text": "Und er sah ihnen nach,", "tokens": ["Und", "er", "sah", "ih\u00b7nen", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-++--+", "measure": "iambic.tri.chol"}, "line.11": {"text": "Und schluchzend erwidert er und sprach:", "tokens": ["Und", "schluch\u00b7zend", "er\u00b7wi\u00b7dert", "er", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "KON", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.45": {"line.1": {"text": "Ja die Rangen!", "tokens": ["Ja", "die", "Ran\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Mir sind die Thr\u00e4nen aus den Augen gegangen.", "tokens": ["Mir", "sind", "die", "Thr\u00e4\u00b7nen", "aus", "den", "Au\u00b7gen", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "++-+-+-+--+-", "measure": "trochaic.hexa.relaxed"}}}}}