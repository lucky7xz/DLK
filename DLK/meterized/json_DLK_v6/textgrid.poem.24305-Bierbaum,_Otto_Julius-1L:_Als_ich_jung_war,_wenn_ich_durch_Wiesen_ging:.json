{"textgrid.poem.24305": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als ich jung war, wenn ich durch Wiesen ging:", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich jung war, wenn ich durch Wiesen ging:", "tokens": ["Als", "ich", "jung", "war", ",", "wenn", "ich", "durch", "Wie\u00b7sen", "ging", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ach, wie leicht ich damals bunte Verse fing!", "tokens": ["Ach", ",", "wie", "leicht", "ich", "da\u00b7mals", "bun\u00b7te", "Ver\u00b7se", "fing", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "ADJD", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Und zur Muse ward mir jedes h\u00fcbsche Ding.", "tokens": ["Und", "zur", "Mu\u00b7se", "ward", "mir", "je\u00b7des", "h\u00fcb\u00b7sche", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Denn ich bin rechtschaffen jung gewesen.", "tokens": ["Denn", "ich", "bin", "recht\u00b7schaf\u00b7fen", "jung", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "VAPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Drum war der Jugend, was ich schrieb,", "tokens": ["Drum", "war", "der", "Ju\u00b7gend", ",", "was", "ich", "schrieb", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ART", "NN", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus dem eignen Herzen geschrieben und lieb,", "tokens": ["Aus", "dem", "eig\u00b7nen", "Her\u00b7zen", "ge\u00b7schrie\u00b7ben", "und", "lieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "KON", "ADJD", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und das junge Volk hat mich gern gelesen.", "tokens": ["Und", "das", "jun\u00b7ge", "Volk", "hat", "mich", "gern", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Nun aber hei\u00dft es: ich soll so bleiben,", "tokens": ["Nun", "a\u00b7ber", "hei\u00dft", "es", ":", "ich", "soll", "so", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$.", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Immer mit gr\u00fcner Tinte schreiben,", "tokens": ["Im\u00b7mer", "mit", "gr\u00fc\u00b7ner", "Tin\u00b7te", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Immer Halli und immer Hallo.", "tokens": ["Im\u00b7mer", "Hal\u00b7li", "und", "im\u00b7mer", "Hal\u00b7lo", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "KON", "ADV", "NE", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Liebe Leute: Das geht nicht so.", "tokens": ["Lie\u00b7be", "Leu\u00b7te", ":", "Das", "geht", "nicht", "so", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PDS", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Man jagt mit vierzig Jahresringen", "tokens": ["Man", "jagt", "mit", "vier\u00b7zig", "Jah\u00b7res\u00b7rin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl nicht mehr gern nach Schmetterlingen,", "tokens": ["Wohl", "nicht", "mehr", "gern", "nach", "Schmet\u00b7ter\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn manches hat man in reiferen Jahren", "tokens": ["Denn", "man\u00b7ches", "hat", "man", "in", "rei\u00b7fe\u00b7ren", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VAFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sowohl von Welt als Kunst erfahren,", "tokens": ["So\u00b7wohl", "von", "Welt", "als", "Kunst", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das einen jetzt sch\u00f6ner und wichtiger deucht", "tokens": ["Das", "ei\u00b7nen", "jetzt", "sch\u00f6\u00b7ner", "und", "wich\u00b7ti\u00b7ger", "deucht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "ADV", "ADJD", "KON", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Als Buntes, das um Buntes fleucht.", "tokens": ["Als", "Bun\u00b7tes", ",", "das", "um", "Bun\u00b7tes", "fleucht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Mit ruhiger Seele das zu erfassen,", "tokens": ["Mit", "ru\u00b7hi\u00b7ger", "See\u00b7le", "das", "zu", "er\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "PTKZU", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In ruhiger Form das leuchten zu lassen,", "tokens": ["In", "ru\u00b7hi\u00b7ger", "Form", "das", "leuch\u00b7ten", "zu", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Dahin geht nun meiner Kunst Begehren,", "tokens": ["Da\u00b7hin", "geht", "nun", "mei\u00b7ner", "Kunst", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Davon wird mich niemand wegbekehren.", "tokens": ["Da\u00b7von", "wird", "mich", "nie\u00b7mand", "weg\u00b7be\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Denn immer, was und wie ich sang:", "tokens": ["Denn", "im\u00b7mer", ",", "was", "und", "wie", "ich", "sang", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWS", "KON", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich folgte immer ", "tokens": ["Ich", "folg\u00b7te", "im\u00b7mer"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "W\u00e4r sonst auch lieber Schuster geworden,", "tokens": ["W\u00e4r", "sonst", "auch", "lie\u00b7ber", "Schus\u00b7ter", "ge\u00b7wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "NN", "VAPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als Bruder im Sankt Apollo-Orden!", "tokens": ["Als", "Bru\u00b7der", "im", "Sankt", "A\u00b7pol\u00b7lo\u00b7Or\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "VVFIN", "NE", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}}}}