{"textgrid.poem.53420": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Bey d\u00fcrrer Zeit", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gott, unsre Zuflucht in der Noth", "tokens": ["Gott", ",", "uns\u00b7re", "Zu\u00b7flucht", "in", "der", "Noth"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Von dem wir t\u00e4glich Schutz und Brot", "tokens": ["Von", "dem", "wir", "t\u00e4g\u00b7lich", "Schutz", "und", "Brot"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gantz \u00fcberfl\u00fc\u00dfig heben,", "tokens": ["Gantz", "\u00fc\u00b7berf\u00b7l\u00fc\u00b7\u00dfig", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Durch den die Welt", "tokens": ["Durch", "den", "die", "Welt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Sich unterh\u00e4lt", "tokens": ["Sich", "un\u00b7ter\u00b7h\u00e4lt"], "token_info": ["word", "word"], "pos": ["PRF", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Mit Nahrung, Geist und Leben,", "tokens": ["Mit", "Nah\u00b7rung", ",", "Geist", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wir haben wieder mi\u00dfgethan,", "tokens": ["Wir", "ha\u00b7ben", "wie\u00b7der", "mi\u00df\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sieh aber uns barmherzig an", "tokens": ["Sieh", "a\u00b7ber", "uns", "barm\u00b7her\u00b7zig", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KON", "PPER", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und la\u00df Dich Vater nennen,", "tokens": ["Und", "la\u00df", "Dich", "Va\u00b7ter", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht deinen Muth", "tokens": ["Nicht", "dei\u00b7nen", "Muth"], "token_info": ["word", "word", "word"], "pos": ["PTKNEG", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Wie diese Gluth", "tokens": ["Wie", "die\u00b7se", "Gluth"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PDAT", "NN"], "meter": "---+", "measure": "unknown.measure.single"}, "line.6": {"text": "Des d\u00fcrren Wetters brennen.", "tokens": ["Des", "d\u00fcr\u00b7ren", "Wet\u00b7ters", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Dein Licht die Sonne scheint so hei\u00df,", "tokens": ["Dein", "Licht", "die", "Son\u00b7ne", "scheint", "so", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df niemand sich zu bergen weis,", "tokens": ["Da\u00df", "nie\u00b7mand", "sich", "zu", "ber\u00b7gen", "weis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "PTKZU", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wald, St\u00e4dte, G\u00e4rten, Saaten,", "tokens": ["Wald", ",", "St\u00e4d\u00b7te", ",", "G\u00e4r\u00b7ten", ",", "Saa\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geb\u00fcrg und Thal", "tokens": ["Ge\u00b7b\u00fcrg", "und", "Thal"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Mu\u00df nicht ohn Qual", "tokens": ["Mu\u00df", "nicht", "ohn", "Qual"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "APPR", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "An ihrem Feuer braten.", "tokens": ["An", "ih\u00b7rem", "Feu\u00b7er", "bra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Wie kl\u00e4glich steht doch Gra\u00df und Laub", "tokens": ["Wie", "kl\u00e4g\u00b7lich", "steht", "doch", "Gra\u00df", "und", "Laub"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es kriegt f\u00fcr Regen dicken Staub,", "tokens": ["Es", "kriegt", "f\u00fcr", "Re\u00b7gen", "di\u00b7cken", "Staub", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wiesen sind versenget", "tokens": ["Die", "Wie\u00b7sen", "sind", "ver\u00b7sen\u00b7get"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil ihre Zier", "tokens": ["Weil", "ih\u00b7re", "Zier"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "So lang von Dir", "tokens": ["So", "lang", "von", "Dir"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Nicht worden ist besprenget.", "tokens": ["Nicht", "wor\u00b7den", "ist", "be\u00b7spren\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAPP", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Die wilden und die zahmen Thier", "tokens": ["Die", "wil\u00b7den", "und", "die", "zah\u00b7men", "Thier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sonderlich dein Erbtheil, wir", "tokens": ["Und", "son\u00b7der\u00b7lich", "dein", "E\u00b7rbtheil", ",", "wir"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sind j\u00e4mmerlich verkommen.", "tokens": ["Sind", "j\u00e4m\u00b7mer\u00b7lich", "ver\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es wird uns Kraft", "tokens": ["Es", "wird", "uns", "Kraft"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und aller Saft", "tokens": ["Und", "al\u00b7ler", "Saft"], "token_info": ["word", "word", "word"], "pos": ["KON", "PIAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Durch Durst und Schwei\u00df genommen.", "tokens": ["Durch", "Durst", "und", "Schwei\u00df", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "F\u00fcr gro\u00dfer D\u00fcrr und Schmachtigkeit", "tokens": ["F\u00fcr", "gro\u00b7\u00dfer", "D\u00fcrr", "und", "Schmach\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist in dem Trank kein Unterscheid,", "tokens": ["Ist", "in", "dem", "Trank", "kein", "Un\u00b7ter\u00b7scheid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es mu\u00df den Durst uns wehren", "tokens": ["Es", "mu\u00df", "den", "Durst", "uns", "weh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was irgend kann", "tokens": ["Was", "ir\u00b7gend", "kann"], "token_info": ["word", "word", "word"], "pos": ["PWS", "ADV", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und w\u00fc\u00dfte man", "tokens": ["Und", "w\u00fc\u00df\u00b7te", "man"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PIS"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Die Str\u00f6m auch auszuleeren.", "tokens": ["Die", "Str\u00f6m", "auch", "aus\u00b7zu\u00b7lee\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Wie wird der gro\u00dfen Hitze Pein", "tokens": ["Wie", "wird", "der", "gro\u00b7\u00dfen", "Hit\u00b7ze", "Pein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So mancher Krankheit Ursach seyn?", "tokens": ["So", "man\u00b7cher", "Krank\u00b7heit", "Ur\u00b7sach", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was Theurung wird man klagen", "tokens": ["Was", "Theu\u00b7rung", "wird", "man", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "VAFIN", "PIS", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wird Dein Gericht", "tokens": ["Wird", "Dein", "Ge\u00b7richt"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "O Vater! nicht", "tokens": ["O", "Va\u00b7ter", "!", "nicht"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "NN", "$.", "PTKNEG"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Erbarmen mit uns tragen.", "tokens": ["Er\u00b7bar\u00b7men", "mit", "uns", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Schleu\u00df den verschlo\u00dfnen Himmel auf", "tokens": ["Schleu\u00df", "den", "ver\u00b7schlo\u00df\u00b7nen", "Him\u00b7mel", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "APPR"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Treib Wolcken \u00fcber uns zu Hauff", "tokens": ["Treib", "Wol\u00b7cken", "\u00fc\u00b7ber", "uns", "zu", "Hauff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "APPR", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die sanften Regen bringen", "tokens": ["Die", "sanf\u00b7ten", "Re\u00b7gen", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dannenher", "tokens": ["Und", "dan\u00b7nen\u00b7her"], "token_info": ["word", "word"], "pos": ["KON", "PAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Auch die Beschwehr", "tokens": ["Auch", "die", "Be\u00b7schwehr"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Der gro\u00dfen Hitze zwingen.", "tokens": ["Der", "gro\u00b7\u00dfen", "Hit\u00b7ze", "zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Schau aller Heiden G\u00f6tzen an,", "tokens": ["Schau", "al\u00b7ler", "Hei\u00b7den", "G\u00f6t\u00b7zen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer ist der Regen geben kann?", "tokens": ["Wer", "ist", "der", "Re\u00b7gen", "ge\u00b7ben", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Heer der Fluth und Flammen", "tokens": ["Das", "Heer", "der", "Fluth", "und", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "H\u00f6rt dein Gehei\u00df", "tokens": ["H\u00f6rt", "dein", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word"], "pos": ["VVIMP", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Und tritt mit Flei\u00df", "tokens": ["Und", "tritt", "mit", "Flei\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "In deinen Dienst zusammen.", "tokens": ["In", "dei\u00b7nen", "Dienst", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Du hast uns vormals zugesagt", "tokens": ["Du", "hast", "uns", "vor\u00b7mals", "zu\u00b7ge\u00b7sagt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn d\u00fcrre Zeit und Brand uns plagt,", "tokens": ["Wenn", "d\u00fcr\u00b7re", "Zeit", "und", "Brand", "uns", "plagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir aber vor dir flehen", "tokens": ["Wir", "a\u00b7ber", "vor", "dir", "fle\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Bu\u00dfe thun,", "tokens": ["Und", "Bu\u00b7\u00dfe", "thun", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Wie eben nun", "tokens": ["Wie", "e\u00b7ben", "nun"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ADV", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Uns gn\u00e4dig anzusehen.", "tokens": ["Uns", "gn\u00e4\u00b7dig", "an\u00b7zu\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "So komm nun deiner Zusag nach,", "tokens": ["So", "komm", "nun", "dei\u00b7ner", "Zu\u00b7sag", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verfolgst Du aber noch mit Rach", "tokens": ["Ver\u00b7folgst", "Du", "a\u00b7ber", "noch", "mit", "Rach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "An uns die b\u00f6sen Thaten,", "tokens": ["An", "uns", "die", "b\u00f6\u00b7sen", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So sitzt Dein Sohn", "tokens": ["So", "sitzt", "Dein", "Sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Auf Deinem Tron", "tokens": ["Auf", "Dei\u00b7nem", "Tron"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Der unsrer Noth gerathen.", "tokens": ["Der", "uns\u00b7rer", "Noth", "ge\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Erh\u00f6r doch ihn nur, dessen Bitt", "tokens": ["Er\u00b7h\u00f6r", "doch", "ihn", "nur", ",", "des\u00b7sen", "Bitt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADV", "PPER", "ADV", "$,", "PRELAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Uns Herz- und Br\u00fcderlich vertritt,", "tokens": ["Uns", "Her\u00b7z", "und", "Br\u00fc\u00b7der\u00b7lich", "ver\u00b7tritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "TRUNC", "KON", "NE", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So sollen unsre Weisen,", "tokens": ["So", "sol\u00b7len", "uns\u00b7re", "Wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dich wahrer Gott", "tokens": ["Dich", "wah\u00b7rer", "Gott"], "token_info": ["word", "word", "word"], "pos": ["PPER", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Herr Zebaoth", "tokens": ["Herr", "Ze\u00b7bao\u00b7th"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "-+--", "measure": "dactylic.init"}, "line.6": {"text": "Aus gantzen Hertzen preisen.", "tokens": ["Aus", "gant\u00b7zen", "Hert\u00b7zen", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}