{"textgrid.poem.48803": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "28. An Miranden", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer mu\u00df, ", "tokens": ["Wer", "mu\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "An Sch\u00f6nheit bist du mehr als menschlich anzuschauen,", "tokens": ["An", "Sch\u00f6n\u00b7heit", "bist", "du", "mehr", "als", "menschlich", "an\u00b7zu\u00b7schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "VVIZU", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "so tugendhaft, so keusch, da\u00df dich auch selbst die Frauen", "tokens": ["so", "tu\u00b7gend\u00b7haft", ",", "so", "keusch", ",", "da\u00df", "dich", "auch", "selbst", "die", "Frau\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "KOUS", "PPER", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "mit Lust gewinnen lieb und seufzen f\u00fcr Begier", "tokens": ["mit", "Lust", "ge\u00b7win\u00b7nen", "lieb", "und", "seuf\u00b7zen", "f\u00fcr", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVINF", "ADJD", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "mit dir bekant zu sein. Ich lobe deine Zier,", "tokens": ["mit", "dir", "be\u00b7kant", "zu", "sein", ".", "Ich", "lo\u00b7be", "dei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADJD", "PTKZU", "VAINF", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die nichts Gemeines hat. Will dir denn Niemand trauen,", "tokens": ["die", "nichts", "Ge\u00b7mei\u00b7nes", "hat", ".", "Will", "dir", "denn", "Nie\u00b7mand", "trau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "$.", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "will kein Geselle denn auf deine Treue bauen?", "tokens": ["will", "kein", "Ge\u00b7sel\u00b7le", "denn", "auf", "dei\u00b7ne", "Treu\u00b7e", "bau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "KON", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Das wundert mir noch mehr, das k\u00f6mmt mir seltsam f\u00fcr.", "tokens": ["Das", "wun\u00b7dert", "mir", "noch", "mehr", ",", "das", "k\u00f6mmt", "mir", "selt\u00b7sam", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "$,", "PDS", "VVFIN", "PPER", "ADJD", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Mich d\u00fcnkt, ich gl\u00e4ub' es nicht, da\u00df du nicht Freiers gnung", "tokens": ["Mich", "d\u00fcnkt", ",", "ich", "gl\u00e4ub'", "es", "nicht", ",", "da\u00df", "du", "nicht", "Frei\u00b7ers", "gnung"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "PTKNEG", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "gehabt hast und hast noch. Sie stehen auf den Sprung", "tokens": ["ge\u00b7habt", "hast", "und", "hast", "noch", ".", "Sie", "ste\u00b7hen", "auf", "den", "Sprung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAPP", "VAFIN", "KON", "VAFIN", "ADV", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und treten immer ab, weil immer Ander kommen.", "tokens": ["und", "tre\u00b7ten", "im\u00b7mer", "ab", ",", "weil", "im\u00b7mer", "An\u00b7der", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer aber hat denn Schuld, sie oder Jungfrau du?", "tokens": ["Wer", "a\u00b7ber", "hat", "denn", "Schuld", ",", "sie", "o\u00b7der", "Jung\u00b7frau", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "NN", "$,", "PPER", "KON", "NN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Immittelst nimt dein Glanz nur ab, dein Alter zu.", "tokens": ["Im\u00b7mit\u00b7telst", "nimt", "dein", "Glanz", "nur", "ab", ",", "dein", "Al\u00b7ter", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ADV", "PTKVZ", "$,", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du wirst zu viel geliebt, zu wenig doch genommen.", "tokens": ["Du", "wirst", "zu", "viel", "ge\u00b7liebt", ",", "zu", "we\u00b7nig", "doch", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "PIS", "VVPP", "$,", "PTKA", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}