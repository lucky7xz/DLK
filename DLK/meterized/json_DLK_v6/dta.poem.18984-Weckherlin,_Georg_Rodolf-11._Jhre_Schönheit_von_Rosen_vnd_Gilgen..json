{"dta.poem.18984": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "11.  \n  Jhre Sch\u00f6nheit von Rosen vnd  \n Gilgen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Jn lieblichem geruch auff frischem gr\u00fcnem thron/", "tokens": ["In", "lieb\u00b7li\u00b7chem", "ge\u00b7ruch", "auff", "fri\u00b7schem", "gr\u00fc\u00b7nem", "thron", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den tau sent Liebelein (auffwartend) allzeit zieren/", "tokens": ["Den", "tau", "sent", "Lie\u00b7be\u00b7lein", "(", "auff\u00b7war\u00b7tend", ")", "all\u00b7zeit", "zie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "CARD", "CARD", "NN", "$(", "VVPP", "$(", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erhube sich die Ro\u00df/ mit l", "tokens": ["Er\u00b7hu\u00b7be", "sich", "die", "Ro\u00df", "/", "mit", "l"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "$(", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als blumen-Kayserin fr\u00f6lich zu triumfieren.", "tokens": ["Als", "blu\u00b7men\u00b7Kay\u00b7se\u00b7rin", "fr\u00f6\u00b7lich", "zu", "tri\u00b7um\u00b7fie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "In reicher Mayestet/ gleichlo\u00df in jhrem wohn/", "tokens": ["In", "rei\u00b7cher", "Ma\u00b7ye\u00b7stet", "/", "gleic\u00b7hlo\u00df", "in", "jhrem", "wohn", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVFIN", "$(", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Mit vnbefl\u00f6ckte\u0304 pracht lie\u00df sich die Gilg auff\u00fchr\u1ebd/", "tokens": ["Mit", "vn\u00b7be\u00b7fl\u00f6ck\u00b7t\u0113", "pracht", "lie\u00df", "sich", "die", "Gilg", "auf\u00b7f\u00fchr\u1ebd", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PRF", "ART", "NE", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vermeinend/ demnach jhr allein geb\u00fchr die Cron/", "tokens": ["Ver\u00b7mei\u00b7nend", "/", "dem\u00b7nach", "jhr", "al\u00b7lein", "ge\u00b7b\u00fchr", "die", "Cron", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$(", "PAV", "PPER", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als K\u00f6nigin das land der blumen zu regieren.", "tokens": ["Als", "K\u00f6\u00b7ni\u00b7gin", "das", "land", "der", "blu\u00b7men", "zu", "re\u00b7gie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Al\u00dfbald bew\u00f6gte sich beeder Princessin scho\u00df", "tokens": ["Al\u00df\u00b7bald", "be\u00b7w\u00f6g\u00b7te", "sich", "bee\u00b7der", "Prin\u00b7ces\u00b7sin", "scho\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "ADJA", "NN", "VVFIN"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch eyfer vnd hochmuht/ der offt die Sch\u00f6n-", "tokens": ["Durch", "ey\u00b7fer", "vnd", "hoch\u00b7muht", "/", "der", "offt", "die", "Sch\u00f6n"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "VVFIN", "$(", "ART", "ADV", "ART", "TRUNC"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "heit qu\u00e4let/", "tokens": ["heit", "qu\u00e4\u00b7let", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Sie fangen an den streit/ vnd sparen kein gescho\u00df:", "tokens": ["Sie", "fan\u00b7gen", "an", "den", "streit", "/", "vnd", "spa\u00b7ren", "kein", "ge\u00b7scho\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$(", "KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Jedoch jhr hassz in lieb (weil Amors raht nicht", "tokens": ["Je\u00b7doch", "jhr", "hassz", "in", "lieb", "(", "weil", "A\u00b7mors", "raht", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "ADJD", "$(", "KOUS", "NE", "VVFIN", "PTKNEG"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "fehlet)", "tokens": ["feh\u00b7let", ")"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Verkehret/ hat zu letzt zugleich die Gilg vnd Ro\u00df", "tokens": ["Ver\u00b7keh\u00b7ret", "/", "hat", "zu", "letzt", "zu\u00b7gleich", "die", "Gilg", "vnd", "Ro\u00df"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "VAFIN", "APPR", "ADV", "ADV", "ART", "NE", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auff ewerm angesicht zu prachtieren/ verm\u00e4hlet.", "tokens": ["Auff", "e\u00b7werm", "an\u00b7ge\u00b7sicht", "zu", "prach\u00b7tie\u00b7ren", "/", "ver\u00b7m\u00e4h\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$(", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}}}}