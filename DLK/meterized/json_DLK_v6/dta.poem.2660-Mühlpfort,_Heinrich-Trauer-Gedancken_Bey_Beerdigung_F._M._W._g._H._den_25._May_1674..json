{"dta.poem.2660": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Trauer-Gedancken  \n  Bey Beerdigung F. M. W. g. H. den 25.  \n May 1674.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ich solte/ Werthster Freund/ mit tieffgesinnten Rei-\nmen/", "tokens": ["Ich", "sol\u00b7te", "/", "Werths\u00b7ter", "Freund", "/", "mit", "tieff\u00b7ge\u00b7sinn\u00b7ten", "Rei", "men", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$(", "ADJA", "NN", "$(", "APPR", "ADJA", "TRUNC", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und Reden-voller Zier bes\u00e4nfftigen sein Leid:", "tokens": ["Und", "Re\u00b7den\u00b7vol\u00b7ler", "Zier", "be\u00b7s\u00e4nff\u00b7ti\u00b7gen", "sein", "Leid", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was nur erquickend ist von Pindus Lorberb\u00e4umen/", "tokens": ["Was", "nur", "er\u00b7qui\u00b7ckend", "ist", "von", "Pin\u00b7dus", "Lor\u00b7ber\u00b7b\u00e4u\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "VAFIN", "APPR", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von Fl\u00fcssen Castalis/ das solt\u2019 ihm seyn geweyht;", "tokens": ["Von", "Fl\u00fcs\u00b7sen", "Cas\u00b7ta\u00b7lis", "/", "das", "solt'", "ihm", "seyn", "ge\u00b7weyht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$(", "PDS", "VMFIN", "PPER", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Denn es schreckt unser Ohr/ wenn man von Gr\u00e4bern saget/", "tokens": ["Denn", "es", "schreckt", "un\u00b7ser", "Ohr", "/", "wenn", "man", "von", "Gr\u00e4\u00b7bern", "sa\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "$(", "KOUS", "PIS", "APPR", "NN", "VVFIN", "$("], "meter": "-++--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Und da\u00df der arme Mensch so bald verfaulen mu\u00df/", "tokens": ["Und", "da\u00df", "der", "ar\u00b7me", "Mensch", "so", "bald", "ver\u00b7fau\u00b7len", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "ADV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wer bey Traurenden nicht auch mitleidend klaget/", "tokens": ["Und", "wer", "bey", "Trau\u00b7ren\u00b7den", "nicht", "auch", "mit\u00b7lei\u00b7dend", "kla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "PTKNEG", "ADV", "VVPP", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vergr\u00f6ssert nur das Leid/ erweckt nichts als Verdru\u00df.", "tokens": ["Ver\u00b7gr\u00f6s\u00b7sert", "nur", "das", "Leid", "/", "er\u00b7weckt", "nichts", "als", "Ver\u00b7dru\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$(", "VVFIN", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Allein/ ich wil allhier der Aertzte Kunst-Grief brauchen", "tokens": ["Al\u00b7lein", "/", "ich", "wil", "all\u00b7hier", "der", "A\u00b7ertz\u00b7te", "Kunst\u00b7Grief", "brau\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "PPER", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Die aus dem \u00e4rgsten Gifft/ die heilsamst Artzney ziehn.", "tokens": ["Die", "aus", "dem", "\u00e4rgs\u00b7ten", "Gifft", "/", "die", "heil\u00b7samst", "Artz\u00b7ney", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wir werden wenn der Dampff des Blutes wird verrauchen/", "tokens": ["Wir", "wer\u00b7den", "wenn", "der", "Dampff", "des", "Blu\u00b7tes", "wird", "ver\u00b7rau\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOUS", "ART", "NN", "ART", "NN", "VAFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Auch mitten aus dem Grad sehn unser Leben bl\u00fchn.", "tokens": ["Auch", "mit\u00b7ten", "aus", "dem", "Grad", "sehn", "un\u00b7ser", "Le\u00b7ben", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Es h\u00e4ngt an einem Punct der Anfang und das Ende/", "tokens": ["Es", "h\u00e4ngt", "an", "ei\u00b7nem", "Punct", "der", "An\u00b7fang", "und", "das", "En\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "In einem Zirckel seyn ", "tokens": ["In", "ei\u00b7nem", "Zir\u00b7ckel", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.15": {"text": "Vergebens/ da\u00df der Mensch Flei\u00df/ W\u00fcnsche/ Klag\u2019 einwende:", "tokens": ["Ver\u00b7ge\u00b7bens", "/", "da\u00df", "der", "Mensch", "Flei\u00df", "/", "W\u00fcn\u00b7sche", "/", "Klag'", "ein\u00b7wen\u00b7de", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "ART", "NN", "NN", "$(", "NN", "$(", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Dem ewigen Gesetz kan niemand wiederstehn.", "tokens": ["Dem", "e\u00b7wi\u00b7gen", "Ge\u00b7setz", "kan", "nie\u00b7mand", "wie\u00b7ders\u00b7tehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es mahlt uns die Natur an jeden Blum\u2019 und Zweigen/", "tokens": ["Es", "mahlt", "uns", "die", "Na\u00b7tur", "an", "je\u00b7den", "Blum'", "und", "Zwei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den Auff- und ", "tokens": ["Den", "Auf\u00b7f", "und"], "token_info": ["word", "word", "word"], "pos": ["ART", "TRUNC", "KON"], "meter": "-+--", "measure": "dactylic.init"}, "line.19": {"text": "Man sieht der Sonnen-Rad bald auff-bald abwerts steigen/", "tokens": ["Man", "sieht", "der", "Son\u00b7nen\u00b7Rad", "bald", "auf\u00b7fbald", "ab\u00b7werts", "stei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "NE", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wie offt deckt Finstern\u00fc\u00df des Mondes Silber-Zier?", "tokens": ["Wie", "offt", "deckt", "Fins\u00b7ter\u00b7n\u00fc\u00df", "des", "Mon\u00b7des", "Sil\u00b7ber\u00b7Zier", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Wie \u00e4ndern nicht den Lauff die feurigen Cometen?", "tokens": ["Wie", "\u00e4n\u00b7dern", "nicht", "den", "Lauff", "die", "feu\u00b7ri\u00b7gen", "Co\u00b7me\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PTKNEG", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Wie schnell zerfleust die Lufft in Regen/ Wolck\u2019 und Wind?", "tokens": ["Wie", "schnell", "zer\u00b7fleust", "die", "Lufft", "in", "Re\u00b7gen", "/", "Wolck'", "und", "Wind", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "APPR", "NN", "$(", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Es wird eiu Purpur-Glantz die Demmerung err\u00f6then/", "tokens": ["Es", "wird", "ei\u00b7u", "Pur\u00b7pur\u00b7Glantz", "die", "Dem\u00b7me\u00b7rung", "er\u00b7r\u00f6\u00b7then", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "NE", "ART", "NN", "VVINF", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Wenn auff den Mittag gleich die schwartzen Wetter sind.", "tokens": ["Wenn", "auff", "den", "Mit\u00b7tag", "gleich", "die", "schwart\u00b7zen", "Wet\u00b7ter", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Der lebende Crystall der Brunnen mu\u00df offt sterben/", "tokens": ["Der", "le\u00b7ben\u00b7de", "Crys\u00b7tall", "der", "Brun\u00b7nen", "mu\u00df", "offt", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VMFIN", "ADV", "VVINF", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Wenn dort ein rauschend Strom die Ufer \u00fcberschwemmt:", "tokens": ["Wenn", "dort", "ein", "rau\u00b7schend", "Strom", "die", "U\u00b7fer", "\u00fc\u00b7bersc\u00b7hwemmt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJD", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Den grossen Ocean wird Eol so erherben/", "tokens": ["Den", "gros\u00b7sen", "O\u00b7cean", "wird", "E\u00b7ol", "so", "er\u00b7her\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Da\u00df den erbosten Schaum noch Kunst noch Macht mehr", "tokens": ["Da\u00df", "den", "er\u00b7bos\u00b7ten", "Schaum", "noch", "Kunst", "noch", "Macht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "NN", "ADV", "NN", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Wie ungeheur die Fluth/ so wird sie endlich schwinden/", "tokens": ["Wie", "un\u00b7ge\u00b7heur", "die", "Fluth", "/", "so", "wird", "sie", "end\u00b7lich", "schwin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "$(", "ADV", "VAFIN", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "So da\u00df man schliessen mu\u00df/ da\u00df nichts best\u00e4ndig sey.", "tokens": ["So", "da\u00df", "man", "schlies\u00b7sen", "mu\u00df", "/", "da\u00df", "nichts", "be\u00b7st\u00e4n\u00b7dig", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VVINF", "VMFIN", "$(", "KOUS", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Sehn wir die Erden an! sie lehrt mit tausend Gr\u00fcnden/", "tokens": ["Sehn", "wir", "die", "Er\u00b7den", "an", "!", "sie", "lehrt", "mit", "tau\u00b7send", "Gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Da\u00df sie nicht feste steh\u2019/ und vor Zerr\u00fcttung frey.", "tokens": ["Da\u00df", "sie", "nicht", "fes\u00b7te", "steh'", "/", "und", "vor", "Zer\u00b7r\u00fct\u00b7tung", "frey", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJA", "VVFIN", "$(", "KON", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Bald bebt vor zittern ihr das innerste Geweide/", "tokens": ["Bald", "bebt", "vor", "zit\u00b7tern", "ihr", "das", "in\u00b7ners\u00b7te", "Ge\u00b7wei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Bald schluckt das wilde Meer die sch\u00f6nsten Inseln ein/", "tokens": ["Bald", "schluckt", "das", "wil\u00b7de", "Meer", "die", "sch\u00f6ns\u00b7ten", "In\u00b7seln", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dort finckt ein hoher Berg/ hier w\u00e4chst in Wellen Seide/", "tokens": ["Dort", "finckt", "ein", "ho\u00b7her", "Berg", "/", "hier", "w\u00e4chst", "in", "Wel\u00b7len", "Sei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$(", "ADV", "VVFIN", "APPR", "NN", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es werden D\u00f6rffer auff Neptunus R\u00fccken seyn.", "tokens": ["Es", "wer\u00b7den", "D\u00f6rf\u00b7fer", "auff", "Nep\u00b7tu\u00b7nus", "R\u00fc\u00b7cken", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NE", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So diese C\u00f6rper nun abnehmeu und vergehen/", "tokens": ["So", "die\u00b7se", "C\u00f6r\u00b7per", "nun", "ab\u00b7neh\u00b7meu", "und", "ver\u00b7ge\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "ADV", "ADJD", "KON", "VVINF", "$("], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die man vor ewig doch in unsern Augen schaut:", "tokens": ["Die", "man", "vor", "e\u00b7wig", "doch", "in", "un\u00b7sern", "Au\u00b7gen", "schaut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ADJD", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie k\u00f6nnen K\u00f6nigreich und L\u00e4nder doch bestehen/", "tokens": ["Wie", "k\u00f6n\u00b7nen", "K\u00f6\u00b7nig\u00b7reich", "und", "L\u00e4n\u00b7der", "doch", "be\u00b7ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "KON", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die so gebrechlich seyn/ als der/ so sie erbaut:", "tokens": ["Die", "so", "ge\u00b7brech\u00b7lich", "seyn", "/", "als", "der", "/", "so", "sie", "er\u00b7baut", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAINF", "$(", "KOUS", "ART", "$(", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer kennet jetzt Corinth und Thebens stoltze Mauren?", "tokens": ["Wer", "ken\u00b7net", "jetzt", "Co\u00b7rinth", "und", "The\u00b7bens", "stolt\u00b7ze", "Mau\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "NE", "KON", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo ist Numantia? der K\u00fcnste Sitz Athen?", "tokens": ["Wo", "ist", "Nu\u00b7man\u00b7tia", "?", "der", "K\u00fcns\u00b7te", "Sitz", "A\u00b7then", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "$.", "ART", "ADJA", "NN", "NE", "$."], "meter": "--+-+-+-+--", "measure": "anapaest.init"}, "line.3": {"text": "Wo Rom/ die Herrscherin/ die immer wolte tauren?", "tokens": ["Wo", "Rom", "/", "die", "Herr\u00b7sche\u00b7rin", "/", "die", "im\u00b7mer", "wol\u00b7te", "tau\u00b7ren", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$(", "ART", "NN", "$(", "ART", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch wie viel Tode must ihr Glantz nicht untergehn?", "tokens": ["Durch", "wie", "viel", "To\u00b7de", "must", "ihr", "Glantz", "nicht", "un\u00b7ter\u00b7gehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOKOM", "PIAT", "NN", "VMFIN", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Was wil der spr\u00f6de Thon der Mensch f\u00fcr Rechnung machen?", "tokens": ["Was", "wil", "der", "spr\u00f6\u00b7de", "Thon", "der", "Mensch", "f\u00fcr", "Rech\u00b7nung", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "ADJA", "NN", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die besten Redner sind in Griechenland verstummt:", "tokens": ["Die", "bes\u00b7ten", "Red\u00b7ner", "sind", "in", "Grie\u00b7chen\u00b7land", "ver\u00b7stummt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die kl\u00fcgsten K\u00f6pffe f\u00fchrt des Charons stiller Nachen/", "tokens": ["Die", "kl\u00fcgs\u00b7ten", "K\u00f6pf\u00b7fe", "f\u00fchrt", "des", "Cha\u00b7rons", "stil\u00b7ler", "Na\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sch\u00f6nheiten hat die Hand der Atropos vermummt.", "tokens": ["Sch\u00f6n\u00b7hei\u00b7ten", "hat", "die", "Hand", "der", "A\u00b7tro\u00b7pos", "ver\u00b7mummt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Beherrschern/ so der Welt ihr meistes Theil besessen/", "tokens": ["Be\u00b7herr\u00b7schern", "/", "so", "der", "Welt", "ihr", "meis\u00b7tes", "Theil", "be\u00b7ses\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADV", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat eine Hand-voll Sand zu ihrem Grab gefehlt/", "tokens": ["Hat", "ei\u00b7ne", "Han\u00b7dvoll", "Sand", "zu", "ih\u00b7rem", "Grab", "ge\u00b7fehlt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und die/ so hochber\u00fchmt/ die liegen ietzt vergessen/", "tokens": ["Und", "die", "/", "so", "hoch\u00b7be\u00b7r\u00fchmt", "/", "die", "lie\u00b7gen", "ietzt", "ver\u00b7ges\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$(", "ADV", "ADJD", "$(", "ART", "VVFIN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df auch die Nach-Welt nicht mehr ihre Namen zehlt.", "tokens": ["Da\u00df", "auch", "die", "Nach\u00b7Welt", "nicht", "mehr", "ih\u00b7re", "Na\u00b7men", "zehlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKNEG", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Di\u00df predigt uns den Tod mit mehr als hundert Zungen/", "tokens": ["Di\u00df", "pre\u00b7digt", "uns", "den", "Tod", "mit", "mehr", "als", "hun\u00b7dert", "Zun\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "KOKOM", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja unser eigen Leib legt st\u00fcndlich Zeugn\u00fc\u00df ab/", "tokens": ["Ja", "un\u00b7ser", "ei\u00b7gen", "Leib", "legt", "st\u00fcnd\u00b7lich", "Zeug\u00b7n\u00fc\u00df", "ab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPOSAT", "ADJA", "NN", "VVFIN", "ADJD", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie allenthalben uns die freye Lufft umbrungen;", "tokens": ["Wie", "al\u00b7len\u00b7thal\u00b7ben", "uns", "die", "frey\u00b7e", "Lufft", "um\u00b7brun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So h\u00e4lt von Anbegin uns auch umbringt das Grab.", "tokens": ["So", "h\u00e4lt", "von", "An\u00b7be\u00b7gin", "uns", "auch", "um\u00b7bringt", "das", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "NN", "PPER", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Und mehr/ ", "tokens": ["Und", "mehr", "/"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$("], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "So stellt sein Kirchen-Ampt ihm klar Bewei\u00dfthum f\u00fcr.", "tokens": ["So", "stellt", "sein", "Kir\u00b7chen\u00b7Ampt", "ihm", "klar", "Be\u00b7wei\u00df\u00b7thum", "f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER", "ADJD", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir setzen unsern Fu\u00df auch in der Kirch auff Leichen:", "tokens": ["Wir", "set\u00b7zen", "un\u00b7sern", "Fu\u00df", "auch", "in", "der", "Kirch", "auff", "Lei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Glocken ihr Gel\u00e4ut rufft: Morgen gilt es dir.", "tokens": ["Der", "Glo\u00b7cken", "ihr", "Ge\u00b7l\u00e4ut", "rufft", ":", "Mor\u00b7gen", "gilt", "es", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$.", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Jtzt wird des Priesters Mund f\u00fcr Schwach\u2019 und Krancke beten/", "tokens": ["Jtzt", "wird", "des", "Pries\u00b7ters", "Mund", "f\u00fcr", "Schwach'", "und", "Kran\u00b7cke", "be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Drauff kommt ein naher Freund/ und bitts Begr\u00e4bn\u00fc\u00df aus:", "tokens": ["Drauff", "kommt", "ein", "na\u00b7her", "Freund", "/", "und", "bitts", "Be\u00b7gr\u00e4\u00b7bn\u00fc\u00df", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "ADJA", "NN", "$(", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir werden kaum zur\u00fcck von dem Verscharrten treten/", "tokens": ["Wir", "wer\u00b7den", "kaum", "zu\u00b7r\u00fcck", "von", "dem", "Ver\u00b7scharr\u00b7ten", "tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKVZ", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So gr\u00fcst ein anderer umb gleichen Dienst sein Hau\u00df.", "tokens": ["So", "gr\u00fcst", "ein", "an\u00b7de\u00b7rer", "umb", "glei\u00b7chen", "Dienst", "sein", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "APPR", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "So gar hat ihm der Tod f\u00fcr Augen wollen schweben/", "tokens": ["So", "gar", "hat", "ihm", "der", "Tod", "f\u00fcr", "Au\u00b7gen", "wol\u00b7len", "schwe\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ART", "NN", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Damit sein Christenthum durch die Gedult geschm\u00fcckt;", "tokens": ["Da\u00b7mit", "sein", "Chris\u00b7ten\u00b7thum", "durch", "die", "Ge\u00b7dult", "ge\u00b7schm\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sich GOttes Willen nun kan willig untergeben/", "tokens": ["Sich", "Got\u00b7tes", "Wil\u00b7len", "nun", "kan", "wil\u00b7lig", "un\u00b7ter\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "NN", "ADV", "VMFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ihm die Liebste wird von seiner Seit entr\u00fcckt.", "tokens": ["Da", "ihm", "die", "Liebs\u00b7te", "wird", "von", "sei\u00b7ner", "Seit", "ent\u00b7r\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Zwar/ di\u00df vernein ich nicht/ da\u00df Myrrhen-bitter Schmertzen", "tokens": ["Zwar", "/", "di\u00df", "ver\u00b7nein", "ich", "nicht", "/", "da\u00df", "Myr\u00b7rhen\u00b7bit\u00b7ter", "Schmert\u00b7zen"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$(", "PDS", "VVFIN", "PPER", "PTKNEG", "$(", "KOUS", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Be\u00e4ngstigen den Geist/ nun ihm sein Schatz entf\u00e4llt:", "tokens": ["Be\u00b7\u00e4ngs\u00b7ti\u00b7gen", "den", "Geist", "/", "nun", "ihm", "sein", "Schatz", "ent\u00b7f\u00e4llt", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$(", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df wenn der Tod zertrennt zwey gleich gesinnte Hertzen/", "tokens": ["Da\u00df", "wenn", "der", "Tod", "zer\u00b7trennt", "zwey", "gleich", "ge\u00b7sinn\u00b7te", "Hert\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "VVFIN", "CARD", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dadurch die l\u00e4ngre Lust zu leben wird verg\u00e4llt.", "tokens": ["Da\u00b7durch", "die", "l\u00e4ng\u00b7re", "Lust", "zu", "le\u00b7ben", "wird", "ver\u00b7g\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Jedoch/ wenn er bedenckt/ da\u00df sie hat m\u00fcssen sterben/", "tokens": ["Je\u00b7doch", "/", "wenn", "er", "be\u00b7denckt", "/", "da\u00df", "sie", "hat", "m\u00fcs\u00b7sen", "ster\u00b7ben", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "PPER", "VAFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df unser Leben Wind/ Dampff/ Wasser/ Gra\u00df und Heu/", "tokens": ["Da\u00df", "un\u00b7ser", "Le\u00b7ben", "Wind", "/", "Dampff", "/", "Was\u00b7ser", "/", "Gra\u00df", "und", "Heu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "$(", "NE", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df weil wir lebend seyn/ der Leib mu\u00df schon verderben/", "tokens": ["Da\u00df", "weil", "wir", "le\u00b7bend", "seyn", "/", "der", "Leib", "mu\u00df", "schon", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "VAINF", "$(", "ART", "NN", "VMFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und jede Stunde was schl\u00e4gt an dem Bau entzwey/", "tokens": ["Und", "je\u00b7de", "Stun\u00b7de", "was", "schl\u00e4gt", "an", "dem", "Bau", "ent\u00b7zwey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PWS", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Ja da\u00df sie numehr ruht und schl\u00e4fft in ihrer Kammer/", "tokens": ["Ja", "da\u00df", "sie", "nu\u00b7mehr", "ruht", "und", "schl\u00e4fft", "in", "ih\u00b7rer", "Kam\u00b7mer", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ist f\u00fcr viel Ungel\u00fcck und Tr\u00fcbsal weggerafft:", "tokens": ["Ist", "f\u00fcr", "viel", "Un\u00b7ge\u00b7l\u00fcck", "und", "Tr\u00fcb\u00b7sal", "weg\u00b7ge\u00b7rafft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PIAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wird der edle Tausch was mindern seinen Jammer", "tokens": ["So", "wird", "der", "ed\u00b7le", "Tausch", "was", "min\u00b7dern", "sei\u00b7nen", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PWS", "ADJA", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der Verblichnen Ruhm ihm geben Trost und Krafft.", "tokens": ["Und", "der", "Ver\u00b7blich\u00b7nen", "Ruhm", "ihm", "ge\u00b7ben", "Trost", "und", "Krafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "PPER", "VVINF", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Es war die Gottesfurcht ihr gleichsam angebohren/", "tokens": ["Es", "war", "die", "Got\u00b7tes\u00b7furcht", "ihr", "gleich\u00b7sam", "an\u00b7ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als die aus ", "tokens": ["Als", "die", "aus"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Und was sonst Frauen ziert zum Kleinod ihr erkohren", "tokens": ["Und", "was", "sonst", "Frau\u00b7en", "ziert", "zum", "Klei\u00b7nod", "ihr", "er\u00b7koh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "NN", "VVFIN", "APPRART", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein gantzes Tugend Chor/ Witz/ Demuth/ Zucht und Scham.", "tokens": ["Ein", "gant\u00b7zes", "Tu\u00b7gend", "Chor", "/", "Witz", "/", "De\u00b7muth", "/", "Zucht", "und", "Scham", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$(", "NN", "$(", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Die ungef\u00e4rbte Treu/ das embsige Bem\u00fchen/", "tokens": ["Die", "un\u00b7ge\u00b7f\u00e4rb\u00b7te", "Treu", "/", "das", "emb\u00b7si\u00b7ge", "Be\u00b7m\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr seines Hauses Heil r\u00fchmt noch gemeine Stadt:", "tokens": ["F\u00fcr", "sei\u00b7nes", "Hau\u00b7ses", "Heil", "r\u00fchmt", "noch", "ge\u00b7mei\u00b7ne", "Stadt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die S\u00f6hne/ so er siht des Stammes S\u00e4ulen bl\u00fchen/", "tokens": ["Die", "S\u00f6h\u00b7ne", "/", "so", "er", "siht", "des", "Stam\u00b7mes", "S\u00e4u\u00b7len", "bl\u00fc\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sind statt der Mutter jetzt im Kummer Trost und Rath.", "tokens": ["Sind", "statt", "der", "Mut\u00b7ter", "jetzt", "im", "Kum\u00b7mer", "Trost", "und", "Rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Wer so/ wie sie gelebt/ der f\u00e4hrt mit Lust von hinnen", "tokens": ["Wer", "so", "/", "wie", "sie", "ge\u00b7lebt", "/", "der", "f\u00e4hrt", "mit", "Lust", "von", "hin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "$(", "PWAV", "PPER", "VVPP", "$(", "ART", "VVFIN", "APPR", "NN", "APPR", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und l\u00e4st das S\u00fcnden-Hau\u00df/ den Leib/ den Kercker stehn/", "tokens": ["Und", "l\u00e4st", "das", "S\u00fcn\u00b7den\u00b7Hau\u00df", "/", "den", "Leib", "/", "den", "Ker\u00b7cker", "stehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$(", "ART", "NN", "$(", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kan durch den kurtzen Tod den Himmel ihm gewinnen", "tokens": ["Kan", "durch", "den", "kurt\u00b7zen", "Tod", "den", "Him\u00b7mel", "ihm", "ge\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ART", "ADJA", "NN", "ART", "NN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und in des Vatern Reich mit Sieges-Kronen gehn.", "tokens": ["Und", "in", "des", "Va\u00b7tern", "Reich", "mit", "Sie\u00b7ges\u00b7Kro\u00b7nen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Man sol der Frommen Tod gl\u00fcckw\u00fcnschende begleiten/", "tokens": ["Man", "sol", "der", "From\u00b7men", "Tod", "gl\u00fcck\u00b7w\u00fcn\u00b7schen\u00b7de", "be\u00b7glei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "ADJA", "VVINF", "$("], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als der den Jammer endt/ der Freuden Anfang macht.", "tokens": ["Als", "der", "den", "Jam\u00b7mer", "endt", "/", "der", "Freu\u00b7den", "An\u00b7fang", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "NN", "VVFIN", "$(", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie haben obgesiegt/ wir liegen noch im streiten/", "tokens": ["Sie", "ha\u00b7ben", "ob\u00b7ge\u00b7siegt", "/", "wir", "lie\u00b7gen", "noch", "im", "strei\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$(", "PPER", "VVFIN", "ADV", "APPRART", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie schm\u00fcckt der Klarheit Glantz/ uns deckt Egyptens Nacht.", "tokens": ["Sie", "schm\u00fcckt", "der", "Klar\u00b7heit", "Glantz", "/", "uns", "deckt", "E\u00b7gyp\u00b7tens", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$(", "PPER", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Ich wei\u00df/ ", "tokens": ["Ich", "wei\u00df", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Der Vater alles Trosts steh ihm gen\u00e4dig bey/", "tokens": ["Der", "Va\u00b7ter", "al\u00b7les", "Trosts", "steh", "ihm", "ge\u00b7n\u00e4\u00b7dig", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und woll\u2019 ihn durch und durch mit Krafft und Heil erf\u00fcllen/", "tokens": ["Und", "woll'", "ihn", "durch", "und", "durch", "mit", "Krafft", "und", "Heil", "er\u00b7f\u00fcl\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "APPR", "KON", "APPR", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df er noch lange Zeit der Kirchen Vater sey/", "tokens": ["Da\u00df", "er", "noch", "lan\u00b7ge", "Zeit", "der", "Kir\u00b7chen", "Va\u00b7ter", "sey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "ART", "NN", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Und r\u00fchmlich/ wie bi\u00dfher/ gemeinem besten diene.", "tokens": ["Und", "r\u00fchm\u00b7lich", "/", "wie", "bi\u00df\u00b7her", "/", "ge\u00b7mei\u00b7nem", "bes\u00b7ten", "die\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$(", "KOKOM", "ADV", "$(", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sp\u00e4te Nach-Welt nennt darvor sich Schuldnerin.", "tokens": ["Die", "sp\u00e4\u00b7te", "Nach\u00b7Welt", "nennt", "dar\u00b7vor", "sich", "Schuld\u00b7ne\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PAV", "PRF", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vern\u00fcnfft\u2019ger Leute Ruhm bleibt nach dem Tode gr\u00fcne/", "tokens": ["Ver\u00b7n\u00fcnf\u00b7ft'\u00b7ger", "Leu\u00b7te", "Ruhm", "bleibt", "nach", "dem", "To\u00b7de", "gr\u00fc\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wenn man die andern sonst vergessen tr\u00e4gt dahin.", "tokens": ["Wenn", "man", "die", "an\u00b7dern", "sonst", "ver\u00b7ges\u00b7sen", "tr\u00e4gt", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "ADJA", "ADV", "VVPP", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}