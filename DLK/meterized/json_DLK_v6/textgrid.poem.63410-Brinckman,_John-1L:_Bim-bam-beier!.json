{"textgrid.poem.63410": {"metadata": {"author": {"name": "Brinckman, John", "birth": "N.A.", "death": "N.A."}, "title": "1L: Bim-bam-beier!", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bim-bam-beier!", "tokens": ["Bim\u00b7bam\u00b7bei\u00b7er", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "De K\u00f6ster mag girn Eier,", "tokens": ["De", "K\u00f6s\u00b7ter", "mag", "girn", "Ei\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VMFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "M\u00e4hl in de Pann,", "tokens": ["M\u00e4hl", "in", "de", "Pann", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "NE", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Botter an \u2013", "tokens": ["Bot\u00b7ter", "an", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "K\u00f6ster is een Leckermann!", "tokens": ["K\u00f6s\u00b7ter", "is", "e\u00b7en", "Le\u00b7cker\u00b7mann", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "FM", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "Bim-bam-J\u00fcnging,", "tokens": ["Bim\u00b7bam\u00b7J\u00fcn\u00b7ging", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "min oll l\u00fctt Lusep\u00fcnging,", "tokens": ["min", "oll", "l\u00fctt", "Lu\u00b7se\u00b7p\u00fcn\u00b7ging", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "NE", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "min oll l\u00fctt leewe Snickermus,", "tokens": ["min", "oll", "l\u00fctt", "lee\u00b7we", "Sni\u00b7cker\u00b7mus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.4": {"text": "din Og is blag, din Poll is krus \u2013", "tokens": ["din", "Og", "is", "blag", ",", "din", "Poll", "is", "krus", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "bim-bam, nu ligg un drus'!", "tokens": ["bim\u00b7bam", ",", "nu", "ligg", "un", "drus'", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "FM", "FM", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Bim-bam-Soehning,", "tokens": ["Bim\u00b7bam\u00b7Soeh\u00b7ning", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "min oll l\u00fctt Kunkeld\u0153ning,", "tokens": ["min", "oll", "l\u00fctt", "Kun\u00b7keld\u0153\u00b7ning", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "du haddst jo lang to Wim all m\u00fc\u00dft,", "tokens": ["du", "haddst", "jo", "lang", "to", "Wim", "all", "m\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "ADJD", "NE", "NE", "PIAT", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wu lang is all de S\u00fcnn to R\u00fcst,", "tokens": ["wu", "lang", "is", "all", "de", "S\u00fcnn", "to", "R\u00fcst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "FM", "PIAT", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "un M\u00f6ding hett di nog nu k\u00fc\u00dft!", "tokens": ["un", "M\u00f6\u00b7ding", "hett", "di", "nog", "nu", "k\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "ADV", "VVFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}}, "stanza.4": {"line.1": {"text": "Bim-bam-brumms\u00fcsing!", "tokens": ["Bim\u00b7bam\u00b7brumms\u00fc\u00b7sing", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Nu ligg un ligg un dr\u00fcsing!", "tokens": ["Nu", "ligg", "un", "ligg", "un", "dr\u00fc\u00b7sing", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "FM", "FM", "FM", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Din P\u0153hl und B\u00fcr is warm, s\u00fch so,", "tokens": ["Din", "P\u0153hl", "und", "B\u00fcr", "is", "warm", ",", "s\u00fch", "so", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "FM", "ADJD", "$,", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "nu do, as ick di heeten do,", "tokens": ["nu", "do", ",", "as", "ick", "di", "hee\u00b7ten", "do", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "do \u00d6ging to, Grall\u00f6ging to!", "tokens": ["do", "\u00d6\u00b7ging", "to", ",", "Gral\u00b7l\u00f6\u00b7ging", "to", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}