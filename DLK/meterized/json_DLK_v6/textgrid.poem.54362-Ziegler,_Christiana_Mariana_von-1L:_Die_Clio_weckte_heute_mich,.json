{"textgrid.poem.54362": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Die Clio weckte heute mich,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Clio weckte heute mich,", "tokens": ["Die", "Clio", "weck\u00b7te", "heu\u00b7te", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "PPER", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Eh noch die Morgenr\u00f6the sich", "tokens": ["Eh", "noch", "die", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN", "PRF"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Lie\u00df sehn, aus Schlaf und Schlummer;", "tokens": ["Lie\u00df", "sehn", ",", "aus", "Schlaf", "und", "Schlum\u00b7mer", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$,", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich dehnte mich halb schnarchend aus,", "tokens": ["Ich", "dehn\u00b7te", "mich", "halb", "schnar\u00b7chend", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch sprang ich zu dem Bett heraus,", "tokens": ["Doch", "sprang", "ich", "zu", "dem", "Bett", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Voll Unruh, und voll Kummer.", "tokens": ["Voll", "Un\u00b7ruh", ",", "und", "voll", "Kum\u00b7mer", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Auf! sprach sie, nimm dein Dintenfa\u00df,", "tokens": ["Auf", "!", "sprach", "sie", ",", "nimm", "dein", "Din\u00b7ten\u00b7fa\u00df", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "VVIMP", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich weis, du h\u00e4ltst unfehlbar was", "tokens": ["Ich", "weis", ",", "du", "h\u00e4ltst", "un\u00b7fehl\u00b7bar", "was"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ADJD", "PWS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von gut getroffnen Bildern;", "tokens": ["Von", "gut", "ge\u00b7troff\u00b7nen", "Bil\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Drum will ich hier ein Conterfey", "tokens": ["Drum", "will", "ich", "hier", "ein", "Con\u00b7ter\u00b7fey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ohn allen Trug und Schmeicheley", "tokens": ["Ohn", "al\u00b7len", "Trug", "und", "Schmei\u00b7che\u00b7ley"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von deiner Freundin schildern.", "tokens": ["Von", "dei\u00b7ner", "Freun\u00b7din", "schil\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Nimm in die Pf\u00f6tchen deinen Kiel,", "tokens": ["Nimm", "in", "die", "Pf\u00f6t\u00b7chen", "dei\u00b7nen", "Kiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schreibe diesmal nur so viel,", "tokens": ["Und", "schrei\u00b7be", "dies\u00b7mal", "nur", "so", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ich itzt glaub und meyne.", "tokens": ["Als", "ich", "itzt", "glaub", "und", "mey\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hat ein Herz voll Redlichkeit,", "tokens": ["Sie", "hat", "ein", "Herz", "voll", "Red\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch trauet sie nicht allezeit,", "tokens": ["Doch", "trau\u00b7et", "sie", "nicht", "al\u00b7le\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und schw\u00f6r man Stein und Beine.", "tokens": ["Und", "schw\u00f6r", "man", "Stein", "und", "Bei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sie ist freygebig; Lobesan", "tokens": ["Sie", "ist", "frey\u00b7ge\u00b7big", ";", "Lo\u00b7be\u00b7san"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ADJD", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kommt diese sch\u00f6ne Laun ihr an;", "tokens": ["Kommt", "die\u00b7se", "sch\u00f6\u00b7ne", "Laun", "ihr", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "ADJA", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch nicht zu allen Stunden.", "tokens": ["Doch", "nicht", "zu", "al\u00b7len", "Stun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Denn wenn man sie vor milde h\u00e4lt,", "tokens": ["Denn", "wenn", "man", "sie", "vor", "mil\u00b7de", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So bleibt der Sack zur\u00fcck gestellt,", "tokens": ["So", "bleibt", "der", "Sack", "zu\u00b7r\u00fcck", "ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sauber zugebunden.", "tokens": ["Und", "sau\u00b7ber", "zu\u00b7ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ihr Haus, wo stets der Tisch gedeckt,", "tokens": ["Ihr", "Haus", ",", "wo", "stets", "der", "Tisch", "ge\u00b7deckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wo Getr\u00e4nk und Speise schmeckt,", "tokens": ["Und", "wo", "Ge\u00b7tr\u00e4nk", "und", "Spei\u00b7se", "schmeckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Steht guten Freunden offen.", "tokens": ["Steht", "gu\u00b7ten", "Freun\u00b7den", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Allein, der Misbrauch mu\u00df nicht seyn,", "tokens": ["Al\u00b7lein", ",", "der", "Mis\u00b7brauch", "mu\u00df", "nicht", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VMFIN", "PTKNEG", "VAINF", "$,"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Denn f\u00e4llt man stets wie Fliegen ein,", "tokens": ["Denn", "f\u00e4llt", "man", "stets", "wie", "Flie\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "KOKOM", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So hat man nichts zu hoffen.", "tokens": ["So", "hat", "man", "nichts", "zu", "hof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Es kann im Umgang alsofort", "tokens": ["Es", "kann", "im", "Um\u00b7gang", "al\u00b7so\u00b7fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie vielmals auch ein einig Wort", "tokens": ["Sie", "viel\u00b7mals", "auch", "ein", "ei\u00b7nig", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gleich verdr\u00fc\u00dflich machen.", "tokens": ["So", "gleich", "ver\u00b7dr\u00fc\u00df\u00b7lich", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wallt ihr auch noch so sehr das Blut,", "tokens": ["Wallt", "ihr", "auch", "noch", "so", "sehr", "das", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wird sie doch gleich wieder gut,", "tokens": ["So", "wird", "sie", "doch", "gleich", "wie\u00b7der", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und f\u00e4nget an zu lachen.", "tokens": ["Und", "f\u00e4n\u00b7get", "an", "zu", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Nach Erb und Gut steht nicht ihr Sinn,", "tokens": ["Nach", "Erb", "und", "Gut", "steht", "nicht", "ihr", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJD", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie viele thun, begierig hin,", "tokens": ["Wie", "vie\u00b7le", "thun", ",", "be\u00b7gie\u00b7rig", "hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVINF", "$,", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die nur dem Mammon fr\u00f6hnen.", "tokens": ["Die", "nur", "dem", "Mam\u00b7mon", "fr\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Viel lieber g\u00e4b sie, was sie hat,", "tokens": ["Viel", "lie\u00b7ber", "g\u00e4b", "sie", ",", "was", "sie", "hat", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$,", "PRELS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um andern ihren Lebensdrat", "tokens": ["Um", "an\u00b7dern", "ih\u00b7ren", "Le\u00b7bens\u00b7drat"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "ADJA", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dadurch lang auszudehnen.", "tokens": ["Da\u00b7durch", "lang", "aus\u00b7zu\u00b7deh\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Bringt man ihr neue Zeitung vor,", "tokens": ["Bringt", "man", "ihr", "neu\u00b7e", "Zei\u00b7tung", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "So pfleget solches zwar ihr Ohr", "tokens": ["So", "pfle\u00b7get", "sol\u00b7ches", "zwar", "ihr", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gar willig anzuh\u00f6ren;", "tokens": ["Gar", "wil\u00b7lig", "an\u00b7zu\u00b7h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie schweiget dabey m\u00e4uschen still,", "tokens": ["Sie", "schwei\u00b7get", "da\u00b7bey", "m\u00e4u\u00b7schen", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch glaubet sie nur, was sie will,", "tokens": ["Doch", "glau\u00b7bet", "sie", "nur", ",", "was", "sie", "will", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PRELS", "PPER", "VMFIN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und l\u00e4\u00dft sich nicht beth\u00f6ren.", "tokens": ["Und", "l\u00e4\u00dft", "sich", "nicht", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "So sch\u00f6n ein J\u00fcngling immer hei\u00dft,", "tokens": ["So", "sch\u00f6n", "ein", "J\u00fcng\u00b7ling", "im\u00b7mer", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der hold und rothe B\u00e4ckchen weist,", "tokens": ["Der", "hold", "und", "ro\u00b7the", "B\u00e4ck\u00b7chen", "weist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "H\u00f6rt man sie zwar ihn loben.", "tokens": ["H\u00f6rt", "man", "sie", "zwar", "ihn", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jedoch, er macht ihr keinen Schmerz,", "tokens": ["Je\u00b7doch", ",", "er", "macht", "ihr", "kei\u00b7nen", "Schmerz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es ist vor ihr empfindlich Herz", "tokens": ["Es", "ist", "vor", "ihr", "emp\u00b7find\u00b7lich", "Herz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ein Riegel vorgeschoben.", "tokens": ["Ein", "Rie\u00b7gel", "vor\u00b7ge\u00b7scho\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Die Hagestolzen ehret sie,", "tokens": ["Die", "Ha\u00b7ge\u00b7stol\u00b7zen", "eh\u00b7ret", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und giebet sich rechtschaffne M\u00fch,", "tokens": ["Und", "gie\u00b7bet", "sich", "recht\u00b7schaff\u00b7ne", "M\u00fch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dieselben hoch zu halten.", "tokens": ["Die\u00b7sel\u00b7ben", "hoch", "zu", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja, was? sie liebt sie inniglich,", "tokens": ["Ja", ",", "was", "?", "sie", "liebt", "sie", "in\u00b7nig\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "$.", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Denn Witz und Klugheit zeiget sich", "tokens": ["Denn", "Witz", "und", "Klug\u00b7heit", "zei\u00b7get", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Allein nur bey den Alten.", "tokens": ["Al\u00b7lein", "nur", "bey", "den", "Al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Sie hat sich Klingen welche man", "tokens": ["Sie", "hat", "sich", "Klin\u00b7gen", "wel\u00b7che", "man"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "NN", "PRELS", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Zieglers Kunst wohl preisen kann,", "tokens": ["Durch", "Zieg\u00b7lers", "Kunst", "wohl", "prei\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu Schimpf und Ernst erkohren.", "tokens": ["Zu", "Schimpf", "und", "Ernst", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bek\u00fcmmert sich doch nicht dabey,", "tokens": ["Be\u00b7k\u00fcm\u00b7mert", "sich", "doch", "nicht", "da\u00b7bey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wohin der Heft gekommen sey;", "tokens": ["Wo\u00b7hin", "der", "Heft", "ge\u00b7kom\u00b7men", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch wer ihn hat verlohren.", "tokens": ["Noch", "wer", "ihn", "hat", "ver\u00b7loh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Kaum, da\u00df ich dies durch meine Hand", "tokens": ["Kaum", ",", "da\u00df", "ich", "dies", "durch", "mei\u00b7ne", "Hand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "PDS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Muse nach geschrieben fand,", "tokens": ["Der", "Mu\u00b7se", "nach", "ge\u00b7schrie\u00b7ben", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die mir dies Bildni\u00df wiese;", "tokens": ["Die", "mir", "dies", "Bild\u00b7ni\u00df", "wie\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PDS", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So sprach ich: dies ist ganz gewi\u00df", "tokens": ["So", "sprach", "ich", ":", "dies", "ist", "ganz", "ge\u00b7wi\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PDS", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Zeichnung und der wahre Ri\u00df", "tokens": ["Die", "Zeich\u00b7nung", "und", "der", "wah\u00b7re", "Ri\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von unsrer Mutter Liese.", "tokens": ["Von", "uns\u00b7rer", "Mut\u00b7ter", "Lie\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Und weil ich weis, da\u00df sie das Fest", "tokens": ["Und", "weil", "ich", "weis", ",", "da\u00df", "sie", "das", "Fest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des sch\u00f6nen Namens feyren l\u00e4\u00dft,", "tokens": ["Des", "sch\u00f6\u00b7nen", "Na\u00b7mens", "fey\u00b7ren", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den wir mit Lust erblicken;", "tokens": ["Den", "wir", "mit", "Lust", "er\u00b7bli\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So will ich ihr heut dieses Blat,", "tokens": ["So", "will", "ich", "ihr", "heut", "die\u00b7ses", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das ihr mein Mund versprochen hat,", "tokens": ["Das", "ihr", "mein", "Mund", "ver\u00b7spro\u00b7chen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum Angebinde schicken.", "tokens": ["Zum", "An\u00b7ge\u00b7bin\u00b7de", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Doch hang ich diesen Wunsch noch dran,", "tokens": ["Doch", "hang", "ich", "die\u00b7sen", "Wunsch", "noch", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDAT", "NN", "ADV", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den ich nicht schuldig bleiben kann;", "tokens": ["Den", "ich", "nicht", "schul\u00b7dig", "blei\u00b7ben", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie mag vergn\u00fcget leben,", "tokens": ["Sie", "mag", "ver\u00b7gn\u00fc\u00b7get", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bis sie dereinst im grauen Haar", "tokens": ["Bis", "sie", "de\u00b7reinst", "im", "grau\u00b7en", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So, wie die \u2013 \u2013 \u2013 \u2013 \u2013 war,", "tokens": ["So", ",", "wie", "die", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "war", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "$(", "$(", "$(", "$(", "$(", "VAFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Der Welt wird Abschied geben.", "tokens": ["Der", "Welt", "wird", "Ab\u00b7schied", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}