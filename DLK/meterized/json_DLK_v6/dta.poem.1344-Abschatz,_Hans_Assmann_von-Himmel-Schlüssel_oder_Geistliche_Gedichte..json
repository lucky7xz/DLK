{"dta.poem.1344": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Himmel-Schl\u00fcssel  \n oder  \n Geistliche Gedichte.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Der fr\u00fche Morgen zeiget sich/", "tokens": ["Der", "fr\u00fc\u00b7he", "Mor\u00b7gen", "zei\u00b7get", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auff/ meine Seel/ und finde dich", "tokens": ["Auff", "/", "mei\u00b7ne", "Seel", "/", "und", "fin\u00b7de", "dich"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "$(", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu JEsu Grab und F\u00fcssen wieder!", "tokens": ["Zu", "Je\u00b7su", "Grab", "und", "F\u00fcs\u00b7sen", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier legte man vons Creutzes Stamm", "tokens": ["Hier", "leg\u00b7te", "man", "vons", "Creut\u00b7zes", "Stamm"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Am Freytag deinen Br\u00e4utigam", "tokens": ["Am", "Frey\u00b7tag", "dei\u00b7nen", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur stillen Todten-Ruhe nieder.", "tokens": ["Zur", "stil\u00b7len", "Tod\u00b7ten\u00b7Ru\u00b7he", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Was f\u00fcrchtestu den schweren Stein", "tokens": ["Was", "f\u00fcrch\u00b7tes\u00b7tu", "den", "schwe\u00b7ren", "Stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der dir im Wege m\u00f6chte seyn/", "tokens": ["Der", "dir", "im", "We\u00b7ge", "m\u00f6ch\u00b7te", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VMFIN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des HErren blassen Mund zu k\u00fcssen:", "tokens": ["Des", "Her\u00b7ren", "blas\u00b7sen", "Mund", "zu", "k\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Er ist durch unbekandte Macht", "tokens": ["Er", "ist", "durch", "un\u00b7be\u00b7kand\u00b7te", "Macht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bereits von seiner St\u00e4tte bracht/", "tokens": ["Be\u00b7reits", "von", "sei\u00b7ner", "St\u00e4t\u00b7te", "bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und kan das Grab nicht mehr verschliessen.", "tokens": ["Und", "kan", "das", "Grab", "nicht", "mehr", "ver\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun meine Seele/ du bist hier/", "tokens": ["Nun", "mei\u00b7ne", "See\u00b7le", "/", "du", "bist", "hier", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$(", "PPER", "VAFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch f\u00e4llt ein neuer Kummer f\u00fcr/", "tokens": ["Doch", "f\u00e4llt", "ein", "neu\u00b7er", "Kum\u00b7mer", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wer wei\u00df dich dessen zu entbinden?", "tokens": ["Wer", "wei\u00df", "dich", "des\u00b7sen", "zu", "ent\u00b7bin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PDS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Begieb dich in di\u00df Todten-Hau\u00df/", "tokens": ["Be\u00b7gieb", "dich", "in", "di\u00df", "Tod\u00b7ten\u00b7Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PDS", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Such alle Winckel drinnen aus:", "tokens": ["Such", "al\u00b7le", "Win\u00b7ckel", "drin\u00b7nen", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein JEsus ist hier nicht zu finden.", "tokens": ["Dein", "Je\u00b7sus", "ist", "hier", "nicht", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VAFIN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Er ward in T\u00fccher eingeh\u00fcllt/", "tokens": ["Er", "ward", "in", "T\u00fc\u00b7cher", "ein\u00b7ge\u00b7h\u00fcllt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Myrrh und Aloe gef\u00fcllt/", "tokens": ["Mit", "Myrrh", "und", "A\u00b7loe", "ge\u00b7f\u00fcllt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Der gantze C\u00f6rper war umwunden.", "tokens": ["Der", "gant\u00b7ze", "C\u00f6r\u00b7per", "war", "um\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Hier zeiget sich des Lagers Platz/", "tokens": ["Hier", "zei\u00b7get", "sich", "des", "La\u00b7gers", "Platz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wo aber ist der beste Schatz/", "tokens": ["Wo", "a\u00b7ber", "ist", "der", "bes\u00b7te", "Schatz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der theure Heyland hin verschwunden?", "tokens": ["Der", "theu\u00b7re", "Hey\u00b7land", "hin", "ver\u00b7schwun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wer ist der mich berichten kan/", "tokens": ["Wer", "ist", "der", "mich", "be\u00b7rich\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PPER", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo man den HErren hingethan/", "tokens": ["Wo", "man", "den", "Her\u00b7ren", "hin\u00b7ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den meine Seele sucht und liebet?", "tokens": ["Den", "mei\u00b7ne", "See\u00b7le", "sucht", "und", "lie\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Find ich des Hertzens Trost und Licht/", "tokens": ["Find", "ich", "des", "Hert\u00b7zens", "Trost", "und", "Licht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Leben meiner Seele nicht/", "tokens": ["Das", "Le\u00b7ben", "mei\u00b7ner", "See\u00b7le", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So bin ich bi\u00df in Tod betr\u00fcbet.", "tokens": ["So", "bin", "ich", "bi\u00df", "in", "Tod", "be\u00b7tr\u00fc\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Was aber such ich den der lebt/", "tokens": ["Was", "a\u00b7ber", "such", "ich", "den", "der", "lebt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "ART", "ART", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein JEsus ist ja aufferstanden.", "tokens": ["Mein", "Je\u00b7sus", "ist", "ja", "auf\u00b7fer\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was scheu ich nunmehr Tod und Grab/", "tokens": ["Was", "scheu", "ich", "nun\u00b7mehr", "Tod", "und", "Grab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nachdem ich die Gewi\u00dfheit hab/", "tokens": ["Nach\u00b7dem", "ich", "die", "Ge\u00b7wi\u00df\u00b7heit", "hab", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Aufferwecker ist verhanden!", "tokens": ["Mein", "Auf\u00b7fer\u00b7we\u00b7cker", "ist", "ver\u00b7han\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ich seh ihn schon von ferne stehn/", "tokens": ["Ich", "seh", "ihn", "schon", "von", "fer\u00b7ne", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADV", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und mir mit Trost entgegen gehn/", "tokens": ["Und", "mir", "mit", "Trost", "ent\u00b7ge\u00b7gen", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "PTKVZ", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In angenommnem G\u00e4rtner-Kleide/", "tokens": ["In", "an\u00b7ge\u00b7nomm\u00b7nem", "G\u00e4rt\u00b7ner\u00b7Klei\u00b7de", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Damit ich fortan sicher wei\u00df/", "tokens": ["Da\u00b7mit", "ich", "for\u00b7tan", "si\u00b7cher", "wei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df mich vom frohen Paradei\u00df", "tokens": ["Da\u00df", "mich", "vom", "fro\u00b7hen", "Pa\u00b7ra\u00b7dei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und ihm nicht Tod/ nicht H\u00f6lle scheide!", "tokens": ["Und", "ihm", "nicht", "Tod", "/", "nicht", "H\u00f6l\u00b7le", "schei\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "NN", "$(", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}