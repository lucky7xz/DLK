{"dta.poem.4155": {"metadata": {"author": {"name": "M\u00fcller, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Thr\u00e4nen und Rosen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1821", "urn": "urn:nbn:de:kobv:b4-200905194209", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wohl um die Abendstund'", "tokens": ["Wohl", "um", "die", "A\u00b7bend\u00b7stund'"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "In einem Rosengarten,", "tokens": ["In", "ei\u00b7nem", "Ro\u00b7sen\u00b7gar\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da bl\u00fchten Bl\u00fcmlein bunt.", "tokens": ["Da", "bl\u00fch\u00b7ten", "Bl\u00fcm\u00b7lein", "bunt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Er ging wohl auf und nieder", "tokens": ["Er", "ging", "wohl", "auf", "und", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "KON", "PTKVZ"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vor eines G\u00e4rtners Haus,", "tokens": ["Vor", "ei\u00b7nes", "G\u00e4rt\u00b7ners", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da lag ein M\u00e4gdlein sch\u00f6ne", "tokens": ["Da", "lag", "ein", "M\u00e4gd\u00b7lein", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zum Fensterlein heraus.", "tokens": ["Zum", "Fens\u00b7ter\u00b7lein", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ein R\u00f6slein th\u00e4t' er brechen,", "tokens": ["Ein", "R\u00f6s\u00b7lein", "th\u00e4t'", "er", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Warf's in das Fensterlein:", "tokens": ["Wa\u00b7rf's", "in", "das", "Fens\u00b7ter\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Thust schlafen oder wachen,", "tokens": ["Thust", "schla\u00b7fen", "o\u00b7der", "wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herzallerliebste mein?", "tokens": ["Her\u00b7zal\u00b7ler\u00b7liebs\u00b7te", "mein", "?"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00abich habe nicht geschlafen,", "tokens": ["\u00ab", "ich", "ha\u00b7be", "nicht", "ge\u00b7schla\u00b7fen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00abich habe nicht gewacht,", "tokens": ["\u00ab", "ich", "ha\u00b7be", "nicht", "ge\u00b7wacht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00abich habe nur getr\u00e4umet,", "tokens": ["\u00ab", "ich", "ha\u00b7be", "nur", "ge\u00b7tr\u00e4u\u00b7met", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00aban dich hab' ich gedacht.\u00bb", "tokens": ["\u00ab", "an", "dich", "hab'", "ich", "ge\u00b7dacht", ".", "\u00bb"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPR", "PPER", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Du hast ja auch geweinet,", "tokens": ["Du", "hast", "ja", "auch", "ge\u00b7wei\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein' Aeuglein sind so na\u00df;", "tokens": ["Dein'", "A\u00b7e\u00b7u\u00b7glein", "sind", "so", "na\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eine Thr\u00e4n' fiel aus dem Fenster,", "tokens": ["Ei\u00b7ne", "Thr\u00e4n'", "fiel", "aus", "dem", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da wuchs eine Ros' im Gras.", "tokens": ["Da", "wuchs", "ei\u00b7ne", "Ros'", "im", "Gras", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00abund ist eine Ros' gewachsen,", "tokens": ["\u00ab", "und", "ist", "ei\u00b7ne", "Ros'", "ge\u00b7wach\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00abso wuchs sie nur f\u00fcr dich,", "tokens": ["\u00ab", "so", "wuchs", "sie", "nur", "f\u00fcr", "dich", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00abund wenn ich hab' geweinet,", "tokens": ["\u00ab", "und", "wenn", "ich", "hab'", "ge\u00b7wei\u00b7net", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00abso weint' ich nur um mich.\u00bb", "tokens": ["\u00ab", "so", "weint'", "ich", "nur", "um", "mich", ".", "\u00bb"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Was zog er aus der Tasche?", "tokens": ["Was", "zog", "er", "aus", "der", "Ta\u00b7sche", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein seidnes T\u00fcchelein.", "tokens": ["Ein", "seid\u00b7nes", "T\u00fc\u00b7chel\u00b7ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nimm hin, Herzallerliebste,", "tokens": ["Nimm", "hin", ",", "Her\u00b7zal\u00b7ler\u00b7liebs\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wisch' ab dein' Aeugelein!", "tokens": ["Wisch'", "ab", "dein'", "A\u00b7e\u00b7u\u00b7ge\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und bin ich in der Fremde,", "tokens": ["Und", "bin", "ich", "in", "der", "Frem\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weit, weit von deinem Haus,", "tokens": ["Weit", ",", "weit", "von", "dei\u00b7nem", "Haus", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So weine deine Thr\u00e4nen", "tokens": ["So", "wei\u00b7ne", "dei\u00b7ne", "Thr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zum Fenster nicht hinaus.", "tokens": ["Zum", "Fens\u00b7ter", "nicht", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "So weine sie bed\u00e4chtig", "tokens": ["So", "wei\u00b7ne", "sie", "be\u00b7d\u00e4ch\u00b7tig"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "All' in das Tuch hinein,", "tokens": ["All'", "in", "das", "Tuch", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Damit kein b\u00f6ser Bube", "tokens": ["Da\u00b7mit", "kein", "b\u00f6\u00b7ser", "Bu\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zertritt die R\u00f6selein.", "tokens": ["Zer\u00b7tritt", "die", "R\u00f6\u00b7se\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}