{"textgrid.poem.49721": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Betrachtung", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Seht auf eine Rinderherde!", "tokens": ["Seht", "auf", "ei\u00b7ne", "Rin\u00b7der\u00b7her\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Friedlich grasen neben K\u00fchen", "tokens": ["Fried\u00b7lich", "gra\u00b7sen", "ne\u00b7ben", "K\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Andre K\u00fche, welche gleichfalls", "tokens": ["And\u00b7re", "K\u00fc\u00b7he", ",", "wel\u00b7che", "gleich\u00b7falls"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um ihr Futter sich bem\u00fchen.", "tokens": ["Um", "ihr", "Fut\u00b7ter", "sich", "be\u00b7m\u00fc\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Alle fressen nur das Quantum,", "tokens": ["Al\u00b7le", "fres\u00b7sen", "nur", "das", "Quan\u00b7tum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welches sie ben\u00f6tigt haben;", "tokens": ["Wel\u00b7ches", "sie", "be\u00b7n\u00f6\u00b7tigt", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Keine k\u00fcmmert sich, ob andre", "tokens": ["Kei\u00b7ne", "k\u00fcm\u00b7mert", "sich", ",", "ob", "and\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "$,", "KOUS", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Etwa reichlicher sich laben.", "tokens": ["Et\u00b7wa", "reich\u00b7li\u00b7cher", "sich", "la\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "VVINF", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.3": {"line.1": {"text": "Keine will die Nahrungstriebe", "tokens": ["Kei\u00b7ne", "will", "die", "Nah\u00b7rungs\u00b7trie\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einer andern ruchlos st\u00f6ren,", "tokens": ["Ei\u00b7ner", "an\u00b7dern", "ruch\u00b7los", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dadurch den Bruch des Friedens", "tokens": ["Und", "da\u00b7durch", "den", "Bruch", "des", "Frie\u00b7dens"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und den Kampf heraufbeschw\u00f6ren.", "tokens": ["Und", "den", "Kampf", "her\u00b7auf\u00b7be\u00b7schw\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "\u00c4hnlich zart ist auch der Ochse,", "tokens": ["\u00c4hn\u00b7lich", "zart", "ist", "auch", "der", "O\u00b7chse", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der die fromme Denkart lernte,", "tokens": ["Der", "die", "from\u00b7me", "Den\u00b7kart", "lern\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als man ihm sein Allersch\u00f6nstes", "tokens": ["Als", "man", "ihm", "sein", "Al\u00b7ler\u00b7sch\u00f6ns\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "PPOSAT", "ADJA"], "meter": "+--++-+-", "measure": "dactylic.init"}, "line.4": {"text": "Mit dem Messerschnitt entfernte.", "tokens": ["Mit", "dem", "Mes\u00b7ser\u00b7schnitt", "ent\u00b7fern\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Nur die b\u00f6sen Stiere raufen.", "tokens": ["Nur", "die", "b\u00f6\u00b7sen", "Stie\u00b7re", "rau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ihr d\u00fcrft es nicht vergessen,", "tokens": ["Doch", "ihr", "d\u00fcrft", "es", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sie f\u00fcr die Liebe k\u00e4mpfen,", "tokens": ["Da\u00df", "sie", "f\u00fcr", "die", "Lie\u00b7be", "k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Niemals aber f\u00fcr das Fressen.", "tokens": ["Nie\u00b7mals", "a\u00b7ber", "f\u00fcr", "das", "Fres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und dabei ward diesen Tieren", "tokens": ["Und", "da\u00b7bei", "ward", "die\u00b7sen", "Tie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VAFIN", "PDAT", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Nie ein Wort des Heils verk\u00fcndet!", "tokens": ["Nie", "ein", "Wort", "des", "Heils", "ver\u00b7k\u00fcn\u00b7det", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es wurde unter ihnen", "tokens": ["Und", "es", "wur\u00b7de", "un\u00b7ter", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Keine Religion gegr\u00fcndet!", "tokens": ["Kei\u00b7ne", "Re\u00b7li\u00b7gi\u00b7on", "ge\u00b7gr\u00fcn\u00b7det", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Wenn wir dieses recht betrachten,", "tokens": ["Wenn", "wir", "die\u00b7ses", "recht", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDAT", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sagen wir vielleicht bescheiden:", "tokens": ["Sa\u00b7gen", "wir", "viel\u00b7leicht", "be\u00b7schei\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie viel schlechter sind die Menschen,", "tokens": ["Wie", "viel", "schlech\u00b7ter", "sind", "die", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die sich hassen und beneiden!", "tokens": ["Die", "sich", "has\u00b7sen", "und", "be\u00b7nei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Die sich hauen, schie\u00dfen, stechen,", "tokens": ["Die", "sich", "hau\u00b7en", ",", "schie\u00b7\u00dfen", ",", "ste\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "PRF", "VVINF", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Leben und Gesundheit rauben", "tokens": ["Le\u00b7ben", "und", "Ge\u00b7sund\u00b7heit", "rau\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00fcr die Liebe, f\u00fcr das Fressen,", "tokens": ["F\u00fcr", "die", "Lie\u00b7be", ",", "f\u00fcr", "das", "Fres\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und f\u00fcr ihren Gottesglauben!", "tokens": ["Und", "f\u00fcr", "ih\u00b7ren", "Got\u00b7tes\u00b7glau\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}