{"textgrid.poem.52797": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: O qu\u00e4let nie ein Thier zum Scherze", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O qu\u00e4let nie ein Thier zum Scherze", "tokens": ["O", "qu\u00e4\u00b7let", "nie", "ein", "Thier", "zum", "Scher\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und auch zum Ernste qu\u00e4lt es nie!", "tokens": ["Und", "auch", "zum", "Erns\u00b7te", "qu\u00e4lt", "es", "nie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bekanntlich unterliegt dem Schmerze", "tokens": ["Be\u00b7kannt\u00b7lich", "un\u00b7ter\u00b7liegt", "dem", "Schmer\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So wie der Mensch das liebe Vieh.", "tokens": ["So", "wie", "der", "Mensch", "das", "lie\u00b7be", "Vieh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es kann euch nicht vor Amt verklagen,", "tokens": ["Es", "kann", "euch", "nicht", "vor", "Amt", "ver\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ach! um so wen'ger sollt ihr's schlagen!", "tokens": ["Ach", "!", "um", "so", "wen'\u00b7ger", "sollt", "ih\u00b7r's", "schla\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "APPR", "ADV", "PIS", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Wer seinem Stier das Maul verbindet,", "tokens": ["Wer", "sei\u00b7nem", "Stier", "das", "Maul", "ver\u00b7bin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der thut es auch bei Weib und Kind,", "tokens": ["Der", "thut", "es", "auch", "bei", "Weib", "und", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Menschenfreund indessen findet,", "tokens": ["Ein", "Men\u00b7schen\u00b7freund", "in\u00b7des\u00b7sen", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df solche Thaten unrecht sind.", "tokens": ["Da\u00df", "sol\u00b7che", "Tha\u00b7ten", "un\u00b7recht", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sogar der Hund, der oftmals fehlet,", "tokens": ["So\u00b7gar", "der", "Hund", ",", "der", "oft\u00b7mals", "feh\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hat Anspruch, da\u00df man ihn nicht qu\u00e4let.", "tokens": ["Hat", "An\u00b7spruch", ",", "da\u00df", "man", "ihn", "nicht", "qu\u00e4\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "KOUS", "PIS", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nach seinem frommen Ebenbilde", "tokens": ["Nach", "sei\u00b7nem", "from\u00b7men", "E\u00b7ben\u00b7bil\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schuf Gott den Menschen, das bedenkt!", "tokens": ["Schuf", "Gott", "den", "Men\u00b7schen", ",", "das", "be\u00b7denkt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ART", "NN", "$,", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O lern't von seiner Vatermilde,", "tokens": ["O", "lern't", "von", "sei\u00b7ner", "Va\u00b7ter\u00b7mil\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auch er hat Mitleid uns geschenkt;", "tokens": ["Auch", "er", "hat", "Mit\u00b7leid", "uns", "ge\u00b7schenkt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und z\u00fcchtiget mit Ruthenhieben", "tokens": ["Und", "z\u00fcch\u00b7ti\u00b7get", "mit", "Ru\u00b7then\u00b7hie\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}}}}