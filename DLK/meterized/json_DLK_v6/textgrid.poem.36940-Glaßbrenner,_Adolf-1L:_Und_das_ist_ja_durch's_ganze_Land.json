{"textgrid.poem.36940": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und das ist ja durch's ganze Land", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und das ist ja durch's ganze Land", "tokens": ["Und", "das", "ist", "ja", "durch's", "gan\u00b7ze", "Land"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beim Buben und der Maid bekannt,", "tokens": ["Beim", "Bu\u00b7ben", "und", "der", "Maid", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df, wenn ein Stern vom Himmel f\u00e4hrt,", "tokens": ["Da\u00df", ",", "wenn", "ein", "Stern", "vom", "Him\u00b7mel", "f\u00e4hrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was schnell man w\u00fcnschte, wird erh\u00f6rt.", "tokens": ["Was", "schnell", "man", "w\u00fcnschte", ",", "wird", "er\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PIS", "VVFIN", "$,", "VAFIN", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Da w\u00fcnscht sich nun beim Sternenglanz:", "tokens": ["Da", "w\u00fcnscht", "sich", "nun", "beim", "Ster\u00b7nen\u00b7glanz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Gretchen bald den Myrthenkranz;", "tokens": ["Das", "Gret\u00b7chen", "bald", "den", "Myr\u00b7then\u00b7kranz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kaum ist der junge Tag heran,", "tokens": ["Kaum", "ist", "der", "jun\u00b7ge", "Tag", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da h\u00e4lt ihr Liebster um sie an!", "tokens": ["Da", "h\u00e4lt", "ihr", "Liebs\u00b7ter", "um", "sie", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Eine w\u00fcnscht sich Glanz und Pracht", "tokens": ["Der", "Ei\u00b7ne", "w\u00fcnscht", "sich", "Glanz", "und", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PRF", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der And're eine s\u00fc\u00dfe Nacht,", "tokens": ["Der", "An\u00b7d'\u00b7re", "ei\u00b7ne", "s\u00fc\u00b7\u00dfe", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Der Dritte w\u00fcnscht sich Dies und Das,", "tokens": ["Der", "Drit\u00b7te", "w\u00fcnscht", "sich", "Dies", "und", "Das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PDS", "KON", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Allen wurd's erf\u00fcllet ba\u00df.", "tokens": ["Und", "Al\u00b7len", "wurd's", "er\u00b7f\u00fcl\u00b7let", "ba\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nur der dies Liedel hat erdacht,", "tokens": ["Nur", "der", "dies", "Lie\u00b7del", "hat", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PDS", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem hat es nicht so gut gemacht;", "tokens": ["Dem", "hat", "es", "nicht", "so", "gut", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PTKNEG", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dem wurde bis auf diese Stund,", "tokens": ["Dem", "wur\u00b7de", "bis", "auf", "die\u00b7se", "Stund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Noch keinerlei Erh\u00f6rung kund.", "tokens": ["Noch", "kei\u00b7ner\u00b7lei", "Er\u00b7h\u00f6\u00b7rung", "kund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Denn j\u00fcngst zur Nacht da schneuzt es sehr,", "tokens": ["Denn", "j\u00fcngst", "zur", "Nacht", "da", "schneuzt", "es", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Sterne flogen hin und her!", "tokens": ["Die", "Ster\u00b7ne", "flo\u00b7gen", "hin", "und", "her", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da rief er: Deutschland, schneuze dich", "tokens": ["Da", "rief", "er", ":", "Deutschland", ",", "schneu\u00b7ze", "dich"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NE", "$,", "VVFIN", "PPER"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auch du ein Mal recht ordentlich!", "tokens": ["Auch", "du", "ein", "Mal", "recht", "or\u00b7dent\u00b7lich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}