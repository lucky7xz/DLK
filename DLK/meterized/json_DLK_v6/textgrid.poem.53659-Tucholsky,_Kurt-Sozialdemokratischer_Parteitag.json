{"textgrid.poem.53659": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Sozialdemokratischer Parteitag", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir sa\u00dfen einst im Zuchthaus und in Ketten,", "tokens": ["Wir", "sa\u00b7\u00dfen", "einst", "im", "Zucht\u00b7haus", "und", "in", "Ket\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wir opferten, um die Partei zu retten,", "tokens": ["wir", "op\u00b7fer\u00b7ten", ",", "um", "die", "Par\u00b7tei", "zu", "ret\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUI", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geld, Freiheit, Stellung und Bequemlichkeit.", "tokens": ["Geld", ",", "Frei\u00b7heit", ",", "Stel\u00b7lung", "und", "Be\u00b7quem\u00b7lich\u00b7keit", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir waren die Gefahr der Eisenwerke,", "tokens": ["Wir", "wa\u00b7ren", "die", "Ge\u00b7fahr", "der", "Ei\u00b7sen\u00b7wer\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wir hatten Glut im Herzen \u2013 unsre St\u00e4rke", "tokens": ["wir", "hat\u00b7ten", "Glut", "im", "Her\u00b7zen", "\u2013", "uns\u00b7re", "St\u00e4r\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN", "$(", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "war unsre Sehnsucht, rein und erdenweit.", "tokens": ["war", "uns\u00b7re", "Sehn\u00b7sucht", ",", "rein", "und", "er\u00b7den\u00b7weit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Uns ha\u00dften Kaiser, Landrat und die Richter:", "tokens": ["Uns", "ha\u00df\u00b7ten", "Kai\u00b7ser", ",", "Land\u00b7rat", "und", "die", "Rich\u00b7ter", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Idee wird Macht \u2013 das f\u00fchlte das Gelichter . . .", "tokens": ["I\u00b7dee", "wird", "Macht", "\u2013", "das", "f\u00fchl\u00b7te", "das", "Ge\u00b7lich\u00b7ter", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "VAFIN", "NN", "$(", "PDS", "VVFIN", "ART", "NN", "$.", "$.", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "Long long ago \u2013", "tokens": ["Long", "long", "a\u00b7go", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Das ist nun heute alles nicht mehr so.", "tokens": ["Das", "ist", "nun", "heu\u00b7te", "al\u00b7les", "nicht", "mehr", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PIS", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wir sehn blasiert auf den Ideennebel.", "tokens": ["Wir", "sehn", "bla\u00b7siert", "auf", "den", "I\u00b7deen\u00b7ne\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Wir husten auf den alten, starken Bebel \u2013", "tokens": ["Wir", "hus\u00b7ten", "auf", "den", "al\u00b7ten", ",", "star\u00b7ken", "Be\u00b7bel", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wir schmunzeln, wenn die Jugend revoltiert.", "tokens": ["Wir", "schmun\u00b7zeln", ",", "wenn", "die", "Ju\u00b7gend", "re\u00b7vol\u00b7tiert", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und w\u00e4hrend man in hundert Konventikeln", "tokens": ["Und", "w\u00e4h\u00b7rend", "man", "in", "hun\u00b7dert", "Kon\u00b7ven\u00b7ti\u00b7keln"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PIS", "APPR", "CARD", "NN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "mit Lohnsatz uns bek\u00e4mpft und Leitartikeln,", "tokens": ["mit", "Lohn\u00b7satz", "uns", "be\u00b7k\u00e4mpft", "und", "Leit\u00b7ar\u00b7ti\u00b7keln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "sind wir realpolitisch orientiert.", "tokens": ["sind", "wir", "re\u00b7al\u00b7po\u00b7li\u00b7tisch", "o\u00b7rien\u00b7tiert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ein Klassenkampf ist gut f\u00fcr Bolschewisten.", "tokens": ["Ein", "Klas\u00b7sen\u00b7kampf", "ist", "gut", "f\u00fcr", "Bol\u00b7sche\u00b7wis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "NE", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Einst pfiffen wir auf die Ministerlisten . . .", "tokens": ["Einst", "pfif\u00b7fen", "wir", "auf", "die", "Mi\u00b7nis\u00b7ter\u00b7lis\u00b7ten", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$.", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Long long ago \u2013", "tokens": ["Long", "long", "a\u00b7go", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$("], "meter": "+--+", "measure": "iambic.di.chol"}, "line.10": {"text": "Das ist nun heute alles nicht mehr so.", "tokens": ["Das", "ist", "nun", "heu\u00b7te", "al\u00b7les", "nicht", "mehr", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "PIS", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Uns imponieren schrecklich die enormen", "tokens": ["Uns", "im\u00b7po\u00b7nie\u00b7ren", "schreck\u00b7lich", "die", "en\u00b7or\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zigarren, Autos und die Umgangsformen \u2013", "tokens": ["Zi\u00b7gar\u00b7ren", ",", "Au\u00b7tos", "und", "die", "Um\u00b7gangs\u00b7for\u00b7men", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Man ist ja schlie\u00dflich doch kein Bolschewist.", "tokens": ["Man", "ist", "ja", "schlie\u00df\u00b7lich", "doch", "kein", "Bol\u00b7sche\u00b7wist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir geben uns auch ohne jede Freite.", "tokens": ["Wir", "ge\u00b7ben", "uns", "auch", "oh\u00b7ne", "je\u00b7de", "Frei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und unser Scheidemann hat keine Seite,", "tokens": ["Und", "un\u00b7ser", "Schei\u00b7de\u00b7mann", "hat", "kei\u00b7ne", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "nach der er nicht schon umgefallen ist.", "tokens": ["nach", "der", "er", "nicht", "schon", "um\u00b7ge\u00b7fal\u00b7len", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PTKNEG", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Herr Weismann grinst, und alle Englein lachen.", "tokens": ["Herr", "Weis\u00b7mann", "grinst", ",", "und", "al\u00b7le", "En\u00b7glein", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "$,", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wir sehen nicht, was sie da mit uns machen,", "tokens": ["Wir", "se\u00b7hen", "nicht", ",", "was", "sie", "da", "mit", "uns", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "PPER", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "nicht die Gefahren all . . .", "tokens": ["nicht", "die", "Ge\u00b7fah\u00b7ren", "all", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKNEG", "ART", "NN", "PIAT", "$.", "$.", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.10": {"text": "Skatbr\u00fcder sind wir, die den Marx gelesen.", "tokens": ["Skat\u00b7br\u00fc\u00b7der", "sind", "wir", ",", "die", "den", "Marx", "ge\u00b7le\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PRELS", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Wir sind noch nie so weit entfernt gewesen,", "tokens": ["Wir", "sind", "noch", "nie", "so", "weit", "ent\u00b7fernt", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "von jener Bahn, die uns gef\u00fchrt Lassall'!", "tokens": ["von", "je\u00b7ner", "Bahn", ",", "die", "uns", "ge\u00b7f\u00fchrt", "Las\u00b7sall'", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PPER", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}