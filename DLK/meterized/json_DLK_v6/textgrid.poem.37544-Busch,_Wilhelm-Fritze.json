{"textgrid.poem.37544": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "Fritze", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fritze war ein Ladenj\u00fcngling,", "tokens": ["Frit\u00b7ze", "war", "ein", "La\u00b7den\u00b7j\u00fcng\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dazu braver Eltern Sohn,", "tokens": ["Da\u00b7zu", "bra\u00b7ver", "El\u00b7tern", "Sohn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "NN", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Und er stand bei Kaufmann Kunze", "tokens": ["Und", "er", "stand", "bei", "Kauf\u00b7mann", "Kun\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon ein Jahr in Konditschon.", "tokens": ["Schon", "ein", "Jahr", "in", "Kon\u00b7ditsc\u00b7hon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbfritze\u00ab, sagte einstens Kunze,", "tokens": ["\u00bb", "frit\u00b7ze", "\u00ab", ",", "sag\u00b7te", "eins\u00b7tens", "Kun\u00b7ze", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$(", "$,", "VVFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbich mu\u00df eben mal wohin;", "tokens": ["\u00bb", "ich", "mu\u00df", "e\u00b7ben", "mal", "wo\u00b7hin", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "ADV", "PWAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mache keine dummen Streiche,", "tokens": ["Ma\u00b7che", "kei\u00b7ne", "dum\u00b7men", "Strei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn ich nicht zugegen bin.\u00ab", "tokens": ["Wenn", "ich", "nicht", "zu\u00b7ge\u00b7gen", "bin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "VAFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Hiermit geht er aus der T\u00fcre.", "tokens": ["Hier\u00b7mit", "geht", "er", "aus", "der", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fritze h\u00e4lt das f\u00fcr ein Gl\u00fcck.", "tokens": ["Frit\u00b7ze", "h\u00e4lt", "das", "f\u00fcr", "ein", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PDS", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Er ergreift die K\u00fcmmelflasche", "tokens": ["Er", "er\u00b7greift", "die", "K\u00fcm\u00b7mel\u00b7fla\u00b7sche"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und dann beugt er sich zur\u00fcck.", "tokens": ["Und", "dann", "beugt", "er", "sich", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Sieh, da naht die alte Grete,", "tokens": ["Sieh", ",", "da", "naht", "die", "al\u00b7te", "Gre\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "ART", "ADJA", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Jungfer ernst und still;", "tokens": ["Ei\u00b7ne", "Jung\u00b7fer", "ernst", "und", "still", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie verlangt nach gr\u00fcner Seife,", "tokens": ["Sie", "ver\u00b7langt", "nach", "gr\u00fc\u00b7ner", "Sei\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil sie morgen waschen will.", "tokens": ["Weil", "sie", "mor\u00b7gen", "wa\u00b7schen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Auch erhub sie eine Klage,", "tokens": ["Auch", "er\u00b7hub", "sie", "ei\u00b7ne", "Kla\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie's so im Leibe hat,", "tokens": ["Da\u00df", "sie's", "so", "im", "Lei\u00b7be", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Weshalb sie vor allen Dingen", "tokens": ["We\u00b7shalb", "sie", "vor", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Erst um einen K\u00fcmmel bat.", "tokens": ["Erst", "um", "ei\u00b7nen", "K\u00fcm\u00b7mel", "bat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Fritze zeigt sich dienstbeflissen.", "tokens": ["Frit\u00b7ze", "zeigt", "sich", "dienst\u00b7be\u00b7flis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "PDAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ihm ist recht konfus und wohl.", "tokens": ["Ihm", "ist", "recht", "kon\u00b7fus", "und", "wohl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "ADJA", "KON", "ADV", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.3": {"text": "Statt der gro\u00dfen K\u00fcmmelflasche", "tokens": ["Statt", "der", "gro\u00b7\u00dfen", "K\u00fcm\u00b7mel\u00b7fla\u00b7sche"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nimmt er die mit Vitriol.", "tokens": ["Nimmt", "er", "die", "mit", "Vi\u00b7tri\u00b7ol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "APPR", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Jungfer Grete, voller Freuden,", "tokens": ["Jung\u00b7fer", "Gre\u00b7te", ",", "vol\u00b7ler", "Freu\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Greift begierig nach dem Glas;", "tokens": ["Greift", "be\u00b7gie\u00b7rig", "nach", "dem", "Glas", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fritz, der gr\u00fcnen Seife wegen,", "tokens": ["Fritz", ",", "der", "gr\u00fc\u00b7nen", "Sei\u00b7fe", "we\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "APPR", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Beugt sich \u00fcbers Seifenfa\u00df.", "tokens": ["Beugt", "sich", "\u00fc\u00b7bers", "Sei\u00b7fen\u00b7fa\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Weh, was mu\u00df man nun erblicken?", "tokens": ["Weh", ",", "was", "mu\u00df", "man", "nun", "er\u00b7bli\u00b7cken", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo ist Fritzens Gleichgewicht?", "tokens": ["Wo", "ist", "Frit\u00b7zens", "Gleich\u00b7ge\u00b7wicht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was sind dies f\u00fcr Angstgeb\u00e4rden", "tokens": ["Was", "sind", "dies", "f\u00fcr", "Angst\u00b7ge\u00b7b\u00e4r\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hier auf Gretens Angesicht?", "tokens": ["Hier", "auf", "Gre\u00b7tens", "An\u00b7ge\u00b7sicht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Fritze strampelt mit den Beinen,", "tokens": ["Frit\u00b7ze", "stram\u00b7pelt", "mit", "den", "Bei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch die Seife wird sein Grab;", "tokens": ["Doch", "die", "Sei\u00b7fe", "wird", "sein", "Grab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Greten nagt die scharfe S\u00e4ure", "tokens": ["Gre\u00b7ten", "nagt", "die", "schar\u00b7fe", "S\u00e4u\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihre M\u00e4dchenseele ab.", "tokens": ["Ih\u00b7re", "M\u00e4d\u00b7chen\u00b7see\u00b7le", "ab", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "K\u00fcmmel zieret keinen J\u00fcngling,", "tokens": ["K\u00fcm\u00b7mel", "zie\u00b7ret", "kei\u00b7nen", "J\u00fcng\u00b7ling", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dazu ist er noch zu klein;", "tokens": ["Da\u00b7zu", "ist", "er", "noch", "zu", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ein braves altes M\u00e4dchen", "tokens": ["Und", "ein", "bra\u00b7ves", "al\u00b7tes", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Mu\u00df nicht mehr so happig sein.", "tokens": ["Mu\u00df", "nicht", "mehr", "so", "hap\u00b7pig", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ADV", "ADV", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}