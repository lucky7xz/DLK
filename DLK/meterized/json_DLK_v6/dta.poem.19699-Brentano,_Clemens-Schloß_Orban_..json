{"dta.poem.19699": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Schlo\u00df Orban .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.85", "en:0.14"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Winter wollte lang bey uns seyn,               ", "tokens": ["Der", "Win\u00b7ter", "woll\u00b7te", "lang", "bey", "uns", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADJD", "APPR", "PPER", "VAINF", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Des trauerte manches V\u00f6gelein,", "tokens": ["Des", "trau\u00b7er\u00b7te", "man\u00b7ches", "V\u00f6\u00b7ge\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das jezt gar fr\u00f6hlig singet,", "tokens": ["Das", "jezt", "gar", "fr\u00f6h\u00b7lig", "sin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf gr\u00fcnem Zwerg h\u00f6rt mans im Wald", "tokens": ["Auf", "gr\u00fc\u00b7nem", "Zwerg", "h\u00f6rt", "mans", "im", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PIS", "APPRART", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Gar s\u00fcssiglich erklingen.", "tokens": ["Gar", "s\u00fcs\u00b7sig\u00b7lich", "er\u00b7klin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der Zweig hat gebracht gar manches Blat,", "tokens": ["Der", "Zweig", "hat", "ge\u00b7bracht", "gar", "man\u00b7ches", "Blat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Danach man grosses Verlangen hat,", "tokens": ["Da\u00b7nach", "man", "gros\u00b7ses", "Ver\u00b7lan\u00b7gen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIS", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Heid' ist worden gr\u00fcne;", "tokens": ["Die", "Heid'", "ist", "wor\u00b7den", "gr\u00fc\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VAPP", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Darum so ist gezogen aus", "tokens": ["Da\u00b7rum", "so", "ist", "ge\u00b7zo\u00b7gen", "aus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VAFIN", "VVPP", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gar mancher Mann so k\u00fchne.", "tokens": ["Gar", "man\u00b7cher", "Mann", "so", "k\u00fch\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Einer zog auf, der andre ab,", "tokens": ["Ei\u00b7ner", "zog", "auf", ",", "der", "and\u00b7re", "ab", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "$,", "PRELS", "PIS", "PTKVZ", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Das hat genommen gar wilde Hab,", "tokens": ["Das", "hat", "ge\u00b7nom\u00b7men", "gar", "wil\u00b7de", "Hab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Schimpf hat sich gemachet,", "tokens": ["Der", "Schimpf", "hat", "sich", "ge\u00b7ma\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Des hat der Herzog von Burgund", "tokens": ["Des", "hat", "der", "Her\u00b7zog", "von", "Bur\u00b7gund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NE"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Gar wenig mehr gelachet.", "tokens": ["Gar", "we\u00b7nig", "mehr", "ge\u00b7la\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Man ist gezogen in sein Land,", "tokens": ["Man", "ist", "ge\u00b7zo\u00b7gen", "in", "sein", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Stadt ist Ponterlin genannt,", "tokens": ["Ein", "Stadt", "ist", "Pon\u00b7ter\u00b7lin", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da ist der Reigen anfangen,", "tokens": ["Da", "ist", "der", "Rei\u00b7gen", "an\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Darin so sieht man Wittwen viel", "tokens": ["Da\u00b7rin", "so", "sieht", "man", "Witt\u00b7wen", "viel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ADV", "VVFIN", "PIS", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gar trauriglichen prangen.", "tokens": ["Gar", "trau\u00b7rig\u00b7li\u00b7chen", "pran\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der B\u00e4r eilt ihnen nach mit der Fahn,", "tokens": ["Der", "B\u00e4r", "eilt", "ih\u00b7nen", "nach", "mit", "der", "Fahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Er brannt, als er vormals gethan,", "tokens": ["Er", "brannt", ",", "als", "er", "vor\u00b7mals", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Den Welschen da zum Leide,", "tokens": ["Den", "Wel\u00b7schen", "da", "zum", "Lei\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da er das Dorf gez\u00fcndet an,", "tokens": ["Da", "er", "das", "Dorf", "ge\u00b7z\u00fcn\u00b7det", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da zog er auf weite Heide.", "tokens": ["Da", "zog", "er", "auf", "wei\u00b7te", "Hei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Da nun der Zug gen Orban kam,", "tokens": ["Da", "nun", "der", "Zug", "gen", "Or\u00b7ban", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da brannt die Stadt in Feuers Flamm,", "tokens": ["Da", "brannt", "die", "Stadt", "in", "Feu\u00b7ers", "Flamm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wann sie sich h\u00e4tten ergeben", "tokens": ["Wann", "sie", "sich", "h\u00e4t\u00b7ten", "er\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "VAFIN", "VVPP"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "An die frommen Herren von Bern!", "tokens": ["An", "die", "from\u00b7men", "Her\u00b7ren", "von", "Bern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Das war dem Schlo\u00df nicht eben.", "tokens": ["Das", "war", "dem", "Schlo\u00df", "nicht", "e\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Darum sie es gez\u00fcndet an,", "tokens": ["Da\u00b7rum", "sie", "es", "ge\u00b7z\u00fcn\u00b7det", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PPER", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das hat entgolten mancher Mann,", "tokens": ["Das", "hat", "ent\u00b7gol\u00b7ten", "man\u00b7cher", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der in das Schlo\u00df ist kommen,", "tokens": ["Der", "in", "das", "Schlo\u00df", "ist", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Eidgenossen in der Stadt", "tokens": ["Die", "Eid\u00b7ge\u00b7nos\u00b7sen", "in", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie l\u00f6schten das Feuer zum Frommen.", "tokens": ["Sie", "l\u00f6schten", "das", "Feu\u00b7er", "zum", "From\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Gesellen nahmen den Kirchthurm ein,", "tokens": ["Ge\u00b7sel\u00b7len", "nah\u00b7men", "den", "Kirch\u00b7thurm", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und schossen zu den Welschen herein,", "tokens": ["Und", "schos\u00b7sen", "zu", "den", "Wel\u00b7schen", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Da\u00df es so laut erkrachet,", "tokens": ["Da\u00df", "es", "so", "laut", "er\u00b7kra\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wiewohl es war ein grosser Ernst", "tokens": ["Wie\u00b7wohl", "es", "war", "ein", "gros\u00b7ser", "Ernst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des Schiessens mancher lachet.", "tokens": ["Des", "Schies\u00b7sens", "man\u00b7cher", "la\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "In dem da st\u00fcrmt man an das Schlo\u00df,", "tokens": ["In", "dem", "da", "st\u00fcrmt", "man", "an", "das", "Schlo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man achtet gar kein Wurfgescho\u00df,", "tokens": ["Man", "ach\u00b7tet", "gar", "kein", "Wurf\u00b7ge\u00b7scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie hauen ein Loch in die Mauren,", "tokens": ["Sie", "hau\u00b7en", "ein", "Loch", "in", "die", "Mau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Dadurch schl\u00fcpft mancher k\u00fchne Mann,", "tokens": ["Da\u00b7durch", "schl\u00fcpft", "man\u00b7cher", "k\u00fch\u00b7ne", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um sich hat er kein Trauren.", "tokens": ["Um", "sich", "hat", "er", "kein", "Trau\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Die von Bern st\u00fcrmten vorne dran", "tokens": ["Die", "von", "Bern", "st\u00fcrm\u00b7ten", "vor\u00b7ne", "dran"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NE", "VVFIN", "ADV", "PAV"], "meter": "-+++-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und die von Basel hinten an,", "tokens": ["Und", "die", "von", "Ba\u00b7sel", "hin\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie kamen darin mit Genossen,", "tokens": ["Sie", "ka\u00b7men", "da\u00b7rin", "mit", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Das F\u00e4hnlein von Luzern, wei\u00df und blau,", "tokens": ["Das", "F\u00e4hn\u00b7lein", "von", "Lu\u00b7zern", ",", "wei\u00df", "und", "blau", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sah man gar bald im Schlosse.", "tokens": ["Sah", "man", "gar", "bald", "im", "Schlos\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Da nun die Welschen sahen klar,", "tokens": ["Da", "nun", "die", "Wel\u00b7schen", "sa\u00b7hen", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie schnell das Schlo\u00df erstiegen war,", "tokens": ["Wie", "schnell", "das", "Schlo\u00df", "er\u00b7stie\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie warfen ab die Wehrn,", "tokens": ["Sie", "war\u00b7fen", "ab", "die", "Wehrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und baten, da\u00df man auf sollt nehmen,", "tokens": ["Und", "ba\u00b7ten", ",", "da\u00df", "man", "auf", "sollt", "neh\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "APPR", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch Gott und unser Frauen Ehrn.", "tokens": ["Durch", "Gott", "und", "un\u00b7ser", "Frau\u00b7en", "Ehrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "H\u00e4tten sie das beyzeit gethan,", "tokens": ["H\u00e4t\u00b7ten", "sie", "das", "bey\u00b7zeit", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Man h\u00e4tt sie allesamt leben gelahn,", "tokens": ["Man", "h\u00e4tt", "sie", "al\u00b7le\u00b7samt", "le\u00b7ben", "ge\u00b7lahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADJD", "VVINF", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Jezt wollt man sie nicht ehren;", "tokens": ["Jezt", "wollt", "man", "sie", "nicht", "eh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da nun die Welschen sehen das,", "tokens": ["Da", "nun", "die", "Wel\u00b7schen", "se\u00b7hen", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "PDS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Begannen sie sich zu wehren.", "tokens": ["Be\u00b7gan\u00b7nen", "sie", "sich", "zu", "weh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Sie hatten ein Thurm eingenomm'n,", "tokens": ["Sie", "hat\u00b7ten", "ein", "Thurm", "ein\u00b7ge\u00b7nom\u00b7m'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Da konnt man lang nicht zu ihn komm'n", "tokens": ["Da", "konnt", "man", "lang", "nicht", "zu", "ihn", "kom\u00b7m'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADJD", "PTKNEG", "APPR", "PPER", "VVINF"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da waren viele innen,", "tokens": ["Da", "wa\u00b7ren", "vie\u00b7le", "in\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie wehrten sich gar lange Zeit,", "tokens": ["Sie", "wehr\u00b7ten", "sich", "gar", "lan\u00b7ge", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und mocht ihr keiner entrinnen.", "tokens": ["Und", "mocht", "ihr", "kei\u00b7ner", "ent\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PIS", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Da f\u00fcgt sich das man zu ihn kam,", "tokens": ["Da", "f\u00fcgt", "sich", "das", "man", "zu", "ihn", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Inwendig im Thurm man aufhin klam,", "tokens": ["In\u00b7wen\u00b7dig", "im", "Thurm", "man", "auf\u00b7hin", "klam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "PIS", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Viel h\u00f6her als sie waren,", "tokens": ["Viel", "h\u00f6\u00b7her", "als", "sie", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Man warf ihr eben viel zu todt,", "tokens": ["Man", "warf", "ihr", "e\u00b7ben", "viel", "zu", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und traf sie \u00fcber den Ohren.", "tokens": ["Und", "traf", "sie", "\u00fc\u00b7ber", "den", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Es gesah nie kein'm Mann gr\u00f6sser Noth,", "tokens": ["Es", "ge\u00b7sah", "nie", "kein'm", "Mann", "gr\u00f6s\u00b7ser", "Noth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man warf sie lebendig und todt,", "tokens": ["Man", "warf", "sie", "le\u00b7ben\u00b7dig", "und", "todt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Allsamt \u00fcber die Zinnen,", "tokens": ["A\u00b7llsamt", "\u00fc\u00b7ber", "die", "Zin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Das Schlo\u00df Orban man also th\u00e4t", "tokens": ["Das", "Schlo\u00df", "Or\u00b7ban", "man", "al\u00b7so", "th\u00e4t"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "PIS", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Welschen abgewinnen.", "tokens": ["Den", "Wel\u00b7schen", "ab\u00b7ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Darin waren mehr denn hundert Mann,", "tokens": ["Da\u00b7rin", "wa\u00b7ren", "mehr", "denn", "hun\u00b7dert", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Die all ihr Leben musten lahn,", "tokens": ["Die", "all", "ihr", "Le\u00b7ben", "mus\u00b7ten", "lahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Darin will ich nicht l\u00fcgen,", "tokens": ["Da\u00b7rin", "will", "ich", "nicht", "l\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Man lehrt sie \u00fcber die Mauer all", "tokens": ["Man", "lehrt", "sie", "\u00fc\u00b7ber", "die", "Mau\u00b7er", "all"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "NN", "PIAT"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ohn alles Gefieder fliegen.", "tokens": ["Ohn", "al\u00b7les", "Ge\u00b7fie\u00b7der", "flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Noch ist ein stark Schlo\u00df Jungi genannt,", "tokens": ["Noch", "ist", "ein", "stark", "Schlo\u00df", "Jun\u00b7gi", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJD", "NN", "NE", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem ward es auch gar bald bekannt,", "tokens": ["Dem", "ward", "es", "auch", "gar", "bald", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie es zu Orban ergangen,", "tokens": ["Wie", "es", "zu", "Or\u00b7ban", "er\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da waren viel der Welschen auf,", "tokens": ["Da", "wa\u00b7ren", "viel", "der", "Wel\u00b7schen", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Herab hatten sie Verlangen.", "tokens": ["Her\u00b7ab", "hat\u00b7ten", "sie", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Man zog gen Jungi in die Stadt,", "tokens": ["Man", "zog", "gen", "Jun\u00b7gi", "in", "die", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NE", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dem Schlo\u00df man gro\u00df Verlangen hat;", "tokens": ["Nach", "dem", "Schlo\u00df", "man", "gro\u00df", "Ver\u00b7lan\u00b7gen", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PIS", "ADJD", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Da man kam dargeschlichen,", "tokens": ["Da", "man", "kam", "dar\u00b7ge\u00b7schli\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "PAV", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Da waren die Welschen alle daraus", "tokens": ["Da", "wa\u00b7ren", "die", "Wel\u00b7schen", "al\u00b7le", "da\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "PIS", "PAV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "In welsche Land gewichen.", "tokens": ["In", "wel\u00b7sche", "Land", "ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Der B\u00e4r war gelaufen aus dem H\u00f6hl,", "tokens": ["Der", "B\u00e4r", "war", "ge\u00b7lau\u00b7fen", "aus", "dem", "H\u00f6hl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es ist ihm ergangen also wehl,", "tokens": ["Es", "ist", "ihm", "er\u00b7gan\u00b7gen", "al\u00b7so", "wehl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wieder heim ist er gesprungen,", "tokens": ["Wie\u00b7der", "heim", "ist", "er", "ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "VAFIN", "PPER", "VVPP", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Gott geb ihm f\u00fcrbas Gl\u00fcck und Heil,", "tokens": ["Gott", "geb", "ihm", "f\u00fcr\u00b7bas", "Gl\u00fcck", "und", "Heil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hat uns Veit Weber gesungen.", "tokens": ["Hat", "uns", "Veit", "We\u00b7ber", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "NE", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}