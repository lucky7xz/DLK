{"textgrid.poem.46298": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nein, es ist nicht mehr not, sich ab dem gro\u00dfen pracht", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nein, es ist nicht mehr not, sich ab dem gro\u00dfen pracht", "tokens": ["Nein", ",", "es", "ist", "nicht", "mehr", "not", ",", "sich", "ab", "dem", "gro\u00b7\u00dfen", "pracht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "$,", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "des r\u00f6mischen triumfs stets also zu entsetzen:", "tokens": ["des", "r\u00f6\u00b7mi\u00b7schen", "tri\u00b7umfs", "stets", "al\u00b7so", "zu", "ent\u00b7set\u00b7zen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Teutschland hat wol numehr dergleichen f\u00fcrgebracht,", "tokens": ["Teutschland", "hat", "wol", "nu\u00b7mehr", "derg\u00b7lei\u00b7chen", "f\u00fcr\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "da\u00df man damit gnug kan gesicht und seel ergetzen.", "tokens": ["da\u00df", "man", "da\u00b7mit", "gnug", "kan", "ge\u00b7sicht", "und", "seel", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PAV", "ADV", "VMFIN", "VVPP", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nein, es ist nicht mehr not, mit welschvermischter sprach", "tokens": ["Nein", ",", "es", "ist", "nicht", "mehr", "not", ",", "mit", "welschver\u00b7mischter", "sprach"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "$,", "APPR", "NN", "VVFIN"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.2": {"text": "ausl\u00e4ndische woll\u00fcst und freuden zu erz\u00e4hlen;", "tokens": ["aus\u00b7l\u00e4n\u00b7di\u00b7sche", "wol\u00b7l\u00fcst", "und", "freu\u00b7den", "zu", "er\u00b7z\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Teutschland empfacht dardurch weder gesp\u00f6t noch schmach", "tokens": ["Teutschland", "em\u00b7pfacht", "dar\u00b7durch", "we\u00b7der", "ge\u00b7sp\u00f6t", "noch", "schmach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PAV", "KON", "ADJD", "ADV", "VVFIN"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "sondern hat in sich selbs noch freud gnug zu erw\u00e4hlen.", "tokens": ["son\u00b7dern", "hat", "in", "sich", "selbs", "noch", "freud", "gnug", "zu", "er\u00b7w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PRF", "ADV", "ADV", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.3": {"line.1": {"text": "Nein, es ist nicht mehr not, der fremden kunst und witz", "tokens": ["Nein", ",", "es", "ist", "nicht", "mehr", "not", ",", "der", "frem\u00b7den", "kunst", "und", "witz"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "PTKNEG", "PIAT", "NN", "$,", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "erfindungen und spil unnachthunlich zu achten:", "tokens": ["er\u00b7fin\u00b7dun\u00b7gen", "und", "spil", "un\u00b7nach\u00b7thun\u00b7lich", "zu", "ach\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-++-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "dan Teutschland, welches selbs der erfindungen sitz,", "tokens": ["dan", "Teutschland", ",", "wel\u00b7ches", "selbs", "der", "er\u00b7fin\u00b7dun\u00b7gen", "sitz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PRELS", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "erweiset vil mehr kunst den fremden zu betrachten.", "tokens": ["er\u00b7wei\u00b7set", "vil", "mehr", "kunst", "den", "frem\u00b7den", "zu", "be\u00b7trach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "NN", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Eben alhie sah man die prinzen mit wolstand", "tokens": ["E\u00b7ben", "al\u00b7hie", "sah", "man", "die", "prin\u00b7zen", "mit", "wol\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "NN"], "meter": "+---+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "verrichten ihre l\u00e4uf wie herschende planeten;", "tokens": ["ver\u00b7rich\u00b7ten", "ih\u00b7re", "l\u00e4uf", "wie", "her\u00b7schen\u00b7de", "pla\u00b7ne\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KOKOM", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "dazu die Nymfen dan durch ihrer augen brand", "tokens": ["da\u00b7zu", "die", "Nym\u00b7fen", "dan", "durch", "ih\u00b7rer", "au\u00b7gen", "brand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "mit s\u00fc\u00dfer influenz leuchteten wie kometen.", "tokens": ["mit", "s\u00fc\u00b7\u00dfer", "in\u00b7flu\u00b7enz", "leuch\u00b7te\u00b7ten", "wie", "ko\u00b7me\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "KOKOM", "VVFIN", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Got, der der geber ist unsers und alles guts,", "tokens": ["Got", ",", "der", "der", "ge\u00b7ber", "ist", "un\u00b7sers", "und", "al\u00b7les", "guts", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ART", "NN", "VAFIN", "ADV", "KON", "PIAT", "NN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.2": {"text": "geb, da\u00df die Teutsche auch (folgend ihren vorfahren)", "tokens": ["geb", ",", "da\u00df", "die", "Teut\u00b7sche", "auch", "(", "fol\u00b7gend", "ih\u00b7ren", "vor\u00b7fah\u00b7ren", ")"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "ADV", "$(", "ADJD", "PPOSAT", "VVINF", "$("], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "wie freigebig sie seind ihrer reichtum und bluts,", "tokens": ["wie", "frei\u00b7ge\u00b7big", "sie", "seind", "ih\u00b7rer", "reich\u00b7tum", "und", "bluts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VAFIN", "PPOSAT", "FM", "KON", "NN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "begirig bleiben, sein und ihr ehr zu bewahren.", "tokens": ["be\u00b7gi\u00b7rig", "blei\u00b7ben", ",", "sein", "und", "ihr", "ehr", "zu", "be\u00b7wah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,", "VAINF", "KON", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}}}}}