{"textgrid.poem.40798": {"metadata": {"author": {"name": "Gr\u00fcn, Anastasius", "birth": "N.A.", "death": "N.A."}, "title": "1L: Fr\u00fchlingsluft weht allbelebend!", "genre": "verse", "period": "N.A.", "pub_year": 1842, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Fr\u00fchlingsluft weht allbelebend!", "tokens": ["Fr\u00fch\u00b7lings\u00b7luft", "weht", "all\u00b7be\u00b7le\u00b7bend", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fchlingsschwalb' ist heimgereist,", "tokens": ["Fr\u00fch\u00b7lings\u00b7schwalb'", "ist", "heim\u00b7ge\u00b7reist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat, ob Wiens Pal\u00e4sten schwebend,", "tokens": ["Hat", ",", "ob", "Wiens", "Pa\u00b7l\u00e4s\u00b7ten", "schwe\u00b7bend", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "NE", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon die Kaiserburg umkreist;", "tokens": ["Schon", "die", "Kai\u00b7ser\u00b7burg", "um\u00b7kreist", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Pickt die Spiegelscheibe leise,", "tokens": ["Pickt", "die", "Spie\u00b7gel\u00b7schei\u00b7be", "lei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da sie einmal schon gepickt,", "tokens": ["Da", "sie", "ein\u00b7mal", "schon", "ge\u00b7pickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Draus der Kaiser sonst, der greise,", "tokens": ["Draus", "der", "Kai\u00b7ser", "sonst", ",", "der", "grei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "$,", "PRELS", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf sein Volk und sie geblickt.", "tokens": ["Auf", "sein", "Volk", "und", "sie", "ge\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch sie sieht die\u00df Antlitz nimmer", "tokens": ["Doch", "sie", "sieht", "die\u00df", "Ant\u00b7litz", "nim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PDS", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit des Munds schalkhaftem Scherz,", "tokens": ["Mit", "des", "Munds", "schalk\u00b7haf\u00b7tem", "Scherz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit des Augs gutm\u00fcth'gem Schimmer, \u2013", "tokens": ["Mit", "des", "Augs", "gut\u00b7m\u00fcth'\u00b7gem", "Schim\u00b7mer", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oft doch hart und kalt wie Erz.", "tokens": ["Oft", "doch", "hart", "und", "kalt", "wie", "Erz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADJD", "KOKOM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Stumm des Jubels Hochgewitter,", "tokens": ["Stumm", "des", "Ju\u00b7bels", "Hoch\u00b7ge\u00b7wit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieses Mannes st\u00e4t Geleit!", "tokens": ["Die\u00b7ses", "Man\u00b7nes", "st\u00e4t", "Ge\u00b7leit", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stumm doch hinter manchem Gitter", "tokens": ["Stumm", "doch", "hin\u00b7ter", "man\u00b7chem", "Git\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch das Murren b\u00f6ser Zeit!", "tokens": ["Auch", "das", "Mur\u00b7ren", "b\u00f6\u00b7ser", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Fr\u00fchlingsschwalbe sei kein Richter,", "tokens": ["Fr\u00fch\u00b7lings\u00b7schwal\u00b7be", "sei", "kein", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Urthel nicht ihr Fr\u00fchlingsgru\u00df;", "tokens": ["Ur\u00b7thel", "nicht", "ihr", "Fr\u00fch\u00b7lings\u00b7gru\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch sie ist Prophet und Dichter,", "tokens": ["Doch", "sie", "ist", "Pro\u00b7phet", "und", "Dich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der vers\u00f6hnen, warnen mu\u00df.", "tokens": ["Der", "ver\u00b7s\u00f6h\u00b7nen", ",", "war\u00b7nen", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PWAV", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Zu des Grabgew\u00f6lbes Hallen,", "tokens": ["Zu", "des", "Grab\u00b7ge\u00b7w\u00f6l\u00b7bes", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Das des Greises Asche barg,", "tokens": ["Das", "des", "Grei\u00b7ses", "A\u00b7sche", "barg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "L\u00e4\u00dft sie ihre Schwingen wallen,", "tokens": ["L\u00e4\u00dft", "sie", "ih\u00b7re", "Schwin\u00b7gen", "wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu dem ehrnen Kaisersarg.", "tokens": ["Zu", "dem", "ehr\u00b7nen", "Kai\u00b7ser\u00b7sarg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Fr\u00fchlingsgru\u00df will sie ihm bringen;", "tokens": ["Fr\u00fch\u00b7lings\u00b7gru\u00df", "will", "sie", "ihm", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch, gestreift vom Fl\u00fcgelschlag,", "tokens": ["Doch", ",", "ge\u00b7streift", "vom", "Fl\u00fc\u00b7gel\u00b7schlag", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "T\u00f6nt von einem Lenz sein Klingen,", "tokens": ["T\u00f6nt", "von", "ei\u00b7nem", "Lenz", "sein", "Klin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Den sie selbst nur ahnen mag.", "tokens": ["Den", "sie", "selbst", "nur", "ah\u00b7nen", "mag."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ART", "PPER", "ADV", "ADV", "VVINF", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Nicht der Schlaf des Kaisersprossen,", "tokens": ["Nicht", "der", "Schlaf", "des", "Kai\u00b7ser\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6h'res heiligt diesen Raum:", "tokens": ["H\u00f6h'\u00b7res", "hei\u00b7ligt", "die\u00b7sen", "Raum", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In dem Katafalk verschlossen", "tokens": ["In", "dem", "Ka\u00b7ta\u00b7falk", "ver\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ruht der deutschen Einheit Traum.", "tokens": ["Ruht", "der", "deut\u00b7schen", "Ein\u00b7heit", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Denn in dieses Greises Haaren", "tokens": ["Denn", "in", "die\u00b7ses", "Grei\u00b7ses", "Haa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lag zuletzt der Reif von Gold,", "tokens": ["Lag", "zu\u00b7letzt", "der", "Reif", "von", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der die deutschen F\u00fcrstenschaaren", "tokens": ["Der", "die", "deut\u00b7schen", "F\u00fcrs\u00b7ten\u00b7schaa\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In Ein Volk verbr\u00fcdern sollt'.", "tokens": ["In", "Ein", "Volk", "ver\u00b7br\u00fc\u00b7dern", "sollt'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Und in diesem ehrnen Bette", "tokens": ["Und", "in", "die\u00b7sem", "ehr\u00b7nen", "Bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schl\u00e4ft der Mann, de\u00df Herz allein", "tokens": ["Schl\u00e4ft", "der", "Mann", ",", "de\u00df", "Herz", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deutschlands Herz war, oder h\u00e4tte", "tokens": ["Deutschlands", "Herz", "war", ",", "o\u00b7der", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "NN", "VAFIN", "$,", "KON", "VAFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Deutschlands Herz doch sollen sein.", "tokens": ["Deutschlands", "Herz", "doch", "sol\u00b7len", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "O da\u00df bei den Leichenkerzen", "tokens": ["O", "da\u00df", "bei", "den", "Lei\u00b7chen\u00b7ker\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "KOUS", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "F\u00fcrsten all im deutschen Land", "tokens": ["F\u00fcrs\u00b7ten", "all", "im", "deut\u00b7schen", "Land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ueber diesem heil'gen Herzen", "tokens": ["Ue\u00b7ber", "die\u00b7sem", "heil'\u00b7gen", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sich zum Bund gereicht die Hand!", "tokens": ["Sich", "zum", "Bund", "ge\u00b7reicht", "die", "Hand", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "VVPP", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "La\u00dft in diesem Sarg verschlossen", "tokens": ["La\u00dft", "in", "die\u00b7sem", "Sarg", "ver\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "APPR", "PDAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deutscher Einheit alten Traum;", "tokens": ["Deut\u00b7scher", "Ein\u00b7heit", "al\u00b7ten", "Traum", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wahrer Einheit, ihr Genossen,", "tokens": ["Wah\u00b7rer", "Ein\u00b7heit", ",", "ihr", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Breitet sich ein gr\u00f6\u00dfrer Raum!", "tokens": ["Brei\u00b7tet", "sich", "ein", "gr\u00f6\u00df\u00b7rer", "Raum", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Denn als Herold mit dem Stabe,", "tokens": ["Denn", "als", "He\u00b7rold", "mit", "dem", "Sta\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der das Wappenschild zerbrach,", "tokens": ["Der", "das", "Wap\u00b7pen\u00b7schild", "zer\u00b7brach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An des letzten Kaisers Grabe", "tokens": ["An", "des", "letz\u00b7ten", "Kai\u00b7sers", "Gra\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein Jahrtausend stand und sprach:", "tokens": ["Ein", "Jahr\u00b7tau\u00b7send", "stand", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "\u00bblernt, da\u00df euer Heil geschmiedet", "tokens": ["\u00bb", "lernt", ",", "da\u00df", "eu\u00b7er", "Heil", "ge\u00b7schmie\u00b7det"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An ein einzeln Haupt nicht sei!", "tokens": ["An", "ein", "ein\u00b7zeln", "Haupt", "nicht", "sei", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "NN", "PTKNEG", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ihr Schein vom Wesen schiedet,", "tokens": ["Da\u00df", "ihr", "Schein", "vom", "We\u00b7sen", "schie\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Brach ich das Symbol entzwei.", "tokens": ["Brach", "ich", "das", "Sym\u00b7bol", "ent\u00b7zwei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Um des Reichs Kleinode lodre", "tokens": ["Um", "des", "Reichs", "Klein\u00b7o\u00b7de", "lod\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "NN", "VVFIN"], "meter": "+-++--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Nimmer Aachens, N\u00fcrnbergs Zank:", "tokens": ["Nim\u00b7mer", "Aa\u00b7chens", ",", "N\u00fcrn\u00b7bergs", "Zank", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stol' und Gurt im Schreine modre,", "tokens": ["Stol'", "und", "Gurt", "im", "Schrei\u00b7ne", "mod\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Karols Degen rost' im Schrank.", "tokens": ["Ka\u00b7rols", "De\u00b7gen", "rost'", "im", "Schrank", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Denn ein sch\u00f6nres Schwert gezogen", "tokens": ["Denn", "ein", "sch\u00f6n\u00b7res", "Schwert", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat der freien M\u00e4nner Hand;", "tokens": ["Hat", "der", "frei\u00b7en", "M\u00e4n\u00b7ner", "Hand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Aller Schultern soll umwogen", "tokens": ["Al\u00b7ler", "Schul\u00b7tern", "soll", "um\u00b7wo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Deutscher Herrlichkeit Gewand.", "tokens": ["Deut\u00b7scher", "Herr\u00b7lich\u00b7keit", "Ge\u00b7wand", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Euer Hoffen, euer Sehnen", "tokens": ["Eu\u00b7er", "Hof\u00b7fen", ",", "eu\u00b7er", "Seh\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat kein Einzler ganz vollbracht;", "tokens": ["Hat", "kein", "Einz\u00b7ler", "ganz", "voll\u00b7bracht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drum euch All will ich belehnen", "tokens": ["Drum", "euch", "All", "will", "ich", "be\u00b7leh\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PPER", "NN", "VMFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit des Reiches Glanz und Macht.", "tokens": ["Mit", "des", "Rei\u00b7ches", "Glanz", "und", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Denn in allen deutschen Adern", "tokens": ["Denn", "in", "al\u00b7len", "deut\u00b7schen", "A\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Flammt der Purpur, der nie bleicht;", "tokens": ["Flammt", "der", "Pur\u00b7pur", ",", "der", "nie", "bleicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "+-++-++", "measure": "unknown.measure.penta"}, "line.3": {"text": "Eure Herzen sei'n die Quadern", "tokens": ["Eu\u00b7re", "Her\u00b7zen", "sei'n", "die", "Qua\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jenes Baus, de\u00df Grund nicht weicht.", "tokens": ["Je\u00b7nes", "Baus", ",", "de\u00df", "Grund", "nicht", "weicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Und ihr Alle seid berufen", "tokens": ["Und", "ihr", "Al\u00b7le", "seid", "be\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "PIS", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mitzubau'n am gro\u00dfen Bau,", "tokens": ["Mit\u00b7zu\u00b7bau'n", "am", "gro\u00b7\u00dfen", "Bau", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr am Thron, ihr an den Stufen,", "tokens": ["Ihr", "am", "Thron", ",", "ihr", "an", "den", "Stu\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "$,", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ob das R\u00f6cklein wei\u00df, ob blau.", "tokens": ["Ob", "das", "R\u00f6ck\u00b7lein", "wei\u00df", ",", "ob", "blau", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,", "KOUS", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Und ihr Priester, Redner, Lehrer,", "tokens": ["Und", "ihr", "Pries\u00b7ter", ",", "Red\u00b7ner", ",", "Leh\u00b7rer", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Streut die Saat mit kluger Hand,", "tokens": ["Streut", "die", "Saat", "mit", "klu\u00b7ger", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Pflanzt, des Reiches wahre Mehrer,", "tokens": ["Pflanzt", ",", "des", "Rei\u00b7ches", "wah\u00b7re", "Meh\u00b7rer", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lieb' und Recht f\u00fcrs deutsche Land!", "tokens": ["Lieb'", "und", "Recht", "f\u00fcrs", "deut\u00b7sche", "Land", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Da\u00df die Gr\u00f6\u00dfen eurer Helden", "tokens": ["Da\u00df", "die", "Gr\u00f6\u00b7\u00dfen", "eu\u00b7rer", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nie auf deutschen Nacken steh'n,", "tokens": ["Nie", "auf", "deut\u00b7schen", "Na\u00b7cken", "steh'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df von deutscher Schmach nie melden", "tokens": ["Da\u00df", "von", "deut\u00b7scher", "Schmach", "nie", "mel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eure deutschen Siegstroph\u00e4'n.", "tokens": ["Eu\u00b7re", "deut\u00b7schen", "Siegstro\u00b7ph\u00e4'", "n."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["PPOSAT", "ADJA", "NN", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Da\u00df nicht Kr\u00e4merellen messen,", "tokens": ["Da\u00df", "nicht", "Kr\u00e4\u00b7me\u00b7rel\u00b7len", "mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ein gro\u00dfes Herz nur mi\u00dft;", "tokens": ["Was", "ein", "gro\u00b7\u00dfes", "Herz", "nur", "mi\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nicht F\u00fcrsten leicht vergessen,", "tokens": ["Und", "nicht", "F\u00fcrs\u00b7ten", "leicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ihr B\u00fcrger schwer vergi\u00dft;", "tokens": ["Was", "ihr", "B\u00fcr\u00b7ger", "schwer", "ver\u00b7gi\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Nicht den Wandrer Pfahl und Schranke,", "tokens": ["Nicht", "den", "Wand\u00b7rer", "Pfahl", "und", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie so klein die L\u00e4ndchen, mahnt,", "tokens": ["Wie", "so", "klein", "die", "L\u00e4nd\u00b7chen", ",", "mahnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sein einiger Gedanke:", "tokens": ["Da\u00df", "sein", "ei\u00b7ni\u00b7ger", "Ge\u00b7dan\u00b7ke", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie so gro\u00df das deutsche Land.", "tokens": ["Wie", "so", "gro\u00df", "das", "deut\u00b7sche", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Da\u00df wo euch der Glauben schiede,", "tokens": ["Da\u00df", "wo", "euch", "der", "Glau\u00b7ben", "schie\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Euch vereine Deutschlands Schild;", "tokens": ["Euch", "ver\u00b7ei\u00b7ne", "Deutschlands", "Schild", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "So verschmilzt ein Liebesfriede", "tokens": ["So", "ver\u00b7schmilzt", "ein", "Lie\u00b7bes\u00b7frie\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Blond und Schwarz, und Streng und Mild.", "tokens": ["Blond", "und", "Schwarz", ",", "und", "Streng", "und", "Mild", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,", "KON", "NE", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Da\u00df der Baum der freien Rede", "tokens": ["Da\u00df", "der", "Baum", "der", "frei\u00b7en", "Re\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Frucht im Nord und S\u00fcden bringt;", "tokens": ["Frucht", "im", "Nord", "und", "S\u00fc\u00b7den", "bringt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Rheingott nicht bedroht mit Fehde,", "tokens": ["Rhein\u00b7gott", "nicht", "be\u00b7droht", "mit", "Feh\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Was die Donaunymphe singt.", "tokens": ["Was", "die", "Do\u00b7na\u00b7u\u00b7nym\u00b7phe", "singt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Bund und Eintracht erst vereine", "tokens": ["Bund", "und", "Ein\u00b7tracht", "erst", "ver\u00b7ei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eure tausend Schulzen fein,", "tokens": ["Eu\u00b7re", "tau\u00b7send", "Schul\u00b7zen", "fein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "CARD", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann ein Leichtes wird's, ich meine,", "tokens": ["Dann", "ein", "Leich\u00b7tes", "wird's", ",", "ich", "mei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "$,", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit den drei\u00dfig F\u00fcrsten sein.\u00ab \u2013", "tokens": ["Mit", "den", "drei\u00b7\u00dfig", "F\u00fcrs\u00b7ten", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ART", "CARD", "NN", "VAINF", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Doch zur Gruft hinab selbst dringen", "tokens": ["Doch", "zur", "Gruft", "hin\u00b7ab", "selbst", "drin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fchlingsstimmen, Fr\u00fchlingsduft;", "tokens": ["Fr\u00fch\u00b7lings\u00b7stim\u00b7men", ",", "Fr\u00fch\u00b7lings\u00b7duft", ";"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wundervolle Lieder klingen", "tokens": ["Wun\u00b7der\u00b7vol\u00b7le", "Lie\u00b7der", "klin\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gr\u00fc\u00dfend, hoffend durch die Luft.", "tokens": ["Gr\u00fc\u00b7\u00dfend", ",", "hof\u00b7fend", "durch", "die", "Luft", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Doch auch niegeh\u00f6rte T\u00f6ne", "tokens": ["Doch", "auch", "nie\u00b7ge\u00b7h\u00f6r\u00b7te", "T\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jauchzt ein k\u00fchn'res Sanggeschlecht;", "tokens": ["Jauchzt", "ein", "k\u00fchn'\u00b7res", "Sang\u00b7ge\u00b7schlecht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das ist eben Fr\u00fchlings Sch\u00f6ne!", "tokens": ["Das", "ist", "e\u00b7ben", "Fr\u00fch\u00b7lings", "Sch\u00f6\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Freiheit ist des Lenzes Recht.", "tokens": ["Frei\u00b7heit", "ist", "des", "Len\u00b7zes", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Schwalbe sagt Lebwohl dem Todten,", "tokens": ["Schwal\u00b7be", "sagt", "Leb\u00b7wohl", "dem", "Tod\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwingt sich in das Blau hinein;", "tokens": ["Schwingt", "sich", "in", "das", "Blau", "hin\u00b7ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo es lenzt, wird sie entboten,", "tokens": ["Wo", "es", "lenzt", ",", "wird", "sie", "ent\u00b7bo\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit dem Fr\u00fchling mu\u00df sie sein.", "tokens": ["Mit", "dem", "Fr\u00fch\u00b7ling", "mu\u00df", "sie", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}