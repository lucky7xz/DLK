{"textgrid.poem.56785": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auf einem Eichenstrunk, die Ziegenbeine", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf einem Eichenstrunk, die Ziegenbeine", "tokens": ["Auf", "ei\u00b7nem", "Ei\u00b7chen\u00b7strunk", ",", "die", "Zie\u00b7gen\u00b7bei\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "behaglich \u00fcberschlagen, sitzt ein Faun", "tokens": ["be\u00b7hag\u00b7lich", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", ",", "sitzt", "ein", "Faun"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und liest in einem alten Zeitungsblatt,", "tokens": ["und", "liest", "in", "ei\u00b7nem", "al\u00b7ten", "Zei\u00b7tungs\u00b7blatt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "das er im Walde irgendwo gefunden.", "tokens": ["das", "er", "im", "Wal\u00b7de", "ir\u00b7gend\u00b7wo", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ein Feuilleton \u00bbDie Presse, ihre Macht", "tokens": ["Ein", "Feu\u00b7il\u00b7le\u00b7ton", "\u00bb", "Die", "Pres\u00b7se", ",", "ih\u00b7re", "Macht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "NN", "$,", "PPOSAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "und heilige Mission\u00ab besch\u00e4ftigt ihn.", "tokens": ["und", "hei\u00b7li\u00b7ge", "Mis\u00b7si\u00b7on", "\u00ab", "be\u00b7sch\u00e4f\u00b7tigt", "ihn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$(", "VVFIN", "PPER", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "\u00bbdie Presse\u00ab liest er \u00bbist das Fundament", "tokens": ["\u00bb", "die", "Pres\u00b7se", "\u00ab", "liest", "er", "\u00bb", "ist", "das", "Fun\u00b7da\u00b7ment"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "$(", "VVFIN", "PPER", "$(", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der heutigen Kultur, der st\u00e4rkste Hebel", "tokens": ["der", "heu\u00b7ti\u00b7gen", "Kul\u00b7tur", ",", "der", "st\u00e4rks\u00b7te", "He\u00b7bel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "geistigen Fortschritts, h\u00f6herer Gesittung.", "tokens": ["geis\u00b7ti\u00b7gen", "Fort\u00b7schritts", ",", "h\u00f6\u00b7he\u00b7rer", "Ge\u00b7sit\u00b7tung", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Sie ist die Lehrerin, Erzieherin", "tokens": ["Sie", "ist", "die", "Leh\u00b7re\u00b7rin", ",", "Er\u00b7zie\u00b7he\u00b7rin"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und Richterin der V\u00f6lker! Nichts entzieht sich", "tokens": ["und", "Rich\u00b7te\u00b7rin", "der", "V\u00f6l\u00b7ker", "!", "Nichts", "ent\u00b7zieht", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "ART", "NN", "$.", "PIS", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "der Allmacht ihrer Kritiker: Sie pr\u00fcft,", "tokens": ["der", "All\u00b7macht", "ih\u00b7rer", "Kri\u00b7ti\u00b7ker", ":", "Sie", "pr\u00fcft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "beleuchtet alles, was du denkst und tust,", "tokens": ["be\u00b7leuch\u00b7tet", "al\u00b7les", ",", "was", "du", "denkst", "und", "tust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "sie ist die vornehmste, stets wachsame", "tokens": ["sie", "ist", "die", "vor\u00b7nehms\u00b7te", ",", "stets", "wach\u00b7sa\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "$,", "ADV", "ADJA"], "meter": "-+--+-++--", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "und drum so wichtige Vertreterin", "tokens": ["und", "drum", "so", "wich\u00b7ti\u00b7ge", "Ver\u00b7tre\u00b7te\u00b7rin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "der \u00f6ffentlichen Meinung. Papst und Kaiser", "tokens": ["der", "\u00f6f\u00b7fent\u00b7li\u00b7chen", "Mei\u00b7nung", ".", "Papst", "und", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "NN", "KON", "NN"], "meter": "-++--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "umbuhlen sie. Und bis herab zum Bettler", "tokens": ["um\u00b7buh\u00b7len", "sie", ".", "Und", "bis", "her\u00b7ab", "zum", "Bett\u00b7ler"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$.", "KON", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "sieht alle St\u00e4nde, alle Klassen man", "tokens": ["sieht", "al\u00b7le", "St\u00e4n\u00b7de", ",", "al\u00b7le", "Klas\u00b7sen", "man"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PIAT", "NN", "PIS"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.13": {"text": "ihr unterworfen und gezwungen, sie", "tokens": ["ihr", "un\u00b7ter\u00b7wor\u00b7fen", "und", "ge\u00b7zwun\u00b7gen", ",", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVPP", "KON", "VVPP", "$,", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "zu respektieren. Und noch mehr, noch mehr!", "tokens": ["zu", "res\u00b7pek\u00b7tie\u00b7ren", ".", "Und", "noch", "mehr", ",", "noch", "mehr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "KON", "ADV", "ADV", "$,", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Sie ist das unentbehrlich-wichtigste", "tokens": ["Sie", "ist", "das", "un\u00b7ent\u00b7behr\u00b7lich\u00b7wich\u00b7tigs\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Verkehrs- und Bildungsmittel unsrer Zeit:", "tokens": ["Ver\u00b7kehrs", "und", "Bil\u00b7dungs\u00b7mit\u00b7tel", "uns\u00b7rer", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Bezieht ein gro\u00dfer Teil der Menschheit doch", "tokens": ["Be\u00b7zieht", "ein", "gro\u00b7\u00dfer", "Teil", "der", "Menschheit", "doch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "heut sein gesamtes Wissen aus der Zeitung!", "tokens": ["heut", "sein", "ge\u00b7sam\u00b7tes", "Wis\u00b7sen", "aus", "der", "Zei\u00b7tung", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Denn mehr und mehr verdr\u00e4ngt die Tagespresse", "tokens": ["Denn", "mehr", "und", "mehr", "ver\u00b7dr\u00e4ngt", "die", "Ta\u00b7ge\u00b7spres\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "KON", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "der langen B\u00fccher zweifelhaften Wert:", "tokens": ["der", "lan\u00b7gen", "B\u00fc\u00b7cher", "zwei\u00b7fel\u00b7haf\u00b7ten", "Wert", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Der Menschen Kraft, Bed\u00fcrfnis nehmen heut", "tokens": ["Der", "Men\u00b7schen", "Kraft", ",", "Be\u00b7d\u00fcrf\u00b7nis", "neh\u00b7men", "heut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "die Zeitungen und Zeitschriften in Anspruch,", "tokens": ["die", "Zei\u00b7tun\u00b7gen", "und", "Zeit\u00b7schrif\u00b7ten", "in", "An\u00b7spruch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+---++--+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "soda\u00df der Sammlung fordernden Lekt\u00fcre", "tokens": ["so\u00b7da\u00df", "der", "Samm\u00b7lung", "for\u00b7dern\u00b7den", "Lek\u00b7t\u00fc\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "kein Raum mehr bleibt. Die f\u00fcr den Tag geschriebnen", "tokens": ["kein", "Raum", "mehr", "bleibt", ".", "Die", "f\u00fcr", "den", "Tag", "ge\u00b7schrieb\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$.", "ART", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "und mit dem Tag vergehnden Zeitungen,", "tokens": ["und", "mit", "dem", "Tag", "ver\u00b7gehn\u00b7den", "Zei\u00b7tun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "sie wirken eben rascher als die dicken,", "tokens": ["sie", "wir\u00b7ken", "e\u00b7ben", "ra\u00b7scher", "als", "die", "di\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KOKOM", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "gedankenschweren B\u00fccher, ja noch mehr!", "tokens": ["ge\u00b7dan\u00b7ken\u00b7schwe\u00b7ren", "B\u00fc\u00b7cher", ",", "ja", "noch", "mehr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "In ihren H\u00e4nden liegt das Schicksal aller", "tokens": ["In", "ih\u00b7ren", "H\u00e4n\u00b7den", "liegt", "das", "Schick\u00b7sal", "al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "schriftstellerisch- und dichterischen Werke!\u00ab", "tokens": ["schrift\u00b7stel\u00b7le\u00b7risch", "und", "dich\u00b7te\u00b7ri\u00b7schen", "Wer\u00b7ke", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["TRUNC", "KON", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Mit breitem Grinsen liest es der Panisk,", "tokens": ["Mit", "brei\u00b7tem", "Grin\u00b7sen", "liest", "es", "der", "Pa\u00b7nisk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und seine Fl\u00f6te an die Lippen langend,", "tokens": ["und", "sei\u00b7ne", "Fl\u00f6\u00b7te", "an", "die", "Lip\u00b7pen", "lan\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "erhebt er sich und trabt vergn\u00fcgt waldein.", "tokens": ["er\u00b7hebt", "er", "sich", "und", "trabt", "ver\u00b7gn\u00fcgt", "wal\u00b7dein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "KON", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein Wiesel raschelt unterm Stamm hervor;", "tokens": ["Ein", "Wie\u00b7sel", "ra\u00b7schelt", "un\u00b7term", "Stamm", "her\u00b7vor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "die hohen Eichen fl\u00fcstern hell im Wind;", "tokens": ["die", "ho\u00b7hen", "Ei\u00b7chen", "fl\u00fcs\u00b7tern", "hell", "im", "Wind", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und das Papierchen tanzt in eine Pf\u00fctze.", "tokens": ["und", "das", "Pa\u00b7pier\u00b7chen", "tanzt", "in", "ei\u00b7ne", "Pf\u00fct\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}