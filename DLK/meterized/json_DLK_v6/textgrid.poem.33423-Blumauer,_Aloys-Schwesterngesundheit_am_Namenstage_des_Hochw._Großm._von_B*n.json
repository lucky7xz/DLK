{"textgrid.poem.33423": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Schwesterngesundheit am Namenstage des Hochw. Gro\u00dfm. von B*n", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wenn unser Meister Ignaz hei\u00dft,", "tokens": ["Wenn", "un\u00b7ser", "Meis\u00b7ter", "Ig\u00b7naz", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und unser Mund den Namen preist,", "tokens": ["Und", "un\u00b7ser", "Mund", "den", "Na\u00b7men", "preist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So m\u00fc\u00dft ihr d'rum nicht glauben,", "tokens": ["So", "m\u00fc\u00dft", "ihr", "d'\u00b7rum", "nicht", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df wir auch Jesuiten sind,", "tokens": ["Da\u00df", "wir", "auch", "Je\u00b7su\u00b7i\u00b7ten", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und gerne jedem sch\u00f6nen Kind", "tokens": ["Und", "ger\u00b7ne", "je\u00b7dem", "sch\u00f6\u00b7nen", "Kind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die jungen M\u00e4nner rauben.", "tokens": ["Die", "jun\u00b7gen", "M\u00e4n\u00b7ner", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Nein, Schwestern, unser Ignaz hat", "tokens": ["Nein", ",", "Schwes\u00b7tern", ",", "un\u00b7ser", "Ig\u00b7naz", "hat"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "$,", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch keinen Heiligenornat", "tokens": ["Noch", "kei\u00b7nen", "Hei\u00b7li\u00b7ge\u00b7nor\u00b7nat"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Vom obern Kirchenhirten;", "tokens": ["Vom", "o\u00b7bern", "Kir\u00b7chen\u00b7hir\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch sch\u00e4tzen wir den Edlen sehr,", "tokens": ["Doch", "sch\u00e4t\u00b7zen", "wir", "den", "Ed\u00b7len", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und lieben ihn unendlich mehr", "tokens": ["Und", "lie\u00b7ben", "ihn", "un\u00b7end\u00b7lich", "mehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als den Canonisirten.", "tokens": ["Als", "den", "Ca\u00b7no\u00b7ni\u00b7sir\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Der Orden, dem wir zugethan,", "tokens": ["Der", "Or\u00b7den", ",", "dem", "wir", "zu\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Baut nicht am r\u00f6m'schen Vatican,", "tokens": ["Baut", "nicht", "am", "r\u00f6m'\u00b7schen", "Va\u00b7ti\u00b7can", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Baut Menschenwohl hienieden,", "tokens": ["Baut", "Men\u00b7schen\u00b7wohl", "hien\u00b7ie\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und alle seine Satzungen", "tokens": ["Und", "al\u00b7le", "sei\u00b7ne", "Sat\u00b7zun\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIS", "PPOSAT", "NN"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Sind von den Jesuitischen", "tokens": ["Sind", "von", "den", "Je\u00b7su\u00b7i\u00b7ti\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Gar himmelweit verschieden.", "tokens": ["Gar", "him\u00b7mel\u00b7weit", "ver\u00b7schie\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sankt Ignaz schuf aus Ueberdru\u00df", "tokens": ["Sankt", "Ig\u00b7naz", "schuf", "aus", "Ue\u00b7berd\u00b7ru\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob seinem Loch im rechten Fu\u00df", "tokens": ["Ob", "sei\u00b7nem", "Loch", "im", "rech\u00b7ten", "Fu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich seinen neuen Orden;", "tokens": ["Sich", "sei\u00b7nen", "neu\u00b7en", "Or\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der uns zusammen hat gesellt,", "tokens": ["Der", "uns", "zu\u00b7sam\u00b7men", "hat", "ge\u00b7sellt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist nicht aus Spleen und Ha\u00df der Welt", "tokens": ["Ist", "nicht", "aus", "Spleen", "und", "Ha\u00df", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "APPR", "NN", "KON", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum Logenstifter worden.", "tokens": ["Zum", "Lo\u00b7gens\u00b7tif\u00b7ter", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Sankt Ignaz war den M\u00e4dchen gram,", "tokens": ["Sankt", "Ig\u00b7naz", "war", "den", "M\u00e4d\u00b7chen", "gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wo ihm ein's nur nahe kam,", "tokens": ["Und", "wo", "ihm", "ein's", "nur", "na\u00b7he", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "PIS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da fing er an zu l\u00e4stern;", "tokens": ["Da", "fing", "er", "an", "zu", "l\u00e4s\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir hegen keinen solchen Groll,", "tokens": ["Wir", "he\u00b7gen", "kei\u00b7nen", "sol\u00b7chen", "Groll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir feuern oft auf euer Wohl,", "tokens": ["Wir", "feu\u00b7ern", "oft", "auf", "eu\u00b7er", "Wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und nennen euch gar Schwestern.", "tokens": ["Und", "nen\u00b7nen", "euch", "gar", "Schwes\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Wir pr\u00fcfen unsern Heldenmuth", "tokens": ["Wir", "pr\u00fc\u00b7fen", "un\u00b7sern", "Hel\u00b7den\u00b7muth"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Wind und Wasser, Feu'r und Blut,", "tokens": ["Durch", "Wind", "und", "Was\u00b7ser", ",", "Feu'r", "und", "Blut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wagen Leib und Leben;", "tokens": ["Und", "wa\u00b7gen", "Leib", "und", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sankt Ignaz, da\u00df er Muth bewies,", "tokens": ["Sankt", "Ig\u00b7naz", ",", "da\u00df", "er", "Muth", "be\u00b7wies", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Lie\u00df in der Schule zu Paris", "tokens": ["Lie\u00df", "in", "der", "Schu\u00b7le", "zu", "Pa\u00b7ris"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich einen Schilling geben.", "tokens": ["Sich", "ei\u00b7nen", "Schil\u00b7ling", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Sankt Ignaz sandte J\u00fcnger gar", "tokens": ["Sankt", "Ig\u00b7naz", "sand\u00b7te", "J\u00fcn\u00b7ger", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach Indien, der Heiden Schaar", "tokens": ["Nach", "In\u00b7di\u00b7en", ",", "der", "Hei\u00b7den", "Schaar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "ART", "ADJA", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Zu t\u00f6dten und zu pl\u00fcndern;", "tokens": ["Zu", "t\u00f6d\u00b7ten", "und", "zu", "pl\u00fcn\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn Maurer nach den L\u00e4ndern zieh'n,", "tokens": ["Wenn", "Mau\u00b7rer", "nach", "den", "L\u00e4n\u00b7dern", "zieh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So werden sie die Heiden d'rin", "tokens": ["So", "wer\u00b7den", "sie", "die", "Hei\u00b7den", "d'\u00b7rin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Eh' mehren, als vermindern.", "tokens": ["Eh'", "meh\u00b7ren", ",", "als", "ver\u00b7min\u00b7dern", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "KOUS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "D'rum, da\u00df wir nicht wie Ignaz thun,", "tokens": ["D'\u00b7rum", ",", "da\u00df", "wir", "nicht", "wie", "Ig\u00b7naz", "thun", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "PTKNEG", "KOKOM", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Das glaubt ihr, liebe Schwestern, nun", "tokens": ["Das", "glaubt", "ihr", ",", "lie\u00b7be", "Schwes\u00b7tern", ",", "nun"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PDS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl ohne mein Betheuern:", "tokens": ["Wohl", "oh\u00b7ne", "mein", "Be\u00b7theu\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Denn st\u00fcnden wir in seiner Pflicht,", "tokens": ["Denn", "st\u00fcn\u00b7den", "wir", "in", "sei\u00b7ner", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir w\u00fcrden aus Kanonen nicht", "tokens": ["Wir", "w\u00fcr\u00b7den", "aus", "Ka\u00b7no\u00b7nen", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf eurer Wohl jetzt feuern.", "tokens": ["Auf", "eu\u00b7rer", "Wohl", "jetzt", "feu\u00b7ern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}