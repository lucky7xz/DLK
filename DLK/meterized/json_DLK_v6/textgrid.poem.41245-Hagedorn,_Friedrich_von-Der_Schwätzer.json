{"textgrid.poem.41245": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Schw\u00e4tzer", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "J\u00fcngst, da ich mich, wie sonst, den Grillen \u00fcberlasse,", "tokens": ["J\u00fcngst", ",", "da", "ich", "mich", ",", "wie", "sonst", ",", "den", "Gril\u00b7len", "\u00fc\u00b7ber\u00b7las\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "PRF", "$,", "PWAV", "ADV", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gerath ich ungef\u00e4hr in die Mariengasse.", "tokens": ["Ge\u00b7rath", "ich", "un\u00b7ge\u00b7f\u00e4hr", "in", "die", "Ma\u00b7ri\u00b7en\u00b7gas\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Fremder, den ich nur dem Namen nach gekannt,", "tokens": ["Ein", "Frem\u00b7der", ",", "den", "ich", "nur", "dem", "Na\u00b7men", "nach", "ge\u00b7kannt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "ART", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "L\u00e4uft pl\u00f6tzlich auf mich zu, ergreift mich bei der Hand", "tokens": ["L\u00e4uft", "pl\u00f6tz\u00b7lich", "auf", "mich", "zu", ",", "er\u00b7greift", "mich", "bei", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJD", "APPR", "PPER", "PTKVZ", "$,", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und spricht: \u00bbWie geht's? ", "tokens": ["Und", "spricht", ":", "\u00bb", "Wie", "geht's", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PWAV", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Von Ihnen hoff' ich auch erw\u00fcnschtes Wohlergehen.", "tokens": ["Von", "Ih\u00b7nen", "hoff'", "ich", "auch", "er\u00b7w\u00fcnschtes", "Woh\u00b7ler\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Er folgt mir Schritt vor Schritt, und klebt mir l\u00e4chelnd an.", "tokens": ["Er", "folgt", "mir", "Schritt", "vor", "Schritt", ",", "und", "klebt", "mir", "l\u00e4\u00b7chelnd", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist etwas, frag' ich ihn, womit ich dienen kann?", "tokens": ["Ist", "et\u00b7was", ",", "frag'", "ich", "ihn", ",", "wo\u00b7mit", "ich", "die\u00b7nen", "kann", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "VVIMP", "PPER", "PPER", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er danket und versetzt: \u00bbSie werden mich schon kennen,", "tokens": ["Er", "dan\u00b7ket", "und", "ver\u00b7setzt", ":", "\u00bb", "Sie", "wer\u00b7den", "mich", "schon", "ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVPP", "$.", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und Ihre Freundschaft mir, als einem Dichter, g\u00f6nnen.\u00ab", "tokens": ["Und", "Ih\u00b7re", "Freund\u00b7schaft", "mir", ",", "als", "ei\u00b7nem", "Dich\u00b7ter", ",", "g\u00f6n\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPER", "$,", "KOUS", "ART", "NN", "$,", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mein Herr, Sie sollen mir um desto werther sein.", "tokens": ["Mein", "Herr", ",", "Sie", "sol\u00b7len", "mir", "um", "des\u00b7to", "wert\u00b7her", "sein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "VMFIN", "PPER", "APPR", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ich eil', ich stehe still, von ihm mich zu befrein,", "tokens": ["Ich", "eil'", ",", "ich", "ste\u00b7he", "still", ",", "von", "ihm", "mich", "zu", "be\u00b7fr\u00b7ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKVZ", "$,", "APPR", "PPER", "PRF", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und raun', ich wei\u00df nicht was, dem Diener in die Ohren;", "tokens": ["Und", "raun'", ",", "ich", "wei\u00df", "nicht", "was", ",", "dem", "Die\u00b7ner", "in", "die", "Oh\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VVFIN", "PTKNEG", "PIS", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Doch hier ist alle M\u00fch' und alle Kunst verloren.", "tokens": ["Doch", "hier", "ist", "al\u00b7le", "M\u00fch'", "und", "al\u00b7le", "Kunst", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Mir bricht der Angstschwei\u00df aus. O wie beneidenswerth", "tokens": ["Mir", "bricht", "der", "A\u00b7ngstschwei\u00df", "aus", ".", "O", "wie", "be\u00b7nei\u00b7dens\u00b7werth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$.", "NE", "KOKOM", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Gedenk' ich, ist der Thor, der Thoren gerne h\u00f6rt!", "tokens": ["Ge\u00b7denk'", "ich", ",", "ist", "der", "Thor", ",", "der", "Tho\u00b7ren", "ger\u00b7ne", "h\u00f6rt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "VAFIN", "ART", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Indessen str\u00f6mt sein Mund von rauschendem Geschw\u00e4tze;", "tokens": ["In\u00b7des\u00b7sen", "str\u00f6mt", "sein", "Mund", "von", "rau\u00b7schen\u00b7dem", "Ge\u00b7schw\u00e4t\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Er lobt die sch\u00f6ne Stadt und nennt mir alle Pl\u00e4tze,", "tokens": ["Er", "lobt", "die", "sch\u00f6\u00b7ne", "Stadt", "und", "nennt", "mir", "al\u00b7le", "Pl\u00e4t\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die Br\u00fccken, jedes Thor, die M\u00e4rkte, Wall und Wacht,", "tokens": ["Die", "Br\u00fc\u00b7cken", ",", "je\u00b7des", "Thor", ",", "die", "M\u00e4rk\u00b7te", ",", "Wall", "und", "Wacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "$,", "ART", "NN", "$,", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und lehrt mich, wie der Lenz die G\u00e4rten lustig macht.", "tokens": ["Und", "lehrt", "mich", ",", "wie", "der", "Lenz", "die", "G\u00e4r\u00b7ten", "lus\u00b7tig", "macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ich schweig, er f\u00e4hret fort: \u00bbIst man so still? ich finde,", "tokens": ["Ich", "schweig", ",", "er", "f\u00e4h\u00b7ret", "fort", ":", "\u00bb", "Ist", "man", "so", "still", "?", "ich", "fin\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PTKVZ", "$.", "$(", "VAFIN", "PIS", "ADV", "ADJD", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Da\u00df die Begleitung Sie nicht sonderlich verbinde;", "tokens": ["Da\u00df", "die", "Be\u00b7glei\u00b7tung", "Sie", "nicht", "son\u00b7der\u00b7lich", "ver\u00b7bin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Allein, ich schlendre mit, und Sie erlauben mir", "tokens": ["Al\u00b7lein", ",", "ich", "schlend\u00b7re", "mit", ",", "und", "Sie", "er\u00b7lau\u00b7ben", "mir"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "PTKVZ", "$,", "KON", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "F\u00fcr dies Mal k\u00fchn zu sein. Doch wohin gehen wir?\u00ab", "tokens": ["F\u00fcr", "dies", "Mal", "k\u00fchn", "zu", "sein", ".", "Doch", "wo\u00b7hin", "ge\u00b7hen", "wir", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PDS", "NN", "ADJD", "PTKZU", "VAINF", "$.", "KON", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Bem\u00fchen Sie sich nicht: ich kann mich nicht verweilen,", "tokens": ["Be\u00b7m\u00fc\u00b7hen", "Sie", "sich", "nicht", ":", "ich", "kann", "mich", "nicht", "ver\u00b7wei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "PTKNEG", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und mu\u00df zu einem Freund, den Sie nicht kennen, eilen.", "tokens": ["Und", "mu\u00df", "zu", "ei\u00b7nem", "Freund", ",", "den", "Sie", "nicht", "ken\u00b7nen", ",", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Er wohnet weit von hier, die Alster ganz vorbei,", "tokens": ["Er", "woh\u00b7net", "weit", "von", "hier", ",", "die", "Als\u00b7ter", "ganz", "vor\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ADV", "$,", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Noch hinter B\u00f6ckelmanns bekannten G\u00e4rtnerei.", "tokens": ["Noch", "hin\u00b7ter", "B\u00f6\u00b7ckel\u00b7manns", "be\u00b7kann\u00b7ten", "G\u00e4rt\u00b7ne\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "\u00bbich habe nichts zu thun; was hei\u00dfen tausend Schritte?", "tokens": ["\u00bb", "ich", "ha\u00b7be", "nichts", "zu", "thun", ";", "was", "hei\u00b7\u00dfen", "tau\u00b7send", "Schrit\u00b7te", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PIS", "PTKZU", "VVINF", "$.", "PWS", "ADJA", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Im Gehen, glauben Sie's, bin ich ein rechter Britte.\u00ab", "tokens": ["Im", "Ge\u00b7hen", ",", "glau\u00b7ben", "Sie's", ",", "bin", "ich", "ein", "rech\u00b7ter", "Brit\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "NE", "$,", "VAFIN", "PPER", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Mich kr\u00fcmm' ich, wie ein Pferd, das, bei zu schwerer Last,", "tokens": ["Mich", "kr\u00fcmm'", "ich", ",", "wie", "ein", "Pferd", ",", "das", ",", "bei", "zu", "schwe\u00b7rer", "Last", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "$,", "PDS", "$,", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Kopf, Maul und Ohren h\u00e4ngt, und seinen Treiber ha\u00dft.", "tokens": ["Kopf", ",", "Maul", "und", "Oh\u00b7ren", "h\u00e4ngt", ",", "und", "sei\u00b7nen", "Trei\u00b7ber", "ha\u00dft", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Er r\u00e4uspert sich und spricht: \u00bbWahr ist's, sich selbst zu r\u00fchmen,", "tokens": ["Er", "r\u00e4us\u00b7pert", "sich", "und", "spricht", ":", "\u00bb", "Wahr", "ist's", ",", "sich", "selbst", "zu", "r\u00fch\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "KON", "VVFIN", "$.", "$(", "NE", "NE", "$,", "PRF", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "So sehr man sich auch kennt, das will sich nicht geziemen;", "tokens": ["So", "sehr", "man", "sich", "auch", "kennt", ",", "das", "will", "sich", "nicht", "ge\u00b7zie\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PRF", "ADV", "VVFIN", "$,", "PDS", "VMFIN", "PRF", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Doch pr\u00fcfen Sie mich nur: ich wette, da\u00df Ihr Freund,", "tokens": ["Doch", "pr\u00fc\u00b7fen", "Sie", "mich", "nur", ":", "ich", "wet\u00b7te", ",", "da\u00df", "Ihr", "Freund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "$.", "PPER", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Mit dem ein jedes Jahr Sie z\u00e4rtlicher vereint,", "tokens": ["Mit", "dem", "ein", "je\u00b7des", "Jahr", "Sie", "z\u00e4rt\u00b7li\u00b7cher", "ver\u00b7eint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "PIAT", "NN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Ich wette: Wilkens selbst, und M\u00fcller, den Sie lieben,", "tokens": ["Ich", "wet\u00b7te", ":", "Wil\u00b7kens", "selbst", ",", "und", "M\u00fcl\u00b7ler", ",", "den", "Sie", "lie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "ADV", "$,", "KON", "NE", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Und Carpser, und Borgeest, die sollen ihren Trieben", "tokens": ["Und", "Carp\u00b7ser", ",", "und", "Bor\u00b7geest", ",", "die", "sol\u00b7len", "ih\u00b7ren", "Trie\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "NN", "$,", "KON", "NE", "$,", "PRELS", "PIAT", "PPOSAT", "NN"], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.39": {"text": "Nie so gef\u00e4llig sein. Mich \u00fcbt der Dichtkunst Flor.", "tokens": ["Nie", "so", "ge\u00b7f\u00e4l\u00b7lig", "sein", ".", "Mich", "\u00fcbt", "der", "Dicht\u00b7kunst", "Flor", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VAINF", "$.", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Neun Musen stell' ich mir, so wie neun Kegel, vor.", "tokens": ["Neun", "Mu\u00b7sen", "stell'", "ich", "mir", ",", "so", "wie", "neun", "Ke\u00b7gel", ",", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "PPER", "$,", "ADV", "KOKOM", "CARD", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Man wirft, und trifft doch Holz: es sei viel oder wenig.", "tokens": ["Man", "wirft", ",", "und", "trifft", "doch", "Holz", ":", "es", "sei", "viel", "o\u00b7der", "we\u00b7nig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KON", "VVFIN", "ADV", "NN", "$.", "PPER", "VAFIN", "ADV", "KON", "PIS", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Die Ecken schl\u00e4gt man um, verfehlt man gleich den K\u00f6nig.", "tokens": ["Die", "E\u00b7cken", "schl\u00e4gt", "man", "um", ",", "ver\u00b7fehlt", "man", "gleich", "den", "K\u00f6\u00b7nig", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PTKVZ", "$,", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Man ziele, dichte nur, und mische sich ins Spiele.", "tokens": ["Man", "zie\u00b7le", ",", "dich\u00b7te", "nur", ",", "und", "mi\u00b7sche", "sich", "ins", "Spie\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "VVFIN", "ADV", "$,", "KON", "VVFIN", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Werd' ich nicht episch gro\u00df, und bin ich kein Virgil;", "tokens": ["Werd'", "ich", "nicht", "e\u00b7pisch", "gro\u00df", ",", "und", "bin", "ich", "kein", "Vir\u00b7gil", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJD", "ADJD", "$,", "KON", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wohlan! so reim' ich schnell von tausend andern Dingen:", "tokens": ["Wo\u00b7hlan", "!", "so", "reim'", "ich", "schnell", "von", "tau\u00b7send", "an\u00b7dern", "Din\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVFIN", "PPER", "ADJD", "APPR", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Mit einer Muse mu\u00df mir doch der Streich gelingen,", "tokens": ["Mit", "ei\u00b7ner", "Mu\u00b7se", "mu\u00df", "mir", "doch", "der", "Streich", "ge\u00b7lin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Erreich' ich Alle nicht. Ich tanze wie du Vall:", "tokens": ["Er\u00b7reich'", "ich", "Al\u00b7le", "nicht", ".", "Ich", "tan\u00b7ze", "wie", "du", "Vall", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "PTKNEG", "$.", "PPER", "VVFIN", "KOKOM", "PPER", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Das sah man auf dem Baum, bei dem Freim\u00e4urerball.", "tokens": ["Das", "sah", "man", "auf", "dem", "Baum", ",", "bei", "dem", "Frei\u00b7m\u00e4u\u00b7rer\u00b7ball", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.49": {"text": "Finazzi singet gut: doch ich kann besser singen.\u00ab", "tokens": ["Fi\u00b7naz\u00b7zi", "sin\u00b7get", "gut", ":", "doch", "ich", "kann", "bes\u00b7ser", "sin\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$.", "KON", "PPER", "VMFIN", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nunmehr gewann ich Zeit, ein W\u00f6rtchen anzubringen.", "tokens": ["Nun\u00b7mehr", "ge\u00b7wann", "ich", "Zeit", ",", "ein", "W\u00f6rt\u00b7chen", "an\u00b7zu\u00b7brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat keine Mutter nicht, kein Vetter, kein Geschlecht,", "tokens": ["Hat", "kei\u00b7ne", "Mut\u00b7ter", "nicht", ",", "kein", "Vet\u00b7ter", ",", "kein", "Ge\u00b7schlecht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "PTKNEG", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An Ihrem Wohlsein Theil, an Ihren Stunden Recht?", "tokens": ["An", "Ih\u00b7rem", "Wohl\u00b7sein", "Theil", ",", "an", "Ih\u00b7ren", "Stun\u00b7den", "Recht", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sollt' ihrer keiner nicht Ihr Dasein n\u00f6thig haben?", "tokens": ["Sollt'", "ih\u00b7rer", "kei\u00b7ner", "nicht", "Ihr", "Da\u00b7sein", "n\u00f6\u00b7thig", "ha\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "PIS", "PTKNEG", "PPOSAT", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbwir sprechen uns nicht mehr, denn alle sind begraben.\u00ab", "tokens": ["\u00bb", "wir", "spre\u00b7chen", "uns", "nicht", "mehr", ",", "denn", "al\u00b7le", "sind", "be\u00b7gra\u00b7ben", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$,", "KON", "PIS", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "O die sind wohl daran! nun trifft die Reihe mich,", "tokens": ["O", "die", "sind", "wohl", "da\u00b7ran", "!", "nun", "trifft", "die", "Rei\u00b7he", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "VAFIN", "ADV", "PAV", "$.", "ADV", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bet\u00e4ubte M\u00e4rtyrer! Verfolge! Morde! Sprich!", "tokens": ["Be\u00b7t\u00e4ub\u00b7te", "M\u00e4r\u00b7ty\u00b7rer", "!", "Ver\u00b7fol\u00b7ge", "!", "Mor\u00b7de", "!", "Sprich", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$.", "VVFIN", "$.", "NN", "$.", "VVIMP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn ach! die Stunde k\u00f6mmt, die ich so lange scheute,", "tokens": ["Denn", "ach", "!", "die", "Stun\u00b7de", "k\u00f6mmt", ",", "die", "ich", "so", "lan\u00b7ge", "scheu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die mir das alte Weib in Borstel prophezeite,", "tokens": ["Die", "mir", "das", "al\u00b7te", "Weib", "in", "Bor\u00b7stel", "pro\u00b7phe\u00b7zei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als ich ein Knabe war, und sie mit d\u00fcrrer Hand", "tokens": ["Als", "ich", "ein", "Kna\u00b7be", "war", ",", "und", "sie", "mit", "d\u00fcr\u00b7rer", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VAFIN", "$,", "KON", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Den Loostopf sch\u00fcttelte, griff, mein Verh\u00e4ngni\u00df fand,", "tokens": ["Den", "Loos\u00b7topf", "sch\u00fct\u00b7tel\u00b7te", ",", "griff", ",", "mein", "Ver\u00b7h\u00e4ng\u00b7ni\u00df", "fand", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "VVFIN", "$,", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und mir den Ausspruch gab: Es wird ihn, merkt es eben!", "tokens": ["Und", "mir", "den", "Aus\u00b7spruch", "gab", ":", "Es", "wird", "ihn", ",", "merkt", "es", "e\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VVFIN", "$.", "PPER", "VAFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Kein Arzt, kein Alchmist, kein Fahnenschmidt vergeben:", "tokens": ["Kein", "Arzt", ",", "kein", "Alch\u00b7mist", ",", "kein", "Fah\u00b7nen\u00b7schmidt", "ver\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Ihn f\u00e4llt kein Rauferschwert, kein Seitenweh und Gicht,", "tokens": ["Ihn", "f\u00e4llt", "kein", "Rau\u00b7fer\u00b7schwert", ",", "kein", "Sei\u00b7ten\u00b7weh", "und", "Gicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das tr\u00e4ge Podagra, die Schwindsucht thut es nicht.", "tokens": ["Das", "tr\u00e4\u00b7ge", "Po\u00b7da\u00b7gra", ",", "die", "Schwind\u00b7sucht", "thut", "es", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die gr\u00f6\u00dfeste Gefahr wird er von Schw\u00e4tzern leiden,", "tokens": ["Die", "gr\u00f6\u00b7\u00dfes\u00b7te", "Ge\u00b7fahr", "wird", "er", "von", "Schw\u00e4t\u00b7zern", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und wird er alt und klug so mu\u00df er Redner meiden.", "tokens": ["Und", "wird", "er", "alt", "und", "klug", "so", "mu\u00df", "er", "Red\u00b7ner", "mei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "ADV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wir waren, recht um zehn, wo man die Kirche schaut,", "tokens": ["Wir", "wa\u00b7ren", ",", "recht", "um", "zehn", ",", "wo", "man", "die", "Kir\u00b7che", "schaut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ADJD", "APPR", "CARD", "$,", "PWAV", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die, Magdalene, dir Graf Adolph aufgebaut.", "tokens": ["Die", ",", "Mag\u00b7da\u00b7le\u00b7ne", ",", "dir", "Graf", "A\u00b7dolph", "auf\u00b7ge\u00b7baut", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "NN", "$,", "PPER", "NE", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da sollte nun mein Freund, mit Acten und Geb\u00fchren,", "tokens": ["Da", "soll\u00b7te", "nun", "mein", "Freund", ",", "mit", "Ac\u00b7ten", "und", "Ge\u00b7b\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PPOSAT", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Selbst vor dem Richter stehn, und sonst sein Recht verlieren.", "tokens": ["Selbst", "vor", "dem", "Rich\u00b7ter", "stehn", ",", "und", "sonst", "sein", "Recht", "ver\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVINF", "$,", "KON", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbweil ich auf diese Zeit jetzt vorgeladen bin,", "tokens": ["\u00bb", "weil", "ich", "auf", "die\u00b7se", "Zeit", "jetzt", "vor\u00b7ge\u00b7la\u00b7den", "bin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "APPR", "PDAT", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So,\u00ab spricht er, \u00bbgehn Sie doch mit mir zum Pr\u00e4tor hin,", "tokens": ["So", ",", "\u00ab", "spricht", "er", ",", "\u00bb", "gehn", "Sie", "doch", "mit", "mir", "zum", "Pr\u00e4\u00b7tor", "hin", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PPER", "ADV", "APPR", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und h\u00f6ren, wie ich dort ...\u00ab Ist mir das zuzumuthen?", "tokens": ["Und", "h\u00f6\u00b7ren", ",", "wie", "ich", "dort", "...", "\u00ab", "Ist", "mir", "das", "zu\u00b7zu\u00b7mut\u00b7hen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$,", "PWAV", "PPER", "ADV", "$(", "$(", "VAFIN", "PPER", "PDS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Kann ich Ihr Beistand sein? Versteh' ich die Statuten?", "tokens": ["Kann", "ich", "Ihr", "Bei\u00b7stand", "sein", "?", "Ver\u00b7steh'", "ich", "die", "Sta\u00b7tu\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "VAINF", "$.", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und bin ich nicht versagt? \u00bbNun werd' ich zweifelvoll,", "tokens": ["Und", "bin", "ich", "nicht", "ver\u00b7sagt", "?", "\u00bb", "Nun", "werd'", "ich", "zwei\u00b7fel\u00b7voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "VVPP", "$.", "$(", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ob ich Sie, oder nicht mein Recht, verlassen soll?\u00ab", "tokens": ["Ob", "ich", "Sie", ",", "o\u00b7der", "nicht", "mein", "Recht", ",", "ver\u00b7las\u00b7sen", "soll", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "KON", "PTKNEG", "PPOSAT", "NN", "$,", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mich, mich, mein Herr. \u00bbO nein!\u00ab Er rennt mir vor; ich schleiche,", "tokens": ["Mich", ",", "mich", ",", "mein", "Herr", ".", "\u00bb", "O", "nein", "!", "\u00ab", "Er", "rennt", "mir", "vor", ";", "ich", "schlei\u00b7che", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "$,", "PPOSAT", "NN", "$.", "$(", "NE", "PTKANT", "$.", "$(", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Als im Triumph gef\u00fchrt, weil ich dem St\u00e4rkern weiche.", "tokens": ["Als", "im", "Tri\u00b7umph", "ge\u00b7f\u00fchrt", ",", "weil", "ich", "dem", "St\u00e4r\u00b7kern", "wei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "VVPP", "$,", "KOUS", "PPER", "ART", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Geduld! Was hab' ich nun f\u00fcr Fragen auszustehn?", "tokens": ["Ge\u00b7duld", "!", "Was", "hab'", "ich", "nun", "f\u00fcr", "Fra\u00b7gen", "aus\u00b7zu\u00b7stehn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u00bbwie finden Sie den Brocks, Hammoniens M\u00e4cen?\u00ab", "tokens": ["\u00bb", "wie", "fin\u00b7den", "Sie", "den", "Brocks", ",", "Ham\u00b7mo\u00b7ni\u00b7ens", "M\u00e4\u00b7cen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,", "NE", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich find' und ehr' in ihm den Weisen unsrer Zeiten;", "tokens": ["Ich", "find'", "und", "ehr'", "in", "ihm", "den", "Wei\u00b7sen", "uns\u00b7rer", "Zei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPR", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Allein, er wird, daher, kein Freund von allen Leuten.", "tokens": ["Al\u00b7lein", ",", "er", "wird", ",", "da\u00b7her", ",", "kein", "Freund", "von", "al\u00b7len", "Leu\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "$,", "PAV", "$,", "PIAT", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er w\u00e4hlet, die er liebt, ist sinnreich ohne Tand,", "tokens": ["Er", "w\u00e4h\u00b7let", ",", "die", "er", "liebt", ",", "ist", "sinn\u00b7reich", "oh\u00b7ne", "Tand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Leutselig ohne Falsch, noch edler, als sein Stand,", "tokens": ["Leut\u00b7se\u00b7lig", "oh\u00b7ne", "Falsch", ",", "noch", "ed\u00b7ler", ",", "als", "sein", "Stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "$,", "ADV", "ADJA", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.7": {"text": "Und ihn vergn\u00fcgen nur die W\u00fcrden, die er schm\u00fccket,", "tokens": ["Und", "ihn", "ver\u00b7gn\u00fc\u00b7gen", "nur", "die", "W\u00fcr\u00b7den", ",", "die", "er", "schm\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wann er sein Vaterland und das Verdienst begl\u00fccket.", "tokens": ["Wann", "er", "sein", "Va\u00b7ter\u00b7land", "und", "das", "Ver\u00b7dienst", "be\u00b7gl\u00fc\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u00bbempfehlen Sie ihm den!\u00ab (Hier zeigt der Thor auf sich.)", "tokens": ["\u00bb", "emp\u00b7feh\u00b7len", "Sie", "ihm", "den", "!", "\u00ab", "(", "Hier", "zeigt", "der", "Thor", "auf", "sich", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "PPER", "ART", "$.", "$(", "$(", "ADV", "VVFIN", "ART", "NN", "APPR", "PRF", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "\u00bbihr Mitgehilf', Ihr Rath, Ihr Hinterhalt werd' ich.", "tokens": ["\u00bb", "ihr", "Mit\u00b7ge\u00b7hil\u00b7f'", ",", "Ihr", "Rath", ",", "Ihr", "Hin\u00b7ter\u00b7halt", "werd'", "ich", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "VAFIN", "PPER", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ich sterbe, falls Sie mir die zweite Rolle geben,", "tokens": ["Ich", "ster\u00b7be", ",", "falls", "Sie", "mir", "die", "zwei\u00b7te", "Rol\u00b7le", "ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PRF", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn wir nicht jeden dort bald aus dem Sattel heben.\u00ab", "tokens": ["Wenn", "wir", "nicht", "je\u00b7den", "dort", "bald", "aus", "dem", "Sat\u00b7tel", "he\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PIAT", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Sie irren ungemein in Ihrer Kl\u00fcgelei.", "tokens": ["Sie", "ir\u00b7ren", "un\u00b7ge\u00b7mein", "in", "Ih\u00b7rer", "Kl\u00fc\u00b7ge\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vor andern ist sein Haus von solchen R\u00e4nken frei.", "tokens": ["Vor", "an\u00b7dern", "ist", "sein", "Haus", "von", "sol\u00b7chen", "R\u00e4n\u00b7ken", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPOSAT", "NN", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Liebling des Mercur, den Flei\u00df und Gl\u00fcck erh\u00f6het,", "tokens": ["Der", "Lieb\u00b7ling", "des", "Mer\u00b7cur", ",", "den", "Flei\u00df", "und", "Gl\u00fcck", "er\u00b7h\u00f6\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Der Doctor, der sogar den Lycophron verstehet,", "tokens": ["Der", "Doc\u00b7tor", ",", "der", "so\u00b7gar", "den", "Ly\u00b7cop\u00b7hron", "ver\u00b7ste\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Verdr\u00e4ngen keinen nicht, der einem Brocks gef\u00e4llt,", "tokens": ["Ver\u00b7dr\u00e4n\u00b7gen", "kei\u00b7nen", "nicht", ",", "der", "ei\u00b7nem", "Brocks", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "PTKNEG", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der jeden, nach Verdienst, den Freunden zugesellt.", "tokens": ["Der", "je\u00b7den", ",", "nach", "Ver\u00b7dienst", ",", "den", "Freun\u00b7den", "zu\u00b7ge\u00b7sellt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "$,", "APPR", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u00bbdas ist was Seltsames. Sie scherzen.\u00ab Was ich sage,", "tokens": ["\u00bb", "das", "ist", "was", "Selt\u00b7sa\u00b7mes", ".", "Sie", "scher\u00b7zen", ".", "\u00ab", "Was", "ich", "sa\u00b7ge", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PIS", "NN", "$.", "PPER", "VVFIN", "$.", "$(", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Best\u00e4tiget gewi\u00df die Wahrheit alle Tage.", "tokens": ["Be\u00b7st\u00e4\u00b7ti\u00b7get", "ge\u00b7wi\u00df", "die", "Wahr\u00b7heit", "al\u00b7le", "Ta\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "\u00bbja, nun verehr' ich erst den weitber\u00fchmten Mann,", "tokens": ["\u00bb", "ja", ",", "nun", "ver\u00b7ehr'", "ich", "erst", "den", "weit\u00b7be\u00b7r\u00fchm\u00b7ten", "Mann", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$,", "ADV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und, kurz, ich ruhe nicht, bis ich ihn sprechen kann.\u00ab", "tokens": ["Und", ",", "kurz", ",", "ich", "ru\u00b7he", "nicht", ",", "bis", "ich", "ihn", "spre\u00b7chen", "kann", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "PPER", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Ihn sprechen f\u00e4llt nicht schwer, wenn Sie es nur verlangen:", "tokens": ["Ihn", "spre\u00b7chen", "f\u00e4llt", "nicht", "schwer", ",", "wenn", "Sie", "es", "nur", "ver\u00b7lan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VVFIN", "PTKNEG", "ADJD", "$,", "KOUS", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Ein so gescheidter Kopf wird immer wohl empfangen.", "tokens": ["Ein", "so", "ge\u00b7scheid\u00b7ter", "Kopf", "wird", "im\u00b7mer", "wohl", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und sollt' er anfangs auch nicht mehr als h\u00f6flich sein,", "tokens": ["Und", "sollt'", "er", "an\u00b7fangs", "auch", "nicht", "mehr", "als", "h\u00f6f\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADV", "KOKOM", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "So r\u00e4umen Sie ihm Zeit, Sie g'nug zu kennen, ein.", "tokens": ["So", "r\u00e4u\u00b7men", "Sie", "ihm", "Zeit", ",", "Sie", "g'\u00b7nug", "zu", "ken\u00b7nen", ",", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "NN", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Vielleicht verbirgt er sich im Reden und im Schweigen,", "tokens": ["Viel\u00b7leicht", "ver\u00b7birgt", "er", "sich", "im", "Re\u00b7den", "und", "im", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Sein hulderf\u00fclltes Herz nicht gar zu fr\u00fch zu zeigen.", "tokens": ["Sein", "hul\u00b7der\u00b7f\u00fcll\u00b7tes", "Herz", "nicht", "gar", "zu", "fr\u00fch", "zu", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKNEG", "ADV", "PTKA", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "\u00bbmir fehlt es nicht an Witz, wann ich gesch\u00e4ftig bin.", "tokens": ["\u00bb", "mir", "fehlt", "es", "nicht", "an", "Witz", ",", "wann", "ich", "ge\u00b7sch\u00e4f\u00b7tig", "bin", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Sprech' ich ihn heute nicht, so geh' ich morgen hin,", "tokens": ["Sprech'", "ich", "ihn", "heu\u00b7te", "nicht", ",", "so", "geh'", "ich", "mor\u00b7gen", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "ADV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Und \u00fcbermorgen auch. Die Sache recht zu lenken,", "tokens": ["Und", "\u00fc\u00b7ber\u00b7mor\u00b7gen", "auch", ".", "Die", "Sa\u00b7che", "recht", "zu", "len\u00b7ken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$.", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Will ich den Diener selbst mit einem Vers beschenken.", "tokens": ["Will", "ich", "den", "Die\u00b7ner", "selbst", "mit", "ei\u00b7nem", "Vers", "be\u00b7schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Ich gebe gar zu gern. Er merkt mir schon den Tag,", "tokens": ["Ich", "ge\u00b7be", "gar", "zu", "gern", ".", "Er", "merkt", "mir", "schon", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKA", "ADV", "$.", "PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Da er mich melden darf, und auch den Zeigerschlag.", "tokens": ["Da", "er", "mich", "mel\u00b7den", "darf", ",", "und", "auch", "den", "Zei\u00b7ger\u00b7schlag", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Begegnet mir der Herr, so eil' ich ihm zur Seiten;", "tokens": ["Be\u00b7geg\u00b7net", "mir", "der", "Herr", ",", "so", "eil'", "ich", "ihm", "zur", "Sei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Ich will vom Rathhaus ihn bis an sein Haus begleiten,", "tokens": ["Ich", "will", "vom", "Rath\u00b7haus", "ihn", "bis", "an", "sein", "Haus", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Oft gegenw\u00e4rtig sein: kraft eines Unterrichts,", "tokens": ["Oft", "ge\u00b7gen\u00b7w\u00e4r\u00b7tig", "sein", ":", "kraft", "ei\u00b7nes", "Un\u00b7ter\u00b7richts", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAINF", "$.", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Den jener Waidmann gab: Jagt; sonsten fangt ihr nichts.\u00ab", "tokens": ["Den", "je\u00b7ner", "Waid\u00b7mann", "gab", ":", "Jagt", ";", "sons\u00b7ten", "fangt", "ihr", "nichts", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PDAT", "NN", "VVFIN", "$.", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PIS", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "So sprach, doch nein! so schrie der unersch\u00f6pfte Schw\u00e4tzer,", "tokens": ["So", "sprach", ",", "doch", "nein", "!", "so", "schrie", "der", "un\u00b7er\u00b7sch\u00f6pf\u00b7te", "Schw\u00e4t\u00b7zer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "PTKANT", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als nun mein Liscow kam: (der Bruder von dem Ketzer,", "tokens": ["Als", "nun", "mein", "Lis\u00b7cow", "kam", ":(", "der", "Bru\u00b7der", "von", "dem", "Ket\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "word", "emoticon", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NE", "VVFIN", "$(", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den noch Germanicus vielleicht dereinst bekehrt)", "tokens": ["Den", "noch", "Ger\u00b7ma\u00b7ni\u00b7cus", "viel\u00b7leicht", "de\u00b7reinst", "be\u00b7kehrt", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NE", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der kannte meinen Mann und seinen ganzen Werth.", "tokens": ["Der", "kann\u00b7te", "mei\u00b7nen", "Mann", "und", "sei\u00b7nen", "gan\u00b7zen", "Werth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir bleiben also stehn. Indem wir uns befragen:", "tokens": ["Wir", "blei\u00b7ben", "al\u00b7so", "stehn", ".", "In\u00b7dem", "wir", "uns", "be\u00b7fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVINF", "$.", "KOUS", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Woher jetzt, und wohin? und uns die Antwort sagen,", "tokens": ["Wo\u00b7her", "jetzt", ",", "und", "wo\u00b7hin", "?", "und", "uns", "die", "Ant\u00b7wort", "sa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "KON", "PWAV", "$.", "KON", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zupf' ich ihn bei dem Arm, durch ihn mich frei zu sehn;", "tokens": ["Zupf'", "ich", "ihn", "bei", "dem", "Arm", ",", "durch", "ihn", "mich", "frei", "zu", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "APPR", "ART", "NN", "$,", "APPR", "PPER", "PRF", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch der verstockte Schalk lacht und will nichts verstehn.", "tokens": ["Doch", "der", "ver\u00b7stock\u00b7te", "Schalk", "lacht", "und", "will", "nichts", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "KON", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Ich wink' ihm, recht im Zorn, weil alle Winke fehlen.", "tokens": ["Ich", "wink'", "ihm", ",", "recht", "im", "Zorn", ",", "weil", "al\u00b7le", "Win\u00b7ke", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADV", "APPRART", "NN", "$,", "KOUS", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie? wollten Sie mir nicht was insgeheim erz\u00e4hlen?", "tokens": ["Wie", "?", "woll\u00b7ten", "Sie", "mir", "nicht", "was", "ins\u00b7ge\u00b7heim", "er\u00b7z\u00e4h\u00b7len", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VMFIN", "PPER", "PPER", "PTKNEG", "PWS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u00bbja: etwas Wichtiges; allein zur andern Zeit,", "tokens": ["\u00bb", "ja", ":", "et\u00b7was", "Wich\u00b7ti\u00b7ges", ";", "al\u00b7lein", "zur", "an\u00b7dern", "Zeit", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKANT", "$.", "ADV", "ADJA", "$.", "ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Denn heute wird von mir der Nisan nicht entweiht.", "tokens": ["Denn", "heu\u00b7te", "wird", "von", "mir", "der", "Ni\u00b7san", "nicht", "ent\u00b7weiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "APPR", "PPER", "ART", "NE", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Das auserw\u00e4hlte Volk aus Abrahams Geschlechte", "tokens": ["Das", "au\u00b7ser\u00b7w\u00e4hl\u00b7te", "Volk", "aus", "Ab\u00b7ra\u00b7hams", "Ge\u00b7schlech\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Verzehrt sein Osterlamm und freut sich seiner Rechte.\u00ab", "tokens": ["Ver\u00b7zehrt", "sein", "Os\u00b7ter\u00b7lamm", "und", "freut", "sich", "sei\u00b7ner", "Rech\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "PRF", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die Scrupel solcher Art, mein Herr, verschonen mich.", "tokens": ["Die", "Scru\u00b7pel", "sol\u00b7cher", "Art", ",", "mein", "Herr", ",", "ver\u00b7scho\u00b7nen", "mich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u00bbdoch mir und Tausenden sind Scrupel f\u00fcrchterlich.", "tokens": ["\u00bb", "doch", "mir", "und", "Tau\u00b7sen\u00b7den", "sind", "Scru\u00b7pel", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "KON", "NN", "VAFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Verh\u00f6hnen Sie so sehr der Juden Glaubenszeichen,", "tokens": ["Ver\u00b7h\u00f6h\u00b7nen", "Sie", "so", "sehr", "der", "Ju\u00b7den", "Glau\u00b7bens\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die, dem Gewissen nach, so vielen Christen gleichen?", "tokens": ["Die", ",", "dem", "Ge\u00b7wis\u00b7sen", "nach", ",", "so", "vie\u00b7len", "Chris\u00b7ten", "glei\u00b7chen", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "ART", "NN", "PTKVZ", "$,", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Entschuldigen Sie mich: ich sprech' ein andermal.\u00ab", "tokens": ["Ent\u00b7schul\u00b7di\u00b7gen", "Sie", "mich", ":", "ich", "sprech'", "ein", "an\u00b7der\u00b7mal", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$.", "PPER", "VVFIN", "ART", "ADV", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "O schwarzer Ungl\u00fcckstag, was bringst du mir f\u00fcr Qual!", "tokens": ["O", "schwar\u00b7zer", "Un\u00b7gl\u00fccks\u00b7tag", ",", "was", "bringst", "du", "mir", "f\u00fcr", "Qual", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PWS", "VVFIN", "PPER", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Unbarmherzige, der Sp\u00f6tter, geht, und fliehet,", "tokens": ["Der", "Un\u00b7barm\u00b7her\u00b7zi\u00b7ge", ",", "der", "Sp\u00f6t\u00b7ter", ",", "geht", ",", "und", "flie\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "VVFIN", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Obgleich er \u00fcber mir das gro\u00dfe Messer siehet,", "tokens": ["Ob\u00b7gleich", "er", "\u00fc\u00b7ber", "mir", "das", "gro\u00b7\u00dfe", "Mes\u00b7ser", "sie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit dem der Prahler ficht. Allein, wer zeigt sich dort?", "tokens": ["Mit", "dem", "der", "Prah\u00b7ler", "ficht", ".", "Al\u00b7lein", ",", "wer", "zeigt", "sich", "dort", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "PTKVZ", "$.", "ADV", "$,", "PWS", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Gegner k\u00f6mmt und schreit: \u00bbWohin, Nichtsw\u00fcrd'ger? Fort!\u00ab", "tokens": ["Sein", "Geg\u00b7ner", "k\u00f6mmt", "und", "schreit", ":", "\u00bb", "Wo\u00b7hin", ",", "Nichts\u00b7w\u00fcrd'\u00b7ger", "?", "Fort", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "ADJD", "$.", "$(", "PWAV", "$,", "NN", "$.", "NN", "$.", "$("], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.6": {"text": "Und sagt im Scherz zu mir: \u00bbD\u00fcrft' ich Sie zeugen lassen!\u00ab", "tokens": ["Und", "sagt", "im", "Scherz", "zu", "mir", ":", "\u00bb", "D\u00fcrft'", "ich", "Sie", "zeu\u00b7gen", "las\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "APPR", "PPER", "$.", "$(", "VMFIN", "PPER", "PPER", "VVFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja! m\u00fc\u00dft' auch Ihre Hand mein Ohr, auf r\u00f6misch, fassen.", "tokens": ["Ja", "!", "m\u00fc\u00dft'", "auch", "Ih\u00b7re", "Hand", "mein", "Ohr", ",", "auf", "r\u00f6\u00b7misch", ",", "fas\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "$.", "VMFIN", "ADV", "PPOSAT", "NN", "PPOSAT", "NN", "$,", "APPR", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Er schleppt ihn vor Gericht: man l\u00e4rmt, man ruft und schilt:", "tokens": ["Er", "schleppt", "ihn", "vor", "Ge\u00b7richt", ":", "man", "l\u00e4rmt", ",", "man", "ruft", "und", "schilt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "$.", "PIS", "VVFIN", "$,", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und alles l\u00e4uft herbei, zu sehen, wem es gilt.", "tokens": ["Und", "al\u00b7les", "l\u00e4uft", "her\u00b7bei", ",", "zu", "se\u00b7hen", ",", "wem", "es", "gilt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PTKVZ", "$,", "PTKZU", "VVINF", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So hat mich dem Verdru\u00df, den ich erdulden m\u00fcssen,", "tokens": ["So", "hat", "mich", "dem", "Ver\u00b7dru\u00df", ",", "den", "ich", "er\u00b7dul\u00b7den", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "ART", "NN", "$,", "PRELS", "PPER", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Gott, den K\u00e4uflin kennt, Apollo selbst entrissen.", "tokens": ["Der", "Gott", ",", "den", "K\u00e4uf\u00b7lin", "kennt", ",", "A\u00b7pol\u00b7lo", "selbst", "ent\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "NE", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}