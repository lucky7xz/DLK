{"textgrid.poem.59891": {"metadata": {"author": {"name": "Bodenstedt, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ja, ja! in seinen Versen spricht er", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ja, ja! in seinen Versen spricht er", "tokens": ["Ja", ",", "ja", "!", "in", "sei\u00b7nen", "Ver\u00b7sen", "spricht", "er"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "$.", "APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Viel von Gem\u00fct, ist fromm und zart,", "tokens": ["Viel", "von", "Ge\u00b7m\u00fct", ",", "ist", "fromm", "und", "zart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein keuscher Joseph ohne Bart.", "tokens": ["Ein", "keu\u00b7scher", "Jo\u00b7se\u00b7ph", "oh\u00b7ne", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "APPR", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Drum h\u00e4lt die Welt ihn auch gew\u00f6hnlich", "tokens": ["Drum", "h\u00e4lt", "die", "Welt", "ihn", "auch", "ge\u00b7w\u00f6hn\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr so gem\u00fctlich; doch pers\u00f6nlich", "tokens": ["F\u00fcr", "so", "ge\u00b7m\u00fct\u00b7lich", ";", "doch", "per\u00b7s\u00f6n\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADV", "ADJD", "$.", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ist er ein Schlingel eigner Art,", "tokens": ["Ist", "er", "ein", "Schlin\u00b7gel", "eig\u00b7ner", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Grobian von unten bis nach oben.", "tokens": ["Ein", "Gro\u00b7bi\u00b7an", "von", "un\u00b7ten", "bis", "nach", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "ADV", "APPR", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und das ist noch zumeist an ihm zu loben!", "tokens": ["Und", "das", "ist", "noch", "zu\u00b7meist", "an", "ihm", "zu", "lo\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "ADV", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "W\u00e4r' er so zart wie seine Lieder,", "tokens": ["W\u00e4r'", "er", "so", "zart", "wie", "sei\u00b7ne", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So ohne Sinn:", "tokens": ["So", "oh\u00b7ne", "Sinn", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "W\u00e4r' mir der Kerl noch mehr zuwider", "tokens": ["W\u00e4r'", "mir", "der", "Kerl", "noch", "mehr", "zu\u00b7wi\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Als ohnehin.", "tokens": ["Als", "oh\u00b7ne\u00b7hin", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}