{"dta.poem.20117": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Chevy-Chase  \n oder  \n  Die Jagd im Chevy-Forst.  \n (Nach dem Alt-Englischen.)", "genre": "Lyrik", "period": "N.A.", "pub_year": "1851", "urn": "urn:nbn:de:kobv:b4-200905191321", "language": ["de:0.99"], "booktitle": "Fontane, Theodor: Gedichte. Berlin, 1851."}, "poem": {"stanza.1": {"line.1": {"text": "Gott sch\u00fctz\u2019 den K\u00f6nig, unsren Herrn,", "tokens": ["Gott", "sch\u00fctz'", "den", "K\u00f6\u00b7nig", ",", "un\u00b7sren", "Herrn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und unser Aller Leben; \u2014 \u2014", "tokens": ["Und", "un\u00b7ser", "Al\u00b7ler", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Im Chevy-Walde hat sich einst", "tokens": ["Im", "Che\u00b7vy\u00b7Wal\u00b7de", "hat", "sich", "einst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wehvolle Jagd begeben. \u2014", "tokens": ["Weh\u00b7vol\u00b7le", "Jagd", "be\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VVPP", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Graf Percy von Northumberland,", "tokens": ["Graf", "Per\u00b7cy", "von", "Nor\u00b7thum\u00b7ber\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Vor Thaue noch und Tage", "tokens": ["Vor", "Thau\u00b7e", "noch", "und", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zog aus er heut, mit Hund und Horn,", "tokens": ["Zog", "aus", "er", "heut", ",", "mit", "Hund", "und", "Horn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADV", "$,", "APPR", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er den Hirsch erjage.", "tokens": ["Da\u00df", "er", "den", "Hirsch", "er\u00b7ja\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Er schwur es j\u00fcngst an heilger St\u00e4tt\u2019,", "tokens": ["Er", "schwur", "es", "j\u00fcngst", "an", "heil\u00b7ger", "St\u00e4tt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2014 Sorglos um Groll und Knirschen, \u2014", "tokens": ["Sorg\u00b7los", "um", "Groll", "und", "Knir\u00b7schen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "APPR", "NN", "KON", "NN", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er woll drei Sommertage lang", "tokens": ["Er", "woll", "drei", "Som\u00b7mer\u00b7ta\u00b7ge", "lang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "CARD", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf schottschem Boden pirschen.", "tokens": ["Auf", "schott\u00b7schem", "Bo\u00b7den", "pir\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Er woll, was lebt im Chevy-Forst", "tokens": ["Er", "woll", ",", "was", "lebt", "im", "Che\u00b7vy\u00b7Forst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "PWS", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Speer und Pfeil erlegen;", "tokens": ["Mit", "Speer", "und", "Pfeil", "er\u00b7le\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201elord Douglas sch\u00fctze, wenn er kann,", "tokens": ["\u201e", "lord", "Doug\u00b7las", "sch\u00fct\u00b7ze", ",", "wenn", "er", "kann", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "NE", "VVFIN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Hirsch in den Gehegen!\u201c", "tokens": ["Den", "Hirsch", "in", "den", "Ge\u00b7he\u00b7gen", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Lord Douglas, der in Schottland lag,", "tokens": ["Lord", "Doug\u00b7las", ",", "der", "in", "Schott\u00b7land", "lag", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PRELS", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als er das Wort vernommen,", "tokens": ["Als", "er", "das", "Wort", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dem Percy Grafen schw\u00f6rt er da", "tokens": ["Dem", "Per\u00b7cy", "Gra\u00b7fen", "schw\u00f6rt", "er", "da"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein blutiges Willkommen;", "tokens": ["Ein", "blu\u00b7ti\u00b7ges", "Will\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Der aber ist im Walde schon", "tokens": ["Der", "a\u00b7ber", "ist", "im", "Wal\u00b7de", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VAFIN", "APPRART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit f\u00fcnfzehn hundert Mannen,", "tokens": ["Mit", "f\u00fcnf\u00b7zehn", "hun\u00b7dert", "Man\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wohlausgesucht und wohlgeprobt", "tokens": ["Wohl\u00b7aus\u00b7ge\u00b7sucht", "und", "wohl\u00b7ge\u00b7probt"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Bogen straff zu spannen.", "tokens": ["Den", "Bo\u00b7gen", "straff", "zu", "span\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Schon, von der Meute aufgeschreckt,", "tokens": ["Schon", ",", "von", "der", "Meu\u00b7te", "auf\u00b7ge\u00b7schreckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Flieht, was die Schlucht geborgen;", "tokens": ["Flieht", ",", "was", "die", "Schlucht", "ge\u00b7bor\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Montag war\u2019s, \u2014 noch halbe Nacht, \u2014", "tokens": ["Ein", "Mon\u00b7tag", "wa\u00b7r's", ",", "noch", "hal\u00b7be", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "$(", "ADV", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es graute just im Morgen.", "tokens": ["Es", "grau\u00b7te", "just", "im", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und eh\u2019 der Mittag kam, da lag", "tokens": ["Und", "eh'", "der", "Mit\u00b7tag", "kam", ",", "da", "lag"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Haufweis das Wild erschlagen;", "tokens": ["Hauf\u00b7weis", "das", "Wild", "er\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch rastlos, nach gethanem Schmaus", "tokens": ["Doch", "rast\u00b7los", ",", "nach", "ge\u00b7tha\u00b7nem", "Schmaus"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Begann ein neues Jagen.", "tokens": ["Be\u00b7gann", "ein", "neu\u00b7es", "Ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Auf\u2019s Neu durch Schlucht und Dickicht hin", "tokens": ["Auf's", "Neu", "durch", "Schlucht", "und", "Di\u00b7ckicht", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stob Huf und Hund nach Beute,", "tokens": ["Stob", "Huf", "und", "Hund", "nach", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und neuer Angstschrei mischte sich", "tokens": ["Und", "neu\u00b7er", "Angst\u00b7schrei", "mischte", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem Lustgeheul der Meute.", "tokens": ["Dem", "Lust\u00b7ge\u00b7heul", "der", "Meu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Graf Percy nur war satt des Spiels", "tokens": ["Graf", "Per\u00b7cy", "nur", "war", "satt", "des", "Spiels"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADV", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Hirschen und mit Hinden,", "tokens": ["Mit", "Hir\u00b7schen", "und", "mit", "Hin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er sprach: \u201eLord Douglas gab sein Wort,", "tokens": ["Er", "sprach", ":", "\u201e", "Lord", "Doug\u00b7las", "gab", "sein", "Wort", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "NN", "NE", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier soll ich heut ihn finden.", "tokens": ["Hier", "soll", "ich", "heut", "ihn", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u201ebei Gott, nicht l\u00e4nger harrt\u2019 ich sein,", "tokens": ["\u201e", "bei", "Gott", ",", "nicht", "l\u00e4n\u00b7ger", "harrt'", "ich", "sein", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$,", "PTKNEG", "ADJD", "VVFIN", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D\u00e4cht\u2019 ich, er k\u00f6nn\u2019 es brechen\u201c;", "tokens": ["D\u00e4cht'", "ich", ",", "er", "k\u00f6nn'", "es", "bre\u00b7chen", "\u201c", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$(", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da th\u00e4t alsbald ein Ritter jung", "tokens": ["Da", "th\u00e4t", "als\u00b7bald", "ein", "Rit\u00b7ter", "jung"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Also zum Grafen sprechen:", "tokens": ["Al\u00b7so", "zum", "Gra\u00b7fen", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "\u201eschau Herr, dort blitzt es durch den Wald,", "tokens": ["\u201e", "schau", "Herr", ",", "dort", "blitzt", "es", "durch", "den", "Wald", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ist er mit den Seinen;", "tokens": ["Das", "ist", "er", "mit", "den", "Sei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "APPR", "ART", "PPOSS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schau, wie im Mittagssonnengl\u00fchn", "tokens": ["Schau", ",", "wie", "im", "Mit\u00b7tags\u00b7son\u00b7nen\u00b7gl\u00fchn"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "APPRART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Die blanken Speere scheinen.", "tokens": ["Die", "blan\u00b7ken", "Spee\u00b7re", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u201ezweitausend sind\u2019s vom Lauf des Tweed,", "tokens": ["\u201e", "zweit\u00b7au\u00b7send", "sin\u00b7d's", "vom", "Lauf", "des", "Tweed", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "APPRART", "NN", "ART", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus Th\u00e4lern und aus Glennen,", "tokens": ["Aus", "Th\u00e4\u00b7lern", "und", "aus", "Glen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und der vorauf ist Douglas selbst", "tokens": ["Und", "der", "vor\u00b7auf", "ist", "Doug\u00b7las", "selbst"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "VAFIN", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An Ro\u00df und Helm zu kennen.\u201c", "tokens": ["An", "Ro\u00df", "und", "Helm", "zu", "ken\u00b7nen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u201enun denn, wohlan!\u201c rief Percy da,", "tokens": ["\u201e", "nun", "denn", ",", "wo\u00b7hlan", "!", "\u201c", "rief", "Per\u00b7cy", "da", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$,", "ADV", "$.", "$(", "VVFIN", "NE", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edies Feld sei unsre Schranke,", "tokens": ["\u201e", "dies", "Feld", "sei", "uns\u00b7re", "Schran\u00b7ke", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Noch schl\u00fcpfte keiner mir hindurch,", "tokens": ["Noch", "schl\u00fcpf\u00b7te", "kei\u00b7ner", "mir", "hin\u00b7durch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sei\u2019s Schotte oder Franke.", "tokens": ["Sei's", "Schot\u00b7te", "o\u00b7der", "Fran\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "\u201edas ist der Hirsch, den ich gesucht,", "tokens": ["\u201e", "das", "ist", "der", "Hirsch", ",", "den", "ich", "ge\u00b7sucht", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun lohnt es sich zu jagen,", "tokens": ["Nun", "lohnt", "es", "sich", "zu", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es brennt mein Herz Mann gegen Mann", "tokens": ["Es", "brennt", "mein", "Herz", "Mann", "ge\u00b7gen", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "APPR", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Mit ihm die Schlacht zu schlagen.\u201c", "tokens": ["Mit", "ihm", "die", "Schlacht", "zu", "schla\u00b7gen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Lord Douglas auf milchwei\u00dfem Ro\u00df,", "tokens": ["Lord", "Doug\u00b7las", "auf", "milch\u00b7wei\u00b7\u00dfem", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt hoch vor den Genossen,", "tokens": ["H\u00e4lt", "hoch", "vor", "den", "Ge\u00b7nos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hell gl\u00e4nzt die Eisenr\u00fcstung, wie", "tokens": ["Hell", "gl\u00e4nzt", "die", "Ei\u00b7sen\u00b7r\u00fcs\u00b7tung", ",", "wie"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NE", "VVFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Golde \u00fcbergossen;", "tokens": ["Von", "Gol\u00b7de", "\u00fc\u00b7ber\u00b7gos\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Er ruft: \u201ewer seid ihr, die ihr\u2019s wagt", "tokens": ["Er", "ruft", ":", "\u201e", "wer", "seid", "ihr", ",", "die", "ih\u00b7r's", "wagt"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWS", "VAFIN", "PPER", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mir Hirsch und Reh zu t\u00f6dten,", "tokens": ["Mir", "Hirsch", "und", "Reh", "zu", "t\u00f6d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und meines Wortes bar und blos", "tokens": ["Und", "mei\u00b7nes", "Wor\u00b7tes", "bar", "und", "blos"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Forst mit Blut zu r\u00f6then!\u201c", "tokens": ["Den", "Forst", "mit", "Blut", "zu", "r\u00f6\u00b7then", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Drauf Percy schnell: \u201eein andermal", "tokens": ["Drauf", "Per\u00b7cy", "schnell", ":", "\u201e", "ein", "an\u00b7der\u00b7mal"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PAV", "NE", "ADJD", "$.", "$(", "ART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf we\u00df Gehei\u00df wir jagen,", "tokens": ["Auf", "we\u00df", "Ge\u00b7hei\u00df", "wir", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Heut denken wir noch manchen Hirsch", "tokens": ["Heut", "den\u00b7ken", "wir", "noch", "man\u00b7chen", "Hirsch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Trotz Deiner zu erschlagen.\u201c", "tokens": ["Trotz", "Dei\u00b7ner", "zu", "er\u00b7schla\u00b7gen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Lord Douglas h\u00f6rt\u2019s, er ruft in Wuth:", "tokens": ["Lord", "Doug\u00b7las", "h\u00f6rt's", ",", "er", "ruft", "in", "Wuth", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eda soll mich Gott verderben!", "tokens": ["\u201e", "da", "soll", "mich", "Gott", "ver\u00b7der\u00b7ben", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So wahr ein Lord ich bin, wie Du,", "tokens": ["So", "wahr", "ein", "Lord", "ich", "bin", ",", "wie", "Du", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "PPER", "VAFIN", "$,", "PWAV", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du oder ich mu\u00df sterben.", "tokens": ["Du", "o\u00b7der", "ich", "mu\u00df", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "\u201edoch h\u00f6r\u2019 mich Percy, Schande w\u00e4r\u2019s", "tokens": ["\u201e", "doch", "h\u00f6r'", "mich", "Per\u00b7cy", ",", "Schan\u00b7de", "w\u00e4r's"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "ADV", "VVFIN", "PPER", "NE", "$,", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Schimpf an unsrem Leben,", "tokens": ["Und", "Schimpf", "an", "uns\u00b7rem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So vieler Mannen schuldlos Blut", "tokens": ["So", "vie\u00b7ler", "Man\u00b7nen", "schuld\u00b7los", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit in den Kauf zu geben;", "tokens": ["Mit", "in", "den", "Kauf", "zu", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "\u201ees sei all unser Streit gelegt", "tokens": ["\u201e", "es", "sei", "all", "un\u00b7ser", "Streit", "ge\u00b7legt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "PIAT", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In unsre beiden Speere!\u201c", "tokens": ["In", "uns\u00b7re", "bei\u00b7den", "Spee\u00b7re", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201everdammt sei der \u2014 rief Percy da \u2014", "tokens": ["\u201e", "ver\u00b7dammt", "sei", "der", "rief", "Per\u00b7cy", "da"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "ART", "$(", "VVFIN", "NE", "ADV", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der andren Sinnes w\u00e4re.\u201c", "tokens": ["Der", "an\u00b7dren", "Sin\u00b7nes", "w\u00e4\u00b7re", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Da trat ein Rittersmann herf\u00fcr,", "tokens": ["Da", "trat", "ein", "Rit\u00b7ters\u00b7mann", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "With\u2019rington hie\u00df der Degen,", "tokens": ["With'\u00b7ring\u00b7ton", "hie\u00df", "der", "De\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der sprach: \u201ehier m\u00fc\u00dfig zuzuschaun", "tokens": ["Der", "sprach", ":", "\u201e", "hier", "m\u00fc\u00b7\u00dfig", "zu\u00b7zu\u00b7schaun"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$.", "$(", "ADV", "ADJD", "VVIZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dran ist uns nicht gelegen.", "tokens": ["Dran", "ist", "uns", "nicht", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "\u201ewir wollen nicht, dieweil ihr k\u00e4mpft,", "tokens": ["\u201e", "wir", "wol\u00b7len", "nicht", ",", "die\u00b7weil", "ihr", "k\u00e4mpft", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hier Psalm und Lieder singen,", "tokens": ["Hier", "Psalm", "und", "Lie\u00b7der", "sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und unsrem K\u00f6nig Heinrich dann", "tokens": ["Und", "uns\u00b7rem", "K\u00f6\u00b7nig", "Hein\u00b7rich", "dann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So saubre Botschaft bringen.", "tokens": ["So", "saub\u00b7re", "Bot\u00b7schaft", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "\u201ewohl seid Ihr Lords und edle Herrn,", "tokens": ["\u201e", "wohl", "seid", "Ihr", "Lords", "und", "ed\u00b7le", "Herrn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wir nur Knapp und Ritter,", "tokens": ["Und", "wir", "nur", "Knapp", "und", "Rit\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch d\u00e4cht\u2019 ich traun, auch unser Schwert", "tokens": ["Doch", "d\u00e4cht'", "ich", "traun", ",", "auch", "un\u00b7ser", "Schwert"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "VVINF", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Macht Wunden wohl und Splitter!\u201c", "tokens": ["Macht", "Wun\u00b7den", "wohl", "und", "Split\u00b7ter", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "ADV", "KON", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Da th\u00e4t alsbald all englisch Volk", "tokens": ["Da", "th\u00e4t", "als\u00b7bald", "all", "eng\u00b7lisch", "Volk"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Eschenbogen biegen,", "tokens": ["Den", "E\u00b7schen\u00b7bo\u00b7gen", "bie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und achtzig Schotten sanken hin", "tokens": ["Und", "acht\u00b7zig", "Schot\u00b7ten", "san\u00b7ken", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "CARD", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von ihrer Pfeile Fliegen.", "tokens": ["Von", "ih\u00b7rer", "Pfei\u00b7le", "Flie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}