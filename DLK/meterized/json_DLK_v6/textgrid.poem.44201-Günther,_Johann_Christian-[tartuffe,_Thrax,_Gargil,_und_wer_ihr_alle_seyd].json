{"textgrid.poem.44201": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "[tartuffe, Thrax, Gargil, und wer ihr alle seyd]", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tartuffe, Thrax", "tokens": ["Tar\u00b7tuf\u00b7fe", ",", "Thrax"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "XY"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Die ihr am Helicon als Thorheitsm\u00e4rtrer leidet,", "tokens": ["Die", "ihr", "am", "He\u00b7li\u00b7con", "als", "Thor\u00b7heits\u00b7m\u00e4r\u00b7trer", "lei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die ihr bis diesen Tag zum Theil auf Hecheln schreyt,", "tokens": ["Die", "ihr", "bis", "die\u00b7sen", "Tag", "zum", "Theil", "auf", "He\u00b7cheln", "schreyt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PDAT", "NN", "APPRART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zum Theil wie Marsyas das nackte Fleisch entkleidet,", "tokens": ["Zum", "Theil", "wie", "Mar\u00b7syas", "das", "nack\u00b7te", "Fleisch", "ent\u00b7klei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KOKOM", "NE", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Seyd froh, nunmehr erscheint das Ziel erlidtner Schmach,", "tokens": ["Seyd", "froh", ",", "nun\u00b7mehr", "er\u00b7scheint", "das", "Ziel", "er\u00b7lidt\u00b7ner", "Schmach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Bl\u00f6\u00dfe des Crispins", "tokens": ["Die", "Bl\u00f6\u00b7\u00dfe", "des", "Cris\u00b7pins"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Macht Plaz, er nimmt den Rang; der Schaum von eurer Bande", "tokens": ["Macht", "Plaz", ",", "er", "nimmt", "den", "Rang", ";", "der", "Schaum", "von", "eu\u00b7rer", "Ban\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$.", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Geht ihm, so klein er ist, an grober Bo\u00dfheit nach.", "tokens": ["Geht", "ihm", ",", "so", "klein", "er", "ist", ",", "an", "gro\u00b7ber", "Bo\u00df\u00b7heit", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Jezt habt ihr Fug und Recht, die Dichter zu verklagen,", "tokens": ["Jezt", "habt", "ihr", "Fug", "und", "Recht", ",", "die", "Dich\u00b7ter", "zu", "ver\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "KON", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die euch der Ewigkeit so he\u00dflich vorgetragen.", "tokens": ["Die", "euch", "der", "E\u00b7wig\u00b7keit", "so", "he\u00df\u00b7lich", "vor\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es wiederrufe nun des Moliere Geist,", "tokens": ["Es", "wie\u00b7der\u00b7ru\u00b7fe", "nun", "des", "Mo\u00b7lie\u00b7re", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Despreaux bequeme sich, den Narren abzubitten,", "tokens": ["De\u00b7sprea\u00b7ux", "be\u00b7que\u00b7me", "sich", ",", "den", "Nar\u00b7ren", "ab\u00b7zu\u00b7bit\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Menage k\u00fc\u00dfe den, den seine Feder bei\u00dft,", "tokens": ["Me\u00b7na\u00b7ge", "k\u00fc\u00b7\u00dfe", "den", ",", "den", "sei\u00b7ne", "Fe\u00b7der", "bei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es werd Eutrop nicht mehr vom Claudian verschnidten.", "tokens": ["Es", "werd", "Eu\u00b7trop", "nicht", "mehr", "vom", "Clau\u00b7di\u00b7an", "ver\u00b7schnid\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "PTKNEG", "ADV", "APPRART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bramarbas", "tokens": ["Bra\u00b7mar\u00b7bas"], "token_info": ["word"], "pos": ["NE"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Und man entschuldige den armen Leporander", "tokens": ["Und", "man", "ent\u00b7schul\u00b7di\u00b7ge", "den", "ar\u00b7men", "Le\u00b7po\u00b7ran\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die St\u00fcmper \u00fcberhaupt, die Sp\u00f6tter miteinander", "tokens": ["Die", "St\u00fcm\u00b7per", "\u00fc\u00b7ber\u00b7haupt", ",", "die", "Sp\u00f6t\u00b7ter", "mi\u00b7tein\u00b7an\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "ART", "NN", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sind unter dem Crispin im kleinern vorgestellt", "tokens": ["Sind", "un\u00b7ter", "dem", "Cris\u00b7pin", "im", "klei\u00b7nern", "vor\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "APPRART", "ADJA", "VVFIN"], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und scheinen, sezt man sie dem Pfuscher an die Seite,", "tokens": ["Und", "schei\u00b7nen", ",", "sezt", "man", "sie", "dem", "Pfu\u00b7scher", "an", "die", "Sei\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "PIS", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So tumm, so arg sie sind, noch klug- und fromme Leute.", "tokens": ["So", "tumm", ",", "so", "arg", "sie", "sind", ",", "noch", "klug", "und", "from\u00b7me", "Leu\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "ADV", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ihr Musen, ist es nicht ein unverdienter Lohn,", "tokens": ["Ihr", "Mu\u00b7sen", ",", "ist", "es", "nicht", "ein", "un\u00b7ver\u00b7dien\u00b7ter", "Lohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den eure Mildigkeit um Haar und Scheitel windet,", "tokens": ["Den", "eu\u00b7re", "Mil\u00b7dig\u00b7keit", "um", "Haar", "und", "Schei\u00b7tel", "win\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So st\u00e4upt, so z\u00fcchtigt mir den geilen Midas-Sohn,", "tokens": ["So", "st\u00e4upt", ",", "so", "z\u00fcch\u00b7tigt", "mir", "den", "gei\u00b7len", "Mi\u00b7das\u00b7Sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bis sein vertracktes Fell die sp\u00e4te Reu empfindet.", "tokens": ["Bis", "sein", "ver\u00b7track\u00b7tes", "Fell", "die", "sp\u00e4\u00b7te", "Reu", "emp\u00b7fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr seht, er will mit Macht der Strafe w\u00fcrdig seyn,", "tokens": ["Ihr", "seht", ",", "er", "will", "mit", "Macht", "der", "Stra\u00b7fe", "w\u00fcr\u00b7dig", "seyn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VMFIN", "APPR", "NN", "ART", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es klaubt sein Unverstand zur Nahrung neidscher Flammen", "tokens": ["Es", "klaubt", "sein", "Un\u00b7ver\u00b7stand", "zur", "Nah\u00b7rung", "neid\u00b7scher", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hier einen Weiberspruch, dort einen Reim zusammen,", "tokens": ["Hier", "ei\u00b7nen", "Wei\u00b7ber\u00b7spruch", ",", "dort", "ei\u00b7nen", "Reim", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Um den verwegnen Gift mit Fudern auszuspein.", "tokens": ["Um", "den", "ver\u00b7weg\u00b7nen", "Gift", "mit", "Fu\u00b7dern", "aus\u00b7zu\u00b7spein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gew\u00e4hrt, wornach er ringt, und last den Kl\u00fcgling f\u00fchlen,", "tokens": ["Ge\u00b7w\u00e4hrt", ",", "wor\u00b7nach", "er", "ringt", ",", "und", "last", "den", "Kl\u00fcg\u00b7ling", "f\u00fch\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df Schweine nicht umsonst in euren G\u00e4rthen w\u00fchlen!", "tokens": ["Da\u00df", "Schwei\u00b7ne", "nicht", "um\u00b7sonst", "in", "eu\u00b7ren", "G\u00e4r\u00b7then", "w\u00fch\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Dir, Warheit, eignet sich die Zuschrift und das Lied,", "tokens": ["Dir", ",", "War\u00b7heit", ",", "eig\u00b7net", "sich", "die", "Zu\u00b7schrift", "und", "das", "Lied", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "VVFIN", "PRF", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von nun an sey dein Wort die Richtschnur meiner Saythen;", "tokens": ["Von", "nun", "an", "sey", "dein", "Wort", "die", "Richt\u00b7schnur", "mei\u00b7ner", "Say\u00b7then", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VAFIN", "PPOSAT", "NN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wen deine Gei\u00dfel schmeist, wem deine Gnade bl\u00fcht,", "tokens": ["Wen", "dei\u00b7ne", "Gei\u00b7\u00dfel", "schmeist", ",", "wem", "dei\u00b7ne", "Gna\u00b7de", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "PWS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der soll durch Laster Schimpf, durch Tugend Ruhm erbeuten.", "tokens": ["Der", "soll", "durch", "Las\u00b7ter", "Schimpf", ",", "durch", "Tu\u00b7gend", "Ruhm", "er\u00b7beu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "APPR", "NN", "NN", "$,", "APPR", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer Unverdiente lobt, der hab am L\u00e4stern Lust,", "tokens": ["Wer", "Un\u00b7ver\u00b7dien\u00b7te", "lobt", ",", "der", "hab", "am", "L\u00e4s\u00b7tern", "Lust", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVFIN", "$,", "PRELS", "VAFIN", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein schmeichlerischer Hauch soll meinen Mund verla\u00dfen.", "tokens": ["Kein", "schmeich\u00b7le\u00b7ri\u00b7scher", "Hauch", "soll", "mei\u00b7nen", "Mund", "ver\u00b7la\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man mag das Schwerd aus Noth und nicht aus Rachgier fa\u00dfen,", "tokens": ["Man", "mag", "das", "Schwerd", "aus", "Noth", "und", "nicht", "aus", "Rach\u00b7gier", "fa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "APPR", "NN", "KON", "PTKNEG", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wirst du mein Friedensschild, mein Colbert, mein August,", "tokens": ["Wirst", "du", "mein", "Frie\u00b7dens\u00b7schild", ",", "mein", "Col\u00b7bert", ",", "mein", "Au\u00b7gust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "So hab ich H\u00fclfe gnug, wenn gleich die Plauder-K\u00e4the", "tokens": ["So", "hab", "ich", "H\u00fcl\u00b7fe", "gnug", ",", "wenn", "gleich", "die", "Plau\u00b7der\u00b7K\u00e4\u00b7the"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "ADV", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den schwermenden Crispin gem\u00fcnzten Vorschub th\u00e4te.", "tokens": ["Den", "schwer\u00b7men\u00b7den", "Cris\u00b7pin", "ge\u00b7m\u00fcnz\u00b7ten", "Vor\u00b7schub", "th\u00e4\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Das Kind der Finstern\u00fc\u00df, die wilde Barbarey,", "tokens": ["Das", "Kind", "der", "Fins\u00b7ter\u00b7n\u00fc\u00df", ",", "die", "wil\u00b7de", "Bar\u00b7ba\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ersah ihr altes Reich in der Elyser Gr\u00e4nzen.", "tokens": ["Er\u00b7sah", "ihr", "al\u00b7tes", "Reich", "in", "der", "E\u00b7ly\u00b7ser", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie sah es und erschrack und schalt und sann dabey", "tokens": ["Sie", "sah", "es", "und", "er\u00b7schrack", "und", "schalt", "und", "sann", "da\u00b7bey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "KON", "ADJD", "KON", "VVFIN", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf Mittel und Gewalt, die Ri\u00dfe zu erg\u00e4nzen.", "tokens": ["Auf", "Mit\u00b7tel", "und", "Ge\u00b7walt", ",", "die", "Ri\u00b7\u00dfe", "zu", "er\u00b7g\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Herold machte Lerm und rief die schwarze Schaar", "tokens": ["Ihr", "He\u00b7rold", "mach\u00b7te", "Lerm", "und", "rief", "die", "schwar\u00b7ze", "Schaar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Glieder ihres Staats in ein geheimes Zimmer,", "tokens": ["Der", "Glie\u00b7der", "ih\u00b7res", "Staats", "in", "ein", "ge\u00b7hei\u00b7mes", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das auf der Riesenh\u00f6h mit anderthalbem Schimmer", "tokens": ["Das", "auf", "der", "Rie\u00b7sen\u00b7h\u00f6h", "mit", "an\u00b7der\u00b7thal\u00b7bem", "Schim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "(so geizig ist die Not) genug zufrieden war.", "tokens": ["(", "so", "gei\u00b7zig", "ist", "die", "Not", ")", "ge\u00b7nug", "zu\u00b7frie\u00b7den", "war", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "VAFIN", "ART", "NN", "$(", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So bald nur der Befehl der Luft verk\u00fcndigt worden,", "tokens": ["So", "bald", "nur", "der", "Be\u00b7fehl", "der", "Luft", "ver\u00b7k\u00fcn\u00b7digt", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "ART", "NN", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bewegte sich ein Schwarm von S\u00fcden, West und Norden.", "tokens": ["Be\u00b7weg\u00b7te", "sich", "ein", "Schwarm", "von", "S\u00fc\u00b7den", ",", "West", "und", "Nor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die Thorheit hat den Staar, doch tappte sie voran,", "tokens": ["Die", "Thor\u00b7heit", "hat", "den", "Staar", ",", "doch", "tapp\u00b7te", "sie", "vo\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es musten sie ein Grei\u00df und sieben Kinder leiten;", "tokens": ["Es", "mus\u00b7ten", "sie", "ein", "Grei\u00df", "und", "sie\u00b7ben", "Kin\u00b7der", "lei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "KON", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Schein hing Masquen vor, die Hoffart trat die Bahn,", "tokens": ["Der", "Schein", "hing", "Mas\u00b7quen", "vor", ",", "die", "Hof\u00b7fart", "trat", "die", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr Steifrock wollte sich wie das Gem\u00fcthe breiten.", "tokens": ["Ihr", "Stei\u00b7frock", "woll\u00b7te", "sich", "wie", "das", "Ge\u00b7m\u00fc\u00b7the", "brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PRF", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Zwietracht zanckt und bi\u00df fast durch den ganzen Weg,", "tokens": ["Die", "Zwiet\u00b7racht", "zanckt", "und", "bi\u00df", "fast", "durch", "den", "gan\u00b7zen", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "APPR", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Post der Eifersucht bekam Medeens Wagen,", "tokens": ["Die", "Post", "der", "Ei\u00b7fer\u00b7sucht", "be\u00b7kam", "Me\u00b7de\u00b7ens", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Die Wollust war bequem und lies sich r\u00fccklings tragen,", "tokens": ["Die", "Wol\u00b7lust", "war", "be\u00b7quem", "und", "lies", "sich", "r\u00fcck\u00b7lings", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "KON", "VVFIN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die na\u00dfe Trunckenheit verfehlte stets den Steg,", "tokens": ["Die", "na\u00b7\u00dfe", "Trun\u00b7cken\u00b7heit", "ver\u00b7fehl\u00b7te", "stets", "den", "Steg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Faulheit hielt es nicht mit dem geschwinden Volcke", "tokens": ["Die", "Faul\u00b7heit", "hielt", "es", "nicht", "mit", "dem", "ge\u00b7schwin\u00b7den", "Vol\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und zog so endelich als eine tr\u00fcbe Wolcke.", "tokens": ["Und", "zog", "so", "en\u00b7de\u00b7lich", "als", "ei\u00b7ne", "tr\u00fc\u00b7be", "Wol\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Der nur mit Schwamm und Moos ringsum spalirte Saal", "tokens": ["Der", "nur", "mit", "Schwamm", "und", "Moos", "ring\u00b7sum", "spa\u00b7lir\u00b7te", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NN", "KON", "NN", "ADV", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lies die Versammleten auf Rasen niedersizen.", "tokens": ["Lies", "die", "Ver\u00b7samm\u00b7le\u00b7ten", "auf", "Ra\u00b7sen", "nie\u00b7der\u00b7si\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Das Erdreich zitterte von der Verdammten Zahl,", "tokens": ["Das", "Er\u00b7dreich", "zit\u00b7ter\u00b7te", "von", "der", "Ver\u00b7damm\u00b7ten", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Als h\u00e4tt es gleichsam Lust, den Boden aufzuschlizen.", "tokens": ["Als", "h\u00e4tt", "es", "gleich\u00b7sam", "Lust", ",", "den", "Bo\u00b7den", "auf\u00b7zu\u00b7schli\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADJD", "NN", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu oberst dehnte sich das obgemeldte Weib,", "tokens": ["Zu", "o\u00b7berst", "dehn\u00b7te", "sich", "das", "ob\u00b7ge\u00b7meld\u00b7te", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Feindin freyer Kunst, der Ha\u00df der Castalinnen.", "tokens": ["Die", "Fein\u00b7din", "frey\u00b7er", "Kunst", ",", "der", "Ha\u00df", "der", "Cas\u00b7ta\u00b7lin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vom Auge sah man Schmeer an statt der Thr\u00e4nen rinnen,", "tokens": ["Vom", "Au\u00b7ge", "sah", "man", "Schmeer", "an", "statt", "der", "Thr\u00e4\u00b7nen", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Nattern z\u00fcngelten um den bewundnen Leib,", "tokens": ["Die", "Nat\u00b7tern", "z\u00fcn\u00b7gel\u00b7ten", "um", "den", "be\u00b7wund\u00b7nen", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Umhang ihrer Pracht war Purpur aus Matrazen", "tokens": ["Der", "Um\u00b7hang", "ih\u00b7rer", "Pracht", "war", "Pur\u00b7pur", "aus", "Mat\u00b7ra\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "NN", "APPR", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Und de\u00dfen \u00dcberschlag ein Hermelin von Kazen.", "tokens": ["Und", "de\u00b7\u00dfen", "\u00dc\u00b7bersc\u00b7hlag", "ein", "Her\u00b7me\u00b7lin", "von", "Ka\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Kaum da\u00df der weite Schlund das erste Wort gebahr,", "tokens": ["Kaum", "da\u00df", "der", "wei\u00b7te", "Schlund", "das", "ers\u00b7te", "Wort", "ge\u00b7bahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(es sazte M\u00fch genug, den Gram herauszuw\u00fcrgen)", "tokens": ["(", "es", "saz\u00b7te", "M\u00fch", "ge\u00b7nug", ",", "den", "Gram", "her\u00b7aus\u00b7zu\u00b7w\u00fcr\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "NN", "ADV", "$,", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So nahms der Oderstrom in seinen H\u00f6hlen wahr,", "tokens": ["So", "nahms", "der", "O\u00b7der\u00b7strom", "in", "sei\u00b7nen", "H\u00f6h\u00b7len", "wahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und der Sudeten Kluft erzehlt es den Geb\u00fcrgen.", "tokens": ["Und", "der", "Su\u00b7de\u00b7ten", "Kluft", "er\u00b7zehlt", "es", "den", "Ge\u00b7b\u00fcr\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "Die Laster sperrten Maul und Nas und Ohren auf", "tokens": ["Die", "Las\u00b7ter", "sperr\u00b7ten", "Maul", "und", "Nas", "und", "Oh\u00b7ren", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "KON", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und machten augenblicks die f\u00fcrchterlichste Stille,", "tokens": ["Und", "mach\u00b7ten", "au\u00b7gen\u00b7blicks", "die", "f\u00fcrch\u00b7ter\u00b7lichs\u00b7te", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie wenn der Wa\u00dfergott und sein erz\u00fcrnter Wille", "tokens": ["Wie", "wenn", "der", "Wa\u00b7\u00dfer\u00b7gott", "und", "sein", "er\u00b7z\u00fcrn\u00b7ter", "Wil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "KOUS", "ART", "NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Wellen Truz gebeuth und den verwirrten Lauf", "tokens": ["Den", "Wel\u00b7len", "Truz", "ge\u00b7beuth", "und", "den", "ver\u00b7wirr\u00b7ten", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In Ruh und Ordnung bringt, das m\u00fcde Brausen schweiget", "tokens": ["In", "Ruh", "und", "Ord\u00b7nung", "bringt", ",", "das", "m\u00fc\u00b7de", "Brau\u00b7sen", "schwei\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und der bedrohte Nord in seine F\u00e4\u00dfer steiget.", "tokens": ["Und", "der", "be\u00b7droh\u00b7te", "Nord", "in", "sei\u00b7ne", "F\u00e4\u00b7\u00dfer", "stei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ach, Liebste, schaft doch Rath, es ist um uns gethan!", "tokens": ["Ach", ",", "Liebs\u00b7te", ",", "schaft", "doch", "Rath", ",", "es", "ist", "um", "uns", "ge\u00b7than", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "VVFIN", "ADV", "NN", "$,", "PPER", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So schrie das Ungeheur mit untermengtem Keichen,", "tokens": ["So", "schrie", "das", "Un\u00b7ge\u00b7heur", "mit", "un\u00b7ter\u00b7meng\u00b7tem", "Kei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Faust der Wi\u00dfenschaft durchl\u00f6chert unsre Bahn", "tokens": ["Die", "Faust", "der", "Wi\u00b7\u00dfen\u00b7schaft", "durch\u00b7l\u00f6\u00b7chert", "uns\u00b7re", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und zwingt mich \u00fcberall, den Musen auszuweichen.", "tokens": ["Und", "zwingt", "mich", "\u00fc\u00b7be\u00b7rall", ",", "den", "Mu\u00b7sen", "aus\u00b7zu\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Wachsthum ihres Ruhms macht, da\u00df mein Ansehn stockt,", "tokens": ["Der", "Wach\u00b7sthum", "ih\u00b7res", "Ruhms", "macht", ",", "da\u00df", "mein", "An\u00b7sehn", "stockt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die L\u00e4nder wickeln sich aus unsern finstern Ketten,", "tokens": ["Die", "L\u00e4n\u00b7der", "wi\u00b7ckeln", "sich", "aus", "un\u00b7sern", "fins\u00b7tern", "Ket\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die sie warhaftig noch an den Gem\u00fcthern h\u00e4tten,", "tokens": ["Die", "sie", "war\u00b7haf\u00b7tig", "noch", "an", "den", "Ge\u00b7m\u00fc\u00b7thern", "h\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "ADV", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.8": {"text": "Wenn mir die Klugheit nicht viel Sclaven abgelockt.", "tokens": ["Wenn", "mir", "die", "Klug\u00b7heit", "nicht", "viel", "Scla\u00b7ven", "ab\u00b7ge\u00b7lockt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dies, dies verschmizte Weib betriegt mich um die Crone,", "tokens": ["Dies", ",", "dies", "ver\u00b7schmiz\u00b7te", "Weib", "be\u00b7triegt", "mich", "um", "die", "Cro\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PDS", "ADJA", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und was sie mir noch l\u00e4st, das ist der Fall vom Throne.", "tokens": ["Und", "was", "sie", "mir", "noch", "l\u00e4st", ",", "das", "ist", "der", "Fall", "vom", "Thro\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "PPER", "ADV", "VVFIN", "$,", "PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Mein Eingeweide brennt, der Schmerz zerfri\u00dft das Marck,", "tokens": ["Mein", "Ein\u00b7ge\u00b7wei\u00b7de", "brennt", ",", "der", "Schmerz", "zer\u00b7fri\u00dft", "das", "Marck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn ich den niedern Theil von Schlesien erwege.", "tokens": ["Wenn", "ich", "den", "nie\u00b7dern", "Theil", "von", "Schle\u00b7si\u00b7en", "er\u00b7we\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr Unkraut wuchert hier so h\u00e4ufig und so starck,", "tokens": ["Ihr", "Un\u00b7kraut", "wu\u00b7chert", "hier", "so", "h\u00e4u\u00b7fig", "und", "so", "starck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df ich Gedult und Lust und Hofnung niederlege.", "tokens": ["Da\u00df", "ich", "Ge\u00b7dult", "und", "Lust", "und", "Hof\u00b7nung", "nie\u00b7der\u00b7le\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Die Frau Pedanterey, als unsre Schw\u00e4gerin,", "tokens": ["Die", "Frau", "Pe\u00b7dan\u00b7te\u00b7rey", ",", "als", "uns\u00b7re", "Schw\u00e4\u00b7ge\u00b7rin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist so verm\u00f6gend nicht, den Jammer zu erzehlen,", "tokens": ["Ist", "so", "ver\u00b7m\u00f6\u00b7gend", "nicht", ",", "den", "Jam\u00b7mer", "zu", "er\u00b7zeh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "PTKNEG", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df Tugend und Verstand ihr altes Erbrecht qu\u00e4len;", "tokens": ["Da\u00df", "Tu\u00b7gend", "und", "Ver\u00b7stand", "ihr", "al\u00b7tes", "Er\u00b7brecht", "qu\u00e4\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie schnaubt, sie f\u00e4hrt mich an, da\u00df ich so schl\u00e4frig bin", "tokens": ["Sie", "schnaubt", ",", "sie", "f\u00e4hrt", "mich", "an", ",", "da\u00df", "ich", "so", "schl\u00e4f\u00b7rig", "bin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ADV", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und nicht mit ganzer Macht und nicht mit vollem Heere", "tokens": ["Und", "nicht", "mit", "gan\u00b7zer", "Macht", "und", "nicht", "mit", "vol\u00b7lem", "Hee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "APPR", "ADJA", "NN", "KON", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Einbruch der Gefahr in dieser Gegend wehre.", "tokens": ["Den", "Ein\u00b7bruch", "der", "Ge\u00b7fahr", "in", "die\u00b7ser", "Ge\u00b7gend", "weh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}}, "stanza.11": {"line.1": {"text": "Ja, sagte sie, nur wie? Verm\u00f6cht es diese Faust,", "tokens": ["Ja", ",", "sag\u00b7te", "sie", ",", "nur", "wie", "?", "Ver\u00b7m\u00f6cht", "es", "die\u00b7se", "Faust", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,", "ADV", "KOKOM", "$.", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was gilts, es sollte sich das Blat in kurzem wenden.", "tokens": ["Was", "gilts", ",", "es", "soll\u00b7te", "sich", "das", "Blat", "in", "kur\u00b7zem", "wen\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PPER", "VMFIN", "PRF", "ART", "NN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich d\u00e4cht, es w\u00e4re klar, wie ich vor dem gehaust,", "tokens": ["Ich", "d\u00e4cht", ",", "es", "w\u00e4\u00b7re", "klar", ",", "wie", "ich", "vor", "dem", "ge\u00b7haust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "$,", "PWAV", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Last euch nur Griechenland ein schriftlich Zeugn\u00fc\u00df senden.", "tokens": ["Last", "euch", "nur", "Grie\u00b7chen\u00b7land", "ein", "schrift\u00b7lich", "Zeug\u00b7n\u00fc\u00df", "sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "NE", "ART", "ADJD", "NN", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Hier ist ein andres Werck und eine st\u00e4rckre Macht,", "tokens": ["Hier", "ist", "ein", "and\u00b7res", "Werck", "und", "ei\u00b7ne", "st\u00e4r\u00b7ck\u00b7re", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Der K\u00f6nig \u00fcber uns hat hier die Hand im Spiele;", "tokens": ["Der", "K\u00f6\u00b7nig", "\u00fc\u00b7ber", "uns", "hat", "hier", "die", "Hand", "im", "Spie\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPER", "VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihr seht sie freylich nicht, genug, da\u00df ich sie f\u00fchle.", "tokens": ["Ihr", "seht", "sie", "frey\u00b7lich", "nicht", ",", "ge\u00b7nug", ",", "da\u00df", "ich", "sie", "f\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wer weis, wie bald der Schlag zum lezten Mahle kracht,", "tokens": ["Wer", "weis", ",", "wie", "bald", "der", "Schlag", "zum", "lez\u00b7ten", "Mah\u00b7le", "kracht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "PWAV", "ADV", "ART", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da die Gelehrsamkeit und tausend be\u00dfre Sitten", "tokens": ["Da", "die", "Ge\u00b7lehr\u00b7sam\u00b7keit", "und", "tau\u00b7send", "be\u00df\u00b7re", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den unsrigen bereits den Freyheitshut beschnidten.", "tokens": ["Den", "uns\u00b7ri\u00b7gen", "be\u00b7reits", "den", "Frey\u00b7he\u00b7its\u00b7hut", "be\u00b7schnid\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.12": {"line.1": {"text": "Die Parzen haben uns den Untergang versehn;", "tokens": ["Die", "Par\u00b7zen", "ha\u00b7ben", "uns", "den", "Un\u00b7ter\u00b7gang", "ver\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es sey nun, wie es sey, das Lezte steht zu wagen,", "tokens": ["Es", "sey", "nun", ",", "wie", "es", "sey", ",", "das", "Lez\u00b7te", "steht", "zu", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$,", "ART", "ADJA", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man strebe, weil man kan; bisweilen ists geschehn,", "tokens": ["Man", "stre\u00b7be", ",", "weil", "man", "kan", ";", "bis\u00b7wei\u00b7len", "ists", "ge\u00b7schehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PIS", "VMFIN", "$.", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df sich die Raserey im Engen durchgeschlagen,", "tokens": ["Da\u00df", "sich", "die", "Ra\u00b7se\u00b7rey", "im", "En\u00b7gen", "durch\u00b7ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was Kleinmuth fahren l\u00e4st, das holt gar oft der Grimm,", "tokens": ["Was", "Klein\u00b7muth", "fah\u00b7ren", "l\u00e4st", ",", "das", "holt", "gar", "oft", "der", "Grimm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VVINF", "VVFIN", "$,", "PDS", "VVFIN", "ADV", "ADV", "ART", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Schl\u00e4gts ja zur Lincken fehl, so w\u00fcte man zur Rechten.", "tokens": ["Schl\u00e4g\u00b7ts", "ja", "zur", "Lin\u00b7cken", "fehl", ",", "so", "w\u00fc\u00b7te", "man", "zur", "Rech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PIS", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.7": {"text": "Mein Arm, so d\u00fcrr er scheint, hat auch noch Blut zum Fechten.", "tokens": ["Mein", "Arm", ",", "so", "d\u00fcrr", "er", "scheint", ",", "hat", "auch", "noch", "Blut", "zum", "Fech\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Courage! treues Volck, erbo\u00dfe dich und nimm", "tokens": ["Cou\u00b7ra\u00b7ge", "!", "treu\u00b7es", "Volck", ",", "er\u00b7bo\u00b7\u00dfe", "dich", "und", "nimm"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "ADJA", "NN", "$,", "VVFIN", "PPER", "KON", "VVIMP"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.9": {"text": "Mein Beyspiel in das Herz, der Eifer schmiedet Wafen,", "tokens": ["Mein", "Bey\u00b7spiel", "in", "das", "Herz", ",", "der", "Ei\u00b7fer", "schmie\u00b7det", "Wa\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die G\u00f6tter m\u00fc\u00dfen wohl die Herrschaft wieder schafen.", "tokens": ["Die", "G\u00f6t\u00b7ter", "m\u00fc\u00b7\u00dfen", "wohl", "die", "Herr\u00b7schaft", "wie\u00b7der", "scha\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Es schlo\u00df ihr Zorn den Mund, ihr Schwur den Daumen zu.", "tokens": ["Es", "schlo\u00df", "ihr", "Zorn", "den", "Mund", ",", "ihr", "Schwur", "den", "Dau\u00b7men", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Stimmen murmelten wie siedend hei\u00dfe T\u00f6pfe", "tokens": ["Die", "Stim\u00b7men", "mur\u00b7mel\u00b7ten", "wie", "sie\u00b7dend", "hei\u00b7\u00dfe", "T\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wurden selbst nicht eins, womit man be\u00dfer thu.", "tokens": ["Und", "wur\u00b7den", "selbst", "nicht", "eins", ",", "wo\u00b7mit", "man", "be\u00b7\u00dfer", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PTKNEG", "PIS", "$,", "PWAV", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So gehts, ein einzger Hut bedeckt kein Duzend K\u00f6pfe.", "tokens": ["So", "gehts", ",", "ein", "einz\u00b7ger", "Hut", "be\u00b7deckt", "kein", "Du\u00b7zend", "K\u00f6p\u00b7fe", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ART", "ADJA", "NN", "VVFIN", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur die Verwegenheit grif nach dem Degen los", "tokens": ["Nur", "die", "Ver\u00b7we\u00b7gen\u00b7heit", "grif", "nach", "dem", "De\u00b7gen", "los"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.6": {"text": "Und rief im Weitergehn: Das h\u00e4tt ich l\u00e4ngst beschlo\u00dfen.", "tokens": ["Und", "rief", "im", "Wei\u00b7ter\u00b7gehn", ":", "Das", "h\u00e4tt", "ich", "l\u00e4ngst", "be\u00b7schlo\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "PDS", "VAFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir wi\u00dfen Furien. Ihr meine Bundsgeno\u00dfen,", "tokens": ["Wir", "wi\u00b7\u00dfen", "Fu\u00b7ri\u00b7en", ".", "Ihr", "mei\u00b7ne", "Bunds\u00b7ge\u00b7no\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$.", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Folgt mir und meiner Faust, ihr ist kein Sturm zu gro\u00df;", "tokens": ["Folgt", "mir", "und", "mei\u00b7ner", "Faust", ",", "ihr", "ist", "kein", "Sturm", "zu", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein jedes Element wird, wollen wir uns r\u00e4chen,", "tokens": ["Ein", "je\u00b7des", "E\u00b7le\u00b7ment", "wird", ",", "wol\u00b7len", "wir", "uns", "r\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "$,", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mit Gott und der Natur den alten Frieden brechen.", "tokens": ["Mit", "Gott", "und", "der", "Na\u00b7tur", "den", "al\u00b7ten", "Frie\u00b7den", "bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Das rieth ich eben nicht, so fiel die Arglist ein;", "tokens": ["Das", "rieth", "ich", "e\u00b7ben", "nicht", ",", "so", "fiel", "die", "Arg\u00b7list", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "PTKNEG", "$,", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn so versch\u00fctten wir das Kind mitsamt dem Bade.", "tokens": ["Denn", "so", "ver\u00b7sch\u00fct\u00b7ten", "wir", "das", "Kind", "mit\u00b7samt", "dem", "Ba\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Pulver wider Gift mu\u00df gleichwohl sicher seyn,", "tokens": ["Ein", "Pul\u00b7ver", "wi\u00b7der", "Gift", "mu\u00df", "gleich\u00b7wohl", "si\u00b7cher", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VMFIN", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Damit der Arzt nicht mehr als Brand und Fieber schade.", "tokens": ["Da\u00b7mit", "der", "Arzt", "nicht", "mehr", "als", "Brand", "und", "Fie\u00b7ber", "scha\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PTKNEG", "ADV", "KOUS", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kennt ihr den Riesen wohl, der dort den Aetna tr\u00e4gt?", "tokens": ["Kennt", "ihr", "den", "Rie\u00b7sen", "wohl", ",", "der", "dort", "den", "A\u00b7et\u00b7na", "tr\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,", "PRELS", "ADV", "ART", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Wo nicht, erinnert euch, warum Lycaon heule;", "tokens": ["Wo", "nicht", ",", "e\u00b7rin\u00b7nert", "euch", ",", "wa\u00b7rum", "Ly\u00b7ca\u00b7on", "heu\u00b7le", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "VVFIN", "PPER", "$,", "PWAV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auch Pallas prahlt und gl\u00e4nzt mit einem Donnerkeile", "tokens": ["Auch", "Pal\u00b7las", "prahlt", "und", "gl\u00e4nzt", "mit", "ei\u00b7nem", "Don\u00b7ner\u00b7kei\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VVFIN", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der wie des Juppiters das Feuer dreyfach schl\u00e4gt.", "tokens": ["Der", "wie", "des", "Jup\u00b7pi\u00b7ters", "das", "Feu\u00b7er", "drey\u00b7fach", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "ART", "NN", "ART", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gewalt thut H\u00f6hern nichts. Wer zwingt uns, zu erfahren,", "tokens": ["Ge\u00b7walt", "thut", "H\u00f6\u00b7hern", "nichts", ".", "Wer", "zwingt", "uns", ",", "zu", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "PIS", "$.", "PWS", "VVFIN", "PPER", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie starck die Himmlischen an Titans Enckeln waren?", "tokens": ["Wie", "starck", "die", "Himm\u00b7li\u00b7schen", "an", "Ti\u00b7tans", "En\u00b7ckeln", "wa\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "NE", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Verfolgung be\u00dfert nur die traumende Vernunft,", "tokens": ["Ver\u00b7fol\u00b7gung", "be\u00b7\u00dfert", "nur", "die", "trau\u00b7men\u00b7de", "Ver\u00b7nunft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+---+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Erweckt den kalten Flei\u00df und mehrt der Weisen Menge;", "tokens": ["Er\u00b7weckt", "den", "kal\u00b7ten", "Flei\u00df", "und", "mehrt", "der", "Wei\u00b7sen", "Men\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir schw\u00e4chen, gebt nur Acht, die Anzahl eigner Zunft,", "tokens": ["Wir", "schw\u00e4\u00b7chen", ",", "gebt", "nur", "Acht", ",", "die", "An\u00b7zahl", "eig\u00b7ner", "Zunft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "ADV", "CARD", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn die Belagerung macht keinen Pindus enge.", "tokens": ["Denn", "die", "Be\u00b7la\u00b7ge\u00b7rung", "macht", "kei\u00b7nen", "Pin\u00b7dus", "en\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der ofenbahre Neid verkehre sich in List,", "tokens": ["Der", "o\u00b7fen\u00b7bah\u00b7re", "Neid", "ver\u00b7keh\u00b7re", "sich", "in", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der st\u00fcrmende Beschlu\u00df in ein gelindres Mittel.", "tokens": ["Der", "st\u00fcr\u00b7men\u00b7de", "Be\u00b7schlu\u00df", "in", "ein", "ge\u00b7lind\u00b7res", "Mit\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vielleicht erh\u00e4lt man mehr, wenn der Gelehrten Tittel", "tokens": ["Viel\u00b7leicht", "er\u00b7h\u00e4lt", "man", "mehr", ",", "wenn", "der", "Ge\u00b7lehr\u00b7ten", "Tit\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$,", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "An einem, der nichts kan, des Ordens Schandfleck ist;", "tokens": ["An", "ei\u00b7nem", ",", "der", "nichts", "kan", ",", "des", "Or\u00b7dens", "Schand\u00b7fleck", "ist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIS", "VMFIN", "$,", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es d\u00fcrft ein tummer Kopf den schlecht bestellten Sachen", "tokens": ["Es", "d\u00fcrft", "ein", "tum\u00b7mer", "Kopf", "den", "schlecht", "be\u00b7stell\u00b7ten", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Vor unsern Trost gar bald ein be\u00dfres Ansehn machen.", "tokens": ["Vor", "un\u00b7sern", "Trost", "gar", "bald", "ein", "be\u00df\u00b7res", "An\u00b7sehn", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Der Momus wurd einmahl, man meint, es sey geschehn,", "tokens": ["Der", "Mo\u00b7mus", "wurd", "ein\u00b7mahl", ",", "man", "meint", ",", "es", "sey", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$,", "PIS", "VVFIN", "$,", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da Zeus den Thron bestieg, zu des Prometheus Afen", "tokens": ["Da", "Zeus", "den", "Thron", "be\u00b7stieg", ",", "zu", "des", "Pro\u00b7me\u00b7theus", "A\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wollte, weil er ihm ein Vortheil abgesehn,", "tokens": ["Und", "woll\u00b7te", ",", "weil", "er", "ihm", "ein", "Vor\u00b7theil", "ab\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "PPER", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(was thut der Vorwiz nicht!) ein Menschenbild erschafen.", "tokens": ["(", "was", "thut", "der", "Vor\u00b7wiz", "nicht", "!", ")", "ein", "Men\u00b7schen\u00b7bild", "er\u00b7scha\u00b7fen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ART", "NN", "PTKNEG", "$.", "$(", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nun traf sichs ohngefehr, da\u00df er zur Eris kam,", "tokens": ["Nun", "traf", "sichs", "ohn\u00b7ge\u00b7fehr", ",", "da\u00df", "er", "zur", "E\u00b7ris", "kam", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "$,", "KOUS", "PPER", "APPRART", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ihr Geburthsfest hielt und mit den Lastern zechte.", "tokens": ["Die", "ihr", "Ge\u00b7burths\u00b7fest", "hielt", "und", "mit", "den", "Las\u00b7tern", "zech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das Vivat gieng herum, bis man den Magen schw\u00e4chte,", "tokens": ["Das", "Vi\u00b7vat", "gieng", "he\u00b7rum", ",", "bis", "man", "den", "Ma\u00b7gen", "schw\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Von dem ein halbes Fa\u00df die Ladung wieder nahm.", "tokens": ["Von", "dem", "ein", "hal\u00b7bes", "Fa\u00df", "die", "La\u00b7dung", "wie\u00b7der", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hier sprizten J\u00e4scht und Schleim dem Momus in die H\u00e4nde,", "tokens": ["Hier", "spriz\u00b7ten", "J\u00e4scht", "und", "Schleim", "dem", "Mo\u00b7mus", "in", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der froh und freudig ward, da\u00df er den C\u00f6rper f\u00e4nde.", "tokens": ["Der", "froh", "und", "freu\u00b7dig", "ward", ",", "da\u00df", "er", "den", "C\u00f6r\u00b7per", "f\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Er trieb den rohen Zeug in f\u00f6rmliche Gestalt,", "tokens": ["Er", "trieb", "den", "ro\u00b7hen", "Zeug", "in", "f\u00f6rm\u00b7li\u00b7che", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und sieh, es wurd ein Kind von h\u00f6hnischen Gebehrden.", "tokens": ["Und", "sieh", ",", "es", "wurd", "ein", "Kind", "von", "h\u00f6h\u00b7ni\u00b7schen", "Ge\u00b7behr\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die G\u00e4ste sprungen zu und w\u00fcntschten alsobald:", "tokens": ["Die", "G\u00e4s\u00b7te", "sprun\u00b7gen", "zu", "und", "w\u00fcnt\u00b7schten", "al\u00b7so\u00b7bald", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du solt, o kleiner Schaz, den M\u00fcttern \u00e4hnlich werden.", "tokens": ["Du", "solt", ",", "o", "klei\u00b7ner", "Schaz", ",", "den", "M\u00fct\u00b7tern", "\u00e4hn\u00b7lich", "wer\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "FM", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Kummer fiel nur vor, es war kein Leben da;", "tokens": ["Der", "Kum\u00b7mer", "fiel", "nur", "vor", ",", "es", "war", "kein", "Le\u00b7ben", "da", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$,", "PPER", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Eris windelt es in ein beschwiztes K\u00fc\u00dfen,", "tokens": ["Die", "E\u00b7ris", "win\u00b7delt", "es", "in", "ein", "be\u00b7schwiz\u00b7tes", "K\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das man den Sterbenden vom Nacken weggeri\u00dfen,", "tokens": ["Das", "man", "den", "Ster\u00b7ben\u00b7den", "vom", "Na\u00b7cken", "weg\u00b7ge\u00b7ri\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Beschrieb den Zauberkrei\u00df, worein sie r\u00fccklings sah,", "tokens": ["Be\u00b7schrieb", "den", "Zau\u00b7ber\u00b7krei\u00df", ",", "wo\u00b7rein", "sie", "r\u00fcck\u00b7lings", "sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein stummes Abra warf und sechsmahl Bonus-Die\u00dfte,", "tokens": ["Ein", "stum\u00b7mes", "Ab\u00b7ra", "warf", "und", "sechs\u00b7mahl", "Bo\u00b7nus\u00b7Die\u00df\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bis die beseelte Frucht der Hex entgegen nie\u00dfte.", "tokens": ["Bis", "die", "be\u00b7seel\u00b7te", "Frucht", "der", "Hex", "ent\u00b7ge\u00b7gen", "nie\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Es blieb in ihrer Zucht und zeigte F\u00e4higkeit,", "tokens": ["Es", "blieb", "in", "ih\u00b7rer", "Zucht", "und", "zeig\u00b7te", "F\u00e4\u00b7hig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Lehren, so sie gab, bis auf den Grund zu fa\u00dfen.", "tokens": ["Die", "Leh\u00b7ren", ",", "so", "sie", "gab", ",", "bis", "auf", "den", "Grund", "zu", "fa\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was d\u00fcnckt euch insgesamt bey so bedr\u00e4ngter Zeit?", "tokens": ["Was", "d\u00fcnckt", "euch", "ins\u00b7ge\u00b7samt", "bey", "so", "be\u00b7dr\u00e4ng\u00b7ter", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es sollte sich von uns gar wohl gebrauchen la\u00dfen.", "tokens": ["Es", "soll\u00b7te", "sich", "von", "uns", "gar", "wohl", "ge\u00b7brau\u00b7chen", "la\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "PPER", "ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der Knabe fast sich gut, es ist nur halbe M\u00fch", "tokens": ["Der", "Kna\u00b7be", "fast", "sich", "gut", ",", "es", "ist", "nur", "hal\u00b7be", "M\u00fch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PRF", "ADJD", "$,", "PPER", "VAFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und kostet kurzen Flei\u00df, ihn v\u00f6llig abzurichten.", "tokens": ["Und", "kos\u00b7tet", "kur\u00b7zen", "Flei\u00df", ",", "ihn", "v\u00f6l\u00b7lig", "ab\u00b7zu\u00b7rich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "$,", "PPER", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man \u00fcbe seinen Kopf in Clausens Lustgeschichten,", "tokens": ["Man", "\u00fc\u00b7be", "sei\u00b7nen", "Kopf", "in", "Clau\u00b7sens", "Lust\u00b7ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Damit der Narrheitstrieb in das Gehirne zieh.", "tokens": ["Da\u00b7mit", "der", "Nar\u00b7rheit\u00b7strieb", "in", "das", "Ge\u00b7hir\u00b7ne", "zieh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Er kan am Helicon mit Bo\u00dfheit, Zung und Schriften", "tokens": ["Er", "kan", "am", "He\u00b7li\u00b7con", "mit", "Bo\u00df\u00b7heit", ",", "Zung", "und", "Schrif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mehr Unheil, mehr Verdru\u00df als zehn Tyrannen stiften.", "tokens": ["Mehr", "Un\u00b7heil", ",", "mehr", "Ver\u00b7dru\u00df", "als", "zehn", "Ty\u00b7ran\u00b7nen", "stif\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "KOKOM", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Ey, lieber geht doch gleich und bringt ihn eilends her,", "tokens": ["Ey", ",", "lie\u00b7ber", "geht", "doch", "gleich", "und", "bringt", "ihn", "ei\u00b7lends", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "ADV", "ADV", "KON", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geht, rief die Barbarey, wir m\u00fc\u00dfen emsig wachen.", "tokens": ["Geht", ",", "rief", "die", "Bar\u00b7ba\u00b7rey", ",", "wir", "m\u00fc\u00b7\u00dfen", "em\u00b7sig", "wa\u00b7chen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ART", "NN", "$,", "PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man gieng, er kam, sie sprach: O, wer doch j\u00fcnger w\u00e4r,", "tokens": ["Man", "gieng", ",", "er", "kam", ",", "sie", "sprach", ":", "O", ",", "wer", "doch", "j\u00fcn\u00b7ger", "w\u00e4r", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "NE", "$,", "PWS", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was vor ein h\u00fcbsches Paar w\u00fcrd unsre Heirat machen!", "tokens": ["Was", "vor", "ein", "h\u00fcb\u00b7sches", "Paar", "w\u00fcrd", "uns\u00b7re", "Hei\u00b7rat", "ma\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN", "VAFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O du mein Augentrost! O, seht das liebe Lamm,", "tokens": ["O", "du", "mein", "Au\u00b7gen\u00b7trost", "!", "O", ",", "seht", "das", "lie\u00b7be", "Lamm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "NN", "$.", "NE", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Seht, Schwestern, seht und sagt, ists nicht ein feiner Junge?", "tokens": ["Seht", ",", "Schwes\u00b7tern", ",", "seht", "und", "sagt", ",", "ists", "nicht", "ein", "fei\u00b7ner", "Jun\u00b7ge", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VAFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Doch halt, wie steht es wohl um deine glatte Zunge?", "tokens": ["Doch", "halt", ",", "wie", "steht", "es", "wohl", "um", "dei\u00b7ne", "glat\u00b7te", "Zun\u00b7ge", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sperr auf, mein Sohn, sperr auf! Gut, der Verleumdungsstamm", "tokens": ["Sperr", "auf", ",", "mein", "Sohn", ",", "sperr", "auf", "!", "Gut", ",", "der", "Ver\u00b7leum\u00b7dungs\u00b7stamm"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "PPOSAT", "NN", "$,", "ADJD", "PTKVZ", "$.", "ADJD", "$,", "ART", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Sieht recht vortreflich aus. Die Misgunst soll ihn n\u00fczen", "tokens": ["Sieht", "recht", "vor\u00b7tre\u00b7flich", "aus", ".", "Die", "Mis\u00b7gunst", "soll", "ihn", "n\u00fc\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "PTKVZ", "$.", "ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und wieder alle Welt die sch\u00e4rfsten Pfeile schnizen.", "tokens": ["Und", "wie\u00b7der", "al\u00b7le", "Welt", "die", "sch\u00e4rfs\u00b7ten", "Pfei\u00b7le", "schni\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Nun h\u00f6re doch, mein Sohn, gef\u00e4llt es dir bey mir?", "tokens": ["Nun", "h\u00f6\u00b7re", "doch", ",", "mein", "Sohn", ",", "ge\u00b7f\u00e4llt", "es", "dir", "bey", "mir", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von Herzen, sch\u00f6ne Frau. Begehrstu treu zu dienen?", "tokens": ["Von", "Her\u00b7zen", ",", "sch\u00f6\u00b7ne", "Frau", ".", "Be\u00b7gehrs\u00b7tu", "treu", "zu", "die\u00b7nen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADJA", "NN", "$.", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lang ich l\u00fcgen kan. Nun wohl, ich seh an dir", "tokens": ["So", "lang", "ich", "l\u00fc\u00b7gen", "kan", ".", "Nun", "wohl", ",", "ich", "seh", "an", "dir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PPER", "VVINF", "VMFIN", "$.", "ADV", "ADV", "$,", "PPER", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Einfalt in der That, die Frechheit aus den Mienen.", "tokens": ["Die", "Ein\u00b7falt", "in", "der", "That", ",", "die", "Frech\u00b7heit", "aus", "den", "Mie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du wirst ein Mann vor mich und wieder alles das,", "tokens": ["Du", "wirst", "ein", "Mann", "vor", "mich", "und", "wie\u00b7der", "al\u00b7les", "das", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPER", "KON", "ADV", "PIS", "PDS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was Recht und Warheit liebt, viel Federkriege f\u00fchren.", "tokens": ["Was", "Recht", "und", "War\u00b7heit", "liebt", ",", "viel", "Fe\u00b7der\u00b7krie\u00b7ge", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVFIN", "$,", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zeuch aus, mein L\u00fcgengeist soll deinen Trieb regieren,", "tokens": ["Zeuch", "aus", ",", "mein", "L\u00fc\u00b7gen\u00b7geist", "soll", "dei\u00b7nen", "Trieb", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPOSAT", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Fall allen in das Haar, begeifre den Parna\u00df,", "tokens": ["Fall", "al\u00b7len", "in", "das", "Haar", ",", "be\u00b7gei\u00b7fre", "den", "Par\u00b7na\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "APPR", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ficht seine Priester an, verschm\u00e4h die Leyerschwestern", "tokens": ["Ficht", "sei\u00b7ne", "Pries\u00b7ter", "an", ",", "ver\u00b7schm\u00e4h", "die", "Ley\u00b7ersc\u00b7hwes\u00b7tern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "PTKVZ", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und schone keinen Knecht des H\u00f6chsten zu verl\u00e4stern!", "tokens": ["Und", "scho\u00b7ne", "kei\u00b7nen", "Knecht", "des", "H\u00f6chs\u00b7ten", "zu", "ver\u00b7l\u00e4s\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Die Dirnen, so du siehst und hier zugegen hast,", "tokens": ["Die", "Dir\u00b7nen", ",", "so", "du", "siehst", "und", "hier", "zu\u00b7ge\u00b7gen", "hast", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "KON", "ADV", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sind willig und gelehrt, den Handgrif anzugeben.", "tokens": ["Sind", "wil\u00b7lig", "und", "ge\u00b7lehrt", ",", "den", "Hand\u00b7grif", "an\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "VVPP", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Thut, Schwestern, euer Amt, die Zeit wird leicht verpa\u00dft;", "tokens": ["Thut", ",", "Schwes\u00b7tern", ",", "eu\u00b7er", "Amt", ",", "die", "Zeit", "wird", "leicht", "ver\u00b7pa\u00dft", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Jugend ist ein Wachs, sie l\u00e4st die Lehren kleben.", "tokens": ["Die", "Ju\u00b7gend", "ist", "ein", "Wachs", ",", "sie", "l\u00e4st", "die", "Leh\u00b7ren", "kle\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Hoffart nahm das Wort sowie des Knabens Hand", "tokens": ["Die", "Hof\u00b7fart", "nahm", "das", "Wort", "so\u00b7wie", "des", "Kna\u00b7bens", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und haucht ihm ihren Wind durch Nase, Maul und Ohren.", "tokens": ["Und", "haucht", "ihm", "ih\u00b7ren", "Wind", "durch", "Na\u00b7se", ",", "Maul", "und", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie sprach: Berede dich, es sey kein Mensch gebohren,", "tokens": ["Sie", "sprach", ":", "Be\u00b7re\u00b7de", "dich", ",", "es", "sey", "kein", "Mensch", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "PPER", "$,", "PPER", "VAFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der mehr als du versteh, der mehr als du erkand;", "tokens": ["Der", "mehr", "als", "du", "ver\u00b7steh", ",", "der", "mehr", "als", "du", "er\u00b7kand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "KOKOM", "PPER", "VVFIN", "$,", "PRELS", "ADV", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ersauf in meiner Brunst, verachte deines gleichen,", "tokens": ["Er\u00b7sauf", "in", "mei\u00b7ner", "Brunst", ",", "ver\u00b7ach\u00b7te", "dei\u00b7nes", "glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und untersteh dich nicht, den Besten auszuweichen!", "tokens": ["Und", "un\u00b7ter\u00b7steh", "dich", "nicht", ",", "den", "Bes\u00b7ten", "aus\u00b7zu\u00b7wei\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Die Thorheit folgte nach und ri\u00df den Wei\u00dfheitszahn", "tokens": ["Die", "Thor\u00b7heit", "folg\u00b7te", "nach", "und", "ri\u00df", "den", "Wei\u00df\u00b7heits\u00b7zahn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Stumpf und Stiel heraus und sagte: Sey verdorben;", "tokens": ["Mit", "Stumpf", "und", "Stiel", "he\u00b7raus", "und", "sag\u00b7te", ":", "Sey", "ver\u00b7dor\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "KON", "VVFIN", "$.", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Stell alles, was du thust, nach meinen Krebsen an,", "tokens": ["Stell", "al\u00b7les", ",", "was", "du", "thust", ",", "nach", "mei\u00b7nen", "Kreb\u00b7sen", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich habe mir dein Herz zum steten Siz erworben.", "tokens": ["Ich", "ha\u00b7be", "mir", "dein", "Herz", "zum", "ste\u00b7ten", "Siz", "er\u00b7wor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Geu\u00df jeden Funcken aus, der etwan deiner Brust,", "tokens": ["Geu\u00df", "je\u00b7den", "Fun\u00b7cken", "aus", ",", "der", "et\u00b7wan", "dei\u00b7ner", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "PTKVZ", "$,", "PRELS", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So schwach er immer glimmt, ein Licht entz\u00fcnden m\u00f6chte,", "tokens": ["So", "schwach", "er", "im\u00b7mer", "glimmt", ",", "ein", "Licht", "ent\u00b7z\u00fcn\u00b7den", "m\u00f6ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$,", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wenn du freyen wilt, so frey in mein Geschlechte.", "tokens": ["Und", "wenn", "du", "frey\u00b7en", "wilt", ",", "so", "frey", "in", "mein", "Ge\u00b7schlech\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Hab einzig und allein an eignen Wercken Lust,", "tokens": ["Hab", "ein\u00b7zig", "und", "al\u00b7lein", "an", "eig\u00b7nen", "Wer\u00b7cken", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADV", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vers\u00e4ume die Vernunft mit niedertr\u00e4chtgem Wi\u00dfen", "tokens": ["Ver\u00b7s\u00e4u\u00b7me", "die", "Ver\u00b7nunft", "mit", "nie\u00b7der\u00b7tr\u00e4cht\u00b7gem", "Wi\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und sey bis in das Grab auf keinen Zweck befli\u00dfen!", "tokens": ["Und", "sey", "bis", "in", "das", "Grab", "auf", "kei\u00b7nen", "Zweck", "be\u00b7fli\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Sie lies ihn weiter fort. Da wickelte der Schein", "tokens": ["Sie", "lies", "ihn", "wei\u00b7ter", "fort", ".", "Da", "wi\u00b7ckel\u00b7te", "der", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Vortuch von der Schoos, durchsuchte Schliz und Ficke,", "tokens": ["Das", "Vor\u00b7tuch", "von", "der", "Schoos", ",", "durch\u00b7such\u00b7te", "Schliz", "und", "Fi\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zog Gips und Talch heraus und strich sein Antliz ein", "tokens": ["Zog", "Gips", "und", "Talch", "he\u00b7raus", "und", "strich", "sein", "Ant\u00b7liz", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NE", "KON", "NN", "PTKVZ", "KON", "ADJD", "PPOSAT", "NN", "ART"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und las die Predigt her: Verhehle ja die T\u00fccke,", "tokens": ["Und", "las", "die", "Pre\u00b7digt", "her", ":", "Ver\u00b7heh\u00b7le", "ja", "die", "T\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beschnelle wen du kanst mit einer frommen Art,", "tokens": ["Be\u00b7schnel\u00b7le", "wen", "du", "kanst", "mit", "ei\u00b7ner", "from\u00b7men", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PWS", "PPER", "VMFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nimm von der Heucheley der Pharis\u00e4er Schmincke,", "tokens": ["Nimm", "von", "der", "Heu\u00b7che\u00b7ley", "der", "Pha\u00b7ri\u00b7s\u00e4\u00b7er", "Schmin\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df auch kein Argus seh, da\u00df deine Klugheit hincke;", "tokens": ["Da\u00df", "auch", "kein", "Ar\u00b7gus", "seh", ",", "da\u00df", "dei\u00b7ne", "Klug\u00b7heit", "hin\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "VVFIN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Durch Blendwerck und Betrug wird manche R\u00f6th erspart.", "tokens": ["Durch", "Blend\u00b7werck", "und", "Be\u00b7trug", "wird", "man\u00b7che", "R\u00f6th", "er\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "PIAT", "NN", "VVPP", "$."], "meter": "-++--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Lern alles obenhin und las von Jung- und Alten", "tokens": ["Lern", "al\u00b7les", "o\u00b7ben\u00b7hin", "und", "las", "von", "Jung", "und", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ADV", "KON", "VVFIN", "APPR", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den F\u00fcrn\u00fc\u00df deines Koths vor reines Golderz halten!", "tokens": ["Den", "F\u00fcr\u00b7n\u00fc\u00df", "dei\u00b7nes", "Koths", "vor", "rei\u00b7nes", "Gol\u00b7derz", "hal\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Der Zuspruch kam herum, und die Verwegenheit", "tokens": ["Der", "Zu\u00b7spruch", "kam", "he\u00b7rum", ",", "und", "die", "Ver\u00b7we\u00b7gen\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Versteinert ihm zulezt die unversch\u00e4mte Stirne.", "tokens": ["Ver\u00b7stei\u00b7nert", "ihm", "zu\u00b7lezt", "die", "un\u00b7ver\u00b7sch\u00e4m\u00b7te", "Stir\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie rieth ihm: Scheue nichts, wie sehr die Ehrfurcht dr\u00e4ut,", "tokens": ["Sie", "rieth", "ihm", ":", "Scheu\u00b7e", "nichts", ",", "wie", "sehr", "die", "Ehr\u00b7furcht", "dr\u00e4ut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "VVFIN", "PIS", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Steh als ein G\u00f6zenbild, damit man \u00e4rger z\u00fcrne,", "tokens": ["Steh", "als", "ein", "G\u00f6\u00b7zen\u00b7bild", ",", "da\u00b7mit", "man", "\u00e4r\u00b7ger", "z\u00fcr\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Halt Ehr und Schande gleich, verfolg und schone nicht,", "tokens": ["Halt", "Ehr", "und", "Schan\u00b7de", "gleich", ",", "ver\u00b7folg", "und", "scho\u00b7ne", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NN", "KON", "NN", "ADV", "$,", "VVFIN", "KON", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Gieb gro\u00dfe Dinge vor; belauscht man deine Bl\u00f6\u00dfe,", "tokens": ["Gieb", "gro\u00b7\u00dfe", "Din\u00b7ge", "vor", ";", "be\u00b7lauscht", "man", "dei\u00b7ne", "Bl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJA", "NN", "PTKVZ", "$.", "VVFIN", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So schlag es in den Wind, verdaue Straf und St\u00f6\u00dfe,", "tokens": ["So", "schlag", "es", "in", "den", "Wind", ",", "ver\u00b7dau\u00b7e", "Straf", "und", "St\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und lecke wieder das, was dein Gewi\u00dfen sticht,", "tokens": ["Und", "le\u00b7cke", "wie\u00b7der", "das", ",", "was", "dein", "Ge\u00b7wi\u00b7\u00dfen", "sticht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PDS", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gieb keinem Thraso nach, verschw\u00f6re Treu und Friede,", "tokens": ["Gieb", "kei\u00b7nem", "Thra\u00b7so", "nach", ",", "ver\u00b7schw\u00f6\u00b7re", "Treu", "und", "Frie\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIAT", "NN", "PTKVZ", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wer mit den S\u00fcnden truzt, der macht die Rache m\u00fcde.", "tokens": ["Wer", "mit", "den", "S\u00fcn\u00b7den", "truzt", ",", "der", "macht", "die", "Ra\u00b7che", "m\u00fc\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "$,", "PRELS", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Crispin war zugestuzt. Die frohe Barbarey", "tokens": ["Cris\u00b7pin", "war", "zu\u00b7ges\u00b7tuzt", ".", "Die", "fro\u00b7he", "Bar\u00b7ba\u00b7rey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VAFIN", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bekr\u00e4ftigte das Werck mit dem verfluchten Seegen:", "tokens": ["Be\u00b7kr\u00e4f\u00b7tig\u00b7te", "das", "Werck", "mit", "dem", "ver\u00b7fluch\u00b7ten", "See\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Geh, lebe, wachs und bl\u00fch, Kraft unsrer Tyranney", "tokens": ["Geh", ",", "le\u00b7be", ",", "wachs", "und", "bl\u00fch", ",", "Kraft", "uns\u00b7rer", "Ty\u00b7ran\u00b7ney"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "$,", "ADJA", "KON", "ADJD", "$,", "NN", "PPOSAT", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Vollf\u00fchre diesen Bau, dem wir den Grundstein legen,", "tokens": ["Voll\u00b7f\u00fch\u00b7re", "die\u00b7sen", "Bau", ",", "dem", "wir", "den", "Grund\u00b7stein", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beweise dein Geschlecht, erbittre, spotte, schreib,", "tokens": ["Be\u00b7wei\u00b7se", "dein", "Ge\u00b7schlecht", ",", "er\u00b7bitt\u00b7re", ",", "spot\u00b7te", ",", "schreib", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was die Gem\u00fcther kr\u00e4nckt, damits die Jugend lerne", "tokens": ["Was", "die", "Ge\u00b7m\u00fc\u00b7ther", "kr\u00e4nckt", ",", "da\u00b7mits", "die", "Ju\u00b7gend", "ler\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und sich auf deinen Zug der Gr\u00fcndligkeit entferne.", "tokens": ["Und", "sich", "auf", "dei\u00b7nen", "Zug", "der", "Gr\u00fcnd\u00b7lig\u00b7keit", "ent\u00b7fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Lohn versprech ich dir: Ein jedes Heringsweib", "tokens": ["Den", "Lohn", "ver\u00b7sprech", "ich", "dir", ":", "Ein", "je\u00b7des", "He\u00b7rings\u00b7weib"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPER", "$.", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Soll dein gelehrtes Buch vor hundert Augen bringen", "tokens": ["Soll", "dein", "ge\u00b7lehr\u00b7tes", "Buch", "vor", "hun\u00b7dert", "Au\u00b7gen", "brin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "APPR", "CARD", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und Fama de\u00dfen Lob auf mancher Bierbanck singen.", "tokens": ["Und", "Fa\u00b7ma", "de\u00b7\u00dfen", "Lob", "auf", "man\u00b7cher", "Bier\u00b7banck", "sin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Die drauf erfolgte Zeit bewies es allzusehr,", "tokens": ["Die", "drauf", "er\u00b7folg\u00b7te", "Zeit", "be\u00b7wies", "es", "all\u00b7zu\u00b7sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PAV", "VVFIN", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie gut das Tadelkind die Lehren eingesogen.", "tokens": ["Wie", "gut", "das", "Ta\u00b7del\u00b7kind", "die", "Leh\u00b7ren", "ein\u00b7ge\u00b7so\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er \u00fcbertraf sie weit und that schon zehnmahl mehr,", "tokens": ["Er", "\u00fc\u00b7bert\u00b7raf", "sie", "weit", "und", "that", "schon", "zehn\u00b7mahl", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Eh ihm das Milchhaar noch das gr\u00fcne Maul bezogen.", "tokens": ["Eh", "ihm", "das", "Milch\u00b7haar", "noch", "das", "gr\u00fc\u00b7ne", "Maul", "be\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es flog sein Aberwiz so wie ein nackter Specht,", "tokens": ["Es", "flog", "sein", "A\u00b7ber\u00b7wiz", "so", "wie", "ein", "nack\u00b7ter", "Specht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dem Schwanz und Fl\u00fcgel kielt, fein zeitig aus dem Neste.", "tokens": ["Dem", "Schwanz", "und", "Fl\u00fc\u00b7gel", "kielt", ",", "fein", "zei\u00b7tig", "aus", "dem", "Nes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$,", "ADJD", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ja, redt er mit sich selbst, dein Ruhm steht doch nicht feste,", "tokens": ["Ja", ",", "redt", "er", "mit", "sich", "selbst", ",", "dein", "Ruhm", "steht", "doch", "nicht", "fes\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "APPR", "PRF", "ADV", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bis der gespizte Kiel den Nebenchristen schw\u00e4cht;", "tokens": ["Bis", "der", "ge\u00b7spiz\u00b7te", "Kiel", "den", "Ne\u00b7benc\u00b7hris\u00b7ten", "schw\u00e4cht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich mu\u00df von jezund an, man weis, wie kurz wir leben,", "tokens": ["Ich", "mu\u00df", "von", "je\u00b7zund", "an", ",", "man", "weis", ",", "wie", "kurz", "wir", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ADV", "PTKVZ", "$,", "PIS", "PTKVZ", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ein Zeugn\u00fc\u00df meines Stamms und des Gehorsams geben.", "tokens": ["Ein", "Zeug\u00b7n\u00fc\u00df", "mei\u00b7nes", "Stamms", "und", "des", "Ge\u00b7hor\u00b7sams", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "O ungl\u00fcckseelger Mensch, der sein vern\u00fcnftges Pfund,", "tokens": ["O", "un\u00b7gl\u00fcck\u00b7seel\u00b7ger", "Mensch", ",", "der", "sein", "ver\u00b7n\u00fcnft\u00b7ges", "Pfund", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit dem er wuchern soll, auf solchen Wechsel leget.", "tokens": ["Mit", "dem", "er", "wu\u00b7chern", "soll", ",", "auf", "sol\u00b7chen", "Wech\u00b7sel", "le\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVINF", "VMFIN", "$,", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er tritt schon zum Voraus mit der Gefahr in Bund,", "tokens": ["Er", "tritt", "schon", "zum", "Vo\u00b7raus", "mit", "der", "Ge\u00b7fahr", "in", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "NN", "APPR", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Die ihr versprochnes Ziel nicht zu vers\u00e4umen pfleget.", "tokens": ["Die", "ihr", "ver\u00b7sproch\u00b7nes", "Ziel", "nicht", "zu", "ver\u00b7s\u00e4u\u00b7men", "pfle\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er st\u00f6\u00dft den weisen Stein mit blindem Fu\u00dfe fort,", "tokens": ["Er", "st\u00f6\u00dft", "den", "wei\u00b7sen", "Stein", "mit", "blin\u00b7dem", "Fu\u00b7\u00dfe", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sucht durch Ged\u00e4chtn\u00fc\u00dfwerck sein h\u00f6chstes Gut in Schalen", "tokens": ["Sucht", "durch", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df\u00b7werck", "sein", "h\u00f6chs\u00b7tes", "Gut", "in", "Scha\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "PPOSAT", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und ahmt den Wilden nach, die Gold vor Puppen zahlen.", "tokens": ["Und", "ahmt", "den", "Wil\u00b7den", "nach", ",", "die", "Gold", "vor", "Pup\u00b7pen", "zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Erhebt sich denn ein Sturm, so weis er keinen Port", "tokens": ["Er\u00b7hebt", "sich", "denn", "ein", "Sturm", ",", "so", "weis", "er", "kei\u00b7nen", "Port"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "$,", "ADV", "PTKVZ", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und kreucht in Noth und Angst so wie in Rock und Hemde,", "tokens": ["Und", "kreucht", "in", "Noth", "und", "Angst", "so", "wie", "in", "Rock", "und", "Hem\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "ADV", "KOKOM", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn wird die Seelenruh in seinen Gr\u00e4nzen fremde.", "tokens": ["Denn", "wird", "die", "See\u00b7len\u00b7ruh", "in", "sei\u00b7nen", "Gr\u00e4n\u00b7zen", "frem\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Es dr\u00e4ng uns Feind und Neid, man sey verhast, verjagt", "tokens": ["Es", "dr\u00e4ng", "uns", "Feind", "und", "Neid", ",", "man", "sey", "ver\u00b7hast", ",", "ver\u00b7jagt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$,", "PIS", "VAFIN", "VVPP", "$,", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und von der Scheitel an bis auf den Fu\u00df geschlagen,", "tokens": ["Und", "von", "der", "Schei\u00b7tel", "an", "bis", "auf", "den", "Fu\u00df", "ge\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Geist, der Wei\u00dfheit liebt, wird, wenn das Fleisch verzagt,", "tokens": ["Ein", "Geist", ",", "der", "Wei\u00df\u00b7heit", "liebt", ",", "wird", ",", "wenn", "das", "Fleisch", "ver\u00b7zagt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "VAFIN", "$,", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Eden in der Brust, sein Gl\u00fcck im Willen tragen.", "tokens": ["Ein", "E\u00b7den", "in", "der", "Brust", ",", "sein", "Gl\u00fcck", "im", "Wil\u00b7len", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PPOSAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er l\u00e4st den Sp\u00f6ttern gern den Ruhm der Eitelkeit;", "tokens": ["Er", "l\u00e4st", "den", "Sp\u00f6t\u00b7tern", "gern", "den", "Ruhm", "der", "Ei\u00b7tel\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Finger der Natur entschleust ihm reichre Sch\u00e4ze,", "tokens": ["Der", "Fin\u00b7ger", "der", "Na\u00b7tur", "ent\u00b7schleust", "ihm", "reich\u00b7re", "Sch\u00e4\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zeigt ihm die Folgerung der ewigen Geseze", "tokens": ["Zeigt", "ihm", "die", "Fol\u00b7ge\u00b7rung", "der", "e\u00b7wi\u00b7gen", "Ge\u00b7se\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wafnet ihm den Muth mit der Zufriedenheit.", "tokens": ["Und", "waf\u00b7net", "ihm", "den", "Muth", "mit", "der", "Zu\u00b7frie\u00b7den\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Daher entsteht in ihm, wenn Kraft und Blut verrauschen,", "tokens": ["Da\u00b7her", "ent\u00b7steht", "in", "ihm", ",", "wenn", "Kraft", "und", "Blut", "ver\u00b7rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPR", "PPER", "$,", "KOUS", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Kein wiederw\u00e4rtiger Gram, die Erde zu vertauschen.", "tokens": ["Kein", "wie\u00b7der\u00b7w\u00e4r\u00b7ti\u00b7ger", "Gram", ",", "die", "Er\u00b7de", "zu", "ver\u00b7tau\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.29": {"line.1": {"text": "Bed\u00e4chte dies das Volck, so noch im Finstern irrt,", "tokens": ["Be\u00b7d\u00e4ch\u00b7te", "dies", "das", "Volck", ",", "so", "noch", "im", "Fins\u00b7tern", "irrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ART", "NN", "$,", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie ernstlich w\u00fcrd es sich aus dem Verderben rei\u00dfen;", "tokens": ["Wie", "ernst\u00b7lich", "w\u00fcrd", "es", "sich", "aus", "dem", "Ver\u00b7der\u00b7ben", "rei\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "So aber lauft es blind, wenn Geiz und Hochmuth kirrt", "tokens": ["So", "a\u00b7ber", "lauft", "es", "blind", ",", "wenn", "Geiz", "und", "Hoch\u00b7muth", "kirrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und H\u00e4nde geiler Lust der Regung K\u00f6rner schmei\u00dfen.", "tokens": ["Und", "H\u00e4n\u00b7de", "gei\u00b7ler", "Lust", "der", "Re\u00b7gung", "K\u00f6r\u00b7ner", "schmei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Es zehlt nicht, was es hat, es w\u00fcntscht nur, was ihm fehlt,", "tokens": ["Es", "zehlt", "nicht", ",", "was", "es", "hat", ",", "es", "w\u00fcnt\u00b7scht", "nur", ",", "was", "ihm", "fehlt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VAFIN", "$,", "PPER", "VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Verschiebt die Be\u00dferung von einer Zeit zur andern,", "tokens": ["Ver\u00b7schiebt", "die", "Be\u00b7\u00dfe\u00b7rung", "von", "ei\u00b7ner", "Zeit", "zur", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "APPRART", "ADJA", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "L\u00e4st die Gelegenheit mitsamt der Stirne wandern,", "tokens": ["L\u00e4st", "die", "Ge\u00b7le\u00b7gen\u00b7heit", "mit\u00b7samt", "der", "Stir\u00b7ne", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.8": {"text": "Sieht nur, was heut erg\u00f6zt, und nicht, was morgen qu\u00e4lt,", "tokens": ["Sieht", "nur", ",", "was", "heut", "er\u00b7g\u00f6zt", ",", "und", "nicht", ",", "was", "mor\u00b7gen", "qu\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PRELS", "ADV", "VVPP", "$,", "KON", "PTKNEG", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es tr\u00e4umt, so lang es lebt und mu\u00df mit wenig Jahren", "tokens": ["Es", "tr\u00e4umt", ",", "so", "lang", "es", "lebt", "und", "mu\u00df", "mit", "we\u00b7nig", "Jah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADJD", "PPER", "VVFIN", "KON", "VMFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und mit dem lieben Vieh in eine Grube fahren.", "tokens": ["Und", "mit", "dem", "lie\u00b7ben", "Vieh", "in", "ei\u00b7ne", "Gru\u00b7be", "fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Crispin ergab sich jezt der Polyhistorie,", "tokens": ["Cris\u00b7pin", "er\u00b7gab", "sich", "jezt", "der", "Po\u00b7ly\u00b7his\u00b7to\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zog Schw\u00e4nck und M\u00e4hrchen ein, die Jung und M\u00e4gde brachten,", "tokens": ["Zog", "Schw\u00e4nck", "und", "M\u00e4hr\u00b7chen", "ein", ",", "die", "Jung", "und", "M\u00e4g\u00b7de", "brach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PTKVZ", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ward vor Freuden kranck, wenn etwan der und die", "tokens": ["Und", "ward", "vor", "Freu\u00b7den", "kranck", ",", "wenn", "et\u00b7wan", "der", "und", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADJD", "$,", "KOUS", "ADV", "ART", "KON", "ART"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Vom P\u00f6bel \u00fcber ihn und sein Gem\u00e4chte lachten.", "tokens": ["Vom", "P\u00f6\u00b7bel", "\u00fc\u00b7ber", "ihn", "und", "sein", "Ge\u00b7m\u00e4ch\u00b7te", "lach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er las und \u00fcberlas, was er mit Angst geschmiert,", "tokens": ["Er", "las", "und", "\u00fc\u00b7ber\u00b7las", ",", "was", "er", "mit", "Angst", "ge\u00b7schmiert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "PWS", "PPER", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er sprach sich pr\u00e4chtig aus, wenn Pre\u00df und Druck vergonnte,", "tokens": ["Er", "sprach", "sich", "pr\u00e4ch\u00b7tig", "aus", ",", "wenn", "Pre\u00df", "und", "Druck", "ver\u00b7gonn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df er sein Anfangs-C. im Nahmen lesen konte,", "tokens": ["Da\u00df", "er", "sein", "An\u00b7fangs", "C.", "im", "Nah\u00b7men", "le\u00b7sen", "kon\u00b7te", ","], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "TRUNC", "NE", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.8": {"text": "Den er beym Schlafengehn aus Liebe buchstabirt.", "tokens": ["Den", "er", "beym", "Schla\u00b7fen\u00b7gehn", "aus", "Lie\u00b7be", "buch\u00b7sta\u00b7birt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun wird man, dacht er oft, in allen B\u00fcchers\u00e4len", "tokens": ["Nun", "wird", "man", ",", "dacht", "er", "oft", ",", "in", "al\u00b7len", "B\u00fc\u00b7cher\u00b7s\u00e4\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "$,", "VVFIN", "PPER", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch deinen M\u00fc\u00dfiggang zur kl\u00fcgsten Arbeit zehlen.", "tokens": ["Auch", "dei\u00b7nen", "M\u00fc\u00b7\u00dfig\u00b7gang", "zur", "kl\u00fcgs\u00b7ten", "Ar\u00b7beit", "zeh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Hier liegt Sarckmasius", "tokens": ["Hier", "liegt", "Sarck\u00b7ma\u00b7sius"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Die unser Sudelkoch dar\u00fcber her gego\u00dfen.", "tokens": ["Die", "un\u00b7ser", "Su\u00b7del\u00b7koch", "da\u00b7r\u00fc\u00b7ber", "her", "ge\u00b7go\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PAV", "APZR", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer ist wohl so gesund, dem sie nicht W\u00fcrmer zieh,", "tokens": ["Wer", "ist", "wohl", "so", "ge\u00b7sund", ",", "dem", "sie", "nicht", "W\u00fcr\u00b7mer", "zieh", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ADV", "ADJD", "$,", "PRELS", "PPER", "PTKNEG", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zumahl da fast ein Pfund von Saamen eingeflo\u00dfen?", "tokens": ["Zu\u00b7mahl", "da", "fast", "ein", "Pfund", "von", "Saa\u00b7men", "ein\u00b7ge\u00b7flo\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer sich dabey erbricht und auf den Eckel flucht,", "tokens": ["Wer", "sich", "da\u00b7bey", "er\u00b7bricht", "und", "auf", "den", "E\u00b7ckel", "flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "PAV", "VVPP", "KON", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der sp\u00fcle nur den Mund aus seiner Priesterquelle", "tokens": ["Der", "sp\u00fc\u00b7le", "nur", "den", "Mund", "aus", "sei\u00b7ner", "Pries\u00b7ter\u00b7quel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dies Werckchen, sehts doch an, vertritt des Glases Stelle,", "tokens": ["Dies", "Wer\u00b7ck\u00b7chen", ",", "sehts", "doch", "an", ",", "ver\u00b7tritt", "des", "Gla\u00b7ses", "Stel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "$,", "ADV", "ADV", "PTKVZ", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.8": {"text": "Wenn sich die Einfalt puzt und zu bespiegeln sucht.", "tokens": ["Wenn", "sich", "die", "Ein\u00b7falt", "puzt", "und", "zu", "be\u00b7spie\u00b7geln", "sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "KON", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nur schade, da\u00df dadurch viel theure M\u00e4nner leiden,", "tokens": ["Nur", "scha\u00b7de", ",", "da\u00df", "da\u00b7durch", "viel", "theu\u00b7re", "M\u00e4n\u00b7ner", "lei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PAV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da wir vor ihr Verdienst so grobe Federn schneiden.", "tokens": ["Da", "wir", "vor", "ihr", "Ver\u00b7dienst", "so", "gro\u00b7be", "Fe\u00b7dern", "schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Wer aber glaubte wohl, da\u00df solche Schmiererey", "tokens": ["Wer", "a\u00b7ber", "glaub\u00b7te", "wohl", ",", "da\u00df", "sol\u00b7che", "Schmie\u00b7re\u00b7rey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "ADV", "VVFIN", "ADV", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich mit der Ewigkeit noch zu vermehlen d\u00e4chte,", "tokens": ["Sich", "mit", "der", "E\u00b7wig\u00b7keit", "noch", "zu", "ver\u00b7meh\u00b7len", "d\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn nicht der St\u00fcmper selbst so prahlrisch und so frey", "tokens": ["Wenn", "nicht", "der", "St\u00fcm\u00b7per", "selbst", "so", "prahl\u00b7risch", "und", "so", "frey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADV", "ADV", "ADJD", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den abgeschmackten Saz vor das Gesichte br\u00e4chte:", "tokens": ["Den", "ab\u00b7ge\u00b7schmack\u00b7ten", "Saz", "vor", "das", "Ge\u00b7sich\u00b7te", "br\u00e4ch\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich und mein M\u00fc\u00dfiggang, ihr seyd ein braves Paar", "tokens": ["Ich", "und", "mein", "M\u00fc\u00b7\u00dfig\u00b7gang", ",", "ihr", "seyd", "ein", "bra\u00b7ves", "Paar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir, schreibt er, eilen nicht zu dem Verge\u00dfungsgrabe.", "tokens": ["Wir", ",", "schreibt", "er", ",", "ei\u00b7len", "nicht", "zu", "dem", "Ver\u00b7ge\u00b7\u00dfungs\u00b7gra\u00b7be", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gar recht, Crispin, gar recht; wo ich zu bitten habe,", "tokens": ["Gar", "recht", ",", "Cris\u00b7pin", ",", "gar", "recht", ";", "wo", "ich", "zu", "bit\u00b7ten", "ha\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "NE", "$,", "ADV", "ADJD", "$.", "PWAV", "PPER", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So mach Apollo dir den stolzen Vortrag wahr", "tokens": ["So", "mach", "A\u00b7pol\u00b7lo", "dir", "den", "stol\u00b7zen", "Vor\u00b7trag", "wahr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "PPER", "ART", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und la\u00dfe, weil wir auch an Eulenspiegeln dencken,", "tokens": ["Und", "la\u00b7\u00dfe", ",", "weil", "wir", "auch", "an", "Eu\u00b7len\u00b7spie\u00b7geln", "den\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dich durch dies Ehrenlied der lezten Nachwelt schencken.", "tokens": ["Dich", "durch", "dies", "Eh\u00b7ren\u00b7lied", "der", "lez\u00b7ten", "Nach\u00b7welt", "schen\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PDS", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Die Luft ern\u00e4hrt kein Thier, das mehr Gel\u00e4chter zeugt,", "tokens": ["Die", "Luft", "er\u00b7n\u00e4hrt", "kein", "Thier", ",", "das", "mehr", "Ge\u00b7l\u00e4ch\u00b7ter", "zeugt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als wo der Hochmuthsgeist in Hasenc\u00f6rper f\u00e4hret.", "tokens": ["Als", "wo", "der", "Hoch\u00b7muths\u00b7geist", "in", "Ha\u00b7sen\u00b7c\u00f6r\u00b7per", "f\u00e4h\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWAV", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da renckt sich Lend und Steu\u00df, da wird kein Knie gebeugt,", "tokens": ["Da", "renckt", "sich", "Lend", "und", "Steu\u00df", ",", "da", "wird", "kein", "Knie", "ge\u00b7beugt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADJD", "KON", "NN", "$,", "ADV", "VAFIN", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ob ihn der Nachbar schon mit H\u00f6fligkeit beschweret.", "tokens": ["Ob", "ihn", "der", "Nach\u00b7bar", "schon", "mit", "H\u00f6f\u00b7lig\u00b7keit", "be\u00b7schwe\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Ga\u00dfen sind zu schmal, das Pflaster f\u00fchlt den Schritt,", "tokens": ["Die", "Ga\u00b7\u00dfen", "sind", "zu", "schmal", ",", "das", "Pflas\u00b7ter", "f\u00fchlt", "den", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es w\u00e4chst der Bauch heraus, als wollt er fr\u00fcher kommen.", "tokens": ["Es", "w\u00e4chst", "der", "Bauch", "he\u00b7raus", ",", "als", "wollt", "er", "fr\u00fc\u00b7her", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "KOUS", "VMFIN", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Des Landmanns guter Tag wird nicht in Acht genommen,", "tokens": ["Des", "Land\u00b7manns", "gu\u00b7ter", "Tag", "wird", "nicht", "in", "Acht", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "PTKNEG", "APPR", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn der gelehrte Mann hat Sinn und Ohr nicht mit,", "tokens": ["Denn", "der", "ge\u00b7lehr\u00b7te", "Mann", "hat", "Sinn", "und", "Ohr", "nicht", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "NN", "KON", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Weil er das Buch sogar zur Brandtweinschule f\u00fchret", "tokens": ["Weil", "er", "das", "Buch", "so\u00b7gar", "zur", "Brandt\u00b7wein\u00b7schu\u00b7le", "f\u00fch\u00b7ret"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und \u00fcber Stock und Stein die Stra\u00dfen durchstudiret.", "tokens": ["Und", "\u00fc\u00b7ber", "Stock", "und", "Stein", "die", "Stra\u00b7\u00dfen", "durch\u00b7stu\u00b7di\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.34": {"line.1": {"text": "Blieb er ein Narr vor sich, so m\u00f6cht es noch geschehn;", "tokens": ["Blieb", "er", "ein", "Narr", "vor", "sich", ",", "so", "m\u00f6cht", "es", "noch", "ge\u00b7schehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PRF", "$,", "ADV", "VMFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was uns nicht Blasen macht, das kan ein andrer l\u00f6schen.", "tokens": ["Was", "uns", "nicht", "Bla\u00b7sen", "macht", ",", "das", "kan", "ein", "an\u00b7drer", "l\u00f6\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "NN", "VVFIN", "$,", "PDS", "VMFIN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Geht hin, ihr werdet ihn in Wochenstuben sehn,", "tokens": ["Geht", "hin", ",", "ihr", "wer\u00b7det", "ihn", "in", "Wo\u00b7chen\u00b7stu\u00b7ben", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "PPER", "VAFIN", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da k\u00fczelt er sein Ohr mit richtenden Gew\u00e4schen,", "tokens": ["Da", "k\u00fc\u00b7zelt", "er", "sein", "Ohr", "mit", "rich\u00b7ten\u00b7den", "Ge\u00b7w\u00e4\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von daraus rennt er flugs die halbe Stadt herum,", "tokens": ["Von", "da\u00b7raus", "rennt", "er", "flugs", "die", "hal\u00b7be", "Stadt", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PAV", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Tr\u00e4gt Schwachheitsm\u00e4ngel aus und bringt sie zu Papiere,", "tokens": ["Tr\u00e4gt", "Schwach\u00b7heits\u00b7m\u00e4n\u00b7gel", "aus", "und", "bringt", "sie", "zu", "Pa\u00b7pie\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als w\u00e4r es ein Verlust, wenn jeder nicht erf\u00fchre,", "tokens": ["Als", "w\u00e4r", "es", "ein", "Ver\u00b7lust", ",", "wenn", "je\u00b7der", "nicht", "er\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "NN", "$,", "KOUS", "PIS", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Lispillens rechter Fu\u00df sey von der Liebe krumm,", "tokens": ["Lis\u00b7pil\u00b7lens", "rech\u00b7ter", "Fu\u00df", "sey", "von", "der", "Lie\u00b7be", "krumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Amandens lincke Brust vertrage Bi\u00df und Zeichen", "tokens": ["A\u00b7man\u00b7dens", "lin\u00b7cke", "Brust", "ver\u00b7tra\u00b7ge", "Bi\u00df", "und", "Zei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "VVFIN", "APPR", "KON", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Und Blanca la\u00dfe sich die Flasch ins Bette reichen.", "tokens": ["Und", "Blan\u00b7ca", "la\u00b7\u00dfe", "sich", "die", "Flasch", "ins", "Bet\u00b7te", "rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Da klatscht, da k\u00fcmmert sich das alte Tr\u00f6delweib", "tokens": ["Da", "klatscht", ",", "da", "k\u00fcm\u00b7mert", "sich", "das", "al\u00b7te", "Tr\u00f6\u00b7del\u00b7weib"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In jeder Rockenzunft um alle Spindelgrillen,", "tokens": ["In", "je\u00b7der", "Ro\u00b7cken\u00b7zunft", "um", "al\u00b7le", "Spin\u00b7del\u00b7gril\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da sucht er unter Lichts der K\u00f6chin Zeitvertreib,", "tokens": ["Da", "sucht", "er", "un\u00b7ter", "Lichts", "der", "K\u00f6\u00b7chin", "Zeit\u00b7ver\u00b7treib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da holt er Ilsen aus, da forscht er von Sybillen,", "tokens": ["Da", "holt", "er", "Il\u00b7sen", "aus", ",", "da", "forscht", "er", "von", "Sy\u00b7bil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Warum ihr guter Mann geduldig schlafen geh,", "tokens": ["Wa\u00b7rum", "ihr", "gu\u00b7ter", "Mann", "ge\u00b7dul\u00b7dig", "schla\u00b7fen", "geh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "ADJD", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie viel Mirmallens Laz, Celindens Hochzeit koste,", "tokens": ["Wie", "viel", "Mir\u00b7mal\u00b7lens", "Laz", ",", "Ce\u00b7lin\u00b7dens", "Hoch\u00b7zeit", "kos\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "NN", "$,", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wovon der Chloris Zahn, Amornens Liebe roste,", "tokens": ["Wo\u00b7von", "der", "Chlo\u00b7ris", "Zahn", ",", "A\u00b7mor\u00b7nens", "Lie\u00b7be", "ros\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NE", "NN", "$,", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie hoch Silvonien ihr Leibgedinge steh,", "tokens": ["Wie", "hoch", "Sil\u00b7vo\u00b7ni\u00b7en", "ihr", "Leib\u00b7ge\u00b7din\u00b7ge", "steh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.9": {"text": "Wie oft sich Frau und Mensch bey dem Begr\u00e4bn\u00fc\u00df raufen", "tokens": ["Wie", "oft", "sich", "Frau", "und", "Mensch", "bey", "dem", "Be\u00b7gr\u00e4\u00b7bn\u00fc\u00df", "rau\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PRF", "NN", "KON", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und Fritz und Florida nach Fingerwalde laufen.", "tokens": ["Und", "Fritz", "und", "Flo\u00b7ri\u00b7da", "nach", "Fin\u00b7ger\u00b7wal\u00b7de", "lau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "KON", "NE", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Den Lehrern muzt er auf, was kaum zu \u00e4ndern steht", "tokens": ["Den", "Leh\u00b7rern", "muzt", "er", "auf", ",", "was", "kaum", "zu", "\u00e4n\u00b7dern", "steht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und was das Gl\u00fcck auch wohl dem Flei\u00dfigsten versaget.", "tokens": ["Und", "was", "das", "Gl\u00fcck", "auch", "wohl", "dem", "Flei\u00b7\u00dfigs\u00b7ten", "ver\u00b7sa\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "F\u00e4llt ja die Menschligkeit, so wird ein Creuz erh\u00f6ht,", "tokens": ["F\u00e4llt", "ja", "die", "Mensc\u00b7hlig\u00b7keit", ",", "so", "wird", "ein", "Creuz", "er\u00b7h\u00f6ht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An dem des L\u00e4strers Maul das Ohr der Unschuld plaget.", "tokens": ["An", "dem", "des", "L\u00e4st\u00b7rers", "Maul", "das", "Ohr", "der", "Un\u00b7schuld", "pla\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mit Sch\u00fclern f\u00e4ngt er schon den Zanck in Schriften an,", "tokens": ["Mit", "Sch\u00fc\u00b7lern", "f\u00e4ngt", "er", "schon", "den", "Zanck", "in", "Schrif\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als h\u00e4tt er nie geh\u00f6rt: Aus Schnaten werden B\u00e4ume.", "tokens": ["Als", "h\u00e4tt", "er", "nie", "ge\u00b7h\u00f6rt", ":", "Aus", "Schna\u00b7ten", "wer\u00b7den", "B\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "VVFIN", "$.", "APPR", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bald jagt er die Gedult mit einem Kn\u00fcttelreime,", "tokens": ["Bald", "jagt", "er", "die", "Ge\u00b7dult", "mit", "ei\u00b7nem", "Kn\u00fct\u00b7tel\u00b7rei\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bald kehrt der Blaustrumpf um und wird ein Wetterhahn,", "tokens": ["Bald", "kehrt", "der", "Blau\u00b7strumpf", "um", "und", "wird", "ein", "Wet\u00b7ter\u00b7hahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "KON", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da soll hernach das Lob des klugen Masorethen", "tokens": ["Da", "soll", "her\u00b7nach", "das", "Lob", "des", "klu\u00b7gen", "Ma\u00b7so\u00b7re\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den dem Porphyr zuvor gegebnen Stich verl\u00f6then", "tokens": ["Den", "dem", "Por\u00b7phyr", "zu\u00b7vor", "ge\u00b7geb\u00b7nen", "Stich", "ver\u00b7l\u00f6\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADV", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Wie schlecht versiehstu dich, geblendeter Crispin!", "tokens": ["Wie", "schlecht", "ver\u00b7sieh\u00b7stu", "dich", ",", "ge\u00b7blen\u00b7de\u00b7ter", "Cris\u00b7pin", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Purgire dich doch selbst, alsdenn gieb andern Pillen.", "tokens": ["Pur\u00b7gi\u00b7re", "dich", "doch", "selbst", ",", "als\u00b7denn", "gieb", "an\u00b7dern", "Pil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$,", "KON", "VVIMP", "ADJA", "NN", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Wer als ein Gerberschwein der M\u00e4gdgen Schoos \u2013 \u2013 \u2013,", "tokens": ["Wer", "als", "ein", "Ger\u00b7ber\u00b7schwein", "der", "M\u00e4gd\u00b7gen", "Schoos", "\u2013", "\u2013", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PWS", "KOKOM", "ART", "NN", "ART", "NN", "NN", "$(", "$(", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der wird die Trunckenheit mit keiner Predigt stillen.", "tokens": ["Der", "wird", "die", "Trun\u00b7cken\u00b7heit", "mit", "kei\u00b7ner", "Pre\u00b7digt", "stil\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O kehre, kehre doch vor deinen Th\u00fcren weg!", "tokens": ["O", "keh\u00b7re", ",", "keh\u00b7re", "doch", "vor", "dei\u00b7nen", "Th\u00fc\u00b7ren", "weg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wir d\u00fcrften etwas mehr als einen Menschen riechen.", "tokens": ["Wir", "d\u00fcrf\u00b7ten", "et\u00b7was", "mehr", "als", "ei\u00b7nen", "Men\u00b7schen", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "KOKOM", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gedenckstu noch ans Glas? Es mag sich jezt verkriechen,", "tokens": ["Ge\u00b7dencks\u00b7tu", "noch", "ans", "Glas", "?", "Es", "mag", "sich", "jezt", "ver\u00b7krie\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPRART", "NN", "$.", "PPER", "VMFIN", "PRF", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Tasch ist weit genug. Was, sag es, ist dein Zweck?", "tokens": ["Die", "Tasch", "ist", "weit", "ge\u00b7nug", ".", "Was", ",", "sag", "es", ",", "ist", "dein", "Zweck", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "$.", "PWS", "$,", "VVFIN", "PPER", "$,", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Des Nechsten Be\u00dferung? Nein, sondern dein Erg\u00f6zen,", "tokens": ["Des", "Nechs\u00b7ten", "Be\u00b7\u00dfe\u00b7rung", "?", "Nein", ",", "son\u00b7dern", "dein", "Er\u00b7g\u00f6\u00b7zen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "PTKANT", "$,", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den Leuten wehzutun, den Argwohn anzuhezen.", "tokens": ["Den", "Leu\u00b7ten", "weh\u00b7zu\u00b7tun", ",", "den", "Arg\u00b7wohn", "an\u00b7zu\u00b7he\u00b7zen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Bes\u00e4h ich das von ihm gesch\u00e4ndete Latein,", "tokens": ["Be\u00b7s\u00e4h", "ich", "das", "von", "ihm", "ge\u00b7sch\u00e4n\u00b7de\u00b7te", "La\u00b7tein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "APPR", "PPER", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Was w\u00fcrde Priscian vor Nasenst\u00fcber holen!", "tokens": ["Was", "w\u00fcr\u00b7de", "Pri\u00b7sci\u00b7an", "vor", "Na\u00b7sen\u00b7st\u00fc\u00b7ber", "ho\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "NE", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Pfeile, so er schiest, sind auch so gar nicht sein,", "tokens": ["Die", "Pfei\u00b7le", ",", "so", "er", "schiest", ",", "sind", "auch", "so", "gar", "nicht", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "ADV", "PTKNEG", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das Unkraut pflanzt sein Flei\u00df, die Blumen sind gestohlen.", "tokens": ["Das", "Un\u00b7kraut", "pflanzt", "sein", "Flei\u00df", ",", "die", "Blu\u00b7men", "sind", "ge\u00b7stoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er f\u00fcllt, er stopft, er flickt, die Schreibart l\u00e4st so bunt", "tokens": ["Er", "f\u00fcllt", ",", "er", "stopft", ",", "er", "flickt", ",", "die", "Schrei\u00b7bart", "l\u00e4st", "so", "bunt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "ART", "NN", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als Florens Unterrock und Fieckchens Sonntagsm\u00fcze.", "tokens": ["Als", "Flo\u00b7rens", "Un\u00b7ter\u00b7rock", "und", "Fieck\u00b7chens", "Sonn\u00b7tags\u00b7m\u00fc\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "(ihr M\u00e4gdgen, eifert nicht, hier steht die Feuersprize!)", "tokens": ["(", "ihr", "M\u00e4gd\u00b7gen", ",", "ei\u00b7fert", "nicht", ",", "hier", "steht", "die", "Feu\u00b7er\u00b7spri\u00b7ze", "!", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "VVFIN", "PTKNEG", "$,", "ADV", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So macht sich eigner Neid durch fremde Wafen kund,", "tokens": ["So", "macht", "sich", "eig\u00b7ner", "Neid", "durch", "frem\u00b7de", "Wa\u00b7fen", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So f\u00e4ngts die Bo\u00dfheit an, sie wirbt entlehnte Kr\u00e4fte", "tokens": ["So", "f\u00e4ngts", "die", "Bo\u00df\u00b7heit", "an", ",", "sie", "wirbt", "ent\u00b7lehn\u00b7te", "Kr\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und tadelt Sitten, Gang, Vermehlung, Tracht, Gesch\u00e4fte.", "tokens": ["Und", "ta\u00b7delt", "Sit\u00b7ten", ",", "Gang", ",", "Ver\u00b7meh\u00b7lung", ",", "Tracht", ",", "Ge\u00b7sch\u00e4f\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Die Elster springt und h\u00fcpft, bis ihr der R\u00fcckgrad bricht;", "tokens": ["Die", "Els\u00b7ter", "springt", "und", "h\u00fcpft", ",", "bis", "ihr", "der", "R\u00fcck\u00b7grad", "bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es geht, so lang es kan, der Frevel weis ein Ende.", "tokens": ["Es", "geht", ",", "so", "lang", "es", "kan", ",", "der", "Fre\u00b7vel", "weis", "ein", "En\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "ADJD", "PPER", "VMFIN", "$,", "ART", "NN", "PTKVZ", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bis hieher scheut er noch des Phoebus Recht und Licht,", "tokens": ["Bis", "hie\u00b7her", "scheut", "er", "noch", "des", "Phoe\u00b7bus", "Recht", "und", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jezt aber f\u00fchlt auch der die ungewaschnen H\u00e4nde.", "tokens": ["Jezt", "a\u00b7ber", "f\u00fchlt", "auch", "der", "die", "un\u00b7ge\u00b7waschnen", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "ART", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Sein Grif entheiligte der Saythen reinen Klang,", "tokens": ["Sein", "Grif", "en\u00b7thei\u00b7lig\u00b7te", "der", "Say\u00b7then", "rei\u00b7nen", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die er nach seiner Art mit grobem Finger dr\u00fcckte,", "tokens": ["Die", "er", "nach", "sei\u00b7ner", "Art", "mit", "gro\u00b7bem", "Fin\u00b7ger", "dr\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und weil er sich dazu wie Kloz zur Fiedel schickte,", "tokens": ["Und", "weil", "er", "sich", "da\u00b7zu", "wie", "Kloz", "zur", "Fie\u00b7del", "schick\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "PAV", "KOKOM", "NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Verdro\u00df ihn diese Scham, da\u00df niemand schlimmer sang,", "tokens": ["Ver\u00b7dro\u00df", "ihn", "die\u00b7se", "Scham", ",", "da\u00df", "nie\u00b7mand", "schlim\u00b7mer", "sang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, da er sich aus Zorn die N\u00e4gel schon verbi\u00dfen,", "tokens": ["Ja", ",", "da", "er", "sich", "aus", "Zorn", "die", "N\u00e4\u00b7gel", "schon", "ver\u00b7bi\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "PRF", "APPR", "NN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So wollt er Harf und Spiel durchaus zerschmettert wi\u00dfen.", "tokens": ["So", "wollt", "er", "Harf", "und", "Spiel", "durc\u00b7haus", "zer\u00b7schmet\u00b7tert", "wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NE", "KON", "NN", "ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Inmittelst legte sich Calliope darein", "tokens": ["In\u00b7mit\u00b7telst", "leg\u00b7te", "sich", "Cal\u00b7li\u00b7o\u00b7pe", "da\u00b7rein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "NE", "PAV"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und eilte vor den Rath der gro\u00df- und kleinen G\u00f6tter.", "tokens": ["Und", "eil\u00b7te", "vor", "den", "Rath", "der", "gro\u00df", "und", "klei\u00b7nen", "G\u00f6t\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ART", "TRUNC", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie lange, flehte sie, soll ich um H\u00fclfe schreyn?", "tokens": ["Wie", "lan\u00b7ge", ",", "fleh\u00b7te", "sie", ",", "soll", "ich", "um", "H\u00fcl\u00b7fe", "schreyn", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "PPER", "APPR", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Errettet euch und uns von dem verlognen Sp\u00f6tter!", "tokens": ["Er\u00b7ret\u00b7tet", "euch", "und", "uns", "von", "dem", "ver\u00b7log\u00b7nen", "Sp\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er spricht euch st\u00fcndlich Hohn und wird uns noch gewis", "tokens": ["Er", "spricht", "euch", "st\u00fcnd\u00b7lich", "Hohn", "und", "wird", "uns", "noch", "ge\u00b7wis"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "NN", "KON", "VAFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "(davor der Himmel sey) den kleinen Anhang rauben.", "tokens": ["(", "da\u00b7vor", "der", "Him\u00b7mel", "sey", ")", "den", "klei\u00b7nen", "An\u00b7hang", "rau\u00b7ben", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "ART", "NN", "VAFIN", "$(", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Furcht hat viel Beweis; denn wollt ihr mir nicht glauben,", "tokens": ["Die", "Furcht", "hat", "viel", "Be\u00b7weis", ";", "denn", "wollt", "ihr", "mir", "nicht", "glau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$.", "KON", "VMFIN", "PPER", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "So schickt nur den Mercur und fragt Hyopolis,", "tokens": ["So", "schickt", "nur", "den", "Mer\u00b7cur", "und", "fragt", "Hyo\u00b7po\u00b7lis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "KON", "VVFIN", "NE", "$,"], "meter": "-+---+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es wird es euch ein Kind von sieben Jahren sagen,", "tokens": ["Es", "wird", "es", "euch", "ein", "Kind", "von", "sie\u00b7ben", "Jah\u00b7ren", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "ART", "NN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df ihn die Wespen so wie er die Leute plagen.", "tokens": ["Da\u00df", "ihn", "die", "Wes\u00b7pen", "so", "wie", "er", "die", "Leu\u00b7te", "pla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "KOKOM", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.42": {"line.1": {"text": "Es sieht vorhin um uns so schlecht und windicht aus.", "tokens": ["Es", "sieht", "vor\u00b7hin", "um", "uns", "so", "schlecht", "und", "win\u00b7dicht", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPER", "ADV", "ADJD", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Des Phoebus Ehre wanckt und steht auf schwachen F\u00fc\u00dfen,", "tokens": ["Des", "Phoe\u00b7bus", "Eh\u00b7re", "wanckt", "und", "steht", "auf", "schwa\u00b7chen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "VVFIN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sophia gr\u00e4mt sich ab, bewohnt ein fl\u00fcchtges Haus", "tokens": ["So\u00b7phia", "gr\u00e4mt", "sich", "ab", ",", "be\u00b7wohnt", "ein", "fl\u00fccht\u00b7ges", "Haus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PRF", "PTKVZ", "$,", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und kan fast nirgends mehr der alten Ruh genie\u00dfen.", "tokens": ["Und", "kan", "fast", "nir\u00b7gends", "mehr", "der", "al\u00b7ten", "Ruh", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man zehlt die Wi\u00dfenschaft zur Grillenf\u00e4ngerey,", "tokens": ["Man", "zehlt", "die", "Wi\u00b7\u00dfen\u00b7schaft", "zur", "Gril\u00b7len\u00b7f\u00e4n\u00b7ge\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die \u00dcbung der Vernunft wird mit Gewalt verge\u00dfen,", "tokens": ["Die", "\u00dc\u00b7bung", "der", "Ver\u00b7nunft", "wird", "mit", "Ge\u00b7walt", "ver\u00b7ge\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man will ihr Winckelmaas nach eignem D\u00fcnckel me\u00dfen,", "tokens": ["Man", "will", "ihr", "Win\u00b7ckel\u00b7maas", "nach", "eig\u00b7nem", "D\u00fcn\u00b7ckel", "me\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man schwizt, man strebt darnach, da\u00df sie verwickelt sey.", "tokens": ["Man", "schwizt", ",", "man", "strebt", "dar\u00b7nach", ",", "da\u00df", "sie", "ver\u00b7wi\u00b7ckelt", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PIS", "VVFIN", "PAV", "$,", "KOUS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man tritt den wahren Kern und s\u00e4ttigt sich an Schelfen", "tokens": ["Man", "tritt", "den", "wah\u00b7ren", "Kern", "und", "s\u00e4t\u00b7tigt", "sich", "an", "Schel\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und h\u00e4lts noch wohl vor Ruhm, der Warheit hinzuhelfen.", "tokens": ["Und", "h\u00e4lts", "noch", "wohl", "vor", "Ruhm", ",", "der", "War\u00b7heit", "hin\u00b7zu\u00b7hel\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "APPR", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Und steckt gleich hier und dar noch mancher edler Geist,", "tokens": ["Und", "steckt", "gleich", "hier", "und", "dar", "noch", "man\u00b7cher", "ed\u00b7ler", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "KON", "PAV", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der wohl den Schaden merckt und gern ein Wort verl\u00f6re,", "tokens": ["Der", "wohl", "den", "Scha\u00b7den", "merckt", "und", "gern", "ein", "Wort", "ver\u00b7l\u00f6\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "KON", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der darf nicht, wie er will, die Thorheit st\u00f6\u00dft und bei\u00dft,", "tokens": ["Der", "darf", "nicht", ",", "wie", "er", "will", ",", "die", "Thor\u00b7heit", "st\u00f6\u00dft", "und", "bei\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PTKNEG", "$,", "PWAV", "PPER", "VMFIN", "$,", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man schm\u00e4lert sein Verdienst, man raubt ihm Gl\u00fcck und Ehre.", "tokens": ["Man", "schm\u00e4\u00b7lert", "sein", "Ver\u00b7dienst", ",", "man", "raubt", "ihm", "Gl\u00fcck", "und", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$,", "PIS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bleib, feuriger Lucil, bleib ja in deiner Gruft", "tokens": ["Bleib", ",", "feu\u00b7ri\u00b7ger", "Lu\u00b7cil", ",", "bleib", "ja", "in", "dei\u00b7ner", "Gruft"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und las den sichern Kopf im Aschennapfe stecken;", "tokens": ["Und", "las", "den", "si\u00b7chern", "Kopf", "im", "A\u00b7schen\u00b7nap\u00b7fe", "ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn sollte dich ein Fall in unsern Tagen wecken,", "tokens": ["Denn", "soll\u00b7te", "dich", "ein", "Fall", "in", "un\u00b7sern", "Ta\u00b7gen", "we\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Vertr\u00fcgstu nimmermehr die angesteckte Luft,", "tokens": ["Ver\u00b7tr\u00fcgs\u00b7tu", "nim\u00b7mer\u00b7mehr", "die", "an\u00b7ge\u00b7steck\u00b7te", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die Laster w\u00fcrden dir bey so verderbten Zeiten,", "tokens": ["Die", "Las\u00b7ter", "w\u00fcr\u00b7den", "dir", "bey", "so", "ver\u00b7derb\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Th\u00e4t es dein Eifer nicht, den andern Tod bereiten.", "tokens": ["Th\u00e4t", "es", "dein", "Ei\u00b7fer", "nicht", ",", "den", "an\u00b7dern", "Tod", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "$,", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Wer wacker schwazen kan, Registerschreiber braucht,", "tokens": ["Wer", "wa\u00b7cker", "schwa\u00b7zen", "kan", ",", "Re\u00b7gis\u00b7ter\u00b7schrei\u00b7ber", "braucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VVINF", "VMFIN", "$,", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Nahmen um sich wirft, davon die Ohren gellen,", "tokens": ["Mit", "Nah\u00b7men", "um", "sich", "wirft", ",", "da\u00b7von", "die", "Oh\u00b7ren", "gel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PRF", "VVFIN", "$,", "PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den unversch\u00e4mten Kiel in Gall und L\u00fcgen taucht,", "tokens": ["Den", "un\u00b7ver\u00b7sch\u00e4m\u00b7ten", "Kiel", "in", "Gall", "und", "L\u00fc\u00b7gen", "taucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zehn alte Schincken list, den eilften darzustellen,", "tokens": ["Zehn", "al\u00b7te", "Schin\u00b7cken", "list", ",", "den", "eilf\u00b7ten", "dar\u00b7zu\u00b7stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "VVFIN", "$,", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer, sag ich, etwan kaum ein Duzend Drucker kennt", "tokens": ["Wer", ",", "sag", "ich", ",", "et\u00b7wan", "kaum", "ein", "Du\u00b7zend", "Dru\u00b7cker", "kennt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "$,", "VVFIN", "PPER", "$,", "ADV", "ADV", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und herzuschnattern weis, was Brown und Hobbes glaubte,", "tokens": ["Und", "her\u00b7zu\u00b7schnat\u00b7tern", "weis", ",", "was", "Brown", "und", "Hob\u00b7bes", "glaub\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "PRELS", "NE", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Welch Weib des Isaacs Braut am Hochzeitabend haubte,", "tokens": ["Welch", "Weib", "des", "I\u00b7saacs", "Braut", "am", "Hoch\u00b7zei\u00b7ta\u00b7bend", "haub\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NE", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie viel Gelehrte seyn, die man Johannes nennt,", "tokens": ["Wie", "viel", "Ge\u00b7lehr\u00b7te", "seyn", ",", "die", "man", "Jo\u00b7han\u00b7nes", "nennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VAINF", "$,", "PRELS", "PIS", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der heist galant gelehrt; ich rede mit der Mode.", "tokens": ["Der", "heist", "ga\u00b7lant", "ge\u00b7lehrt", ";", "ich", "re\u00b7de", "mit", "der", "Mo\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "VVPP", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Crispin ist so ein Fisch, jedoch aus \u00e4rgrem Sode.", "tokens": ["Cris\u00b7pin", "ist", "so", "ein", "Fisch", ",", "je\u00b7doch", "aus", "\u00e4r\u00b7grem", "So\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ART", "NN", "$,", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Er wird in seiner Stadt wie b\u00f6ses Geld bekand;", "tokens": ["Er", "wird", "in", "sei\u00b7ner", "Stadt", "wie", "b\u00f6\u00b7ses", "Geld", "be\u00b7kand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "KOKOM", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Er heist Astr\u00e4ens Sohn, sie will ihn nicht erkennen", "tokens": ["Er", "heist", "A\u00b7str\u00e4\u00b7ens", "Sohn", ",", "sie", "will", "ihn", "nicht", "er\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "NN", "$,", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und sch\u00e4mt sich, so ein Glied, an dem der kalte Brand", "tokens": ["Und", "sch\u00e4mt", "sich", ",", "so", "ein", "Glied", ",", "an", "dem", "der", "kal\u00b7te", "Brand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "$,", "ADV", "ART", "NN", "$,", "APPR", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Verstockter Einfalt h\u00e4ngt, ein Glied von ihr zu nennen.", "tokens": ["Ver\u00b7stock\u00b7ter", "Ein\u00b7falt", "h\u00e4ngt", ",", "ein", "Glied", "von", "ihr", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Sie \u00e4rgert sich genug, da\u00df er mit Latten l\u00e4uft.", "tokens": ["Sie", "\u00e4r\u00b7gert", "sich", "ge\u00b7nug", ",", "da\u00df", "er", "mit", "Lat\u00b7ten", "l\u00e4uft", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Erst neulich machten ihn, da er aufs Dorf gerathen,", "tokens": ["Erst", "neu\u00b7lich", "mach\u00b7ten", "ihn", ",", "da", "er", "aufs", "Dorf", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Schenck und das Gelach zum Hundstagsadvocaten.", "tokens": ["Die", "Schenck", "und", "das", "Ge\u00b7lach", "zum", "Hunds\u00b7tags\u00b7ad\u00b7vo\u00b7ca\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "So tief verf\u00e4llt ein Mensch, der aus dem Circkel s\u00e4uft.", "tokens": ["So", "tief", "ver\u00b7f\u00e4llt", "ein", "Mensch", ",", "der", "aus", "dem", "Cir\u00b7ckel", "s\u00e4uft", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Dies sprach Calliope und wollte mehr entdecken", "tokens": ["Dies", "sprach", "Cal\u00b7li\u00b7o\u00b7pe", "und", "woll\u00b7te", "mehr", "ent\u00b7de\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "NE", "KON", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und blieb doch unverhoft in der Erzehlung stecken.", "tokens": ["Und", "blieb", "doch", "un\u00b7ver\u00b7hoft", "in", "der", "Er\u00b7zeh\u00b7lung", "ste\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Die Ursach war ein Trupp, den Meditrine schlo\u00df;", "tokens": ["Die", "Ur\u00b7sach", "war", "ein", "Trupp", ",", "den", "Me\u00b7di\u00b7tri\u00b7ne", "schlo\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie jagte den vorher, dem wir sein Lob gesungen.", "tokens": ["Sie", "jag\u00b7te", "den", "vor\u00b7her", ",", "dem", "wir", "sein", "Lob", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADV", "$,", "PRELS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Satyr peitschte zu und schleppt ihn durch den Tro\u00df,", "tokens": ["Ein", "Sa\u00b7tyr", "peitschte", "zu", "und", "schleppt", "ihn", "durch", "den", "Tro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Den die Verwunderung von weiten hergezwungen.", "tokens": ["Den", "die", "Ver\u00b7wun\u00b7de\u00b7rung", "von", "wei\u00b7ten", "her\u00b7ge\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier, rief Hygeens Zorn, kommt, gro\u00dfer Juppiter,", "tokens": ["Hier", ",", "rief", "Hy\u00b7ge\u00b7ens", "Zorn", ",", "kommt", ",", "gro\u00b7\u00dfer", "Jup\u00b7pi\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "NE", "NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.6": {"text": "Der Bruder des Suffens, der meine Priester sch\u00e4ndet", "tokens": ["Der", "Bru\u00b7der", "des", "Suf\u00b7fens", ",", "der", "mei\u00b7ne", "Pries\u00b7ter", "sch\u00e4n\u00b7det"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und unsre Langmuth noch auf neue Bo\u00dfheit wendet.", "tokens": ["Und", "uns\u00b7re", "Lang\u00b7muth", "noch", "auf", "neu\u00b7e", "Bo\u00df\u00b7heit", "wen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ach, bistu, der du bist, ein stets gerechter Herr,", "tokens": ["Ach", ",", "bis\u00b7tu", ",", "der", "du", "bist", ",", "ein", "stets", "ge\u00b7rech\u00b7ter", "Herr", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "$,", "PRELS", "PPER", "VAFIN", "$,", "ART", "ADV", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So las, ich bitte kurz, den sch\u00e4rfsten Spruch erklingen", "tokens": ["So", "las", ",", "ich", "bit\u00b7te", "kurz", ",", "den", "sch\u00e4rfs\u00b7ten", "Spruch", "er\u00b7klin\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PPER", "ADV", "ADJD", "$,", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und dieses Momus-Kind zu der Erk\u00e4ntn\u00fc\u00df bringen.", "tokens": ["Und", "die\u00b7ses", "Mo\u00b7mus\u00b7Kind", "zu", "der", "Er\u00b7k\u00e4nt\u00b7n\u00fc\u00df", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Beklagter wollte viel, allein der G\u00f6tterf\u00fcrst", "tokens": ["Be\u00b7klag\u00b7ter", "woll\u00b7te", "viel", ",", "al\u00b7lein", "der", "G\u00f6t\u00b7ter\u00b7f\u00fcrst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VMFIN", "ADV", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Verschlo\u00df ihm Muth und Mund mit einem finstren Blicke.", "tokens": ["Ver\u00b7schlo\u00df", "ihm", "Muth", "und", "Mund", "mit", "ei\u00b7nem", "finst\u00b7ren", "Bli\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schweig, Tadler, donnert er; denn da\u00df du l\u00fcgen wirst,", "tokens": ["Schweig", ",", "Tad\u00b7ler", ",", "don\u00b7nert", "er", ";", "denn", "da\u00df", "du", "l\u00fc\u00b7gen", "wirst", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "VVFIN", "PPER", "$.", "KON", "KOUS", "PPER", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das sagt dein Angesicht, der Schauplaz stummer T\u00fccke.", "tokens": ["Das", "sagt", "dein", "An\u00b7ge\u00b7sicht", ",", "der", "Schau\u00b7plaz", "stum\u00b7mer", "T\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kein S\u00fcnder deiner Art verdient den Donnerkeil,", "tokens": ["Kein", "S\u00fcn\u00b7der", "dei\u00b7ner", "Art", "ver\u00b7dient", "den", "Don\u00b7ner\u00b7keil", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er streckt nur Riesen hin, besch\u00e4digt keinen Hasen.", "tokens": ["Er", "streckt", "nur", "Rie\u00b7sen", "hin", ",", "be\u00b7sch\u00e4\u00b7digt", "kei\u00b7nen", "Ha\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "PTKVZ", "$,", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Jedoch damit du nicht vergebens Gift geblasen,", "tokens": ["Je\u00b7doch", "da\u00b7mit", "du", "nicht", "ver\u00b7ge\u00b7bens", "Gift", "ge\u00b7bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PTKNEG", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So bieth ich dich anjezt als einen Sclaven feil;", "tokens": ["So", "bieth", "ich", "dich", "an\u00b7jezt", "als", "ei\u00b7nen", "Scla\u00b7ven", "feil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "KOUS", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der ungewohnte Stand soll dir mir derben Schl\u00e4gen", "tokens": ["Der", "un\u00b7ge\u00b7wohn\u00b7te", "Stand", "soll", "dir", "mir", "der\u00b7ben", "Schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das auf Haut und Schedel pr\u00e4gen.", "tokens": ["Das", "auf", "Haut", "und", "Sche\u00b7del", "pr\u00e4\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.47": {"line.1": {"text": "Man both den Tadler aus, kein K\u00e4ufer wollte dran;", "tokens": ["Man", "both", "den", "Tad\u00b7ler", "aus", ",", "kein", "K\u00e4u\u00b7fer", "woll\u00b7te", "dran", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PIAT", "NN", "VMFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Denn der geringste Werth schien allen noch zu theuer.", "tokens": ["Denn", "der", "ge\u00b7rings\u00b7te", "Werth", "schien", "al\u00b7len", "noch", "zu", "theu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PIS", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Silen erbarmte sich, erstund ihn durch den Pan", "tokens": ["Si\u00b7len", "er\u00b7barm\u00b7te", "sich", ",", "er\u00b7stund", "ihn", "durch", "den", "Pan"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PRF", "$,", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und gab vor seinen Leib zween ganze Betteldreyer.", "tokens": ["Und", "gab", "vor", "sei\u00b7nen", "Leib", "zween", "gan\u00b7ze", "Bet\u00b7tel\u00b7dre\u00b7yer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Der stets versofne Gott bestraft ihn recht und gut", "tokens": ["Der", "stets", "ver\u00b7sof\u00b7ne", "Gott", "be\u00b7straft", "ihn", "recht", "und", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN", "ADJD", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und schlug ihn unverh\u00f6rt zu einem Sattelknechte,", "tokens": ["Und", "schlug", "ihn", "un\u00b7ver\u00b7h\u00f6rt", "zu", "ei\u00b7nem", "Sat\u00b7tel\u00b7knech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Damit er k\u00fcnftighin sein Leibpferd h\u00fcten m\u00f6chte,", "tokens": ["Da\u00b7mit", "er", "k\u00fcnf\u00b7tig\u00b7hin", "sein", "Leib\u00b7pferd", "h\u00fc\u00b7ten", "m\u00f6ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das viel vern\u00fcnftiger als so ein W\u00e4chter thut.", "tokens": ["Das", "viel", "ver\u00b7n\u00fcnf\u00b7ti\u00b7ger", "als", "so", "ein", "W\u00e4ch\u00b7ter", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "KOKOM", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Nun kan er, ists nicht wahr? bey seinem Eselstreiben", "tokens": ["Nun", "kan", "er", ",", "ists", "nicht", "wahr", "?", "bey", "sei\u00b7nem", "E\u00b7sel\u00b7strei\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "$,", "VAFIN", "PTKNEG", "PTKVZ", "$.", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Viel m\u00fc\u00dfge Stunden sehn und faule Tage schreiben.", "tokens": ["Viel", "m\u00fc\u00df\u00b7ge", "Stun\u00b7den", "sehn", "und", "fau\u00b7le", "Ta\u00b7ge", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Die Musen murrten noch: die Strafe sey zu leicht.", "tokens": ["Die", "Mu\u00b7sen", "murr\u00b7ten", "noch", ":", "die", "Stra\u00b7fe", "sey", "zu", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$.", "ART", "NN", "VAFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein der Phoebus kam und stillte seine T\u00f6chter:", "tokens": ["Al\u00b7lein", "der", "Phoe\u00b7bus", "kam", "und", "still\u00b7te", "sei\u00b7ne", "T\u00f6ch\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NE", "VVFIN", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "O, seyd mit dem vergn\u00fcgt, was euch das Urthel reicht.", "tokens": ["O", ",", "seyd", "mit", "dem", "ver\u00b7gn\u00fcgt", ",", "was", "euch", "das", "Ur\u00b7thel", "reicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "APPR", "ART", "VVPP", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich straf ihn noch darzu mit ewigem Gel\u00e4chter;", "tokens": ["Ich", "straf", "ihn", "noch", "dar\u00b7zu", "mit", "e\u00b7wi\u00b7gem", "Ge\u00b7l\u00e4ch\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PAV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ist irgends wo ein Volck, das mein Altar erw\u00e4rmt,", "tokens": ["Ist", "ir\u00b7gends", "wo", "ein", "Volck", ",", "das", "mein", "Al\u00b7tar", "er\u00b7w\u00e4rmt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PWAV", "ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Das melde seinen Schimpf den Dichtern aller Zungen.", "tokens": ["Das", "mel\u00b7de", "sei\u00b7nen", "Schimpf", "den", "Dich\u00b7tern", "al\u00b7ler", "Zun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es schalle weit und breit: So ist es dem gelungen,", "tokens": ["Es", "schal\u00b7le", "weit", "und", "breit", ":", "So", "ist", "es", "dem", "ge\u00b7lun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "$.", "ADV", "VAFIN", "PPER", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der mit der Barbarey um den Parna\u00df geschwermt.", "tokens": ["Der", "mit", "der", "Bar\u00b7ba\u00b7rey", "um", "den", "Par\u00b7na\u00df", "ge\u00b7schwermt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Jezt bleibt ihm der Gewinn, da\u00df sein Ged\u00e4chtn\u00fc\u00df stincket,", "tokens": ["Jezt", "bleibt", "ihm", "der", "Ge\u00b7winn", ",", "da\u00df", "sein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "stin\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So lang ein Schlesier aus unsern Brunnen trincket.", "tokens": ["So", "lang", "ein", "Schle\u00b7sier", "aus", "un\u00b7sern", "Brun\u00b7nen", "trin\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.49": {"line.1": {"text": "Den Trost des Delius beschlo\u00df ein Jubelschall.", "tokens": ["Den", "Trost", "des", "De\u00b7lius", "be\u00b7schlo\u00df", "ein", "Ju\u00b7bel\u00b7schall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die Schw\u00e4ne wachten auf und schlugen mit dem Fl\u00fcgel,", "tokens": ["Die", "Schw\u00e4\u00b7ne", "wach\u00b7ten", "auf", "und", "schlu\u00b7gen", "mit", "dem", "Fl\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das Echo lachte nach und der verdiente Fall", "tokens": ["Das", "E\u00b7cho", "lach\u00b7te", "nach", "und", "der", "ver\u00b7dien\u00b7te", "Fall"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Erg\u00f6zte Thal und Hayn, bewegte Berg und H\u00fcgel.", "tokens": ["Er\u00b7g\u00f6z\u00b7te", "Thal", "und", "Hayn", ",", "be\u00b7weg\u00b7te", "Berg", "und", "H\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die frohe Castalis erfuhr den Lobgesang", "tokens": ["Die", "fro\u00b7he", "Cas\u00b7ta\u00b7lis", "er\u00b7fuhr", "den", "Lob\u00b7ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und \u00fcberstieg sich selbst und lief vor Freuden \u00fcber;", "tokens": ["Und", "\u00fc\u00b7bers\u00b7tieg", "sich", "selbst", "und", "lief", "vor", "Freu\u00b7den", "\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "KON", "VVFIN", "APPR", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da war kein Baum so gro\u00df, der nicht je eh je lieber,", "tokens": ["Da", "war", "kein", "Baum", "so", "gro\u00df", ",", "der", "nicht", "je", "eh", "je", "lie\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADV", "ADJD", "$,", "PRELS", "PTKNEG", "ADV", "KOUS", "ADV", "ADV", "$,"], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Als w\u00e4r ein Orpheus da, mit Haupt und Wurzel sprang.", "tokens": ["Als", "w\u00e4r", "ein", "Or\u00b7pheus", "da", ",", "mit", "Haupt", "und", "Wur\u00b7zel", "sprang", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NE", "ADV", "$,", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, das Ger\u00fcchte sagt, es h\u00e4tten Ast und Bl\u00e4tter", "tokens": ["Ja", ",", "das", "Ge\u00b7r\u00fcch\u00b7te", "sagt", ",", "es", "h\u00e4t\u00b7ten", "Ast", "und", "Bl\u00e4t\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Worte nachgezischt: So geh es jedem Sp\u00f6tter!", "tokens": ["Die", "Wor\u00b7te", "nach\u00b7ge\u00b7zischt", ":", "So", "geh", "es", "je\u00b7dem", "Sp\u00f6t\u00b7ter", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$.", "ADV", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Der Pindus war erl\u00f6st. Drum sa\u00df das Jungfernchor", "tokens": ["Der", "Pin\u00b7dus", "war", "er\u00b7l\u00f6st", ".", "Drum", "sa\u00df", "das", "Jung\u00b7fern\u00b7chor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "PAV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und feyrete die Lust der angenehmen Stunde.", "tokens": ["Und", "fey\u00b7re\u00b7te", "die", "Lust", "der", "an\u00b7ge\u00b7neh\u00b7men", "Stun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Calliope stand auf, versucht ihr Heldenrohr,", "tokens": ["Cal\u00b7li\u00b7o\u00b7pe", "stand", "auf", ",", "ver\u00b7sucht", "ihr", "Hel\u00b7den\u00b7rohr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Sah Schweidniz abw\u00e4rts ein und stie\u00df aus vollem Munde:", "tokens": ["Sah", "Schweid\u00b7niz", "ab\u00b7w\u00e4rts", "ein", "und", "stie\u00df", "aus", "vol\u00b7lem", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PTKVZ", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du mir geweihte Stadt, erhebe doch das Haupt", "tokens": ["Du", "mir", "ge\u00b7weih\u00b7te", "Stadt", ",", "er\u00b7he\u00b7be", "doch", "das", "Haupt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "ADJA", "NN", "$,", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Aus der mit deiner Pracht bisher vermengten Asche;", "tokens": ["Aus", "der", "mit", "dei\u00b7ner", "Pracht", "bis\u00b7her", "ver\u00b7meng\u00b7ten", "A\u00b7sche", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "APPR", "PPOSAT", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zeuch Feyerkleider an, zerbrich die Thr\u00e4nenflasche,", "tokens": ["Zeuch", "Fe\u00b7yer\u00b7klei\u00b7der", "an", ",", "zer\u00b7brich", "die", "Thr\u00e4\u00b7nen\u00b7fla\u00b7sche", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKVZ", "$,", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Himmel hat noch mehr, als dir sein Zorn geraubt.", "tokens": ["Der", "Him\u00b7mel", "hat", "noch", "mehr", ",", "als", "dir", "sein", "Zorn", "ge\u00b7raubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "$,", "KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Besinnstu dich denn nicht, da\u00df Schutt und Kohlen d\u00fcngen?", "tokens": ["Be\u00b7sinns\u00b7tu", "dich", "denn", "nicht", ",", "da\u00df", "Schutt", "und", "Koh\u00b7len", "d\u00fcn\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "$,", "KOUS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die St\u00e4tte, wo du weinst, soll Seegensfr\u00fcchte bringen.", "tokens": ["Die", "St\u00e4t\u00b7te", ",", "wo", "du", "weinst", ",", "soll", "See\u00b7gens\u00b7fr\u00fcch\u00b7te", "brin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Dein Carl, dein Kayser, lebt, dein Herr, dein irdscher Gott;", "tokens": ["Dein", "Carl", ",", "dein", "Kay\u00b7ser", ",", "lebt", ",", "dein", "Herr", ",", "dein", "ird\u00b7scher", "Gott", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sein Adler schencket dir den Fittich hoher Gnaden.", "tokens": ["Sein", "Ad\u00b7ler", "schen\u00b7cket", "dir", "den", "Fit\u00b7tich", "ho\u00b7her", "Gna\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verschmerze die Gefahr, vergi\u00df der Feinde Spott,", "tokens": ["Ver\u00b7schmer\u00b7ze", "die", "Ge\u00b7fahr", ",", "ver\u00b7gi\u00df", "der", "Fein\u00b7de", "Spott", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVIMP", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Wucher, den du hofst, ersezt den hei\u00dfen Schaden.", "tokens": ["Der", "Wu\u00b7cher", ",", "den", "du", "hofst", ",", "er\u00b7sezt", "den", "hei\u00b7\u00dfen", "Scha\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein theurer Schaffgotsch wacht, die Allmacht la\u00dfe dir", "tokens": ["Dein", "theu\u00b7rer", "Schaff\u00b7gotsch", "wacht", ",", "die", "All\u00b7macht", "la\u00b7\u00dfe", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Noch unter langer Zeit dies Auge nicht entfallen.", "tokens": ["Noch", "un\u00b7ter", "lan\u00b7ger", "Zeit", "dies", "Au\u00b7ge", "nicht", "ent\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "PDS", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es m\u00fc\u00dfen Fried und Ruh in deinen H\u00e4usern schallen,", "tokens": ["Es", "m\u00fc\u00b7\u00dfen", "Fried", "und", "Ruh", "in", "dei\u00b7nen", "H\u00e4u\u00b7sern", "schal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "KON", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Es \u00fcberkleide dich des reichsten Seegens Zier.", "tokens": ["Es", "\u00fc\u00b7berk\u00b7lei\u00b7de", "dich", "des", "reichs\u00b7ten", "See\u00b7gens", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So wird die Barbarey mit ihren Thorheitskindern", "tokens": ["So", "wird", "die", "Bar\u00b7ba\u00b7rey", "mit", "ih\u00b7ren", "Thor\u00b7heits\u00b7kin\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dir nun und nimmermehr die Wi\u00dfenschaft verhindern.", "tokens": ["Dir", "nun", "und", "nim\u00b7mer\u00b7mehr", "die", "Wi\u00b7\u00dfen\u00b7schaft", "ver\u00b7hin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "Du hast, ber\u00fchmter Ort, der kl\u00fcgsten V\u00e4ter Rath;", "tokens": ["Du", "hast", ",", "be\u00b7r\u00fchm\u00b7ter", "Ort", ",", "der", "kl\u00fcgs\u00b7ten", "V\u00e4\u00b7ter", "Rath", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich \u00fcberla\u00dfe dich der Wei\u00dfheit ihrer Sorgen.", "tokens": ["Ich", "\u00fc\u00b7berl\u00b7a\u00b7\u00dfe", "dich", "der", "Wei\u00df\u00b7heit", "ih\u00b7rer", "Sor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich ruft, ich h\u00f6r es schon, ich h\u00f6r es in der That,", "tokens": ["Mich", "ruft", ",", "ich", "h\u00f6r", "es", "schon", ",", "ich", "h\u00f6r", "es", "in", "der", "That", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein Lied der Siegenden und ein Geschrey von Morgen.", "tokens": ["Ein", "Lied", "der", "Sie\u00b7gen\u00b7den", "und", "ein", "Ge\u00b7schrey", "von", "Mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Fort, Fama, fliege mit, fort, fort, hier gilt kein Ruhn,", "tokens": ["Fort", ",", "Fa\u00b7ma", ",", "flie\u00b7ge", "mit", ",", "fort", ",", "fort", ",", "hier", "gilt", "kein", "Ruhn", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "VVFIN", "PTKVZ", "$,", "PTKVZ", "$,", "PTKVZ", "$,", "ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Fort, las dir beym Vulcan die Siegstrompete be\u00dfern", "tokens": ["Fort", ",", "las", "dir", "beym", "Vul\u00b7can", "die", "Siegs\u00b7trom\u00b7pe\u00b7te", "be\u00b7\u00dfern"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "VVFIN", "PPER", "APPRART", "NE", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.7": {"text": "Und ihre Lieberey in frischem Purpur w\u00e4\u00dfern;", "tokens": ["Und", "ih\u00b7re", "Lie\u00b7be\u00b7rey", "in", "fri\u00b7schem", "Pur\u00b7pur", "w\u00e4\u00b7\u00dfern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Denn dein und unser Amt bekommt gar viel zu thun.", "tokens": ["Denn", "dein", "und", "un\u00b7ser", "Amt", "be\u00b7kommt", "gar", "viel", "zu", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "KON", "PPOSAT", "NN", "VVFIN", "ADV", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Komm, komm dem Helden nach, er eilt mit Ro\u00df und Wagen,", "tokens": ["Komm", ",", "komm", "dem", "Hel\u00b7den", "nach", ",", "er", "eilt", "mit", "Ro\u00df", "und", "Wa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er eilt, er steht, er schl\u00e4gt, Triumph! wir m\u00fc\u00dfens sagen.", "tokens": ["Er", "eilt", ",", "er", "steht", ",", "er", "schl\u00e4gt", ",", "Tri\u00b7umph", "!", "wir", "m\u00fc\u00b7\u00dfens", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$,", "NN", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}