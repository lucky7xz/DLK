{"textgrid.poem.54004": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Die Tagung", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nun, Mutter, b\u00fcrst mir den Zylinder,", "tokens": ["Nun", ",", "Mut\u00b7ter", ",", "b\u00fcrst", "mir", "den", "Zy\u00b7lin\u00b7der", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "den guten Sonntags-Gehrock hol herbei;", "tokens": ["den", "gu\u00b7ten", "Sonn\u00b7tags\u00b7Geh\u00b7rock", "hol", "her\u00b7bei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "gehab dich wohl \u2013 pa\u00df gut auf, auf die Kinder,", "tokens": ["ge\u00b7hab", "dich", "wohl", "\u2013", "pa\u00df", "gut", "auf", ",", "auf", "die", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$(", "VVIMP", "ADJD", "PTKVZ", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "pack mir die Stullen ein und auch ein Ei . . .", "tokens": ["pack", "mir", "die", "Stul\u00b7len", "ein", "und", "auch", "ein", "Ei", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "PTKVZ", "KON", "ADV", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Heut fahr ich los, um neun Uhr, im Expre\u00df . . .", "tokens": ["Heut", "fahr", "ich", "los", ",", "um", "neun", "Uhr", ",", "im", "Ex\u00b7pre\u00df", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "APPR", "CARD", "NN", "$,", "APPRART", "NN", "$.", "$.", "$."], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}, "line.6": {"text": "heut ist Kongre\u00df!", "tokens": ["heut", "ist", "Kon\u00b7gre\u00df", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Vom Reichsverband sind die Kollegen", "tokens": ["Vom", "Reichs\u00b7ver\u00b7band", "sind", "die", "Kol\u00b7le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "schon alle in die ferne Stadt geeilt.", "tokens": ["schon", "al\u00b7le", "in", "die", "fer\u00b7ne", "Stadt", "ge\u00b7eilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man wird uns dort brillant verpflegen,", "tokens": ["Man", "wird", "uns", "dort", "bril\u00b7lant", "ver\u00b7pfle\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "weil ein Minister bei uns weilt.", "tokens": ["weil", "ein", "Mi\u00b7nis\u00b7ter", "bei", "uns", "weilt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Hoteliers sind froh. Sie wissen es:", "tokens": ["Die", "Ho\u00b7te\u00b7liers", "sind", "froh", ".", "Sie", "wis\u00b7sen", "es", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "heut ist Kongre\u00df.", "tokens": ["heut", "ist", "Kon\u00b7gre\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Zu ernster Arbeit sind wir dort versammelt.", "tokens": ["Zu", "erns\u00b7ter", "Ar\u00b7beit", "sind", "wir", "dort", "ver\u00b7sam\u00b7melt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Herr Minister spricht \u2013 das ist der Clou", "tokens": ["Der", "Herr", "Mi\u00b7nis\u00b7ter", "spricht", "\u2013", "das", "ist", "der", "Clou"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$(", "PDS", "VAFIN", "ART", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "(da ist der Saal noch voll, voll wie gerammelt) \u2013", "tokens": ["(", "da", "ist", "der", "Saal", "noch", "voll", ",", "voll", "wie", "ge\u00b7ram\u00b7melt", ")", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,", "ADJD", "KOKOM", "VVPP", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "er sagt uns seine Unterst\u00fctzung zu . . .", "tokens": ["er", "sagt", "uns", "sei\u00b7ne", "Un\u00b7ter\u00b7st\u00fct\u00b7zung", "zu", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das ist ein gro\u00dfes Wort. Ein amtliches \u2013", "tokens": ["Das", "ist", "ein", "gro\u00b7\u00dfes", "Wort", ".", "Ein", "amt\u00b7li\u00b7ches", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "ART", "ADJA", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "heut ist Kongre\u00df.", "tokens": ["heut", "ist", "Kon\u00b7gre\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Dann wird man viele sch\u00f6nen Reden h\u00f6ren.", "tokens": ["Dann", "wird", "man", "vie\u00b7le", "sch\u00f6\u00b7nen", "Re\u00b7den", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jedweder bittet um des Wortes Gunst.", "tokens": ["Jed\u00b7we\u00b7der", "bit\u00b7tet", "um", "des", "Wor\u00b7tes", "Gunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.3": {"text": "Da kann uns die Opposition nicht st\u00f6ren \u2013", "tokens": ["Da", "kann", "uns", "die", "Op\u00b7po\u00b7si\u00b7ti\u00b7on", "nicht", "st\u00f6\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Abstimmen lassen ist ", "tokens": ["Ab\u00b7stim\u00b7men", "las\u00b7sen", "ist"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVINF", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die H\u00e4nde hoch! Und kurz ist der Proze\u00df . . .", "tokens": ["Die", "H\u00e4n\u00b7de", "hoch", "!", "Und", "kurz", "ist", "der", "Pro\u00b7ze\u00df", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "ADJD", "$.", "KON", "ADJD", "VAFIN", "ART", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "heut ist Kongre\u00df.", "tokens": ["heut", "ist", "Kon\u00b7gre\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Wir sprechen von den einfach ungeheuern", "tokens": ["Wir", "spre\u00b7chen", "von", "den", "ein\u00b7fach", "un\u00b7ge\u00b7heu\u00b7ern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Unkosten in Fabrik und in B\u00fcro", "tokens": ["Un\u00b7kos\u00b7ten", "in", "Fab\u00b7rik", "und", "in", "B\u00fc\u00b7ro"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "NN", "KON", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und von den viel zu hohen Steuern \u2013", "tokens": ["und", "von", "den", "viel", "zu", "ho\u00b7hen", "Steu\u00b7ern", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADV", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbdas, meine Herren, geht nicht weiter so!", "tokens": ["\u00bb", "das", ",", "mei\u00b7ne", "Her\u00b7ren", ",", "geht", "nicht", "wei\u00b7ter", "so", "!"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PTKNEG", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was hier geschieht, ist ein Exze\u00df!\u00ab", "tokens": ["Was", "hier", "ge\u00b7schieht", ",", "ist", "ein", "Ex\u00b7ze\u00df", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADV", "VVFIN", "$,", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Heut ist Kongre\u00df.", "tokens": ["Heut", "ist", "Kon\u00b7gre\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Im Saal ein Nickerchen . . . die Uhr ist viere . . .", "tokens": ["Im", "Saal", "ein", "Ni\u00b7cker\u00b7chen", ".", ".", ".", "die", "Uhr", "ist", "vie\u00b7re", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$.", "$.", "$.", "ART", "NN", "VAFIN", "PIS", "$.", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Redner liest und liest und redet seins . . .", "tokens": ["Der", "Red\u00b7ner", "liest", "und", "liest", "und", "re\u00b7det", "seins", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "NE", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dann sitzen wir in Reihen froh beim Biere", "tokens": ["Dann", "sit\u00b7zen", "wir", "in", "Rei\u00b7hen", "froh", "beim", "Bie\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und trinken, trinken immer noch eins.", "tokens": ["und", "trin\u00b7ken", ",", "trin\u00b7ken", "im\u00b7mer", "noch", "eins", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "ADV", "ADV", "PIS", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Denn, Mutter, schon die ollen Germanen", "tokens": ["Denn", ",", "Mut\u00b7ter", ",", "schon", "die", "ol\u00b7len", "Ger\u00b7ma\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "NN", "$,", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "versammelten sich mit allen Schikanen", "tokens": ["ver\u00b7sam\u00b7mel\u00b7ten", "sich", "mit", "al\u00b7len", "Schi\u00b7ka\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.7": {"text": "rechts vom Rhein und links vom Rhein:", "tokens": ["rechts", "vom", "Rhein", "und", "links", "vom", "Rhein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NE", "KON", "ADV", "APPRART", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Deutsche Arbeit will beredet sein.", "tokens": ["Deut\u00b7sche", "Ar\u00b7beit", "will", "be\u00b7re\u00b7det", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Weil selbe immer nur gedeiht", "tokens": ["Weil", "sel\u00b7be", "im\u00b7mer", "nur", "ge\u00b7deiht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADJA", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "im Treibhaus unserer Wichtigkeit.", "tokens": ["im", "Treib\u00b7haus", "un\u00b7se\u00b7rer", "Wich\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Leb wohl! Da pfeift schon der Expre\u00df . . . !", "tokens": ["Leb", "wohl", "!", "Da", "pfeift", "schon", "der", "Ex\u00b7pre\u00df", ".", ".", ".", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["VVIMP", "ADV", "$.", "ADV", "VVFIN", "ADV", "ART", "NN", "$.", "$.", "$.", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Heut ist Kongre\u00df.", "tokens": ["Heut", "ist", "Kon\u00b7gre\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}