{"textgrid.poem.54257": {"metadata": {"author": {"name": "Ziegler, Christiana Mariana von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Geschickter P-- du Wunder unsrer Zeiten,", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Geschickter P-- du Wunder unsrer Zeiten,", "tokens": ["Ge\u00b7schick\u00b7ter", "P\u00b7", "du", "Wun\u00b7der", "uns\u00b7rer", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "TRUNC", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "meter.parsing.error", "measure": "measure.parsing.error"}, "line.2": {"text": "Kein Virtuose wird mit mir deswegen streiten,", "tokens": ["Kein", "Vir\u00b7tu\u00b7o\u00b7se", "wird", "mit", "mir", "des\u00b7we\u00b7gen", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "PPER", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kein heydnisch G\u00f6tzen-Bild ruf ich zum Zeugen an,", "tokens": ["Kein", "heyd\u00b7nisch", "G\u00f6t\u00b7zen\u00b7Bild", "ruf", "ich", "zum", "Zeu\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil Schatt- und Fabel-Werck kein Zeugni\u00df geben kan.", "tokens": ["Weil", "Schat\u00b7t", "und", "Fa\u00b7bel\u00b7\u00b7Werck", "kein", "Zeug\u00b7ni\u00df", "ge\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "TRUNC", "KON", "NN", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+--+-+-+-+--", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ein schwartzer Linden-Baum mag dir kein Lob-Lied dichten,", "tokens": ["Ein", "schwart\u00b7zer", "Lin\u00b7den\u00b7Baum", "mag", "dir", "kein", "Lob\u00b7Lied", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "PIAT", "NN", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie mag ein d\u00fcrrer Ast die Melodie berichten?", "tokens": ["Wie", "mag", "ein", "d\u00fcr\u00b7rer", "Ast", "die", "Me\u00b7lo\u00b7die", "be\u00b7rich\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein Werth und auch dein Ruhm, der dich unsch\u00e4tzbar macht,", "tokens": ["Dein", "Werth", "und", "auch", "dein", "Ruhm", ",", "der", "dich", "un\u00b7sch\u00e4tz\u00b7bar", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "ADV", "PPOSAT", "NN", "$,", "PRELS", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Steigt h\u00f6her, als der Ruf, den man dir zugedacht.", "tokens": ["Steigt", "h\u00f6\u00b7her", ",", "als", "der", "Ruf", ",", "den", "man", "dir", "zu\u00b7ge\u00b7dacht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "KOUS", "ART", "NN", "$,", "PRELS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich suche nicht den Kiel in Schmeicheley zu tauchen,", "tokens": ["Ich", "su\u00b7che", "nicht", "den", "Kiel", "in", "Schmei\u00b7che\u00b7ley", "zu", "tau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn heucheln darff man nicht bey Orpheus S\u00f6hnen brauchen.", "tokens": ["Denn", "heu\u00b7cheln", "darff", "man", "nicht", "bey", "Or\u00b7pheus", "S\u00f6h\u00b7nen", "brau\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "PIS", "PTKNEG", "APPR", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wer deine Fl\u00f6the h\u00f6rt, sagt di\u00df Gest\u00e4ndni\u00df frey:", "tokens": ["Wer", "dei\u00b7ne", "Fl\u00f6\u00b7the", "h\u00f6rt", ",", "sagt", "di\u00df", "Ge\u00b7st\u00e4nd\u00b7ni\u00df", "frey", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Da\u00df in Germanien nicht deines gleichen sey.", "tokens": ["Da\u00df", "in", "Ger\u00b7ma\u00b7ni\u00b7en", "nicht", "dei\u00b7nes", "glei\u00b7chen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "PTKNEG", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ein Kluger wei\u00df gar wohl den Unterscheid zu machen,", "tokens": ["Ein", "Klu\u00b7ger", "wei\u00df", "gar", "wohl", "den", "Un\u00b7ter\u00b7scheid", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Man sieht bey deinen Thon die Charitinnen lachen,", "tokens": ["Man", "sieht", "bey", "dei\u00b7nen", "Thon", "die", "Cha\u00b7ri\u00b7tin\u00b7nen", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Worbey man gantz erstaunt ein sanfftes Echo h\u00f6rt,", "tokens": ["Wor\u00b7bey", "man", "gantz", "er\u00b7staunt", "ein", "sanff\u00b7tes", "E\u00b7cho", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Das uns, Amphion gleich, so Sinn als Ohr beth\u00f6rt.", "tokens": ["Das", "uns", ",", "Am\u00b7phi\u00b7on", "gleich", ",", "so", "Sinn", "als", "Ohr", "be\u00b7th\u00f6rt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "$,", "NN", "ADV", "$,", "ADV", "NN", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Besonders ist an dir die Sittensamkeit zu loben,", "tokens": ["Be\u00b7son\u00b7ders", "ist", "an", "dir", "die", "Sit\u00b7ten\u00b7sam\u00b7keit", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PPER", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.18": {"text": "Denn P-- hat nie sein Noten-Block erhoben,", "tokens": ["Denn", "P\u00b7", "hat", "nie", "sein", "No\u00b7ten\u00b7Block", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "TRUNC", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "meter.parsing.error", "measure": "measure.parsing.error"}, "line.19": {"text": "Er wei\u00df, da\u00df Kunst und Griff den Meister selber prei\u00dft,", "tokens": ["Er", "wei\u00df", ",", "da\u00df", "Kunst", "und", "Griff", "den", "Meis\u00b7ter", "sel\u00b7ber", "prei\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ob gleich kein Schmeichel-Lied ihn mit Douceurgen spei\u00dft!", "tokens": ["Ob", "gleich", "kein", "Schmei\u00b7chel\u00b7Lied", "ihn", "mit", "Dou\u00b7ce\u00b7ur\u00b7gen", "spei\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}}}}