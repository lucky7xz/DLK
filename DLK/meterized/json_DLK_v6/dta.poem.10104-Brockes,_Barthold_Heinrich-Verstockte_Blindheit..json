{"dta.poem.10104": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Verstockte Blindheit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der nimmer ruhige verschmitzte Cacopist,", "tokens": ["Der", "nim\u00b7mer", "ru\u00b7hi\u00b7ge", "ver\u00b7schmitz\u00b7te", "Ca\u00b7co\u00b7pist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein Arbeit-seelger Alchymist,", "tokens": ["Ein", "Ar\u00b7beit\u00b7seel\u00b7ger", "Al\u00b7chy\u00b7mist", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tag und Nacht aus Bley, und aus verbrannten Kohlen,", "tokens": ["Der", "Tag", "und", "Nacht", "aus", "Bley", ",", "und", "aus", "ver\u00b7brann\u00b7ten", "Koh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "$,", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Weisen Stein besch\u00e4fftigt war zu holen;", "tokens": ["Der", "Wei\u00b7sen", "Stein", "be\u00b7sch\u00e4ff\u00b7tigt", "war", "zu", "ho\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Dem aber nun, weil er so offt betrogen,", "tokens": ["Dem", "a\u00b7ber", "nun", ",", "weil", "er", "so", "offt", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sein letzter Heller auch aus dem Camin geflogen,", "tokens": ["Sein", "letz\u00b7ter", "Hel\u00b7ler", "auch", "aus", "dem", "Ca\u00b7min", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ward von dem m\u00e4chtigen und reichen Agathander", "tokens": ["Ward", "von", "dem", "m\u00e4ch\u00b7ti\u00b7gen", "und", "rei\u00b7chen", "A\u00b7gat\u00b7han\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "In seiner Klufft besucht, wo schwartz berauchte W\u00e4nde,", "tokens": ["In", "sei\u00b7ner", "Klufft", "be\u00b7sucht", ",", "wo", "schwartz", "be\u00b7rauch\u00b7te", "W\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,", "PWAV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo Schlacken sonder Maa\u00df, wo Tiegel ohne Zahl,", "tokens": ["Wo", "Schla\u00b7cken", "son\u00b7der", "Maa\u00df", ",", "wo", "Tie\u00b7gel", "oh\u00b7ne", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "$,", "PWAV", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wo Oefen sonder Ende,", "tokens": ["Wo", "O\u00b7e\u00b7fen", "son\u00b7der", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Und welche nun, seit so viel Jahren,", "tokens": ["Und", "wel\u00b7che", "nun", ",", "seit", "so", "viel", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "ADV", "$,", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Zum ersten mahl", "tokens": ["Zum", "ers\u00b7ten", "mahl"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Vom Feur und Kohlen leer und kalt,", "tokens": ["Vom", "Feur", "und", "Koh\u00b7len", "leer", "und", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Bey Hauffen anzutreffen waren.", "tokens": ["Bey", "Hauf\u00b7fen", "an\u00b7zu\u00b7tref\u00b7fen", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Aus diesem Schwefel-Loch und finstern Aufenthalt,", "tokens": ["Aus", "die\u00b7sem", "Schwe\u00b7fel\u00b7Loch", "und", "fins\u00b7tern", "Auf\u00b7ent\u00b7halt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wird Cacopist, mit vieler H\u00f6flichkeit", "tokens": ["Wird", "Ca\u00b7co\u00b7pist", ",", "mit", "vie\u00b7ler", "H\u00f6f\u00b7lich\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und Bitten, in ein Schlo\u00df gezogen,", "tokens": ["Und", "Bit\u00b7ten", ",", "in", "ein", "Schlo\u00df", "ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Agathander erst vor kurtzer Zeit,", "tokens": ["Das", "A\u00b7gat\u00b7han\u00b7der", "erst", "vor", "kurt\u00b7zer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Nebst einem mehr als K\u00f6niglichen Garten,", "tokens": ["Nebst", "ei\u00b7nem", "mehr", "als", "K\u00f6\u00b7nig\u00b7li\u00b7chen", "Gar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Erbaut und angelegt. Die Pracht, Vollkommenheit,", "tokens": ["Er\u00b7baut", "und", "an\u00b7ge\u00b7legt", ".", "Die", "Pracht", ",", "Voll\u00b7kom\u00b7men\u00b7heit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "VVPP", "$.", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Bau-Kunst, tausend Arten", "tokens": ["Die", "Bau\u00b7Kunst", ",", "tau\u00b7send", "Ar\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Von fremder Seltenheit,", "tokens": ["Von", "frem\u00b7der", "Sel\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Fontainen, Grotten und Alleen;", "tokens": ["Fon\u00b7tai\u00b7nen", ",", "Grot\u00b7ten", "und", "Al\u00b7leen", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die fast nicht abzusehen seyn;", "tokens": ["Die", "fast", "nicht", "ab\u00b7zu\u00b7se\u00b7hen", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "VVIZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Geb\u00fcsche voller Nachtigallen", "tokens": ["Ge\u00b7b\u00fc\u00b7sche", "vol\u00b7ler", "Nach\u00b7ti\u00b7gal\u00b7len"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Gew\u00e4sser die von Stein auf Stein", "tokens": ["Ge\u00b7w\u00e4s\u00b7ser", "die", "von", "Stein", "auf", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Mit murmelndem Geriesel fallen,", "tokens": ["Mit", "mur\u00b7meln\u00b7dem", "Ge\u00b7rie\u00b7sel", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Sind ja so sch\u00f6n daselbst, als zu Jertzbeck, zu sehen.", "tokens": ["Sind", "ja", "so", "sch\u00f6n", "da\u00b7selbst", ",", "als", "zu", "Jertz\u00b7beck", ",", "zu", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "PAV", "$,", "KOUS", "APPR", "NE", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Was denckst du nun, wie Cacopist,", "tokens": ["Was", "denckst", "du", "nun", ",", "wie", "Ca\u00b7co\u00b7pist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "PWAV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der nunmehr mehr im Paradise", "tokens": ["Der", "nun\u00b7mehr", "mehr", "im", "Pa\u00b7ra\u00b7di\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als wie in einem Garten ist,", "tokens": ["Als", "wie", "in", "ei\u00b7nem", "Gar\u00b7ten", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich gegen alle Pracht erwiese?", "tokens": ["Sich", "ge\u00b7gen", "al\u00b7le", "Pracht", "er\u00b7wie\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was meinest du?", "tokens": ["Was", "mei\u00b7nest", "du", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Er stopffte Nas\u2019 und Ohr, und knipff die Augen zu;", "tokens": ["Er", "stopff\u00b7te", "Nas'", "und", "Ohr", ",", "und", "knipff", "die", "Au\u00b7gen", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Um in den eitlen Gold-Gedancken", "tokens": ["Um", "in", "den", "eit\u00b7len", "Gold\u00b7Ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sich nicht zu st\u00f6ren,", "tokens": ["Sich", "nicht", "zu", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Auch seinen G\u00f6nner nicht zu ehren,", "tokens": ["Auch", "sei\u00b7nen", "G\u00f6n\u00b7ner", "nicht", "zu", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wollt er nicht riechen, sehn noch h\u00f6ren.", "tokens": ["Wollt", "er", "nicht", "rie\u00b7chen", ",", "sehn", "noch", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Die Bosheit nun ward Agathander gleich,", "tokens": ["Die", "Bos\u00b7heit", "nun", "ward", "A\u00b7gat\u00b7han\u00b7der", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch ohn Betr\u00fcbni\u00df nicht, gewahr:", "tokens": ["Doch", "ohn", "Be\u00b7tr\u00fcb\u00b7ni\u00df", "nicht", ",", "ge\u00b7wahr", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "NN", "PTKNEG", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und, sonder sich mit ihm zu zancken und zu streiten,", "tokens": ["Und", ",", "son\u00b7der", "sich", "mit", "ihm", "zu", "zan\u00b7cken", "und", "zu", "strei\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KON", "PRF", "APPR", "PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Lie\u00df er ihn wieder\u00fcm in seine H\u00f6le leiten.", "tokens": ["Lie\u00df", "er", "ihn", "wie\u00b7de\u00b7r\u00fcm", "in", "sei\u00b7ne", "H\u00f6\u00b7le", "lei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ach leider! w\u00e4ren nur nicht viele Christen", "tokens": ["Ach", "lei\u00b7der", "!", "w\u00e4\u00b7ren", "nur", "nicht", "vie\u00b7le", "Chris\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "$.", "VAFIN", "ADV", "PTKNEG", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "In dieser sch\u00f6nen Welt dergleichen Cacopisten!", "tokens": ["In", "die\u00b7ser", "sch\u00f6\u00b7nen", "Welt", "derg\u00b7lei\u00b7chen", "Ca\u00b7co\u00b7pis\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "PIS", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}