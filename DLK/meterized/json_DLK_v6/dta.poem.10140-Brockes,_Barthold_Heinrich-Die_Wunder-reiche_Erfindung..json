{"dta.poem.10140": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Wunder-reiche Erfindung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Auf, auf, mein Geist, auf, auf! versammle deine Kr\u00e4ffte", "tokens": ["Auf", ",", "auf", ",", "mein", "Geist", ",", "auf", ",", "auf", "!", "ver\u00b7samm\u00b7le", "dei\u00b7ne", "Kr\u00e4ff\u00b7te"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "$,", "PTKVZ", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$,", "PTKVZ", "$.", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und folge williglich dem ietzt versp\u00fcrten Zug!", "tokens": ["Und", "fol\u00b7ge", "wil\u00b7lig\u00b7lich", "dem", "ietzt", "ver\u00b7sp\u00fcr\u00b7ten", "Zug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bereite dich zu einem hohen Flug!", "tokens": ["Be\u00b7rei\u00b7te", "dich", "zu", "ei\u00b7nem", "ho\u00b7hen", "Flug", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es reitzt und leitet dich ein wichtiges Gesch\u00e4ffte", "tokens": ["Es", "reitzt", "und", "lei\u00b7tet", "dich", "ein", "wich\u00b7ti\u00b7ges", "Ge\u00b7sch\u00e4ff\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu einer nie betretnen Bahn.", "tokens": ["Zu", "ei\u00b7ner", "nie", "be\u00b7tret\u00b7nen", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es wird dir eine Th\u00fcr zum Himmel aufgethan;", "tokens": ["Es", "wird", "dir", "ei\u00b7ne", "Th\u00fcr", "zum", "Him\u00b7mel", "auf\u00b7ge\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein Abgrund aufgedeckt, der allen unsichtbar:", "tokens": ["Ein", "Ab\u00b7grund", "auf\u00b7ge\u00b7deckt", ",", "der", "al\u00b7len", "un\u00b7sicht\u00b7bar", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "PRELS", "PIAT", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und welchen keinem Witz, bishero zu entriegeln,", "tokens": ["Und", "wel\u00b7chen", "kei\u00b7nem", "Witz", ",", "bis\u00b7he\u00b7ro", "zu", "ent\u00b7rie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "PIAT", "NN", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Noch die Geheimnisse derselben zu entsiegeln,", "tokens": ["Noch", "die", "Ge\u00b7heim\u00b7nis\u00b7se", "der\u00b7sel\u00b7ben", "zu", "ent\u00b7sie\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PDAT", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von allen Sterblichen bisher verg\u00f6nnet war.", "tokens": ["Von", "al\u00b7len", "Sterb\u00b7li\u00b7chen", "bis\u00b7her", "ver\u00b7g\u00f6n\u00b7net", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Hier, deucht mich, h\u00f6r\u2019 ich dich, mein Leser, billig fragen:", "tokens": ["Hier", ",", "deucht", "mich", ",", "h\u00f6r'", "ich", "dich", ",", "mein", "Le\u00b7ser", ",", "bil\u00b7lig", "fra\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PRF", "$,", "PPOSAT", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo ist die\u00df Wunder denn? Wolan! ich will dirs sagen.", "tokens": ["Wo", "ist", "die\u00df", "Wun\u00b7der", "denn", "?", "Wo\u00b7lan", "!", "ich", "will", "dirs", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PDS", "NN", "KON", "$.", "ADV", "$.", "PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Von unsers Sch\u00f6pfers Gr\u00f6ss\u2019 und Wunder mehr zu", "tokens": ["Von", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Gr\u00f6ss'", "und", "Wun\u00b7der", "mehr", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "KON", "NN", "ADV", "PTKZU"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Und Seiner Wercke Meng\u2019 noch tieffer einzusehn,", "tokens": ["Und", "Sei\u00b7ner", "Wer\u00b7cke", "Meng'", "noch", "tief\u00b7fer", "ein\u00b7zu\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als von der Menschheit sonst geschehn,", "tokens": ["Als", "von", "der", "Menschheit", "sonst", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Hat Er die Menschheit wehrt geachtet,", "tokens": ["Hat", "Er", "die", "Menschheit", "wehrt", "ge\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und, vor nicht gar zu langer Zeit,", "tokens": ["Und", ",", "vor", "nicht", "gar", "zu", "lan\u00b7ger", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "PTKNEG", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Fern- und Gr\u00f6ssrungs-Glas erfinden lassen.", "tokens": ["Ein", "Fern", "und", "Gr\u00f6ss\u00b7rungs\u00b7Glas", "er\u00b7fin\u00b7den", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Damit Sein\u2019 Allmacht, Lieb\u2019 und weise Herrlichkeit", "tokens": ["Da\u00b7mit", "Sein'", "All\u00b7macht", ",", "Lieb'", "und", "wei\u00b7se", "Herr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "PPOSAT", "NN", "$,", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "W\u00fcrd\u2019 ehrerbietiger und mehr annoch betrachtet.", "tokens": ["W\u00fcrd'", "ehr\u00b7er\u00b7bie\u00b7ti\u00b7ger", "und", "mehr", "an\u00b7noch", "be\u00b7trach\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Die\u00df ist wahrhaftig wehrt, ja nicht nur wehrt allein", "tokens": ["Die\u00df", "ist", "wahr\u00b7haf\u00b7tig", "wehrt", ",", "ja", "nicht", "nur", "wehrt", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJD", "VVFIN", "$,", "ADV", "PTKNEG", "ADV", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von Ehr-Furcht ausser sich dadurch gesetzt zu seyn;", "tokens": ["Von", "Ehr\u00b7Furcht", "aus\u00b7ser", "sich", "da\u00b7durch", "ge\u00b7setzt", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PRF", "PAV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die gr\u00f6sste Schuldigkeit erforderts, zu erwegen,", "tokens": ["Die", "gr\u00f6ss\u00b7te", "Schul\u00b7dig\u00b7keit", "er\u00b7for\u00b7derts", ",", "zu", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Welch ein Geheimni\u00df-voller Segen", "tokens": ["Welch", "ein", "Ge\u00b7heim\u00b7ni\u00df\u00b7vol\u00b7ler", "Se\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "In diesem Werck-Zeug steckt,", "tokens": ["In", "die\u00b7sem", "Wer\u00b7ck\u00b7Zeug", "steckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "So uns des Sch\u00f6pfers Huld, kein Ungefehr, entdeckt.", "tokens": ["So", "uns", "des", "Sch\u00f6p\u00b7fers", "Huld", ",", "kein", "Un\u00b7ge\u00b7fehr", ",", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PPER", "ART", "NN", "NN", "$,", "PIAT", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "In Dir, verborgner GOtt, nichts ist, das auf der Welt", "tokens": ["In", "Dir", ",", "ver\u00b7borg\u00b7ner", "Gott", ",", "nichts", "ist", ",", "das", "auf", "der", "Welt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "ADJA", "NN", "$,", "PIS", "VAFIN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von Deiner Majest\u00e4t was w\u00fcrdigers, was gr\u00f6ssers,", "tokens": ["Von", "Dei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "was", "w\u00fcr\u00b7di\u00b7gers", ",", "was", "gr\u00f6s\u00b7sers", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PWS", "VAFIN", "$,", "PWS", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was unbegreifflichers, was herrlichers, was bessers,", "tokens": ["Was", "un\u00b7be\u00b7greif\u00b7fli\u00b7chers", ",", "was", "herr\u00b7li\u00b7chers", ",", "was", "bes\u00b7sers", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADV", "$,", "PRELS", "ADV", "$,", "PRELS", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So vor den leiblichen, als Seelen-Augen, stellt.", "tokens": ["So", "vor", "den", "leib\u00b7li\u00b7chen", ",", "als", "See\u00b7len\u00b7Au\u00b7gen", ",", "stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "$,", "KOUS", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nichts ist, das Deine Macht, im grossen und im kleinen,", "tokens": ["Nichts", "ist", ",", "das", "Dei\u00b7ne", "Macht", ",", "im", "gros\u00b7sen", "und", "im", "klei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "$,", "PRELS", "PPOSAT", "NN", "$,", "APPRART", "ADJA", "KON", "APPRART", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In einem hellern Licht, in einer gr\u00f6ssern Klarheit", "tokens": ["In", "ei\u00b7nem", "hel\u00b7lern", "Licht", ",", "in", "ei\u00b7ner", "gr\u00f6s\u00b7sern", "Klar\u00b7heit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In un\u00fcmst\u00f6\u00dflicher und klarern Wahrheit", "tokens": ["In", "un\u00b7\u00fcm\u00b7st\u00f6\u00df\u00b7li\u00b7cher", "und", "kla\u00b7rern", "Wahr\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Uns \u00fcberzeuglich scheinen,", "tokens": ["Uns", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Und heller sehen l\u00e4sst. Nichts, das auch unsern Geist", "tokens": ["Und", "hel\u00b7ler", "se\u00b7hen", "l\u00e4sst", ".", "Nichts", ",", "das", "auch", "un\u00b7sern", "Geist"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVINF", "VVFIN", "$.", "PIS", "$,", "PRELS", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zugleich so sehr erhebt, und seinen Vorzug weist,", "tokens": ["Zu\u00b7gleich", "so", "sehr", "er\u00b7hebt", ",", "und", "sei\u00b7nen", "Vor\u00b7zug", "weist", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVFIN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Als dieses Wunder-Werck.", "tokens": ["Als", "die\u00b7ses", "Wun\u00b7der\u00b7\u00b7Werck", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das Schatz-Haus der Natur wird uns ietzt aufgedeckt:", "tokens": ["Das", "Schatz\u00b7Haus", "der", "Na\u00b7tur", "wird", "uns", "ietzt", "auf\u00b7ge\u00b7deckt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was in dem schwartzen Reich der tieffen Dunckelheit,", "tokens": ["Was", "in", "dem", "schwart\u00b7zen", "Reich", "der", "tief\u00b7fen", "Dun\u00b7ckel\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja fast in einem Nichts, bisher f\u00fcr uns gesteckt,", "tokens": ["Ja", "fast", "in", "ei\u00b7nem", "Nichts", ",", "bis\u00b7her", "f\u00fcr", "uns", "ge\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "APPR", "ART", "NN", "$,", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wird etwas, w\u00e4chst, wird viel. Der Wahrheit Heiterkeit", "tokens": ["Wird", "et\u00b7was", ",", "w\u00e4chst", ",", "wird", "viel", ".", "Der", "Wahr\u00b7heit", "Hei\u00b7ter\u00b7keit"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PIS", "$,", "VVFIN", "$,", "VAFIN", "ADV", "$.", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "F\u00e4ngt in dem Gr\u00f6ssten an, und f\u00e4ngt auch an im Kleinen,", "tokens": ["F\u00e4ngt", "in", "dem", "Gr\u00f6ss\u00b7ten", "an", ",", "und", "f\u00e4ngt", "auch", "an", "im", "Klei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zu unsers Sch\u00f6pfers Nuhm, in hellerm Licht zu scheinen.", "tokens": ["Zu", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Nuhm", ",", "in", "hel\u00b7lerm", "Licht", "zu", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ward von Columbus dort uns eine neue Welt", "tokens": ["Ward", "von", "Co\u00b7lum\u00b7bus", "dort", "uns", "ei\u00b7ne", "neu\u00b7e", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "NE", "ADV", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gezeiget und entdeckt; war es zwar viel; allein", "tokens": ["Ge\u00b7zei\u00b7get", "und", "ent\u00b7deckt", ";", "war", "es", "zwar", "viel", ";", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["VVPP", "KON", "VVPP", "$.", "VAFIN", "PPER", "ADV", "ADV", "$.", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was heisst die\u00df gegen dem,", "tokens": ["Was", "heisst", "die\u00df", "ge\u00b7gen", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDS", "APPR", "ART", "$,"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Was ich mich dir anietzt zu zeigen unternehm.", "tokens": ["Was", "ich", "mich", "dir", "an\u00b7ietzt", "zu", "zei\u00b7gen", "un\u00b7ter\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Nicht eine neue Welt, viel tausend Welt\u2019 entstehen;", "tokens": ["Nicht", "ei\u00b7ne", "neu\u00b7e", "Welt", ",", "viel", "tau\u00b7send", "Welt'", "ent\u00b7ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "ADJA", "NN", "$,", "ADV", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es lassen sich so gar selbst neue Sonnen-Heere,", "tokens": ["Es", "las\u00b7sen", "sich", "so", "gar", "selbst", "neu\u00b7e", "Son\u00b7nen\u00b7Hee\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ja tausend neue Himmel, sehn.", "tokens": ["Ja", "tau\u00b7send", "neu\u00b7e", "Him\u00b7mel", ",", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PTKANT", "CARD", "ADJA", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der unerf\u00fcllte Raum, das ungeheure Leere", "tokens": ["Der", "un\u00b7er\u00b7f\u00fcll\u00b7te", "Raum", ",", "das", "un\u00b7ge\u00b7heu\u00b7re", "Lee\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "H\u00f6rt auf, und ist nicht mehr.", "tokens": ["H\u00f6rt", "auf", ",", "und", "ist", "nicht", "mehr", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "KON", "VAFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Hier, da der Seelen Blick, durch dieses Glas gest\u00e4rcket,", "tokens": ["Hier", ",", "da", "der", "See\u00b7len", "Blick", ",", "durch", "die\u00b7ses", "Glas", "ge\u00b7st\u00e4r\u00b7cket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "NN", "$,", "APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "In Grentzen-losen H\u00f6hen steiget,", "tokens": ["In", "Grent\u00b7zen\u00b7lo\u00b7sen", "H\u00f6\u00b7hen", "stei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird allererst von ihr in Ehr-Furcht recht bemercket,", "tokens": ["Wird", "al\u00b7le\u00b7rerst", "von", "ihr", "in", "Ehr\u00b7Furcht", "recht", "be\u00b7mer\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "APPR", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In welcher Herrlichkeit der Schaaren HERR sich zeiget.", "tokens": ["In", "wel\u00b7cher", "Herr\u00b7lich\u00b7keit", "der", "Schaa\u00b7ren", "HeRR", "sich", "zei\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "ART", "NN", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Man sieht der Tieffen Raum, als Sein unendlich Kleid,", "tokens": ["Man", "sieht", "der", "Tief\u00b7fen", "Raum", ",", "als", "Sein", "un\u00b7end\u00b7lich", "Kleid", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Voll Millionen Edelsteinen,", "tokens": ["Voll", "Mil\u00b7lion\u00b7en", "E\u00b7del\u00b7stei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Die alle Sonnen sind, in solcher Herrlichkeit,", "tokens": ["Die", "al\u00b7le", "Son\u00b7nen", "sind", ",", "in", "sol\u00b7cher", "Herr\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "In solcher Majest\u00e4t, so hell, so pr\u00e4chtig, scheinen;", "tokens": ["In", "sol\u00b7cher", "Ma\u00b7jes\u00b7t\u00e4t", ",", "so", "hell", ",", "so", "pr\u00e4ch\u00b7tig", ",", "schei\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Da\u00df man f\u00fcr Lust und Furcht, sich gantz in Jhm verliert,", "tokens": ["Da\u00df", "man", "f\u00fcr", "Lust", "und", "Furcht", ",", "sich", "gantz", "in", "Jhm", "ver\u00b7liert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NN", "KON", "NN", "$,", "PRF", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Jedoch in dem Verlust sich allererst recht findet,", "tokens": ["Je\u00b7doch", "in", "dem", "Ver\u00b7lust", "sich", "al\u00b7le\u00b7rerst", "recht", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Indem die Seele selbst, f\u00fcr Lust, die sie empfindet,", "tokens": ["In\u00b7dem", "die", "See\u00b7le", "selbst", ",", "f\u00fcr", "Lust", ",", "die", "sie", "emp\u00b7fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "$,", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "In ihrem Nichts so gar sich gleichsam neu gebiert,", "tokens": ["In", "ih\u00b7rem", "Nichts", "so", "gar", "sich", "gleich\u00b7sam", "neu", "ge\u00b7biert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADV", "PRF", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und einer, blo\u00df durch GOTT ihr eingefl\u00f6ssten Krafft,", "tokens": ["Und", "ei\u00b7ner", ",", "blo\u00df", "durch", "GoTT", "ihr", "ein\u00b7ge\u00b7fl\u00f6ss\u00b7ten", "Krafft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ADV", "APPR", "NE", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und ihr verliehnen Eigenschaft,", "tokens": ["Und", "ihr", "ver\u00b7lieh\u00b7nen", "Ei\u00b7gen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Sich recht mit inniglichen Freuden", "tokens": ["Sich", "recht", "mit", "in\u00b7nig\u00b7li\u00b7chen", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.21": {"text": "Am grossen und unendlichen zu weiden,", "tokens": ["Am", "gros\u00b7sen", "und", "un\u00b7end\u00b7li\u00b7chen", "zu", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "KON", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "In sich gewahr wird und versp\u00fchrt.", "tokens": ["In", "sich", "ge\u00b7wahr", "wird", "und", "ver\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ADJD", "VAFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "O ew\u2019ger Urstand aller Dinge,", "tokens": ["O", "ew'\u00b7ger", "Ur\u00b7stand", "al\u00b7ler", "Din\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von Dem, was worden ist, allein sein Seyn empfinge,", "tokens": ["Von", "Dem", ",", "was", "wor\u00b7den", "ist", ",", "al\u00b7lein", "sein", "Seyn", "emp\u00b7fin\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "VAPP", "VAFIN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hab ewig ewig Danck! sey ewiglich gepriesen,", "tokens": ["Hab", "e\u00b7wig", "e\u00b7wig", "Danck", "!", "sey", "e\u00b7wig\u00b7lich", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ADJD", "NN", "$.", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df Du Dich gegen uns so Gnaden-reich erwiesen,", "tokens": ["Da\u00df", "Du", "Dich", "ge\u00b7gen", "uns", "so", "Gna\u00b7den\u00b7reich", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und, blo\u00df aus Lieb\u2019 und Huld, der Menschen Seelen", "tokens": ["Und", ",", "blo\u00df", "aus", "Lieb'", "und", "Huld", ",", "der", "Men\u00b7schen", "See\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "ADV", "APPR", "NN", "KON", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Mit solchen Kr\u00e4fften zu verm\u00e4hlen,", "tokens": ["Mit", "sol\u00b7chen", "Kr\u00e4ff\u00b7ten", "zu", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Gew\u00fcrdigt und geschickt gemacht!", "tokens": ["Ge\u00b7w\u00fcr\u00b7digt", "und", "ge\u00b7schickt", "ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ach! la\u00df doch diese Krafft zu Deiner Ehr allein", "tokens": ["Ach", "!", "la\u00df", "doch", "die\u00b7se", "Krafft", "zu", "Dei\u00b7ner", "Ehr", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$.", "VVIMP", "ADV", "PDAT", "NN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und zur Bewunderung von Deiner Wercke Pracht,", "tokens": ["Und", "zur", "Be\u00b7wun\u00b7de\u00b7rung", "von", "Dei\u00b7ner", "Wer\u00b7cke", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Von uns stets angewendet seyn!", "tokens": ["Von", "uns", "stets", "an\u00b7ge\u00b7wen\u00b7det", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wie herrlich, un\u00fcmschrenckt, gewaltig und unendlich", "tokens": ["Wie", "herr\u00b7lich", ",", "un\u00b7\u00fcm\u00b7schrenckt", ",", "ge\u00b7wal\u00b7tig", "und", "un\u00b7end\u00b7lich"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sich in den Himmeln nun des Sch\u00f6pfers Gr\u00f6sse zeigt;", "tokens": ["Sich", "in", "den", "Him\u00b7meln", "nun", "des", "Sch\u00f6p\u00b7fers", "Gr\u00f6s\u00b7se", "zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So wird doch Seine Gr\u00f6ss\u2019 auch in dem Kleinen kenntlich,", "tokens": ["So", "wird", "doch", "Sei\u00b7ne", "Gr\u00f6ss'", "auch", "in", "dem", "Klei\u00b7nen", "kennt\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn unser Blick, durchs Glas, sich in die Tieffe neigt.", "tokens": ["Wenn", "un\u00b7ser", "Blick", ",", "durchs", "Glas", ",", "sich", "in", "die", "Tief\u00b7fe", "neigt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "APPRART", "NN", "$,", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "O Wunder! was sind hier f\u00fcr Wunder nicht entdeckt,", "tokens": ["O", "Wun\u00b7der", "!", "was", "sind", "hier", "f\u00fcr", "Wun\u00b7der", "nicht", "ent\u00b7deckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWS", "VAFIN", "ADV", "APPR", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die bis daher vor aller Welt versteckt!", "tokens": ["Die", "bis", "da\u00b7her", "vor", "al\u00b7ler", "Welt", "ver\u00b7steckt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PAV", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Es l\u00e4sst der Sch\u00f6pfer, auch im Kleinen,", "tokens": ["Es", "l\u00e4sst", "der", "Sch\u00f6p\u00b7fer", ",", "auch", "im", "Klei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die Strahlen Seiner Allmacht scheinen,", "tokens": ["Die", "Strah\u00b7len", "Sei\u00b7ner", "All\u00b7macht", "schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wovon uns bis daher so gar die Spuren", "tokens": ["Wo\u00b7von", "uns", "bis", "da\u00b7her", "so", "gar", "die", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "PAV", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Verdeckt gewesen sind. Von kleinen Creaturen", "tokens": ["Ver\u00b7deckt", "ge\u00b7we\u00b7sen", "sind", ".", "Von", "klei\u00b7nen", "Crea\u00b7tu\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "VAPP", "VAFIN", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Wird eine gantze neue Welt,", "tokens": ["Wird", "ei\u00b7ne", "gant\u00b7ze", "neu\u00b7e", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Und in derselben uns der Sch\u00f6pfer vorgestellt", "tokens": ["Und", "in", "der\u00b7sel\u00b7ben", "uns", "der", "Sch\u00f6p\u00b7fer", "vor\u00b7ge\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "PPER", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "In einem neuen Glantz, in einer neuen Pracht,", "tokens": ["In", "ei\u00b7nem", "neu\u00b7en", "Glantz", ",", "in", "ei\u00b7ner", "neu\u00b7en", "Pracht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "In neuer Weisheit, neuer Macht.", "tokens": ["In", "neu\u00b7er", "Weis\u00b7heit", ",", "neu\u00b7er", "Macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Unendlich zeigt sich GOTT in Kleinen ja so wol,", "tokens": ["Un\u00b7end\u00b7lich", "zeigt", "sich", "GoTT", "in", "Klei\u00b7nen", "ja", "so", "wol", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PRF", "NE", "APPR", "NN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Als er sich in dem gr\u00f6ssten zeiget:", "tokens": ["Als", "er", "sich", "in", "dem", "gr\u00f6ss\u00b7ten", "zei\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So uns absonderlich zum Troste dienen soll.", "tokens": ["So", "uns", "ab\u00b7son\u00b7der\u00b7lich", "zum", "Tros\u00b7te", "die\u00b7nen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADJD", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn, w\u00e4r der Sch\u00f6pfer blo\u00df im Grossen gro\u00df allein,", "tokens": ["Denn", ",", "w\u00e4r", "der", "Sch\u00f6p\u00b7fer", "blo\u00df", "im", "Gros\u00b7sen", "gro\u00df", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "ART", "NN", "ADV", "APPRART", "NN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie k\u00f6nnt\u2019 er uns, die wir so klein,", "tokens": ["Wie", "k\u00f6nnt'", "er", "uns", ",", "die", "wir", "so", "klein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PPER", "$,", "PRELS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Recht doch zugeeignet seyn?", "tokens": ["Mit", "Recht", "doch", "zu\u00b7ge\u00b7eig\u00b7net", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So aber zeiget sich die Gottheit ja so kr\u00e4fftig,", "tokens": ["So", "a\u00b7ber", "zei\u00b7get", "sich", "die", "Got\u00b7theit", "ja", "so", "kr\u00e4ff\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PRF", "ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und ist im Niedrigen nicht weniger gesch\u00e4fftig,", "tokens": ["Und", "ist", "im", "Nied\u00b7ri\u00b7gen", "nicht", "we\u00b7ni\u00b7ger", "ge\u00b7sch\u00e4ff\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Als sie im Gr\u00f6ssten ist. Da\u00df aber dem Verstand", "tokens": ["Als", "sie", "im", "Gr\u00f6ss\u00b7ten", "ist", ".", "Da\u00df", "a\u00b7ber", "dem", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN", "$.", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Blo\u00df durch ein wenig Asch\u2019 und Sand,", "tokens": ["Blo\u00df", "durch", "ein", "we\u00b7nig", "Asch'", "und", "Sand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Wenn es das Feur im rechten Grad", "tokens": ["Wenn", "es", "das", "Feur", "im", "rech\u00b7ten", "Grad"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Vereint und zugerichtet hat,", "tokens": ["Ver\u00b7eint", "und", "zu\u00b7ge\u00b7rich\u00b7tet", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ein solches helles Licht", "tokens": ["Ein", "sol\u00b7ches", "hel\u00b7les", "Licht"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PIAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "In dem geschliffnen Glas entstellet,", "tokens": ["In", "dem", "ge\u00b7schliff\u00b7nen", "Glas", "ent\u00b7stel\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Da es des C\u00f6rpers Auge st\u00e4rckt;", "tokens": ["Da", "es", "des", "C\u00f6r\u00b7pers", "Au\u00b7ge", "st\u00e4rckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ist etwas, wenn man es bemerckt,", "tokens": ["Ist", "et\u00b7was", ",", "wenn", "man", "es", "be\u00b7merckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Das \u00fcber alles dencken gehet.", "tokens": ["Das", "\u00fc\u00b7ber", "al\u00b7les", "den\u00b7cken", "ge\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PIS", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Bey diesem Wunder-Licht kann unsre Seele lesen", "tokens": ["Bey", "die\u00b7sem", "Wun\u00b7der\u00b7Licht", "kann", "uns\u00b7re", "See\u00b7le", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geheimnisse, die sonst, von Anbeginn der Welt,", "tokens": ["Ge\u00b7heim\u00b7nis\u00b7se", ",", "die", "sonst", ",", "von", "An\u00b7be\u00b7ginn", "der", "Welt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "$,", "APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Menschheit unbekannt, und gantz verdeckt gewesen;", "tokens": ["Der", "Menschheit", "un\u00b7be\u00b7kannt", ",", "und", "gantz", "ver\u00b7deckt", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "KON", "ADV", "VVPP", "VAPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.4": {"text": "Die aber GOTT der HERR uns ietzt vor Augen stellt.", "tokens": ["Die", "a\u00b7ber", "GoTT", "der", "HeRR", "uns", "ietzt", "vor", "Au\u00b7gen", "stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NE", "ART", "NN", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "O GOTT! ein seliges Erstaunen nimmt mich ein.", "tokens": ["O", "GoTT", "!", "ein", "se\u00b7li\u00b7ges", "Er\u00b7stau\u00b7nen", "nimmt", "mich", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Abgrund Deiner Macht und Weisheit stellet mir", "tokens": ["Der", "Ab\u00b7grund", "Dei\u00b7ner", "Macht", "und", "Weis\u00b7heit", "stel\u00b7let", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mich selber gro\u00df, Dich recht unendlich f\u00fcr.", "tokens": ["Mich", "sel\u00b7ber", "gro\u00df", ",", "Dich", "recht", "un\u00b7end\u00b7lich", "f\u00fcr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "$,", "PPER", "ADV", "ADJD", "APPR", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.13": {"line.1": {"text": "Ja wenn ich noch erwege, wie so klein", "tokens": ["Ja", "wenn", "ich", "noch", "er\u00b7we\u00b7ge", ",", "wie", "so", "klein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "KOUS", "PPER", "ADV", "VVFIN", "$,", "PWAV", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die\u00df Werck-Zeug, welches unsern Geist", "tokens": ["Die\u00df", "Wer\u00b7ck\u00b7Zeug", ",", "wel\u00b7ches", "un\u00b7sern", "Geist"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "NN", "$,", "PRELS", "PPOSAT", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Der dicken Finsterni\u00df entreisst;", "tokens": ["Der", "di\u00b7cken", "Fins\u00b7ter\u00b7ni\u00df", "en\u00b7treisst", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Komm ich annoch auf andere Gedancken.", "tokens": ["Komm", "ich", "an\u00b7noch", "auf", "an\u00b7de\u00b7re", "Ge\u00b7dan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Da GOttes Macht ohn Ende, sonder Schrancken;", "tokens": ["Da", "Got\u00b7tes", "Macht", "ohn", "En\u00b7de", ",", "son\u00b7der", "Schran\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "APPR", "NN", "$,", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Was k\u00f6nnen nicht f\u00fcr Herrlichkeiten,", "tokens": ["Was", "k\u00f6n\u00b7nen", "nicht", "f\u00fcr", "Herr\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr Sch\u00f6nheit- und Vollkommenheiten", "tokens": ["F\u00fcr", "Sch\u00f6n\u00b7heit", "und", "Voll\u00b7kom\u00b7men\u00b7hei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "TRUNC", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In der Natur annoch verborgen seyn!", "tokens": ["In", "der", "Na\u00b7tur", "an\u00b7noch", "ver\u00b7bor\u00b7gen", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die unsern Sinnen noch verhehlt,", "tokens": ["Die", "un\u00b7sern", "Sin\u00b7nen", "noch", "ver\u00b7hehlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und die wir blo\u00df daher vielleicht noch nicht bemerckt,", "tokens": ["Und", "die", "wir", "blo\u00df", "da\u00b7her", "viel\u00b7leicht", "noch", "nicht", "be\u00b7merckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "PAV", "ADV", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Weil uns dazu ein Werckzeug fehlt,", "tokens": ["Weil", "uns", "da\u00b7zu", "ein", "Wer\u00b7ck\u00b7zeug", "fehlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Das andre Sinnen, so wie Glas die Augen, st\u00e4rckt.", "tokens": ["Das", "and\u00b7re", "Sin\u00b7nen", ",", "so", "wie", "Glas", "die", "Au\u00b7gen", ",", "st\u00e4rckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "KOKOM", "NN", "ART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Ursprungs-Quell! aus Dem entspringen", "tokens": ["Ur\u00b7sprungs\u00b7Quell", "!", "aus", "Dem", "ent\u00b7sprin\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Dinge, die so sch\u00f6n!", "tokens": ["Al\u00b7le", "Din\u00b7ge", ",", "die", "so", "sch\u00f6n", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PRELS", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wovon wir in allen Dingen,", "tokens": ["Wo\u00b7von", "wir", "in", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn wir sie bewundernd sehn,", "tokens": ["Wenn", "wir", "sie", "be\u00b7wun\u00b7dernd", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Seine Macht und Weisheit lesen!", "tokens": ["Sei\u00b7ne", "Macht", "und", "Weis\u00b7heit", "le\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wesen! woraus aller Wesen", "tokens": ["We\u00b7sen", "!", "wo\u00b7raus", "al\u00b7ler", "We\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PWAV", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wesen und die Krafft\u2019 entstehn!", "tokens": ["We\u00b7sen", "und", "die", "Krafft'", "ent\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Welches alles in der That", "tokens": ["Wel\u00b7ches", "al\u00b7les", "in", "der", "That"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "PIS", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Wunderbar entnichtigt hat!", "tokens": ["Wun\u00b7der\u00b7bar", "ent\u00b7nich\u00b7tigt", "hat", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Wesen, welches blo\u00df die Liebe", "tokens": ["We\u00b7sen", ",", "wel\u00b7ches", "blo\u00df", "die", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.11": {"text": "Zu des Sch\u00f6pfungs Wunder triebe,", "tokens": ["Zu", "des", "Sch\u00f6p\u00b7fungs", "Wun\u00b7der", "trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.12": {"text": "Und von Dem, durch Lieb\u2019 allein,", "tokens": ["Und", "von", "Dem", ",", "durch", "Lieb'", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PDS", "$,", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.13": {"text": "In den Himmeln und auf Erden", "tokens": ["In", "den", "Him\u00b7meln", "und", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.14": {"text": "Alle Ding\u2019 erhalten werden,", "tokens": ["Al\u00b7le", "Ding'", "er\u00b7hal\u00b7ten", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.15": {"text": "La\u00df uns Dir gef\u00e4llig seyn!", "tokens": ["La\u00df", "uns", "Dir", "ge\u00b7f\u00e4l\u00b7lig", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "La\u00df uns uns mit Lust bestreben,", "tokens": ["La\u00df", "uns", "uns", "mit", "Lust", "be\u00b7stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PRF", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.17": {"text": "Dich in Ehr-Furcht zu erheben,", "tokens": ["Dich", "in", "Ehr\u00b7Furcht", "zu", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.18": {"text": "Dir allein zum Ruhm zu leben!", "tokens": ["Dir", "al\u00b7lein", "zum", "Ruhm", "zu", "le\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.19": {"text": "La\u00df uns doch in Deinen Wercken,", "tokens": ["La\u00df", "uns", "doch", "in", "Dei\u00b7nen", "Wer\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Uns zur Lust, und Dir zur Ehr,", "tokens": ["Uns", "zur", "Lust", ",", "und", "Dir", "zur", "Ehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "$,", "KON", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.21": {"text": "Deine Macht ie mehr und mehr", "tokens": ["Dei\u00b7ne", "Macht", "ie", "mehr", "und", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "ADV", "KON", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Mit vergn\u00fcgter Seele mercken!", "tokens": ["Mit", "ver\u00b7gn\u00fcg\u00b7ter", "See\u00b7le", "mer\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}