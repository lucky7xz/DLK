{"textgrid.poem.44505": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Epistel", "genre": "verse", "period": "N.A.", "pub_year": 1840, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr wollt denn wirklich deutsche Poesie,", "tokens": ["Ihr", "wollt", "denn", "wirk\u00b7lich", "deut\u00b7sche", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die es auch sei, nicht blo\u00df nur so sich nenne?", "tokens": ["Die", "es", "auch", "sei", ",", "nicht", "blo\u00df", "nur", "so", "sich", "nen\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "$,", "PTKNEG", "ADV", "ADV", "ADV", "PRF", "VVFIN", "$."], "meter": "+--+-+--+--", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Gerechtre W\u00fcnsche h\u00f6rte man wohl nie,", "tokens": ["Ge\u00b7recht\u00b7re", "W\u00fcn\u00b7sche", "h\u00f6r\u00b7te", "man", "wohl", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PIS", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch deutsche Art! Macht erst, da\u00df ich sie kenne.", "tokens": ["Doch", "deut\u00b7sche", "Art", "!", "Macht", "erst", ",", "da\u00df", "ich", "sie", "ken\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "NN", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich wei\u00df euch ruhig, fest, von schlichtem Sinn,", "tokens": ["Ich", "wei\u00df", "euch", "ru\u00b7hig", ",", "fest", ",", "von", "schlich\u00b7tem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "PTKVZ", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zum Handeln minder r\u00fchrig als zum Denken,", "tokens": ["Zum", "Han\u00b7deln", "min\u00b7der", "r\u00fch\u00b7rig", "als", "zum", "Den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch seh ich auf das Tags Gestalten hin,", "tokens": ["Doch", "seh", "ich", "auf", "das", "Tags", "Ge\u00b7stal\u00b7ten", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mu\u00df ich zum Widerspiel die Meinung lenken.", "tokens": ["Mu\u00df", "ich", "zum", "Wi\u00b7der\u00b7spiel", "die", "Mei\u00b7nung", "len\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da l\u00e4rmts und prahlt und tobt und schreit und droht,", "tokens": ["Da", "l\u00e4rmts", "und", "prahlt", "und", "tobt", "und", "schreit", "und", "droht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "KON", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vernichtet jede Stunde zehn Tyrannen,", "tokens": ["Ver\u00b7nich\u00b7tet", "je\u00b7de", "Stun\u00b7de", "zehn", "Ty\u00b7ran\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Will Freiheit, g\u00e4lt es hundertfachen Tod,", "tokens": ["Will", "Frei\u00b7heit", ",", "g\u00e4lt", "es", "hun\u00b7dert\u00b7fa\u00b7chen", "Tod", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "$,", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und f\u00fchrt doch Krieg nur mit den vollen Kannen.", "tokens": ["Und", "f\u00fchrt", "doch", "Krieg", "nur", "mit", "den", "vol\u00b7len", "Kan\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ihr r\u00fchmt der V\u00e4ter Biedersinn und Art.", "tokens": ["Ihr", "r\u00fchmt", "der", "V\u00e4\u00b7ter", "Bie\u00b7der\u00b7sinn", "und", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Historisch, nur historisch, rufts hysterisch,", "tokens": ["His\u00b7to\u00b7risch", ",", "nur", "his\u00b7to\u00b7risch", ",", "rufts", "hys\u00b7te\u00b7risch", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADJD", "$,", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Im Glauben ruht das Heil der Gegenwart!", "tokens": ["Im", "Glau\u00b7ben", "ruht", "das", "Heil", "der", "Ge\u00b7gen\u00b7wart", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und Strau\u00df macht euch mit seinen Mythen n\u00e4rrisch.", "tokens": ["Und", "Strau\u00df", "macht", "euch", "mit", "sei\u00b7nen", "My\u00b7then", "n\u00e4r\u00b7risch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.5": {"line.1": {"text": "Freund Hegel gibt euch einen neuen Gott,", "tokens": ["Freund", "He\u00b7gel", "gibt", "euch", "ei\u00b7nen", "neu\u00b7en", "Gott", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und Schelling stutzt euch zu auf neu den alten.", "tokens": ["Und", "Schel\u00b7ling", "stutzt", "euch", "zu", "auf", "neu", "den", "al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPER", "PTKZU", "APPR", "ADJD", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Welt aus nichts, war schon ein hart Gebot,", "tokens": ["Die", "Welt", "aus", "nichts", ",", "war", "schon", "ein", "hart", "Ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PIS", "$,", "VAFIN", "ADV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.4": {"text": "Doch Nichts \u2013 das eine Welt \u2013 will gar nicht halten.", "tokens": ["Doch", "Nichts", "\u2013", "das", "ei\u00b7ne", "Welt", "\u2013", "will", "gar", "nicht", "hal\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$(", "PDS", "ART", "NN", "$(", "VMFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Gef\u00fchl, r\u00fchmt man, da\u00df euer Vorzug sei \u2013", "tokens": ["Ge\u00b7f\u00fchl", ",", "r\u00fchmt", "man", ",", "da\u00df", "eu\u00b7er", "Vor\u00b7zug", "sei", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PIS", "$,", "KOUS", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Drum kostet wohl Verstand euch \u00dcberwindung \u2013", "tokens": ["Drum", "kos\u00b7tet", "wohl", "Ver\u00b7stand", "euch", "\u00dc\u00b7berw\u00b7in\u00b7dung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "NN", "PPER", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch als ihr totschlugt die Empfindelei,", "tokens": ["Doch", "als", "ihr", "tot\u00b7schlugt", "die", "Emp\u00b7fin\u00b7de\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Traf mancher harte Schlag auch die Empfindung.", "tokens": ["Traf", "man\u00b7cher", "har\u00b7te", "Schlag", "auch", "die", "Emp\u00b7fin\u00b7dung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und statt Gef\u00fchl, womit ihr euch begabt,", "tokens": ["Und", "statt", "Ge\u00b7f\u00fchl", ",", "wo\u00b7mit", "ihr", "euch", "be\u00b7gabt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "PWAV", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Find ich euch kalt in holperichten Reimen,", "tokens": ["Find", "ich", "euch", "kalt", "in", "hol\u00b7pe\u00b7rich\u00b7ten", "Rei\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wo nur Gedanken, die man l\u00e4ngst gehabt,", "tokens": ["Wo", "nur", "Ge\u00b7dan\u00b7ken", ",", "die", "man", "l\u00e4ngst", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NN", "$,", "PRELS", "PIS", "ADV", "VAPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Zum Harlekin sich aneinanderleimen.", "tokens": ["Zum", "Har\u00b7le\u00b7kin", "sich", "an\u00b7ein\u00b7an\u00b7der\u00b7lei\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ein Volk von Denkern? Und sprecht plappernd nach,", "tokens": ["Ein", "Volk", "von", "Den\u00b7kern", "?", "Und", "sprecht", "plap\u00b7pernd", "nach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$.", "KON", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Was ihr geh\u00f6rt von nichtgen Unterweisern,", "tokens": ["Was", "ihr", "ge\u00b7h\u00f6rt", "von", "nicht\u00b7gen", "Un\u00b7ter\u00b7wei\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gervinus, Menzel stehen wie zur Wach,", "tokens": ["Ger\u00b7vi\u00b7nus", ",", "Men\u00b7zel", "ste\u00b7hen", "wie", "zur", "Wach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "VVFIN", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Bald abgel\u00f6st, in engen Schilderh\u00e4usern.", "tokens": ["Bald", "ab\u00b7ge\u00b7l\u00f6st", ",", "in", "en\u00b7gen", "Schil\u00b7der\u00b7h\u00e4u\u00b7sern", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Was heute gut, weicht morgen schon vom Platz,", "tokens": ["Was", "heu\u00b7te", "gut", ",", "weicht", "mor\u00b7gen", "schon", "vom", "Platz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "$,", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So Billigung als Urteil ohne St\u00e4rke,", "tokens": ["So", "Bil\u00b7li\u00b7gung", "als", "Ur\u00b7teil", "oh\u00b7ne", "St\u00e4r\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ihr lebt von gestern, nie h\u00e4uft sich ein Schatz,", "tokens": ["Ihr", "lebt", "von", "ge\u00b7stern", ",", "nie", "h\u00e4uft", "sich", "ein", "Schatz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADV", "$,", "ADV", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ihr habt nur B\u00fccher, aber keine Werke.", "tokens": ["Ihr", "habt", "nur", "B\u00fc\u00b7cher", ",", "a\u00b7ber", "kei\u00b7ne", "Wer\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$,", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wo ist dann deutsche Art? Auf, zeigt mir sie,", "tokens": ["Wo", "ist", "dann", "deut\u00b7sche", "Art", "?", "Auf", ",", "zeigt", "mir", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ADJA", "NN", "$.", "APPR", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Statt Launen, immer bunter und vertrackter;", "tokens": ["Statt", "Lau\u00b7nen", ",", "im\u00b7mer", "bun\u00b7ter", "und", "ver\u00b7track\u00b7ter", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und fordert ihr ihn von der Poesie,", "tokens": ["Und", "for\u00b7dert", "ihr", "ihn", "von", "der", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.4": {"text": "So habt vor allem selber erst Charakter.", "tokens": ["So", "habt", "vor", "al\u00b7lem", "sel\u00b7ber", "erst", "Cha\u00b7rak\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIS", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Allein ihr m\u00f6chtet sein, was ihr nicht seid;", "tokens": ["Al\u00b7lein", "ihr", "m\u00f6ch\u00b7tet", "sein", ",", "was", "ihr", "nicht", "seid", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "VAINF", "$,", "PWS", "PPER", "PTKNEG", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Geht in die Schule denn und lernt zu leben,", "tokens": ["Geht", "in", "die", "Schu\u00b7le", "denn", "und", "lernt", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "KON", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und seid ihr zum Empfangen erst bereit,", "tokens": ["Und", "seid", "ihr", "zum", "Emp\u00b7fan\u00b7gen", "erst", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "APPRART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wird euch die Dichtkunst das Gem\u00e4\u00dfe geben.", "tokens": ["Wird", "euch", "die", "Dicht\u00b7kunst", "das", "Ge\u00b7m\u00e4\u00b7\u00dfe", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}