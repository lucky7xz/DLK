{"textgrid.poem.59718": {"metadata": {"author": {"name": "Arndt, Ernst Moritz", "birth": "N.A.", "death": "N.A."}, "title": "Hermann von Boyen in Walhall", "genre": "verse", "period": "N.A.", "pub_year": 1814, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Blast! Blaset hell von Walhalls Zinnen!", "tokens": ["Blast", "!", "Bla\u00b7set", "hell", "von", "Wal\u00b7halls", "Zin\u00b7nen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NN", "ADJD", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Tut weit die goldnen Pforten auf!", "tokens": ["Tut", "weit", "die", "gold\u00b7nen", "Pfor\u00b7ten", "auf", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weckt alle Ehren, alle Minnen!", "tokens": ["Weckt", "al\u00b7le", "Eh\u00b7ren", ",", "al\u00b7le", "Min\u00b7nen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es steigt ein hoher Glanz herauf.", "tokens": ["Es", "steigt", "ein", "ho\u00b7her", "Glanz", "her\u00b7auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Weckt jede Harfe, jede Leier!", "tokens": ["Weckt", "je\u00b7de", "Har\u00b7fe", ",", "je\u00b7de", "Lei\u00b7er", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Erleuchtet jeder Wonne Schein!", "tokens": ["Er\u00b7leuch\u00b7tet", "je\u00b7der", "Won\u00b7ne", "Schein", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Held, ein Retter, ein Befreier,", "tokens": ["Ein", "Held", ",", "ein", "Ret\u00b7ter", ",", "ein", "Be\u00b7frei\u00b7er", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Worunter Hermann Boyen stritt,", "tokens": ["Wo\u00b7run\u00b7ter", "Her\u00b7mann", "Bo\u00b7yen", "stritt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die l\u00e4\u00dft den Enkeln er als Ahnen", "tokens": ["Die", "l\u00e4\u00dft", "den", "En\u00b7keln", "er", "als", "Ah\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "PPER", "KOUS", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fcr deutscher Zukunft Heldenschritt.", "tokens": ["F\u00fcr", "deut\u00b7scher", "Zu\u00b7kunft", "Hel\u00b7den\u00b7schritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wird wo gesungen, wo gelesen", "tokens": ["Wird", "wo", "ge\u00b7sun\u00b7gen", ",", "wo", "ge\u00b7le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PWAV", "VVPP", "$,", "PWAV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von einem hohen, edlen Mann,", "tokens": ["Von", "ei\u00b7nem", "ho\u00b7hen", ",", "ed\u00b7len", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der rein und fleckenlos gewesen,", "tokens": ["Der", "rein", "und", "fle\u00b7cken\u00b7los", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So bleibt der Boyen Vordermann.", "tokens": ["So", "bleibt", "der", "Bo\u00b7yen", "Vor\u00b7der\u00b7mann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Schon steht er da im G\u00f6tterglanze", "tokens": ["Schon", "steht", "er", "da", "im", "G\u00f6t\u00b7ter\u00b7glan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Idas ewig gr\u00fcner Au,", "tokens": ["Auf", "I\u00b7das", "e\u00b7wig", "gr\u00fc\u00b7ner", "Au", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Schon gr\u00fc\u00dfen aus dem Heldenkranze", "tokens": ["Schon", "gr\u00fc\u00b7\u00dfen", "aus", "dem", "Hel\u00b7den\u00b7kran\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sein Scharnhorst ihn, sein Gneisenau.", "tokens": ["Sein", "Scharn\u00b7horst", "ihn", ",", "sein", "Gnei\u00b7se\u00b7nau", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Der Bl\u00fccher gr\u00fc\u00dft, B\u00fclow der Schnelle,", "tokens": ["Der", "Bl\u00fc\u00b7cher", "gr\u00fc\u00dft", ",", "B\u00fc\u00b7low", "der", "Schnel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Streitgeno\u00df und Siegsgeno\u00df,", "tokens": ["Sein", "Streit\u00b7ge\u00b7no\u00df", "und", "Siegs\u00b7ge\u00b7no\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Grolman der Freund, der Ernste, Helle,", "tokens": ["Grol\u00b7man", "der", "Freund", ",", "der", "Erns\u00b7te", ",", "Hel\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ART", "NN", "$,", "NE", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Des Auge Schlachtenblicke scho\u00df.", "tokens": ["Des", "Au\u00b7ge", "Schlach\u00b7ten\u00b7bli\u00b7cke", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch steigen von der hohen St\u00e4tte", "tokens": ["Doch", "stei\u00b7gen", "von", "der", "ho\u00b7hen", "St\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zur kleinen Erde wir hinab", "tokens": ["Zur", "klei\u00b7nen", "Er\u00b7de", "wir", "hin\u00b7ab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und legen Hoffnung und Gebete", "tokens": ["Und", "le\u00b7gen", "Hoff\u00b7nung", "und", "Ge\u00b7be\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auf unsers deutschen Hermanns Grab.", "tokens": ["Auf", "un\u00b7sers", "deut\u00b7schen", "Her\u00b7manns", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wir beten: Ewig lebe Treue", "tokens": ["Wir", "be\u00b7ten", ":", "E\u00b7wig", "le\u00b7be", "Treu\u00b7e"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "NE", "VVFIN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr K\u00f6nig, Gott und Vaterland,", "tokens": ["F\u00fcr", "K\u00f6\u00b7nig", ",", "Gott", "und", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie dieser stille Schlachtenleue", "tokens": ["Wie", "die\u00b7ser", "stil\u00b7le", "Schlach\u00b7ten\u00b7leu\u00b7e"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich ihre Ehrenkr\u00e4nze wand!", "tokens": ["Sich", "ih\u00b7re", "Eh\u00b7ren\u00b7kr\u00e4n\u00b7ze", "wand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Wir beten: Nimmer m\u00f6ge fehlen", "tokens": ["Wir", "be\u00b7ten", ":", "Nim\u00b7mer", "m\u00f6\u00b7ge", "feh\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die freie, fromme Heldensaat", "tokens": ["Die", "frei\u00b7e", ",", "from\u00b7me", "Hel\u00b7den\u00b7saat"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Von solchen festen, starken Seelen,", "tokens": ["Von", "sol\u00b7chen", "fes\u00b7ten", ",", "star\u00b7ken", "See\u00b7len", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ger\u00fcstet gleich f\u00fcr Wort und Tat!", "tokens": ["Ge\u00b7r\u00fcs\u00b7tet", "gleich", "f\u00fcr", "Wort", "und", "Tat", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wir beten: Nimmer m\u00f6ge fehlen", "tokens": ["Wir", "be\u00b7ten", ":", "Nim\u00b7mer", "m\u00f6\u00b7ge", "feh\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Blitz, der durch die Herzen f\u00e4hrt,", "tokens": ["Der", "Blitz", ",", "der", "durch", "die", "Her\u00b7zen", "f\u00e4hrt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der rechte Blitz f\u00fcr deutsche Seelen,", "tokens": ["Der", "rech\u00b7te", "Blitz", "f\u00fcr", "deut\u00b7sche", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Blitz von Licht und Recht und Schwert!", "tokens": ["Der", "Blitz", "von", "Licht", "und", "Recht", "und", "Schwert", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}