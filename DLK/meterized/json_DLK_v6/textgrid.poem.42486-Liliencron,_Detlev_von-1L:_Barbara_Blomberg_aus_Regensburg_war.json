{"textgrid.poem.42486": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Barbara Blomberg aus Regensburg war", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Barbara Blomberg aus Regensburg war", "tokens": ["Bar\u00b7ba\u00b7ra", "Blom\u00b7berg", "aus", "Re\u00b7gens\u00b7burg", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "APPR", "NE", "VAFIN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Don Juans sch\u00f6ne Mutter.", "tokens": ["Don", "Ju\u00b7ans", "sch\u00f6\u00b7ne", "Mut\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sein Vater, Carolus Quintus, C\u00e4sar,", "tokens": ["Sein", "Va\u00b7ter", ",", "Ca\u00b7ro\u00b7lus", "Quin\u00b7tus", ",", "C\u00e4\u00b7sar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "FM.la", "FM.la", "$,", "NE", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "F\u00fchrte Krieg mit Martin Luther.", "tokens": ["F\u00fchr\u00b7te", "Krieg", "mit", "Mar\u00b7tin", "Lu\u00b7ther", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NE", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alba, der finstre Herzog, tat nie", "tokens": ["Al\u00b7ba", ",", "der", "finst\u00b7re", "Her\u00b7zog", ",", "tat", "nie"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PRELS", "VVFIN", "NE", "$,", "FM.la", "FM.la"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.6": {"text": "Vor einem Menschen erschrecken;", "tokens": ["Vor", "ei\u00b7nem", "Men\u00b7schen", "er\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Nur vor B\u00e4rbel, seltsam, sah er sie,", "tokens": ["Nur", "vor", "B\u00e4r\u00b7bel", ",", "selt\u00b7sam", ",", "sah", "er", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$,", "ADJD", "$,", "VVFIN", "PPER", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Verkroch er sich zag in die Ecken.", "tokens": ["Ver\u00b7kroch", "er", "sich", "zag", "in", "die", "E\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Don Juan ward ein ber\u00fchmter Held,", "tokens": ["Don", "Juan", "ward", "ein", "be\u00b7r\u00fchm\u00b7ter", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schlug T\u00fcrken, Mohren und Christen;", "tokens": ["Schlug", "T\u00fcr\u00b7ken", ",", "Moh\u00b7ren", "und", "Chris\u00b7ten", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00dcberall prunkt er als Sieger im Feld,", "tokens": ["\u00dc\u00b7be\u00b7rall", "prunkt", "er", "als", "Sie\u00b7ger", "im", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOUS", "NN", "APPRART", "NN", "$,"], "meter": "+--+-++--+", "measure": "iambic.penta.invert"}, "line.4": {"text": "Wo seine Fahnen sich hi\u00dften.", "tokens": ["Wo", "sei\u00b7ne", "Fah\u00b7nen", "sich", "hi\u00df\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "K\u00f6nig Philipp, sein Bruder, hie\u00df ihn setzen den Fu\u00df", "tokens": ["K\u00f6\u00b7nig", "Phi\u00b7lipp", ",", "sein", "Bru\u00b7der", ",", "hie\u00df", "ihn", "set\u00b7zen", "den", "Fu\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "VVFIN", "ART", "NN"], "meter": "+--+-+-+-+--+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "In die fernen Niederlande,", "tokens": ["In", "die", "fer\u00b7nen", "Nie\u00b7der\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df er mit Graus zu Grus und Mus", "tokens": ["Da\u00df", "er", "mit", "Graus", "zu", "Grus", "und", "Mus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Oranien schl\u00fcge in Bande.", "tokens": ["O\u00b7ra\u00b7ni\u00b7en", "schl\u00fc\u00b7ge", "in", "Ban\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "$."], "meter": "----+--+-", "measure": "iambic.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Don Juan duckte flugs bei Gemblours", "tokens": ["Don", "Juan", "duck\u00b7te", "flugs", "bei", "Gem\u00b7blours"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die ungl\u00fcckseligen Staaten.", "tokens": ["Die", "un\u00b7gl\u00fcck\u00b7se\u00b7li\u00b7gen", "Staa\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dann bat er Don Philipp um M\u00fcnzzufuhr,", "tokens": ["Dann", "bat", "er", "Don", "Phi\u00b7lipp", "um", "M\u00fcnz\u00b7zu\u00b7fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NE", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Doch dem fehlten auch die Dukaten.", "tokens": ["Doch", "dem", "fehl\u00b7ten", "auch", "die", "Du\u00b7ka\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "In Niederland wie in Spanien blieb", "tokens": ["In", "Nie\u00b7der\u00b7land", "wie", "in", "Spa\u00b7ni\u00b7en", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "KOKOM", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Geldchose h\u00f6chst verquackelt,", "tokens": ["Die", "Geld\u00b7cho\u00b7se", "h\u00f6chst", "ver\u00b7qua\u00b7ckelt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Und wie Don Juan auch schrieb und schrieb,", "tokens": ["Und", "wie", "Don", "Juan", "auch", "schrieb", "und", "schrieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NE", "NE", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kein Pfennig kam angewackelt.", "tokens": ["Kein", "Pfen\u00b7nig", "kam", "an\u00b7ge\u00b7wa\u00b7ckelt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Was sollt er nun machen, der arme Tropf;", "tokens": ["Was", "sollt", "er", "nun", "ma\u00b7chen", ",", "der", "ar\u00b7me", "Tropf", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVINF", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Ohne Kassa ist nichts zu erreichen.", "tokens": ["Oh\u00b7ne", "Kas\u00b7sa", "ist", "nichts", "zu", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Kein Gulden fiel aus seinem Schopf,", "tokens": ["Kein", "Gul\u00b7den", "fiel", "aus", "sei\u00b7nem", "Schopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kein St\u00fcver aus seinen Weichen.", "tokens": ["Kein", "St\u00fc\u00b7ver", "aus", "sei\u00b7nen", "Wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Dazu kam die Pest und warf ihn hin", "tokens": ["Da\u00b7zu", "kam", "die", "Pest", "und", "warf", "ihn", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ART", "NN", "KON", "VVFIN", "PPER", "PTKVZ"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "In Bouges auf die k\u00e4rglichste Sch\u00fctte.", "tokens": ["In", "Bou\u00b7ges", "auf", "die", "k\u00e4rg\u00b7lichs\u00b7te", "Sch\u00fct\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Er starb im Elend, das war sein Gewinn,", "tokens": ["Er", "starb", "im", "E\u00b7lend", ",", "das", "war", "sein", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "In einer Zigeunerh\u00fctte.", "tokens": ["In", "ei\u00b7ner", "Zi\u00b7geu\u00b7ner\u00b7h\u00fct\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Bei Carolo Quinto im Eskorial,", "tokens": ["Bei", "Ca\u00b7ro\u00b7lo", "Quin\u00b7to", "im", "Es\u00b7ko\u00b7ri\u00b7al", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "So k\u00fcndet sein letzter Wille,", "tokens": ["So", "k\u00fcn\u00b7det", "sein", "letz\u00b7ter", "Wil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "W\u00fcnscht er zu ruhn nach der Daseinsqual", "tokens": ["W\u00fcnscht", "er", "zu", "ruhn", "nach", "der", "Da\u00b7seins\u00b7qual"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "APPR", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "In tiefer, unendlicher Stille.", "tokens": ["In", "tie\u00b7fer", ",", "un\u00b7end\u00b7li\u00b7cher", "Stil\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJD", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Aber, o weh, wie gro\u00df war die Not,", "tokens": ["A\u00b7ber", ",", "o", "weh", ",", "wie", "gro\u00df", "war", "die", "Not", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "FM", "PTKVZ", "$,", "PWAV", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Wer zahlt nach Madrid die Di\u00e4ten?", "tokens": ["Wer", "zahlt", "nach", "Mad\u00b7rid", "die", "Di\u00b7\u00e4\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Leiche soll weg; umsonst ist der Tod,", "tokens": ["Die", "Lei\u00b7che", "soll", "weg", ";", "um\u00b7sonst", "ist", "der", "Tod", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "$.", "ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Doch zum Leben geh\u00f6ren Moneten.", "tokens": ["Doch", "zum", "Le\u00b7ben", "ge\u00b7h\u00f6\u00b7ren", "Mo\u00b7ne\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADJA", "NN", "$."], "meter": "--+--+----", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Und was, um zu sparen, geschah? Man zerschnitt", "tokens": ["Und", "was", ",", "um", "zu", "spa\u00b7ren", ",", "ge\u00b7schah", "?", "Man", "zer\u00b7schnitt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "$,", "KOUI", "PTKZU", "VVINF", "$,", "VVFIN", "$.", "PIS", "VVFIN"], "meter": "----+--+--+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den Seligen in drei Teile,", "tokens": ["Den", "Se\u00b7li\u00b7gen", "in", "drei", "Tei\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Verpackt sie, und gibt sie am Sattelknopf mit", "tokens": ["Ver\u00b7packt", "sie", ",", "und", "gibt", "sie", "am", "Sat\u00b7tel\u00b7knopf", "mit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVFIN", "PPER", "APPRART", "NN", "APPR"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Drei Reitern, nebst Auftrag zur Eile.", "tokens": ["Drei", "Rei\u00b7tern", ",", "nebst", "Auf\u00b7trag", "zur", "Ei\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "APPR", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und als sie so nach Spanien geschickt,", "tokens": ["Und", "als", "sie", "so", "nach", "Spa\u00b7ni\u00b7en", "ge\u00b7schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "L\u00f6st man sie dort von den S\u00e4tteln.", "tokens": ["L\u00f6st", "man", "sie", "dort", "von", "den", "S\u00e4t\u00b7teln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.7": {"text": "Schnell sind sie wieder zusammengeflickt,", "tokens": ["Schnell", "sind", "sie", "wie\u00b7der", "zu\u00b7sam\u00b7men\u00b7ge\u00b7flickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.8": {"text": "Herr Johann braucht nicht mehr zu betteln.", "tokens": ["Herr", "Jo\u00b7hann", "braucht", "nicht", "mehr", "zu", "bet\u00b7teln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}}, "stanza.7": {"line.1": {"text": "Er wird bestattet mit gro\u00dfem Aplomb,", "tokens": ["Er", "wird", "be\u00b7stat\u00b7tet", "mit", "gro\u00b7\u00dfem", "Ap\u00b7lomb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "K\u00f6nig Philipp war selbst zur Stelle,", "tokens": ["K\u00f6\u00b7nig", "Phi\u00b7lipp", "war", "selbst", "zur", "Stel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADV", "APPRART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und ganz Castiliens Grandenpomp", "tokens": ["Und", "ganz", "Cas\u00b7ti\u00b7li\u00b7ens", "Gran\u00b7den\u00b7pomp"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "NE", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Zog mit bis zur Jaspisschwelle.", "tokens": ["Zog", "mit", "bis", "zur", "Jas\u00b7pis\u00b7schwel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPR", "APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Im Eskorial wuchtet der Sarkophag;", "tokens": ["Im", "Es\u00b7ko\u00b7ri\u00b7al", "wuch\u00b7tet", "der", "Sar\u00b7ko\u00b7phag", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.6": {"text": "Bei Caroli Quinti Gest\u00fchle", "tokens": ["Bei", "Ca\u00b7ro\u00b7li", "Quin\u00b7ti", "Ge\u00b7st\u00fch\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "Warten Vater und Sohn auf den j\u00fcngsten Tag", "tokens": ["War\u00b7ten", "Va\u00b7ter", "und", "Sohn", "auf", "den", "j\u00fcng\u00b7sten", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "In Marmor und Nischenk\u00fchle.", "tokens": ["In", "Mar\u00b7mor", "und", "Ni\u00b7schen\u00b7k\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}