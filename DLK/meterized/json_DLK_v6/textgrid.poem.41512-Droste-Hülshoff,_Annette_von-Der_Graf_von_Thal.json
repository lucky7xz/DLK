{"textgrid.poem.41512": {"metadata": {"author": {"name": "Droste-H\u00fclshoff, Annette von", "birth": "N.A.", "death": "N.A."}, "title": "Der Graf von Thal", "genre": "verse", "period": "N.A.", "pub_year": 1835, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das war der Graf von Thal,", "tokens": ["Das", "war", "der", "Graf", "von", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "So ritt an der Felsenwand;", "tokens": ["So", "ritt", "an", "der", "Fel\u00b7sen\u00b7wand", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das war sein ehlich Gemahl,", "tokens": ["Das", "war", "sein", "eh\u00b7lich", "Ge\u00b7mahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Die hinter dem Steine stand.", "tokens": ["Die", "hin\u00b7ter", "dem", "Stei\u00b7ne", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie schaut' im Sonnenstrahl", "tokens": ["Sie", "schaut'", "im", "Son\u00b7nen\u00b7strahl"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Hinunter den linden Hang,", "tokens": ["Hin\u00b7un\u00b7ter", "den", "lin\u00b7den", "Hang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwo bleibt der Graf von Thal?", "tokens": ["\u00bb", "wo", "bleibt", "der", "Graf", "von", "Thal", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich h\u00f6rt' ihn doch reiten entlang!", "tokens": ["Ich", "h\u00f6rt'", "ihn", "doch", "rei\u00b7ten", "ent\u00b7lang", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Ob das ein Hufschlag ist?", "tokens": ["Ob", "das", "ein", "Huf\u00b7schlag", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Vielleicht ein Hufschlag fern?", "tokens": ["Viel\u00b7leicht", "ein", "Huf\u00b7schlag", "fern", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich wei\u00df doch wohl ohne List,", "tokens": ["Ich", "wei\u00df", "doch", "wohl", "oh\u00b7ne", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ich hab' geh\u00f6rt meinen Herrn!\u00ab", "tokens": ["Ich", "hab'", "ge\u00b7h\u00f6rt", "mei\u00b7nen", "Herrn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "VVFIN", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Sie bog zur\u00fcck den Zweig.", "tokens": ["Sie", "bog", "zu\u00b7r\u00fcck", "den", "Zweig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbbin blind ich oder auch taub?\u00ab", "tokens": ["\u00bb", "bin", "blind", "ich", "o\u00b7der", "auch", "taub", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "ADJD", "PPER", "KON", "ADV", "ADJD", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Sie blinzelt' in das Gestr\u00e4uch,", "tokens": ["Sie", "blin\u00b7zelt'", "in", "das", "Ge\u00b7str\u00e4uch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Und horcht' auf das rauschende Laub.", "tokens": ["Und", "horcht'", "auf", "das", "rau\u00b7schen\u00b7de", "Laub", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.5": {"line.1": {"text": "\u00d6d war's, im Hohlweg leer,", "tokens": ["\u00d6d", "wa\u00b7r's", ",", "im", "Hohl\u00b7weg", "leer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Einsam im rispelnden Wald;", "tokens": ["Ein\u00b7sam", "im", "ris\u00b7peln\u00b7den", "Wald", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Doch \u00fcberm Weiher, am Wehr,", "tokens": ["Doch", "\u00fc\u00b7berm", "Wei\u00b7her", ",", "am", "Wehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Da fand sie den Grafen bald.", "tokens": ["Da", "fand", "sie", "den", "Gra\u00b7fen", "bald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "In seinen Schatten sie trat.", "tokens": ["In", "sei\u00b7nen", "Schat\u00b7ten", "sie", "trat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Er und seine Gesellen,", "tokens": ["Er", "und", "sei\u00b7ne", "Ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Die fl\u00fcstern und halten Rat,", "tokens": ["Die", "fl\u00fcs\u00b7tern", "und", "hal\u00b7ten", "Rat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Viel lauter rieseln die Wellen.", "tokens": ["Viel", "lau\u00b7ter", "rie\u00b7seln", "die", "Wel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie starrten \u00fcber das Land,", "tokens": ["Sie", "starr\u00b7ten", "\u00fc\u00b7ber", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Genau sie sp\u00e4hten, genau,", "tokens": ["Ge\u00b7nau", "sie", "sp\u00e4h\u00b7ten", ",", "ge\u00b7nau", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sahn jedes Zweiglein am Strand,", "tokens": ["Sahn", "je\u00b7des", "Zwei\u00b7glein", "am", "Strand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Doch nicht am Wehre die Frau.", "tokens": ["Doch", "nicht", "am", "Weh\u00b7re", "die", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Zur Erde blickte der Graf,", "tokens": ["Zur", "Er\u00b7de", "blick\u00b7te", "der", "Graf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "So sprach der Graf von Thal:", "tokens": ["So", "sprach", "der", "Graf", "von", "Thal", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbseit dreizehn Jahren den Schlaf", "tokens": ["\u00bb", "seit", "drei\u00b7zehn", "Jah\u00b7ren", "den", "Schlaf"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "APPR", "CARD", "NN", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Rachlose Schmach mir stahl.", "tokens": ["Rach\u00b7lo\u00b7se", "Schmach", "mir", "stahl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "VVFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.9": {"line.1": {"text": "War das ein Seufzer lind?", "tokens": ["War", "das", "ein", "Seuf\u00b7zer", "lind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Gesellen, wer hat's geh\u00f6rt?\u00ab", "tokens": ["Ge\u00b7sel\u00b7len", ",", "wer", "hat's", "ge\u00b7h\u00f6rt", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PWS", "VAFIN", "VVPP", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sprach Kurt: \u00bbEs ist nur der Wind,", "tokens": ["Sprach", "Kurt", ":", "\u00bb", "Es", "ist", "nur", "der", "Wind", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Der \u00fcber das Schilfblatt f\u00e4hrt.\u00ab \u2013", "tokens": ["Der", "\u00fc\u00b7ber", "das", "Schilf\u00b7blatt", "f\u00e4hrt", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$.", "$(", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbso schw\u00f6r' ich beim h\u00f6chsten Gut,", "tokens": ["\u00bb", "so", "schw\u00f6r'", "ich", "beim", "h\u00f6chs\u00b7ten", "Gut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und w\u00e4r's mein ehlich Weib,", "tokens": ["Und", "w\u00e4r's", "mein", "eh\u00b7lich", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und w\u00e4r's meines Bruders Blut,", "tokens": ["Und", "w\u00e4r's", "mei\u00b7nes", "Bru\u00b7ders", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Viel minder mein eigner Leib:", "tokens": ["Viel", "min\u00b7der", "mein", "eig\u00b7ner", "Leib", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Nichts soll mir wenden den Sinn,", "tokens": ["Nichts", "soll", "mir", "wen\u00b7den", "den", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Da\u00df ich die Rache ihm spar';", "tokens": ["Da\u00df", "ich", "die", "Ra\u00b7che", "ihm", "spa\u00b7r'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Freche soll werden inn',", "tokens": ["Der", "Fre\u00b7che", "soll", "wer\u00b7den", "inn'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VAINF", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Zins tragen auch dreizehn Jahr'.", "tokens": ["Zins", "tra\u00b7gen", "auch", "drei\u00b7zehn", "Jahr'", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "CARD", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Bei Gott! das war ein Gest\u00f6hn!\u00ab", "tokens": ["Bei", "Gott", "!", "das", "war", "ein", "Ge\u00b7st\u00f6hn", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "PDS", "VAFIN", "ART", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Sie schossen die Blicke in Hast.", "tokens": ["Sie", "schos\u00b7sen", "die", "Bli\u00b7cke", "in", "Hast", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Sprach Kurt: \u00bbEs ist der F\u00f6hn,", "tokens": ["Sprach", "Kurt", ":", "\u00bb", "Es", "ist", "der", "F\u00f6hn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "$(", "PPER", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Der macht seufzen den Tannenast.\u00ab \u2013", "tokens": ["Der", "macht", "seuf\u00b7zen", "den", "Tan\u00b7ne\u00b7nast", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PDS", "VVFIN", "VVFIN", "ART", "NN", "$.", "$(", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.13": {"line.1": {"text": "\u00bbund ist sein Aug' auch blind,", "tokens": ["\u00bb", "und", "ist", "sein", "Aug'", "auch", "blind", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Und ist sein Haar auch grau,", "tokens": ["Und", "ist", "sein", "Haar", "auch", "grau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und mein Weib seiner Schwester Kind \u2013\u00ab", "tokens": ["Und", "mein", "Weib", "sei\u00b7ner", "Schwes\u00b7ter", "Kind", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "PPOSAT", "NN", "NN", "$(", "$("], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hier tat einen Schrei die Frau.", "tokens": ["Hier", "tat", "ei\u00b7nen", "Schrei", "die", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Wie Wetterfahnen schnell", "tokens": ["Wie", "Wet\u00b7ter\u00b7fah\u00b7nen", "schnell"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NN", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Die dreie wendeten sich.", "tokens": ["Die", "drei\u00b7e", "wen\u00b7de\u00b7ten", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "VVFIN", "PRF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "\u00bbzur\u00fcck, zur\u00fcck, mein Gesell'!", "tokens": ["\u00bb", "zu\u00b7r\u00fcck", ",", "zu\u00b7r\u00fcck", ",", "mein", "Ge\u00b7sell'", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PTKVZ", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Dieses Weibes Richter bin ich.", "tokens": ["Die\u00b7ses", "Wei\u00b7bes", "Rich\u00b7ter", "bin", "ich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NN", "VAFIN", "PPER", "$."], "meter": "+-+-+-++", "measure": "unknown.measure.penta"}}, "stanza.15": {"line.1": {"text": "Hast du gelauscht, Allgund?", "tokens": ["Hast", "du", "ge\u00b7lauscht", ",", "All\u00b7gund", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Du schweigst, du blickst zur Erd'?", "tokens": ["Du", "schweigst", ",", "du", "blickst", "zur", "Erd'", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das bringt dir bittre Stund'!", "tokens": ["Das", "bringt", "dir", "bitt\u00b7re", "Stund'", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Allgund, was hast du geh\u00f6rt?\u00ab \u2013", "tokens": ["All\u00b7gund", ",", "was", "hast", "du", "ge\u00b7h\u00f6rt", "?", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "$,", "PWS", "VAFIN", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.16": {"line.1": {"text": "\u00bbich lausch' deines Rosses Klang,", "tokens": ["\u00bb", "ich", "lausch'", "dei\u00b7nes", "Ros\u00b7ses", "Klang", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich sp\u00e4h' deiner Augen Schein,", "tokens": ["Ich", "sp\u00e4h'", "dei\u00b7ner", "Au\u00b7gen", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So kam ich hinab den Hang.", "tokens": ["So", "kam", "ich", "hin\u00b7ab", "den", "Hang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Nun tue was not mag sein.\u00ab \u2013", "tokens": ["Nun", "tue", "was", "not", "mag", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "VMFIN", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "\u00bbo Frau!\u00ab sprach Jakob Port,", "tokens": ["\u00bb", "o", "Frau", "!", "\u00ab", "sprach", "Ja\u00b7kob", "Port", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$.", "$(", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbda habt ihr schlimmes Spiel!", "tokens": ["\u00bb", "da", "habt", "ihr", "schlim\u00b7mes", "Spiel", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Grad' sprach der Herr ein Wort,", "tokens": ["Grad'", "sprach", "der", "Herr", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das sich verma\u00df gar viel.\u00ab", "tokens": ["Das", "sich", "ver\u00b7ma\u00df", "gar", "viel", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PRF", "VVFIN", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Sprach Kurt: \u00bbIch sag' es rund,", "tokens": ["Sprach", "Kurt", ":", "\u00bb", "Ich", "sag'", "es", "rund", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$.", "$(", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Viel lieber den Wolf im Stall,", "tokens": ["Viel", "lie\u00b7ber", "den", "Wolf", "im", "Stall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NE", "APPRART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Als eines Weibes Mund", "tokens": ["Als", "ei\u00b7nes", "Wei\u00b7bes", "Mund"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Zum H\u00fcter in solchem Fall.\u00ab", "tokens": ["Zum", "H\u00fc\u00b7ter", "in", "sol\u00b7chem", "Fall", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Da sah der Graf sie an,", "tokens": ["Da", "sah", "der", "Graf", "sie", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Zu einem und zu zwein;", "tokens": ["Zu", "ei\u00b7nem", "und", "zu", "zwein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Drauf sprach zur Fraue der Mann:", "tokens": ["Drauf", "sprach", "zur", "Frau\u00b7e", "der", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "\u00bbwohl wei\u00df ich, du bist mein.", "tokens": ["\u00bb", "wohl", "wei\u00df", "ich", ",", "du", "bist", "mein", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Als du gefangen lagst", "tokens": ["Als", "du", "ge\u00b7fan\u00b7gen", "lagst"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Um mich ein ganzes Jahr,", "tokens": ["Um", "mich", "ein", "gan\u00b7zes", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und keine Silbe sprachst:", "tokens": ["Und", "kei\u00b7ne", "Sil\u00b7be", "sprachst", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da ward deine Treu' mir klar.", "tokens": ["Da", "ward", "dei\u00b7ne", "Treu'", "mir", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPER", "ADJD", "$."], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.21": {"line.1": {"text": "So schw\u00f6re mir denn sogleich:", "tokens": ["So", "schw\u00f6\u00b7re", "mir", "denn", "sog\u00b7leich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Sei's wenig oder auch viel,", "tokens": ["Sei's", "we\u00b7nig", "o\u00b7der", "auch", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KON", "ADV", "ADV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Was du vernahmst am Teich,", "tokens": ["Was", "du", "ver\u00b7nahmst", "am", "Teich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dir sei's wie Rauch und Spiel.", "tokens": ["Dir", "sei's", "wie", "Rauch", "und", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Als seie nichts geschehn,", "tokens": ["Als", "sei\u00b7e", "nichts", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "So mu\u00df ich v\u00f6llig meinen;", "tokens": ["So", "mu\u00df", "ich", "v\u00f6l\u00b7lig", "mei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Darf dich nicht weinen sehn,", "tokens": ["Darf", "dich", "nicht", "wei\u00b7nen", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "VVINF", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Darfst mir nicht bleich erscheinen.", "tokens": ["Darfst", "mir", "nicht", "bleich", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Denk nach, denk nach, Allgund!", "tokens": ["Denk", "nach", ",", "denk", "nach", ",", "All\u00b7gund", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Was zu verhei\u00dfen not.", "tokens": ["Was", "zu", "ver\u00b7hei\u00b7\u00dfen", "not", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Wahrheit spricht dein Mund,", "tokens": ["Die", "Wahr\u00b7heit", "spricht", "dein", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich wei\u00df, und br\u00e4cht' es Tod.\u00ab", "tokens": ["Ich", "wei\u00df", ",", "und", "br\u00e4cht'", "es", "Tod", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PPER", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Und konnte sie sich besinnen,", "tokens": ["Und", "konn\u00b7te", "sie", "sich", "be\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Verhei\u00dfen h\u00e4tte sie's nie;", "tokens": ["Ver\u00b7hei\u00b7\u00dfen", "h\u00e4t\u00b7te", "sie's", "nie", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "So war sie halb von Sinnen,", "tokens": ["So", "war", "sie", "halb", "von", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie schwur, und wu\u00dfte nicht wie.", "tokens": ["Sie", "schwur", ",", "und", "wu\u00df\u00b7te", "nicht", "wie", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "PTKNEG", "PWAV", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}}}}