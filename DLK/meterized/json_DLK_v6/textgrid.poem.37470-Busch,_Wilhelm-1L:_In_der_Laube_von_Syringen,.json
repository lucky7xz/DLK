{"textgrid.poem.37470": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: In der Laube von Syringen,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In der Laube von Syringen,", "tokens": ["In", "der", "Lau\u00b7be", "von", "Sy\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oh, wie ist der Abend fein.", "tokens": ["Oh", ",", "wie", "ist", "der", "A\u00b7bend", "fein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PWAV", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Br\u00fcder, la\u00dft die Gl\u00e4ser klingen,", "tokens": ["Br\u00fc\u00b7der", ",", "la\u00dft", "die", "Gl\u00e4\u00b7ser", "klin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Angef\u00fcllt mit Maienwein.", "tokens": ["An\u00b7ge\u00b7f\u00fcllt", "mit", "Mai\u00b7en\u00b7wein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Heija, der frische Mai", "tokens": ["Hei\u00b7ja", ",", "der", "fri\u00b7sche", "Mai"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "ADJA", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Er bringt uns mancherlei.", "tokens": ["Er", "bringt", "uns", "man\u00b7cher\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Sch\u00f6nste aber hier auf Erden", "tokens": ["Das", "Sch\u00f6ns\u00b7te", "a\u00b7ber", "hier", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist lieben und geliebt zu werden,", "tokens": ["Ist", "lie\u00b7ben", "und", "ge\u00b7liebt", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "KON", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Heija, im frischen Mai.", "tokens": ["Hei\u00b7ja", ",", "im", "fri\u00b7schen", "Mai", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "\u00dcber uns die lieben Sterne", "tokens": ["\u00dc\u00b7ber", "uns", "die", "lie\u00b7ben", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Blinken hell und frohgemut,", "tokens": ["Blin\u00b7ken", "hell", "und", "froh\u00b7ge\u00b7mut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn sie sehen schon von ferne,", "tokens": ["Denn", "sie", "se\u00b7hen", "schon", "von", "fer\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPR", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch hier unten geht es gut.", "tokens": ["Auch", "hier", "un\u00b7ten", "geht", "es", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer sich jetzt bei tr\u00fcber Kerzen", "tokens": ["Wer", "sich", "jetzt", "bei", "tr\u00fc\u00b7ber", "Ker\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PRF", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Gelehrsamkeit beflei\u00dft,", "tokens": ["Der", "Ge\u00b7lehr\u00b7sam\u00b7keit", "be\u00b7flei\u00dft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Diesem w\u00fcnschen wir von Herzen,", "tokens": ["Die\u00b7sem", "w\u00fcn\u00b7schen", "wir", "von", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df er bald Professor hei\u00dft.", "tokens": ["Da\u00df", "er", "bald", "Pro\u00b7fes\u00b7sor", "hei\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wer als Wein- und", "tokens": ["Wer", "als", "Wein", "und"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "KOKOM", "TRUNC", "KON"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Weiberhasser", "tokens": ["Wei\u00b7ber\u00b7has\u00b7ser"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Jedermann im Wege steht,", "tokens": ["Je\u00b7der\u00b7mann", "im", "We\u00b7ge", "steht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPRART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Der genie\u00dfe Brot und Wasser,", "tokens": ["Der", "ge\u00b7nie\u00b7\u00dfe", "Brot", "und", "Was\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Bis er endlich in sich geht.", "tokens": ["Bis", "er", "end\u00b7lich", "in", "sich", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wem vielleicht sein altes Hannchen", "tokens": ["Wem", "viel\u00b7leicht", "sein", "al\u00b7tes", "Hann\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Irgendwie abhanden kam,", "tokens": ["Ir\u00b7gend\u00b7wie", "ab\u00b7han\u00b7den", "kam", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Nur getrost, es gab schon manchen,", "tokens": ["Nur", "ge\u00b7trost", ",", "es", "gab", "schon", "man\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "PPER", "VVFIN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der ein neues Hannchen nahm.", "tokens": ["Der", "ein", "neu\u00b7es", "Hann\u00b7chen", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Also, eh der Mai zu Ende,", "tokens": ["Al\u00b7so", ",", "eh", "der", "Mai", "zu", "En\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aufgeschaut und umgeblickt,", "tokens": ["Auf\u00b7ge\u00b7schaut", "und", "um\u00b7ge\u00b7blickt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "KON", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keiner, der nicht eine f\u00e4nde,", "tokens": ["Kei\u00b7ner", ",", "der", "nicht", "ei\u00b7ne", "f\u00e4n\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PTKNEG", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die ihn an ihr Herze dr\u00fcckt.", "tokens": ["Die", "ihn", "an", "ihr", "Her\u00b7ze", "dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Jahre steigen auf und nieder;", "tokens": ["Jah\u00b7re", "stei\u00b7gen", "auf", "und", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber, wenn der Lenz erbl\u00fcht,", "tokens": ["A\u00b7ber", ",", "wenn", "der", "Lenz", "er\u00b7bl\u00fcht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Dann, ihr Br\u00fcder, immer wieder", "tokens": ["Dann", ",", "ihr", "Br\u00fc\u00b7der", ",", "im\u00b7mer", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$,", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6ne unser Jubellied.", "tokens": ["T\u00f6\u00b7ne", "un\u00b7ser", "Ju\u00b7bel\u00b7lied", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Heija, der frische Mai,", "tokens": ["Hei\u00b7ja", ",", "der", "fri\u00b7sche", "Mai", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.2": {"text": "Er bringt uns mancherlei,", "tokens": ["Er", "bringt", "uns", "man\u00b7cher\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Sch\u00f6nste aber hier auf Erden", "tokens": ["Das", "Sch\u00f6ns\u00b7te", "a\u00b7ber", "hier", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ist lieben und geliebt zu werden,", "tokens": ["Ist", "lie\u00b7ben", "und", "ge\u00b7liebt", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "KON", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Heija, im frischen Mai.", "tokens": ["Hei\u00b7ja", ",", "im", "fri\u00b7schen", "Mai", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}}}}