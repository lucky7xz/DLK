{"textgrid.poem.64196": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Das verlorene Schwesterlein und die drei Br\u00fcder", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbo, S\u00f6hne mein, o, S\u00f6hne drei,", "tokens": ["\u00bb", "o", ",", "S\u00f6h\u00b7ne", "mein", ",", "o", ",", "S\u00f6h\u00b7ne", "drei", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "$,", "NN", "PPOSAT", "$,", "FM", "$,", "NN", "CARD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verschwunden ist, dieweil ihr fern", "tokens": ["Ver\u00b7schwun\u00b7den", "ist", ",", "die\u00b7weil", "ihr", "fern"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$,", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Waffendienst f\u00fcr euren Herrn,", "tokens": ["Im", "Waf\u00b7fen\u00b7dienst", "f\u00fcr", "eu\u00b7ren", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verschwunden euer Schwesterlein!", "tokens": ["Ver\u00b7schwun\u00b7den", "eu\u00b7er", "Schwes\u00b7ter\u00b7lein", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das bringt der Mutter Todespein!", "tokens": ["Das", "bringt", "der", "Mut\u00b7ter", "To\u00b7de\u00b7spein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Schafft ihr das Kind nicht wieder bei,", "tokens": ["Schafft", "ihr", "das", "Kind", "nicht", "wie\u00b7der", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKNEG", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Schafft ihr nicht wieder bei das Kind,", "tokens": ["Schafft", "ihr", "nicht", "wie\u00b7der", "bei", "das", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So wein' ich mir die Augen blind!", "tokens": ["So", "wein'", "ich", "mir", "die", "Au\u00b7gen", "blind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zieht aus und sucht das Gretelein!\u00ab", "tokens": ["Zieht", "aus", "und", "sucht", "das", "Gre\u00b7tel\u00b7ein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PTKVZ", "KON", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbach Schwesterlein, ach Schwesterlein!", "tokens": ["\u00bb", "ach", "Schwes\u00b7ter\u00b7lein", ",", "ach", "Schwes\u00b7ter\u00b7lein", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "$,", "XY", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie hast du dich so weit hinaus", "tokens": ["Wie", "hast", "du", "dich", "so", "weit", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "PRF", "ADV", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verloren von dem Vaterhaus!", "tokens": ["Ver\u00b7lo\u00b7ren", "von", "dem", "Va\u00b7ter\u00b7haus", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir Br\u00fcder tragen gro\u00df Begehr", "tokens": ["Wir", "Br\u00fc\u00b7der", "tra\u00b7gen", "gro\u00df", "Be\u00b7gehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und m\u00f6chten gerne bei dir sein", "tokens": ["Und", "m\u00f6ch\u00b7ten", "ger\u00b7ne", "bei", "dir", "sein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PPER", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und kennen ach! die Wege nicht", "tokens": ["Und", "ken\u00b7nen", "ach", "!", "die", "We\u00b7ge", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ITJ", "$.", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und finden ach! die Stege nicht", "tokens": ["Und", "fin\u00b7den", "ach", "!", "die", "Ste\u00b7ge", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVINF", "ITJ", "$.", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und reiten in die Welt hinein", "tokens": ["Und", "rei\u00b7ten", "in", "die", "Welt", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und irren fragend im Land umher.", "tokens": ["Und", "ir\u00b7ren", "fra\u00b7gend", "im", "Land", "um\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Wie war so sonnenhell dein Haar!", "tokens": ["Wie", "war", "so", "son\u00b7nen\u00b7hell", "dein", "Haar", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie war dein blaues Aug' so klar!", "tokens": ["Wie", "war", "dein", "blau\u00b7es", "Aug'", "so", "klar", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein' Rosenknospe war dein Mund,", "tokens": ["Ein'", "Ro\u00b7sen\u00b7knos\u00b7pe", "war", "dein", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und l\u00e4g' ein Herz zu Tode wund, \u2013", "tokens": ["Und", "l\u00e4g'", "ein", "Herz", "zu", "To\u00b7de", "wund", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "ADJD", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein L\u00e4cheln macht' es flugs gesund!", "tokens": ["Dein", "L\u00e4\u00b7cheln", "macht'", "es", "flugs", "ge\u00b7sund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wir suchen dich mit Horn und Hund!", "tokens": ["Wir", "su\u00b7chen", "dich", "mit", "Horn", "und", "Hund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wir suchen dich in Busch und Dorn,", "tokens": ["Wir", "su\u00b7chen", "dich", "in", "Busch", "und", "Dorn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wir schauen bang in Bach und Born,", "tokens": ["Wir", "schau\u00b7en", "bang", "in", "Bach", "und", "Born", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "NE", "KON", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wir rufen dich mit Hund und Horn.", "tokens": ["Wir", "ru\u00b7fen", "dich", "mit", "Hund", "und", "Horn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sag an, du Zecher hinter'm Krug,", "tokens": ["Sag", "an", ",", "du", "Ze\u00b7cher", "hin\u00b7ter'm", "Krug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sag an, du Bauer hinter'm Pflug,", "tokens": ["Sag", "an", ",", "du", "Bau\u00b7er", "hin\u00b7ter'm", "Pflug", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPER", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du Fuhrmann in dem Saumro\u00dfzug,", "tokens": ["Du", "Fuhr\u00b7mann", "in", "dem", "Saum\u00b7ro\u00df\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sag an im Wald, du Kr\u00e4uterfrau,", "tokens": ["Sag", "an", "im", "Wald", ",", "du", "Kr\u00e4u\u00b7ter\u00b7frau", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "APPRART", "NN", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du T\u00fcrmer hoch am Zinnenbau,", "tokens": ["Du", "T\u00fcr\u00b7mer", "hoch", "am", "Zin\u00b7nen\u00b7bau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch h\u00f6her, Falk im \u00c4therblau,", "tokens": ["Noch", "h\u00f6\u00b7her", ",", "Falk", "im", "\u00c4\u00b7ther\u00b7blau", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "NE", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u2013 Du hast die allersch\u00e4rfste Schau,", "tokens": ["\u2013", "Du", "hast", "die", "al\u00b7ler\u00b7sch\u00e4rfs\u00b7te", "Schau", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sagt, saht ihr sie denn nirgendwo? \u2013", "tokens": ["Sagt", ",", "saht", "ihr", "sie", "denn", "nir\u00b7gend\u00b7wo", "?", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So werden wir niemals wieder froh!\u00ab \u2013 \u2013", "tokens": ["So", "wer\u00b7den", "wir", "nie\u00b7mals", "wie\u00b7der", "froh", "!", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$.", "$(", "$(", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Lang' ritten sie, landaus, landein,", "tokens": ["Lang'", "rit\u00b7ten", "sie", ",", "lan\u00b7daus", ",", "lan\u00b7de\u00b7in", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$,", "ADV", "$,", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und fanden nicht ihr Schwesterlein.", "tokens": ["Und", "fan\u00b7den", "nicht", "ihr", "Schwes\u00b7ter\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die \u00e4ltern Br\u00fcder weinten sehr;", "tokens": ["Die", "\u00e4l\u00b7tern", "Br\u00fc\u00b7der", "wein\u00b7ten", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Des J\u00fcngsten Aug' blieb tr\u00e4nenleer,", "tokens": ["Des", "J\u00fcng\u00b7sten", "Aug'", "blieb", "tr\u00e4\u00b7nen\u00b7leer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da schalten ihn die beiden schwer.", "tokens": ["Da", "schal\u00b7ten", "ihn", "die", "bei\u00b7den", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "PIAT", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er aber schwieg. \u2013 Und einst im Traum", "tokens": ["Er", "a\u00b7ber", "schwieg", ".", "\u2013", "Und", "einst", "im", "Traum"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "$.", "$(", "KON", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sang ihm ein V\u00f6glein aus dem Baum:", "tokens": ["Sang", "ihm", "ein", "V\u00f6\u00b7glein", "aus", "dem", "Baum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbich wei\u00df: \u2013 du liebst sie noch viel mehr:", "tokens": ["\u00bb", "ich", "wei\u00df", ":", "\u2013", "du", "liebst", "sie", "noch", "viel", "mehr", ":"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Schau, was hier glei\u00dft im Sonnenschein!\u00ab", "tokens": ["Schau", ",", "was", "hier", "glei\u00dft", "im", "Son\u00b7nen\u00b7schein", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "VVFIN", "APPRART", "NN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Vom Schlaf fuhr auf jung Reinhold da,", "tokens": ["Vom", "Schlaf", "fuhr", "auf", "jung", "Rein\u00b7hold", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "APPR", "ADJD", "NE", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wie er staunend um sich sah,", "tokens": ["Und", "wie", "er", "stau\u00b7nend", "um", "sich", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADJD", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da, an dem Hagedorn, ganz nah,", "tokens": ["Da", ",", "an", "dem", "Ha\u00b7ge\u00b7dorn", ",", "ganz", "nah", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da hing ein sonnengolden Haar!", "tokens": ["Da", "hing", "ein", "son\u00b7nen\u00b7gol\u00b7den", "Haar", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie froh sein Herz erschrocken war!", "tokens": ["Wie", "froh", "sein", "Herz", "er\u00b7schro\u00b7cken", "war", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbwach auf!\u00ab rief er, \u00bbdu Br\u00fcderpaar,", "tokens": ["\u00bb", "wach", "auf", "!", "\u00ab", "rief", "er", ",", "\u00bb", "du", "Br\u00fc\u00b7der\u00b7paar", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "PTKVZ", "$.", "$(", "VVFIN", "PPER", "$,", "$(", "PPER", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Solch Haar wie eitel Sonnenschein", "tokens": ["Solch", "Haar", "wie", "ei\u00b7tel", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KOKOM", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Tr\u00e4gt einzig unser Schwesterlein: \u2013", "tokens": ["Tr\u00e4gt", "ein\u00b7zig", "un\u00b7ser", "Schwes\u00b7ter\u00b7lein", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADJD", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Hier ging des Wegs das Gretelein!\u00ab", "tokens": ["Hier", "ging", "des", "Wegs", "das", "Gre\u00b7tel\u00b7ein", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbschau, durch das feuchte Moos ein Pfad,", "tokens": ["\u00bb", "schau", ",", "durch", "das", "feuch\u00b7te", "Moos", "ein", "Pfad", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "APPR", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Das sind die Schrittlein, die sie trat:", "tokens": ["Das", "sind", "die", "Schritt\u00b7lein", ",", "die", "sie", "trat", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So schmalen Fu\u00df hat sie allein!", "tokens": ["So", "schma\u00b7len", "Fu\u00df", "hat", "sie", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier, vor dem Berg aus schwarzem Stein,", "tokens": ["Hier", ",", "vor", "dem", "Berg", "aus", "schwar\u00b7zem", "Stein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.5": {"text": "Erlischt die Spur: \u2013 hier mu\u00df sie sein!\u00ab", "tokens": ["Er\u00b7lischt", "die", "Spur", ":", "\u2013", "hier", "mu\u00df", "sie", "sein", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "$(", "ADV", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch unwirsch sprach das \u00e4ltre Paar:", "tokens": ["Doch", "un\u00b7wirsch", "sprach", "das", "\u00e4l\u00b7tre", "Paar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbdu Bruder Tr\u00e4umer! Was nicht gar!", "tokens": ["\u00bb", "du", "Bru\u00b7der", "Tr\u00e4u\u00b7mer", "!", "Was", "nicht", "gar", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "NN", "NN", "$.", "PWS", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Manch' M\u00e4dchen wohl hat solches Haar,", "tokens": ["Man\u00b7ch'", "M\u00e4d\u00b7chen", "wohl", "hat", "sol\u00b7ches", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Manch' M\u00e4dchen auch solch F\u00fc\u00dfchen klein.", "tokens": ["Man\u00b7ch'", "M\u00e4d\u00b7chen", "auch", "solch", "F\u00fc\u00df\u00b7chen", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "PIAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.8": {"line.1": {"text": "Wir suchten nun ein volles Jahr. \u2013", "tokens": ["Wir", "such\u00b7ten", "nun", "ein", "vol\u00b7les", "Jahr", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ist verloren, das ist klar. \u2013", "tokens": ["Sie", "ist", "ver\u00b7lo\u00b7ren", ",", "das", "ist", "klar", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PDS", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir kehren heim. \u2013 Wir geben's auf. \u2013", "tokens": ["Wir", "keh\u00b7ren", "heim", ".", "\u2013", "Wir", "ge\u00b7ben's", "auf", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Welt will gehen ihren Lauf;", "tokens": ["Die", "Welt", "will", "ge\u00b7hen", "ih\u00b7ren", "Lauf", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wir m\u00fcssen sorgen f\u00fcr Hab und Haus.\u00ab", "tokens": ["Wir", "m\u00fcs\u00b7sen", "sor\u00b7gen", "f\u00fcr", "Hab", "und", "Haus", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "NN", "APPR", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und sie ritten aus dem Tann hinaus. \u2013", "tokens": ["Und", "sie", "rit\u00b7ten", "aus", "dem", "Tann", "hin\u00b7aus", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.7": {"text": "Doch Reinhold zog sein Schwert und sprach:", "tokens": ["Doch", "Rein\u00b7hold", "zog", "sein", "Schwert", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbich forsche meiner Schwester nach,", "tokens": ["\u00bb", "ich", "for\u00b7sche", "mei\u00b7ner", "Schwes\u00b7ter", "nach", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Bis dieser Stahl den Berg durchstach.", "tokens": ["Bis", "die\u00b7ser", "Stahl", "den", "Berg", "durch\u00b7stach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Vom Gretlein ich nicht lassen mag, \u2013", "tokens": ["Vom", "Gret\u00b7lein", "ich", "nicht", "las\u00b7sen", "mag", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich suche bis zum j\u00fcngsten Tag.\u00ab", "tokens": ["Ich", "su\u00b7che", "bis", "zum", "j\u00fcng\u00b7sten", "Tag", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da kracht im Berg ein Donnerschlag:", "tokens": ["Da", "kracht", "im", "Berg", "ein", "Don\u00b7ner\u00b7schlag", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auf springt das schwarze Felsgestein,", "tokens": ["Auf", "springt", "das", "schwar\u00b7ze", "Fels\u00b7ge\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sieh, da steht das Gretelein,", "tokens": ["Und", "sieh", ",", "da", "steht", "das", "Gre\u00b7tel\u00b7ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So sch\u00f6n, wie es noch niemals war,", "tokens": ["So", "sch\u00f6n", ",", "wie", "es", "noch", "nie\u00b7mals", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWAV", "PPER", "ADV", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Umflutet ganz vom Sonnenhaar:", "tokens": ["Um\u00b7flu\u00b7tet", "ganz", "vom", "Son\u00b7nen\u00b7haar", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbhab Dank! Nun ist der Zauber aus.", "tokens": ["\u00bb", "hab", "Dank", "!", "Nun", "ist", "der", "Zau\u00b7ber", "aus", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "O, bring zur Mutter mich nach Haus!\u00ab", "tokens": ["O", ",", "bring", "zur", "Mut\u00b7ter", "mich", "nach", "Haus", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "VVFIN", "APPRART", "NN", "PRF", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Da hob jung Reinhold sie aufs Ro\u00df", "tokens": ["Da", "hob", "jung", "Rein\u00b7hold", "sie", "aufs", "Ro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJD", "NN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fchrte sie ins V\u00e4terschlo\u00df", "tokens": ["Und", "f\u00fchr\u00b7te", "sie", "ins", "V\u00e4\u00b7ter\u00b7schlo\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und rief: \u00bbHei Bauer hinter'm Pflug,", "tokens": ["Und", "rief", ":", "\u00bb", "Hei", "Bau\u00b7er", "hin\u00b7ter'm", "Pflug", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "NE", "NE", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Fuhrmann im Zug und Gast beim Krug,", "tokens": ["Fuhr\u00b7mann", "im", "Zug", "und", "Gast", "beim", "Krug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "KON", "NN", "APPRART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Hei T\u00fcrmer hoch am Zinnenbau,", "tokens": ["Hei", "T\u00fcr\u00b7mer", "hoch", "am", "Zin\u00b7nen\u00b7bau", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Falke du im Himmelsblau \u2013,", "tokens": ["Und", "Fal\u00b7ke", "du", "im", "Him\u00b7mels\u00b7blau", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "PPER", "APPRART", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u2013 Du hast die allersch\u00e4rfste Schau: \u2013,", "tokens": ["\u2013", "Du", "hast", "die", "al\u00b7ler\u00b7sch\u00e4rfs\u00b7te", "Schau", ":", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Doch Froh'res ist euch nicht bekannt,", "tokens": ["Doch", "Froh'\u00b7res", "ist", "euch", "nicht", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als der Bruder, der die Schwester fand.\u00ab", "tokens": ["Als", "der", "Bru\u00b7der", ",", "der", "die", "Schwes\u00b7ter", "fand", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}