{"textgrid.poem.34452": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Prometheus brach jahrtausendalte Fesseln.", "genre": "verse", "period": "N.A.", "pub_year": 1886, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Prometheus brach jahrtausendalte Fesseln.", "tokens": ["Pro\u00b7me\u00b7theus", "brach", "jahr\u00b7tau\u00b7sen\u00b7dal\u00b7te", "Fes\u00b7seln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er reckt die Glieder, er erhebt das Haupt,", "tokens": ["Er", "reckt", "die", "Glie\u00b7der", ",", "er", "er\u00b7hebt", "das", "Haupt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wie ein Morgenroth erhellt die Welt", "tokens": ["und", "wie", "ein", "Mor\u00b7gen\u00b7roth", "er\u00b7hellt", "die", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der ungebrochne Strahl der grossen Augen.", "tokens": ["der", "un\u00b7ge\u00b7broch\u00b7ne", "Strahl", "der", "gros\u00b7sen", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "\u2013 Prometheus! Prometheus!", "tokens": ["\u2013", "Pro\u00b7me\u00b7theus", "!", "Pro\u00b7me\u00b7theus", "!"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "NE", "$.", "NE", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}}, "stanza.2": {"line.1": {"text": "\u2013 Ihr Menschen, die mein Sch\u00f6pfersehnen rief", "tokens": ["\u2013", "Ihr", "Men\u00b7schen", ",", "die", "mein", "Sch\u00f6p\u00b7fer\u00b7seh\u00b7nen", "rief"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "hervor ans Licht der g\u00f6tterfrohen Sonne,", "tokens": ["her\u00b7vor", "ans", "Licht", "der", "g\u00f6t\u00b7ter\u00b7fro\u00b7hen", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "habt ihr vollendet, was ich ahnend sann?", "tokens": ["habt", "ihr", "voll\u00b7en\u00b7det", ",", "was", "ich", "ah\u00b7nend", "sann", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "PWS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Lebt ihr und dankt ihr mir das Leben?", "tokens": ["Lebt", "ihr", "und", "dankt", "ihr", "mir", "das", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Der Funke, der aus meinen H\u00e4nden troff,", "tokens": ["Der", "Fun\u00b7ke", ",", "der", "aus", "mei\u00b7nen", "H\u00e4n\u00b7den", "troff", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "erhellt er eure Stirn?", "tokens": ["er\u00b7hellt", "er", "eu\u00b7re", "Stirn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Liebe, die mein Athem Euch gehaucht", "tokens": ["Die", "Lie\u00b7be", ",", "die", "mein", "A\u00b7them", "Euch", "ge\u00b7haucht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "in kalte Brust, hat sie die Brust durchseelt?", "tokens": ["in", "kal\u00b7te", "Brust", ",", "hat", "sie", "die", "Brust", "durch\u00b7seelt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich lag, geschmiedet in die Eisenbande,", "tokens": ["Ich", "lag", ",", "ge\u00b7schmie\u00b7det", "in", "die", "Ei\u00b7sen\u00b7ban\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "am harten Fels. Zu meinen F\u00fcssen rauschte", "tokens": ["am", "har\u00b7ten", "Fels", ".", "Zu", "mei\u00b7nen", "F\u00fcs\u00b7sen", "rauschte"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$.", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "das Meer, und seiner Brandung wilder, steter", "tokens": ["das", "Meer", ",", "und", "sei\u00b7ner", "Bran\u00b7dung", "wil\u00b7der", ",", "ste\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "KON", "PPOSAT", "NN", "ADJA", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Laut \u00fcbert\u00f6nte alles Menschliche.", "tokens": ["Laut", "\u00fc\u00b7ber\u00b7t\u00f6n\u00b7te", "al\u00b7les", "Menschli\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Gischt der Fluthen h\u00fcllte jede Ferne", "tokens": ["Der", "Gischt", "der", "Flut\u00b7hen", "h\u00fcll\u00b7te", "je\u00b7de", "Fer\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "vor meinem Blick in weisse Schleier.", "tokens": ["vor", "mei\u00b7nem", "Blick", "in", "weis\u00b7se", "Schlei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Menschen!", "tokens": ["Men\u00b7schen", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Ich brach die Ketten neiderf\u00fcllter G\u00f6tter \u2013", "tokens": ["Ich", "brach", "die", "Ket\u00b7ten", "nei\u00b7der\u00b7f\u00fcll\u00b7ter", "G\u00f6t\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ich rufe euch! H\u00f6rt mich!", "tokens": ["ich", "ru\u00b7fe", "euch", "!", "H\u00f6rt", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "VVIMP", "PPER", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u2013 Prometheus! Prometheus!", "tokens": ["\u2013", "Pro\u00b7me\u00b7theus", "!", "Pro\u00b7me\u00b7theus", "!"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "NE", "$.", "NE", "$."], "meter": "-+-+--", "measure": "unknown.measure.di"}}, "stanza.6": {"line.1": {"text": "Da kroch heran das sclavische Gez\u00fccht", "tokens": ["Da", "kroch", "he\u00b7ran", "das", "scla\u00b7vi\u00b7sche", "Ge\u00b7z\u00fccht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PTKVZ", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Menschen. \u2013 Herr, wie sollen wir", "tokens": ["der", "Men\u00b7schen", ".", "\u2013", "Herr", ",", "wie", "sol\u00b7len", "wir"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$.", "$(", "NN", "$,", "PWAV", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "dir dienen? \u2013 Unterw\u00fcrfigkeit im Blick,", "tokens": ["dir", "die\u00b7nen", "?", "\u2013", "Un\u00b7ter\u00b7w\u00fcr\u00b7fig\u00b7keit", "im", "Blick", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$.", "$(", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "gekr\u00fcmmt den R\u00fccken und gebeugt das Knie.", "tokens": ["ge\u00b7kr\u00fcmmt", "den", "R\u00fc\u00b7cken", "und", "ge\u00b7beugt", "das", "Knie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ein Mann mit einem goldnen Reif im Haar", "tokens": ["Ein", "Mann", "mit", "ei\u00b7nem", "gold\u00b7nen", "Reif", "im", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "sprach: Dein Geschenk verehren wir geb\u00fchrend.", "tokens": ["sprach", ":", "Dein", "Ge\u00b7schenk", "ver\u00b7eh\u00b7ren", "wir", "ge\u00b7b\u00fch\u00b7rend", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich beuge mich vor deiner Sch\u00f6pfergr\u00f6sse,", "tokens": ["Ich", "beu\u00b7ge", "mich", "vor", "dei\u00b7ner", "Sch\u00f6p\u00b7fer\u00b7gr\u00f6s\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und meine Unterthanen sind die deinen.", "tokens": ["und", "mei\u00b7ne", "Un\u00b7ter\u00b7tha\u00b7nen", "sind", "die", "dei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "PPOSAT", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ein Mann im groben Kittel voller Schmutz", "tokens": ["Ein", "Mann", "im", "gro\u00b7ben", "Kit\u00b7tel", "vol\u00b7ler", "Schmutz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "sprach: Herr, ich friste mir mit meiner Arbeit", "tokens": ["sprach", ":", "Herr", ",", "ich", "fris\u00b7te", "mir", "mit", "mei\u00b7ner", "Ar\u00b7beit"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "NN", "$,", "PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "das Leben, und mein Weib ern\u00e4hrt die Kinder.", "tokens": ["das", "Le\u00b7ben", ",", "und", "mein", "Weib", "er\u00b7n\u00e4hrt", "die", "Kin\u00b7der", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir sind zufrieden und wir danken dir.", "tokens": ["Wir", "sind", "zu\u00b7frie\u00b7den", "und", "wir", "dan\u00b7ken", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und nach ihm kamen andere, ungez\u00e4hlt,", "tokens": ["Und", "nach", "ihm", "ka\u00b7men", "an\u00b7de\u00b7re", ",", "un\u00b7ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PIS", "$,", "ADJD", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "und alle sprachen scheu und lallten:", "tokens": ["und", "al\u00b7le", "spra\u00b7chen", "scheu", "und", "lall\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u2013 Herr! Herr!", "tokens": ["\u2013", "Herr", "!", "Herr", "!"], "token_info": ["punct", "word", "punct", "word", "punct"], "pos": ["$(", "NN", "$.", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.10": {"line.1": {"text": "Ein H\u00e4uflein stand beiseit und blickte stumm", "tokens": ["Ein", "H\u00e4uf\u00b7lein", "stand", "bei\u00b7seit", "und", "blick\u00b7te", "stumm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "auf jene, die vor ihnen lagen", "tokens": ["auf", "je\u00b7ne", ",", "die", "vor", "ih\u00b7nen", "la\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "$,", "PRELS", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "zu F\u00fcssen des entfesselten Gebieters.", "tokens": ["zu", "F\u00fcs\u00b7sen", "des", "ent\u00b7fes\u00b7sel\u00b7ten", "Ge\u00b7bie\u00b7ters", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}}, "stanza.11": {"line.1": {"text": "Verachtung zuckte herb um ihre Lippen,", "tokens": ["Ver\u00b7ach\u00b7tung", "zuck\u00b7te", "herb", "um", "ih\u00b7re", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "auf ihren Brauen lag der Trotz.", "tokens": ["auf", "ih\u00b7ren", "Brau\u00b7en", "lag", "der", "Trotz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "\u2013 Und ihr?", "tokens": ["\u2013", "Und", "ihr", "?"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "KON", "PPER", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.13": {"line.1": {"text": "\u2013 Der Funke, der aus deinen H\u00e4nden troff,", "tokens": ["\u2013", "Der", "Fun\u00b7ke", ",", "der", "aus", "dei\u00b7nen", "H\u00e4n\u00b7den", "troff", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Strom der Zeiten hat ihn ausgel\u00f6scht.", "tokens": ["der", "Strom", "der", "Zei\u00b7ten", "hat", "ihn", "aus\u00b7ge\u00b7l\u00f6scht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Liebe, die dein Athem einst gehaucht", "tokens": ["Die", "Lie\u00b7be", ",", "die", "dein", "A\u00b7them", "einst", "ge\u00b7haucht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "in Menschenbrust, sie ist erstickt und tot.", "tokens": ["in", "Men\u00b7schen\u00b7brust", ",", "sie", "ist", "er\u00b7stickt", "und", "tot", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PPER", "VAFIN", "VVPP", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Enterbt, im Staube w\u00e4lzen sich Millionen", "tokens": ["En\u00b7terbt", ",", "im", "Stau\u00b7be", "w\u00e4l\u00b7zen", "sich", "Mil\u00b7lion\u00b7en"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "APPRART", "NN", "VVFIN", "PRF", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und f\u00fchlen keine Schmach.", "tokens": ["und", "f\u00fch\u00b7len", "kei\u00b7ne", "Schmach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und andre treten auf die Menschenstirnen", "tokens": ["Und", "and\u00b7re", "tre\u00b7ten", "auf", "die", "Men\u00b7schens\u00b7tir\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und f\u00fchlen keine Scham.", "tokens": ["und", "f\u00fch\u00b7len", "kei\u00b7ne", "Scham", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sieh dieses Volk zu deinen F\u00fcssen winseln,", "tokens": ["Sieh", "die\u00b7ses", "Volk", "zu", "dei\u00b7nen", "F\u00fcs\u00b7sen", "win\u00b7seln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "das nur nach neuen G\u00f6tzen noch verlangt,", "tokens": ["das", "nur", "nach", "neu\u00b7en", "G\u00f6t\u00b7zen", "noch", "ver\u00b7langt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und frage nicht!", "tokens": ["und", "fra\u00b7ge", "nicht", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.15": {"line.1": {"text": "Prometheus schweigt und sinnt.", "tokens": ["Pro\u00b7me\u00b7theus", "schweigt", "und", "sinnt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Dann heftet er des Auges Glanz", "tokens": ["Dann", "hef\u00b7tet", "er", "des", "Au\u00b7ges", "Glanz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auf diese, die da aufrecht vor ihm stehn,", "tokens": ["auf", "die\u00b7se", ",", "die", "da", "auf\u00b7recht", "vor", "ihm", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "$,", "PRELS", "ADV", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und langsam rollen seine Worte:", "tokens": ["und", "lang\u00b7sam", "rol\u00b7len", "sei\u00b7ne", "Wor\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "\u2013 Geschaffen hab ich Menschen.", "tokens": ["\u2013", "Ge\u00b7schaf\u00b7fen", "hab", "ich", "Men\u00b7schen", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VAFIN", "PPER", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Gross war das Werk, und Stolz f\u00fcllt meine Brust,", "tokens": ["Gross", "war", "das", "Werk", ",", "und", "Stolz", "f\u00fcllt", "mei\u00b7ne", "Brust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$,", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "seh ich auf euch, auf meine echten S\u00f6hne.", "tokens": ["seh", "ich", "auf", "euch", ",", "auf", "mei\u00b7ne", "ech\u00b7ten", "S\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Doch nicht umsonst war ich gefesselt!", "tokens": ["Doch", "nicht", "um\u00b7sonst", "war", "ich", "ge\u00b7fes\u00b7selt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weit Gr\u00f6ssres wahrlich gilts noch zu vollenden:", "tokens": ["Weit", "Gr\u00f6ss\u00b7res", "wahr\u00b7lich", "gilts", "noch", "zu", "voll\u00b7en\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADV", "VVFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Funke muss zur Flamme werden!", "tokens": ["Der", "Fun\u00b7ke", "muss", "zur", "Flam\u00b7me", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Da zuckt erhabner Freude lichte Gluth", "tokens": ["Da", "zuckt", "er\u00b7hab\u00b7ner", "Freu\u00b7de", "lich\u00b7te", "Gluth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "auf jenen d\u00fcstren Stirnen auf.", "tokens": ["auf", "je\u00b7nen", "d\u00fcst\u00b7ren", "Stir\u00b7nen", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sie jauchzen:", "tokens": ["Sie", "jauch\u00b7zen", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "\u2013 ", "tokens": ["\u2013"], "token_info": ["punct"], "pos": ["$("]}}}}}