{"textgrid.poem.49762": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Breslauer Festspiel", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Viele gramerf\u00fcllte Spie\u00dfer,", "tokens": ["Vie\u00b7le", "gra\u00b7mer\u00b7f\u00fcll\u00b7te", "Spie\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zentenare Kannengie\u00dfer", "tokens": ["Zen\u00b7te\u00b7na\u00b7re", "Kan\u00b7nen\u00b7gie\u00b7\u00dfer"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fanden jetzt als Festgenie\u00dfer,", "tokens": ["Fan\u00b7den", "jetzt", "als", "Fest\u00b7ge\u00b7nie\u00b7\u00dfer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOUS", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df der hohe Weiheakt", "tokens": ["Da\u00df", "der", "ho\u00b7he", "Wei\u00b7he\u00b7akt"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie zu wenig seelisch packt.", "tokens": ["Sie", "zu", "we\u00b7nig", "see\u00b7lisch", "packt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Kein Gebet nicht vor den Schlachten,", "tokens": ["Kein", "Ge\u00b7bet", "nicht", "vor", "den", "Schlach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKNEG", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Trommeln, die Spektakel machten,", "tokens": ["Trom\u00b7meln", ",", "die", "Spek\u00b7ta\u00b7kel", "mach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Keine Flinten nicht, die krachten,", "tokens": ["Kei\u00b7ne", "Flin\u00b7ten", "nicht", ",", "die", "krach\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKNEG", "$,", "PRELS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "\u00dcberhaupt kein Heldentum!", "tokens": ["\u00dc\u00b7ber\u00b7haupt", "kein", "Hel\u00b7den\u00b7tum", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Piff und paff! und bum! bum! bum!", "tokens": ["Piff", "und", "paff", "!", "und", "bum", "!", "bum", "!", "bum", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "$.", "KON", "XY", "$.", "XY", "$.", "XY", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo blieb K\u00f6nigin Lawise?", "tokens": ["Wo", "blieb", "K\u00f6\u00b7ni\u00b7gin", "La\u00b7wi\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War es richtig, da\u00df man diese", "tokens": ["War", "es", "rich\u00b7tig", ",", "da\u00df", "man", "die\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "KOUS", "PIS", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nicht noch ganz besonders priese?", "tokens": ["Nicht", "noch", "ganz", "be\u00b7son\u00b7ders", "prie\u00b7se", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als den guten Chenius,", "tokens": ["Als", "den", "gu\u00b7ten", "Che\u00b7ni\u00b7us", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der f\u00fcr allens helfen mu\u00df?", "tokens": ["Der", "f\u00fcr", "al\u00b7lens", "hel\u00b7fen", "mu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und dann kam auch viel zu wenig", "tokens": ["Und", "dann", "kam", "auch", "viel", "zu", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "ADV", "PTKA", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Friedrich Willem als ein K\u00f6nig,", "tokens": ["Fried\u00b7rich", "Wil\u00b7lem", "als", "ein", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KOUS", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der doch selbsten h\u00f6chstpers\u00f6nig", "tokens": ["Der", "doch", "selbs\u00b7ten", "h\u00f6chst\u00b7per\u00b7s\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und mit edlem Zeugungstrieb", "tokens": ["Und", "mit", "ed\u00b7lem", "Zeu\u00b7gungs\u00b7trieb"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "\u00bban mein Volk\u00ab den Aufruf schrieb!", "tokens": ["\u00bb", "an", "mein", "Volk", "\u00ab", "den", "Auf\u00b7ruf", "schrieb", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$(", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00dcberhaupt kein Schlachtgemenge,", "tokens": ["\u00dc\u00b7ber\u00b7haupt", "kein", "Schlacht\u00b7ge\u00b7men\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kein Hurra und Ro\u00dfgesprenge,", "tokens": ["Kein", "Hur\u00b7ra", "und", "Ro\u00df\u00b7ge\u00b7spren\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zapfenstreich und schneddredenge!", "tokens": ["Zap\u00b7fen\u00b7streich", "und", "schned\u00b7dre\u00b7den\u00b7ge", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sag' mir, Hauptmann, guter Mensch,", "tokens": ["Sag'", "mir", ",", "Haupt\u00b7mann", ",", "gu\u00b7ter", "Mensch", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist das auch noch vaterl\u00e4nd'sch?", "tokens": ["Ist", "das", "auch", "noch", "va\u00b7ter\u00b7l\u00e4n\u00b7d'sch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}}}}