{"textgrid.poem.34335": {"metadata": {"author": {"name": "Lenz, Jakob Michael Reinhold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Schulmeister bin, Matz H\u00f6cker genannt,", "genre": "verse", "period": "N.A.", "pub_year": 1775, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Schulmeister bin, Matz H\u00f6cker genannt,", "tokens": ["Ein", "Schul\u00b7meis\u00b7ter", "bin", ",", "Matz", "H\u00f6\u00b7cker", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "NE", "NE", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Bin flei\u00dfig gewesen, ist Gott bekannt,", "tokens": ["Bin", "flei\u00b7\u00dfig", "ge\u00b7we\u00b7sen", ",", "ist", "Gott", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VAPP", "$,", "VAFIN", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Drum darf, Gottlob! mich jezund nicht entbl\u00f6den,", "tokens": ["Drum", "darf", ",", "Gott\u00b7lob", "!", "mich", "je\u00b7zund", "nicht", "ent\u00b7bl\u00f6\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "$,", "NN", "$.", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit meiner gn\u00e4digen Herrschaft zu reden.", "tokens": ["Mit", "mei\u00b7ner", "gn\u00e4\u00b7di\u00b7gen", "Herr\u00b7schaft", "zu", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Herr K ... hat solches angestellt,", "tokens": ["Herr", "K", "...", "hat", "sol\u00b7ches", "an\u00b7ge\u00b7stellt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Nuz und Frommen der teutschen Welt,", "tokens": ["Zu", "Nuz", "und", "From\u00b7men", "der", "teut\u00b7schen", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und weil mei'm Nebenmenschen allzeit gerne diene,", "tokens": ["Und", "weil", "mei'm", "Ne\u00b7ben\u00b7men\u00b7schen", "all\u00b7zeit", "ger\u00b7ne", "die\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "ADV", "ADV", "PDS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Warum nit auch hierinn, Herr K ... Ihne?", "tokens": ["Wa\u00b7rum", "nit", "auch", "hie\u00b7rinn", ",", "Herr", "K", "...", "Ih\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ADV", "ADV", "$,", "NN", "NE", "$(", "PPER", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Also denn, gn\u00e4dige Frauen verzeihn,", "tokens": ["Al\u00b7so", "denn", ",", "gn\u00e4\u00b7di\u00b7ge", "Frau\u00b7en", "ver\u00b7zeihn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADJA", "NN", "VVINF", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "(die Herrn schliesse hier mit ein,", "tokens": ["(", "die", "Herrn", "schlies\u00b7se", "hier", "mit", "ein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie es die Mode thut mit sich f\u00fchren,)", "tokens": ["Wie", "es", "die", "Mo\u00b7de", "thut", "mit", "sich", "f\u00fch\u00b7ren", ",", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "APPR", "PRF", "VVINF", "$,", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wenn mich verfehle im deklamiren,", "tokens": ["Wenn", "mich", "ver\u00b7feh\u00b7le", "im", "de\u00b7kla\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPRART", "VVINF", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Und anbei noch was sch\u00fcchtern thu,", "tokens": ["Und", "an\u00b7bei", "noch", "was", "sch\u00fcch\u00b7tern", "thu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wegen meiner zerri\u00dfnen Schuh.", "tokens": ["We\u00b7gen", "mei\u00b7ner", "zer\u00b7ri\u00df\u00b7nen", "Schuh", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "Und nit viel Capriolen darf schneiden,", "tokens": ["Und", "nit", "viel", "Cap\u00b7ri\u00b7o\u00b7len", "darf", "schnei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Weil meine Finanzen es nit wohl leiden,", "tokens": ["Weil", "mei\u00b7ne", "Fi\u00b7nan\u00b7zen", "es", "nit", "wohl", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Wie der Philosophus Socrates that,", "tokens": ["Wie", "der", "Phi\u00b7lo\u00b7so\u00b7phus", "So\u00b7cra\u00b7tes", "that", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Als er gedanzt beim Kallias hat.", "tokens": ["Als", "er", "ge\u00b7danzt", "beim", "Kal\u00b7li\u00b7as", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Ich wei\u00df zwar wohl viele Junggesellen,", "tokens": ["Ich", "wei\u00df", "zwar", "wohl", "vie\u00b7le", "Jung\u00b7ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die heut zu Tag sich als Schulmeister stellen,", "tokens": ["Die", "heut", "zu", "Tag", "sich", "als", "Schul\u00b7meis\u00b7ter", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "PRF", "KOUS", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Weil's meinen, in dem schwarzen Habit", "tokens": ["Weil's", "mei\u00b7nen", ",", "in", "dem", "schwar\u00b7zen", "Ha\u00b7bit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Menschenkind ihre Pferdsf\u00fc\u00df sieht,", "tokens": ["Kein", "Men\u00b7schen\u00b7kind", "ih\u00b7re", "Pferds\u00b7f\u00fc\u00df", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und d\u00fcrften sagen unbescholten,", "tokens": ["Und", "d\u00fcrf\u00b7ten", "sa\u00b7gen", "un\u00b7be\u00b7schol\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vom Lehr- Nehr- Wehrstand was sie wollten", "tokens": ["Vom", "Lehr", "Nehr", "Wehr\u00b7stand", "was", "sie", "woll\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "TRUNC", "TRUNC", "NN", "PWS", "PPER", "VMFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "\u1fbd\u03b5\u03bd \u03c0\u03b1\u03c1\u03bf\u03b4\u03c9 so denk ich nicht,", "tokens": ["\u1fbd\u03b5\u03bd", "\u03c0\u03b1\u03c1\u03bf\u03b4\u03c9", "so", "denk", "ich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADV", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Kommt alles doch zulezt ans Licht,", "tokens": ["Kommt", "al\u00b7les", "doch", "zu\u00b7lezt", "ans", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und werden am End doch m\u00fcssen b\u00fcssen,", "tokens": ["Und", "wer\u00b7den", "am", "End", "doch", "m\u00fcs\u00b7sen", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Alle die Herren mit den Pferdef\u00fcssen.", "tokens": ["Al\u00b7le", "die", "Her\u00b7ren", "mit", "den", "Pfer\u00b7de\u00b7f\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.5": {"line.1": {"text": "Bin auch in s' manchen St\u00e4dten gewesen,", "tokens": ["Bin", "auch", "in", "s'", "man\u00b7chen", "St\u00e4d\u00b7ten", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NE", "PIAT", "NN", "VAPP", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Hab alt und junge B\u00fccher gelesen,", "tokens": ["Hab", "alt", "und", "jun\u00b7ge", "B\u00fc\u00b7cher", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Hab alles g'sehen und alles geh\u00f6rt,", "tokens": ["Hab", "al\u00b7les", "g'\u00b7se\u00b7hen", "und", "al\u00b7les", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADJA", "KON", "PIS", "VVFIN", "$,"], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Bin jezo verst\u00e4ndig und gelehrt.", "tokens": ["Bin", "je\u00b7zo", "ver\u00b7st\u00e4n\u00b7dig", "und", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "KON", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Will also gn\u00e4digen Frauen es wagen", "tokens": ["Will", "al\u00b7so", "gn\u00e4\u00b7di\u00b7gen", "Frau\u00b7en", "es", "wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADJA", "NN", "PPER", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Meine Betrachtungen vorzutragen,", "tokens": ["Mei\u00b7ne", "Be\u00b7trach\u00b7tun\u00b7gen", "vor\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVIZU", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.7": {"text": "Mit treuem Herzen und frohem Muth,", "tokens": ["Mit", "treu\u00b7em", "Her\u00b7zen", "und", "fro\u00b7hem", "Muth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Da\u00df es der Welt n\u00fczen thut.", "tokens": ["Da\u00df", "es", "der", "Welt", "n\u00fc\u00b7zen", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.6": {"line.1": {"text": "D' B\u00fccher nu 'nd die Gesellschaften heuer", "tokens": ["D'", "B\u00fc\u00b7cher", "nu", "'nd", "die", "Ge\u00b7sell\u00b7schaf\u00b7ten", "heu\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "NN", "ADV", "ADJD", "ART", "NN", "ADV"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.2": {"text": "Sind oder gar schlecht oder gar theuer;", "tokens": ["Sind", "o\u00b7der", "gar", "schlecht", "o\u00b7der", "gar", "theu\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "ADV", "ADJD", "KON", "ADV", "ADJD", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Bin hie und da doch rumgekommen,", "tokens": ["Bin", "hie", "und", "da", "doch", "rum\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "KON", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Habs aller Orten so vernommen.", "tokens": ["Habs", "al\u00b7ler", "Or\u00b7ten", "so", "ver\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Nachdruck und die Bulerei'n,", "tokens": ["Der", "Nach\u00b7druck", "und", "die", "Bu\u00b7le\u00b7rei'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sagt man, die sollen Schuld dran sein;", "tokens": ["Sagt", "man", ",", "die", "sol\u00b7len", "Schuld", "dran", "sein", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PRELS", "PIAT", "NN", "PAV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und weilen die B\u00fccher doch s' Oel sollen geben", "tokens": ["Und", "wei\u00b7len", "die", "B\u00fc\u00b7cher", "doch", "s'", "O\u00b7el", "sol\u00b7len", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "NE", "NN", "VMFIN", "VVINF"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Zur Gesellschaft und b\u00fcrgerlichem Leben,", "tokens": ["Zur", "Ge\u00b7sell\u00b7schaft", "und", "b\u00fcr\u00b7ger\u00b7li\u00b7chem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.9": {"text": "Meint ich, die hohe Obrigkeit", "tokens": ["Meint", "ich", ",", "die", "ho\u00b7he", "Ob\u00b7rig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Steurte der Landplag zur rechter Zeit,", "tokens": ["Steur\u00b7te", "der", "Land\u00b7plag", "zur", "rech\u00b7ter", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$,"], "meter": "+--++-+-+", "measure": "dactylic.init"}, "line.11": {"text": "Sonst die Gelehrten, die recht studieren,", "tokens": ["Sonst", "die", "Ge\u00b7lehr\u00b7ten", ",", "die", "recht", "stu\u00b7die\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.12": {"text": "Alle m\u00fcssen Hungers krepiren.", "tokens": ["Al\u00b7le", "m\u00fcs\u00b7sen", "Hun\u00b7gers", "kre\u00b7pi\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Hab auch B\u00fccher ohn' Ende gesehn,", "tokens": ["Hab", "auch", "B\u00fc\u00b7cher", "ohn'", "En\u00b7de", "ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Alle gedruckt und gestochen sch\u00f6n,", "tokens": ["Al\u00b7le", "ge\u00b7druckt", "und", "ge\u00b7sto\u00b7chen", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "KON", "ADJA", "ADJD", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "S\u00fcsser W\u00f6rter und Strich' die Menge,", "tokens": ["S\u00fcs\u00b7ser", "W\u00f6r\u00b7ter", "und", "Strich'", "die", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Brachten mir allen Verstand ins Gedr\u00e4nge,", "tokens": ["Brach\u00b7ten", "mir", "al\u00b7len", "Ver\u00b7stand", "ins", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.5": {"text": "Da\u00df ich am Ende, wie 'ne W \u2013 laus", "tokens": ["Da\u00df", "ich", "am", "En\u00b7de", ",", "wie", "'ne", "W", "\u2013", "laus"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "$,", "PWAV", "ART", "NE", "$(", "XY"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Gar nit w\u00fc\u00dfte ein oder aus.", "tokens": ["Gar", "nit", "w\u00fc\u00df\u00b7te", "ein", "o\u00b7der", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVFIN", "ART", "KON", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.7": {"text": "Habe des Specks so viel gefressen,", "tokens": ["Ha\u00b7be", "des", "Specks", "so", "viel", "ge\u00b7fres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Verlohr allen App'tit zum Essen,", "tokens": ["Ver\u00b7lohr", "al\u00b7len", "Ap\u00b7p'\u00b7tit", "zum", "Es\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Dankte Gott und meinem Bart,", "tokens": ["Dank\u00b7te", "Gott", "und", "mei\u00b7nem", "Bart", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Da\u00df ich im Dorf Schulmeister ward.", "tokens": ["Da\u00df", "ich", "im", "Dorf", "Schul\u00b7meis\u00b7ter", "ward", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Hab auch an ei'm gewissen Ort konditschonirt", "tokens": ["Hab", "auch", "an", "ei'm", "ge\u00b7wis\u00b7sen", "Ort", "kon\u00b7ditsc\u00b7ho\u00b7nirt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "ART", "ADJA", "NN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "'n f\u00fcrnehmen H\u00e4usern konversirt,", "tokens": ["'n", "f\u00fcr\u00b7neh\u00b7men", "H\u00e4u\u00b7sern", "kon\u00b7ver\u00b7sirt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.13": {"text": "Fund die Konversationen doch", "tokens": ["Fund", "die", "Kon\u00b7ver\u00b7sa\u00b7ti\u00b7o\u00b7nen", "doch"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "Schlimmer als die B\u00fccher noch.", "tokens": ["Schlim\u00b7mer", "als", "die", "B\u00fc\u00b7cher", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "All im d\u00e4mmernden Wirrwarr schweben", "tokens": ["All", "im", "d\u00e4m\u00b7mern\u00b7den", "Wirr\u00b7warr", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPRART", "ADJA", "NN", "VVINF"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.16": {"text": "Und im Zweifel \u00fcber Tod und Leben;", "tokens": ["Und", "im", "Zwei\u00b7fel", "\u00fc\u00b7ber", "Tod", "und", "Le\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Trauten unserm Herrngott gar", "tokens": ["Trau\u00b7ten", "un\u00b7serm", "Herrn\u00b7gott", "gar"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.18": {"text": "Nicht mehr zu ein einzig gut Haar.", "tokens": ["Nicht", "mehr", "zu", "ein", "ein\u00b7zig", "gut", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ART", "ADJD", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Liessen in einer halben Sekunde", "tokens": ["Lies\u00b7sen", "in", "ei\u00b7ner", "hal\u00b7ben", "Se\u00b7kun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.20": {"text": "Vierzigtausend Widerspr\u00fcch' aus ihrem Munde,", "tokens": ["Vier\u00b7zig\u00b7tau\u00b7send", "Wi\u00b7der\u00b7spr\u00fcch'", "aus", "ih\u00b7rem", "Mun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.21": {"text": "Hatten weder Freund noch Feind,", "tokens": ["Hat\u00b7ten", "we\u00b7der", "Freund", "noch", "Feind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KON", "NN", "ADV", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Weil's nimmer wissen, woran sie seind.", "tokens": ["Weil's", "nim\u00b7mer", "wis\u00b7sen", ",", "wo\u00b7ran", "sie", "seind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVINF", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Schauten an ihre Nebenchristen,", "tokens": ["Schau\u00b7ten", "an", "ih\u00b7re", "Ne\u00b7benc\u00b7hris\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.24": {"text": "Wie die Akturen die Staatisten,", "tokens": ["Wie", "die", "Ak\u00b7tu\u00b7ren", "die", "Staa\u00b7tis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "++-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.25": {"text": "Denkt keiner an den andern nicht,", "tokens": ["Denkt", "kei\u00b7ner", "an", "den", "an\u00b7dern", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "ADJA", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Denkt nur immer an das, was er spricht,", "tokens": ["Denkt", "nur", "im\u00b7mer", "an", "das", ",", "was", "er", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.27": {"text": "Sucht den andern durch L\u00e4cheln und L\u00fcgen", "tokens": ["Sucht", "den", "an\u00b7dern", "durch", "L\u00e4\u00b7cheln", "und", "L\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "APPR", "NN", "KON", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.28": {"text": "Wieder um L\u00fcgen und L\u00e4cheln zu betr\u00fcgen.", "tokens": ["Wie\u00b7der", "um", "L\u00fc\u00b7gen", "und", "L\u00e4\u00b7cheln", "zu", "be\u00b7tr\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Meint jeder, er sei der Mann allein,", "tokens": ["Meint", "je\u00b7der", ",", "er", "sei", "der", "Mann", "al\u00b7lein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PPER", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Des andern Hirn sei von Holz oder Stein,", "tokens": ["Des", "an\u00b7dern", "Hirn", "sei", "von", "Holz", "o\u00b7der", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Und seine Faulheit mehr Nuzen br\u00e4chte,", "tokens": ["Und", "sei\u00b7ne", "Faul\u00b7heit", "mehr", "Nu\u00b7zen", "br\u00e4ch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Als des andern sein schlaflose N\u00e4chte.", "tokens": ["Als", "des", "an\u00b7dern", "sein", "schlaf\u00b7lo\u00b7se", "N\u00e4ch\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "PPOSAT", "ADJA", "NN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}}, "stanza.8": {"line.1": {"text": "Nun denk ich wohl oft, wie wohl ist mir", "tokens": ["Nun", "denk", "ich", "wohl", "oft", ",", "wie", "wohl", "ist", "mir"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$,", "PWAV", "ADV", "VAFIN", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Doch jezt in meinem Dorfe daf\u00fcr.", "tokens": ["Doch", "jezt", "in", "mei\u00b7nem", "Dor\u00b7fe", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "PAV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "K\u00e4men nur nit manche faule M\u00e4hren,", "tokens": ["K\u00e4\u00b7men", "nur", "nit", "man\u00b7che", "fau\u00b7le", "M\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Mir meine B\u00e4uerlein auch 'fzukl\u00e4ren", "tokens": ["Mir", "mei\u00b7ne", "B\u00e4u\u00b7er\u00b7lein", "auch", "'f\u00b7zu\u00b7kl\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Und einzublattern ihnen Wind,", "tokens": ["Und", "ein\u00b7zu\u00b7blat\u00b7tern", "ih\u00b7nen", "Wind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dass gleich mit allem fertig sind,", "tokens": ["Dass", "gleich", "mit", "al\u00b7lem", "fer\u00b7tig", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PIS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Gott und Menschen lernen verachten,", "tokens": ["Und", "Gott", "und", "Men\u00b7schen", "ler\u00b7nen", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Dr\u00fcber mit Leib und Seele verschmachten.", "tokens": ["Dr\u00fc\u00b7ber", "mit", "Leib", "und", "See\u00b7le", "ver\u00b7schmach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Ach, gn\u00e4dige Herren, gro\u00df und klein,", "tokens": ["Ach", ",", "gn\u00e4\u00b7di\u00b7ge", "Her\u00b7ren", ",", "gro\u00df", "und", "klein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Bitte, w\u00f6llet uns lassen allein,", "tokens": ["Bit\u00b7te", ",", "w\u00f6l\u00b7let", "uns", "las\u00b7sen", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.11": {"text": "Uns verspotten nach Herzens Begehren,", "tokens": ["Uns", "ver\u00b7spot\u00b7ten", "nach", "Her\u00b7zens", "Be\u00b7geh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.12": {"text": "Nur unsre Leutlein nit sp\u00f6tteln lehren.", "tokens": ["Nur", "uns\u00b7re", "Leut\u00b7lein", "nit", "sp\u00f6t\u00b7teln", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKNEG", "VVINF", "VVINF", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Raumt aus bei euch so viel ihr wollt,", "tokens": ["Raumt", "aus", "bei", "euch", "so", "viel", "ihr", "wollt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "APPR", "PPER", "ADV", "ADV", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "All euern Mist und all euer Gold,", "tokens": ["All", "eu\u00b7ern", "Mist", "und", "all", "eu\u00b7er", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PPOSAT", "NN", "KON", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.15": {"text": "Treu, Redlichkeit und Aberglauben,", "tokens": ["Treu", ",", "Red\u00b7lich\u00b7keit", "und", "A\u00b7berg\u00b7lau\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Wollen euch gern die Vernunft erlauben,", "tokens": ["Wol\u00b7len", "euch", "gern", "die", "Ver\u00b7nunft", "er\u00b7lau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Euch respektiren hoch und sehr.", "tokens": ["Euch", "res\u00b7pek\u00b7ti\u00b7ren", "hoch", "und", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.18": {"text": "Gn\u00e4dige Herren, was wollt ihr mehr?", "tokens": ["Gn\u00e4\u00b7di\u00b7ge", "Her\u00b7ren", ",", "was", "wollt", "ihr", "mehr", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWS", "VMFIN", "PPER", "ADV", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "D\u00fcrft ich euch aber, um vergn\u00fcgter zu leben,", "tokens": ["D\u00fcrft", "ich", "euch", "a\u00b7ber", ",", "um", "ver\u00b7gn\u00fcg\u00b7ter", "zu", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$,", "KOUI", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "++-+-+-+--+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "In aller Unterth\u00e4nigkeit einen Rath doch geben,", "tokens": ["In", "al\u00b7ler", "Un\u00b7ter\u00b7th\u00e4\u00b7nig\u00b7keit", "ei\u00b7nen", "Rath", "doch", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Bindt euch mit mehr Menschen an,", "tokens": ["Bindt", "euch", "mit", "mehr", "Men\u00b7schen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PIAT", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jeder vom andern lernen kann.", "tokens": ["Je\u00b7der", "vom", "an\u00b7dern", "ler\u00b7nen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gott allein die Bekehrung g'h\u00f6ret,", "tokens": ["Gott", "al\u00b7lein", "die", "Be\u00b7keh\u00b7rung", "g'\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Ein Mensch den andern zum Teufel bekehret.", "tokens": ["Ein", "Mensch", "den", "an\u00b7dern", "zum", "Teu\u00b7fel", "be\u00b7keh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Gott woll' mir verzeihen die S\u00fcnd,", "tokens": ["Gott", "woll'", "mir", "ver\u00b7zei\u00b7hen", "die", "S\u00fcnd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Konnte kein ander Wort finden geschwind.", "tokens": ["Konn\u00b7te", "kein", "an\u00b7der", "Wort", "fin\u00b7den", "ge\u00b7schwind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJD", "NN", "VVINF", "VVPP", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.9": {"text": "H\u00e4tt' ich viel Geld zusammen geschrieben,", "tokens": ["H\u00e4tt'", "ich", "viel", "Geld", "zu\u00b7sam\u00b7men", "ge\u00b7schrie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Gieng ich aufs Dorf, ein Maidel zu lieben,", "tokens": ["Gieng", "ich", "aufs", "Dorf", ",", "ein", "Mai\u00b7del", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Weil man eure gr\u00fcnen Augen in der Stadt", "tokens": ["Weil", "man", "eu\u00b7re", "gr\u00fc\u00b7nen", "Au\u00b7gen", "in", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPOSAT", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.12": {"text": "Und Wallnu\u00dfgesichter doch nicht gern hat.", "tokens": ["Und", "Wall\u00b7nu\u00df\u00b7ge\u00b7sich\u00b7ter", "doch", "nicht", "gern", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "PTKNEG", "ADV", "VAFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Und w\u00e4r ich ein altes Maidel geblieben,", "tokens": ["Und", "w\u00e4r", "ich", "ein", "al\u00b7tes", "Mai\u00b7del", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Gieng ich aufs Dorf, einen Schulbuben lieben,", "tokens": ["Gieng", "ich", "aufs", "Dorf", ",", "ei\u00b7nen", "Schul\u00b7bu\u00b7ben", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--++-+-", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Kauft ihm Kleider und N\u00e4scherei'n,", "tokens": ["Kauft", "ihm", "Klei\u00b7der", "und", "N\u00e4\u00b7sche\u00b7rei'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.16": {"text": "W\u00fcrde gewi\u00df erkanntlich sein;", "tokens": ["W\u00fcr\u00b7de", "ge\u00b7wi\u00df", "er\u00b7kannt\u00b7lich", "sein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.17": {"text": "Liesse die Gecken dar\u00fcber lachen,", "tokens": ["Lies\u00b7se", "die", "Ge\u00b7cken", "da\u00b7r\u00fc\u00b7ber", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PAV", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.18": {"text": "Die sonst nixs g'scheiders wissen zu machen,", "tokens": ["Die", "sonst", "nixs", "g'\u00b7schei\u00b7ders", "wis\u00b7sen", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.19": {"text": "Und sich kultiviren krumm und blind,", "tokens": ["Und", "sich", "kul\u00b7ti\u00b7vi\u00b7ren", "krumm", "und", "blind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "Bis sie selbst zum Gel\u00e4chter sind.", "tokens": ["Bis", "sie", "selbst", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN", "VAFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.21": {"text": "Hier die Romanen, und all Gottesgaben", "tokens": ["Hier", "die", "Ro\u00b7ma\u00b7nen", ",", "und", "all", "Got\u00b7tes\u00b7ga\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Ihren wahren Grund doch haben;", "tokens": ["Ih\u00b7ren", "wah\u00b7ren", "Grund", "doch", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.23": {"text": "Und ihr rezensirt doch stets wie'n Huhn,", "tokens": ["Und", "ihr", "re\u00b7zen\u00b7sirt", "doch", "stets", "wie'n", "Huhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.24": {"text": "Wenn selbst nit w\u00f6llet erfahren thun.", "tokens": ["Wenn", "selbst", "nit", "w\u00f6l\u00b7let", "er\u00b7fah\u00b7ren", "thun", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKNEG", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Hier d' Metaphysik und die Dogmatik,", "tokens": ["Hier", "d'", "Me\u00b7ta\u00b7phy\u00b7sik", "und", "die", "Dog\u00b7ma\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "KON", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.26": {"text": "Und die Moral, die Aesthetik und Statik,", "tokens": ["Und", "die", "Mo\u00b7ral", ",", "die", "A\u00b7e\u00b7sthe\u00b7tik", "und", "Sta\u00b7tik", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "NN", "KON", "NN", "$,"], "meter": "---+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Aller Theorie Betrug", "tokens": ["Al\u00b7ler", "The\u00b7o\u00b7rie", "Be\u00b7trug"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.28": {"text": "Finden mu\u00df aufzubeissen genug.", "tokens": ["Fin\u00b7den", "mu\u00df", "auf\u00b7zu\u00b7beis\u00b7sen", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "ADV", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.29": {"text": "Hier w\u00fcrd' euch der K\u00fctzel vergehen,", "tokens": ["Hier", "w\u00fcrd'", "euch", "der", "K\u00fct\u00b7zel", "ver\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.30": {"text": "Da\u00df ihr best\u00e4ndig was neues wollt sehen,", "tokens": ["Da\u00df", "ihr", "be\u00b7st\u00e4n\u00b7dig", "was", "neu\u00b7es", "wollt", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PWS", "ADJA", "VMFIN", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Immer wie Wickelkindelein", "tokens": ["Im\u00b7mer", "wie", "Wi\u00b7ckel\u00b7kin\u00b7de\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "KOKOM", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.32": {"text": "Ueberrumpelt und eingel\u00fcllt sein,", "tokens": ["Ue\u00b7ber\u00b7rum\u00b7pelt", "und", "ein\u00b7ge\u00b7l\u00fcllt", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VAINF", "$,"], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.33": {"text": "Immer an Licht und Schimmer euch weiden,", "tokens": ["Im\u00b7mer", "an", "Licht", "und", "Schim\u00b7mer", "euch", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "PPER", "VVINF", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.34": {"text": "Gar keinen Schatten dazwischen mehr leiden,", "tokens": ["Gar", "kei\u00b7nen", "Schat\u00b7ten", "da\u00b7zwi\u00b7schen", "mehr", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PAV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Allzeit leben im s\u00fcssen Traum,", "tokens": ["All\u00b7zeit", "le\u00b7ben", "im", "s\u00fcs\u00b7sen", "Traum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Keinem Gef\u00fchl lassen Zeit und Raum.", "tokens": ["Kei\u00b7nem", "Ge\u00b7f\u00fchl", "las\u00b7sen", "Zeit", "und", "Raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "NN", "KON", "NN", "$."], "meter": "+-----+-+", "measure": "dactylic.init"}, "line.37": {"text": "Ach, so machtens nit unsre Vorfahren,", "tokens": ["Ach", ",", "so", "mach\u00b7tens", "nit", "uns\u00b7re", "Vor\u00b7fah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADV", "PTKNEG", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.38": {"text": "Die schwer zu k\u00fczeln und gl\u00fccklicher waren,", "tokens": ["Die", "schwer", "zu", "k\u00fc\u00b7zeln", "und", "gl\u00fcck\u00b7li\u00b7cher", "wa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PTKZU", "VVINF", "KON", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "Aber auch nicht im h\u00f6chsten Gl\u00fcck", "tokens": ["A\u00b7ber", "auch", "nicht", "im", "h\u00f6chs\u00b7ten", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "APPRART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.40": {"text": "Nahmen ihr butterweich Herze zur\u00fcck.", "tokens": ["Nah\u00b7men", "ihr", "but\u00b7ter\u00b7weich", "Her\u00b7ze", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "VVFIN", "PTKVZ", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.41": {"text": "Liessen alles seine Zeit dauren,", "tokens": ["Lies\u00b7sen", "al\u00b7les", "sei\u00b7ne", "Zeit", "dau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.42": {"text": "Wu\u00dften zu lachen, und wu\u00dften zu trauren,", "tokens": ["Wu\u00df\u00b7ten", "zu", "la\u00b7chen", ",", "und", "wu\u00df\u00b7ten", "zu", "trau\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$,", "KON", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.43": {"text": "Liebten ewig, ha\u00dften schwer,", "tokens": ["Lieb\u00b7ten", "e\u00b7wig", ",", "ha\u00df\u00b7ten", "schwer", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.44": {"text": "Hatten das Herz nie d\u00fcrftig und leer.", "tokens": ["Hat\u00b7ten", "das", "Herz", "nie", "d\u00fcrf\u00b7tig", "und", "leer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Hier findt ihr auch noch W\u00f6rter regieren.", "tokens": ["Hier", "findt", "ihr", "auch", "noch", "W\u00f6r\u00b7ter", "re\u00b7gie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die ihr l\u00e4ngst th\u00e4tet verbannisiren,", "tokens": ["Die", "ihr", "l\u00e4ngst", "th\u00e4\u00b7tet", "ver\u00b7ban\u00b7ni\u00b7si\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und euern Umgang gemacht so arm,", "tokens": ["Und", "eu\u00b7ern", "Um\u00b7gang", "ge\u00b7macht", "so", "arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie eine Dorfgeig' mit einem Darm.", "tokens": ["Wie", "ei\u00b7ne", "Dorf\u00b7geig'", "mit", "ei\u00b7nem", "Darm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Hier nimmt der Leib und seine Glieder", "tokens": ["Hier", "nimmt", "der", "Leib", "und", "sei\u00b7ne", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sein' alten freiherrlichen Rechte wieder.", "tokens": ["Sein'", "al\u00b7ten", "frei\u00b7herr\u00b7li\u00b7chen", "Rech\u00b7te", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "ADV", "$."], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Hier ist unserer Dirnen Brust", "tokens": ["Hier", "ist", "un\u00b7se\u00b7rer", "Dir\u00b7nen", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "NN"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.8": {"text": "Noch der Augen und Ohren Lust.", "tokens": ["Noch", "der", "Au\u00b7gen", "und", "Oh\u00b7ren", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NN", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Hier steht man ohne Respekt auf den F\u00fcssen,", "tokens": ["Hier", "steht", "man", "oh\u00b7ne", "Res\u00b7pekt", "auf", "den", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Darf Nahrung und Kleid nit verbr\u00e4men, vers\u00fcssen,", "tokens": ["Darf", "Nah\u00b7rung", "und", "Kleid", "nit", "ver\u00b7br\u00e4\u00b7men", ",", "ver\u00b7s\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VMFIN", "NN", "KON", "NN", "PTKNEG", "VVINF", "$,", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.11": {"text": "R\u00fccket den Strohhut \u00fcber das Ohr,", "tokens": ["R\u00fc\u00b7cket", "den", "Stroh\u00b7hut", "\u00fc\u00b7ber", "das", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "Als ein Biedermann herzhaft hervor,", "tokens": ["Als", "ein", "Bie\u00b7der\u00b7mann", "herz\u00b7haft", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.13": {"text": "Denkt nit an die verwandten Ideen,", "tokens": ["Denkt", "nit", "an", "die", "ver\u00b7wand\u00b7ten", "I\u00b7deen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.14": {"text": "Darf dem Schelm auf d' Per\u00fcke sehen.", "tokens": ["Darf", "dem", "Schelm", "auf", "d'", "Pe\u00b7r\u00fc\u00b7ke", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "APPR", "NE", "NE", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Hier ists nit wie in euern Gassen,", "tokens": ["Hier", "ists", "nit", "wie", "in", "eu\u00b7ern", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "KOKOM", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo nichts wird gethan, noch gelassen,", "tokens": ["Wo", "nichts", "wird", "ge\u00b7than", ",", "noch", "ge\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VAFIN", "VVPP", "$,", "ADV", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Ohne da\u00df gleich Rezensenten sch\u00f6n", "tokens": ["Oh\u00b7ne", "da\u00df", "gleich", "Re\u00b7zen\u00b7sen\u00b7ten", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "ADV", "NN", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Rund umher auffangende stehn.", "tokens": ["Rund", "um\u00b7her", "auf\u00b7fan\u00b7gen\u00b7de", "stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "ADJA", "VVINF", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Wers nit versteht, nit nach mag gr\u00fcbeln,", "tokens": ["Wers", "nit", "ver\u00b7steht", ",", "nit", "nach", "mag", "gr\u00fc\u00b7beln", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "VVFIN", "$,", "PTKNEG", "APPR", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Schweigt lieber still, wird ihm niemand ver\u00fcbeln;", "tokens": ["Schweigt", "lie\u00b7ber", "still", ",", "wird", "ihm", "nie\u00b7mand", "ver\u00b7\u00fc\u00b7beln", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "VAFIN", "PPER", "PIS", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Weg zur Kunst ist verborgen und tief,", "tokens": ["Weg", "zur", "Kunst", "ist", "ver\u00b7bor\u00b7gen", "und", "tief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VAFIN", "VVPP", "KON", "ADJD", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Besser redt spat, als urtheilt schief.", "tokens": ["Bes\u00b7ser", "redt", "spat", ",", "als", "ur\u00b7theilt", "schief", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "KOUS", "NE", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Bei euch wird die Liebe so geistlich getrieben,", "tokens": ["Bei", "euch", "wird", "die", "Lie\u00b7be", "so", "geist\u00b7lich", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Plato selbst wird konfus bei eu'erm Lieben;", "tokens": ["Pla\u00b7to", "selbst", "wird", "kon\u00b7fus", "bei", "eu'\u00b7erm", "Lie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "NE", "APPR", "PPOSAT", "ADJA", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Ihr pfeift stets feiner und h\u00f6her hinaus,", "tokens": ["Ihr", "pfeift", "stets", "fei\u00b7ner", "und", "h\u00f6\u00b7her", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und pfeift sie am Ende zum Schornstein 'raus.", "tokens": ["Und", "pfeift", "sie", "am", "En\u00b7de", "zum", "Schorn\u00b7stein", "'raus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "APPRART", "NN", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Ist das ein ewiges Reimen und Singen,", "tokens": ["Ist", "das", "ein", "e\u00b7wi\u00b7ges", "Rei\u00b7men", "und", "Sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Ein ewiges l\u00e4cherliches Feilschen und Dingen,", "tokens": ["Ein", "e\u00b7wi\u00b7ges", "l\u00e4\u00b7cher\u00b7li\u00b7ches", "Feil\u00b7schen", "und", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Jeder des andern im Herzen lacht,", "tokens": ["Je\u00b7der", "des", "an\u00b7dern", "im", "Her\u00b7zen", "lacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "APPRART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Wenn er ihn treuherzig gemacht.", "tokens": ["Wenn", "er", "ihn", "treu\u00b7her\u00b7zig", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die Herrn wollen nur ihren Stil exerciren,", "tokens": ["Die", "Herrn", "wol\u00b7len", "nur", "ih\u00b7ren", "Stil", "ex\u00b7er\u00b7ci\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+---+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Die Dames wollen f\u00fcr sch\u00f6n passieren,", "tokens": ["Die", "Da\u00b7mes", "wol\u00b7len", "f\u00fcr", "sch\u00f6n", "pas\u00b7sie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPR", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und k\u00e4m' man bis auf den Herzens-Grund,", "tokens": ["Und", "k\u00e4m'", "man", "bis", "auf", "den", "Her\u00b7zens\u00b7Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Sie liebten sich beide wie Katz und Hund.", "tokens": ["Sie", "lieb\u00b7ten", "sich", "bei\u00b7de", "wie", "Katz", "und", "Hund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PIS", "KOKOM", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Gott sch\u00fctz und bewahr vor der Art zu lieben,", "tokens": ["Gott", "sch\u00fctz", "und", "be\u00b7wahr", "vor", "der", "Art", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Solchen Roman hat der B\u00f6se geschrieben;", "tokens": ["Sol\u00b7chen", "Ro\u00b7man", "hat", "der", "B\u00f6\u00b7se", "ge\u00b7schrie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Der kalte Wohlstand dr\u00fcber heckt,", "tokens": ["Der", "kal\u00b7te", "Wohl\u00b7stand", "dr\u00fc\u00b7ber", "heckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wie'n Schornsteinfeger mit Ru\u00df bedeckt,", "tokens": ["Wie'n", "Schorn\u00b7stein\u00b7fe\u00b7ger", "mit", "Ru\u00df", "be\u00b7deckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-++-+-+-+", "measure": "unknown.measure.penta"}, "line.17": {"text": "Den er wei\u00df sorgsam abzuschaben,", "tokens": ["Den", "er", "wei\u00df", "sorg\u00b7sam", "ab\u00b7zu\u00b7scha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "ADJD", "VVIZU", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.18": {"text": "Und \u00fcberl\u00e4sset das Feuer den Knaben.", "tokens": ["Und", "\u00fc\u00b7berl\u00b7\u00e4s\u00b7set", "das", "Feu\u00b7er", "den", "Kna\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Bei uns ein Handdruck, ein Sto\u00df mit'm Knie", "tokens": ["Bei", "uns", "ein", "Hand\u00b7druck", ",", "ein", "Sto\u00df", "mit'm", "Knie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ART", "NN", "$,", "ART", "NN", "APPRART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Ist unsre ganze Poesie.", "tokens": ["Ist", "uns\u00b7re", "gan\u00b7ze", "Poe\u00b7sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Daf\u00fcr ist uns auch das Leben nit theuer,", "tokens": ["Da\u00b7f\u00fcr", "ist", "uns", "auch", "das", "Le\u00b7ben", "nit", "theu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "------+--+-", "measure": "iambic.di.relaxed"}, "line.22": {"text": "Und springen f\u00fcr 'nander durchs Feuer.", "tokens": ["Und", "sprin\u00b7gen", "f\u00fcr", "'n\u00b7an\u00b7der", "durchs", "Feu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "APPRART", "NN", "$."], "meter": "-+---+--+-", "measure": "iambic.tri.relaxed"}, "line.23": {"text": "Wir fragen nit erst warum, wozu,", "tokens": ["Wir", "fra\u00b7gen", "nit", "erst", "wa\u00b7rum", ",", "wo\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "PWAV", "$,", "PWAV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Du Bub, du Maidel, liebest du?", "tokens": ["Du", "Bub", ",", "du", "Mai\u00b7del", ",", "lie\u00b7best", "du", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Das hei\u00dft in Engel des Lichts sich stellen,", "tokens": ["Das", "hei\u00dft", "in", "En\u00b7gel", "des", "Lichts", "sich", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NE", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Das nennet sich Lieb, und f\u00fchret zur H\u00f6llen.", "tokens": ["Das", "nen\u00b7net", "sich", "Lieb", ",", "und", "f\u00fch\u00b7ret", "zur", "H\u00f6l\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "NN", "$,", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Die Absicht reiner Lieb ist klar,", "tokens": ["Die", "Ab\u00b7sicht", "rei\u00b7ner", "Lieb", "ist", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Da\u00df da nur Lieb', nit Absicht war.", "tokens": ["Da\u00df", "da", "nur", "Lieb'", ",", "nit", "Ab\u00b7sicht", "war", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "NN", "$,", "PTKNEG", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Wenn also den Herren Magnaten", "tokens": ["Wenn", "al\u00b7so", "den", "Her\u00b7ren", "Mag\u00b7na\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Ich darf in Unterth\u00e4nigkeit helfen und rathen,", "tokens": ["Ich", "darf", "in", "Un\u00b7ter\u00b7th\u00e4\u00b7nig\u00b7keit", "hel\u00b7fen", "und", "ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Schlagt euer galantes W\u00f6rterbuch zu:", "tokens": ["Schlagt", "eu\u00b7er", "ga\u00b7lan\u00b7tes", "W\u00f6r\u00b7ter\u00b7buch", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wer liebt, der schw\u00e4ze nit viel, der thu!", "tokens": ["Wer", "liebt", ",", "der", "schw\u00e4\u00b7ze", "nit", "viel", ",", "der", "thu", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PRELS", "VVFIN", "PTKNEG", "ADV", "$,", "PRELS", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Erlaubt euch daf\u00fcr mit dreisteren W\u00f6rtern", "tokens": ["Er\u00b7laubt", "euch", "da\u00b7f\u00fcr", "mit", "dreis\u00b7te\u00b7ren", "W\u00f6r\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PAV", "APPR", "ADJA", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Nat\u00fcrlich unschuldige Ding zu er\u00f6rtern,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "un\u00b7schul\u00b7di\u00b7ge", "Ding", "zu", "er\u00b7\u00f6r\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "Und schreiet nit gleich, wie die Venus schrie,", "tokens": ["Und", "schrei\u00b7et", "nit", "gleich", ",", "wie", "die", "Ve\u00b7nus", "schrie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Als der General Diomed blessirte sie.", "tokens": ["Als", "der", "Ge\u00b7ne\u00b7ral", "Dio\u00b7med", "bles\u00b7sir\u00b7te", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NE", "VVFIN", "PPER", "$."], "meter": "+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.9": {"text": "Wenn manchmal W\u00f6rter voll Feuer und Leben", "tokens": ["Wenn", "manch\u00b7mal", "W\u00f6r\u00b7ter", "voll", "Feu\u00b7er", "und", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "ADJD", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Sich mitten unter euch wie Raketen begeben,", "tokens": ["Sich", "mit\u00b7ten", "un\u00b7ter", "euch", "wie", "Ra\u00b7ke\u00b7ten", "be\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PPER", "KOKOM", "NN", "VVPP", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.11": {"text": "Und brennen auf die Leidenschaft los;", "tokens": ["Und", "bren\u00b7nen", "auf", "die", "Lei\u00b7den\u00b7schaft", "los", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Der Pulvergestank ist drum nit so gro\u00df.", "tokens": ["Der", "Pul\u00b7ver\u00b7ge\u00b7stank", "ist", "drum", "nit", "so", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PAV", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Die Damen selbst sich zu allem gew\u00f6hnen,", "tokens": ["Die", "Da\u00b7men", "selbst", "sich", "zu", "al\u00b7lem", "ge\u00b7w\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PRF", "APPR", "PIS", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Und d\u00fcrfen alsdann so viel doch nit g\u00e4hnen.", "tokens": ["Und", "d\u00fcr\u00b7fen", "als\u00b7dann", "so", "viel", "doch", "nit", "g\u00e4h\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ADV", "ADV", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Denn heurig' Poeten fliegen doch nicht,", "tokens": ["Denn", "heu\u00b7rig'", "Po\u00b7et\u00b7en", "flie\u00b7gen", "doch", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVFIN", "ADV", "PTKNEG", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "(die Luft ist so d\u00fcnn,) oder kriegen die Gicht,", "tokens": ["(", "die", "Luft", "ist", "so", "d\u00fcnn", ",", ")", "o\u00b7der", "krie\u00b7gen", "die", "Gicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,", "$(", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.17": {"text": "So lang sich die Kr\u00e4nz'gens die Sprache so l\u00e4hmen", "tokens": ["So", "lang", "sich", "die", "Kr\u00e4nz'\u00b7gens", "die", "Spra\u00b7che", "so", "l\u00e4h\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "PRF", "ART", "NN", "ART", "NN", "ADV", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.18": {"text": "Ihr alle ihre W\u00f6rter und Schnellkraft nehmen.", "tokens": ["Ihr", "al\u00b7le", "ih\u00b7re", "W\u00f6r\u00b7ter", "und", "Schnell\u00b7kraft", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Nehmt einem Mahler die Farben weg,", "tokens": ["Nehmt", "ei\u00b7nem", "Mah\u00b7ler", "die", "Far\u00b7ben", "weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Und la\u00dft ihn was mahlen aus Wasser und Dreck!", "tokens": ["Und", "la\u00dft", "ihn", "was", "mah\u00b7len", "aus", "Was\u00b7ser", "und", "Dreck", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "PIS", "VVINF", "APPR", "NN", "KON", "NE", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.21": {"text": "H\u00e4tten die alten Nationen", "tokens": ["H\u00e4t\u00b7ten", "die", "al\u00b7ten", "Na\u00b7ti\u00b7o\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.22": {"text": "Sich so lassen die Oehrlein schonen,", "tokens": ["Sich", "so", "las\u00b7sen", "die", "O\u00b7e\u00b7hrlein", "scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.23": {"text": "Kaiser Alexanders Kopfk\u00fcssen Homer", "tokens": ["Kai\u00b7ser", "A\u00b7lex\u00b7an\u00b7ders", "Kopf\u00b7k\u00fcs\u00b7sen", "Ho\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "NE", "NE"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.24": {"text": "Sein Sprach gieng gewi\u00df durch kein Nadel\u00f6hr.", "tokens": ["Sein", "Sprach", "gieng", "ge\u00b7wi\u00df", "durch", "kein", "Na\u00b7de\u00b7l\u00f6hr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "Ueberhaupt wollet ihr immer nur scherzen!", "tokens": ["Ue\u00b7ber\u00b7haupt", "wol\u00b7let", "ihr", "im\u00b7mer", "nur", "scher\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "+-+---+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Was vom Herzen k\u00f6mmt, das gehet zu Herzen.", "tokens": ["Was", "vom", "Her\u00b7zen", "k\u00f6mmt", ",", "das", "ge\u00b7het", "zu", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPRART", "NN", "VVFIN", "$,", "PDS", "VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Nun aber treibt ihr dess nur Scherz,", "tokens": ["Nun", "a\u00b7ber", "treibt", "ihr", "dess", "nur", "Scherz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PDS", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Denkt weder Poet noch Leser ans Herz.", "tokens": ["Denkt", "we\u00b7der", "Po\u00b7et", "noch", "Le\u00b7ser", "ans", "Herz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "NN", "ADV", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Poet will nur was in Beutel schreiben,", "tokens": ["Po\u00b7et", "will", "nur", "was", "in", "Beu\u00b7tel", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PWS", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Leser will nur seine Zeit vertreiben.", "tokens": ["Le\u00b7ser", "will", "nur", "sei\u00b7ne", "Zeit", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Seid gleich gut Freund mit jedermann,", "tokens": ["Seid", "gleich", "gut", "Freund", "mit", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADV", "ADJD", "NN", "APPR", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Seid gleich aus'nander, seht euch nit mehr an.", "tokens": ["Seid", "gleich", "aus'\u00b7nan\u00b7der", ",", "seht", "euch", "nit", "mehr", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "PTKVZ", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Soll der Poet denn sich winden und richten", "tokens": ["Soll", "der", "Po\u00b7et", "denn", "sich", "win\u00b7den", "und", "rich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "KON", "PRF", "VVINF", "KON", "VVINF"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Nach euern schaalen Alltagsgeschichten?", "tokens": ["Nach", "eu\u00b7ern", "schaa\u00b7len", "All\u00b7tags\u00b7ge\u00b7schich\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Das \u00fcbrig', und m\u00f6gt' die Welt untergahn,", "tokens": ["Das", "\u00fcb\u00b7rig'", ",", "und", "m\u00f6gt'", "die", "Welt", "un\u00b7ter\u00b7gahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKVZ", "$,", "KON", "VMFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Hat gar nichts zu sagen, geht euch nit an.", "tokens": ["Hat", "gar", "nichts", "zu", "sa\u00b7gen", ",", "geht", "euch", "nit", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "PTKZU", "VVINF", "$,", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.13": {"text": "Drum kann's nit fehlen, Kopfweh und Schlummer", "tokens": ["Drum", "kann's", "nit", "feh\u00b7len", ",", "Kopf\u00b7weh", "und", "Schlum\u00b7mer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PTKNEG", "VVINF", "$,", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Ist eure einzige Freud, euer einziger Kummer.", "tokens": ["Ist", "eu\u00b7re", "ein\u00b7zi\u00b7ge", "Freud", ",", "eu\u00b7er", "ein\u00b7zi\u00b7ger", "Kum\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+---+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Nun aber, gn\u00e4dige Frauen, nun", "tokens": ["Nun", "a\u00b7ber", ",", "gn\u00e4\u00b7di\u00b7ge", "Frau\u00b7en", ",", "nun"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Will wieder zu ihnen mich wenden thun;", "tokens": ["Will", "wie\u00b7der", "zu", "ih\u00b7nen", "mich", "wen\u00b7den", "thun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "PPER", "PRF", "VVINF", "VVINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Hat mir jener Ort am Herzen gelegen,", "tokens": ["Hat", "mir", "je\u00b7ner", "Ort", "am", "Her\u00b7zen", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PDAT", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Um dort den Sauertaig auszufegen.", "tokens": ["Um", "dort", "den", "Sau\u00b7er\u00b7taig", "aus\u00b7zu\u00b7fe\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Wollen verzeihen die Paranthesis,", "tokens": ["Wol\u00b7len", "ver\u00b7zei\u00b7hen", "die", "Pa\u00b7ran\u00b7the\u00b7sis", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "Welche so gro\u00df war, wie Herr ** seine gewi\u00df.", "tokens": ["Wel\u00b7che", "so", "gro\u00df", "war", ",", "wie", "Herr", "*", "*", "sei\u00b7ne", "ge\u00b7wi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "VAFIN", "$,", "PWAV", "NN", "XY", "XY", "PPOSAT", "ADV", "$."], "meter": "+--++-++--+", "measure": "iambic.hexa.chol"}, "line.7": {"text": "Haben auch Sie in Flecken und St\u00e4dten", "tokens": ["Ha\u00b7ben", "auch", "Sie", "in", "Fle\u00b7cken", "und", "St\u00e4d\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PPER", "APPR", "NN", "KON", "NN"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.8": {"text": "Gar viel Schulmeister und Poeten,", "tokens": ["Gar", "viel", "Schul\u00b7meis\u00b7ter", "und", "Po\u00b7et\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Welche alle, jung und alt,", "tokens": ["Wel\u00b7che", "al\u00b7le", ",", "jung", "und", "alt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": "Ich in hohen Ehren halt.", "tokens": ["Ich", "in", "ho\u00b7hen", "Eh\u00b7ren", "halt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.11": {"text": "Hab' auch im Homerus gelesen,", "tokens": ["Hab'", "auch", "im", "Ho\u00b7me\u00b7rus", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NE", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df ein gewisser Bettler gewesen,", "tokens": ["Da\u00df", "ein", "ge\u00b7wis\u00b7ser", "Bett\u00b7ler", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VAPP", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Welcher nach vieler Gef\u00e4hrlichkeit", "tokens": ["Wel\u00b7cher", "nach", "vie\u00b7ler", "Ge\u00b7f\u00e4hr\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "APPR", "PIAT", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.14": {"text": "Unter Freund und Feinden, in Lumpen gekleidt,", "tokens": ["Un\u00b7ter", "Freund", "und", "Fein\u00b7den", ",", "in", "Lum\u00b7pen", "ge\u00b7kleidt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.15": {"text": "Durch den Oceanus ist geschwommen,", "tokens": ["Durch", "den", "O\u00b7ce\u00b7a\u00b7nus", "ist", "ge\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.16": {"text": "Und ist zu seiner Frau Liebste gekommen,", "tokens": ["Und", "ist", "zu", "sei\u00b7ner", "Frau", "Liebs\u00b7te", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Hat da eine Menge Buler g'sehn,", "tokens": ["Hat", "da", "ei\u00b7ne", "Men\u00b7ge", "Bu\u00b7ler", "g'\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "VVINF", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Th\u00e4ten all seinem Weibe sch\u00f6n,", "tokens": ["Th\u00e4\u00b7ten", "all", "sei\u00b7nem", "Wei\u00b7be", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "PPOSAT", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.19": {"text": "Auf sein' Rechnung pokulirten,", "tokens": ["Auf", "sein'", "Rech\u00b7nung", "po\u00b7ku\u00b7lir\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "Und ein' Studentenhaushaltung f\u00fchrten.", "tokens": ["Und", "ein'", "Stu\u00b7den\u00b7ten\u00b7haus\u00b7hal\u00b7tung", "f\u00fchr\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$."], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.21": {"text": "Dacht der arme Mann bei sich,", "tokens": ["Dacht", "der", "ar\u00b7me", "Mann", "bei", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.22": {"text": "Blieb' ihr Herz nur g'treu f\u00fcr mich,", "tokens": ["Blieb'", "ihr", "Herz", "nur", "g'\u00b7treu", "f\u00fcr", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "APPR", "PPER", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.23": {"text": "K\u00f6nnt ihnen meinethalb meine Reben", "tokens": ["K\u00f6nnt", "ih\u00b7nen", "mei\u00b7net\u00b7halb", "mei\u00b7ne", "Re\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Roh und gekeltert zu saufen geben,", "tokens": ["Roh", "und", "ge\u00b7kel\u00b7tert", "zu", "sau\u00b7fen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.25": {"text": "Liegt an Haus und Meubeln mir nichts.", "tokens": ["Liegt", "an", "Haus", "und", "Meu\u00b7beln", "mir", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN", "PPER", "PIS", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.26": {"text": "Und wie er dachte, sieh so geschichts.", "tokens": ["Und", "wie", "er", "dach\u00b7te", ",", "sieh", "so", "ge\u00b7schichts", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "VVIMP", "ADV", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.27": {"text": "Immer und immer dem armen Weibe", "tokens": ["Im\u00b7mer", "und", "im\u00b7mer", "dem", "ar\u00b7men", "Wei\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.28": {"text": "Trauerte das Herz im Leibe,", "tokens": ["Trau\u00b7er\u00b7te", "das", "Herz", "im", "Lei\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.29": {"text": "Sah ihr Gesicht gleich aus so froh", "tokens": ["Sah", "ihr", "Ge\u00b7sicht", "gleich", "aus", "so", "froh"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Wie ein Berlinisches Allegro.", "tokens": ["Wie", "ein", "Ber\u00b7li\u00b7ni\u00b7sches", "Al\u00b7le\u00b7gro", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}