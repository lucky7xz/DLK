{"dta.poem.21807": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "X.  \n  Scheiden bringt Leiden.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Ich bin mein Tage so mit Schmerzen/", "tokens": ["Ich", "bin", "mein", "Ta\u00b7ge", "so", "mit", "Schmer\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "mit Ungedult und weichem Herzen", "tokens": ["mit", "Un\u00b7ge\u00b7dult", "und", "wei\u00b7chem", "Her\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "von iener Stat nicht abgereist.", "tokens": ["von", "ie\u00b7ner", "Stat", "nicht", "ab\u00b7ge\u00b7reist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nu ich auff wenig wenig Tage", "tokens": ["Nu", "ich", "auff", "we\u00b7nig", "we\u00b7nig", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "APPR", "PIS", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der s\u00fcssen Gegend Abschied sage/", "tokens": ["der", "s\u00fcs\u00b7sen", "Ge\u00b7gend", "Ab\u00b7schied", "sa\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "verwirrt sich Herze/ Muht und Geist.", "tokens": ["ver\u00b7wirrt", "sich", "Her\u00b7ze", "/", "Muht", "und", "Geist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVFIN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich bin ia nicht so hoch empfangen/", "tokens": ["Ich", "bin", "i\u00b7a", "nicht", "so", "hoch", "emp\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "nicht so auff weichen Rosen gangen/", "tokens": ["nicht", "so", "auff", "wei\u00b7chen", "Ro\u00b7sen", "gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJA", "NN", "VVPP", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "mit Gold\u2019 und Silber nicht beschenkt:", "tokens": ["mit", "Gold'", "und", "Sil\u00b7ber", "nicht", "be\u00b7schenkt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df ich mich sollte drum zu sehnen/", "tokens": ["da\u00df", "ich", "mich", "soll\u00b7te", "drum", "zu", "seh\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VMFIN", "PAV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "mich so zu Leid und Angst gewehnen.", "tokens": ["mich", "so", "zu", "Leid", "und", "Angst", "ge\u00b7weh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ein anders ist es/ das mich krankt.", "tokens": ["Ein", "an\u00b7ders", "ist", "es", "/", "das", "mich", "krankt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "PPER", "$(", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo du es/ Fama/ nicht willst sagen/", "tokens": ["Wo", "du", "es", "/", "Fa\u00b7ma", "/", "nicht", "willst", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "$(", "NN", "$(", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "mich durch die M\u00e4uler nicht willst tragen/", "tokens": ["mich", "durch", "die", "M\u00e4u\u00b7ler", "nicht", "willst", "tra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKNEG", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "will ich es wol vertrauen dir:", "tokens": ["will", "ich", "es", "wol", "ver\u00b7trau\u00b7en", "dir", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist Melinde/ meine Sch\u00f6ne/", "tokens": ["Es", "ist", "Me\u00b7lin\u00b7de", "/", "mei\u00b7ne", "Sch\u00f6\u00b7ne", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "wornach ich mich so hefftig sehne/", "tokens": ["wor\u00b7nach", "ich", "mich", "so", "heff\u00b7tig", "seh\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "di\u00df eine/ dieses mangelt mir.", "tokens": ["di\u00df", "ei\u00b7ne", "/", "die\u00b7ses", "man\u00b7gelt", "mir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "$(", "PDS", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Melinde/ Ach! du liebe Seele/", "tokens": ["Me\u00b7lin\u00b7de", "/", "Ach", "!", "du", "lie\u00b7be", "See\u00b7le", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ITJ", "$.", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "wie hefftig ich mich um dich queele/", "tokens": ["wie", "heff\u00b7tig", "ich", "mich", "um", "dich", "que\u00b7e\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "PRF", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Ich wei\u00df es da\u00df viel tausend St\u00e4hnen/", "tokens": ["Ich", "wei\u00df", "es", "da\u00df", "viel", "tau\u00b7send", "St\u00e4h\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOUS", "ADV", "CARD", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "viel tausend Seuffzer/ Leid und Tr\u00e4hnen", "tokens": ["viel", "tau\u00b7send", "Seuff\u00b7zer", "/", "Leid", "und", "Tr\u00e4h\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "$(", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "mein Scheiden dir erwekken mu\u00df.", "tokens": ["mein", "Schei\u00b7den", "dir", "er\u00b7wek\u00b7ken", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was helffen mich nunmehr die K\u00fcsse/", "tokens": ["Was", "helf\u00b7fen", "mich", "nun\u00b7mehr", "die", "K\u00fcs\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die du/ Melinde/ mir/ du s\u00fc\u00dfe/", "tokens": ["die", "du", "/", "Me\u00b7lin\u00b7de", "/", "mir", "/", "du", "s\u00fc\u00b7\u00dfe", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "$(", "NE", "$(", "PPER", "$(", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du Zukker-kind/ gegeben hast?", "tokens": ["du", "Zuk\u00b7ker\u00b7kind", "/", "ge\u00b7ge\u00b7ben", "hast", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$(", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun sind es W\u00fcrme/ die mich nagen/", "tokens": ["Nun", "sind", "es", "W\u00fcr\u00b7me", "/", "die", "mich", "na\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$(", "PRELS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "nun sind es Pfeile die mich plagen.", "tokens": ["nun", "sind", "es", "Pfei\u00b7le", "die", "mich", "pla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "ART", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ach Lust! wie wirstu so zur Last.", "tokens": ["Ach", "Lust", "!", "wie", "wirs\u00b7tu", "so", "zur", "Last", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "PWAV", "VAFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wo etwas nicht mich armen Kranken/", "tokens": ["Wo", "et\u00b7was", "nicht", "mich", "ar\u00b7men", "Kran\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PTKNEG", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "enthielt die Freude der Gedanken/", "tokens": ["ent\u00b7hielt", "die", "Freu\u00b7de", "der", "Ge\u00b7dan\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und ich auff Hoffnung nicht gedacht.", "tokens": ["und", "ich", "auff", "Hoff\u00b7nung", "nicht", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ich h\u00e4tte mein verha\u00dftes Leben", "tokens": ["ich", "h\u00e4t\u00b7te", "mein", "ver\u00b7ha\u00df\u00b7tes", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "auch vor dem Tode Prei\u00df gegeben", "tokens": ["auch", "vor", "dem", "To\u00b7de", "Prei\u00df", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und mir den Garau\u00df selbst gemacht.", "tokens": ["und", "mir", "den", "Gar\u00b7au\u00df", "selbst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie hundertmahl denk\u2019 ich der Stunde/", "tokens": ["Wie", "hun\u00b7dert\u00b7mahl", "denk'", "ich", "der", "Stun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "da ich/ Melind\u2019/ an deinem Munde/", "tokens": ["da", "ich", "/", "Me\u00b7lind'", "/", "an", "dei\u00b7nem", "Mun\u00b7de", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$(", "NE", "$(", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "mit halb zerteiltem Geiste lag.", "tokens": ["mit", "halb", "zer\u00b7teil\u00b7tem", "Geis\u00b7te", "lag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erinnerstu dich wie vor allen", "tokens": ["E\u00b7rin\u00b7ners\u00b7tu", "dich", "wie", "vor", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "KOKOM", "APPR", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "nur der mir wolte wolgefallen/", "tokens": ["nur", "der", "mir", "wol\u00b7te", "wol\u00b7ge\u00b7fal\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wie ich ihn offt zu r\u00fchmen pflag.", "tokens": ["wie", "ich", "ihn", "offt", "zu", "r\u00fch\u00b7men", "pflag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Warum hastu denn nicht/ Mein Leben/", "tokens": ["Wa\u00b7rum", "has\u00b7tu", "denn", "nicht", "/", "Mein", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "PTKNEG", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "mir nu dein M\u00fcndchen mit gegeben?", "tokens": ["mir", "nu", "dein", "M\u00fcnd\u00b7chen", "mit", "ge\u00b7ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "di\u00df w\u00e4re mir ja noch ein Trost.", "tokens": ["di\u00df", "w\u00e4\u00b7re", "mir", "ja", "noch", "ein", "Trost", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst. Ich mu\u00df es alles meiden/", "tokens": ["Um\u00b7sonst", ".", "Ich", "mu\u00df", "es", "al\u00b7les", "mei\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VMFIN", "PPER", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der Himmel zwinget uns zu scheiden.", "tokens": ["der", "Him\u00b7mel", "zwin\u00b7get", "uns", "zu", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "das Gl\u00fckk ist allzusehr erboost.", "tokens": ["das", "Gl\u00fckk", "ist", "all\u00b7zu\u00b7sehr", "er\u00b7boost", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ists m\u00fcglich: da\u00df es soll geschehen/", "tokens": ["Ists", "m\u00fcg\u00b7lich", ":", "da\u00df", "es", "soll", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "$.", "KOUS", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ich werde wieder sehen/", "tokens": ["da\u00df", "ich", "wer\u00b7de", "wie\u00b7der", "se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wie glukklich soll mir sein die Zeit.", "tokens": ["wie", "gluk\u00b7klich", "soll", "mir", "sein", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPER", "PPOSAT", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "La\u00df kr\u00f6sen den mit Golde laben", "tokens": ["La\u00df", "kr\u00f6\u00b7sen", "den", "mit", "Gol\u00b7de", "la\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "VVFIN", "ART", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und ienen stehn durch Rom erhaben:", "tokens": ["und", "ie\u00b7nen", "stehn", "durch", "Rom", "er\u00b7ha\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "NE", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ich werde h\u00f6her sein erfreut.", "tokens": ["ich", "wer\u00b7de", "h\u00f6\u00b7her", "sein", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VAINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}