{"dta.poem.8074": {"metadata": {"author": {"name": "Uhland, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Junker Rechberger .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1815", "urn": "urn:nbn:de:kobv:b4-200905196438", "language": ["de:0.99"], "booktitle": "Uhland, Ludwig: Gedichte. Stuttgart u. a., 1815."}, "poem": {"stanza.1": {"line.1": {"text": "Rechberger war ein Junker keck,", "tokens": ["Rech\u00b7ber\u00b7ger", "war", "ein", "Jun\u00b7ker", "keck", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Der Kaufleut\u2019 und der Wanderer Schreck.", "tokens": ["Der", "Kauf\u00b7leut'", "und", "der", "Wan\u00b7de\u00b7rer", "Schreck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "In einer Kirche, verlassen,", "tokens": ["In", "ei\u00b7ner", "Kir\u00b7che", ",", "ver\u00b7las\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da th\u00e4t er die Nacht verpassen.", "tokens": ["Da", "th\u00e4t", "er", "die", "Nacht", "ver\u00b7pas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Und als es war nach Mitternacht,", "tokens": ["Und", "als", "es", "war", "nach", "Mit\u00b7ter\u00b7nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da hat er sich auf den Fang gemacht.", "tokens": ["Da", "hat", "er", "sich", "auf", "den", "Fang", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Kaufzug, hat er vernommen,", "tokens": ["Ein", "Kauf\u00b7zug", ",", "hat", "er", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wird fr\u00fche vor\u00fcberkommen.", "tokens": ["Wird", "fr\u00fc\u00b7he", "vor\u00b7\u00fc\u00b7ber\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Sie waren geritten ein kleines St\u00fcck,", "tokens": ["Sie", "wa\u00b7ren", "ge\u00b7rit\u00b7ten", "ein", "klei\u00b7nes", "St\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Da sprach er: \u201eReitknecht! reite zur\u00fcck!", "tokens": ["Da", "sprach", "er", ":", "\u201e", "Reit\u00b7knecht", "!", "rei\u00b7te", "zu\u00b7r\u00fcck", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "NN", "$.", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Die Handschuh hab\u2019 ich vergessen", "tokens": ["Die", "Hand\u00b7schuh", "hab'", "ich", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Auf der Bahre, da ich gesessen.\u201c", "tokens": ["Auf", "der", "Bah\u00b7re", ",", "da", "ich", "ge\u00b7ses\u00b7sen", ".", "\u201c"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "NN", "$,", "KOUS", "PPER", "VVPP", "$.", "$("], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Der Reitknecht kam zur\u00fcck so bleich:", "tokens": ["Der", "Reit\u00b7knecht", "kam", "zu\u00b7r\u00fcck", "so", "bleich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edie Handschuh hole der Teufel Euch!", "tokens": ["\u201e", "die", "Hand\u00b7schuh", "ho\u00b7le", "der", "Teu\u00b7fel", "Euch", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "PPER", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es sitzt ein Geist auf der Bahre;", "tokens": ["Es", "sitzt", "ein", "Geist", "auf", "der", "Bah\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Es starren mir noch die Haare.", "tokens": ["Es", "star\u00b7ren", "mir", "noch", "die", "Haa\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Er hat die Handschuh angethan", "tokens": ["Er", "hat", "die", "Hand\u00b7schuh", "an\u00b7ge\u00b7than"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schaut sie mit feurigen Augen an,", "tokens": ["Und", "schaut", "sie", "mit", "feu\u00b7ri\u00b7gen", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Er streicht sie wohl auf und nieder;", "tokens": ["Er", "streicht", "sie", "wohl", "auf", "und", "nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Es beben mir noch die Glieder.\u201c", "tokens": ["Es", "be\u00b7ben", "mir", "noch", "die", "Glie\u00b7der", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Da ritt der Junker zur\u00fcck im Flug,", "tokens": ["Da", "ritt", "der", "Jun\u00b7ker", "zu\u00b7r\u00fcck", "im", "Flug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er mit dem Geiste sich tapfer schlug,", "tokens": ["Er", "mit", "dem", "Geis\u00b7te", "sich", "tap\u00b7fer", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Er hat den Geist bezwungen,", "tokens": ["Er", "hat", "den", "Geist", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Seine Handschuh wieder errungen.", "tokens": ["Sei\u00b7ne", "Hand\u00b7schuh", "wie\u00b7der", "er\u00b7run\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Da sprach der Geist mit wilder Gier:", "tokens": ["Da", "sprach", "der", "Geist", "mit", "wil\u00b7der", "Gier", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201eund l\u00e4\u00dft du sie nicht zu eigen mir,", "tokens": ["\u201e", "und", "l\u00e4\u00dft", "du", "sie", "nicht", "zu", "ei\u00b7gen", "mir", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PPER", "PTKNEG", "PTKA", "ADJD", "PPER", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So leihe mir auf ein J\u00e4hrlein", "tokens": ["So", "lei\u00b7he", "mir", "auf", "ein", "J\u00e4hr\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das schmucke, schmeidige P\u00e4rlein!\u201c", "tokens": ["Das", "schmu\u00b7cke", ",", "schmei\u00b7di\u00b7ge", "P\u00e4r\u00b7lein", "!", "\u201c"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "\u201eein J\u00e4hrlein ich sie dir gerne leih\u2019,", "tokens": ["\u201e", "ein", "J\u00e4hr\u00b7lein", "ich", "sie", "dir", "ger\u00b7ne", "leih'", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PPER", "PPER", "PPER", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So kann ich erproben des Teufels Treu.", "tokens": ["So", "kann", "ich", "er\u00b7pro\u00b7ben", "des", "Teu\u00b7fels", "Treu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Sie werden wohl nicht zerplatzen", "tokens": ["Sie", "wer\u00b7den", "wohl", "nicht", "zer\u00b7plat\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PTKNEG", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "An deinen d\u00fcrren Tatzen.\u201c", "tokens": ["An", "dei\u00b7nen", "d\u00fcr\u00b7ren", "Tat\u00b7zen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Rechberger sprengte von dannen stolz,", "tokens": ["Rech\u00b7ber\u00b7ger", "spreng\u00b7te", "von", "dan\u00b7nen", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ADV", "ADJD", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Er streifte mit seinem Knecht im Holz.", "tokens": ["Er", "streif\u00b7te", "mit", "sei\u00b7nem", "Knecht", "im", "Holz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Hahn hat ferne gerufen,", "tokens": ["Der", "Hahn", "hat", "fer\u00b7ne", "ge\u00b7ru\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da h\u00f6ren sie Pferdehufen.", "tokens": ["Da", "h\u00f6\u00b7ren", "sie", "Pfer\u00b7de\u00b7hu\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Dem Junker hoch das Herze schlug,", "tokens": ["Dem", "Jun\u00b7ker", "hoch", "das", "Her\u00b7ze", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Weges kam ein schwarzer Zug", "tokens": ["Des", "We\u00b7ges", "kam", "ein", "schwar\u00b7zer", "Zug"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vermummter Rittersleute;", "tokens": ["Ver\u00b7mumm\u00b7ter", "Rit\u00b7ters\u00b7leu\u00b7te", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Junker wich auf die Seite.", "tokens": ["Der", "Jun\u00b7ker", "wich", "auf", "die", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Und hinten trabt noch Einer daher,", "tokens": ["Und", "hin\u00b7ten", "trabt", "noch", "Ei\u00b7ner", "da\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ADV", "PIS", "PAV", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ein ledig R\u00e4pplein f\u00fchret er,", "tokens": ["Ein", "le\u00b7dig", "R\u00e4pp\u00b7lein", "f\u00fch\u00b7ret", "er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Mit Sattel und Zeug staffiret,", "tokens": ["Mit", "Sat\u00b7tel", "und", "Zeug", "staf\u00b7fi\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mit schwarzer Decke gezieret.", "tokens": ["Mit", "schwar\u00b7zer", "De\u00b7cke", "ge\u00b7zie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Rechberger ritt heran und frug:", "tokens": ["Rech\u00b7ber\u00b7ger", "ritt", "he\u00b7ran", "und", "frug", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "\u201esag an! wer sind die Herren vom Zug?", "tokens": ["\u201e", "sag", "an", "!", "wer", "sind", "die", "Her\u00b7ren", "vom", "Zug", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$.", "PWS", "VAFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-----+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Sag an, traut lieber Knappe!", "tokens": ["Sag", "an", ",", "traut", "lie\u00b7ber", "Knap\u00b7pe", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wem geh\u00f6rt der ledige Rappe?\u201c", "tokens": ["Wem", "ge\u00b7h\u00f6rt", "der", "le\u00b7di\u00b7ge", "Rap\u00b7pe", "?", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "\u201edem treuesten Diener meines Herrn,", "tokens": ["\u201e", "dem", "treu\u00b7es\u00b7ten", "Die\u00b7ner", "mei\u00b7nes", "Herrn", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Rechberger nennt man ihn nah und fern.", "tokens": ["Rech\u00b7ber\u00b7ger", "nennt", "man", "ihn", "nah", "und", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Ein J\u00e4hrlein, so ist er erschlagen,", "tokens": ["Ein", "J\u00e4hr\u00b7lein", ",", "so", "ist", "er", "er\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Dann wird das R\u00e4pplein ihn tragen.\u201c", "tokens": ["Dann", "wird", "das", "R\u00e4pp\u00b7lein", "ihn", "tra\u00b7gen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Der Schwarze ritt den Andern nach,", "tokens": ["Der", "Schwar\u00b7ze", "ritt", "den", "An\u00b7dern", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Junker zu seinem Knechte sprach:", "tokens": ["Der", "Jun\u00b7ker", "zu", "sei\u00b7nem", "Knech\u00b7te", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201eweh mir! vom Ro\u00df ich steige,", "tokens": ["\u201e", "weh", "mir", "!", "vom", "Ro\u00df", "ich", "stei\u00b7ge", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPER", "$.", "APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es geht mit mir zur Neige.", "tokens": ["Es", "geht", "mit", "mir", "zur", "Nei\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ist dir mein R\u00f6\u00dflein nicht zu wild,", "tokens": ["Ist", "dir", "mein", "R\u00f6\u00df\u00b7lein", "nicht", "zu", "wild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und nicht zu schwer mein Degen und Schild:", "tokens": ["Und", "nicht", "zu", "schwer", "mein", "De\u00b7gen", "und", "Schild", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "PTKA", "ADJD", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Nimm\u2019s hin dir zum Gewinnste,", "tokens": ["Nim\u00b7m's", "hin", "dir", "zum", "Ge\u00b7winns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und brauch es in Gottes Dienste!\u201c", "tokens": ["Und", "brauch", "es", "in", "Got\u00b7tes", "Diens\u00b7te", "!", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Rechberger in ein Kloster ging:", "tokens": ["Rech\u00b7ber\u00b7ger", "in", "ein", "Klos\u00b7ter", "ging", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "\u201eherr Abt, ich bin zum M\u00f6nche zu ring,", "tokens": ["\u201e", "herr", "Abt", ",", "ich", "bin", "zum", "M\u00f6n\u00b7che", "zu", "ring", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "$,", "PPER", "VAFIN", "APPRART", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Doch m\u00f6cht\u2019 ich in tiefer Reue", "tokens": ["Doch", "m\u00f6cht'", "ich", "in", "tie\u00b7fer", "Reu\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Dem Kloster dienen als Laie.\u201c", "tokens": ["Dem", "Klos\u00b7ter", "die\u00b7nen", "als", "Lai\u00b7e", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "KOKOM", "NE", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "\u201edu bist gewesen ein Reitersmann,", "tokens": ["\u201e", "du", "bist", "ge\u00b7we\u00b7sen", "ein", "Rei\u00b7ters\u00b7mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "VAPP", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich seh\u2019 es dir an den Sporen an,", "tokens": ["Ich", "seh'", "es", "dir", "an", "den", "Spo\u00b7ren", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So magst du der Pferde walten,", "tokens": ["So", "magst", "du", "der", "Pfer\u00b7de", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die im Klosterstalle wir halten.\u201c", "tokens": ["Die", "im", "Klos\u00b7ter\u00b7stal\u00b7le", "wir", "hal\u00b7ten", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPRART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Am Tag, da selbiges Jahr sich schlo\u00df,", "tokens": ["Am", "Tag", ",", "da", "sel\u00b7bi\u00b7ges", "Jahr", "sich", "schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da kaufte der Abt ein schwarz wild Ro\u00df,", "tokens": ["Da", "kauf\u00b7te", "der", "Abt", "ein", "schwarz", "wild", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJD", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Rechberger sollt\u2019 es z\u00e4umen,", "tokens": ["Rech\u00b7ber\u00b7ger", "sollt'", "es", "z\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Doch es th\u00e4t sich stellen und b\u00e4umen.", "tokens": ["Doch", "es", "th\u00e4t", "sich", "stel\u00b7len", "und", "b\u00e4u\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Es schlug den Junker mitten auf\u2019s Herz,", "tokens": ["Es", "schlug", "den", "Jun\u00b7ker", "mit\u00b7ten", "auf's", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df er sank in bitterem Todesschmerz.", "tokens": ["Da\u00df", "er", "sank", "in", "bit\u00b7te\u00b7rem", "To\u00b7des\u00b7schmerz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es ist im Walde verschwunden,", "tokens": ["Es", "ist", "im", "Wal\u00b7de", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Man hat\u2019s nicht wieder gefunden.", "tokens": ["Man", "hat's", "nicht", "wie\u00b7der", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PTKNEG", "ADV", "VVPP", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Um Mitternacht, an Junkers Grab,", "tokens": ["Um", "Mit\u00b7ter\u00b7nacht", ",", "an", "Jun\u00b7kers", "Grab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da stieg ein schwarzer Reitknecht ab,", "tokens": ["Da", "stieg", "ein", "schwar\u00b7zer", "Reit\u00b7knecht", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Einem Rappen h\u00e4lt er die Stangen,", "tokens": ["Ei\u00b7nem", "Rap\u00b7pen", "h\u00e4lt", "er", "die", "Stan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Reithandschuh am Sattel hangen.", "tokens": ["Reit\u00b7hand\u00b7schuh", "am", "Sat\u00b7tel", "han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Rechberger stieg aus dem Grab herauf,", "tokens": ["Rech\u00b7ber\u00b7ger", "stieg", "aus", "dem", "Grab", "her\u00b7auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Er nahm die Handschuh vom Sattelknauf,", "tokens": ["Er", "nahm", "die", "Hand\u00b7schuh", "vom", "Sat\u00b7tel\u00b7knauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er schwang sich in Sattels Mitte,", "tokens": ["Er", "schwang", "sich", "in", "Sat\u00b7tels", "Mit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Der Grabstein diente zum Tritte.", "tokens": ["Der", "Grab\u00b7stein", "dien\u00b7te", "zum", "Trit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Dies Lieb ist Junkern zur Lehr\u2019 gemacht:", "tokens": ["Dies", "Lieb", "ist", "Jun\u00b7kern", "zur", "Lehr'", "ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df sie geben auf ihre Handschuh Acht,", "tokens": ["Da\u00df", "sie", "ge\u00b7ben", "auf", "ih\u00b7re", "Hand\u00b7schuh", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "CARD", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und da\u00df sie fein bleiben lassen,", "tokens": ["Und", "da\u00df", "sie", "fein", "blei\u00b7ben", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVINF", "VVINF", "$,"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.4": {"text": "In der Nacht am Wege zn passen.", "tokens": ["In", "der", "Nacht", "am", "We\u00b7ge", "zn", "pas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "NE", "VVINF", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}}}}