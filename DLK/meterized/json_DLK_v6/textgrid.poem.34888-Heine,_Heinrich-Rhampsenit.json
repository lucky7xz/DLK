{"textgrid.poem.34888": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Rhampsenit", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als der K\u00f6nig Rhampsenit", "tokens": ["Als", "der", "K\u00f6\u00b7nig", "Rhamp\u00b7se\u00b7nit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Eintrat in die goldne Halle", "tokens": ["Ein\u00b7trat", "in", "die", "gold\u00b7ne", "Hal\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Seiner Tochter, lachte diese,", "tokens": ["Sei\u00b7ner", "Toch\u00b7ter", ",", "lach\u00b7te", "die\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PDS", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Lachten ihre Zofen alle.", "tokens": ["Lach\u00b7ten", "ih\u00b7re", "Zo\u00b7fen", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PIAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Auch die Schwarzen, die Eunuchen,", "tokens": ["Auch", "die", "Schwar\u00b7zen", ",", "die", "Eu\u00b7nu\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stimmten lachend ein, es lachten", "tokens": ["Stimm\u00b7ten", "la\u00b7chend", "ein", ",", "es", "lach\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Selbst die Mumien, selbst die Sphinxe,", "tokens": ["Selbst", "die", "Mu\u00b7mi\u00b7en", ",", "selbst", "die", "Sphin\u00b7xe", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "+----+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Da\u00df sie schier zu bersten dachten.", "tokens": ["Da\u00df", "sie", "schier", "zu", "bers\u00b7ten", "dach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Die Prinzessin sprach: \u00bbIch glaubte", "tokens": ["Die", "Prin\u00b7zes\u00b7sin", "sprach", ":", "\u00bb", "Ich", "glaub\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "PPER", "VVFIN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Schon, den Schatzdieb zu erfassen,", "tokens": ["Schon", ",", "den", "Schatz\u00b7dieb", "zu", "er\u00b7fas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der hat aber einen toten", "tokens": ["Der", "hat", "a\u00b7ber", "ei\u00b7nen", "to\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Arm in meiner Hand gelassen.", "tokens": ["Arm", "in", "mei\u00b7ner", "Hand", "ge\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Jetzt begreif ich, wie der Schatzdieb", "tokens": ["Jetzt", "be\u00b7greif", "ich", ",", "wie", "der", "Schatz\u00b7dieb"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Dringt in deine Schatzhauskammern,", "tokens": ["Dringt", "in", "dei\u00b7ne", "Schatz\u00b7haus\u00b7kam\u00b7mern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Sch\u00e4tze dir entwendet,", "tokens": ["Und", "die", "Sch\u00e4t\u00b7ze", "dir", "ent\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Trotz den Schl\u00f6ssern, Riegeln, Klammern.", "tokens": ["Trotz", "den", "Schl\u00f6s\u00b7sern", ",", "Rie\u00b7geln", ",", "Klam\u00b7mern", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Einen Zauberschl\u00fcssel hat er,", "tokens": ["Ei\u00b7nen", "Zau\u00b7ber\u00b7schl\u00fcs\u00b7sel", "hat", "er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der erschlie\u00dfet allerorten", "tokens": ["Der", "er\u00b7schlie\u00b7\u00dfet", "al\u00b7le\u00b7ror\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jede T\u00fcre, widerstehen", "tokens": ["Je\u00b7de", "T\u00fc\u00b7re", ",", "wi\u00b7der\u00b7ste\u00b7hen"], "token_info": ["word", "word", "punct", "word"], "pos": ["PIAT", "NN", "$,", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nnen nicht die st\u00e4rksten Pforten.", "tokens": ["K\u00f6n\u00b7nen", "nicht", "die", "st\u00e4rks\u00b7ten", "Pfor\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich bin keine starke Pforte,", "tokens": ["Ich", "bin", "kei\u00b7ne", "star\u00b7ke", "Pfor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Und ich hab nicht widerstanden,", "tokens": ["Und", "ich", "hab", "nicht", "wi\u00b7der\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sch\u00e4tzeh\u00fctend diese Nacht", "tokens": ["Sch\u00e4t\u00b7ze\u00b7h\u00fc\u00b7tend", "die\u00b7se", "Nacht"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Kam ein Sch\u00e4tzlein mir abhanden.\u00ab", "tokens": ["Kam", "ein", "Sch\u00e4tz\u00b7lein", "mir", "ab\u00b7han\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ART", "NN", "PPER", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "So sprach lachend die Prinzessin,", "tokens": ["So", "sprach", "la\u00b7chend", "die", "Prin\u00b7zes\u00b7sin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Und sie t\u00e4nzelt im Gemache,", "tokens": ["Und", "sie", "t\u00e4n\u00b7zelt", "im", "Ge\u00b7ma\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Und die Zofen und Eunuchen", "tokens": ["Und", "die", "Zo\u00b7fen", "und", "Eu\u00b7nu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "KON", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Hoben wieder ihre Lache.", "tokens": ["Ho\u00b7ben", "wie\u00b7der", "ih\u00b7re", "La\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "An demselben Tag ganz Memphis", "tokens": ["An", "dem\u00b7sel\u00b7ben", "Tag", "ganz", "Mem\u00b7phis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ADV", "NE"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lachte, selbst die Krokodile", "tokens": ["Lach\u00b7te", ",", "selbst", "die", "Kro\u00b7ko\u00b7di\u00b7le"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Reckten lachend ihre H\u00e4upter", "tokens": ["Reck\u00b7ten", "la\u00b7chend", "ih\u00b7re", "H\u00e4up\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADJD", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aus dem schlammig gelben Nile,", "tokens": ["Aus", "dem", "schlam\u00b7mig", "gel\u00b7ben", "Ni\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Als sie Trommelschlag vernahmen", "tokens": ["Als", "sie", "Trom\u00b7mel\u00b7schlag", "ver\u00b7nah\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und sie h\u00f6rten an dem Ufer", "tokens": ["Und", "sie", "h\u00f6r\u00b7ten", "an", "dem", "U\u00b7fer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Folgendes Reskript verlesen", "tokens": ["Fol\u00b7gen\u00b7des", "Res\u00b7kript", "ver\u00b7le\u00b7sen"], "token_info": ["word", "word", "word"], "pos": ["NN", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Von dem Kanzeleiausrufer:", "tokens": ["Von", "dem", "Kan\u00b7ze\u00b7lei\u00b7aus\u00b7ru\u00b7fer", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "\u00bbrhampsenit, von Gottes Gnaden", "tokens": ["\u00bb", "rhamp\u00b7se\u00b7nit", ",", "von", "Got\u00b7tes", "Gna\u00b7den"], "token_info": ["punct", "word", "punct", "word", "word", "word"], "pos": ["$(", "FM.la", "$,", "APPR", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "K\u00f6nig zu und in \u00c4gypten,", "tokens": ["K\u00f6\u00b7nig", "zu", "und", "in", "\u00c4\u00b7gyp\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wir entbieten Gru\u00df und Freundschaft", "tokens": ["Wir", "ent\u00b7bie\u00b7ten", "Gru\u00df", "und", "Freund\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsern Vielgetreun und Liebden.", "tokens": ["Un\u00b7sern", "Viel\u00b7ge\u00b7treun", "und", "Lieb\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "CARD", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "In der Nacht vom dritten zu dem", "tokens": ["In", "der", "Nacht", "vom", "drit\u00b7ten", "zu", "dem"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPRART", "ADJA", "APPR", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vierten Junius des Jahres", "tokens": ["Vier\u00b7ten", "Ju\u00b7nius", "des", "Jah\u00b7res"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Dreizehnhundertvierundzwanzig", "tokens": ["Drei\u00b7zehn\u00b7hun\u00b7dert\u00b7vie\u00b7rund\u00b7zwan\u00b7zig"], "token_info": ["word"], "pos": ["CARD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor Christi Geburt, da war es,", "tokens": ["Vor", "Chris\u00b7ti", "Ge\u00b7burt", ",", "da", "war", "es", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,", "ADV", "VAFIN", "PPER", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Da\u00df ein Dieb aus unserm Schatzhaus", "tokens": ["Da\u00df", "ein", "Dieb", "aus", "un\u00b7serm", "Schatz\u00b7haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Eine Menge von Juwelen", "tokens": ["Ei\u00b7ne", "Men\u00b7ge", "von", "Ju\u00b7we\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Uns entwendet; es gelang ihm,", "tokens": ["Uns", "ent\u00b7wen\u00b7det", ";", "es", "ge\u00b7lang", "ihm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "$.", "PPER", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Uns auch sp\u00e4ter zu bestehlen.", "tokens": ["Uns", "auch", "sp\u00e4\u00b7ter", "zu", "be\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Zur Ermittelung des T\u00e4ters", "tokens": ["Zur", "Er\u00b7mit\u00b7te\u00b7lung", "des", "T\u00e4\u00b7ters"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lie\u00dfen schlafen wir die Tochter", "tokens": ["Lie\u00b7\u00dfen", "schla\u00b7fen", "wir", "die", "Toch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bei den Sch\u00e4tzen \u2013 doch auch jene", "tokens": ["Bei", "den", "Sch\u00e4t\u00b7zen", "\u2013", "doch", "auch", "je\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$(", "ADV", "ADV", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu bestehlen schlau vermocht er.", "tokens": ["Zu", "be\u00b7steh\u00b7len", "schlau", "ver\u00b7mocht", "er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADJD", "VVFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Um zu steuern solchem Diebstahl", "tokens": ["Um", "zu", "steu\u00b7ern", "sol\u00b7chem", "Dieb\u00b7stahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "PTKZU", "VVINF", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und zu gleicher Zeit dem Diebe", "tokens": ["Und", "zu", "glei\u00b7cher", "Zeit", "dem", "Die\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unsre Sympathie zu zeigen,", "tokens": ["Uns\u00b7re", "Sym\u00b7pa\u00b7thie", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unsre Ehrfurcht, unsre Liebe,", "tokens": ["Uns\u00b7re", "Ehr\u00b7furcht", ",", "uns\u00b7re", "Lie\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Wollen wir ihm zur Gemahlin", "tokens": ["Wol\u00b7len", "wir", "ihm", "zur", "Ge\u00b7mah\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre einz'ge Tochter geben", "tokens": ["Uns\u00b7re", "einz'\u00b7ge", "Toch\u00b7ter", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ihn auch als Thronnachfolger", "tokens": ["Und", "ihn", "auch", "als", "Thron\u00b7nach\u00b7fol\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "KOUS", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In den F\u00fcrstenstand erheben.", "tokens": ["In", "den", "F\u00fcrs\u00b7ten\u00b7stand", "er\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Sintemal uns die Adresse", "tokens": ["Sin\u00b7te\u00b7mal", "uns", "die", "Ad\u00b7res\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Unsres Eidams noch zur Stunde", "tokens": ["Uns\u00b7res", "Ei\u00b7dams", "noch", "zur", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Unbekannt, soll dies Reskript ihm", "tokens": ["Un\u00b7be\u00b7kannt", ",", "soll", "dies", "Res\u00b7kript", "ihm"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VMFIN", "PDS", "NN", "PPER"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Bringen Unsrer Gnade Kunde.", "tokens": ["Brin\u00b7gen", "Uns\u00b7rer", "Gna\u00b7de", "Kun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "So geschehn den dritten J\u00e4nner", "tokens": ["So", "ge\u00b7schehn", "den", "drit\u00b7ten", "J\u00e4n\u00b7ner"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dreizehnhundertzwanzigsechs", "tokens": ["Drei\u00b7zehn\u00b7hun\u00b7dert\u00b7zwan\u00b7zig\u00b7sechs"], "token_info": ["word"], "pos": ["CARD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vor Christi Geburt. \u2013 Signieret", "tokens": ["Vor", "Chris\u00b7ti", "Ge\u00b7burt", ".", "\u2013", "Sig\u00b7nie\u00b7ret"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["APPR", "NE", "NN", "$.", "$(", "NE"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Von Uns: Rhampsenitus Rex.\u00ab", "tokens": ["Von", "Uns", ":", "Rhamp\u00b7se\u00b7ni\u00b7tus", "Rex", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPR", "PPER", "$.", "NE", "NE", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Rhampsenit hat Wort gehalten,", "tokens": ["Rhamp\u00b7se\u00b7nit", "hat", "Wort", "ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahm den Dieb zum Schwiegersohne,", "tokens": ["Nahm", "den", "Dieb", "zum", "Schwie\u00b7ger\u00b7soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und nach seinem Tode erbte", "tokens": ["Und", "nach", "sei\u00b7nem", "To\u00b7de", "erb\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch der Dieb \u00c4gyptens Krone.", "tokens": ["Auch", "der", "Dieb", "\u00c4\u00b7gyp\u00b7tens", "Kro\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NE", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Er regierte wie die andern,", "tokens": ["Er", "re\u00b7gier\u00b7te", "wie", "die", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sch\u00fctzte Handel und Talente;", "tokens": ["Sch\u00fctz\u00b7te", "Han\u00b7del", "und", "Ta\u00b7len\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenig, hei\u00dft es, ward gestohlen", "tokens": ["We\u00b7nig", ",", "hei\u00dft", "es", ",", "ward", "ge\u00b7stoh\u00b7len"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unter seinem Regimente.", "tokens": ["Un\u00b7ter", "sei\u00b7nem", "Re\u00b7gi\u00b7men\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}