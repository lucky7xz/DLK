{"textgrid.poem.51237": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Kr\u00f6tensage", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Des Berges alte Wangen sind", "tokens": ["Des", "Ber\u00b7ges", "al\u00b7te", "Wan\u00b7gen", "sind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Maiensonne beschienen;", "tokens": ["Von", "Mai\u00b7en\u00b7son\u00b7ne", "be\u00b7schie\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Sie l\u00e4cheln unter Quellenglanz,", "tokens": ["Sie", "l\u00e4\u00b7cheln", "un\u00b7ter", "Quel\u00b7len\u00b7glanz", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Schilfe, die Farren ergr\u00fcnen.", "tokens": ["Die", "Schil\u00b7fe", ",", "die", "Far\u00b7ren", "er\u00b7gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.2": {"line.1": {"text": "Die Kr\u00f6te springt aus dem Kieselstein,", "tokens": ["Die", "Kr\u00f6\u00b7te", "springt", "aus", "dem", "Kie\u00b7sel\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Hirt hat ihn zerschlagen;", "tokens": ["Ein", "Hirt", "hat", "ihn", "zer\u00b7schla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie schaut verdrossen die Scherben an,", "tokens": ["Sie", "schaut", "ver\u00b7dros\u00b7sen", "die", "Scher\u00b7ben", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und sie beginnt zu sagen:", "tokens": ["Und", "sie", "be\u00b7ginnt", "zu", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "\u00bbviel tausend Jahre bin ich alt", "tokens": ["\u00bb", "viel", "tau\u00b7send", "Jah\u00b7re", "bin", "ich", "alt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "CARD", "NN", "VAFIN", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Samt diesem Futterale!", "tokens": ["Samt", "die\u00b7sem", "Fut\u00b7te\u00b7ra\u00b7le", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es schob vom hohen Felsgebirg", "tokens": ["Es", "schob", "vom", "ho\u00b7hen", "Fels\u00b7ge\u00b7birg"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Allm\u00e4hlich mit mir zu Tale.", "tokens": ["All\u00b7m\u00e4h\u00b7lich", "mit", "mir", "zu", "Ta\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "APPR", "NE", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}}, "stanza.4": {"line.1": {"text": "Doch manchmal in der Wasser Sturz", "tokens": ["Doch", "manch\u00b7mal", "in", "der", "Was\u00b7ser", "Sturz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sind wir gewaltig gesprungen;", "tokens": ["Sind", "wir", "ge\u00b7wal\u00b7tig", "ge\u00b7sprun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Dann hat's um meine dunkle Klausur", "tokens": ["Dann", "hat's", "um", "mei\u00b7ne", "dunk\u00b7le", "Klau\u00b7sur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Gesungen und geklungen.", "tokens": ["Ge\u00b7sun\u00b7gen", "und", "ge\u00b7klun\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und wie mir ist \u2013 ich wei\u00df es nicht,", "tokens": ["Und", "wie", "mir", "ist", "\u2013", "ich", "wei\u00df", "es", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VAFIN", "$(", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch was ich getrieben indessen;", "tokens": ["Noch", "was", "ich", "ge\u00b7trie\u00b7ben", "in\u00b7des\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PPER", "VVPP", "ADV", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Ich hab im mindesten nichts gelernt", "tokens": ["Ich", "hab", "im", "min\u00b7des\u00b7ten", "nichts", "ge\u00b7lernt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "ADJA", "PIS", "VVPP"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und hatte nicht viel zu vergessen.", "tokens": ["Und", "hat\u00b7te", "nicht", "viel", "zu", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.6": {"line.1": {"text": "Ein warmer Regen, ein gr\u00fcnes Kraut", "tokens": ["Ein", "war\u00b7mer", "Re\u00b7gen", ",", "ein", "gr\u00fc\u00b7nes", "Kraut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nur konnten mir behagen;", "tokens": ["Nur", "konn\u00b7ten", "mir", "be\u00b7ha\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie liegen mir fort und fort im Sinn", "tokens": ["Sie", "lie\u00b7gen", "mir", "fort", "und", "fort", "im", "Sinn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "APPRART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Aus fernen Jugendtagen.", "tokens": ["Aus", "fer\u00b7nen", "Ju\u00b7gend\u00b7ta\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "So hab ich ein langweilig St\u00fcck", "tokens": ["So", "hab", "ich", "ein", "lang\u00b7wei\u00b7lig", "St\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unsterblichkeit erworben;", "tokens": ["U\u00b7nsterb\u00b7lich\u00b7keit", "er\u00b7wor\u00b7ben", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "++-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "H\u00e4tt ich getrunken lebendige Luft,", "tokens": ["H\u00e4tt", "ich", "ge\u00b7trun\u00b7ken", "le\u00b7ben\u00b7di\u00b7ge", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "ADJA", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "L\u00e4ngst w\u00e4r ich vern\u00fcnftig gestorben.\u00ab", "tokens": ["L\u00e4ngst", "w\u00e4r", "ich", "ver\u00b7n\u00fcnf\u00b7tig", "ge\u00b7stor\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}