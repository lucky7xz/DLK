{"textgrid.poem.53984": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "B\u00e4nkelbuch", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wem es bestimmt, der endet auf dem Mist", "tokens": ["Wem", "es", "be\u00b7stimmt", ",", "der", "en\u00b7det", "auf", "dem", "Mist"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVPP", "$,", "PRELS", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit seinem edelsten Bestreben . . .", "tokens": ["Mit", "sei\u00b7nem", "e\u00b7dels\u00b7ten", "Be\u00b7stre\u00b7ben", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$.", "$.", "$."], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.3": {"text": "Ich bin zum Beispiel immer noch Jurist.", "tokens": ["Ich", "bin", "zum", "Bei\u00b7spiel", "im\u00b7mer", "noch", "Ju\u00b7rist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So ist das Leben.", "tokens": ["So", "ist", "das", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Man hat unsern K\u00f6rper und unsern Geist", "tokens": ["Man", "hat", "un\u00b7sern", "K\u00f6r\u00b7per", "und", "un\u00b7sern", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "ein wenig zu wenig gekr\u00e4ftigt.", "tokens": ["ein", "we\u00b7nig", "zu", "we\u00b7nig", "ge\u00b7kr\u00e4f\u00b7tigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKA", "PIS", "VVPP", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Man hat uns zu viel, zu fr\u00fch und zumeist", "tokens": ["Man", "hat", "uns", "zu", "viel", ",", "zu", "fr\u00fch", "und", "zu\u00b7meist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "PTKA", "PIS", "$,", "PTKA", "ADJD", "KON", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "in der Weltgeschichte besch\u00e4ftigt!", "tokens": ["in", "der", "Welt\u00b7ge\u00b7schich\u00b7te", "be\u00b7sch\u00e4f\u00b7tigt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Am Nebentisch im Caf\u00e9 Anglais:", "tokens": ["Am", "Ne\u00b7ben\u00b7tisch", "im", "Ca\u00b7f\u00e9", "An\u00b7glais", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbich kann blo\u00df leben in deiner N\u00e4h!\u00ab", "tokens": ["\u00bb", "ich", "kann", "blo\u00df", "le\u00b7ben", "in", "dei\u00b7ner", "N\u00e4h", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u2013 Det versteh ick nich.", "tokens": ["\u2013", "Det", "ver\u00b7steh", "ick", "nich", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "\u00bbf\u00fcr mich ist dein \u00e4ltester Anzug neu.", "tokens": ["\u00bb", "f\u00fcr", "mich", "ist", "dein", "\u00e4l\u00b7tes\u00b7ter", "An\u00b7zug", "neu", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "ADJD", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Du gehst mit andern, ich bin dir treu.\u00ab", "tokens": ["Du", "gehst", "mit", "an\u00b7dern", ",", "ich", "bin", "dir", "treu", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "\u2013 Det versteh ick nich.", "tokens": ["\u2013", "Det", "ver\u00b7steh", "ick", "nich", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Wenn der Tag zu Ende gebrannt ist,", "tokens": ["Wenn", "der", "Tag", "zu", "En\u00b7de", "ge\u00b7brannt", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NN", "VVPP", "VAFIN", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "ist es schwer, nach Hause zu gehn,", "tokens": ["ist", "es", "schwer", ",", "nach", "Hau\u00b7se", "zu", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "$,", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "wo viermal die starre Wand ist", "tokens": ["wo", "vier\u00b7mal", "die", "star\u00b7re", "Wand", "ist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und die leeren St\u00fchle stehn.", "tokens": ["und", "die", "lee\u00b7ren", "St\u00fch\u00b7le", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "In der Esse fliegt der Hammer", "tokens": ["In", "der", "Es\u00b7se", "fliegt", "der", "Ham\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "im Cylinder auf und ab;", "tokens": ["im", "Cy\u00b7lin\u00b7der", "auf", "und", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gottfried in der M\u00e4dchenkammer", "tokens": ["Gott\u00b7fried", "in", "der", "M\u00e4d\u00b7chen\u00b7kam\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "APPR", "ART", "NN"], "meter": "++--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "fliegt nicht minder auf und ab \u2013", "tokens": ["fliegt", "nicht", "min\u00b7der", "auf", "und", "ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "PTKVZ", "KON", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "La\u00df du doch das Klavier in Ruhe;", "tokens": ["La\u00df", "du", "doch", "das", "Kla\u00b7vier", "in", "Ru\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "es hat dir nichts getan;", "tokens": ["es", "hat", "dir", "nichts", "ge\u00b7tan", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PIS", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "nimm lieber deine Gummischuhe", "tokens": ["nimm", "lie\u00b7ber", "dei\u00b7ne", "Gum\u00b7mi\u00b7schu\u00b7he"], "token_info": ["word", "word", "word", "word"], "pos": ["VVIMP", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und bring mich an die Bahn \u2013", "tokens": ["und", "bring", "mich", "an", "die", "Bahn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}