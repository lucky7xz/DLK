{"dta.poem.11085": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte thr\u00e4nen.  \n  C. H.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.71", "nl:0.28"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn ich an Clelien gedencke,", "tokens": ["Wenn", "ich", "an", "Cle\u00b7li\u00b7en", "ge\u00b7den\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sie in n\u00e4chster fr\u00fchlings-zeit", "tokens": ["Wie", "sie", "in", "n\u00e4chs\u00b7ter", "fr\u00fch\u00b7lings\u00b7zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch ihr gebl\u00fcme mich erfreut;", "tokens": ["Durch", "ihr", "ge\u00b7bl\u00fc\u00b7me", "mich", "er\u00b7freut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie ihrer k\u00fcsse perlen-tr\u00e4ncke", "tokens": ["Wie", "ih\u00b7rer", "k\u00fcs\u00b7se", "per\u00b7len\u00b7tr\u00e4n\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mich aus der schlaf-sucht aufgeweckt,", "tokens": ["Mich", "aus", "der", "schlaf\u00b7sucht", "auf\u00b7ge\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Darein der kummer mich gesteckt;", "tokens": ["Da\u00b7rein", "der", "kum\u00b7mer", "mich", "ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ja, wenn ich ferner \u00fcberlege,", "tokens": ["Ja", ",", "wenn", "ich", "fer\u00b7ner", "\u00fc\u00b7berl\u00b7e\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie durch des himmels strengen schlu\u00df", "tokens": ["Wie", "durch", "des", "him\u00b7mels", "stren\u00b7gen", "schlu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ich ihrer nun entbehren mu\u00df:", "tokens": ["Ich", "ih\u00b7rer", "nun", "ent\u00b7beh\u00b7ren", "mu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "So wird die wehmuth in mir rege.", "tokens": ["So", "wird", "die", "weh\u00b7muth", "in", "mir", "re\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PPER", "ADJA", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "So qu\u00e4lt die sterbens-angst die sinnen:", "tokens": ["So", "qu\u00e4lt", "die", "ster\u00b7bens\u00b7angst", "die", "sin\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mir wird wie einem, dem das schwerd", "tokens": ["Mir", "wird", "wie", "ei\u00b7nem", ",", "dem", "das", "schwerd"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch das erschrockne hertze f\u00e4hrt,", "tokens": ["Durch", "das", "er\u00b7schrock\u00b7ne", "hert\u00b7ze", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem blut und seele will entrinnen;", "tokens": ["Dem", "blut", "und", "see\u00b7le", "will", "ent\u00b7rin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "VVFIN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die augen sehen nichts als nacht;", "tokens": ["Die", "au\u00b7gen", "se\u00b7hen", "nichts", "als", "nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der zungen fehlet alle macht,", "tokens": ["Der", "zun\u00b7gen", "feh\u00b7let", "al\u00b7le", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die trauer-w\u00f6rter vorzubringen;", "tokens": ["Die", "trau\u00b7e\u00b7rw\u00f6r\u00b7ter", "vor\u00b7zu\u00b7brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Der jammer h\u00e4lt der thr\u00e4nen lauff", "tokens": ["Der", "jam\u00b7mer", "h\u00e4lt", "der", "thr\u00e4\u00b7nen", "lauff"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Jtzt wider meinen willen auf,", "tokens": ["Jtzt", "wi\u00b7der", "mei\u00b7nen", "wil\u00b7len", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wie gern ich ihn auch wolt erzwingen.", "tokens": ["Wie", "gern", "ich", "ihn", "auch", "wolt", "er\u00b7zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "So mu\u00df ich wie gefesselt gehen,", "tokens": ["So", "mu\u00df", "ich", "wie", "ge\u00b7fes\u00b7selt", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "KOKOM", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nichts, als die seuffzer sind mir frey,", "tokens": ["Nichts", ",", "als", "die", "seuff\u00b7zer", "sind", "mir", "frey", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "ADJA", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und manchmahl ein verwirrt geschrey,", "tokens": ["Und", "manch\u00b7mahl", "ein", "ver\u00b7wirrt", "ge\u00b7schrey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ich doch selbst nicht kan verstehen.", "tokens": ["Das", "ich", "doch", "selbst", "nicht", "kan", "ver\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "ADV", "ADV", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch soll es heissen: Ach! und weh!", "tokens": ["Doch", "soll", "es", "heis\u00b7sen", ":", "Ach", "!", "und", "weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$.", "ITJ", "$.", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wo ist, wo bleibt die Clelie?", "tokens": ["Wo", "ist", ",", "wo", "bleibt", "die", "Cle\u00b7lie", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "$,", "PWAV", "VVFIN", "ART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Will, oder mu\u00df sie sich entfernen?", "tokens": ["Will", ",", "o\u00b7der", "mu\u00df", "sie", "sich", "ent\u00b7fer\u00b7nen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "KON", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was ist es vor ein ungl\u00fccks-rath,", "tokens": ["Was", "ist", "es", "vor", "ein", "un\u00b7gl\u00fccks\u00b7rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Von welchem sie, gezwungen, hat", "tokens": ["Von", "wel\u00b7chem", "sie", ",", "ge\u00b7zwun\u00b7gen", ",", "hat"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "PRELS", "PPER", "$,", "VVPP", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mich zu verlassen m\u00fcssen lernen?", "tokens": ["Mich", "zu", "ver\u00b7las\u00b7sen", "m\u00fcs\u00b7sen", "ler\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der ort, wo wir uns offt umschlossen,", "tokens": ["Der", "ort", ",", "wo", "wir", "uns", "offt", "um\u00b7schlos\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo ein gespr\u00e4ch, ein schertz, ein spiel,", "tokens": ["Wo", "ein", "ge\u00b7spr\u00e4ch", ",", "ein", "schertz", ",", "ein", "spiel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJD", "$,", "ART", "ADJD", "$,", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Uns gar niemahls beschwerlich fiel,", "tokens": ["Uns", "gar", "nie\u00b7mahls", "be\u00b7schwer\u00b7lich", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Und wo es offt das gras verdrossen,", "tokens": ["Und", "wo", "es", "offt", "das", "gras", "ver\u00b7dros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn wir da ungemein vergn\u00fcgt", "tokens": ["Wenn", "wir", "da", "un\u00b7ge\u00b7mein", "ver\u00b7gn\u00fcgt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den mund dem munde zugef\u00fcgt,", "tokens": ["Den", "mund", "dem", "mun\u00b7de", "zu\u00b7ge\u00b7f\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df jenes ein ger\u00e4usch erreget,", "tokens": ["Da\u00df", "je\u00b7nes", "ein", "ge\u00b7r\u00e4usch", "er\u00b7re\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ART", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "War\u2019s gleich, wiewohl nur uns zum schein,", "tokens": ["Wa\u00b7r's", "gleich", ",", "wie\u00b7wohl", "nur", "uns", "zum", "schein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "KOUS", "ADV", "PPER", "APPRART", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.9": {"text": "Als w\u00fcrd\u2019 es von der lufft beweget;", "tokens": ["Als", "w\u00fcrd'", "es", "von", "der", "lufft", "be\u00b7we\u00b7get", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der ort nun wird es itzt noch wissen,", "tokens": ["Der", "ort", "nun", "wird", "es", "itzt", "noch", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was da ihr unbefleckter mund,", "tokens": ["Was", "da", "ihr", "un\u00b7be\u00b7fleck\u00b7ter", "mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der voller frischer rosen stund,", "tokens": ["Der", "vol\u00b7ler", "fri\u00b7scher", "ro\u00b7sen", "stund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor sch\u00f6ne reden offt lie\u00df fliessen;", "tokens": ["Vor", "sch\u00f6\u00b7ne", "re\u00b7den", "offt", "lie\u00df", "flies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sprach: ich schw\u00f6re bey der macht,", "tokens": ["Sie", "sprach", ":", "ich", "schw\u00f6\u00b7re", "bey", "der", "macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die mich zu lieben hat gebracht,", "tokens": ["Die", "mich", "zu", "lie\u00b7ben", "hat", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKZU", "VVINF", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da\u00df ich nur dir mein hertz will schencken:", "tokens": ["Da\u00df", "ich", "nur", "dir", "mein", "hertz", "will", "schen\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und werd\u2019 ich wo dawider thun;", "tokens": ["Und", "werd'", "ich", "wo", "da\u00b7wi\u00b7der", "thun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PWAV", "PAV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So soll kein segen auf mir ruhn,", "tokens": ["So", "soll", "kein", "se\u00b7gen", "auf", "mir", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIAT", "NN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Noch dessen thau mein blum-werck tr\u00e4ncken.", "tokens": ["Noch", "des\u00b7sen", "thau", "mein", "blum\u00b7\u00b7werck", "tr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ja, hat es dieser ort vergessen;", "tokens": ["Ja", ",", "hat", "es", "die\u00b7ser", "ort", "ver\u00b7ges\u00b7sen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VAFIN", "PPER", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So ist nicht weit ein bircken-wald,", "tokens": ["So", "ist", "nicht", "weit", "ein", "bir\u00b7cken\u00b7wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "ADJD", "ART", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In dessen k\u00fchlen aufenthalt", "tokens": ["In", "des\u00b7sen", "k\u00fch\u00b7len", "auf\u00b7ent\u00b7halt"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wir \u00f6ffters und mit lust gesessen,", "tokens": ["Wir", "\u00f6ff\u00b7ters", "und", "mit", "lust", "ge\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "KON", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.5": {"text": "Da wird den rinden eingehaun", "tokens": ["Da", "wird", "den", "rin\u00b7den", "ein\u00b7ge\u00b7haun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Man die versicherungen schaun,", "tokens": ["Man", "die", "ver\u00b7si\u00b7che\u00b7run\u00b7gen", "schaun", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und in den jungen bircken-rinden", "tokens": ["Und", "in", "den", "jun\u00b7gen", "bir\u00b7cken\u00b7rin\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wird man das wort: Di\u00df ist mein schlu\u00df,", "tokens": ["Wird", "man", "das", "wort", ":", "Di\u00df", "ist", "mein", "schlu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "$.", "PDS", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df ich den Criton haben mu\u00df;", "tokens": ["Da\u00df", "ich", "den", "Cri\u00b7ton", "ha\u00b7ben", "mu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Durch ihre hand geschnitten, finden.", "tokens": ["Durch", "ih\u00b7re", "hand", "ge\u00b7schnit\u00b7ten", ",", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ach! d\u00e4chte sie an diese rinden,", "tokens": ["Ach", "!", "d\u00e4ch\u00b7te", "sie", "an", "die\u00b7se", "rin\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "APPR", "PDAT", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die itzund \u00fcber meiner pein", "tokens": ["Die", "it\u00b7zund", "\u00fc\u00b7ber", "mei\u00b7ner", "pein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Aus beyleid h\u00f6chst betr\u00fcbet seyn,", "tokens": ["Aus", "bey\u00b7leid", "h\u00f6chst", "be\u00b7tr\u00fc\u00b7bet", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und meinen schmertzen mit empfinden;", "tokens": ["Und", "mei\u00b7nen", "schmert\u00b7zen", "mit", "emp\u00b7fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So w\u00fcrde durch die leere lufft", "tokens": ["So", "w\u00fcr\u00b7de", "durch", "die", "lee\u00b7re", "lufft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von ihr vielleicht mir zugeruft,", "tokens": ["Von", "ihr", "viel\u00b7leicht", "mir", "zu\u00b7ge\u00b7ruft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es w\u00fcrd\u2019 ein lispeln um mich schweben", "tokens": ["Es", "w\u00fcrd'", "ein", "lis\u00b7peln", "um", "mich", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PPER", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und mir, wie da\u00df noch ihre treu", "tokens": ["Und", "mir", ",", "wie", "da\u00df", "noch", "ih\u00b7re", "treu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$,", "KOKOM", "KOUS", "ADV", "PPOSAT", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und liebe nicht entheiligt sey;", "tokens": ["Und", "lie\u00b7be", "nicht", "en\u00b7thei\u00b7ligt", "sey", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Gantz deutlich zu verstehen geben.", "tokens": ["Gantz", "deut\u00b7lich", "zu", "ver\u00b7ste\u00b7hen", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "So aber ist es nur vergebens,", "tokens": ["So", "a\u00b7ber", "ist", "es", "nur", "ver\u00b7ge\u00b7bens", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bleibe g\u00e4ntzlich ausgethan.", "tokens": ["Ich", "blei\u00b7be", "g\u00e4ntz\u00b7lich", "aus\u00b7ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn de\u00df ich mich getr\u00f6sten kan,", "tokens": ["Denn", "de\u00df", "ich", "mich", "ge\u00b7tr\u00f6s\u00b7ten", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist blos das ende meines lebens.", "tokens": ["Ist", "blos", "das", "en\u00b7de", "mei\u00b7nes", "le\u00b7bens", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es kan alsdenn mein leichen-stein", "tokens": ["Es", "kan", "als\u00b7denn", "mein", "lei\u00b7chen\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit dieser schrifft bezeichnet seyn:", "tokens": ["Mit", "die\u00b7ser", "schrifft", "be\u00b7zeich\u00b7net", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hier lieget lieb und treu begraben.", "tokens": ["Hier", "lie\u00b7get", "lieb", "und", "treu", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und welcher im vor\u00fcber gehn", "tokens": ["Und", "wel\u00b7cher", "im", "vor\u00b7\u00fc\u00b7ber", "gehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PRELS", "APPRART", "ADV", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Hieraus wird meinen tod verstehn,", "tokens": ["Hier\u00b7aus", "wird", "mei\u00b7nen", "tod", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Der wird mit mir erbarmung haben;", "tokens": ["Der", "wird", "mit", "mir", "er\u00b7bar\u00b7mung", "ha\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Doch eh ich noch die augen schliessen;", "tokens": ["Doch", "eh", "ich", "noch", "die", "au\u00b7gen", "schlies\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und meiner schmertzen end und ziel", "tokens": ["Und", "mei\u00b7ner", "schmert\u00b7zen", "end", "und", "ziel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bey euch, ihr leichen! suchen will;", "tokens": ["Bey", "euch", ",", "ihr", "lei\u00b7chen", "!", "su\u00b7chen", "will", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPER", "VVINF", "$.", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So sollen vorher alle wissen,", "tokens": ["So", "sol\u00b7len", "vor\u00b7her", "al\u00b7le", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df, ob ich gleich um ihre zier", "tokens": ["Da\u00df", ",", "ob", "ich", "gleich", "um", "ih\u00b7re", "zier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In rein-gesinnter liebs-begier", "tokens": ["In", "rein\u00b7ge\u00b7sinn\u00b7ter", "liebs\u00b7be\u00b7gier"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mich fast zu tode hier mu\u00df kr\u00e4ncken,", "tokens": ["Mich", "fast", "zu", "to\u00b7de", "hier", "mu\u00df", "kr\u00e4n\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "NN", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich doch um ihres leibes wohl,", "tokens": ["Ich", "doch", "um", "ih\u00b7res", "lei\u00b7bes", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und was sie sonst vergn\u00fcgen soll,", "tokens": ["Und", "was", "sie", "sonst", "ver\u00b7gn\u00fc\u00b7gen", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Zum himmel will die augen lencken.", "tokens": ["Zum", "him\u00b7mel", "will", "die", "au\u00b7gen", "len\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich will vor ihre blumen-wangen", "tokens": ["Ich", "will", "vor", "ih\u00b7re", "blu\u00b7men\u00b7wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bey allen winden b\u00fcrge seyn,", "tokens": ["Bey", "al\u00b7len", "win\u00b7den", "b\u00fcr\u00b7ge", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df nicht ihr rosen-lichter schein", "tokens": ["Da\u00df", "nicht", "ihr", "ro\u00b7sen\u00b7lich\u00b7ter", "schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Woll\u2019 ihnen zum gesp\u00f6tte prangen,", "tokens": ["Woll'", "ih\u00b7nen", "zum", "ge\u00b7sp\u00f6t\u00b7te", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Damit sich selbe nicht bem\u00fchn,", "tokens": ["Da\u00b7mit", "sich", "sel\u00b7be", "nicht", "be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADJA", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den purpur ihnen abzuziehn,", "tokens": ["Den", "pur\u00b7pur", "ih\u00b7nen", "ab\u00b7zu\u00b7ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Noch ihre blumen zu entbl\u00e4ttern;", "tokens": ["Noch", "ih\u00b7re", "blu\u00b7men", "zu", "ent\u00b7bl\u00e4t\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die andern blumen, gras und laub", "tokens": ["Die", "an\u00b7dern", "blu\u00b7men", ",", "gras", "und", "laub"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Nehmt, o ihr wind\u2019! als euren raub;", "tokens": ["Nehmt", ",", "o", "ihr", "wind'", "!", "als", "eu\u00b7ren", "raub", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "FM", "PPOSAT", "NN", "$.", "KOUS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Hier aber schont mit harten wettern!", "tokens": ["Hier", "a\u00b7ber", "schont", "mit", "har\u00b7ten", "wet\u00b7tern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "O unerbittliches geschicke!", "tokens": ["O", "un\u00b7er\u00b7bitt\u00b7li\u00b7ches", "ge\u00b7schi\u00b7cke", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00df ja dem wunsch ein gn\u00fcgen thun!", "tokens": ["La\u00df", "ja", "dem", "wunsch", "ein", "gn\u00fc\u00b7gen", "thun", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "ART", "NN", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sonst kan ich nicht im grabe ruhn,", "tokens": ["Sonst", "kan", "ich", "nicht", "im", "gra\u00b7be", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PTKNEG", "APPRART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und komm aus jener welt zur\u00fccke;", "tokens": ["Und", "komm", "aus", "je\u00b7ner", "welt", "zu\u00b7r\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wiewohl, wo ich vorm tode darff,", "tokens": ["Wie\u00b7wohl", ",", "wo", "ich", "vorm", "to\u00b7de", "darff", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "PPER", "APPRART", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und dessen satzung nicht zu scharff,", "tokens": ["Und", "des\u00b7sen", "sat\u00b7zung", "nicht", "zu", "scharff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wird ohnedem mein leichter schatten", "tokens": ["Wird", "oh\u00b7ne\u00b7dem", "mein", "leich\u00b7ter", "schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PAV", "PPOSAT", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Aufsuchen dieses sch\u00f6ne kind,", "tokens": ["Auf\u00b7su\u00b7chen", "die\u00b7ses", "sch\u00f6\u00b7ne", "kind", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Um sich, so bald er es nur findt,", "tokens": ["Um", "sich", ",", "so", "bald", "er", "es", "nur", "findt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "$,", "ADV", "ADV", "PPER", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Mit seiner fleischlichkeit zu gatten.", "tokens": ["Mit", "sei\u00b7ner", "fleischlich\u00b7keit", "zu", "gat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}