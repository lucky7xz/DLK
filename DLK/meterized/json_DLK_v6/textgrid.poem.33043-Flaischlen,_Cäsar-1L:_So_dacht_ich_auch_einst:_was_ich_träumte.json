{"textgrid.poem.33043": {"metadata": {"author": {"name": "Flaischlen, C\u00e4sar", "birth": "N.A.", "death": "N.A."}, "title": "1L: So dacht ich auch einst: was ich tr\u00e4umte", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So dacht ich auch einst: was ich tr\u00e4umte", "tokens": ["So", "dacht", "ich", "auch", "einst", ":", "was", "ich", "tr\u00e4um\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "$.", "PWS", "PPER", "VVFIN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "in Fr\u00fchlingsf\u00fclle m\u00fcsse es ein Mai", "tokens": ["in", "Fr\u00fch\u00b7lings\u00b7f\u00fcl\u00b7le", "m\u00fcs\u00b7se", "es", "ein", "Mai"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "aussch\u00fctten \u00fcber mich aus goldenem Horn", "tokens": ["aus\u00b7sch\u00fct\u00b7ten", "\u00fc\u00b7ber", "mich", "aus", "gol\u00b7de\u00b7nem", "Horn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "und eines Morgens oder eines Abends m\u00fc\u00dften", "tokens": ["und", "ei\u00b7nes", "Mor\u00b7gens", "o\u00b7der", "ei\u00b7nes", "A\u00b7bends", "m\u00fc\u00df\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "KON", "ART", "NN", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "pl\u00f6tzlich", "tokens": ["pl\u00f6tz\u00b7lich"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "die Berge auseinandergehn, durch die ich rang,", "tokens": ["die", "Ber\u00b7ge", "aus\u00b7ein\u00b7an\u00b7der\u00b7gehn", ",", "durch", "die", "ich", "rang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "und alles k\u00f6stlich in Erf\u00fcllung stehn,", "tokens": ["und", "al\u00b7les", "k\u00f6st\u00b7lich", "in", "Er\u00b7f\u00fcl\u00b7lung", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "in Glanz und Klang.", "tokens": ["in", "Glanz", "und", "Klang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Und Jahr um Jahr kam und verrann", "tokens": ["Und", "Jahr", "um", "Jahr", "kam", "und", "ver\u00b7rann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und Ferne \u00fcber Ferne h\u00fcllte", "tokens": ["und", "Fer\u00b7ne", "\u00fc\u00b7ber", "Fer\u00b7ne", "h\u00fcll\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sich auf ... nicht eine aber erf\u00fcllte,", "tokens": ["sich", "auf", "...", "nicht", "ei\u00b7ne", "a\u00b7ber", "er\u00b7f\u00fcll\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "$(", "PTKNEG", "ART", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "was meine Sehnsucht hinter ihre Schleier spann!", "tokens": ["was", "mei\u00b7ne", "Sehn\u00b7sucht", "hin\u00b7ter", "ih\u00b7re", "Schlei\u00b7er", "spann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nun wart ich l\u00e4ngst nicht mehr", "tokens": ["Nun", "wart", "ich", "l\u00e4ngst", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "auf solche M\u00e4rchentage", "tokens": ["auf", "sol\u00b7che", "M\u00e4r\u00b7chen\u00b7ta\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "und glaube wie ein t\u00f6richt Kind", "tokens": ["und", "glau\u00b7be", "wie", "ein", "t\u00f6\u00b7richt", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mein bestes K\u00f6nnen in den Wind!", "tokens": ["mein", "bes\u00b7tes", "K\u00f6n\u00b7nen", "in", "den", "Wind", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ich will vom Leben nichts geschenkt mehr haben!", "tokens": ["Ich", "will", "vom", "Le\u00b7ben", "nichts", "ge\u00b7schenkt", "mehr", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PIS", "VVPP", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ich schaff mir selbst, was ich mir w\u00fcnsche!", "tokens": ["ich", "schaff", "mir", "selbst", ",", "was", "ich", "mir", "w\u00fcn\u00b7sche", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Tat ist Erf\u00fcllung, nicht Gebet:", "tokens": ["Tat", "ist", "Er\u00b7f\u00fcl\u00b7lung", ",", "nicht", "Ge\u00b7bet", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,", "PTKNEG", "NN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die Ferne reift nur, was die N\u00e4he s\u00e4t!", "tokens": ["die", "Fer\u00b7ne", "reift", "nur", ",", "was", "die", "N\u00e4\u00b7he", "s\u00e4t", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ich nehme mir, was ich vom Leben will ...", "tokens": ["Ich", "neh\u00b7me", "mir", ",", "was", "ich", "vom", "Le\u00b7ben", "will", "..."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWS", "PPER", "APPRART", "NN", "VMFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ich will vielleicht so viel nicht mehr wie fr\u00fcher,", "tokens": ["ich", "will", "viel\u00b7leicht", "so", "viel", "nicht", "mehr", "wie", "fr\u00fc\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV", "PTKNEG", "ADV", "KOKOM", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "doch lachend steht es und h\u00e4lt still", "tokens": ["doch", "la\u00b7chend", "steht", "es", "und", "h\u00e4lt", "still"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "KON", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und bl\u00fcht mir seinen \u00dcberflu\u00df entgegen", "tokens": ["und", "bl\u00fcht", "mir", "sei\u00b7nen", "\u00dc\u00b7berf\u00b7lu\u00df", "ent\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "in reicherer F\u00fclle, als ich je getr\u00e4umt!", "tokens": ["in", "rei\u00b7che\u00b7rer", "F\u00fcl\u00b7le", ",", "als", "ich", "je", "ge\u00b7tr\u00e4umt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}}}}