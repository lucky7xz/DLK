{"dta.poem.7591": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "6.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1836", "urn": "urn:nbn:de:kobv:b4-200905195073", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wenn du das dicke Buch durchbl\u00e4tterst der Geschichte,", "tokens": ["Wenn", "du", "das", "di\u00b7cke", "Buch", "durch\u00b7bl\u00e4t\u00b7terst", "der", "Ge\u00b7schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du findest wiederholt auf jedem Blatt Berichte", "tokens": ["Du", "fin\u00b7dest", "wie\u00b7der\u00b7holt", "auf", "je\u00b7dem", "Blatt", "Be\u00b7rich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Von widerw\u00e4rt'gem Kampf und greulichem Verrath,", "tokens": ["Von", "wi\u00b7der\u00b7w\u00e4rt'\u00b7gem", "Kampf", "und", "greu\u00b7li\u00b7chem", "Ver\u00b7rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und selbst auf dunklem Grund steht jede lichte That.", "tokens": ["Und", "selbst", "auf", "dunk\u00b7lem", "Grund", "steht", "je\u00b7de", "lich\u00b7te", "That", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Und auch des Dichters Kunst, die sich die freie nennt,", "tokens": ["Und", "auch", "des", "Dich\u00b7ters", "Kunst", ",", "die", "sich", "die", "frei\u00b7e", "nennt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "$,", "PRELS", "PRF", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch knechtisch hinterdrein nur der Geschichte rennt.", "tokens": ["Doch", "knech\u00b7tisch", "hin\u00b7ter\u00b7drein", "nur", "der", "Ge\u00b7schich\u00b7te", "rennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wei\u00df auch nichts Besseres zu unserem Ergetzen,", "tokens": ["Wei\u00df", "auch", "nichts", "Bes\u00b7se\u00b7res", "zu", "un\u00b7se\u00b7rem", "Er\u00b7get\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "PIS", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als n\u00e4chtliches Geschick und blutiges Entsetzen.", "tokens": ["Als", "n\u00e4cht\u00b7li\u00b7ches", "Ge\u00b7schick", "und", "blu\u00b7ti\u00b7ges", "Ent\u00b7set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Als sei von Gottes Welt nur dieses vorzuzeigen,", "tokens": ["Als", "sei", "von", "Got\u00b7tes", "Welt", "nur", "die\u00b7ses", "vor\u00b7zu\u00b7zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "APPR", "NN", "NN", "ADV", "PDAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was man ehr sollt' aus ihr vertilgen durch Verschweigen.", "tokens": ["Was", "man", "ehr", "sollt'", "aus", "ihr", "ver\u00b7til\u00b7gen", "durch", "Ver\u00b7schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "NN", "VMFIN", "APPR", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.6": {"line.1": {"text": "Als sei in der Natur nur Frost und Hagelschlag,", "tokens": ["Als", "sei", "in", "der", "Na\u00b7tur", "nur", "Frost", "und", "Ha\u00b7gel\u00b7schlag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "APPR", "ART", "NN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und gift'ger Raupenfra\u00df, kein bl\u00fchnder Rosenhag;", "tokens": ["Und", "gift'\u00b7ger", "Rau\u00b7pen\u00b7fra\u00df", ",", "kein", "bl\u00fchn\u00b7der", "Ro\u00b7sen\u00b7hag", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Und in des Menschen Haus nur Krankenstubenjammer,", "tokens": ["Und", "in", "des", "Men\u00b7schen", "Haus", "nur", "Kran\u00b7ken\u00b7stu\u00b7ben\u00b7jam\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Kindertummelplatz und keine Hochzeitkammer.", "tokens": ["Kein", "Kin\u00b7der\u00b7tum\u00b7mel\u00b7platz", "und", "kei\u00b7ne", "Hoch\u00b7zeit\u00b7kam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die Weichlichkeit ist schlecht, der Leichtsinn ist nicht gut,", "tokens": ["Die", "Weich\u00b7lich\u00b7keit", "ist", "schlecht", ",", "der", "Leicht\u00b7sinn", "ist", "nicht", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch noth ist heitrer Ernst und froher Lebensmuth.", "tokens": ["Doch", "noth", "ist", "hei\u00b7trer", "Ernst", "und", "fro\u00b7her", "Le\u00b7bens\u00b7muth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Des Schattens kann im Bild entbehren nicht die Kunst,", "tokens": ["Des", "Schat\u00b7tens", "kann", "im", "Bild", "ent\u00b7beh\u00b7ren", "nicht", "die", "Kunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "APPRART", "NN", "VVFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch ist ihr Element das Licht, und nicht der Dunst.", "tokens": ["Doch", "ist", "ihr", "E\u00b7le\u00b7ment", "das", "Licht", ",", "und", "nicht", "der", "Dunst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ART", "NN", "$,", "KON", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Mag die Geschichte nicht des traur'gen Amts entbehren,", "tokens": ["Mag", "die", "Ge\u00b7schich\u00b7te", "nicht", "des", "traur'\u00b7gen", "Amts", "ent\u00b7beh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da\u00df durch Unmenschliches sie uns will Menschheit lehren;", "tokens": ["Da\u00df", "durch", "Un\u00b7menschli\u00b7ches", "sie", "uns", "will", "Menschheit", "leh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "PPER", "PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "O Fantasie wenn du die Bl\u00fcte willst entfalten", "tokens": ["O", "Fan\u00b7ta\u00b7sie", "wenn", "du", "die", "Bl\u00fc\u00b7te", "willst", "ent\u00b7fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "KOUS", "PPER", "ART", "NN", "VMFIN", "VVINF"], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Menschheit, sollst du ihr kein Jammerbild vorhalten.", "tokens": ["Der", "Menschheit", ",", "sollst", "du", "ihr", "kein", "Jam\u00b7mer\u00b7bild", "vor\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VMFIN", "PPER", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "--+-+-+-+-+-", "measure": "anapaest.init"}}}}}