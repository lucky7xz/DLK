{"textgrid.poem.40096": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich habe Alles euch gegeben,", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe Alles euch gegeben,", "tokens": ["Ich", "ha\u00b7be", "Al\u00b7les", "euch", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "nun wollt ihr auch das Letzte noch:", "tokens": ["nun", "wollt", "ihr", "auch", "das", "Letz\u00b7te", "noch", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "ADJA", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "nun soll ich knechten auch mein Streben,", "tokens": ["nun", "soll", "ich", "knech\u00b7ten", "auch", "mein", "Stre\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zertreten mich f\u00fcr euer Joch?", "tokens": ["zer\u00b7tre\u00b7ten", "mich", "f\u00fcr", "eu\u00b7er", "Joch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich hab' in mir um euch gerungen,", "tokens": ["Ich", "hab'", "in", "mir", "um", "euch", "ge\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "f\u00fcr ", "tokens": ["f\u00fcr"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Stolz, Liebe, Ha\u00df um euch bezwungen:", "tokens": ["Stolz", ",", "Lie\u00b7be", ",", "Ha\u00df", "um", "euch", "be\u00b7zwun\u00b7gen", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "nun danket ihr nach altem Brauch!", "tokens": ["nun", "dan\u00b7ket", "ihr", "nach", "al\u00b7tem", "Brauch", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Nun soll ich feige das Gef\u00fcge,", "tokens": ["Nun", "soll", "ich", "fei\u00b7ge", "das", "Ge\u00b7f\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dran mitzur\u00fcsten ich geweiht,", "tokens": ["dran", "mit\u00b7zu\u00b7r\u00fcs\u00b7ten", "ich", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "verleugnen f\u00fcr die gro\u00dfe L\u00fcge,", "tokens": ["ver\u00b7leug\u00b7nen", "f\u00fcr", "die", "gro\u00b7\u00dfe", "L\u00fc\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "an der sich jetzt berauscht die Zeit?!", "tokens": ["an", "der", "sich", "jetzt", "be\u00b7rauscht", "die", "Zeit", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ja, eine Zeit ", "tokens": ["Ja", ",", "ei\u00b7ne", "Zeit"], "token_info": ["word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "f\u00fcr jeden engsten Kreis ist heut", "tokens": ["f\u00fcr", "je\u00b7den", "engs\u00b7ten", "Kreis", "ist", "heut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein neuer Heiland uns von N\u00f6ten:", "tokens": ["ein", "neu\u00b7er", "Hei\u00b7land", "uns", "von", "N\u00f6\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "der alte ", "tokens": ["der", "al\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.5": {"line.1": {"text": "Doch nicht, da\u00df man aus Luggeweben", "tokens": ["Doch", "nicht", ",", "da\u00df", "man", "aus", "Lug\u00b7ge\u00b7we\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "$,", "KOUS", "PIS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die Dornenkrone selbst sich flicht:", "tokens": ["die", "Dor\u00b7nen\u00b7kro\u00b7ne", "selbst", "sich", "flicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich habe Alles euch gegeben,", "tokens": ["ich", "ha\u00b7be", "Al\u00b7les", "euch", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch mein Gewissen geb' ich nicht!", "tokens": ["doch", "mein", "Ge\u00b7wis\u00b7sen", "geb'", "ich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}