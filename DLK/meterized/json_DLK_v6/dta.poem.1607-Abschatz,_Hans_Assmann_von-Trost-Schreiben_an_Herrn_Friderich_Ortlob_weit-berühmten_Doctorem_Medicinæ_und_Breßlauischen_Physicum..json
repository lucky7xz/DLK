{"dta.poem.1607": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Trost-Schreiben an Herrn Friderich Ortlob/  \n weit-ber\u00fchmten  Doctorem Medicin\u00e6  und  \n Bre\u00dflauischen  Physicum.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Mein Freund/ des HErren Hand hat ihn wohl harte trof-\nfen/ ", "tokens": ["Mein", "Freund", "/", "des", "Her\u00b7ren", "Hand", "hat", "ihn", "wohl", "har\u00b7te", "trof", "fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "ART", "NN", "NN", "VAFIN", "PPER", "ADV", "ADJA", "TRUNC", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Indem die liebsten Zwey von seiner Seite ziehn.", "tokens": ["In\u00b7dem", "die", "liebs\u00b7ten", "Zwey", "von", "sei\u00b7ner", "Sei\u00b7te", "ziehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo \u00e4usserlicher Schein hie\u00df langes Leben hoffen/", "tokens": ["Wo", "\u00e4us\u00b7ser\u00b7li\u00b7cher", "Schein", "hie\u00df", "lan\u00b7ges", "Le\u00b7ben", "hof\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das ri\u00df der fr\u00fche Tod/ eh mans gedacht/ dahin.", "tokens": ["Das", "ri\u00df", "der", "fr\u00fc\u00b7he", "Tod", "/", "eh", "mans", "ge\u00b7dacht", "/", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$(", "KOUS", "PIS", "VVPP", "$(", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was treue Br\u00fcder-Lieb und Einigkeit verbunden/", "tokens": ["Was", "treu\u00b7e", "Br\u00fc\u00b7der\u00b7Lieb", "und", "Ei\u00b7nig\u00b7keit", "ver\u00b7bun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "KON", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "(ein sch\u00f6n und seltnes Gutt) wird unvermutt getrennt.", "tokens": ["(", "ein", "sch\u00f6n", "und", "selt\u00b7nes", "Gutt", ")", "wird", "un\u00b7ver\u00b7mutt", "ge\u00b7trennt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJD", "KON", "ADJA", "NN", "$(", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was aber reiss\u2019 ich auff die kaum verharschten Wunden/", "tokens": ["Was", "a\u00b7ber", "reiss'", "ich", "auff", "die", "kaum", "ver\u00b7harschten", "Wun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVFIN", "PPER", "APPR", "ART", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wenn noch ein neuer Leyd in heisser Wehmutt brennt?", "tokens": ["Wenn", "noch", "ein", "neu\u00b7er", "Leyd", "in", "heis\u00b7ser", "Weh\u00b7mutt", "brennt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der Seelen halbes Theil von GOttes Hand ger\u00fchret/", "tokens": ["Der", "See\u00b7len", "hal\u00b7bes", "Theil", "von", "Got\u00b7tes", "Hand", "ge\u00b7r\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weist schon ein Ebenbild der blassen Leichen aus.", "tokens": ["Weist", "schon", "ein", "E\u00b7ben\u00b7bild", "der", "blas\u00b7sen", "Lei\u00b7chen", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es wird durch treuen Flei\u00df was Besserung gesp\u00fcret/", "tokens": ["Es", "wird", "durch", "treu\u00b7en", "Flei\u00df", "was", "Bes\u00b7se\u00b7rung", "ge\u00b7sp\u00fc\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "PWS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dar\u00fcber st\u00e4rcket sich mit ihr das gantze Hau\u00df.", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "st\u00e4r\u00b7cket", "sich", "mit", "ihr", "das", "gant\u00b7ze", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "APPR", "PPOSAT", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Verwandt-Bekandter hofft ein v\u00f6lliges Genesen/", "tokens": ["Ver\u00b7wandt\u00b7Be\u00b7kand\u00b7ter", "hofft", "ein", "v\u00f6l\u00b7li\u00b7ges", "Ge\u00b7ne\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und bildet ihm annoch ein langes Wohlseyn ein;", "tokens": ["Und", "bil\u00b7det", "ihm", "an\u00b7noch", "ein", "lan\u00b7ges", "Wohl\u00b7seyn", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Er aber/ der versteht wie die Gefahr gewesen/", "tokens": ["Er", "a\u00b7ber", "/", "der", "ver\u00b7steht", "wie", "die", "Ge\u00b7fahr", "ge\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "ART", "VVFIN", "KOKOM", "ART", "NN", "VAPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kan nimmer ohne Leyd und stille Sorgen seyn.", "tokens": ["Kan", "nim\u00b7mer", "oh\u00b7ne", "Leyd", "und", "stil\u00b7le", "Sor\u00b7gen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "KON", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Sein eigner Leib empfindt/ wie er von andern jage", "tokens": ["Sein", "eig\u00b7ner", "Leib", "emp\u00b7findt", "/", "wie", "er", "von", "an\u00b7dern", "ja\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$(", "PWAV", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch Kunst und GOttes Gunst/ was seinem Hause stellt/", "tokens": ["Durch", "Kunst", "und", "Got\u00b7tes", "Gunst", "/", "was", "sei\u00b7nem", "Hau\u00b7se", "stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "NN", "$(", "PWS", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie er den Samen de\u00df/ gleich andern/ bey sich trage/", "tokens": ["Wie", "er", "den", "Sa\u00b7men", "de\u00df", "/", "gleich", "an\u00b7dern", "/", "bey", "sich", "tra\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ART", "$(", "ADV", "ADJA", "$(", "APPR", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Worwider doch kein Kraut zu finden in der Welt.", "tokens": ["Wor\u00b7wi\u00b7der", "doch", "kein", "Kraut", "zu", "fin\u00b7den", "in", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der vor-erwehnte Fall mu\u00df solchen Schmertz vermehren/", "tokens": ["Der", "vor\u00b7er\u00b7wehn\u00b7te", "Fall", "mu\u00df", "sol\u00b7chen", "Schmertz", "ver\u00b7meh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bi\u00df GOttes Hand numehr noch einmahl wiederk\u00fcmmt/", "tokens": ["Bi\u00df", "Got\u00b7tes", "Hand", "nu\u00b7mehr", "noch", "ein\u00b7mahl", "wie\u00b7der\u00b7k\u00fcmmt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "ADV", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wir mitleidig die betr\u00fcbte Zeitung h\u00f6ren/", "tokens": ["Und", "wir", "mit\u00b7lei\u00b7dig", "die", "be\u00b7tr\u00fcb\u00b7te", "Zei\u00b7tung", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADJD", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da\u00df sie das liebste Pfand aus seinen Armen nimmt.", "tokens": ["Da\u00df", "sie", "das", "liebs\u00b7te", "Pfand", "aus", "sei\u00b7nen", "Ar\u00b7men", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Den Epheu kan man nicht aus seiner Mauer bringen/", "tokens": ["Den", "E\u00b7pheu", "kan", "man", "nicht", "aus", "sei\u00b7ner", "Mau\u00b7er", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIS", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df nicht in selbiger die tieffe Narbe bleibt:", "tokens": ["Da\u00df", "nicht", "in", "sel\u00b7bi\u00b7ger", "die", "tief\u00b7fe", "Nar\u00b7be", "bleibt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "APPR", "ADJA", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie wolte Thr\u00e4nen-Blutt nicht aus dem Hertzen springen/", "tokens": ["Wie", "wol\u00b7te", "Thr\u00e4\u00b7nen\u00b7Blutt", "nicht", "aus", "dem", "Hert\u00b7zen", "sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "PTKNEG", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Von dem der Keil der Noth das Angewach\u00dfne treibt!", "tokens": ["Von", "dem", "der", "Keil", "der", "Noth", "das", "An\u00b7ge\u00b7wach\u00df\u00b7ne", "treibt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Die wahre Gottesfurcht/ der Geist voll Andachts-Flamme/", "tokens": ["Die", "wah\u00b7re", "Got\u00b7tes\u00b7furcht", "/", "der", "Geist", "voll", "An\u00b7dachts\u00b7Flam\u00b7me", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die treue H\u00e4u\u00dfligkeit mu\u00df nun vermisset seyn;", "tokens": ["Die", "treu\u00b7e", "H\u00e4u\u00df\u00b7lig\u00b7keit", "mu\u00df", "nun", "ver\u00b7mis\u00b7set", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Freund/ des Armen Mund beklagt die Wohlthats-", "tokens": ["Der", "Freund", "/", "des", "Ar\u00b7men", "Mund", "be\u00b7klagt", "die", "Wohl\u00b7thats"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "NN", "NN", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Spiegel der Gedult verlieret seinen Schein.", "tokens": ["Der", "Spie\u00b7gel", "der", "Ge\u00b7dult", "ver\u00b7lie\u00b7ret", "sei\u00b7nen", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Der treu-erkandte Sinn/ der immer gleiche Wille/", "tokens": ["Der", "treu\u00b7er\u00b7kand\u00b7te", "Sinn", "/", "der", "im\u00b7mer", "glei\u00b7che", "Wil\u00b7le", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sezt numehr von ihm ab/ will izt nicht/ was er will.", "tokens": ["Sezt", "nu\u00b7mehr", "von", "ihm", "ab", "/", "will", "izt", "nicht", "/", "was", "er", "will", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "PTKVZ", "$(", "VMFIN", "ADV", "PTKNEG", "$(", "PWS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Tages Einsamkeit/ der Nacht betr\u00fcbte Stille", "tokens": ["Des", "Ta\u00b7ges", "Ein\u00b7sam\u00b7keit", "/", "der", "Nacht", "be\u00b7tr\u00fcb\u00b7te", "Stil\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$(", "ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Steckt seinem Leyd kein Maa\u00df/ und seiner Angst kein Ziel.", "tokens": ["Steckt", "sei\u00b7nem", "Leyd", "kein", "Maa\u00df", "/", "und", "sei\u00b7ner", "Angst", "kein", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PIAT", "NN", "$(", "KON", "PPOSAT", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Wir sind nicht Felsen-Art/ da\u00df wir nicht f\u00fchlen solten/", "tokens": ["Wir", "sind", "nicht", "Fel\u00b7sen\u00b7Art", "/", "da\u00df", "wir", "nicht", "f\u00fch\u00b7len", "sol\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "$(", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn unser Hertze wird von solchem Weh beklemmt:", "tokens": ["Wenn", "un\u00b7ser", "Hert\u00b7ze", "wird", "von", "sol\u00b7chem", "Weh", "be\u00b7klemmt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VAFIN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wenn wir/ als erstarrt/ die Schmertzen bergen wolten/", "tokens": ["Und", "wenn", "wir", "/", "als", "er\u00b7starrt", "/", "die", "Schmert\u00b7zen", "ber\u00b7gen", "wol\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "$(", "KOKOM", "VVFIN", "$(", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00fcrden sie doch nur auff eine Zeit gehemmt.", "tokens": ["So", "w\u00fcr\u00b7den", "sie", "doch", "nur", "auff", "ei\u00b7ne", "Zeit", "ge\u00b7hemmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Jedennoch m\u00fcssen wir in Thr\u00e4nen nicht zerrinnen/", "tokens": ["Je\u00b7den\u00b7noch", "m\u00fcs\u00b7sen", "wir", "in", "Thr\u00e4\u00b7nen", "nicht", "zer\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Z\u00e4hren m\u00fcssen uns nicht selber zehren auff:", "tokens": ["Die", "Z\u00e4h\u00b7ren", "m\u00fcs\u00b7sen", "uns", "nicht", "sel\u00b7ber", "zeh\u00b7ren", "auff", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "ADV", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wir k\u00fcnnen doch dadurch vom Tode nichts gewinnen/", "tokens": ["Wir", "k\u00fcn\u00b7nen", "doch", "da\u00b7durch", "vom", "To\u00b7de", "nichts", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PAV", "APPRART", "NN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verk\u00fcrtzen uns nur selbst den kurtzen Lebens-Lauff.", "tokens": ["Ver\u00b7k\u00fcrt\u00b7zen", "uns", "nur", "selbst", "den", "kurt\u00b7zen", "Le\u00b7bens\u00b7Lauff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wer aber nun erg\u00e4nzt die Wunden in dem Hertzen?", "tokens": ["Wer", "a\u00b7ber", "nun", "er\u00b7g\u00e4nzt", "die", "Wun\u00b7den", "in", "dem", "Hert\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die/ aller Urtheil nach/ vor t\u00f6dtlich sind erkandt.", "tokens": ["Die", "/", "al\u00b7ler", "Ur\u00b7theil", "nach", "/", "vor", "t\u00f6dt\u00b7lich", "sind", "er\u00b7kandt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "PIAT", "NN", "APPR", "$(", "APPR", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Welch Julep k\u00fchlet ab die hei\u00df-entbrannten Schmertzen?", "tokens": ["Welch", "Ju\u00b7lep", "k\u00fch\u00b7let", "ab", "die", "hei\u00df\u00b7ent\u00b7brann\u00b7ten", "Schmert\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Welch Mittel/ welcher Arzt/ wird n\u00fctzlich angewandt?", "tokens": ["Welch", "Mit\u00b7tel", "/", "wel\u00b7cher", "Arzt", "/", "wird", "n\u00fctz\u00b7lich", "an\u00b7ge\u00b7wandt", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PWAT", "NN", "$(", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Kein Heydnisch Wundkraut heilt dergleichen s\u00fcchtge Wunden/", "tokens": ["Kein", "Heyd\u00b7nisch", "Wund\u00b7kraut", "heilt", "derg\u00b7lei\u00b7chen", "s\u00fccht\u00b7ge", "Wun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "PIS", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Pflaster vom Parna\u00df/ kein Anstrich von Athen/", "tokens": ["Kein", "Pflas\u00b7ter", "vom", "Par\u00b7na\u00df", "/", "kein", "An\u00b7strich", "von", "A\u00b7then", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NE", "$(", "PIAT", "NN", "APPR", "NE", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Hier hat kein Podalir vergn\u00fcgte Mittel funden/", "tokens": ["Hier", "hat", "kein", "Po\u00b7da\u00b7lir", "ver\u00b7gn\u00fcg\u00b7te", "Mit\u00b7tel", "fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Man heisset uns umsonst zur harten Stoa gehn.", "tokens": ["Man", "heis\u00b7set", "uns", "um\u00b7sonst", "zur", "har\u00b7ten", "Stoa", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Die Wehmutt ist ein Gla\u00df/ das falsche Farben zeiget/", "tokens": ["Die", "Weh\u00b7mutt", "ist", "ein", "Gla\u00df", "/", "das", "fal\u00b7sche", "Far\u00b7ben", "zei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$(", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein thr\u00e4nend Auge sieht den heitern Himmel nicht/", "tokens": ["Ein", "thr\u00e4\u00b7nend", "Au\u00b7ge", "sieht", "den", "hei\u00b7tern", "Him\u00b7mel", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Monde der Vernunfft/ der in die H\u00f6he steiget/", "tokens": ["Der", "Mon\u00b7de", "der", "Ver\u00b7nunfft", "/", "der", "in", "die", "H\u00f6\u00b7he", "stei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$(", "ART", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist doch zu schwach/ da\u00df er die dicken Wolcken bricht;", "tokens": ["Ist", "doch", "zu", "schwach", "/", "da\u00df", "er", "die", "di\u00b7cken", "Wol\u00b7cken", "bricht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKA", "ADJD", "$(", "KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Es mu\u00df ein ander Glantz vom hohen Himmel scheinen/", "tokens": ["Es", "mu\u00df", "ein", "an\u00b7der", "Glantz", "vom", "ho\u00b7hen", "Him\u00b7mel", "schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJD", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der solchen Nebeldunst mit Krafft zertheilen kan:", "tokens": ["Der", "sol\u00b7chen", "Ne\u00b7bel\u00b7dunst", "mit", "Krafft", "zer\u00b7thei\u00b7len", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die irdsche Sonne macht ein bl\u00f6des Auge weinen;", "tokens": ["Die", "ird\u00b7sche", "Son\u00b7ne", "macht", "ein", "bl\u00f6\u00b7des", "Au\u00b7ge", "wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Ungeschaffne frischt zu wahrer Gro\u00dfmntt an.", "tokens": ["Die", "Un\u00b7ge\u00b7schaff\u00b7ne", "frischt", "zu", "wah\u00b7rer", "Gro\u00dfmntt", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.16": {"line.1": {"text": "Nun/ mein geehrter Freund/ er folge deren Leiten/", "tokens": ["Nun", "/", "mein", "ge\u00b7ehr\u00b7ter", "Freund", "/", "er", "fol\u00b7ge", "de\u00b7ren", "Lei\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "PPOSAT", "ADJA", "NN", "$(", "PPER", "VVFIN", "PRELAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ihn aus einer Nacht des tieffen Traurens zieht/", "tokens": ["Die", "ihn", "aus", "ei\u00b7ner", "Nacht", "des", "tief\u00b7fen", "Trau\u00b7rens", "zieht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die ihm hat Zeit verg\u00f6nnt sich Christlich zu bereiten", "tokens": ["Die", "ihm", "hat", "Zeit", "ver\u00b7g\u00f6nnt", "sich", "Christ\u00b7lich", "zu", "be\u00b7rei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VAFIN", "NN", "VVFIN", "PRF", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu dem/ was er itzund vor seinen Augen sieht.", "tokens": ["Zu", "dem", "/", "was", "er", "it\u00b7zund", "vor", "sei\u00b7nen", "Au\u00b7gen", "sieht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "PWS", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Wer uns geschlagen hat/ kan auch am besten heilen.", "tokens": ["Wer", "uns", "ge\u00b7schla\u00b7gen", "hat", "/", "kan", "auch", "am", "bes\u00b7ten", "hei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "VAFIN", "$(", "VMFIN", "ADV", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Hand/ die uns verlezt/ thu auch den ersten Bund.", "tokens": ["Die", "Hand", "/", "die", "uns", "ver\u00b7lezt", "/", "thu", "auch", "den", "ers\u00b7ten", "Bund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$(", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erfahrung und Natur heist uns nach diesem eilen/", "tokens": ["Er\u00b7fah\u00b7rung", "und", "Na\u00b7tur", "heist", "uns", "nach", "die\u00b7sem", "ei\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "APPR", "PDAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was uns durch seine Gifft und zorngen Bi\u00df verwundt.", "tokens": ["Was", "uns", "durch", "sei\u00b7ne", "Gifft", "und", "zorn\u00b7gen", "Bi\u00df", "ver\u00b7wundt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "KON", "VVFIN", "APPR", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Zwar hier ist keine Gifft/ hier ist kein Zorn zu finden:", "tokens": ["Zwar", "hier", "ist", "kei\u00b7ne", "Gifft", "/", "hier", "ist", "kein", "Zorn", "zu", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PIAT", "NN", "$(", "ADV", "VAFIN", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es thuts des HErren Hand/ die alles wohl gemacht/", "tokens": ["Es", "thuts", "des", "Her\u00b7ren", "Hand", "/", "die", "al\u00b7les", "wohl", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$(", "ART", "PIS", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des HErren Hand/ gewohnt zum Schlagen und verbinden/", "tokens": ["Des", "Her\u00b7ren", "Hand", "/", "ge\u00b7wohnt", "zum", "Schla\u00b7gen", "und", "ver\u00b7bin\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "VVPP", "APPRART", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Des HErren Hand/ der nie zu unserm Schaden wacht.", "tokens": ["Des", "Her\u00b7ren", "Hand", "/", "der", "nie", "zu", "un\u00b7serm", "Scha\u00b7den", "wacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Schwer ist es/ unsern Schmertz bald erstlich zu bestillen/", "tokens": ["Schwer", "ist", "es", "/", "un\u00b7sern", "Schmertz", "bald", "erst\u00b7lich", "zu", "be\u00b7stil\u00b7len", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "$(", "PPOSAT", "NN", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Eigen-Liebe denckt offt mehr auff sich/ als GOtt/", "tokens": ["Die", "Ei\u00b7gen\u00b7Lie\u00b7be", "denckt", "offt", "mehr", "auff", "sich", "/", "als", "Gott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "PRF", "$(", "KOUS", "NN", "$("], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sieht ihren Kummer an durch falsch-geschliffne Brillen/", "tokens": ["Sieht", "ih\u00b7ren", "Kum\u00b7mer", "an", "durch", "falschge\u00b7schliff\u00b7ne", "Bril\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Verdoppelt ihren Harm/ vergr\u00f6ssert ihre Noth.", "tokens": ["Ver\u00b7dop\u00b7pelt", "ih\u00b7ren", "Harm", "/", "ver\u00b7gr\u00f6s\u00b7sert", "ih\u00b7re", "Noth", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$(", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Wir suchen nur/ was wir an unsrer Seite                                     missen/", "tokens": ["Wir", "su\u00b7chen", "nur", "/", "was", "wir", "an", "uns\u00b7rer", "Sei\u00b7te", "mis\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$(", "PWS", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und klagen/ da\u00df uns Freud/ und H\u00fclff/ und Trost                                     entgeht/", "tokens": ["Und", "kla\u00b7gen", "/", "da\u00df", "uns", "Freud", "/", "und", "H\u00fclff", "/", "und", "Trost", "ent\u00b7geht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "$(", "KOUS", "PPER", "NN", "$(", "KON", "NN", "$(", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Erwegen aber nicht/ da\u00df wir di\u00df Liebe wissen/", "tokens": ["Er\u00b7we\u00b7gen", "a\u00b7ber", "nicht", "/", "da\u00df", "wir", "di\u00df", "Lie\u00b7be", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "$(", "KOUS", "PPER", "PDS", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohin auch unser Wunsch und br\u00fcnstig                                     Seufftzen steht:", "tokens": ["Wo\u00b7hin", "auch", "un\u00b7ser", "Wunsch", "und", "br\u00fcns\u00b7tig", "Seufft\u00b7zen", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "KON", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Bedencken nicht/ wie es dem Tode kan entrinnen/", "tokens": ["Be\u00b7den\u00b7cken", "nicht", "/", "wie", "es", "dem", "To\u00b7de", "kan", "ent\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$(", "PWAV", "PPER", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie es verlassen hat das Siech-Hau\u00df dieser Welt/", "tokens": ["Wie", "es", "ver\u00b7las\u00b7sen", "hat", "das", "Siech\u00b7Hau\u00df", "die\u00b7ser", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVPP", "VAFIN", "ART", "NN", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wollen ihm gar bald die Freude nicht verg\u00fcnnen/", "tokens": ["Und", "wol\u00b7len", "ihm", "gar", "bald", "die", "Freu\u00b7de", "nicht", "ver\u00b7g\u00fcn\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die ihm des HErren Hand in seiner Schos bestellt.", "tokens": ["Die", "ihm", "des", "Her\u00b7ren", "Hand", "in", "sei\u00b7ner", "Schos", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Wir sehen nicht/ wie GOtt auff seine liebsten Kinder", "tokens": ["Wir", "se\u00b7hen", "nicht", "/", "wie", "Gott", "auff", "sei\u00b7ne", "liebs\u00b7ten", "Kin\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "KOKOM", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Siegel iederzeit des hei\u00dfen Creutzes dr\u00fcckt/", "tokens": ["Das", "Sie\u00b7gel", "ie\u00b7der\u00b7zeit", "des", "hei\u00b7\u00dfen", "Creut\u00b7zes", "dr\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn er die wilde Schaar der Gotts-vergessnen S\u00fcnder/", "tokens": ["Wenn", "er", "die", "wil\u00b7de", "Schaar", "der", "Gotts\u00b7ver\u00b7ge\u00b7ss\u00b7nen", "S\u00fcn\u00b7der", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Bey bl\u00fchendem Gel\u00fcck in ewge Straffe schickt.", "tokens": ["Bey", "bl\u00fc\u00b7hen\u00b7dem", "Ge\u00b7l\u00fcck", "in", "ew\u00b7ge", "Straf\u00b7fe", "schickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Wir wissen nicht/ was die vor Ungl\u00fcck offt entkommen/", "tokens": ["Wir", "wis\u00b7sen", "nicht", "/", "was", "die", "vor", "Un\u00b7gl\u00fcck", "offt", "ent\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "PWS", "ART", "APPR", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die ein noch fr\u00fcher Tod aus unsern Augen reist;", "tokens": ["Die", "ein", "noch", "fr\u00fc\u00b7her", "Tod", "aus", "un\u00b7sern", "Au\u00b7gen", "reist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "ADJD", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und anders/ was ich mir zu melden vorgenommen/", "tokens": ["Und", "an\u00b7ders", "/", "was", "ich", "mir", "zu", "mel\u00b7den", "vor\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "PWS", "PPER", "PPER", "PTKZU", "VVINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn nicht die Schwachheit noch beschwerte Leib und Geist.", "tokens": ["Wenn", "nicht", "die", "Schwach\u00b7heit", "noch", "be\u00b7schwer\u00b7te", "Leib", "und", "Geist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ADV", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Doch wird sein Christenthum/ mit welchem kluges Wissen/", "tokens": ["Doch", "wird", "sein", "Chris\u00b7ten\u00b7thum", "/", "mit", "wel\u00b7chem", "klu\u00b7ges", "Wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "$(", "APPR", "PWAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vern\u00fcnfftges Urtheil und Verstand gesellet gehn/", "tokens": ["Ver\u00b7n\u00fcnfft\u00b7ges", "Ur\u00b7theil", "und", "Ver\u00b7stand", "ge\u00b7sel\u00b7let", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "VVPP", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sein stets gem\u00e4\u00dfigt Sinn/ und m\u00e4nnliches Entschl\u00fcssen/", "tokens": ["Sein", "stets", "ge\u00b7m\u00e4\u00b7\u00dfigt", "Sinn", "/", "und", "m\u00e4nn\u00b7li\u00b7ches", "Ent\u00b7schl\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "VVPP", "NN", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So di\u00df und mehr betracht/ dem H\u00f6chsten stille stehn.", "tokens": ["So", "di\u00df", "und", "mehr", "be\u00b7tracht", "/", "dem", "H\u00f6chs\u00b7ten", "stil\u00b7le", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "KON", "PIAT", "NN", "$(", "ART", "NN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Der selge Geist ruht nun in seines HErren H\u00e4nden/", "tokens": ["Der", "sel\u00b7ge", "Geist", "ruht", "nun", "in", "sei\u00b7nes", "Her\u00b7ren", "H\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Kranckheits-m\u00fcde Leib schl\u00e4fft in dem Grabe wohl!", "tokens": ["Der", "Kranck\u00b7heits\u00b7m\u00fc\u00b7de", "Leib", "schl\u00e4fft", "in", "dem", "Gra\u00b7be", "wohl", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Man wird der Tugend Ruhm zur sp\u00e4ten Nachwelt senden:", "tokens": ["Man", "wird", "der", "Tu\u00b7gend", "Ruhm", "zur", "sp\u00e4\u00b7ten", "Nach\u00b7welt", "sen\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "NN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+---", "measure": "unknown.measure.penta"}, "line.4": {"text": "Kein ORT ist/ welcher nicht ihr LOB vermelden soll.", "tokens": ["Kein", "OrT", "ist", "/", "wel\u00b7cher", "nicht", "ihr", "LoB", "ver\u00b7mel\u00b7den", "soll", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "$(", "PRELS", "PTKNEG", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}