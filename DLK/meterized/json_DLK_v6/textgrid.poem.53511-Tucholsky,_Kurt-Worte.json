{"textgrid.poem.53511": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Worte", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbso zum Beispiel diese Balten.", "tokens": ["\u00bb", "so", "zum", "Bei\u00b7spiel", "die\u00b7se", "Bal\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPRART", "NN", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Deutsch der Adel, deutsch das Land.", "tokens": ["Deutsch", "der", "A\u00b7del", ",", "deutsch", "das", "Land", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ADJD", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Also la\u00dft uns sie behalten,", "tokens": ["Al\u00b7so", "la\u00dft", "uns", "sie", "be\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stammesbr\u00fcder, Hand in Hand.", "tokens": ["Stam\u00b7mes\u00b7br\u00fc\u00b7der", ",", "Hand", "in", "Hand", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn es mu\u00df an deutschem Wesen", "tokens": ["Denn", "es", "mu\u00df", "an", "deut\u00b7schem", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "einmal noch die Welt genesen.", "tokens": ["ein\u00b7mal", "noch", "die", "Welt", "ge\u00b7ne\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Deutsch sei Eskimo und Mohr!\u00ab", "tokens": ["Deutsch", "sei", "Es\u00b7ki\u00b7mo", "und", "Mohr", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VAFIN", "NE", "KON", "NN", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.8": {"text": "Goldene Worte, Herr Pastor.", "tokens": ["Gol\u00b7de\u00b7ne", "Wor\u00b7te", ",", "Herr", "Pas\u00b7tor", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "\u00bbmann und Weib sind nur zwei \u00c4ste,", "tokens": ["\u00bb", "mann", "und", "Weib", "sind", "nur", "zwei", "\u00c4s\u00b7te", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "KON", "NN", "VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00c4ste von demselben Baum.", "tokens": ["\u00c4s\u00b7te", "von", "dem\u00b7sel\u00b7ben", "Baum", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zweiheit ist f\u00fcr sie das beste:", "tokens": ["Zwei\u00b7heit", "ist", "f\u00fcr", "sie", "das", "bes\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPER", "ART", "ADJA", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "gleicher Schlaf und gleicher Traum.", "tokens": ["glei\u00b7cher", "Schlaf", "und", "glei\u00b7cher", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn sie auch zerrissen wandern,", "tokens": ["Wenn", "sie", "auch", "zer\u00b7ris\u00b7sen", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sie zu Hause, er in Flandern \u2013", "tokens": ["sie", "zu", "Hau\u00b7se", ",", "er", "in", "Flan\u00b7dern", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "$,", "PPER", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Halt ihn fest, der dich erkor!\u00ab", "tokens": ["Halt", "ihn", "fest", ",", "der", "dich", "er\u00b7kor", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVIMP", "PPER", "PTKVZ", "$,", "PRELS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Goldene Worte, Herr Pastor.", "tokens": ["Gol\u00b7de\u00b7ne", "Wor\u00b7te", ",", "Herr", "Pas\u00b7tor", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "\u00bbfriede! Friede sei auf Erden!", "tokens": ["\u00bb", "frie\u00b7de", "!", "Frie\u00b7de", "sei", "auf", "Er\u00b7den", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NN", "$.", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sieh, auch dr\u00fcben schie\u00dft ein Christ.", "tokens": ["Sieh", ",", "auch", "dr\u00fc\u00b7ben", "schie\u00dft", "ein", "Christ", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwar, man wird schon selig werden,", "tokens": ["Zwar", ",", "man", "wird", "schon", "se\u00b7lig", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PIS", "VAFIN", "ADV", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn man nur gehorsam ist.", "tokens": ["wenn", "man", "nur", "ge\u00b7hor\u00b7sam", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Christi Worte gelten immer,", "tokens": ["Chris\u00b7ti", "Wor\u00b7te", "gel\u00b7ten", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "selbst in Blut und Schmerzgewimmer,", "tokens": ["selbst", "in", "Blut", "und", "Schmerz\u00b7ge\u00b7wim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "gelten bis zum Himmelstor!\u00ab", "tokens": ["gel\u00b7ten", "bis", "zum", "Him\u00b7mels\u00b7tor", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "APPR", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Goldene Worte \u2013 goldene Worte . . .", "tokens": ["Gol\u00b7de\u00b7ne", "Wor\u00b7te", "\u2013", "gol\u00b7de\u00b7ne", "Wor\u00b7te", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$.", "$.", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Und die Taten, Herr Pastor?", "tokens": ["Und", "die", "Ta\u00b7ten", ",", "Herr", "Pas\u00b7tor", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}