{"dta.poem.21777": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n  Sch\u00f6nheit gebiert Hochmuht.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Fjlidor lag in dem Schatten/", "tokens": ["Fjli\u00b7dor", "lag", "in", "dem", "Schat\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "wo der gelbe Pregel-flu\u00df", "tokens": ["wo", "der", "gel\u00b7be", "Pre\u00b7gel\u00b7flu\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "durch Prutenens braune Matten", "tokens": ["durch", "Pru\u00b7te\u00b7nens", "brau\u00b7ne", "Mat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "ziehet seinen leisen Gu\u00df/", "tokens": ["zie\u00b7het", "sei\u00b7nen", "lei\u00b7sen", "Gu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da befielen ihn die Grillen", "tokens": ["da", "be\u00b7fie\u00b7len", "ihn", "die", "Gril\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "von der falschen Erotillen.", "tokens": ["von", "der", "fal\u00b7schen", "E\u00b7ro\u00b7til\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Jhr/ ihr unbewohnten \u00f6rter/", "tokens": ["Ihr", "/", "ihr", "un\u00b7be\u00b7wohn\u00b7ten", "\u00f6r\u00b7ter", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wo die au\u00dfgebrachten W\u00f6rter", "tokens": ["wo", "die", "au\u00df\u00b7ge\u00b7brach\u00b7ten", "W\u00f6r\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "meiner Brunst verschwiegen sein/", "tokens": ["mei\u00b7ner", "Brunst", "ver\u00b7schwie\u00b7gen", "sein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und die sachte Lufft der Westen", "tokens": ["und", "die", "sach\u00b7te", "Lufft", "der", "Wes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "h\u00f6ret meiner Quaal gebr\u00f6sten.", "tokens": ["h\u00f6\u00b7ret", "mei\u00b7ner", "Qua\u00b7al", "ge\u00b7br\u00f6s\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Hier d\u00fcrff ich mein Leid beweinen/", "tokens": ["Hier", "d\u00fcrff", "ich", "mein", "Leid", "be\u00b7wei\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "hier verr\u00e4ht mich niemand nicht/", "tokens": ["hier", "ver\u00b7r\u00e4ht", "mich", "nie\u00b7mand", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "PTKNEG", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "wo den stummen Ufer-steinen", "tokens": ["wo", "den", "stum\u00b7men", "U\u00b7fer\u00b7stei\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nur die Treue nicht gebricht:", "tokens": ["nur", "die", "Treu\u00b7e", "nicht", "ge\u00b7bricht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "werden bey euch au\u00dfgegossen.", "tokens": ["wer\u00b7den", "bey", "euch", "au\u00df\u00b7ge\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Erotill\u2019 hat mich verf\u00fchret/", "tokens": ["E\u00b7ro\u00b7till'", "hat", "mich", "ver\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Erotille/ derer Zier", "tokens": ["E\u00b7ro\u00b7til\u00b7le", "/", "de\u00b7rer", "Zier"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$(", "PDS", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "fast bi\u00df an die Wolken r\u00fchret.", "tokens": ["fast", "bi\u00df", "an", "die", "Wol\u00b7ken", "r\u00fch\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "W\u00e4r\u2019 ach! di\u00df verborgen Jhr!", "tokens": ["W\u00e4r'", "ach", "!", "di\u00df", "ver\u00b7bor\u00b7gen", "Ihr", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ITJ", "$.", "PDS", "VVPP", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "kommen so gew\u00fcnscht zu steuer!", "tokens": ["kom\u00b7men", "so", "ge\u00b7w\u00fcnscht", "zu", "steu\u00b7er", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVPP", "PTKA", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Nu ist sie es worden innen/", "tokens": ["Nu", "ist", "sie", "es", "wor\u00b7den", "in\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VAPP", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "als sie in die F", "tokens": ["als", "sie", "in", "die", "F"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "da ward ihre Hoffart wach.", "tokens": ["da", "ward", "ih\u00b7re", "Hof\u00b7fart", "wach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Seit der Zeit sie sich gesehen", "tokens": ["Seit", "der", "Zeit", "sie", "sich", "ge\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPER", "PRF", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "darff ich nimmer zu ihr gehen.", "tokens": ["darff", "ich", "nim\u00b7mer", "zu", "ihr", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Daher hab\u2019 ich erst geweinet", "tokens": ["Da\u00b7her", "hab'", "ich", "erst", "ge\u00b7wei\u00b7net"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "daher fing mein Elend an", "tokens": ["da\u00b7her", "fing", "mein", "E\u00b7lend", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPOSAT", "NN", "PTKVZ"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "weil nechstdehm mir nimmer scheinet", "tokens": ["weil", "nechst\u00b7dehm", "mir", "nim\u00b7mer", "schei\u00b7net"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was mir einig leuchten kan/", "tokens": ["was", "mir", "ei\u00b7nig", "leuch\u00b7ten", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "ihrer Blikke g\u00f6ldne Sternen", "tokens": ["ih\u00b7rer", "Blik\u00b7ke", "g\u00f6ld\u00b7ne", "Ster\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wehrt die Venus nachzulernen.", "tokens": ["wehrt", "die", "Ve\u00b7nus", "nach\u00b7zu\u00b7ler\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Erst ist sie mir nachgerennet/", "tokens": ["Erst", "ist", "sie", "mir", "nach\u00b7ge\u00b7ren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "erst hie\u00df sie mich stille stehn/", "tokens": ["erst", "hie\u00df", "sie", "mich", "stil\u00b7le", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJA", "VVINF", "$("], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "und da war ich nicht entbrennet/", "tokens": ["und", "da", "war", "ich", "nicht", "ent\u00b7bren\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PTKNEG", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "hatt\u2019 auff Liebe nie gesehn/", "tokens": ["hatt'", "auff", "Lie\u00b7be", "nie", "ge\u00b7sehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Flegel/ Pflug/ Karst/ Rohr und Nezze", "tokens": ["Fle\u00b7gel", "/", "Pflug", "/", "Karst", "/", "Rohr", "und", "Nez\u00b7ze"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "NE", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "waren meine Lust und Sch\u00e4zze.", "tokens": ["wa\u00b7ren", "mei\u00b7ne", "Lust", "und", "Sch\u00e4z\u00b7ze", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Eine Zytter geel gef\u00e4rbet", "tokens": ["Ei\u00b7ne", "Zyt\u00b7ter", "geel", "ge\u00b7f\u00e4r\u00b7bet"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "bunte Seiten oben drauff", "tokens": ["bun\u00b7te", "Sei\u00b7ten", "o\u00b7ben", "drauff"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "hat mir Daffnis angeerbet/", "tokens": ["hat", "mir", "Daff\u00b7nis", "an\u00b7ge\u00b7er\u00b7bet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dar spielt\u2019 ich zuweilen auff/", "tokens": ["dar", "spielt'", "ich", "zu\u00b7wei\u00b7len", "auff", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "VVFIN", "PPER", "ADV", "APPR", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wenn ich von der Arbeit m\u00fcde", "tokens": ["wenn", "ich", "von", "der", "Ar\u00b7beit", "m\u00fc\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "nachdacht einem Sch\u00e4ffer-Liede.", "tokens": ["nach\u00b7dacht", "ei\u00b7nem", "Sch\u00e4f\u00b7fer\u00b7Lie\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "O wie offt kahm sie geschlichen", "tokens": ["O", "wie", "offt", "kahm", "sie", "ge\u00b7schli\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KOKOM", "ADV", "VVIMP", "PPER", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "auch wol mitten in der Nacht/", "tokens": ["auch", "wol", "mit\u00b7ten", "in", "der", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "ist auch eher nicht gewichen", "tokens": ["ist", "auch", "e\u00b7her", "nicht", "ge\u00b7wi\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bi\u00df ich mich ins Stroh gemacht.", "tokens": ["bi\u00df", "ich", "mich", "ins", "Stroh", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da hat sie sich offt beklaget/", "tokens": ["Da", "hat", "sie", "sich", "offt", "be\u00b7kla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADV", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "da\u00df es so geschwinde taget.", "tokens": ["da\u00df", "es", "so", "ge\u00b7schwin\u00b7de", "ta\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Jhre L\u00e4mmer gingen weiden", "tokens": ["Ih\u00b7re", "L\u00e4m\u00b7mer", "gin\u00b7gen", "wei\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "offtermals in meiner Trifft/", "tokens": ["off\u00b7ter\u00b7mals", "in", "mei\u00b7ner", "Trifft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Di\u00df war darauff angestifft", "tokens": ["Di\u00df", "war", "dar\u00b7auff", "an\u00b7ge\u00b7stifft"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PAV", "VVPP"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "da\u00df ich mit ihr reden solte.", "tokens": ["da\u00df", "ich", "mit", "ihr", "re\u00b7den", "sol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Denn so fragte sie bi\u00dfweilen", "tokens": ["Denn", "so", "frag\u00b7te", "sie", "bi\u00df\u00b7wei\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hastu nicht das b\u00f6se Tiehr", "tokens": ["has\u00b7tu", "nicht", "das", "b\u00f6\u00b7se", "Ti\u00b7ehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "heute morgen h\u00f6ren heulen?", "tokens": ["heu\u00b7te", "mor\u00b7gen", "h\u00f6\u00b7ren", "heu\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bleibe diesen Tag bey mir", "tokens": ["blei\u00b7be", "die\u00b7sen", "Tag", "bey", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wie k\u00f6nt\u2019 ich mich/ Schwache/ r\u00e4chen", "tokens": ["wie", "k\u00f6nt'", "ich", "mich", "/", "Schwa\u00b7che", "/", "r\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "$(", "NN", "$(", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Noch geschahen tausend Renke", "tokens": ["Noch", "ge\u00b7scha\u00b7hen", "tau\u00b7send", "Ren\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVPP", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch/ ich lie\u00df mich nirgend ein", "tokens": ["Doch", "/", "ich", "lie\u00df", "mich", "nir\u00b7gend", "ein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$(", "PPER", "VVFIN", "PPER", "ADV", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "bi\u00df ich einmahl bey der Tr\u00e4nke", "tokens": ["bi\u00df", "ich", "ein\u00b7mahl", "bey", "der", "Tr\u00e4n\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "macht ein weinig mich gemein.", "tokens": ["macht", "ein", "wei\u00b7nig", "mich", "ge\u00b7mein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ja ihr milden Honigk\u00fcsse!", "tokens": ["Ja", "ihr", "mil\u00b7den", "Ho\u00b7nig\u00b7k\u00fcs\u00b7se", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nu habt ihr nur Bitterkeit", "tokens": ["Nu", "habt", "ihr", "nur", "Bit\u00b7ter\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "meinem Herzen eingestreut/", "tokens": ["mei\u00b7nem", "Her\u00b7zen", "ein\u00b7ge\u00b7streut", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nu ich euch nicht l\u00e4nger schmekke", "tokens": ["Nu", "ich", "euch", "nicht", "l\u00e4n\u00b7ger", "schmek\u00b7ke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "PPER", "PTKNEG", "ADJD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Da entglommen meine Flammen", "tokens": ["Da", "ent\u00b7glom\u00b7men", "mei\u00b7ne", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "damit wars umb mich getahn:", "tokens": ["da\u00b7mit", "wars", "umb", "mich", "ge\u00b7tahn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zwar/ dieweil wir noch beysammen", "tokens": ["Zwar", "/", "die\u00b7weil", "wir", "noch", "bey\u00b7sam\u00b7men"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "KOUS", "PPER", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "kehret\u2019 ich mich nirgends an/", "tokens": ["keh\u00b7ret'", "ich", "mich", "nir\u00b7gends", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "aber da sie von mir flohe", "tokens": ["a\u00b7ber", "da", "sie", "von", "mir", "flo\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "APPR", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und auff fremde Wiesen zohe:", "tokens": ["und", "auff", "frem\u00b7de", "Wie\u00b7sen", "zo\u00b7he", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "G\u00f6tter weh! Indehme schwunden", "tokens": ["G\u00f6t\u00b7ter", "weh", "!", "In\u00b7deh\u00b7me", "schwun\u00b7den"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "PTKVZ", "$.", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zunge/ Mund/ Bluht/ Farb\u2019 und Geist.", "tokens": ["Zun\u00b7ge", "/", "Mund", "/", "Bluht", "/", "Fa\u00b7rb'", "und", "Geist", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Eh er sich zu recht gefunden/", "tokens": ["Eh", "er", "sich", "zu", "recht", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKA", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "war der Sonnen Wagen meist", "tokens": ["war", "der", "Son\u00b7nen", "Wa\u00b7gen", "meist"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "in der braunen See gek\u00fchlet", "tokens": ["in", "der", "brau\u00b7nen", "See", "ge\u00b7k\u00fch\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und die R\u00e4der abgesp\u00fchlet.", "tokens": ["und", "die", "R\u00e4\u00b7der", "ab\u00b7ge\u00b7sp\u00fch\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}