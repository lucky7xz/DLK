{"textgrid.poem.40288": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sie war geflochten aus besten Stricken,", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie war geflochten aus besten Stricken,", "tokens": ["Sie", "war", "ge\u00b7floch\u00b7ten", "aus", "bes\u00b7ten", "Stri\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "aus bleiverknoteten, festen, dicken,", "tokens": ["aus", "blei\u00b7ver\u00b7kno\u00b7te\u00b7ten", ",", "fes\u00b7ten", ",", "di\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "VVFIN", "$,", "ADJA", "$,", "ADJA", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "meine Gei\u00dfel n\u00e4mlich \u2013 und der Stiel", "tokens": ["mei\u00b7ne", "Gei\u00b7\u00dfel", "n\u00e4m\u00b7lich", "\u2013", "und", "der", "Stiel"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "$(", "KON", "ART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "so grad recht handlich zum Pr\u00fcgelspiel.", "tokens": ["so", "grad", "recht", "hand\u00b7lich", "zum", "Pr\u00fc\u00b7gel\u00b7spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Doch nein: es sollte ja ernst zugehn,", "tokens": ["Doch", "nein", ":", "es", "soll\u00b7te", "ja", "ernst", "zu\u00b7gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "PPER", "VMFIN", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "ich wollte die Hexe blutig karbatschen,", "tokens": ["ich", "woll\u00b7te", "die", "He\u00b7xe", "blu\u00b7tig", "kar\u00b7bat\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "diese alte Pr\u00fcde mal zappeln sehn.", "tokens": ["die\u00b7se", "al\u00b7te", "Pr\u00fc\u00b7de", "mal", "zap\u00b7peln", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "ADV", "VVINF", "VVINF", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Also rasch in den Frack! in die Ecke die Latschen,", "tokens": ["Al\u00b7so", "rasch", "in", "den", "Frack", "!", "in", "die", "E\u00b7cke", "die", "Lat\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "$.", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.9": {"text": "die Lackschuh an, Manschetten, Chapeau,", "tokens": ["die", "Lack\u00b7schuh", "an", ",", "Man\u00b7schet\u00b7ten", ",", "Cha\u00b7pe\u00b7au", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "NN", "$,", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "damit nicht etwa, k\u00e4m'ich so", "tokens": ["da\u00b7mit", "nicht", "et\u00b7wa", ",", "k\u00e4\u00b7m'\u00b7ich", "so"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "PTKNEG", "ADV", "$,", "ADJD", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.11": {"text": "als Mensch blos, ohne den Affenschniepel,", "tokens": ["als", "Mensch", "blos", ",", "oh\u00b7ne", "den", "Af\u00b7fen\u00b7schnie\u00b7pel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "$,", "KOUI", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Verdacht entst\u00fcnde: hinaus, du R\u00fcpel!", "tokens": ["Ver\u00b7dacht", "ent\u00b7st\u00fcn\u00b7de", ":", "hin\u00b7aus", ",", "du", "R\u00fc\u00b7pel", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "APZR", "$,", "PPER", "NE", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Ich las noch einmal die Adresse:", "tokens": ["Ich", "las", "noch", "ein\u00b7mal", "die", "Ad\u00b7res\u00b7se", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Frau Geheime Comm.-Rath S. von Kohn", "tokens": ["Frau", "Ge\u00b7hei\u00b7me", "Comm", ".", "S.", "von", "Kohn"], "token_info": ["word", "word", "word", "punct", "word", "abbreviation", "word", "word"], "pos": ["NN", "NE", "NE", "$.", "NN", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.15": {"text": "verschwieg man, schien's, aus Delikatesse.", "tokens": ["ver\u00b7schwieg", "man", ",", "schien's", ",", "aus", "De\u00b7li\u00b7ka\u00b7tes\u00b7se", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "ADJA", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.16": {"text": "Eine Krone dr\u00fcber, riesengro\u00df,", "tokens": ["Ei\u00b7ne", "Kro\u00b7ne", "dr\u00fc\u00b7ber", ",", "rie\u00b7sen\u00b7gro\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PAV", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "ersetzte das \u00bbgeborne\u00ab Schw\u00e4nzchen.", "tokens": ["er\u00b7setz\u00b7te", "das", "\u00bb", "ge\u00b7bor\u00b7ne", "\u00ab", "Schw\u00e4nz\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "$(", "ADJA", "$(", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Da war ich geladen zum Lesekr\u00e4nzchen.", "tokens": ["Da", "war", "ich", "ge\u00b7la\u00b7den", "zum", "Le\u00b7se\u00b7kr\u00e4nz\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "APPRART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Denn \u2013 verehrter Leser, ich tr\u00e4umte blos ...", "tokens": ["Denn", "\u2013", "ver\u00b7ehr\u00b7ter", "Le\u00b7ser", ",", "ich", "tr\u00e4um\u00b7te", "blos", "..."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "ADJA", "NN", "$,", "PPER", "VVFIN", "ADV", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Hm! sollt ich sie also wiederbegr\u00fc\u00dfen.", "tokens": ["Hm", "!", "sollt", "ich", "sie", "al\u00b7so", "wie\u00b7der\u00b7be\u00b7gr\u00fc\u00b7\u00dfen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+---+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wahrhaftig, sie hatte Carierre gemacht", "tokens": ["Wahr\u00b7haf\u00b7tig", ",", "sie", "hat\u00b7te", "Ca\u00b7rier\u00b7re", "ge\u00b7macht"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PPER", "VAFIN", "NN", "VVPP"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "hatte mich immer schon ausgelacht \u2013", "tokens": ["hat\u00b7te", "mich", "im\u00b7mer", "schon", "aus\u00b7ge\u00b7lacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "VVPP", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "na warte, du Kr\u00f6te heut sollst du's b\u00fc\u00dfen!", "tokens": ["na", "war\u00b7te", ",", "du", "Kr\u00f6\u00b7te", "heut", "sollst", "du's", "b\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$,", "PPER", "NN", "ADV", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Ich \u00fcbte Probe; verdammt. Das zog,", "tokens": ["Ich", "\u00fcb\u00b7te", "Pro\u00b7be", ";", "ver\u00b7dammt", ".", "Das", "zog", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$.", "VVPP", "$.", "PDS", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "wie die Knute um Wade und Schienbein flog!", "tokens": ["wie", "die", "Knu\u00b7te", "um", "Wa\u00b7de", "und", "Schien\u00b7bein", "flog", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.7": {"text": "Ich kn\u00f6pfte sie z\u00e4rtlich unter die Weste,", "tokens": ["Ich", "kn\u00f6pf\u00b7te", "sie", "z\u00e4rt\u00b7lich", "un\u00b7ter", "die", "Wes\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ich \u00fcbte den Handgriff, es ging aufs beste.", "tokens": ["ich", "\u00fcb\u00b7te", "den", "Hand\u00b7griff", ",", "es", "ging", "aufs", "bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "APPRART", "ADJA", "$."], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Noch ein Blick in den Spiegel: Famos, famos,", "tokens": ["Noch", "ein", "Blick", "in", "den", "Spie\u00b7gel", ":", "Fa\u00b7mos", ",", "fa\u00b7mos", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "$.", "NN", "$,", "ADJD", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.10": {"text": "das wird ein lustiges Lesekr\u00e4nzchen,", "tokens": ["das", "wird", "ein", "lus\u00b7ti\u00b7ges", "Le\u00b7se\u00b7kr\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "erst Faust von Goethe, und dann mein T\u00e4nzchen!", "tokens": ["erst", "Faust", "von", "Goe\u00b7the", ",", "und", "dann", "mein", "T\u00e4nz\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NE", "$,", "KON", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Faust?? \u2013 Wie gesagt, ich tr\u00e4umte blos.", "tokens": ["Faust", "??", "\u2013", "Wie", "ge\u00b7sagt", ",", "ich", "tr\u00e4um\u00b7te", "blos", "."], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PWAV", "VVPP", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wo hatt ich sie eigentlich kennen gelernt?", "tokens": ["Wo", "hatt", "ich", "sie", "ei\u00b7gent\u00b7lich", "ken\u00b7nen", "ge\u00b7lernt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "ADV", "VVINF", "VVPP", "$."], "meter": "-+---+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Seltsam! ich sann und sann und sinnte,", "tokens": ["Selt\u00b7sam", "!", "ich", "sann", "und", "sann", "und", "sinn\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "meine Gedanken waren wie Stinte:", "tokens": ["mei\u00b7ne", "Ge\u00b7dan\u00b7ken", "wa\u00b7ren", "wie", "Stin\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "kaum da, schon wieder weit entfernt.", "tokens": ["kaum", "da", ",", "schon", "wie\u00b7der", "weit", "ent\u00b7fernt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich lief und lief \u2013 das war doch rein", "tokens": ["Ich", "lief", "und", "lief", "\u2013", "das", "war", "doch", "rein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$(", "PDS", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zum Rasendwerden mit dieser Fratze!", "tokens": ["zum", "Ra\u00b7send\u00b7wer\u00b7den", "mit", "die\u00b7ser", "Frat\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Doch immer die selbe! das Auge! Nein,", "tokens": ["Doch", "im\u00b7mer", "die", "sel\u00b7be", "!", "das", "Au\u00b7ge", "!", "Nein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "$.", "ART", "NN", "$.", "PTKANT", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "doch nicht! jetzt so \u2013 fast wie ein Schwein,", "tokens": ["doch", "nicht", "!", "jetzt", "so", "\u2013", "fast", "wie", "ein", "Schwein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$.", "ADV", "ADV", "$(", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "jetzt wie'ne Schlange, nein, wie'ne Katze.", "tokens": ["jetzt", "wie'\u00b7ne", "Schlan\u00b7ge", ",", "nein", ",", "wie'\u00b7ne", "Kat\u00b7ze", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "PTKANT", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und doch \u2013 zum Teufel, ich irr mich nicht:", "tokens": ["Und", "doch", "\u2013", "zum", "Teu\u00b7fel", ",", "ich", "irr", "mich", "nicht", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "APPRART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "um diese kaltl\u00fcsternen Blicke immer", "tokens": ["um", "die\u00b7se", "kalt\u00b7l\u00fcs\u00b7ter\u00b7nen", "Bli\u00b7cke", "im\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN", "ADV"], "meter": "-+-++--+-++", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "das selbe zahme Kaninchengesicht,", "tokens": ["das", "sel\u00b7be", "zah\u00b7me", "Ka\u00b7nin\u00b7chen\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "nein Affengesicht, nein H\u00fchnchengesicht,", "tokens": ["nein", "Af\u00b7fen\u00b7ge\u00b7sicht", ",", "nein", "H\u00fchn\u00b7chen\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$,", "PTKANT", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "das selbe s\u00fc\u00dflederne Frauenzimmer.", "tokens": ["das", "sel\u00b7be", "s\u00fc\u00df\u00b7le\u00b7der\u00b7ne", "Frau\u00b7en\u00b7zim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ah \u2013 ja nat\u00fcrlich! klar wie Butter!", "tokens": ["Ah", "\u2013", "ja", "na\u00b7t\u00fcr\u00b7lich", "!", "klar", "wie", "But\u00b7ter", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADV", "ADV", "$.", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "erst war sie die Tochter von unserm Paster.", "tokens": ["erst", "war", "sie", "die", "Toch\u00b7ter", "von", "un\u00b7serm", "Pas\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die warnte mich stets vor dem Pfad der Laster,", "tokens": ["Die", "warn\u00b7te", "mich", "stets", "vor", "dem", "Pfad", "der", "Las\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "zwei Jahr drauf war sie Fr\u00e4ulein Mutter.", "tokens": ["zwei", "Jahr", "drauf", "war", "sie", "Fr\u00e4u\u00b7lein", "Mut\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "PAV", "VAFIN", "PPER", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Das hei\u00dft, nicht etwa von meiner Seite,", "tokens": ["Das", "hei\u00dft", ",", "nicht", "et\u00b7wa", "von", "mei\u00b7ner", "Sei\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "ich wu\u00dfte noch nicht, was der Vogel gepfiffen,", "tokens": ["ich", "wu\u00df\u00b7te", "noch", "nicht", ",", "was", "der", "Vo\u00b7gel", "ge\u00b7pfif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "ich nahm die Worte noch f\u00fcr die Leute;", "tokens": ["ich", "nahm", "die", "Wor\u00b7te", "noch", "f\u00fcr", "die", "Leu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "ein Andrer, der hatte sie \u2013 besser begriffen.", "tokens": ["ein", "A\u00b7ndrer", ",", "der", "hat\u00b7te", "sie", "\u2013", "bes\u00b7ser", "be\u00b7grif\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "PPER", "$(", "ADJD", "VVPP", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}}, "stanza.5": {"line.1": {"text": "Dann war sie die J\u00fcngste von meinen Tanten,", "tokens": ["Dann", "war", "sie", "die", "J\u00fcngs\u00b7te", "von", "mei\u00b7nen", "Tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "nein \u2013 Eine von ihren Gouvernanten,", "tokens": ["nein", "\u2013", "Ei\u00b7ne", "von", "ih\u00b7ren", "Gou\u00b7ver\u00b7nan\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ART", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "nur da\u00df sie mich beide nicht wiedererkannten;", "tokens": ["nur", "da\u00df", "sie", "mich", "bei\u00b7de", "nicht", "wie\u00b7der\u00b7er\u00b7kann\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.4": {"text": "die brachten uns jungen S\u00fcndern bei,", "tokens": ["die", "brach\u00b7ten", "uns", "jun\u00b7gen", "S\u00fcn\u00b7dern", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "was alles unaussprechlich sei.", "tokens": ["was", "al\u00b7les", "un\u00b7aus\u00b7sprech\u00b7lich", "sei", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie lasen immer vor Schlafengehn", "tokens": ["Sie", "la\u00b7sen", "im\u00b7mer", "vor", "Schla\u00b7fen\u00b7gehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "bei verriegelten Th\u00fcren die Bibel zusammen,", "tokens": ["bei", "ver\u00b7rie\u00b7gel\u00b7ten", "Th\u00fc\u00b7ren", "die", "Bi\u00b7bel", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.8": {"text": "die Reinheit ihrer Seelenflammen", "tokens": ["die", "Rein\u00b7heit", "ih\u00b7rer", "See\u00b7len\u00b7flam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "war aus der Reinheit der Bl\u00e4tter zu sehn;", "tokens": ["war", "aus", "der", "Rein\u00b7heit", "der", "Bl\u00e4t\u00b7ter", "zu", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.10": {"text": "die fettigsten Stellen \u2013 will ich nicht nennen,", "tokens": ["die", "fet\u00b7tigs\u00b7ten", "Stel\u00b7len", "\u2013", "will", "ich", "nicht", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+--", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "die keusche Leserin wird sie kennen.", "tokens": ["die", "keu\u00b7sche", "Le\u00b7se\u00b7rin", "wird", "sie", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Herrgott, und die Pate, das war sie ja auch!", "tokens": ["Herr\u00b7gott", ",", "und", "die", "Pa\u00b7te", ",", "das", "war", "sie", "ja", "auch", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ART", "NN", "$,", "PDS", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "die mit dem wohlgemeinten Bauch.", "tokens": ["die", "mit", "dem", "wohl\u00b7ge\u00b7mein\u00b7ten", "Bauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr seliger Gatte war sehr verderbt,", "tokens": ["Ihr", "se\u00b7li\u00b7ger", "Gat\u00b7te", "war", "sehr", "ver\u00b7derbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "er hatte ihr einen Apoll vererbt,", "tokens": ["er", "hat\u00b7te", "ihr", "ei\u00b7nen", "A\u00b7poll", "ver\u00b7erbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "der hatte nur ein Blatt zum Kleide;", "tokens": ["der", "hat\u00b7te", "nur", "ein", "Blatt", "zum", "Klei\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "drum band sie ihm, so geht die Fabel,", "tokens": ["drum", "band", "sie", "ihm", ",", "so", "geht", "die", "Fa\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "aus dunkelblauer chinesischer Seide", "tokens": ["aus", "dun\u00b7kel\u00b7blau\u00b7er", "chi\u00b7ne\u00b7si\u00b7scher", "Sei\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "ein christliches M\u00e4ntelchen um den Nabel.", "tokens": ["ein", "christ\u00b7li\u00b7ches", "M\u00e4n\u00b7tel\u00b7chen", "um", "den", "Na\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Nein Himmel \u2013 es war ja ihr Fr\u00e4ulein Base!", "tokens": ["Nein", "Him\u00b7mel", "\u2013", "es", "war", "ja", "ihr", "Fr\u00e4u\u00b7lein", "Ba\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$(", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "NE", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Nein \u2013 Fr\u00e4ulein Rosaura von gegen\u00fcber,", "tokens": ["Nein", "\u2013", "Fr\u00e4u\u00b7lein", "Ro\u00b7sau\u00b7ra", "von", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "NN", "NE", "APPR", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die mit der Entenschnabelnase", "tokens": ["die", "mit", "der", "En\u00b7ten\u00b7schna\u00b7bel\u00b7na\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und dem lyrischen Epos \u00bbJe l\u00e4nger je lieber\u00ab.", "tokens": ["und", "dem", "ly\u00b7ri\u00b7schen", "E\u00b7pos", "\u00bb", "Je", "l\u00e4n\u00b7ger", "je", "lie\u00b7ber", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$(", "ADV", "ADJD", "ADV", "ADV", "$(", "$."], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "Sie hatte sich z\u00fcchtig nach einem Mann", "tokens": ["Sie", "hat\u00b7te", "sich", "z\u00fcch\u00b7tig", "nach", "ei\u00b7nem", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "in den vornehmsten Zeitungen umgethan,", "tokens": ["in", "den", "vor\u00b7nehms\u00b7ten", "Zei\u00b7tun\u00b7gen", "um\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.7": {"text": "doch wollte Keiner die Tugend belohnen;", "tokens": ["doch", "woll\u00b7te", "Kei\u00b7ner", "die", "Tu\u00b7gend", "be\u00b7loh\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "nun schrieb sie Novellen und Recensionen.", "tokens": ["nun", "schrieb", "sie", "No\u00b7vel\u00b7len", "und", "Re\u00b7cen\u00b7si\u00b7o\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Ganz Deutschland pries den neuen Stern", "tokens": ["Ganz", "Deutschland", "pries", "den", "neu\u00b7en", "Stern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NE", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "ob seiner jungfr\u00e4ulichen Reinlichkeit;", "tokens": ["ob", "sei\u00b7ner", "jung\u00b7fr\u00e4u\u00b7li\u00b7chen", "Rein\u00b7lich\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "besonders Zola'n besprach sie gern", "tokens": ["be\u00b7son\u00b7ders", "Zo\u00b7la'n", "be\u00b7sprach", "sie", "gern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "und \u2013 warnte vor seiner Peinlichkeit.", "tokens": ["und", "\u2013", "warn\u00b7te", "vor", "sei\u00b7ner", "Pein\u00b7lich\u00b7keit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "In H\u00f6herem Auftrag lie\u00df sie auch,", "tokens": ["In", "H\u00f6\u00b7he\u00b7rem", "Auf\u00b7trag", "lie\u00df", "sie", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "der Staat bewilligte die Mittel,", "tokens": ["der", "Staat", "be\u00b7wil\u00b7lig\u00b7te", "die", "Mit\u00b7tel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "ein Werk erscheinen mit dem Titel:", "tokens": ["ein", "Werk", "er\u00b7schei\u00b7nen", "mit", "dem", "Ti\u00b7tel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbdas verbesserte Volkslied zum Schulgebrauch\u00ab.", "tokens": ["\u00bb", "das", "ver\u00b7bes\u00b7ser\u00b7te", "Volks\u00b7lied", "zum", "Schul\u00b7ge\u00b7brauch", "\u00ab", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "APPRART", "NN", "$(", "$."], "meter": "--+--++-+-+", "measure": "anapaest.di.plus"}, "line.17": {"text": "An den Anfang war als Motto gestellt:", "tokens": ["An", "den", "An\u00b7fang", "war", "als", "Mot\u00b7to", "ge\u00b7stellt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "KOKOM", "NE", "VVPP", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.18": {"text": "\u00bbh\u00e4hnchen von Tharau ist's, das mir gef\u00e4llt\u00ab.", "tokens": ["\u00bb", "h\u00e4hn\u00b7chen", "von", "Tha\u00b7rau", "ist's", ",", "das", "mir", "ge\u00b7f\u00e4llt", "\u00ab", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "APPR", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVPP", "$(", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.8": {"line.1": {"text": "Und immer neue! Verdammte Hexe:", "tokens": ["Und", "im\u00b7mer", "neu\u00b7e", "!", "Ver\u00b7damm\u00b7te", "He\u00b7xe", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "$.", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "kaum bist du Eine, so sind es sechse \u2013", "tokens": ["kaum", "bist", "du", "Ei\u00b7ne", ",", "so", "sind", "es", "sech\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "$,", "ADV", "VAFIN", "PPER", "VVFIN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Herrgott, nun ist sie ja gar ein Mann!", "tokens": ["Herr\u00b7gott", ",", "nun", "ist", "sie", "ja", "gar", "ein", "Mann", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADV", "ART", "NN", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "der Herr Kollege von nebenan,", "tokens": ["der", "Herr", "Kol\u00b7le\u00b7ge", "von", "ne\u00b7be\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NE", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "der gepr\u00fcfte Schulamtskandidat,", "tokens": ["der", "ge\u00b7pr\u00fcf\u00b7te", "Schul\u00b7amts\u00b7kan\u00b7di\u00b7dat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.6": {"text": "der die ausgezeichneten Zeugnisse hat;", "tokens": ["der", "die", "aus\u00b7ge\u00b7zeich\u00b7ne\u00b7ten", "Zeug\u00b7nis\u00b7se", "hat", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "er schwingt f\u00fcrs Frauenwohl die Feder.", "tokens": ["er", "schwingt", "f\u00fcrs", "Frau\u00b7en\u00b7wohl", "die", "Fe\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "In Schriften spricht er und vom Katheder", "tokens": ["In", "Schrif\u00b7ten", "spricht", "er", "und", "vom", "Ka\u00b7the\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVFIN", "PPER", "KON", "APPRART", "NN"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.9": {"text": "\u00fcber die h\u00f6here Sinnlichkeit", "tokens": ["\u00fc\u00b7ber", "die", "h\u00f6\u00b7he\u00b7re", "Sinn\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.10": {"text": "aller wahrhaft sittlich Emancipirten", "tokens": ["al\u00b7ler", "wahr\u00b7haft", "sitt\u00b7lich", "E\u00b7man\u00b7ci\u00b7pir\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADV", "ADJD", "NN"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "und die sexuelle Verworfenheit", "tokens": ["und", "die", "se\u00b7xu\u00b7el\u00b7le", "Ver\u00b7wor\u00b7fen\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "und perversen Affecte der Prostituirten;", "tokens": ["und", "per\u00b7ver\u00b7sen", "Af\u00b7fec\u00b7te", "der", "Pros\u00b7ti\u00b7tu\u00b7ir\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "er will ein kirchliches Zuchthaus gr\u00fcnden", "tokens": ["er", "will", "ein", "kirch\u00b7li\u00b7ches", "Zucht\u00b7haus", "gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "zur Korrektur der nat\u00fcrlichen S\u00fcnden.", "tokens": ["zur", "Kor\u00b7rek\u00b7tur", "der", "na\u00b7t\u00fcr\u00b7li\u00b7chen", "S\u00fcn\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.16": {"text": "so ein Fremdwort finden die Damen scharmant;", "tokens": ["so", "ein", "Fremd\u00b7wort", "fin\u00b7den", "die", "Da\u00b7men", "schar\u00b7mant", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.17": {"text": "deutsch klingt gleich alles so besch\u00e4mlich", "tokens": ["deutsch", "klingt", "gleich", "al\u00b7les", "so", "be\u00b7sch\u00e4m\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "ADV", "PIS", "ADV", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "und zehnmal weniger intressant.", "tokens": ["und", "zehn\u00b7mal", "we\u00b7ni\u00b7ger", "in\u00b7tres\u00b7sant", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Drum ist er, nur aus besagtem Grunde,", "tokens": ["Drum", "ist", "er", ",", "nur", "aus", "be\u00b7sag\u00b7tem", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "$,", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "bei einem Specialarzt st\u00e4ndiger Kunde.", "tokens": ["bei", "ei\u00b7nem", "Spe\u00b7ci\u00b7al\u00b7arzt", "st\u00e4n\u00b7di\u00b7ger", "Kun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "Ah, da geht er ja wieder \u2013 Herr, warten Sie doch!", "tokens": ["Ah", ",", "da", "geht", "er", "ja", "wie\u00b7der", "\u2013", "Herr", ",", "war\u00b7ten", "Sie", "doch", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADV", "$(", "NN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+--+--+--+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "was machen Sie denn so breite Beine?!", "tokens": ["was", "ma\u00b7chen", "Sie", "denn", "so", "brei\u00b7te", "Bei\u00b7ne", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nein, das ist er ja garnicht \u2013 ah: Frau von Knoch", "tokens": ["Nein", ",", "das", "ist", "er", "ja", "gar\u00b7nicht", "\u2013", "ah", ":", "Frau", "von", "Knoch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PDS", "VAFIN", "PPER", "ADV", "VVFIN", "$(", "ITJ", "$.", "NN", "APPR", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "mit ihrem M\u00f6pschen an der Leine,", "tokens": ["mit", "ih\u00b7rem", "M\u00f6p\u00b7schen", "an", "der", "Lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "seine verehrte G\u00f6nnerin.", "tokens": ["sei\u00b7ne", "ver\u00b7ehr\u00b7te", "G\u00f6n\u00b7ne\u00b7rin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Ach nein: Frau Consistorialrath Kloo\u00df,", "tokens": ["Ach", "nein", ":", "Frau", "Con\u00b7sis\u00b7to\u00b7ri\u00b7al\u00b7rath", "Kloo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "mit dem w\u00fcrdevoll wackelnden Doppelkinn", "tokens": ["mit", "dem", "w\u00fcr\u00b7de\u00b7voll", "wa\u00b7ckeln\u00b7den", "Dop\u00b7pel\u00b7kinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "und bald Millionenbesitzerin,", "tokens": ["und", "bald", "Mil\u00b7li\u00b7o\u00b7nen\u00b7be\u00b7sit\u00b7ze\u00b7rin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "die \u00bbWitwen- und Waisen-Besch\u00fctzerin\u00ab,", "tokens": ["die", "\u00bb", "Wit\u00b7wen", "und", "Wai\u00b7sen\u00b7Be\u00b7sch\u00fct\u00b7ze\u00b7rin", "\u00ab", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "$(", "TRUNC", "KON", "NN", "$(", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "geborene Freiin von \u2013 Kronenspro\u00df.", "tokens": ["ge\u00b7bo\u00b7re\u00b7ne", "Frei\u00b7in", "von", "\u2013", "Kro\u00b7nens\u00b7pro\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "$(", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Ihr Neffe, der war ein deutscher Dichter,", "tokens": ["Ihr", "Nef\u00b7fe", ",", "der", "war", "ein", "deut\u00b7scher", "Dich\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "so einer von dem modernen Gelichter,", "tokens": ["so", "ei\u00b7ner", "von", "dem", "mo\u00b7der\u00b7nen", "Ge\u00b7lich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "die alles beim rechten Namen nennen", "tokens": ["die", "al\u00b7les", "beim", "rech\u00b7ten", "Na\u00b7men", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPRART", "ADJA", "NN", "VVINF"], "meter": "-+--+--+--", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "und gar keine moralischen R\u00fccksichten kennen;", "tokens": ["und", "gar", "kei\u00b7ne", "mo\u00b7ra\u00b7li\u00b7schen", "R\u00fcck\u00b7sich\u00b7ten", "ken\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.15": {"text": "dem hat sie nat\u00fcrlich ihr Haus verschlossen.", "tokens": ["dem", "hat", "sie", "na\u00b7t\u00fcr\u00b7lich", "ihr", "Haus", "ver\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Und da hat der Mensch die Frechheit besessen,", "tokens": ["Und", "da", "hat", "der", "Mensch", "die", "Frech\u00b7heit", "be\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "angeblich aus Mangel an Kleidung und Essen,", "tokens": ["an\u00b7ge\u00b7blich", "aus", "Man\u00b7gel", "an", "Klei\u00b7dung", "und", "Es\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "und hat sich ne Kugel durchs Herz geschossen.", "tokens": ["und", "hat", "sich", "ne", "Ku\u00b7gel", "durchs", "Herz", "ge\u00b7schos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.10": {"line.1": {"text": "Und immer neue! mein Atem brannte,", "tokens": ["Und", "im\u00b7mer", "neu\u00b7e", "!", "mein", "A\u00b7tem", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "$.", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "w\u00e4hrend ich so durch die Stra\u00dfen rannte;", "tokens": ["w\u00e4h\u00b7rend", "ich", "so", "durch", "die", "Stra\u00b7\u00dfen", "rann\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "ich lief und lief, von Schwei\u00df bedeckt.", "tokens": ["ich", "lief", "und", "lief", ",", "von", "Schwei\u00df", "be\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus allen Mienen, aus allen Blicken,", "tokens": ["Aus", "al\u00b7len", "Mie\u00b7nen", ",", "aus", "al\u00b7len", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "als h\u00e4tte ein Teufel die Welt beleckt,", "tokens": ["als", "h\u00e4t\u00b7te", "ein", "Teu\u00b7fel", "die", "Welt", "be\u00b7leckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "schien mir dies Weibsbild entgegenzunicken.", "tokens": ["schien", "mir", "dies", "Weibs\u00b7bild", "ent\u00b7ge\u00b7gen\u00b7zu\u00b7ni\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "NN", "VVINF", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.7": {"text": "Seitdem ich die Nase ins Leben gesteckt,", "tokens": ["Seit\u00b7dem", "ich", "die", "Na\u00b7se", "ins", "Le\u00b7ben", "ge\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "war sie mir \u00fcber den Weg gekrochen", "tokens": ["war", "sie", "mir", "\u00fc\u00b7ber", "den", "Weg", "ge\u00b7kro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVPP"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "mit ihrem frommen Kaninchengesicht,", "tokens": ["mit", "ih\u00b7rem", "from\u00b7men", "Ka\u00b7nin\u00b7chen\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "nein Katzengesicht, nein H\u00fchnchengesicht,", "tokens": ["nein", "Kat\u00b7zen\u00b7ge\u00b7sicht", ",", "nein", "H\u00fchn\u00b7chen\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "NN", "$,", "PTKANT", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "mit ihren schlangengeschmeidigen Knochen.", "tokens": ["mit", "ih\u00b7ren", "schlan\u00b7gen\u00b7ge\u00b7schmei\u00b7di\u00b7gen", "Kno\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Sie hatte so'was in den Augen,", "tokens": ["Sie", "hat\u00b7te", "so'\u00b7was", "in", "den", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "das schien sich Einem ums Herz zu stricken,", "tokens": ["das", "schien", "sich", "Ei\u00b7nem", "ums", "Herz", "zu", "stri\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "jede Liebe drin zu ersticken", "tokens": ["je\u00b7de", "Lie\u00b7be", "drin", "zu", "er\u00b7sti\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADV", "PTKZU", "VVINF"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.15": {"text": "und jede M\u00e4nnlichkeit auszusaugen.", "tokens": ["und", "je\u00b7de", "M\u00e4nn\u00b7lich\u00b7keit", "aus\u00b7zu\u00b7sau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVIZU", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Und wo man hinkam, war sie zu treffen,", "tokens": ["Und", "wo", "man", "hin\u00b7kam", ",", "war", "sie", "zu", "tref\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "VVFIN", "$,", "VAFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "sie schien die reine Gesellschaftsklette;", "tokens": ["sie", "schien", "die", "rei\u00b7ne", "Ge\u00b7sell\u00b7schafts\u00b7klet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "sie lie\u00dfen sich Alle geduldig \u00e4ffen", "tokens": ["sie", "lie\u00b7\u00dfen", "sich", "Al\u00b7le", "ge\u00b7dul\u00b7dig", "\u00e4f\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PIAT", "ADJD", "VVINF"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "von dieser verzuckerten, glatten Kokette", "tokens": ["von", "die\u00b7ser", "ver\u00b7zu\u00b7cker\u00b7ten", ",", "glat\u00b7ten", "Ko\u00b7ket\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "$,", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.20": {"text": "mit ihren ahnungslosen Mienen,", "tokens": ["mit", "ih\u00b7ren", "ah\u00b7nungs\u00b7lo\u00b7sen", "Mie\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "die \u2013 seltsam \u2013 nimmer zu altern schienen", "tokens": ["die", "\u2013", "selt\u00b7sam", "\u2013", "nim\u00b7mer", "zu", "al\u00b7tern", "schie\u00b7nen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$(", "ADJD", "$(", "ADV", "PTKZU", "VVINF", "VVINF"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "und die ich auch niemals jung gesehn;", "tokens": ["und", "die", "ich", "auch", "nie\u00b7mals", "jung", "ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELS", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.23": {"text": "ihr schien die Natur aus dem Wege zu gehn.", "tokens": ["ihr", "schien", "die", "Na\u00b7tur", "aus", "dem", "We\u00b7ge", "zu", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.24": {"text": "Zwar \u2013 sie auch ihr! denn sonderbar:", "tokens": ["Zwar", "\u2013", "sie", "auch", "ihr", "!", "denn", "son\u00b7der\u00b7bar", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$(", "PPER", "ADV", "PPER", "$.", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "kein Haus, in dem dies Rackervieh", "tokens": ["kein", "Haus", ",", "in", "dem", "dies", "Ra\u00b7cker\u00b7vieh"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "$,", "APPR", "ART", "PDS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "nicht irgendmal zu finden war,", "tokens": ["nicht", "ir\u00b7gend\u00b7mal", "zu", "fin\u00b7den", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "blos in den H\u00fctten der Arbeit nie.", "tokens": ["blos", "in", "den", "H\u00fct\u00b7ten", "der", "Ar\u00b7beit", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "ADV", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.28": {"text": "Und immer, waren mir mal zu Zwein", "tokens": ["Und", "im\u00b7mer", ",", "wa\u00b7ren", "mir", "mal", "zu", "Zwein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "VAFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "und ich wollte der Kr\u00f6te die Wahrheit geigen,", "tokens": ["und", "ich", "woll\u00b7te", "der", "Kr\u00f6\u00b7te", "die", "Wahr\u00b7heit", "gei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.30": {"text": "so ein L\u00e4cheln und Lispeln: \u00bbLassen Sie sein,", "tokens": ["so", "ein", "L\u00e4\u00b7cheln", "und", "Lis\u00b7peln", ":", "\u00bb", "Las\u00b7sen", "Sie", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "KON", "NN", "$.", "$(", "VVFIN", "PPER", "VAINF", "$,"], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.31": {"text": "geliebter Freund! wie s\u00fc\u00df dies Schweigen!\u00ab", "tokens": ["ge\u00b7lieb\u00b7ter", "Freund", "!", "wie", "s\u00fc\u00df", "dies", "Schwei\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "ADJD", "PDS", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "und ein Seufzen, ein schmachtendes F\u00e4cherwiegen:", "tokens": ["und", "ein", "Seuf\u00b7zen", ",", "ein", "schmach\u00b7ten\u00b7des", "F\u00e4\u00b7cher\u00b7wie\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.33": {"text": "\u00bbich wei\u00df ja, alles ist nat\u00fcrlich!\u00ab", "tokens": ["\u00bb", "ich", "wei\u00df", "ja", ",", "al\u00b7les", "ist", "na\u00b7t\u00fcr\u00b7lich", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "$,", "PIS", "VAFIN", "ADV", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "und ein l\u00fcstern lauerndes H\u00fcftenbiegen:", "tokens": ["und", "ein", "l\u00fcs\u00b7tern", "lau\u00b7ern\u00b7des", "H\u00fcf\u00b7ten\u00b7bie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.35": {"text": "\u00bbim Wort nur ist es ungeb\u00fchrlich!\u00ab", "tokens": ["\u00bb", "im", "Wort", "nur", "ist", "es", "un\u00b7ge\u00b7b\u00fchr\u00b7lich", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "NN", "ADV", "VAFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "dann aber, wie ein sattes Schwein", "tokens": ["dann", "a\u00b7ber", ",", "wie", "ein", "sat\u00b7tes", "Schwein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "am vollen Troge pflegt zu liegen,", "tokens": ["am", "vol\u00b7len", "Tro\u00b7ge", "pflegt", "zu", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "fing pl\u00f6tzlich so ein glasiger Schein", "tokens": ["fing", "pl\u00f6tz\u00b7lich", "so", "ein", "gla\u00b7si\u00b7ger", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.39": {"text": "ihre geilen Blicke an zu l\u00e4hmen,", "tokens": ["ih\u00b7re", "gei\u00b7len", "Bli\u00b7cke", "an", "zu", "l\u00e4h\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.40": {"text": "ich konnte den Ekel nicht bez\u00e4hmen,", "tokens": ["ich", "konn\u00b7te", "den", "E\u00b7kel", "nicht", "be\u00b7z\u00e4h\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.41": {"text": "ich mu\u00dft ihr vor die F\u00fc\u00dfe spein.", "tokens": ["ich", "mu\u00dft", "ihr", "vor", "die", "F\u00fc\u00b7\u00dfe", "spein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Das brachte sie jedesmal zum Lachen:", "tokens": ["Das", "brach\u00b7te", "sie", "je\u00b7des\u00b7mal", "zum", "La\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.43": {"text": "\u00bbsie wollen die Welt wol besser machen?\u00ab", "tokens": ["\u00bb", "sie", "wol\u00b7len", "die", "Welt", "wol", "bes\u00b7ser", "ma\u00b7chen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "ART", "NN", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Nur manchmal, wenn sie wie in Schauern,", "tokens": ["Nur", "manch\u00b7mal", ",", "wenn", "sie", "wie", "in", "Schau\u00b7ern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als ob sich ihr Gef\u00fchl ertappte,", "tokens": ["als", "ob", "sich", "ihr", "Ge\u00b7f\u00fchl", "er\u00b7tapp\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "PRF", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die Lider \u00fcber die Augen klappte,", "tokens": ["die", "Li\u00b7der", "\u00fc\u00b7ber", "die", "Au\u00b7gen", "klapp\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "empfand ich was wie ein Bedauern;", "tokens": ["emp\u00b7fand", "ich", "was", "wie", "ein", "Be\u00b7dau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "vielleicht, da\u00df doch in all dem Schleim", "tokens": ["viel\u00b7leicht", ",", "da\u00df", "doch", "in", "all", "dem", "Schleim"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "ADV", "APPR", "PIAT", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein kleiner, verschimmelter Edelkeim!", "tokens": ["ein", "klei\u00b7ner", ",", "ver\u00b7schim\u00b7mel\u00b7ter", "E\u00b7del\u00b7keim", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Ich sp\u00fcrte dann immer so ein Jucken", "tokens": ["Ich", "sp\u00fcr\u00b7te", "dann", "im\u00b7mer", "so", "ein", "Ju\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "in allen f\u00fcnf Fingern, ihr die Mucken", "tokens": ["in", "al\u00b7len", "f\u00fcnf", "Fin\u00b7gern", ",", "ihr", "die", "Mu\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "CARD", "NN", "$,", "PPER", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "mal mit der Karbatsche auszupl\u00e4tten \u2013", "tokens": ["mal", "mit", "der", "Kar\u00b7bat\u00b7sche", "aus\u00b7zu\u00b7pl\u00e4t\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "man wei\u00df ja: Pr\u00fcgel und dann ein Ku\u00df", "tokens": ["man", "wei\u00df", "ja", ":", "Pr\u00fc\u00b7gel", "und", "dann", "ein", "Ku\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$.", "NN", "KON", "ADV", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "ist verr\u00fcckten Weibern ein Hochgenu\u00df \u2013", "tokens": ["ist", "ver\u00b7r\u00fcck\u00b7ten", "Wei\u00b7bern", "ein", "Hoch\u00b7ge\u00b7nu\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "ART", "NN", "$("], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.12": {"text": "Das war das Letzte, das konnte sie retten.", "tokens": ["Das", "war", "das", "Letz\u00b7te", ",", "das", "konn\u00b7te", "sie", "ret\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Herjeeh ja, das war's ja, das wollt'ich ja eben!", "tokens": ["Her\u00b7jeeh", "ja", ",", "das", "wa\u00b7r's", "ja", ",", "das", "wollt'\u00b7ich", "ja", "e\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PDS", "VAFIN", "ADV", "$,", "PRELS", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "ah sieh, da bin ich ja schon zur Stelle.", "tokens": ["ah", "sieh", ",", "da", "bin", "ich", "ja", "schon", "zur", "Stel\u00b7le", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Sie thronte, von ihrem Stab umgeben,", "tokens": ["Sie", "thron\u00b7te", ",", "von", "ih\u00b7rem", "Stab", "um\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "der kleine Herr Gatte stand dick daneben,", "tokens": ["der", "klei\u00b7ne", "Herr", "Gat\u00b7te", "stand", "dick", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "ADJD", "PAV", "$,"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "grad gegen\u00fcber der Zimmerschwelle.", "tokens": ["grad", "ge\u00b7gen\u00b7\u00fc\u00b7ber", "der", "Zim\u00b7mer\u00b7schwel\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Die persischen Polster und Teppiche strahlten", "tokens": ["Die", "per\u00b7si\u00b7schen", "Pols\u00b7ter", "und", "Tep\u00b7pi\u00b7che", "strahl\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "VVFIN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "im wei\u00dfen Schimmer der Gl\u00fchlichtbl\u00fcten,", "tokens": ["im", "wei\u00b7\u00dfen", "Schim\u00b7mer", "der", "Gl\u00fch\u00b7licht\u00b7bl\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "die Teel\u00f6ffel klirrten, Brillanten spr\u00fchten,", "tokens": ["die", "Tee\u00b7l\u00f6f\u00b7fel", "klirr\u00b7ten", ",", "Bril\u00b7lan\u00b7ten", "spr\u00fch\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "die Seidenroben rauschten und prahlten;", "tokens": ["die", "Sei\u00b7den\u00b7ro\u00b7ben", "rauschten", "und", "prahl\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "auch sprach man schon ... Ich legte die Rechte", "tokens": ["auch", "sprach", "man", "schon", "...", "Ich", "leg\u00b7te", "die", "Rech\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$(", "PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "verbindlich an mein Westenl\u00e4tzchen", "tokens": ["ver\u00b7bind\u00b7lich", "an", "mein", "Wes\u00b7ten\u00b7l\u00e4tz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "und \u2013 f\u00fchlte nach meiner Knutenflechte,", "tokens": ["und", "\u2013", "f\u00fchl\u00b7te", "nach", "mei\u00b7ner", "Knu\u00b7ten\u00b7flech\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "sie steckte sicher; na warte, Sch\u00e4tzchen!", "tokens": ["sie", "steck\u00b7te", "si\u00b7cher", ";", "na", "war\u00b7te", ",", "Sch\u00e4tz\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "ITJ", "VVFIN", "$,", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Laut: \u00bbGn\u00e4'ge Frau, ich habe das Gl\u00fcck,\u00ab", "tokens": ["Laut", ":", "\u00bb", "Gn\u00e4'\u00b7ge", "Frau", ",", "ich", "ha\u00b7be", "das", "Gl\u00fcck", ",", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "$.", "$(", "ADJA", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$,", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.15": {"text": "sie schien mich gar nicht wiederzukennen,", "tokens": ["sie", "schien", "mich", "gar", "nicht", "wie\u00b7der\u00b7zu\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "ich nahm die Ehre, mich zu nennen \u2013", "tokens": ["ich", "nahm", "die", "Eh\u00b7re", ",", "mich", "zu", "nen\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "\u00bbah, der neue Herr Lektor. Ein'n Augenblick.\u00ab", "tokens": ["\u00bb", "ah", ",", "der", "neu\u00b7e", "Herr", "Lek\u00b7tor", ".", "Ein'n", "Au\u00b7gen\u00b7blick", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ART", "ADJA", "NN", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.18": {"text": "Nat\u00fcrlich! sie hatte jetzt h\u00f6here Ziele,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "!", "sie", "hat\u00b7te", "jetzt", "h\u00f6\u00b7he\u00b7re", "Zie\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "PPER", "VAFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.19": {"text": "die Geheime Comm.-Rath S. von Kohn,", "tokens": ["die", "Ge\u00b7hei\u00b7me", "Comm", ".", "S.", "von", "Kohn", ","], "token_info": ["word", "word", "word", "punct", "word", "abbreviation", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "NN", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.20": {"text": "als ihre plebejischen Kinderspiele;", "tokens": ["als", "ih\u00b7re", "ple\u00b7be\u00b7ji\u00b7schen", "Kin\u00b7der\u00b7spie\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "sie war ja bei Hofe Vertrauensperson!", "tokens": ["sie", "war", "ja", "bei", "Ho\u00b7fe", "Ver\u00b7trau\u00b7en\u00b7sper\u00b7son", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "NN", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.22": {"text": "Sonst schien sie aber nicht ver\u00e4ndert,", "tokens": ["Sonst", "schien", "sie", "a\u00b7ber", "nicht", "ver\u00b7\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "nur sozusagen zart conservirt,", "tokens": ["nur", "so\u00b7zu\u00b7sa\u00b7gen", "zart", "con\u00b7ser\u00b7virt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "die verschleierten Augen pikant umr\u00e4ndert,", "tokens": ["die", "ver\u00b7schlei\u00b7er\u00b7ten", "Au\u00b7gen", "pi\u00b7kant", "um\u00b7r\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "--+--+--+-+-", "measure": "anapaest.tri.plus"}, "line.25": {"text": "und ein wenig ", "tokens": ["und", "ein", "we\u00b7nig"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "PIS"], "meter": "+-+-", "measure": "trochaic.di"}, "line.26": {"text": "Dem Herrn Geheimen schien, wie Allen,", "tokens": ["Dem", "Herrn", "Ge\u00b7hei\u00b7men", "schien", ",", "wie", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "PWAV", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "seine Geheime sehr zu gefallen.", "tokens": ["sei\u00b7ne", "Ge\u00b7hei\u00b7me", "sehr", "zu", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.13": {"line.1": {"text": "Nun fing man an von Kunst zu sprechen.", "tokens": ["Nun", "fing", "man", "an", "von", "Kunst", "zu", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Herr Geheime sprach: \u00bbVer\u00dfeihn Se,", "tokens": ["Der", "Herr", "Ge\u00b7hei\u00b7me", "sprach", ":", "\u00bb", "Ver\u00b7\u00dfeihn", "Se", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "$(", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wenn ich so frei bin aufzubrechen,", "tokens": ["wenn", "ich", "so", "frei", "bin", "auf\u00b7zu\u00b7bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "ich habe Gesch\u00e4fte beim Hofrat Heinse.\u00ab", "tokens": ["ich", "ha\u00b7be", "Ge\u00b7sch\u00e4f\u00b7te", "beim", "Hof\u00b7rat", "Hein\u00b7se", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPRART", "NN", "NN", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "\u00bboh\u00ab \u2013 \u00bbleider\u00ab \u2013 \u00bbbitte\u00ab \u2013 bedauerndes L\u00e4cheln,", "tokens": ["\u00bb", "oh", "\u00ab", "\u2013", "\u00bb", "lei\u00b7der", "\u00ab", "\u2013", "\u00bb", "bit\u00b7te", "\u00ab", "\u2013", "be\u00b7dau\u00b7ern\u00b7des", "L\u00e4\u00b7cheln", ","], "token_info": ["punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "$(", "$(", "$(", "ADV", "$(", "$(", "$(", "PTKANT", "$(", "$(", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Verbeugen und Neigen und Wangenf\u00e4cheln \u2013", "tokens": ["Ver\u00b7beu\u00b7gen", "und", "Nei\u00b7gen", "und", "Wan\u00b7gen\u00b7f\u00e4\u00b7cheln", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "\u00bbja, leider dringende Commission,\u00ab", "tokens": ["\u00bb", "ja", ",", "lei\u00b7der", "drin\u00b7gen\u00b7de", "Com\u00b7mis\u00b7si\u00b7on", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "ADV", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "verschwand mit W\u00fcrde Herr S. von Kohn;", "tokens": ["ver\u00b7schwand", "mit", "W\u00fcr\u00b7de", "Herr", "S.", "von", "Kohn", ";"], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "NN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "nun ging es hoffentlich bald los.", "tokens": ["nun", "ging", "es", "hof\u00b7fent\u00b7lich", "bald", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "Ich sah mich um \u2013 i Gott soll sch\u00fctzen,", "tokens": ["Ich", "sah", "mich", "um", "\u2013", "i", "Gott", "soll", "sch\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "$(", "NE", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "da schienen ja lauter Bekannte zu sitzen!", "tokens": ["da", "schie\u00b7nen", "ja", "lau\u00b7ter", "Be\u00b7kann\u00b7te", "zu", "sit\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.12": {"text": "Da rechts \u2013 Frau Consistorialrath Kloo\u00df,", "tokens": ["Da", "rechts", "\u2013", "Frau", "Con\u00b7sis\u00b7to\u00b7ri\u00b7al\u00b7rath", "Kloo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$(", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "geborene Freiin von Kronenspro\u00df.", "tokens": ["ge\u00b7bo\u00b7re\u00b7ne", "Frei\u00b7in", "von", "Kro\u00b7nens\u00b7pro\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.14": {"text": "Da \u2013 Fr\u00e4ulein Rosaura von Entenschnabel,", "tokens": ["Da", "\u2013", "Fr\u00e4u\u00b7lein", "Ro\u00b7sau\u00b7ra", "von", "En\u00b7ten\u00b7schna\u00b7bel", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "NN", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "da die Pate mit dem verbundenen Nabel,", "tokens": ["da", "die", "Pa\u00b7te", "mit", "dem", "ver\u00b7bun\u00b7de\u00b7nen", "Na\u00b7bel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.16": {"text": "und Frau von Knoch mit ihrem Begleiter,", "tokens": ["und", "Frau", "von", "Knoch", "mit", "ih\u00b7rem", "Be\u00b7glei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "und die Pastertochter \u2013 na und so weiter:", "tokens": ["und", "die", "Pas\u00b7ter\u00b7toch\u00b7ter", "\u2013", "na", "und", "so", "wei\u00b7ter", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$(", "ITJ", "KON", "ADV", "ADV", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "das ganze gediegene Lesekr\u00e4nzchen,", "tokens": ["das", "gan\u00b7ze", "ge\u00b7die\u00b7ge\u00b7ne", "Le\u00b7se\u00b7kr\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "wie sie da sa\u00dfen und standen die Biedern", "tokens": ["wie", "sie", "da", "sa\u00b7\u00dfen", "und", "stan\u00b7den", "die", "Bie\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "++-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "auf ihren unaussprechlichen Gliedern,", "tokens": ["auf", "ih\u00b7ren", "un\u00b7aus\u00b7sprech\u00b7li\u00b7chen", "Glie\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "germanische wie semitische Pfl\u00e4nzchen:", "tokens": ["ger\u00b7ma\u00b7ni\u00b7sche", "wie", "se\u00b7mi\u00b7ti\u00b7sche", "Pfl\u00e4nz\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "KOKOM", "ADJA", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "oh Boccaccio, g\u00f6ttlicher Schmetterling,", "tokens": ["oh", "Boc\u00b7cac\u00b7cio", ",", "g\u00f6tt\u00b7li\u00b7cher", "Schmet\u00b7ter\u00b7ling", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "dies H\u00e4ufchen Gem\u00fcse in Einer Sch\u00fcssel,", "tokens": ["dies", "H\u00e4uf\u00b7chen", "Ge\u00b7m\u00fc\u00b7se", "in", "Ei\u00b7ner", "Sch\u00fcs\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.24": {"text": "das w\u00e4r was gewesen f\u00fcr Deinen R\u00fcssel,", "tokens": ["das", "w\u00e4r", "was", "ge\u00b7we\u00b7sen", "f\u00fcr", "Dei\u00b7nen", "R\u00fcs\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIS", "VAPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.25": {"text": "wenn nicht auch Dir der Spa\u00df verging!", "tokens": ["wenn", "nicht", "auch", "Dir", "der", "Spa\u00df", "ver\u00b7ging", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Ja: ihr ganzes Leben lag vor mir offen,", "tokens": ["Ja", ":", "ihr", "gan\u00b7zes", "Le\u00b7ben", "lag", "vor", "mir", "of\u00b7fen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.27": {"text": "ich kannte sie Alle \u2013 und das Pack", "tokens": ["ich", "kann\u00b7te", "sie", "Al\u00b7le", "\u2013", "und", "das", "Pack"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "$(", "KON", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "schien nicht ein bi\u00dfchen davon betroffen,", "tokens": ["schien", "nicht", "ein", "bi\u00df\u00b7chen", "da\u00b7von", "be\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ART", "PIS", "PAV", "VVPP", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.29": {"text": "na wart't! ich f\u00fchlte an meinen Frack.", "tokens": ["na", "wart't", "!", "ich", "f\u00fchl\u00b7te", "an", "mei\u00b7nen", "Frack", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Ja \u2013 die Frau Geheime war augenscheinlich", "tokens": ["Ja", "\u2013", "die", "Frau", "Ge\u00b7hei\u00b7me", "war", "au\u00b7gen\u00b7schein\u00b7lich"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "ART", "NN", "NN", "VAFIN", "ADJD"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.31": {"text": "in ihrem Umgang \u00e4u\u00dferst reinlich.", "tokens": ["in", "ih\u00b7rem", "Um\u00b7gang", "\u00e4u\u00b7\u00dferst", "rein\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Gott sei getrommelt und gepfiffen:", "tokens": ["Gott", "sei", "ge\u00b7trom\u00b7melt", "und", "ge\u00b7pfif\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "KON", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "jetzt winkte sie. Die ganze Herde", "tokens": ["jetzt", "wink\u00b7te", "sie", ".", "Die", "gan\u00b7ze", "Her\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "war pl\u00f6tzlich ehrfurchtsvoll ergriffen,", "tokens": ["war", "pl\u00f6tz\u00b7lich", "ehr\u00b7furchts\u00b7voll", "er\u00b7grif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und mit entsprechender Geberde", "tokens": ["und", "mit", "ent\u00b7spre\u00b7chen\u00b7der", "Ge\u00b7ber\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "sprach die Geheime: \u00bbLieben Freunde,", "tokens": ["sprach", "die", "Ge\u00b7hei\u00b7me", ":", "\u00bb", "Lie\u00b7ben", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "$(", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "ich bin entz\u00fcckt und hingerissen,", "tokens": ["ich", "bin", "ent\u00b7z\u00fcckt", "und", "hin\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df meine kleine Kunstgemeinde", "tokens": ["da\u00df", "mei\u00b7ne", "klei\u00b7ne", "Kunst\u00b7ge\u00b7mein\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "so treu zusammenh\u00e4lt. Sie wissen,", "tokens": ["so", "treu", "zu\u00b7sam\u00b7men\u00b7h\u00e4lt", ".", "Sie", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "da\u00df wir uns heute dem unendlich", "tokens": ["da\u00df", "wir", "uns", "heu\u00b7te", "dem", "un\u00b7end\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ADV", "ART", "ADJD"], "meter": "++-+---+-", "measure": "unknown.measure.tetra"}, "line.10": {"text": "von uns verehrten, wundervollen", "tokens": ["von", "uns", "ver\u00b7ehr\u00b7ten", ",", "wun\u00b7der\u00b7vol\u00b7len"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "VVFIN", "$,", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Genie von Weimar widmen wollen,", "tokens": ["Ge\u00b7nie", "von", "Wei\u00b7mar", "wid\u00b7men", "wol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "das hei\u00dft mit Auswahl selbstverst\u00e4ndlich.", "tokens": ["das", "hei\u00dft", "mit", "Aus\u00b7wahl", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Ich darf wol bitten \u2013 hier, mein Lieber,\u00ab", "tokens": ["Ich", "darf", "wol", "bit\u00b7ten", "\u2013", "hier", ",", "mein", "Lie\u00b7ber", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADV", "VVINF", "$(", "ADV", "$,", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "das ging an meine Wenigkeit,", "tokens": ["das", "ging", "an", "mei\u00b7ne", "We\u00b7nig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "sie reichte mir den Faust her\u00fcber \u2013", "tokens": ["sie", "reich\u00b7te", "mir", "den", "Faust", "her\u00b7\u00fc\u00b7ber", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbdie gestrichenen Stellen zu beachten;", "tokens": ["\u00bb", "die", "ge\u00b7stri\u00b7che\u00b7nen", "Stel\u00b7len", "zu", "be\u00b7ach\u00b7ten", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "wenn's dann gef\u00e4llig, wir sind bereit.\u00ab", "tokens": ["wenn's", "dann", "ge\u00b7f\u00e4l\u00b7lig", ",", "wir", "sind", "be\u00b7reit", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ADJD", "$,", "PPER", "VAFIN", "ADJD", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.18": {"text": "Ich sah in das Buch; zwei Diener brachten", "tokens": ["Ich", "sah", "in", "das", "Buch", ";", "zwei", "Die\u00b7ner", "brach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "CARD", "NN", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "mir Lesepult und Wasserglas;", "tokens": ["mir", "Le\u00b7se\u00b7pult", "und", "Was\u00b7ser\u00b7glas", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "ich sah in das Buch. Ei Teufel \u2013 das,", "tokens": ["ich", "sah", "in", "das", "Buch", ".", "Ei", "Teu\u00b7fel", "\u2013", "das", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "NN", "NE", "$(", "PDS", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "das ging wahrhaftig \u00fcber den Spa\u00df:", "tokens": ["das", "ging", "wahr\u00b7haf\u00b7tig", "\u00fc\u00b7ber", "den", "Spa\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "da war ja Alles, schien's, gestrichen.", "tokens": ["da", "war", "ja", "Al\u00b7les", ",", "schien's", ",", "ge\u00b7stri\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PIS", "$,", "ADJA", "$,", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Na, ich nahm Platz; die Diener schlichen", "tokens": ["Na", ",", "ich", "nahm", "Platz", ";", "die", "Die\u00b7ner", "schli\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "NN", "$.", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "lautlos hinaus \u2013 ich machte tief", "tokens": ["laut\u00b7los", "hin\u00b7aus", "\u2013", "ich", "mach\u00b7te", "tief"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "PTKVZ", "$(", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "mein Kompliment \u2013 mein Auge lief", "tokens": ["mein", "Kom\u00b7pli\u00b7ment", "\u2013", "mein", "Au\u00b7ge", "lief"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "die Bl\u00e4tter durch \u2013 aha! hier oben", "tokens": ["die", "Bl\u00e4t\u00b7ter", "durch", "\u2013", "a\u00b7ha", "!", "hier", "o\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPR", "$(", "ITJ", "$.", "ADV", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "ein ganz besonders dicker Strich!", "tokens": ["ein", "ganz", "be\u00b7son\u00b7ders", "di\u00b7cker", "Strich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "und salbungsvoll das Kinn gehoben,", "tokens": ["und", "sal\u00b7bungs\u00b7voll", "das", "Kinn", "ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "begann ich ernst und feierlich:", "tokens": ["be\u00b7gann", "ich", "ernst", "und", "fei\u00b7er\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "\u00bbein Jeder lernt nur, was er lernen kann,", "tokens": ["\u00bb", "ein", "Je\u00b7der", "lernt", "nur", ",", "was", "er", "ler\u00b7nen", "kann", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PIS", "VVFIN", "ADV", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Vergebens da\u00df ihr wissenschaftlich schweift;", "tokens": ["Ver\u00b7ge\u00b7bens", "da\u00df", "ihr", "wis\u00b7sen\u00b7schaft\u00b7lich", "schweift", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch wer den Augenblick ergreift\u00ab \u2013", "tokens": ["Doch", "wer", "den", "Au\u00b7gen\u00b7blick", "er\u00b7greift", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "man horchte auf \u2013 \u00bbDas ist der rechte Mann.", "tokens": ["man", "horch\u00b7te", "auf", "\u2013", "\u00bb", "Das", "ist", "der", "rech\u00b7te", "Mann", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "$(", "$(", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ihr seid noch ziemlich wohlgebaut\u00ab,", "tokens": ["Ihr", "seid", "noch", "ziem\u00b7lich", "wohl\u00b7ge\u00b7baut", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Fr\u00e4ulein Rosaura nickte zart,", "tokens": ["Fr\u00e4u\u00b7lein", "Ro\u00b7sau\u00b7ra", "nick\u00b7te", "zart", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "ADJD", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.7": {"text": "\u00bban K\u00fchnheit wird's euch auch nicht fehlen,", "tokens": ["\u00bb", "an", "K\u00fchn\u00b7heit", "wird's", "euch", "auch", "nicht", "feh\u00b7len", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "VAFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und wenn ihr euch nur selbst vertraut\u00ab,", "tokens": ["Und", "wenn", "ihr", "euch", "nur", "selbst", "ver\u00b7traut", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "ADV", "ADV", "ADJD", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "ich griff mir schmachtend in den Bart,", "tokens": ["ich", "griff", "mir", "schmach\u00b7tend", "in", "den", "Bart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Fr\u00e4ulein Rosaura sa\u00df erstarrt,", "tokens": ["Fr\u00e4u\u00b7lein", "Ro\u00b7sau\u00b7ra", "sa\u00df", "er\u00b7starrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "VVPP", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.11": {"text": "\u00bbvertraun euch auch die andern Seelen.", "tokens": ["\u00bb", "ver\u00b7traun", "euch", "auch", "die", "an\u00b7dern", "See\u00b7len", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Besonders lernt die Weiber f\u00fchren\u00ab,", "tokens": ["Be\u00b7son\u00b7ders", "lernt", "die", "Wei\u00b7ber", "f\u00fch\u00b7ren", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "der Pastertochter wurde schwach,", "tokens": ["der", "Pas\u00b7ter\u00b7toch\u00b7ter", "wur\u00b7de", "schwach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "\u00bbes ist ihr ewig Weh und Ach\u00ab,", "tokens": ["\u00bb", "es", "ist", "ihr", "e\u00b7wig", "Weh", "und", "Ach", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ADJD", "NN", "KON", "NN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "die Pate schien der Schlag zu r\u00fchren,", "tokens": ["die", "Pa\u00b7te", "schien", "der", "Schlag", "zu", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbso tausendfach\u00ab \u2013", "tokens": ["\u00bb", "so", "tau\u00b7send\u00b7fach", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$(", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Frau Kloo\u00df erkannte mit Gewimmer:", "tokens": ["Frau", "Kloo\u00df", "er\u00b7kann\u00b7te", "mit", "Ge\u00b7wim\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Herr Gott, das wird ja immer schlimmer \u2013", "tokens": ["Herr", "Gott", ",", "das", "wird", "ja", "im\u00b7mer", "schlim\u00b7mer", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PDS", "VAFIN", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "\u00bbaus Einem Punkte zu kurieren.", "tokens": ["\u00bb", "aus", "Ei\u00b7nem", "Punk\u00b7te", "zu", "ku\u00b7rie\u00b7ren", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und wenn ihr halbweg ehrbar thut\u00ab,", "tokens": ["Und", "wenn", "ihr", "halb\u00b7weg", "ehr\u00b7bar", "thut", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "jetzt ging ein \u00c4chzen durch das Zimmer,", "tokens": ["jetzt", "ging", "ein", "\u00c4ch\u00b7zen", "durch", "das", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "\u00bbversteht das P\u00fclslein wohl zu dr\u00fccken\u00ab,", "tokens": ["\u00bb", "ver\u00b7steht", "das", "P\u00fcls\u00b7lein", "wohl", "zu", "dr\u00fc\u00b7cken", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "die Frau Geheime schien zu sticken,", "tokens": ["die", "Frau", "Ge\u00b7hei\u00b7me", "schien", "zu", "sti\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "\u00bbhabt ihr sie Alle unterm Hut.", "tokens": ["\u00bb", "habt", "ihr", "sie", "Al\u00b7le", "un\u00b7term", "Hut", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "PIAT", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Und fa\u00dft ihr sie mit feurig schlauen Blicken\u00ab,", "tokens": ["Und", "fa\u00dft", "ihr", "sie", "mit", "feu\u00b7rig", "schlau\u00b7en", "Bli\u00b7cken", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "ADJD", "ADJA", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "schrie ich \u2013 \u00bbverdammte verquiente Brut,", "tokens": ["schrie", "ich", "\u2013", "\u00bb", "ver\u00b7damm\u00b7te", "ver\u00b7qui\u00b7en\u00b7te", "Brut", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "$(", "ADJA", "ADJA", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.27": {"text": "Wol um die schlanke H\u00fcfte frei,", "tokens": ["Wol", "um", "die", "schlan\u00b7ke", "H\u00fcf\u00b7te", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.28": {"text": "Zu sehn, wie fest geschn\u00fcrt sie sei\u00ab \u2013 \u2013", "tokens": ["Zu", "sehn", ",", "wie", "fest", "ge\u00b7schn\u00fcrt", "sie", "sei", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PTKZU", "VVINF", "$,", "PWAV", "ADJD", "VVPP", "PPER", "VAFIN", "$(", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "da platzte die Bombe, ein Jammergeschrei,", "tokens": ["da", "platz\u00b7te", "die", "Bom\u00b7be", ",", "ein", "Jam\u00b7mer\u00b7ge\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.30": {"text": "die Frau Geheime lag auf dem R\u00fccken.", "tokens": ["die", "Frau", "Ge\u00b7hei\u00b7me", "lag", "auf", "dem", "R\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Und krach! auf die Diele das Wasserglas", "tokens": ["Und", "krach", "!", "auf", "die", "Die\u00b7le", "das", "Was\u00b7ser\u00b7glas"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "$.", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.32": {"text": "und den Lesetisch, und heraus die Knute:", "tokens": ["und", "den", "Le\u00b7se\u00b7tisch", ",", "und", "he\u00b7raus", "die", "Knu\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "KON", "ADV", "ART", "NN", "$."], "meter": "--+---+--+-", "measure": "iambic.tri.relaxed"}, "line.33": {"text": "\u00bbnu t\u00e4uw, du schielige Zimperpute \u2013", "tokens": ["\u00bb", "nu", "t\u00e4uw", ",", "du", "schie\u00b7li\u00b7ge", "Zim\u00b7per\u00b7pu\u00b7te", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "PPER", "ADJA", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.34": {"text": "Karline, jetzt kommt der Kontraba\u00df!", "tokens": ["Kar\u00b7li\u00b7ne", ",", "jetzt", "kommt", "der", "Kon\u00b7tra\u00b7ba\u00df", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.35": {"text": "jetzt will ich dir zeigen, wie man streicht!\u00ab", "tokens": ["jetzt", "will", "ich", "dir", "zei\u00b7gen", ",", "wie", "man", "streicht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "VVINF", "$,", "PWAV", "PIS", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.36": {"text": "und rietsch, da hatt ich sie beim Wickel.", "tokens": ["und", "rietsch", ",", "da", "hatt", "ich", "sie", "beim", "Wi\u00b7ckel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ADV", "VAFIN", "PPER", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Ei, alle Wetter: dies fette Karnickel,", "tokens": ["Ei", ",", "al\u00b7le", "Wet\u00b7ter", ":", "dies", "fet\u00b7te", "Kar\u00b7ni\u00b7ckel", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIAT", "NN", "$.", "PDS", "ADJA", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.38": {"text": "das war ja wie'ne Feder leicht!", "tokens": ["das", "war", "ja", "wie'\u00b7ne", "Fe\u00b7der", "leicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.39": {"text": "Und pl\u00f6tzlich \u2013 Teufel, was war denn ", "tokens": ["Und", "pl\u00f6tz\u00b7lich", "\u2013", "Teu\u00b7fel", ",", "was", "war", "denn"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "$(", "NE", "$,", "PWS", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Fr\u00e4ulein Rosaura sank fassungslos", "tokens": ["Fr\u00e4u\u00b7lein", "Ro\u00b7sau\u00b7ra", "sank", "fas\u00b7sungs\u00b7los"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.41": {"text": "dem Herrn vom Frauenwohl in den Schoo\u00df,", "tokens": ["dem", "Herrn", "vom", "Frau\u00b7en\u00b7wohl", "in", "den", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.42": {"text": "die Pate schnappte leichenbla\u00df", "tokens": ["die", "Pa\u00b7te", "schnapp\u00b7te", "lei\u00b7chen\u00b7bla\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "nach Luft: in meinen Fingern sa\u00df", "tokens": ["nach", "Luft", ":", "in", "mei\u00b7nen", "Fin\u00b7gern", "sa\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$.", "APPR", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "\u2013 die Frau Geheime bibberte nur \u2013", "tokens": ["\u2013", "die", "Frau", "Ge\u00b7hei\u00b7me", "bib\u00b7ber\u00b7te", "nur", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "NN", "VVFIN", "ADV", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.45": {"text": "ihre ganze bezaubernde Lockenfrisur.", "tokens": ["ih\u00b7re", "gan\u00b7ze", "be\u00b7zau\u00b7bern\u00b7de", "Lo\u00b7cken\u00b7fri\u00b7sur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.46": {"text": "Und auf der grau strupphaarigen Platte \u2013", "tokens": ["Und", "auf", "der", "grau", "strupp\u00b7haa\u00b7ri\u00b7gen", "Plat\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "mir ekelte \u2013 ein Schorf und Schinn", "tokens": ["mir", "e\u00b7kel\u00b7te", "\u2013", "ein", "Schorf", "und", "Schinn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "und Speck und Spinster, als klebte drin", "tokens": ["und", "Speck", "und", "Spins\u00b7ter", ",", "als", "kleb\u00b7te", "drin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.49": {"text": "die ganze abgekratzte Pomade", "tokens": ["die", "gan\u00b7ze", "ab\u00b7ge\u00b7kratz\u00b7te", "Po\u00b7ma\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.50": {"text": "von zehn Jahrhunderten festgefilzt,", "tokens": ["von", "zehn", "Jahr\u00b7hun\u00b7der\u00b7ten", "fest\u00b7ge\u00b7filzt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.51": {"text": "so eingeschimmelt und verpilzt.", "tokens": ["so", "ein\u00b7ge\u00b7schim\u00b7melt", "und", "ver\u00b7pilzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Die ganze Bande lag in Kr\u00e4mpfen \u2013", "tokens": ["Die", "gan\u00b7ze", "Ban\u00b7de", "lag", "in", "Kr\u00e4mp\u00b7fen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "na wart't, Canaillen, es kommt noch besser,", "tokens": ["na", "wart't", ",", "Ca\u00b7nail\u00b7len", ",", "es", "kommt", "noch", "bes\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$,", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "ich will euch schon die Ohnmacht d\u00e4mpfen!", "tokens": ["ich", "will", "euch", "schon", "die", "Ohn\u00b7macht", "d\u00e4mp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und schnipp schnapp flitz: mein Federmesser:", "tokens": ["Und", "schnipp", "schnapp", "flitz", ":", "mein", "Fe\u00b7der\u00b7mes\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "PTKVZ", "$.", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "herrjeh, wie wurden sie pl\u00f6tzlich munter \u2013", "tokens": ["herr\u00b7jeh", ",", "wie", "wur\u00b7den", "sie", "pl\u00f6tz\u00b7lich", "mun\u00b7ter", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "VAFIN", "PPER", "ADJD", "ADJD", "$("], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.6": {"text": "Frau Kloo\u00df, geborene Freiin, schrie:", "tokens": ["Frau", "Kloo\u00df", ",", "ge\u00b7bo\u00b7re\u00b7ne", "Frei\u00b7in", ",", "schrie", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "NN", "$,", "ADJA", "NN", "$,", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bballm\u00e4chtiger Vater, er mordet sie\u00ab \u2013", "tokens": ["\u00bb", "all\u00b7m\u00e4ch\u00b7ti\u00b7ger", "Va\u00b7ter", ",", "er", "mor\u00b7det", "sie", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "PPER", "VVFIN", "PPER", "$(", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "und holter di polter, stuhl\u00fcber stuhlunter,", "tokens": ["und", "hol\u00b7ter", "di", "pol\u00b7ter", ",", "stuh\u00b7l\u00fc\u00b7ber", "stuhl\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJA", "NE", "NE", "$,", "ADV", "ADJD", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "als ob ein Satan zwischen sie f\u00fchre,", "tokens": ["als", "ob", "ein", "Sa\u00b7tan", "zwi\u00b7schen", "sie", "f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.10": {"text": "das ganze gediegene Lesekr\u00e4nzchen,", "tokens": ["das", "gan\u00b7ze", "ge\u00b7die\u00b7ge\u00b7ne", "Le\u00b7se\u00b7kr\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "germanische wie semitische Pfl\u00e4nzchen,", "tokens": ["ger\u00b7ma\u00b7ni\u00b7sche", "wie", "se\u00b7mi\u00b7ti\u00b7sche", "Pfl\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "KOKOM", "ADJA", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "klabotter klabatter hinaus zur Th\u00fcre.", "tokens": ["kla\u00b7bot\u00b7ter", "kla\u00b7bat\u00b7ter", "hin\u00b7aus", "zur", "Th\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APZR", "APPRART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbso, Schatz!\u00ab ich nahm sie sacht beim Kragen,", "tokens": ["\u00bb", "so", ",", "Schatz", "!", "\u00ab", "ich", "nahm", "sie", "sacht", "beim", "Kra\u00b7gen", ","], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$,", "NN", "$.", "$(", "PPER", "VVFIN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zum Gl\u00fcck hatt'ich noch Handschuh an \u2013", "tokens": ["zum", "Gl\u00fcck", "hatt'\u00b7ich", "noch", "Hand\u00b7schuh", "an", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbjetzt wollen wir mal, wie zwischen Mann", "tokens": ["\u00bb", "jetzt", "wol\u00b7len", "wir", "mal", ",", "wie", "zwi\u00b7schen", "Mann"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "ADV", "VMFIN", "PPER", "ADV", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "und Weib das manchmal soll passieren,", "tokens": ["und", "Weib", "das", "manch\u00b7mal", "soll", "pas\u00b7sie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "ADV", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "uns etwas n\u00e4her inspiciren!\u00ab", "tokens": ["uns", "et\u00b7was", "n\u00e4\u00b7her", "ins\u00b7pi\u00b7ci\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Quietsch, legte sie los mit Zappeln und Klagen", "tokens": ["Qui\u00b7etsch", ",", "leg\u00b7te", "sie", "los", "mit", "Zap\u00b7peln", "und", "Kla\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "APPR", "NN", "KON", "NN"], "meter": "+-+--+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.7": {"text": "und D\u00e4mpfelassen und Wasserschlagen \u2013", "tokens": ["und", "D\u00e4mp\u00b7fe\u00b7las\u00b7sen", "und", "Was\u00b7ser\u00b7schla\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "wei\u00df Gott, mir wurde wieder \u00fcbel.", "tokens": ["wei\u00df", "Gott", ",", "mir", "wur\u00b7de", "wie\u00b7der", "\u00fc\u00b7bel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Na, ich spuckte mir's weg \u2013 und \u00bbNa warte, du Zwiebel\u00ab", "tokens": ["Na", ",", "ich", "spuck\u00b7te", "mir's", "weg", "\u2013", "und", "\u00bb", "Na", "war\u00b7te", ",", "du", "Zwie\u00b7bel", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "NE", "PTKVZ", "$(", "KON", "$(", "ITJ", "VVFIN", "$,", "PPER", "NN", "$("], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.10": {"text": "langt'ich die Knute vom Teppich hoch,", "tokens": ["langt'\u00b7ich", "die", "Knu\u00b7te", "vom", "Tep\u00b7pich", "hoch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "\u00bbbist endlich ruhig mit deinem Loch?", "tokens": ["\u00bb", "bist", "end\u00b7lich", "ru\u00b7hig", "mit", "dei\u00b7nem", "Loch", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "sonst gibt's mit der da aufs Hinterst\u00fcbel!\u00ab", "tokens": ["sonst", "gibt's", "mit", "der", "da", "aufs", "Hin\u00b7ter\u00b7st\u00fc\u00b7bel", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADV", "APPRART", "NN", "$.", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.13": {"text": "Und rietsch raatsch runter die Br\u00fcsseler Spitzen", "tokens": ["Und", "rietsch", "raatsch", "run\u00b7ter", "die", "Br\u00fcs\u00b7se\u00b7ler", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADJD", "ADJD", "ART", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "und Seidenfranjen und Sammetlitzen,", "tokens": ["und", "Sei\u00b7den\u00b7fran\u00b7jen", "und", "Sam\u00b7met\u00b7lit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "und schlitz \u2013 an Kn\u00f6pfen war nicht zu denken,", "tokens": ["und", "schlitz", "\u2013", "an", "Kn\u00f6p\u00b7fen", "war", "nicht", "zu", "den\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$(", "APPR", "NN", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "so war die Zimpe verschn\u00fcrt und verschnallt \u2013", "tokens": ["so", "war", "die", "Zim\u00b7pe", "ver\u00b7schn\u00fcrt", "und", "ver\u00b7schnallt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "KON", "VVFIN", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "das Federmesser! und \u2013 \u2013 brrr, schnitt's kalt", "tokens": ["das", "Fe\u00b7der\u00b7mes\u00b7ser", "!", "und", "\u2013", "\u2013", "brrr", ",", "schnitt's", "kalt"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$.", "KON", "$(", "$(", "NE", "$,", "VVFIN", "ADJD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "und hei\u00df mir selber in allen Gelenken,", "tokens": ["und", "hei\u00df", "mir", "sel\u00b7ber", "in", "al\u00b7len", "Ge\u00b7len\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "wie da aus Flunker und Flitter und Flatter,", "tokens": ["wie", "da", "aus", "Flun\u00b7ker", "und", "Flit\u00b7ter", "und", "Flat\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "aus Fetzengeknitter und Fadengeknatter", "tokens": ["aus", "Fet\u00b7zen\u00b7ge\u00b7knit\u00b7ter", "und", "Fa\u00b7den\u00b7ge\u00b7knat\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.21": {"text": "und Watte und Wolle und Fischbeinzacken", "tokens": ["und", "Wat\u00b7te", "und", "Wol\u00b7le", "und", "Fischbein\u00b7za\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "und Gummi-Busen und -Hinterbacken", "tokens": ["und", "Gum\u00b7mi\u00b7Bu\u00b7sen", "und"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "mit Winseln und Betteln und Strampeln und Schelten", "tokens": ["mit", "Win\u00b7seln", "und", "Bet\u00b7teln", "und", "Stram\u00b7peln", "und", "Schel\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.24": {"text": "sich diese \u2013 vermickerten Knickknochen pellten.", "tokens": ["sich", "die\u00b7se", "\u2013", "ver\u00b7mi\u00b7cker\u00b7ten", "Knick\u00b7kno\u00b7chen", "pell\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "PDAT", "$(", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+---+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Ich stand \u2013 na, wie das Kind beim Drecke.", "tokens": ["Ich", "stand", "\u2013", "na", ",", "wie", "das", "Kind", "beim", "Dre\u00b7cke", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ITJ", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Henker! um diese verschrumpelte Schrippe,", "tokens": ["Zum", "Hen\u00b7ker", "!", "um", "die\u00b7se", "ver\u00b7schrum\u00b7pel\u00b7te", "Schrip\u00b7pe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "dies Bastardkl\u00fcmpchen von Spinne und Schnecke,", "tokens": ["dies", "Bas\u00b7tard\u00b7kl\u00fcmp\u00b7chen", "von", "Spin\u00b7ne", "und", "Schne\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "dies d\u00fcrre, vermuffte Altjungferngerippe,", "tokens": ["dies", "d\u00fcr\u00b7re", ",", "ver\u00b7muff\u00b7te", "Alt\u00b7jung\u00b7fern\u00b7ge\u00b7rip\u00b7pe", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "da hatte ich Narr mich so geplagt?!", "tokens": ["da", "hat\u00b7te", "ich", "Narr", "mich", "so", "ge\u00b7plagt", "?!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Zwar Jungfer \u2013 Das zu untersuchen", "tokens": ["Zwar", "Jung\u00b7fer", "\u2013", "Das", "zu", "un\u00b7ter\u00b7su\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "NE", "$(", "PDS", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "bei diesem verpimperten Hutzelkuchen,", "tokens": ["bei", "die\u00b7sem", "ver\u00b7pim\u00b7per\u00b7ten", "Hut\u00b7zel\u00b7ku\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "das h\u00e4tte wol kaum ein Arzt gewagt.", "tokens": ["das", "h\u00e4t\u00b7te", "wol", "kaum", "ein", "Arzt", "ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Ich konnte mich immer noch nicht fassen,", "tokens": ["Ich", "konn\u00b7te", "mich", "im\u00b7mer", "noch", "nicht", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "PTKNEG", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "blos heimlich w\u00fcnscht'ich: h\u00e4tt'ich ihr doch", "tokens": ["blos", "heim\u00b7lich", "w\u00fcnscht'\u00b7ich", ":", "h\u00e4tt'\u00b7ich", "ihr", "doch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADJD", "$.", "ADJD", "PPER", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.11": {"text": "das Hemde wenigstens angelassen!", "tokens": ["das", "Hem\u00b7de", "we\u00b7nigs\u00b7tens", "an\u00b7ge\u00b7las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Pfui Teufel \u2013 wie sie da vor mir kroch", "tokens": ["Pfui", "Teu\u00b7fel", "\u2013", "wie", "sie", "da", "vor", "mir", "kroch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$(", "PWAV", "PPER", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "mit ihren Runzeln und Faltenschlitzen", "tokens": ["mit", "ih\u00b7ren", "Run\u00b7zeln", "und", "Fal\u00b7ten\u00b7schlit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "und ihren Zotteln und schlaffen Zitzen", "tokens": ["und", "ih\u00b7ren", "Zot\u00b7teln", "und", "schlaf\u00b7fen", "Zit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "und ihren ausgetrockneten Waden", "tokens": ["und", "ih\u00b7ren", "aus\u00b7ge\u00b7trock\u00b7ne\u00b7ten", "Wa\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "und eingetrockneten Hinterfladen,", "tokens": ["und", "ein\u00b7ge\u00b7trock\u00b7ne\u00b7ten", "Hin\u00b7ter\u00b7fla\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "und zwischen den schlotternden Schultern und Armen", "tokens": ["und", "zwi\u00b7schen", "den", "schlot\u00b7tern\u00b7den", "Schul\u00b7tern", "und", "Ar\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "KON", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.18": {"text": "auf der vermergelten Wirbelleiste", "tokens": ["auf", "der", "ver\u00b7mer\u00b7gel\u00b7ten", "Wir\u00b7bel\u00b7leis\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.19": {"text": "der griese, grindige Sch\u00e4del glei\u00dfte:", "tokens": ["der", "grie\u00b7se", ",", "grin\u00b7di\u00b7ge", "Sch\u00e4\u00b7del", "glei\u00df\u00b7te", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "mein Ekel stieg bis zum Erbarmen.", "tokens": ["mein", "E\u00b7kel", "stieg", "bis", "zum", "Er\u00b7bar\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Lern aber einer die Weiber kennen!", "tokens": ["Lern", "a\u00b7ber", "ei\u00b7ner", "die", "Wei\u00b7ber", "ken\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Noch eben mitten in Pl\u00e4rren und Flennen:", "tokens": ["Noch", "e\u00b7ben", "mit\u00b7ten", "in", "Pl\u00e4r\u00b7ren", "und", "Flen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "kaum merkte sie meine M\u00e4nnerschw\u00e4che \u2013", "tokens": ["kaum", "merk\u00b7te", "sie", "mei\u00b7ne", "M\u00e4n\u00b7ner\u00b7schw\u00e4\u00b7che", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "ich merkt'es selber erst durch sie,", "tokens": ["ich", "merkt'\u00b7es", "sel\u00b7ber", "erst", "durch", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "ADV", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "es war die reine Telepathie:", "tokens": ["es", "war", "die", "rei\u00b7ne", "Te\u00b7le\u00b7pa\u00b7thie", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "da grinst und \u00e4ugelt mich die freche", "tokens": ["da", "grinst", "und", "\u00e4u\u00b7gelt", "mich", "die", "fre\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "KON", "VVFIN", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Vettel mit ihrer geschminkten Fratze", "tokens": ["Vet\u00b7tel", "mit", "ih\u00b7rer", "ge\u00b7schmink\u00b7ten", "Frat\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.8": {"text": "so von unten \u00fcber die Achsel an,", "tokens": ["so", "von", "un\u00b7ten", "\u00fc\u00b7ber", "die", "Ach\u00b7sel", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": "da\u00df mir's durch beide Nieren rann.", "tokens": ["da\u00df", "mir's", "durch", "bei\u00b7de", "Nie\u00b7ren", "rann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ich wei\u00df nicht, ob die alte Katze", "tokens": ["Ich", "wei\u00df", "nicht", ",", "ob", "die", "al\u00b7te", "Kat\u00b7ze"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "mich etwa zu \u2013 begl\u00fccken dachte,", "tokens": ["mich", "et\u00b7wa", "zu", "\u2013", "be\u00b7gl\u00fc\u00b7cken", "dach\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "$(", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "ob sie sich \u00fcber mich lustig machte,", "tokens": ["ob", "sie", "sich", "\u00fc\u00b7ber", "mich", "lus\u00b7tig", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "ob diese abgetakelte Ratte", "tokens": ["ob", "die\u00b7se", "ab\u00b7ge\u00b7ta\u00b7kel\u00b7te", "Rat\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "in ihrer kahlen Scheu\u00dflichkeit", "tokens": ["in", "ih\u00b7rer", "kah\u00b7len", "Scheu\u00df\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "meinte, sie sei dadurch gefeit", "tokens": ["mein\u00b7te", ",", "sie", "sei", "da\u00b7durch", "ge\u00b7feit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VAFIN", "PAV", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.16": {"text": "ich sah nur unter der rundigen Platte.", "tokens": ["ich", "sah", "nur", "un\u00b7ter", "der", "run\u00b7di\u00b7gen", "Plat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "nur zwischen den gelben, verschmuzten Runzeln,", "tokens": ["nur", "zwi\u00b7schen", "den", "gel\u00b7ben", ",", "ver\u00b7schmuz\u00b7ten", "Run\u00b7zeln", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "den Pustelflecken und Zottenzunzeln,", "tokens": ["den", "Pus\u00b7tel\u00b7fle\u00b7cken", "und", "Zot\u00b7ten\u00b7zun\u00b7zeln", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "dies wei\u00df und rosa beschmierte Grinsen,", "tokens": ["dies", "wei\u00df", "und", "ro\u00b7sa", "be\u00b7schmier\u00b7te", "Grin\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "dies schlaue, gemeine Blicken und Blinsen,", "tokens": ["dies", "schlau\u00b7e", ",", "ge\u00b7mei\u00b7ne", "Bli\u00b7cken", "und", "Blin\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "und pl\u00f6tzlich fa\u00dfte mich eine Wut:", "tokens": ["und", "pl\u00f6tz\u00b7lich", "fa\u00df\u00b7te", "mich", "ei\u00b7ne", "Wut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "mir schien das ganze verfaulte Blut", "tokens": ["mir", "schien", "das", "gan\u00b7ze", "ver\u00b7faul\u00b7te", "Blut"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "unsrer vergreisten, verspensterten Zeit", "tokens": ["uns\u00b7rer", "ver\u00b7greis\u00b7ten", ",", "ver\u00b7spens\u00b7ter\u00b7ten", "Zeit"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.24": {"text": "in dieser Hexe zusammengebreit,", "tokens": ["in", "die\u00b7ser", "He\u00b7xe", "zu\u00b7sam\u00b7men\u00b7ge\u00b7breit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "und \u2013 \u00bbSo, nu pl\u00e4rre, verw\u00fcnschte Zicke,", "tokens": ["und", "\u2013", "\u00bb", "So", ",", "nu", "pl\u00e4r\u00b7re", ",", "ver\u00b7w\u00fcnschte", "Zi\u00b7cke", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$(", "$(", "ADV", "$,", "ADV", "VVFIN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "jetzt bin ich mit meiner Geduld zu Rand!\u00ab", "tokens": ["jetzt", "bin", "ich", "mit", "mei\u00b7ner", "Ge\u00b7duld", "zu", "Rand", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "APPR", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "hob ich zum Hiebe die Knutenstricke,", "tokens": ["hob", "ich", "zum", "Hie\u00b7be", "die", "Knu\u00b7ten\u00b7stri\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.28": {"text": "da \u2013 \u2013 legt sich sanft um meine Hand", "tokens": ["da", "\u2013", "\u2013", "legt", "sich", "sanft", "um", "mei\u00b7ne", "Hand"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$(", "$(", "VVFIN", "PRF", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "und r\u00fchrt mich bis ins weheste Mark", "tokens": ["und", "r\u00fchrt", "mich", "bis", "ins", "we\u00b7hes\u00b7te", "Mark"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.30": {"text": "wie junge Liebe so still und stark", "tokens": ["wie", "jun\u00b7ge", "Lie\u00b7be", "so", "still", "und", "stark"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "und warm, um meinen Hals gebogen,", "tokens": ["und", "warm", ",", "um", "mei\u00b7nen", "Hals", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUI", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "ein Arm, \u2013 und mild, voll Stolz und Huld,", "tokens": ["ein", "Arm", ",", "\u2013", "und", "mild", ",", "voll", "Stolz", "und", "Huld", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "$(", "KON", "ADJD", "$,", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "t\u00f6nt eines Atems leises Wogen:", "tokens": ["t\u00f6nt", "ei\u00b7nes", "A\u00b7tems", "lei\u00b7ses", "Wo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "\u00bbla\u00df ab! sie ", "tokens": ["\u00bb", "la\u00df", "ab", "!", "sie"], "token_info": ["punct", "word", "word", "punct", "word"], "pos": ["$(", "VVIMP", "PTKVZ", "$.", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.20": {"line.1": {"text": "Und wie sich nun mein Nacken wendet,", "tokens": ["Und", "wie", "sich", "nun", "mein", "Na\u00b7cken", "wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Schauern m\u00e4chtig \u00fcberwallt,", "tokens": ["von", "Schau\u00b7ern", "m\u00e4ch\u00b7tig", "\u00fc\u00b7berw\u00b7allt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da steh ich, fast von Scheu geblendet", "tokens": ["da", "steh", "ich", ",", "fast", "von", "Scheu", "ge\u00b7blen\u00b7det"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "vor dieser schimmernden Gestalt.", "tokens": ["vor", "die\u00b7ser", "schim\u00b7mern\u00b7den", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im matten Glanz der Gl\u00fchlichtglocken", "tokens": ["Im", "mat\u00b7ten", "Glanz", "der", "Gl\u00fch\u00b7licht\u00b7glo\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ist ihre Nacktheit heller Tag,", "tokens": ["ist", "ih\u00b7re", "Nackt\u00b7heit", "hel\u00b7ler", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "es geht ein Schein von Stirn und Locken", "tokens": ["es", "geht", "ein", "Schein", "von", "Stirn", "und", "Lo\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "wie Bl\u00fctenschmelz im Fr\u00fchlingshag.", "tokens": ["wie", "Bl\u00fc\u00b7ten\u00b7schmelz", "im", "Fr\u00fch\u00b7lings\u00b7hag", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Zur H\u00fcfte nieder um die Br\u00fcste", "tokens": ["Zur", "H\u00fcf\u00b7te", "nie\u00b7der", "um", "die", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "flie\u00dft mantelschwer ihr lang braun Haar", "tokens": ["flie\u00dft", "man\u00b7tel\u00b7schwer", "ihr", "lang", "braun", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "und wogt und flimmert goldenklar,", "tokens": ["und", "wogt", "und", "flim\u00b7mert", "gol\u00b7den\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "als ob ein Morgenwind sie k\u00fc\u00dfte.", "tokens": ["als", "ob", "ein", "Mor\u00b7gen\u00b7wind", "sie", "k\u00fc\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wei\u00df leuchtet aus der schlanken Rechten,", "tokens": ["Wei\u00df", "leuch\u00b7tet", "aus", "der", "schlan\u00b7ken", "Rech\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "zum Gru\u00df geneigt und zum Gebot,", "tokens": ["zum", "Gru\u00df", "ge\u00b7neigt", "und", "zum", "Ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "ein Lilienstab, den dunkelrot", "tokens": ["ein", "Li\u00b7li\u00b7en\u00b7stab", ",", "den", "dun\u00b7kel\u00b7rot"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "zwei volle Rosen dicht umflechten;", "tokens": ["zwei", "vol\u00b7le", "Ro\u00b7sen", "dicht", "um\u00b7flech\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "so steht sie wehrend, wundersam", "tokens": ["so", "steht", "sie", "weh\u00b7rend", ",", "wun\u00b7der\u00b7sam"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "begl\u00e4nzt. Und ich \u2013 mich \u00fcberkam", "tokens": ["be\u00b7gl\u00e4nzt", ".", "Und", "ich", "\u2013", "mich", "\u00fc\u00b7ber\u00b7kam"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "$.", "KON", "PPER", "$(", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "ein Ahnen wie Erinnerung,", "tokens": ["ein", "Ah\u00b7nen", "wie", "E\u00b7rin\u00b7ne\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "ein Sehnen neu und kinderjung:", "tokens": ["ein", "Seh\u00b7nen", "neu", "und", "kin\u00b7der\u00b7jung", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "ich hatte sie nie noch nimmer wo", "tokens": ["ich", "hat\u00b7te", "sie", "nie", "noch", "nim\u00b7mer", "wo"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "PWAV"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "gesehn, und wie mir dennoch so", "tokens": ["ge\u00b7sehn", ",", "und", "wie", "mir", "den\u00b7noch", "so"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KON", "PWAV", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "ihr blauklar Auge, seelenweit,", "tokens": ["ihr", "blau\u00b7klar", "Au\u00b7ge", ",", "see\u00b7len\u00b7weit", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "und ihres Mundes Z\u00e4rtlichkeit", "tokens": ["und", "ih\u00b7res", "Mun\u00b7des", "Z\u00e4rt\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "jedwedes Faserchen tief innen", "tokens": ["jed\u00b7we\u00b7des", "Fa\u00b7ser\u00b7chen", "tief", "in\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "ADJD", "ADV"], "meter": "++-+--++-", "measure": "trochaic.penta.relaxed"}, "line.26": {"text": "zu lauter Andacht lie\u00df gerinnen \u2013", "tokens": ["zu", "lau\u00b7ter", "An\u00b7dacht", "lie\u00df", "ge\u00b7rin\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "ach war's denn nicht, als s\u00e4he wieder", "tokens": ["ach", "wa\u00b7r's", "denn", "nicht", ",", "als", "s\u00e4\u00b7he", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "PTKNEG", "$,", "KOKOM", "VVFIN", "ADV"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.28": {"text": "meine liebe Mutter zu mir nieder?", "tokens": ["mei\u00b7ne", "lie\u00b7be", "Mut\u00b7ter", "zu", "mir", "nie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.29": {"text": "und nun verwirrt und fromm befangen", "tokens": ["und", "nun", "ver\u00b7wirrt", "und", "fromm", "be\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "KON", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "mein Blick an ihr zu Boden wollte", "tokens": ["mein", "Blick", "an", "ihr", "zu", "Bo\u00b7den", "woll\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "PPER", "APPR", "NN", "VMFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "und doch, in bangem Hinverlangen,", "tokens": ["und", "doch", ",", "in", "ban\u00b7gem", "Hin\u00b7ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "wie so ihr Haar an Ohr und Wangen", "tokens": ["wie", "so", "ihr", "Haar", "an", "Ohr", "und", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "und Br\u00fcsten schmeichelnd sie umrollte,", "tokens": ["und", "Br\u00fcs\u00b7ten", "schmei\u00b7chelnd", "sie", "um\u00b7roll\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "mein Herz nach ihrer Sch\u00f6nheit schrie,", "tokens": ["mein", "Herz", "nach", "ih\u00b7rer", "Sch\u00f6n\u00b7heit", "schrie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "als bebtest Du mir, Du mir wieder,", "tokens": ["als", "beb\u00b7test", "Du", "mir", ",", "Du", "mir", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PPER", "$,", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Du Eine Eine zu mir nieder", "tokens": ["Du", "Ei\u00b7ne", "Ei\u00b7ne", "zu", "mir", "nie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "ART", "APPR", "PPER", "PTKVZ"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "in deiner Reinheit, die mir nie", "tokens": ["in", "dei\u00b7ner", "Rein\u00b7heit", ",", "die", "mir", "nie"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "ein Wort noch Winkchen vorenthalten,", "tokens": ["ein", "Wort", "noch", "Wink\u00b7chen", "vor\u00b7ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "nicht Seel noch Leibs geheimste Falten,", "tokens": ["nicht", "Seel", "noch", "Leibs", "ge\u00b7heims\u00b7te", "Fal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "ADV", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "als l\u00e4s'ich ein ergr\u00fcndet Buch, \u2013", "tokens": ["als", "l\u00e4s'\u00b7ich", "ein", "er\u00b7gr\u00fcn\u00b7det", "Buch", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADJD", "PTKVZ", "VVFIN", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "und wie's so immer tiefer w\u00fchlte", "tokens": ["und", "wie's", "so", "im\u00b7mer", "tie\u00b7fer", "w\u00fchl\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "und s\u00fc\u00df und s\u00fc\u00dfer mich umh\u00fcllte", "tokens": ["und", "s\u00fc\u00df", "und", "s\u00fc\u00b7\u00dfer", "mich", "um\u00b7h\u00fcll\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.43": {"text": "der dunklen Rosen Wollgeruch:", "tokens": ["der", "dunk\u00b7len", "Ro\u00b7sen", "Woll\u00b7ge\u00b7ruch", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "es ri\u00df mich nieder ihr zu F\u00fc\u00dfen", "tokens": ["es", "ri\u00df", "mich", "nie\u00b7der", "ihr", "zu", "F\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "und machte meine Arme breit:", "tokens": ["und", "mach\u00b7te", "mei\u00b7ne", "Ar\u00b7me", "breit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "\u00bbwer bist du, Weib, in deiner s\u00fc\u00dfen,", "tokens": ["\u00bb", "wer", "bist", "du", ",", "Weib", ",", "in", "dei\u00b7ner", "s\u00fc\u00b7\u00dfen", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "PPER", "$,", "NN", "$,", "APPR", "PPOSAT", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "in deiner milden, herben, s\u00fc\u00dfen,", "tokens": ["in", "dei\u00b7ner", "mil\u00b7den", ",", "her\u00b7ben", ",", "s\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "$,", "VVPP", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "unsagbar s\u00fc\u00dfen Herrlichkeit?\u00ab", "tokens": ["un\u00b7sag\u00b7bar", "s\u00fc\u00b7\u00dfen", "Herr\u00b7lich\u00b7keit", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADJD", "ADJA", "NN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.21": {"line.1": {"text": "Und aus der Rechten sacht zur Linken", "tokens": ["Und", "aus", "der", "Rech\u00b7ten", "sacht", "zur", "Lin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "l\u00e4\u00dft sie das Blumenzepter sinken,", "tokens": ["l\u00e4\u00dft", "sie", "das", "Blu\u00b7men\u00b7zep\u00b7ter", "sin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "dann spricht sie \u00fcber mich geneigt,", "tokens": ["dann", "spricht", "sie", "\u00fc\u00b7ber", "mich", "ge\u00b7neigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "nimmt mir die Gei\u00dfel aus der Hand nun,", "tokens": ["nimmt", "mir", "die", "Gei\u00b7\u00dfel", "aus", "der", "Hand", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "nimmt eines Teppichs bunten Rand nun,", "tokens": ["nimmt", "ei\u00b7nes", "Tep\u00b7pichs", "bun\u00b7ten", "Rand", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "indem sie ihn der Andern reicht,", "tokens": ["in\u00b7dem", "sie", "ihn", "der", "An\u00b7dern", "reicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und winkt ihr mit der Lilie: \u00bbGeh!", "tokens": ["und", "winkt", "ihr", "mit", "der", "Li\u00b7lie", ":", "\u00bb", "Geh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$(", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "bedecke dich! es thut mir weh,", "tokens": ["be\u00b7de\u00b7cke", "dich", "!", "es", "thut", "mir", "weh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "in deiner Bl\u00f6\u00dfe dich zu sehn.\u00ab", "tokens": ["in", "dei\u00b7ner", "Bl\u00f6\u00b7\u00dfe", "dich", "zu", "sehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und wieder \u00fcber mich geneigt nun,", "tokens": ["Und", "wie\u00b7der", "\u00fc\u00b7ber", "mich", "ge\u00b7neigt", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "inde\u00df die Andre scheu entweicht nun,", "tokens": ["in\u00b7de\u00df", "die", "And\u00b7re", "scheu", "ent\u00b7weicht", "nun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIS", "ADJD", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "t\u00f6nt ihres Atems leises Wehn:", "tokens": ["t\u00f6nt", "ih\u00b7res", "A\u00b7tems", "lei\u00b7ses", "Wehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbwas war's doch, was in tiefsten L\u00fcsten,", "tokens": ["\u00bb", "was", "wa\u00b7r's", "doch", ",", "was", "in", "tiefs\u00b7ten", "L\u00fcs\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "ADV", "$,", "PRELS", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.14": {"text": "wenn Lippen sich und Seelen k\u00fc\u00dften,", "tokens": ["wenn", "Lip\u00b7pen", "sich", "und", "See\u00b7len", "k\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PRF", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "den trunknen Blick dir ganz benahm,", "tokens": ["den", "trunk\u00b7nen", "Blick", "dir", "ganz", "be\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "was dich im \u00dcberdurst der Wonnen,", "tokens": ["was", "dich", "im", "\u00dc\u00b7berd\u00b7urst", "der", "Won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "so in ein Andres ganz versponnen,", "tokens": ["so", "in", "ein", "And\u00b7res", "ganz", "ver\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "wie willige Blindheit \u00fcberkam?", "tokens": ["wie", "wil\u00b7li\u00b7ge", "Blind\u00b7heit", "\u00fc\u00b7ber\u00b7kam", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Dann warst du Mein! ich bin die ", "tokens": ["Dann", "warst", "du", "Mein", "!", "ich", "bin", "die"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "$.", "PPER", "VAFIN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "Mu\u00dft dich aber nicht gleich, mein Bester,\u00ab", "tokens": ["Mu\u00dft", "dich", "a\u00b7ber", "nicht", "gleich", ",", "mein", "Bes\u00b7ter", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "ADV", "PTKNEG", "ADV", "$,", "PPOSAT", "NN", "$,", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.21": {"text": "senkte sie l\u00e4chelnd die Lilienbl\u00fcten,", "tokens": ["senk\u00b7te", "sie", "l\u00e4\u00b7chelnd", "die", "Li\u00b7li\u00b7en\u00b7bl\u00fc\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.22": {"text": "\u00bbso um alles in Eifer w\u00fcten.", "tokens": ["\u00bb", "so", "um", "al\u00b7les", "in", "Ei\u00b7fer", "w\u00fc\u00b7ten", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.23": {"text": "Die da, meine mi\u00dfratene Schwester,\u00ab", "tokens": ["Die", "da", ",", "mei\u00b7ne", "mi\u00df\u00b7ra\u00b7te\u00b7ne", "Schwes\u00b7ter", ",", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.24": {"text": "nickte sie neckisch nach der Th\u00fcr hin,", "tokens": ["nick\u00b7te", "sie", "ne\u00b7ckisch", "nach", "der", "Th\u00fcr", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+--++", "measure": "trochaic.penta.relaxed"}, "line.25": {"text": "w\u00e4hrend sie mir den Scheitel zauste", "tokens": ["w\u00e4h\u00b7rend", "sie", "mir", "den", "Schei\u00b7tel", "zaus\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVFIN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.26": {"text": "und ihre zierlichen N\u00fcstern krauste,", "tokens": ["und", "ih\u00b7re", "zier\u00b7li\u00b7chen", "N\u00fcs\u00b7tern", "kraus\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "\u00bbdie da ist schon \u00fcber Geb\u00fchr hin", "tokens": ["\u00bb", "die", "da", "ist", "schon", "\u00fc\u00b7ber", "Ge\u00b7b\u00fchr", "hin"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "ADV", "VAFIN", "ADV", "APPR", "NN", "PTKVZ"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.28": {"text": "durch die eigene Ohnmacht gestraft:", "tokens": ["durch", "die", "ei\u00b7ge\u00b7ne", "Ohn\u00b7macht", "ge\u00b7straft", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+---+-+", "measure": "unknown.measure.tetra"}, "line.29": {"text": "fehlt ihr zur rechten Freude die Kraft.", "tokens": ["fehlt", "ihr", "zur", "rech\u00b7ten", "Freu\u00b7de", "die", "Kraft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.30": {"text": "Hat ja viele Seelen zu Sklaven,", "tokens": ["Hat", "ja", "vie\u00b7le", "See\u00b7len", "zu", "Skla\u00b7ven", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "APPR", "NN", "$,"], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.31": {"text": "alle die Biedern, alle die Braven", "tokens": ["al\u00b7le", "die", "Bie\u00b7dern", ",", "al\u00b7le", "die", "Bra\u00b7ven"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "ART", "NN", "$,", "PIS", "ART", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.32": {"text": "vom werten Orden der Glei\u00dfnerschaft,", "tokens": ["vom", "wer\u00b7ten", "Or\u00b7den", "der", "Glei\u00df\u00b7ner\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "alle die zahmen, ewig alten,", "tokens": ["al\u00b7le", "die", "zah\u00b7men", ",", "e\u00b7wig", "al\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ART", "ADJA", "$,", "ADJD", "ADJA", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.34": {"text": "sinnenlahmen Halben und Kalten,", "tokens": ["sin\u00b7nen\u00b7lah\u00b7men", "Hal\u00b7ben", "und", "Kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.35": {"text": "scheint ein gar gewaltiger Bund,", "tokens": ["scheint", "ein", "gar", "ge\u00b7wal\u00b7ti\u00b7ger", "Bund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.36": {"text": "ist aber doch nur \u2013 nun eben Schund.", "tokens": ["ist", "a\u00b7ber", "doch", "nur", "\u2013", "nun", "e\u00b7ben", "Schund", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADV", "$(", "ADV", "ADV", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.37": {"text": "Haben die Welt nie aufgehalten,", "tokens": ["Ha\u00b7ben", "die", "Welt", "nie", "auf\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.38": {"text": "und Alles, was sie zu Stande brachten,", "tokens": ["und", "Al\u00b7les", ",", "was", "sie", "zu", "Stan\u00b7de", "brach\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.39": {"text": "und ihrer Weisheit letzter Grund", "tokens": ["und", "ih\u00b7rer", "Weis\u00b7heit", "letz\u00b7ter", "Grund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "ist \u2013 ihr gegenseitig Verachten.", "tokens": ["ist", "\u2013", "ihr", "ge\u00b7gen\u00b7sei\u00b7tig", "Ver\u00b7ach\u00b7ten", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "PPER", "ADJD", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.41": {"text": "K\u00f6nnen sich nicht gesund betrachten,", "tokens": ["K\u00f6n\u00b7nen", "sich", "nicht", "ge\u00b7sund", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKNEG", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.42": {"text": "weil ihrem armen d\u00fcnnen Blut", "tokens": ["weil", "ih\u00b7rem", "ar\u00b7men", "d\u00fcn\u00b7nen", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.43": {"text": "jedes freie L\u00fcftchen wehe thut,", "tokens": ["je\u00b7des", "frei\u00b7e", "L\u00fcft\u00b7chen", "we\u00b7he", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.44": {"text": "und machen drum aus ihrer Not", "tokens": ["und", "ma\u00b7chen", "drum", "aus", "ih\u00b7rer", "Not"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PAV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "ein Gebot.", "tokens": ["ein", "Ge\u00b7bot", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.46": {"text": "Und, Lieber,\u00ab streicht sie zart mein Haar,", "tokens": ["Und", ",", "Lie\u00b7ber", ",", "\u00ab", "streicht", "sie", "zart", "mein", "Haar", ","], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "$,", "$(", "VVFIN", "PPER", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.47": {"text": "\u00bbder Heuchler meint die L\u00fcge wahr,", "tokens": ["\u00bb", "der", "Heuch\u00b7ler", "meint", "die", "L\u00fc\u00b7ge", "wahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "der Wahre mu\u00df ihn nur verstehn!", "tokens": ["der", "Wah\u00b7re", "mu\u00df", "ihn", "nur", "ver\u00b7stehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Wenn Kraft und Sch\u00f6nheit nackend gehn,", "tokens": ["Wenn", "Kraft", "und", "Sch\u00f6n\u00b7heit", "na\u00b7ckend", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "man w\u00fcrde sich nicht sehr beklagen;", "tokens": ["man", "w\u00fcr\u00b7de", "sich", "nicht", "sehr", "be\u00b7kla\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PRF", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "doch etwas schwerer zu vertragen", "tokens": ["doch", "et\u00b7was", "schwe\u00b7rer", "zu", "ver\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.52": {"text": "ist H\u00e4\u00dfliches, bei Licht besehn.\u00ab", "tokens": ["ist", "H\u00e4\u00df\u00b7li\u00b7ches", ",", "bei", "Licht", "be\u00b7sehn", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "$,", "APPR", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und w\u00e4hrend silbern noch im Ohr mir", "tokens": ["Und", "w\u00e4h\u00b7rend", "sil\u00b7bern", "noch", "im", "Ohr", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "ADV", "APPRART", "NN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "ihr fr\u00f6hlich stolz Gel\u00e4chter klingt,", "tokens": ["ihr", "fr\u00f6h\u00b7lich", "stolz", "Ge\u00b7l\u00e4ch\u00b7ter", "klingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "winkt mit den Rosen sie empor mir", "tokens": ["winkt", "mit", "den", "Ro\u00b7sen", "sie", "em\u00b7por", "mir"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "PTKVZ", "PPER"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und spricht: \u00bbEin schlechter Boden bringt", "tokens": ["und", "spricht", ":", "\u00bb", "Ein", "schlech\u00b7ter", "Bo\u00b7den", "bringt"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "$(", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "aus echter Wurzel schlechte Bl\u00fcte,", "tokens": ["aus", "ech\u00b7ter", "Wur\u00b7zel", "schlech\u00b7te", "Bl\u00fc\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und wer mit schw\u00e4chlichem Gem\u00fcte", "tokens": ["und", "wer", "mit", "schw\u00e4ch\u00b7li\u00b7chem", "Ge\u00b7m\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "sich sch\u00e4mt, der ist zur Scham verdorben,", "tokens": ["sich", "sch\u00e4mt", ",", "der", "ist", "zur", "Scham", "ver\u00b7dor\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "$,", "PRELS", "VAFIN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "doch ist sie drum \u2013 nit ausgestorben.", "tokens": ["doch", "ist", "sie", "drum", "\u2013", "nit", "aus\u00b7ge\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PAV", "$(", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "So beugt sie sich mit gn\u00e4digem Kusse", "tokens": ["So", "beugt", "sie", "sich", "mit", "gn\u00e4\u00b7di\u00b7gem", "Kus\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "in heller Anmut zu mir hin,", "tokens": ["in", "hel\u00b7ler", "An\u00b7mut", "zu", "mir", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich aber f\u00fchle ihrem Gru\u00dfe", "tokens": ["ich", "a\u00b7ber", "f\u00fch\u00b7le", "ih\u00b7rem", "Gru\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mein ganz Gef\u00fchl entgegengl\u00fchn \u2013", "tokens": ["mein", "ganz", "Ge\u00b7f\u00fchl", "ent\u00b7ge\u00b7gen\u00b7gl\u00fchn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "NN", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und nur noch, wie's mich \u00fcbermannte,", "tokens": ["und", "nur", "noch", ",", "wie's", "mich", "\u00fc\u00b7berm\u00b7ann\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "ich wieder an ihr niedersank,", "tokens": ["ich", "wie\u00b7der", "an", "ihr", "nie\u00b7der\u00b7sank", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "mein Mund auf ihren Br\u00fcsten brannte,", "tokens": ["mein", "Mund", "auf", "ih\u00b7ren", "Br\u00fcs\u00b7ten", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "ich ihre Lenden ganz umspannte,", "tokens": ["ich", "ih\u00b7re", "Len\u00b7den", "ganz", "um\u00b7spann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "ihr Haar mir um die Finger schlang,", "tokens": ["ihr", "Haar", "mir", "um", "die", "Fin\u00b7ger", "schlang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "die Stirn gew\u00fchlt in ihren Schoo\u00df \u2013", "tokens": ["die", "Stirn", "ge\u00b7w\u00fchlt", "in", "ih\u00b7ren", "Schoo\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "und sie nur, hold und m\u00fctterlich,", "tokens": ["und", "sie", "nur", ",", "hold", "und", "m\u00fct\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "am Ohr mich zupft: \u00bbIch bitte dich,", "tokens": ["am", "Ohr", "mich", "zupft", ":", "\u00bb", "Ich", "bit\u00b7te", "dich", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "mein lieber Freund! was willst? la\u00df los!", "tokens": ["mein", "lie\u00b7ber", "Freund", "!", "was", "willst", "?", "la\u00df", "los", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "PWS", "VMFIN", "$.", "VVIMP", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "ermuntre dich! du \u2013 tr\u00e4umst ja blos.\u00ab", "tokens": ["er\u00b7munt\u00b7re", "dich", "!", "du", "\u2013", "tr\u00e4umst", "ja", "blos", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "$(", "VVFIN", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}