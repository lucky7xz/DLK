{"textgrid.poem.41134": {"metadata": {"author": {"name": "Kerner, Justinus", "birth": "N.A.", "death": "N.A."}, "title": "Prognostikon", "genre": "verse", "period": "N.A.", "pub_year": 1824, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bin ich eine Leiche kalt,", "tokens": ["Bin", "ich", "ei\u00b7ne", "Lei\u00b7che", "kalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Werden sie wohl um mich klagen", "tokens": ["Wer\u00b7den", "sie", "wohl", "um", "mich", "kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "APPR", "PPER", "VVINF"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Bis zum Grabe, und dann bald", "tokens": ["Bis", "zum", "Gra\u00b7be", ",", "und", "dann", "bald"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "APPRART", "NN", "$,", "KON", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nach dem lauten Markte fragen.", "tokens": ["Nach", "dem", "lau\u00b7ten", "Mark\u00b7te", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Diese Lieder sind zu klein,", "tokens": ["Die\u00b7se", "Lie\u00b7der", "sind", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind zu schwach, zu leben lange,", "tokens": ["Sind", "zu", "schwach", ",", "zu", "le\u00b7ben", "lan\u00b7ge", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKA", "ADJD", "$,", "PTKZU", "VVINF", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00fcster Streit bricht bald herein,", "tokens": ["W\u00fcs\u00b7ter", "Streit", "bricht", "bald", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Bringet Tod auch dem Gesange.", "tokens": ["Brin\u00b7get", "Tod", "auch", "dem", "Ge\u00b7san\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Fl\u00fcchtig leb' ich durchs Gedicht,", "tokens": ["Fl\u00fcch\u00b7tig", "leb'", "ich", "durchs", "Ge\u00b7dicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch des Arztes Kunst nur fl\u00fcchtig;", "tokens": ["Durch", "des", "Arz\u00b7tes", "Kunst", "nur", "fl\u00fcch\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nur wenn man von Geistern spricht,", "tokens": ["Nur", "wenn", "man", "von", "Geis\u00b7tern", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Denkt man mein noch und schimpft t\u00fcchtig.", "tokens": ["Denkt", "man", "mein", "noch", "und", "schimpft", "t\u00fcch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "ADV", "KON", "VVFIN", "ADJD", "$."], "meter": "+-+--++-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Meinen H\u00fcgel deckt kein Stein,", "tokens": ["Mei\u00b7nen", "H\u00fc\u00b7gel", "deckt", "kein", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fch ihn ebnen Sturm und Regen,", "tokens": ["Fr\u00fch", "ihn", "eb\u00b7nen", "Sturm", "und", "Re\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ADJA", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ausgr\u00e4bt bald man mein Gebein,", "tokens": ["Aus\u00b7gr\u00e4bt", "bald", "man", "mein", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Bessern drein zu legen.", "tokens": ["Ei\u00b7nen", "Bes\u00b7sern", "drein", "zu", "le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Doch mit ", "tokens": ["Doch", "mit"], "token_info": ["word", "word"], "pos": ["KON", "APPR"], "meter": "++", "measure": "spondeus"}, "line.2": {"text": "Ich in ewigem Vereine.", "tokens": ["Ich", "in", "e\u00b7wi\u00b7gem", "Ver\u00b7ei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Liest dies Herz, was ich hier schreib',", "tokens": ["Liest", "dies", "Herz", ",", "was", "ich", "hier", "schreib'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "NN", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "F\u00fchlt es wohl, welch Herz ich meine.", "tokens": ["F\u00fchlt", "es", "wohl", ",", "welch", "Herz", "ich", "mei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}