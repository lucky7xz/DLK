{"textgrid.poem.57522": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und endlich k\u00f6mmt, o Freund! die sch\u00f6ne Zeit heran,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und endlich k\u00f6mmt, o Freund! die sch\u00f6ne Zeit heran,", "tokens": ["Und", "end\u00b7lich", "k\u00f6mmt", ",", "o", "Freund", "!", "die", "sch\u00f6\u00b7ne", "Zeit", "he\u00b7ran", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "FM", "NN", "$.", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da Neid und Misgunst dich nicht l\u00e4nger hindern kann,", "tokens": ["Da", "Neid", "und", "Mis\u00b7gunst", "dich", "nicht", "l\u00e4n\u00b7ger", "hin\u00b7dern", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zum Kirchenlehreramt, dazu man dich beruffen,", "tokens": ["Zum", "Kir\u00b7chen\u00b7leh\u00b7re\u00b7ramt", ",", "da\u00b7zu", "man", "dich", "be\u00b7ruf\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PAV", "PIS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dich eingeweiht zu sehn. Betritt nunmehr die Stuffen", "tokens": ["Dich", "ein\u00b7ge\u00b7weiht", "zu", "sehn", ".", "Be\u00b7tritt", "nun\u00b7mehr", "die", "Stuf\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVPP", "PTKZU", "VVINF", "$.", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Des hohen Predigtstuhls, mit Eifer, Geist und Kraft.", "tokens": ["Des", "ho\u00b7hen", "Pre\u00b7digt\u00b7stuhls", ",", "mit", "Ei\u00b7fer", ",", "Geist", "und", "Kraft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es fehlt dir weder Muth, Verstand und Wissenschaft,", "tokens": ["Es", "fehlt", "dir", "we\u00b7der", "Muth", ",", "Ver\u00b7stand", "und", "Wis\u00b7sen\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Noch wahre Gottesfurcht; ob gleich die Feinde toben,", "tokens": ["Noch", "wah\u00b7re", "Got\u00b7tes\u00b7furcht", ";", "ob", "gleich", "die", "Fein\u00b7de", "to\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$.", "KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die durch ihr L\u00e4stermaul dich nur am sch\u00f6nsten loben.", "tokens": ["Die", "durch", "ihr", "L\u00e4s\u00b7ter\u00b7maul", "dich", "nur", "am", "sch\u00f6ns\u00b7ten", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "PPER", "ADV", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Begl\u00fcckt ist, wer, wie du, der Schm\u00e4hsucht Gift besiegt,", "tokens": ["Be\u00b7gl\u00fcckt", "ist", ",", "wer", ",", "wie", "du", ",", "der", "Schm\u00e4h\u00b7sucht", "Gift", "be\u00b7siegt", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PWS", "$,", "PWAV", "PPER", "$,", "ART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn seiner Unschuld Pracht ganz klar am Tage liegt.", "tokens": ["Wenn", "sei\u00b7ner", "Un\u00b7schuld", "Pracht", "ganz", "klar", "am", "Ta\u00b7ge", "liegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Begl\u00fcckt! wer so, wie du, durch Gro\u00dfmuth \u00fcberwunden,", "tokens": ["Be\u00b7gl\u00fcckt", "!", "wer", "so", ",", "wie", "du", ",", "durch", "Gro\u00df\u00b7muth", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$.", "PWS", "ADV", "$,", "PWAV", "PPER", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was die Verl\u00e4umdung auch f\u00fcr L\u00fcgen ausgefunden.", "tokens": ["Was", "die", "Ver\u00b7l\u00e4um\u00b7dung", "auch", "f\u00fcr", "L\u00fc\u00b7gen", "aus\u00b7ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich, dem die Poesie der Tugend Lob gebeut,", "tokens": ["Ich", ",", "dem", "die", "Poe\u00b7sie", "der", "Tu\u00b7gend", "Lob", "ge\u00b7beut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Erinnre mich dabey der s\u00fc\u00dfen Schuldigkeit,", "tokens": ["E\u00b7rinn\u00b7re", "mich", "da\u00b7bey", "der", "s\u00fc\u00b7\u00dfen", "Schul\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die sie mir auferlegt. Ich soll nichts falsches dichten,", "tokens": ["Die", "sie", "mir", "auf\u00b7er\u00b7legt", ".", "Ich", "soll", "nichts", "fal\u00b7sches", "dich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVPP", "$.", "PPER", "VMFIN", "PIS", "ADJA", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und mir durch Schm\u00e4ucheley der Thoren Stolz verpflichten.", "tokens": ["Und", "mir", "durch", "Schm\u00e4u\u00b7che\u00b7ley", "der", "Tho\u00b7ren", "Stolz", "ver\u00b7pflich\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich soll nicht ganz erstaunt vor kleinen Geistern stehn,", "tokens": ["Ich", "soll", "nicht", "ganz", "er\u00b7staunt", "vor", "klei\u00b7nen", "Geis\u00b7tern", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und was ich nie geglaubt, durch eiteln Ruhm erh\u00f6hn.", "tokens": ["Und", "was", "ich", "nie", "ge\u00b7glaubt", ",", "durch", "ei\u00b7teln", "Ruhm", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVPP", "$,", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Wahrheit winket mir, die Wahrheit, der ich diene,", "tokens": ["Die", "Wahr\u00b7heit", "win\u00b7ket", "mir", ",", "die", "Wahr\u00b7heit", ",", "der", "ich", "die\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ART", "NN", "$,", "PRELS", "PPER", "PDS", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn ich den Wahn der Welt zu st\u00f6ren mich erk\u00fchne.", "tokens": ["Wenn", "ich", "den", "Wahn", "der", "Welt", "zu", "st\u00f6\u00b7ren", "mich", "er\u00b7k\u00fch\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich weis, du siehest die\u00df mit muntern Sinnen an,", "tokens": ["Ich", "weis", ",", "du", "sie\u00b7hest", "die\u00df", "mit", "mun\u00b7tern", "Sin\u00b7nen", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "PPER", "VVFIN", "PDS", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Weil das, was dich nicht trifft, dich nicht verletzen kann.", "tokens": ["Weil", "das", ",", "was", "dich", "nicht", "trifft", ",", "dich", "nicht", "ver\u00b7let\u00b7zen", "kann", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PWS", "PPER", "PTKNEG", "VVFIN", "$,", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wer sich getroffen f\u00fchlt, der mag sich kundbar machen;", "tokens": ["Wer", "sich", "ge\u00b7trof\u00b7fen", "f\u00fchlt", ",", "der", "mag", "sich", "kund\u00b7bar", "ma\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVPP", "VVFIN", "$,", "PRELS", "VMFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So kriegt die kluge Welt das Recht ihn auszulachen.", "tokens": ["So", "kriegt", "die", "klu\u00b7ge", "Welt", "das", "Recht", "ihn", "aus\u00b7zu\u00b7la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Du wirst ein Geistlicher, und zwar zu einer Zeit,", "tokens": ["Du", "wirst", "ein", "Geist\u00b7li\u00b7cher", ",", "und", "zwar", "zu", "ei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "KON", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da mancher, der sich auch dem Predigtstuhl geweiht,", "tokens": ["Da", "man\u00b7cher", ",", "der", "sich", "auch", "dem", "Pre\u00b7digt\u00b7stuhl", "ge\u00b7weiht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PRF", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Hand vom Pfluge zieht: ein schreckliches Verbrechen!", "tokens": ["Die", "Hand", "vom", "Pflu\u00b7ge", "zieht", ":", "ein", "schreck\u00b7li\u00b7ches", "Ver\u00b7bre\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn man den P\u00f6bel h\u00f6rt sein altes Urtheil sprechen.", "tokens": ["Wenn", "man", "den", "P\u00f6\u00b7bel", "h\u00f6rt", "sein", "al\u00b7tes", "Ur\u00b7theil", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "VVFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein, wen wundert das, der auch nur halb bedenkt,", "tokens": ["Al\u00b7lein", ",", "wen", "wun\u00b7dert", "das", ",", "der", "auch", "nur", "halb", "be\u00b7denkt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VVFIN", "PDS", "$,", "PRELS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie sehr die Mode schon die Kanzeln eingeschr\u00e4nkt,", "tokens": ["Wie", "sehr", "die", "Mo\u00b7de", "schon", "die", "Kan\u00b7zeln", "ein\u00b7ge\u00b7schr\u00e4nkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und wie genau man sich, ein Aemtchen zu erhalten,", "tokens": ["Und", "wie", "ge\u00b7nau", "man", "sich", ",", "ein", "A\u00b7emt\u00b7chen", "zu", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "PIS", "PRF", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Der eingef\u00fchrten Art ganz \u00e4hnlich soll gestalten.", "tokens": ["Der", "ein\u00b7ge\u00b7f\u00fchr\u00b7ten", "Art", "ganz", "\u00e4hn\u00b7lich", "soll", "ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VMFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man redet hier, o Freund! von Glaubenslehren nicht,", "tokens": ["Man", "re\u00b7det", "hier", ",", "o", "Freund", "!", "von", "Glau\u00b7bens\u00b7leh\u00b7ren", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "FM", "NN", "$.", "APPR", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die wahr und g\u00f6ttlich sind. Wer diesen widerspricht,", "tokens": ["Die", "wahr", "und", "g\u00f6tt\u00b7lich", "sind", ".", "Wer", "die\u00b7sen", "wi\u00b7der\u00b7spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "$.", "PWS", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Ist freylich selbst verkehrt. Man redet nicht von Kennern", "tokens": ["Ist", "frey\u00b7lich", "selbst", "ver\u00b7kehrt", ".", "Man", "re\u00b7det", "nicht", "von", "Ken\u00b7nern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$.", "PIS", "VVFIN", "PTKNEG", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der wahren Redekunst, als hochgelehrten M\u00e4nnern,", "tokens": ["Der", "wah\u00b7ren", "Re\u00b7de\u00b7kunst", ",", "als", "hoch\u00b7ge\u00b7lehr\u00b7ten", "M\u00e4n\u00b7nern", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die unsers Sachsens Schmuck, der Kirchen Ehre sind:", "tokens": ["Die", "un\u00b7sers", "Sach\u00b7sens", "Schmuck", ",", "der", "Kir\u00b7chen", "Eh\u00b7re", "sind", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wer diese schelten will, ist selbst aus Thorheit blind,", "tokens": ["Wer", "die\u00b7se", "schel\u00b7ten", "will", ",", "ist", "selbst", "aus", "Thor\u00b7heit", "blind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVINF", "VMFIN", "$,", "VAFIN", "ADV", "APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ja vieler Strafe werth. Man redet nur von Moden,", "tokens": ["Ja", "vie\u00b7ler", "Stra\u00b7fe", "werth", ".", "Man", "re\u00b7det", "nur", "von", "Mo\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PIAT", "NN", "ADJD", "$.", "PIS", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Die Menschenwitz erdacht, und k\u00fcnstlichen Methoden.", "tokens": ["Die", "Men\u00b7schen\u00b7witz", "er\u00b7dacht", ",", "und", "k\u00fcnst\u00b7li\u00b7chen", "Me\u00b7tho\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die, die sind eine Last, die manche Schulter schreckt,", "tokens": ["Die", ",", "die", "sind", "ei\u00b7ne", "Last", ",", "die", "man\u00b7che", "Schul\u00b7ter", "schreckt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "VAFIN", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df sie den Mantel flieht, der so viel Pein erweckt,", "tokens": ["Da\u00df", "sie", "den", "Man\u00b7tel", "flieht", ",", "der", "so", "viel", "Pein", "er\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "PRELS", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und unertr\u00e4glich wird. Doch, ich kann alles sparen;", "tokens": ["Und", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "wird", ".", "Doch", ",", "ich", "kann", "al\u00b7les", "spa\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "$.", "KON", "$,", "PPER", "VMFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Du, werthgesch\u00e4tzter Freund! hast dieses selbst erfahren.", "tokens": ["Du", ",", "werth\u00b7ge\u00b7sch\u00e4tz\u00b7ter", "Freund", "!", "hast", "die\u00b7ses", "selbst", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "$.", "VAFIN", "PDAT", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Seit dem des H\u00f6chsten Geist, mit wunderbarer Kraft,", "tokens": ["Seit", "dem", "des", "H\u00f6chs\u00b7ten", "Geist", ",", "mit", "wun\u00b7der\u00b7ba\u00b7rer", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht mehr Propheten treibt, nicht mehr Apostel schafft;", "tokens": ["Nicht", "mehr", "Pro\u00b7phe\u00b7ten", "treibt", ",", "nicht", "mehr", "A\u00b7pos\u00b7tel", "schafft", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIAT", "NN", "VVFIN", "$,", "PTKNEG", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Seit dem die Sendung nicht unmittelbar geschiehet,", "tokens": ["Seit", "dem", "die", "Sen\u00b7dung", "nicht", "un\u00b7mit\u00b7tel\u00b7bar", "ge\u00b7schie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil das geschriebne Wort allein die Herzen ziehet:", "tokens": ["Weil", "das", "ge\u00b7schrieb\u00b7ne", "Wort", "al\u00b7lein", "die", "Her\u00b7zen", "zie\u00b7het", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Seit dieser ersten Welt mu\u00df Flei\u00df, Belesenheit,", "tokens": ["Seit", "die\u00b7ser", "ers\u00b7ten", "Welt", "mu\u00df", "Flei\u00df", ",", "Be\u00b7le\u00b7sen\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VMFIN", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Sprachen Wissenschaft, und die Beredsamkeit", "tokens": ["Der", "Spra\u00b7chen", "Wis\u00b7sen\u00b7schaft", ",", "und", "die", "Be\u00b7red\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den frommen Lehrerstand, bey Bethen und bey Wachen,", "tokens": ["Den", "from\u00b7men", "Leh\u00b7rer\u00b7stand", ",", "bey", "Be\u00b7then", "und", "bey", "Wa\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+--++-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Zu der Gemeinen Dienst geschickt und t\u00fcchtig machen.", "tokens": ["Zu", "der", "Ge\u00b7mei\u00b7nen", "Dienst", "ge\u00b7schickt", "und", "t\u00fcch\u00b7tig", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVPP", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Je weiter man es nun in diesen St\u00fccken bringt,", "tokens": ["Je", "wei\u00b7ter", "man", "es", "nun", "in", "die\u00b7sen", "St\u00fc\u00b7cken", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PPER", "ADV", "APPR", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Je mehr man in den Schatz der Heiligth\u00fcmer dringt,", "tokens": ["Je", "mehr", "man", "in", "den", "Schatz", "der", "Hei\u00b7ligt\u00b7h\u00fc\u00b7mer", "dringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "APPR", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Je mehr man sich bem\u00fcht, die Wahrheit recht zu lehren,", "tokens": ["Je", "mehr", "man", "sich", "be\u00b7m\u00fcht", ",", "die", "Wahr\u00b7heit", "recht", "zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "PRF", "VVPP", "$,", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Um desto mehr ist auch ein solcher Mann zu ehren.", "tokens": ["Um", "des\u00b7to", "mehr", "ist", "auch", "ein", "sol\u00b7cher", "Mann", "zu", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADV", "VAFIN", "ADV", "ART", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wer sein vertrautes Pfund nur redlich angelegt,", "tokens": ["Wer", "sein", "ver\u00b7trau\u00b7tes", "Pfund", "nur", "red\u00b7lich", "an\u00b7ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Des H\u00f6chsten Weinberg baut, so, da\u00df er Fr\u00fcchte tr\u00e4gt,", "tokens": ["Des", "H\u00f6chs\u00b7ten", "Wein\u00b7berg", "baut", ",", "so", ",", "da\u00df", "er", "Fr\u00fcch\u00b7te", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ADV", "$,", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Den darf kein fremder Knecht in seiner Arbeit schelten,", "tokens": ["Den", "darf", "kein", "frem\u00b7der", "Knecht", "in", "sei\u00b7ner", "Ar\u00b7beit", "schel\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und dessen Sorgfalt mu\u00df, gleich andrer Diensten, gelten.", "tokens": ["Und", "des\u00b7sen", "Sorg\u00b7falt", "mu\u00df", ",", "gleich", "an\u00b7drer", "Diens\u00b7ten", ",", "gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "VMFIN", "$,", "ADV", "ADJA", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Freund! die\u00df ist sonnenklar: allein, wer weis auch nicht,", "tokens": ["Freund", "!", "die\u00df", "ist", "son\u00b7nen\u00b7klar", ":", "al\u00b7lein", ",", "wer", "weis", "auch", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PDS", "VAFIN", "ADJD", "$.", "ADV", "$,", "PWS", "PTKVZ", "ADV", "PTKNEG", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da\u00df hier der Eigensinn ein strenger Urtheil spricht?", "tokens": ["Da\u00df", "hier", "der", "Ei\u00b7gen\u00b7sinn", "ein", "stren\u00b7ger", "Ur\u00b7theil", "spricht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was? hei\u00dft es, sollte sichs ein junger Mensch erk\u00fchnen,", "tokens": ["Was", "?", "hei\u00dft", "es", ",", "soll\u00b7te", "sichs", "ein", "jun\u00b7ger", "Mensch", "er\u00b7k\u00fch\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "VVFIN", "PPER", "$,", "VMFIN", "PIS", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und unsrer Kirche blo\u00df nach eignem Kopfe dienen?", "tokens": ["Und", "uns\u00b7rer", "Kir\u00b7che", "blo\u00df", "nach", "eig\u00b7nem", "Kop\u00b7fe", "die\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, Regeln aufgesetzt! darnach der Lehrerstand", "tokens": ["Nein", ",", "Re\u00b7geln", "auf\u00b7ge\u00b7setzt", "!", "dar\u00b7nach", "der", "Leh\u00b7rer\u00b7stand"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "NN", "VVPP", "$.", "PAV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sich hier und anderw\u00e4rts, ja durch das ganze Land,", "tokens": ["Sich", "hier", "und", "an\u00b7der\u00b7w\u00e4rts", ",", "ja", "durch", "das", "gan\u00b7ze", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "KON", "ADV", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Geb\u00fchrend richten mu\u00df. Gesetze vorgeschrieben!", "tokens": ["Ge\u00b7b\u00fch\u00b7rend", "rich\u00b7ten", "mu\u00df", ".", "Ge\u00b7set\u00b7ze", "vor\u00b7ge\u00b7schrie\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "VVINF", "VMFIN", "$.", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Pflicht des Predigens nach gleicher Art zu \u00fcben.", "tokens": ["Die", "Pflicht", "des", "Pre\u00b7di\u00b7gens", "nach", "glei\u00b7cher", "Art", "zu", "\u00fc\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Methoden ausgedacht! darnach man jedermann", "tokens": ["Me\u00b7tho\u00b7den", "aus\u00b7ge\u00b7dacht", "!", "dar\u00b7nach", "man", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVPP", "$.", "PAV", "PIS", "PIS"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Kanzelrednerkunst recht m\u00fchsam zeigen kann.", "tokens": ["Die", "Kan\u00b7zel\u00b7red\u00b7ner\u00b7kunst", "recht", "m\u00fch\u00b7sam", "zei\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Was blo\u00df die Bibel sagt, was die Vernunft erfunden,", "tokens": ["Was", "blo\u00df", "die", "Bi\u00b7bel", "sagt", ",", "was", "die", "Ver\u00b7nunft", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "L\u00e4\u00dft junge Leute noch zu frey und ungebunden.", "tokens": ["L\u00e4\u00dft", "jun\u00b7ge", "Leu\u00b7te", "noch", "zu", "frey", "und", "un\u00b7ge\u00b7bun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "ADV", "PTKA", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Drum spanne man sie mehr ins Joch der Lehrart ein,", "tokens": ["Drum", "span\u00b7ne", "man", "sie", "mehr", "ins", "Joch", "der", "Le\u00b7hrart", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIS", "PPER", "ADV", "APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und wer sich nicht ergiebt, der soll nicht z\u00fcnftig seyn.", "tokens": ["Und", "wer", "sich", "nicht", "er\u00b7giebt", ",", "der", "soll", "nicht", "z\u00fcnf\u00b7tig", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "PTKNEG", "VVFIN", "$,", "PRELS", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Entfernet jemand sich, so mu\u00df man ihn verdammen:", "tokens": ["Ent\u00b7fer\u00b7net", "je\u00b7mand", "sich", ",", "so", "mu\u00df", "man", "ihn", "ver\u00b7dam\u00b7men", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "$,", "ADV", "VMFIN", "PIS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Man bring ihn in Verdacht; nehm alle List zusammen,", "tokens": ["Man", "bring", "ihn", "in", "Ver\u00b7dacht", ";", "nehm", "al\u00b7le", "List", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "$.", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Bis er gest\u00fcrzet ist. Dann sage man der Welt:", "tokens": ["Bis", "er", "ge\u00b7st\u00fcr\u00b7zet", "ist", ".", "Dann", "sa\u00b7ge", "man", "der", "Welt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$.", "ADV", "VVFIN", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Er sey in Meynungen und Lehren schlecht bestellt;", "tokens": ["Er", "sey", "in", "Mey\u00b7nun\u00b7gen", "und", "Leh\u00b7ren", "schlecht", "be\u00b7stellt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Man hab ihn, als die Pest des Glaubens, zu vermeiden,", "tokens": ["Man", "hab", "ihn", ",", "als", "die", "Pest", "des", "Glau\u00b7bens", ",", "zu", "ver\u00b7mei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "$,", "KOUS", "ART", "NN", "ART", "NN", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und m\u00fc\u00df ein faules Glied vom Kirchenk\u00f6rper schneiden.", "tokens": ["Und", "m\u00fc\u00df", "ein", "fau\u00b7les", "Glied", "vom", "Kir\u00b7chen\u00b7k\u00f6r\u00b7per", "schnei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "ADJA", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Die\u00df ist der Lauf der Welt, gelehrtberedter Freund!", "tokens": ["Die\u00df", "ist", "der", "Lauf", "der", "Welt", ",", "ge\u00b7lehrt\u00b7be\u00b7red\u00b7ter", "Freund", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der oft noch \u00e4rger wird, als mancher glaubt und meynt:", "tokens": ["Der", "oft", "noch", "\u00e4r\u00b7ger", "wird", ",", "als", "man\u00b7cher", "glaubt", "und", "meynt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zumal, wer so, wie du, sich nicht an Moden bindet,", "tokens": ["Zu\u00b7mal", ",", "wer", "so", ",", "wie", "du", ",", "sich", "nicht", "an", "Mo\u00b7den", "bin\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "ADV", "$,", "PWAV", "PPER", "$,", "PRF", "PTKNEG", "APPR", "NN", "VVFIN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Und doch erbaulich lehrt, und doch viel Beyfall findet.", "tokens": ["Und", "doch", "er\u00b7bau\u00b7lich", "lehrt", ",", "und", "doch", "viel", "Bey\u00b7fall", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVFIN", "$,", "KON", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da flucht der Handwerksneid; da schilt er auf die Art,", "tokens": ["Da", "flucht", "der", "Hand\u00b7werks\u00b7neid", ";", "da", "schilt", "er", "auf", "die", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darnach, als er studirt, noch nicht gepredigt ward;", "tokens": ["Dar\u00b7nach", ",", "als", "er", "stu\u00b7dirt", ",", "noch", "nicht", "ge\u00b7pre\u00b7digt", "ward", ";"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PPER", "VVPP", "$,", "ADV", "PTKNEG", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nennt alles Neuerung, was sich von dem entfernet,", "tokens": ["Nennt", "al\u00b7les", "Neu\u00b7e\u00b7rung", ",", "was", "sich", "von", "dem", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PRELS", "PRF", "APPR", "ART", "VVFIN", "$,"], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Was er zu seiner Zeit, doch auch als neu, erlernet.", "tokens": ["Was", "er", "zu", "sei\u00b7ner", "Zeit", ",", "doch", "auch", "als", "neu", ",", "er\u00b7ler\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "$,", "ADV", "ADV", "KOUS", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie k\u00f6mmt es, da\u00df er schm\u00e4hlt? Wie k\u00f6mmts, da\u00df er dich ha\u00dft?", "tokens": ["Wie", "k\u00f6mmt", "es", ",", "da\u00df", "er", "schm\u00e4hlt", "?", "Wie", "k\u00f6mmts", ",", "da\u00df", "er", "dich", "ha\u00dft", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$.", "PWAV", "NE", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Blo\u00df, weil dein Schuh sich nicht auf seinen Leisten pa\u00dft;", "tokens": ["Blo\u00df", ",", "weil", "dein", "Schuh", "sich", "nicht", "auf", "sei\u00b7nen", "Leis\u00b7ten", "pa\u00dft", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "NN", "PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Blo\u00df, weil dein Hut sich nicht auf seinen Kopf l\u00e4\u00dft dr\u00fccken,", "tokens": ["Blo\u00df", ",", "weil", "dein", "Hut", "sich", "nicht", "auf", "sei\u00b7nen", "Kopf", "l\u00e4\u00dft", "dr\u00fc\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPOSAT", "NN", "PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und deine Kleider sich auf seinen Rumpf nicht schicken.", "tokens": ["Und", "dei\u00b7ne", "Klei\u00b7der", "sich", "auf", "sei\u00b7nen", "Rumpf", "nicht", "schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PRF", "APPR", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Du wundergro\u00dfer Mann! verg\u00f6tterter ", "tokens": ["Du", "wun\u00b7der\u00b7gro\u00b7\u00dfer", "Mann", "!", "ver\u00b7g\u00f6t\u00b7ter\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPER", "ADJA", "NN", "$.", "ADJA"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Durch dessen grundgelehrt- beredt- und frommen Kiel", "tokens": ["Durch", "des\u00b7sen", "grund\u00b7ge\u00b7lehr\u00b7t", "be\u00b7redt", "und", "from\u00b7men", "Kiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDS", "TRUNC", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein tr\u00f6stlich Werk entstund. O ", "tokens": ["Ein", "tr\u00f6st\u00b7lich", "Werk", "ent\u00b7stund", ".", "O"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJD", "NN", "PTKVZ", "$.", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und du, gepriesner ", "tokens": ["Und", "du", ",", "ge\u00b7pri\u00b7es\u00b7ner"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "PPER", "$,", "ADJA"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.5": {"text": "Ihr habt der rohen Welt die rechte Kunst gezeigt,", "tokens": ["Ihr", "habt", "der", "ro\u00b7hen", "Welt", "die", "rech\u00b7te", "Kunst", "ge\u00b7zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie man recht bibelfest auf seine Kanzel steigt.", "tokens": ["Wie", "man", "recht", "bi\u00b7bel\u00b7fest", "auf", "sei\u00b7ne", "Kan\u00b7zel", "steigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ihr unterdr\u00fccket fast die Menge der Postillen,", "tokens": ["Ihr", "un\u00b7ter\u00b7dr\u00fc\u00b7cket", "fast", "die", "Men\u00b7ge", "der", "Pos\u00b7til\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und lehrt die Predigten aus Liederb\u00fcchern f\u00fcllen.", "tokens": ["Und", "lehrt", "die", "Pre\u00b7dig\u00b7ten", "aus", "Lie\u00b7der\u00b7b\u00fc\u00b7chern", "f\u00fcl\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wer die mit Spr\u00fcchen mischt, darf weiter nichts verstehn,", "tokens": ["Wer", "die", "mit", "Spr\u00fc\u00b7chen", "mischt", ",", "darf", "wei\u00b7ter", "nichts", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "APPR", "NN", "VVFIN", "$,", "VMFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als mit den Texten selbst methodisch umzugehn;", "tokens": ["Als", "mit", "den", "Tex\u00b7ten", "selbst", "me\u00b7tho\u00b7disch", "um\u00b7zu\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "ADV", "ADJD", "VVIZU", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Nach der Zergliederkunst sie k\u00fcnstlich zu zertrennen,", "tokens": ["Nach", "der", "Zer\u00b7glie\u00b7der\u00b7kunst", "sie", "k\u00fcnst\u00b7lich", "zu", "zer\u00b7tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PPER", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Theile sonderbar und klappend zu benennen.", "tokens": ["Die", "Thei\u00b7le", "son\u00b7der\u00b7bar", "und", "klap\u00b7pend", "zu", "be\u00b7nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Fragen, wer? und was? warum? und wie? und wo?", "tokens": ["Die", "Fra\u00b7gen", ",", "wer", "?", "und", "was", "?", "wa\u00b7rum", "?", "und", "wie", "?", "und", "wo", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWS", "$.", "KON", "PWS", "$.", "PWAV", "$.", "KON", "PWAV", "$.", "KON", "PWAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wodurch? und wenn? besehn; hei\u00dft ", "tokens": ["Wo\u00b7durch", "?", "und", "wenn", "?", "be\u00b7sehn", ";", "hei\u00dft"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "$.", "KON", "KOUS", "$.", "VVINF", "$.", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Hierinn steckt alle Kunst! ", "tokens": ["Hie\u00b7rinn", "steckt", "al\u00b7le", "Kunst", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}}, "stanza.8": {"line.1": {"text": "Du lachest, werther Freund! und das nicht ohne Grund:", "tokens": ["Du", "la\u00b7chest", ",", "wert\u00b7her", "Freund", "!", "und", "das", "nicht", "oh\u00b7ne", "Grund", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJA", "NN", "$.", "KON", "PDS", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Doch sage mir einmal, ob jener g\u00fcldne Mund,", "tokens": ["Doch", "sa\u00b7ge", "mir", "ein\u00b7mal", ",", "ob", "je\u00b7ner", "g\u00fcld\u00b7ne", "Mund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nach deiner Meynung wohl ein Redner sey gewesen?", "tokens": ["Nach", "dei\u00b7ner", "Mey\u00b7nung", "wohl", "ein", "Red\u00b7ner", "sey", "ge\u00b7we\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ART", "NN", "VAFIN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vermuthlich sprichst du ja, und alle Welt stimmt ein:", "tokens": ["Ver\u00b7muth\u00b7lich", "sprichst", "du", "ja", ",", "und", "al\u00b7le", "Welt", "stimmt", "ein", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "PIAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Allein, verzeihe mirs, ich selber sage Nein!", "tokens": ["Al\u00b7lein", ",", "ver\u00b7zei\u00b7he", "mirs", ",", "ich", "sel\u00b7ber", "sa\u00b7ge", "Nein", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "NE", "$,", "PPER", "ADV", "VVFIN", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ists m\u00f6glich, da\u00df man den mit Recht beredsam nennet,", "tokens": ["Ists", "m\u00f6g\u00b7lich", ",", "da\u00df", "man", "den", "mit", "Recht", "be\u00b7red\u00b7sam", "nen\u00b7net", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PIS", "ART", "APPR", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der nicht das A.B.C. der ", "tokens": ["Der", "nicht", "das", "A.", "B.", "C.", "der"], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "abbreviation", "word"], "pos": ["ART", "PTKNEG", "ART", "APPRART", "NN", "NE", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Nein! Nein! ", "tokens": ["Nein", "!", "Nein", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["PTKANT", "$.", "PTKANT", "$."], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Macht keinen Eingang h\u00fcbsch, formirt kein ", "tokens": ["Macht", "kei\u00b7nen", "Ein\u00b7gang", "h\u00fcbsch", ",", "for\u00b7mirt", "kein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "PIAT", "NN", "ADJD", "$,", "VVPP", "PIAT"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Theilt solches niemals ab, kann nicht exegesiren;", "tokens": ["Theilt", "sol\u00b7ches", "nie\u00b7mals", "ab", ",", "kann", "nicht", "e\u00b7xe\u00b7ge\u00b7si\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKVZ", "$,", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Weis nicht der Sylben Kraft im Grundtext nachzusp\u00fcren;", "tokens": ["Weis", "nicht", "der", "Syl\u00b7ben", "Kraft", "im", "Grund\u00b7text", "nach\u00b7zu\u00b7sp\u00fc\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "NN", "APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Citirt die Spr\u00fcche nicht, und plaudert ungef\u00e4hr", "tokens": ["Ci\u00b7tirt", "die", "Spr\u00fc\u00b7che", "nicht", ",", "und", "plau\u00b7dert", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ART", "NN", "PTKNEG", "$,", "KON", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nur lauter Menschenwitz und eigne Worte her;", "tokens": ["Nur", "lau\u00b7ter", "Men\u00b7schen\u00b7witz", "und", "eig\u00b7ne", "Wor\u00b7te", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gebraucht, an statt der Schrift, die Redekunst der Heyden,", "tokens": ["Ge\u00b7braucht", ",", "an", "statt", "der", "Schrift", ",", "die", "Re\u00b7de\u00b7kunst", "der", "Hey\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "APPR", "APPR", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und pflegt das Christenthum ganz weltlich einzukleiden.", "tokens": ["Und", "pflegt", "das", "Chris\u00b7ten\u00b7thum", "ganz", "welt\u00b7lich", "ein\u00b7zu\u00b7klei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ist das ein ", "tokens": ["Ist", "das", "ein"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PDS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.17": {"text": "Ich hab es auch gedacht, ich hab es auch gemeynt:", "tokens": ["Ich", "hab", "es", "auch", "ge\u00b7dacht", ",", "ich", "hab", "es", "auch", "ge\u00b7meynt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$,", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Doch, als ich neulich selbst sein Predigtbuch gelesen;", "tokens": ["Doch", ",", "als", "ich", "neu\u00b7lich", "selbst", "sein", "Pre\u00b7digt\u00b7buch", "ge\u00b7le\u00b7sen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Nahm ich erstaunend wahr, da\u00df er ein Kind gewesen.", "tokens": ["Nahm", "ich", "er\u00b7stau\u00b7nend", "wahr", ",", "da\u00df", "er", "ein", "Kind", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVPP", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Noch mehr! ", "tokens": ["Noch", "mehr", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADV", "$."], "meter": "++", "measure": "spondeus"}, "line.2": {"text": "Verdient den Lobspruch nicht, da\u00df er die Lehrart kann.", "tokens": ["Ver\u00b7di\u00b7ent", "den", "Lob\u00b7spruch", "nicht", ",", "da\u00df", "er", "die", "Le\u00b7hrart", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKNEG", "$,", "KOUS", "PPER", "ART", "NN", "VMFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zwar ist sein Vortrag stets voll Eifer, Geist und Leben,", "tokens": ["Zwar", "ist", "sein", "Vor\u00b7trag", "stets", "voll", "Ei\u00b7fer", ",", "Geist", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie seine Schriften noch das sichre Zeugni\u00df geben.", "tokens": ["Wie", "sei\u00b7ne", "Schrif\u00b7ten", "noch", "das", "sich\u00b7re", "Zeug\u00b7ni\u00df", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Er dringt durch Mark und Bein, er strafet, drohet, schreckt,", "tokens": ["Er", "dringt", "durch", "Mark", "und", "Bein", ",", "er", "stra\u00b7fet", ",", "dro\u00b7het", ",", "schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$,", "PPER", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ermahnet, tr\u00f6stet, warnt, ermuntert und erweckt:", "tokens": ["Er\u00b7mah\u00b7net", ",", "tr\u00f6s\u00b7tet", ",", "warnt", ",", "er\u00b7mun\u00b7tert", "und", "er\u00b7weckt", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Allein, was hilft ihm das, wenn die Methode fehlet,", "tokens": ["Al\u00b7lein", ",", "was", "hilft", "ihm", "das", ",", "wenn", "die", "Me\u00b7tho\u00b7de", "feh\u00b7let", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VVFIN", "PPER", "PDS", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und jeder, der sie sucht, sich ganz vergebens qu\u00e4let?", "tokens": ["Und", "je\u00b7der", ",", "der", "sie", "sucht", ",", "sich", "ganz", "ver\u00b7ge\u00b7bens", "qu\u00e4\u00b7let", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "PRF", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ach st\u00fcnde ", "tokens": ["Ach", "st\u00fcn\u00b7de"], "token_info": ["word", "word"], "pos": ["ITJ", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.10": {"text": "Er g\u00e4be ganz gewi\u00df sein Feuer in den Kauf,", "tokens": ["Er", "g\u00e4\u00b7be", "ganz", "ge\u00b7wi\u00df", "sein", "Feu\u00b7er", "in", "den", "Kauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und n\u00e4hme Regeln an. Er w\u00fcrde gern bekennen,", "tokens": ["Und", "n\u00e4h\u00b7me", "Re\u00b7geln", "an", ".", "Er", "w\u00fcr\u00b7de", "gern", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sein ganzes Predigen sey ein Geschw\u00e4tz zu nennen:", "tokens": ["Sein", "gan\u00b7zes", "Pre\u00b7di\u00b7gen", "sey", "ein", "Ge\u00b7schw\u00e4tz", "zu", "nen\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--++-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Er kaufte sich den ", "tokens": ["Er", "kauf\u00b7te", "sich", "den"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.14": {"text": "Er w\u00fcrde ", "tokens": ["Er", "w\u00fcr\u00b7de"], "token_info": ["word", "word"], "pos": ["PPER", "VAFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Und ganze Jahre lang, nach hundert Arten, lernen,", "tokens": ["Und", "gan\u00b7ze", "Jah\u00b7re", "lang", ",", "nach", "hun\u00b7dert", "Ar\u00b7ten", ",", "ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "$,", "APPR", "CARD", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Sich k\u00fcnstlich von dem Sinn des Geistes zu entfernen.", "tokens": ["Sich", "k\u00fcnst\u00b7lich", "von", "dem", "Sinn", "des", "Geis\u00b7tes", "zu", "ent\u00b7fer\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Du lebest itzt, o Freund! und thust es dennoch nicht.", "tokens": ["Du", "le\u00b7best", "itzt", ",", "o", "Freund", "!", "und", "thust", "es", "den\u00b7noch", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "FM", "NN", "$.", "KON", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was denkst du immermehr? Ach! drehe, wie man spricht,", "tokens": ["Was", "denkst", "du", "im\u00b7mer\u00b7mehr", "?", "Ach", "!", "dre\u00b7he", ",", "wie", "man", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "ITJ", "$.", "VVFIN", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn jeder Kluge thuts, den Mantel nach dem Winde.", "tokens": ["Denn", "je\u00b7der", "Klu\u00b7ge", "thuts", ",", "den", "Man\u00b7tel", "nach", "dem", "Win\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie z\u00fcrnet nicht bereits ", "tokens": ["Wie", "z\u00fcr\u00b7net", "nicht", "be\u00b7reits"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PTKNEG", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da\u00df sein Gewerbe f\u00e4llt! Es st\u00fcrmet auf dich zu", "tokens": ["Da\u00df", "sein", "Ge\u00b7wer\u00b7be", "f\u00e4llt", "!", "Es", "st\u00fcr\u00b7met", "auf", "dich", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PPER", "PTKZU"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bedenke doch dein Gl\u00fcck! bedenke deine Ruh!", "tokens": ["Be\u00b7den\u00b7ke", "doch", "dein", "Gl\u00fcck", "!", "be\u00b7den\u00b7ke", "dei\u00b7ne", "Ruh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Es kann dich mit der Zeit noch in der That gereuen;", "tokens": ["Es", "kann", "dich", "mit", "der", "Zeit", "noch", "in", "der", "That", "ge\u00b7reu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So bald die Zunft nur wird: ", "tokens": ["So", "bald", "die", "Zunft", "nur", "wird", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "ADV", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Allein, ich sehe schon, du nimmst kein Warnen an,", "tokens": ["Al\u00b7lein", ",", "ich", "se\u00b7he", "schon", ",", "du", "nimmst", "kein", "War\u00b7nen", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Weil dein beherzter Muth so leicht nicht zittern kann.", "tokens": ["Weil", "dein", "be\u00b7herz\u00b7ter", "Muth", "so", "leicht", "nicht", "zit\u00b7tern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "ADJD", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du schreibest gar ein Buch, und suchest einzusch\u00e4rfen,", "tokens": ["Du", "schrei\u00b7best", "gar", "ein", "Buch", ",", "und", "su\u00b7chest", "ein\u00b7zu\u00b7sch\u00e4r\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,", "KON", "VVFIN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Das hei\u00dft zu viel gewagt! Freund! hast du auch bedacht,", "tokens": ["Das", "hei\u00dft", "zu", "viel", "ge\u00b7wagt", "!", "Freund", "!", "hast", "du", "auch", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKA", "PIS", "VVPP", "$.", "NN", "$.", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie arm die\u00df Unterstehn dich an Erfindung macht?", "tokens": ["Wie", "arm", "die\u00df", "Un\u00b7ter\u00b7stehn", "dich", "an", "Er\u00b7fin\u00b7dung", "macht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PDS", "VVFIN", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie matt wird k\u00fcnftig nicht dein kaltes ", "tokens": ["Wie", "matt", "wird", "k\u00fcnf\u00b7tig", "nicht", "dein", "kal\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "ADJD", "PTKNEG", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was nicht ", "tokens": ["Was", "nicht"], "token_info": ["word", "word"], "pos": ["PWS", "PTKNEG"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Denn man versteht es gleich, und hat die Freude nicht,", "tokens": ["Denn", "man", "ver\u00b7steht", "es", "gleich", ",", "und", "hat", "die", "Freu\u00b7de", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "ADV", "$,", "KON", "VAFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da\u00df der gemeine Mann zu seinem Nachbar spricht:", "tokens": ["Da\u00df", "der", "ge\u00b7mei\u00b7ne", "Mann", "zu", "sei\u00b7nem", "Nach\u00b7bar", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "\u00bbdas ist was artiges! das ist schwer auszuf\u00fchren!", "tokens": ["\u00bb", "das", "ist", "was", "ar\u00b7ti\u00b7ges", "!", "das", "ist", "schwer", "aus\u00b7zu\u00b7f\u00fch\u00b7ren", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "PIS", "ADJA", "$.", "PDS", "VAFIN", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Im Texte wenigstens ist nichts davon zu sp\u00fcren.\u00ab", "tokens": ["Im", "Tex\u00b7te", "we\u00b7nigs\u00b7tens", "ist", "nichts", "da\u00b7von", "zu", "sp\u00fc\u00b7ren", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "PIS", "PAV", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Du guter L\u00e4ye, du! was weist doch du davon?", "tokens": ["Du", "gu\u00b7ter", "L\u00e4\u00b7ye", ",", "du", "!", "was", "weist", "doch", "du", "da\u00b7von", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PPER", "$.", "PWS", "VVFIN", "ADV", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein rechter ", "tokens": ["Ein", "rech\u00b7ter"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Wer wird sich so genau an Christi Worte binden?", "tokens": ["Wer", "wird", "sich", "so", "ge\u00b7nau", "an", "Chris\u00b7ti", "Wor\u00b7te", "bin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PRF", "ADV", "ADJD", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Man mu\u00df in jedem Text auch jedes ", "tokens": ["Man", "mu\u00df", "in", "je\u00b7dem", "Text", "auch", "je\u00b7des"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "APPR", "PIAT", "NN", "ADV", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Denn w\u00e4re dieses nicht; wie w\u00e4r es auszustehn,", "tokens": ["Denn", "w\u00e4\u00b7re", "die\u00b7ses", "nicht", ";", "wie", "w\u00e4r", "es", "aus\u00b7zu\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PDS", "PTKNEG", "$.", "PWAV", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.19": {"text": "Und dennoch allezeit die l\u00e4ngst bekannten Sachen,", "tokens": ["Und", "den\u00b7noch", "al\u00b7le\u00b7zeit", "die", "l\u00e4ngst", "be\u00b7kann\u00b7ten", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Durch wahren Wortverstand, beliebt und neu zu machen?", "tokens": ["Durch", "wah\u00b7ren", "Wort\u00b7ver\u00b7stand", ",", "be\u00b7liebt", "und", "neu", "zu", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein h\u00fcbscher Uebergu\u00df macht saure Speisen s\u00fc\u00df:", "tokens": ["Ein", "h\u00fcb\u00b7scher", "Ue\u00b7ber\u00b7gu\u00df", "macht", "sau\u00b7re", "Spei\u00b7sen", "s\u00fc\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Und Dank sey dem gesagt! der uns die Lehrart wies,", "tokens": ["Und", "Dank", "sey", "dem", "ge\u00b7sagt", "!", "der", "uns", "die", "Le\u00b7hrart", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "ART", "VVPP", "$.", "ART", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Was in dem Texte fehlt, durch Kunst hinein zu bringen,", "tokens": ["Was", "in", "dem", "Tex\u00b7te", "fehlt", ",", "durch", "Kunst", "hin\u00b7ein", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Und was nicht flie\u00dfen will, ein wenig zu erzwingen.", "tokens": ["Und", "was", "nicht", "flie\u00b7\u00dfen", "will", ",", "ein", "we\u00b7nig", "zu", "er\u00b7zwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "VVINF", "VMFIN", "$,", "ART", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Kein Jahrgang ist so schlecht, er giebt ein Muster ab,", "tokens": ["Kein", "Jahr\u00b7gang", "ist", "so", "schlecht", ",", "er", "giebt", "ein", "Mus\u00b7ter", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Wie artig man dem Text die neue Deutung gab.", "tokens": ["Wie", "ar\u00b7tig", "man", "dem", "Text", "die", "neu\u00b7e", "Deu\u00b7tung", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PIS", "ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Ich weis, da\u00df Paulus selbst sich oft im Engelorden", "tokens": ["Ich", "weis", ",", "da\u00df", "Pau\u00b7lus", "selbst", "sich", "oft", "im", "En\u00b7ge\u00b7lor\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "PTKVZ", "$,", "KOUS", "NE", "ADV", "PRF", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Gewundert, wie sein Text so sch\u00f6n verst\u00fcmmelt worden.", "tokens": ["Ge\u00b7wun\u00b7dert", ",", "wie", "sein", "Text", "so", "sch\u00f6n", "ver\u00b7st\u00fcm\u00b7melt", "wor\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Vergieb den freyen Scherz, mein ", "tokens": ["Ver\u00b7gieb", "den", "frey\u00b7en", "Scherz", ",", "mein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$,", "PPOSAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Du weist es ohnedem, wie gut mein Herz es meynt:", "tokens": ["Du", "weist", "es", "oh\u00b7ne\u00b7dem", ",", "wie", "gut", "mein", "Herz", "es", "meynt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PAV", "$,", "PWAV", "ADJD", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich kenne dein Verdienst, und ehrete dein Lehren,", "tokens": ["Ich", "ken\u00b7ne", "dein", "Ver\u00b7dienst", ",", "und", "eh\u00b7re\u00b7te", "dein", "Leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So oft es mir gegl\u00fcckt, dein Predigen zu h\u00f6ren.", "tokens": ["So", "oft", "es", "mir", "ge\u00b7gl\u00fcckt", ",", "dein", "Pre\u00b7di\u00b7gen", "zu", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "PPER", "VVPP", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dein Merseburg gewinnt, und wir verlieren viel:", "tokens": ["Dein", "Mer\u00b7se\u00b7burg", "ge\u00b7winnt", ",", "und", "wir", "ver\u00b7lie\u00b7ren", "viel", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "KON", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch unser W\u00fcnschen ist nicht stets des Himmels Ziel.", "tokens": ["Doch", "un\u00b7ser", "W\u00fcn\u00b7schen", "ist", "nicht", "stets", "des", "Him\u00b7mels", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PTKNEG", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Noch mehr, ich freute mich, so oft ich nur bedachte,", "tokens": ["Noch", "mehr", ",", "ich", "freu\u00b7te", "mich", ",", "so", "oft", "ich", "nur", "be\u00b7dach\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "PPER", "$,", "ADV", "ADV", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wie viel dein Unterricht geschickte Sch\u00fcler machte.", "tokens": ["Wie", "viel", "dein", "Un\u00b7ter\u00b7richt", "ge\u00b7schick\u00b7te", "Sch\u00fc\u00b7ler", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ach! sprach ich bey mir selbst, der Mann wird ungemein,", "tokens": ["Ach", "!", "sprach", "ich", "bey", "mir", "selbst", ",", "der", "Mann", "wird", "un\u00b7ge\u00b7mein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "APPR", "PPER", "ADV", "$,", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wird unserm Leipzig einst ein andrer ", "tokens": ["Wird", "un\u00b7serm", "Leip\u00b7zig", "einst", "ein", "an\u00b7drer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NE", "ADV", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Er wird den bunten Kram der Kunstmethoden st\u00f6ren,", "tokens": ["Er", "wird", "den", "bun\u00b7ten", "Kram", "der", "Kunst\u00b7me\u00b7tho\u00b7den", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und die Beredsamkeit der alten V\u00e4ter lehren;", "tokens": ["Und", "die", "Be\u00b7red\u00b7sam\u00b7keit", "der", "al\u00b7ten", "V\u00e4\u00b7ter", "leh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die ungezwungen flie\u00dft, und voller Geist und Kraft,", "tokens": ["Die", "un\u00b7ge\u00b7zwun\u00b7gen", "flie\u00dft", ",", "und", "vol\u00b7ler", "Geist", "und", "Kraft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "$,", "KON", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Verstand und Willen lenkt und tausend Nutzen schafft.", "tokens": ["Ver\u00b7stand", "und", "Wil\u00b7len", "lenkt", "und", "tau\u00b7send", "Nut\u00b7zen", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "KON", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wie gl\u00fccklich sind nicht die, die schon von dir gelernet,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "sind", "nicht", "die", ",", "die", "schon", "von", "dir", "ge\u00b7ler\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PTKNEG", "ART", "$,", "PRELS", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Wie l\u00f6blich sich der Mund vom ", "tokens": ["Wie", "l\u00f6b\u00b7lich", "sich", "der", "Mund", "vom"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "PRF", "ART", "NN", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Der alles \u00fcberschwemmt. Wiewohl ich hoffe noch!", "tokens": ["Der", "al\u00b7les", "\u00fc\u00b7bersc\u00b7hwemmt", ".", "Wie\u00b7wohl", "ich", "hof\u00b7fe", "noch", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "KOUS", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wer weis, was bald geschieht? So kann dich Leipzig doch", "tokens": ["Wer", "weis", ",", "was", "bald", "ge\u00b7schieht", "?", "So", "kann", "dich", "Leip\u00b7zig", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKVZ", "$,", "PRELS", "ADV", "VVFIN", "$.", "ADV", "VMFIN", "PRF", "NE", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Auf seinem Lehrstuhl sehn. Kommt, kommt, erw\u00fcnschte Zeiten!", "tokens": ["Auf", "sei\u00b7nem", "Lehr\u00b7stuhl", "sehn", ".", "Kommt", ",", "kommt", ",", "er\u00b7w\u00fcnschte", "Zei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$.", "VVFIN", "$,", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Und helft zu ", "tokens": ["Und", "helft", "zu"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}}}}}