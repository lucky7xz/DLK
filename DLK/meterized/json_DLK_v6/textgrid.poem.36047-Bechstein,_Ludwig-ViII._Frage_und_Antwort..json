{"textgrid.poem.36047": {"metadata": {"author": {"name": "Bechstein, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "ViII. Frage und Antwort.", "genre": "verse", "period": "N.A.", "pub_year": 1830, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im gr\u00fcnen Walde wandeln zwei M\u00e4nner, k\u00fchl umrauscht,", "tokens": ["Im", "gr\u00fc\u00b7nen", "Wal\u00b7de", "wan\u00b7deln", "zwei", "M\u00e4n\u00b7ner", ",", "k\u00fchl", "um\u00b7rauscht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "CARD", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da wird von hohen Dingen manch ernstes Wort getauscht.", "tokens": ["Da", "wird", "von", "ho\u00b7hen", "Din\u00b7gen", "manch", "erns\u00b7tes", "Wort", "ge\u00b7tauscht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ADJA", "NN", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Eine f\u00fcr sein Wissen sucht reichlichen Gewinn,", "tokens": ["Der", "Ei\u00b7ne", "f\u00fcr", "sein", "Wis\u00b7sen", "sucht", "reich\u00b7li\u00b7chen", "Ge\u00b7winn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}, "line.4": {"text": "Dem reicht des Trugs Narzissen der zweite listig hin.", "tokens": ["Dem", "reicht", "des", "Trugs", "Nar\u00b7zis\u00b7sen", "der", "zwei\u00b7te", "lis\u00b7tig", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "NN", "ART", "ADJA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Belehrung ist ein Saatkorn, das Fr\u00fcchte tr\u00fcgt mit Lust;", "tokens": ["Be\u00b7leh\u00b7rung", "ist", "ein", "Saat\u00b7korn", ",", "das", "Fr\u00fcch\u00b7te", "tr\u00fcgt", "mit", "Lust", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "T\u00e4uschung ist eine Giftsaat, geworfen in die Brust.", "tokens": ["T\u00e4u\u00b7schung", "ist", "ei\u00b7ne", "Gift\u00b7saat", ",", "ge\u00b7wor\u00b7fen", "in", "die", "Brust", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "VVPP", "APPR", "ART", "NN", "$."], "meter": "+--+-++-+-+-+", "measure": "iambic.septa.invert"}, "line.3": {"text": "Belehrung ist die Tochter der Wahrheit und des Lichts,", "tokens": ["Be\u00b7leh\u00b7rung", "ist", "die", "Toch\u00b7ter", "der", "Wahr\u00b7heit", "und", "des", "Lichts", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der L\u00fcge Kind ist T\u00e4uschung, ein buntbemaltes Nichts.", "tokens": ["Der", "L\u00fc\u00b7ge", "Kind", "ist", "T\u00e4u\u00b7schung", ",", "ein", "bunt\u00b7be\u00b7mal\u00b7tes", "Nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Und Faustus zu Mephisto: \u00bbWer hier sich dingt den Knecht,", "tokens": ["Und", "Faus\u00b7tus", "zu", "Me\u00b7phis\u00b7to", ":", "\u00bb", "Wer", "hier", "sich", "dingt", "den", "Knecht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "NE", "$.", "$(", "PWS", "ADV", "PRF", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der fragt nach dessen Herkunft mit Fug und Vollem Recht.", "tokens": ["Der", "fragt", "nach", "des\u00b7sen", "Her\u00b7kunft", "mit", "Fug", "und", "Vol\u00b7lem", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PRELAT", "NN", "APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich weiss, Du bist ein D\u00e4mon, doch sage: welcher Art,", "tokens": ["Ich", "weiss", ",", "Du", "bist", "ein", "D\u00e4\u00b7mon", ",", "doch", "sa\u00b7ge", ":", "wel\u00b7cher", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "$.", "PWAT", "NN", "$,"], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "Wess Ursprungs und was alles Dir unterworfen ward?\u00ab", "tokens": ["Wess", "Ur\u00b7sprungs", "und", "was", "al\u00b7les", "Dir", "un\u00b7ter\u00b7wor\u00b7fen", "ward", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "NE", "KON", "PWS", "PIS", "PPER", "VVPP", "VAFIN", "$.", "$("], "meter": "--+-++--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "\u203ader Stolzeste der Stolzen riss uns in seinen Fall;", "tokens": ["\u203a", "der", "Stol\u00b7zes\u00b7te", "der", "Stol\u00b7zen", "riss", "uns", "in", "sei\u00b7nen", "Fall", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+---+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Nun schweben wir verbreitet, wie Luft und Licht, im All.", "tokens": ["Nun", "schwe\u00b7ben", "wir", "ver\u00b7brei\u00b7tet", ",", "wie", "Luft", "und", "Licht", ",", "im", "All", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,", "PWAV", "NN", "KON", "NN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wir sind es, die mit Sch\u00f6nheit die Belladonnen schm\u00fccken,", "tokens": ["Wir", "sind", "es", ",", "die", "mit", "Sch\u00f6n\u00b7heit", "die", "Bel\u00b7la\u00b7don\u00b7nen", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "APPR", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Damit die Menschenkinder sie desto gier'ger pfl\u00fccken.\u2039", "tokens": ["Da\u00b7mit", "die", "Men\u00b7schen\u00b7kin\u00b7der", "sie", "des\u00b7to", "gier'\u00b7ger", "pfl\u00fc\u00b7cken", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "ADV", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "\u00bbso s\u00e4't Vernichtungskeime die Sippschaft, die verdammte?", "tokens": ["\u00bb", "so", "s\u00e4't", "Ver\u00b7nich\u00b7tungs\u00b7kei\u00b7me", "die", "Sipp\u00b7schaft", ",", "die", "ver\u00b7damm\u00b7te", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "NN", "ART", "NN", "$,", "ART", "ADJA", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und w\u00e4ren Deines Gleichen noch viel vom gleichen Amte?\u00ab", "tokens": ["Und", "w\u00e4\u00b7ren", "Dei\u00b7nes", "Glei\u00b7chen", "noch", "viel", "vom", "glei\u00b7chen", "Am\u00b7te", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "APPRART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203azahlreich, wie Bienenschw\u00e4rme, verderblich abgesandt", "tokens": ["\u203a", "zahl\u00b7reich", ",", "wie", "Bie\u00b7nen\u00b7schw\u00e4r\u00b7me", ",", "ver\u00b7derb\u00b7lich", "ab\u00b7ge\u00b7sandt"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "ADJD", "$,", "PWAV", "NN", "$,", "ADJD", "VVPP"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Sind wir, wie Sternenheere; wie Kies am Meeresstrand.\u2039", "tokens": ["Sind", "wir", ",", "wie", "Ster\u00b7nen\u00b7hee\u00b7re", ";", "wie", "Kies", "am", "Mee\u00b7res\u00b7strand", ".", "\u2039"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "$,", "PWAV", "NN", "$.", "PWAV", "NE", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbso zahlreich? Nun, dann sage: wo weilt, wo wohnet Ihr?\u00ab", "tokens": ["\u00bb", "so", "zahl\u00b7reich", "?", "Nun", ",", "dann", "sa\u00b7ge", ":", "wo", "weilt", ",", "wo", "woh\u00b7net", "Ihr", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "$.", "ADV", "$,", "ADV", "VVFIN", "$.", "PWAV", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u203awir ruhen in Metallen, erf\u00fcllen Pflanz' und Thier,", "tokens": ["\u203a", "wir", "ru\u00b7hen", "in", "Me\u00b7tal\u00b7len", ",", "er\u00b7f\u00fcl\u00b7len", "Pflanz'", "und", "Thier", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "NN", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das Kleinste wie das Gr\u00f6sste dient uns als Unterthan;", "tokens": ["Das", "Kleins\u00b7te", "wie", "das", "Gr\u00f6ss\u00b7te", "dient", "uns", "als", "Un\u00b7ter\u00b7than", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "ADJA", "VVFIN", "PPER", "KOUS", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zur Wollust uns \u00fcbt rastlos Zerst\u00f6rung ihren Zahn.\u2039", "tokens": ["Zur", "Wol\u00b7lust", "uns", "\u00fcbt", "rast\u00b7los", "Zer\u00b7st\u00f6\u00b7rung", "ih\u00b7ren", "Zahn", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "ADJD", "NN", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00bbund welches war die Ursach, das sprich mir, jenes Falles,", "tokens": ["\u00bb", "und", "wel\u00b7ches", "war", "die", "Ur\u00b7sach", ",", "das", "sprich", "mir", ",", "je\u00b7nes", "Fal\u00b7les", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "KON", "PWS", "VAFIN", "ART", "NN", "$,", "PDS", "VVFIN", "PPER", "$,", "PDAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Unheil zeugend fortwirkt auf Dich, auf mich, auf Alles?\u00ab", "tokens": ["Der", "Un\u00b7heil", "zeu\u00b7gend", "fort\u00b7wirkt", "auf", "Dich", ",", "auf", "mich", ",", "auf", "Al\u00b7les", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVPP", "VVFIN", "APPR", "PPER", "$,", "APPR", "PPER", "$,", "APPR", "PIS", "$.", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203afaustus, der Drang, sich \u00e4hnlich der Gottheit stolz zu bl\u00e4hn;", "tokens": ["\u203a", "faus\u00b7tus", ",", "der", "Drang", ",", "sich", "\u00e4hn\u00b7lich", "der", "Got\u00b7theit", "stolz", "zu", "bl\u00e4hn", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "$,", "ART", "NN", "$,", "PRF", "ADJD", "ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Du weisst wohl, das auch Menschen sich Gleiches unterstehn.\u2039", "tokens": ["Du", "weisst", "wohl", ",", "das", "auch", "Men\u00b7schen", "sich", "Glei\u00b7ches", "un\u00b7ter\u00b7stehn", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PRELS", "ADV", "NN", "PRF", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "\u00bbnoch hat mich nicht befriedigt, was Du mir hast vertraut:", "tokens": ["\u00bb", "noch", "hat", "mich", "nicht", "be\u00b7frie\u00b7digt", ",", "was", "Du", "mir", "hast", "ver\u00b7traut", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,", "PWS", "PPER", "PPER", "VAFIN", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den Anblick dessen schildre, den froh der Engel schaut.\u00ab", "tokens": ["Den", "An\u00b7blick", "des\u00b7sen", "schild\u00b7re", ",", "den", "froh", "der", "En\u00b7gel", "schaut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PDS", "VVFIN", "$,", "PRELS", "ADJD", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203aseit wir verworfen worden von jener Himmelsmacht,", "tokens": ["\u203a", "seit", "wir", "ver\u00b7wor\u00b7fen", "wor\u00b7den", "von", "je\u00b7ner", "Him\u00b7mels\u00b7macht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PPER", "VVPP", "VAPP", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sank uns der Mond ", "tokens": ["Sank", "uns", "der", "Mond"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "\u00bbso rede von den Engeln, die selig sind mit ihm!", "tokens": ["\u00bb", "so", "re\u00b7de", "von", "den", "En\u00b7geln", ",", "die", "se\u00b7lig", "sind", "mit", "ihm", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "APPR", "PPER", "$."], "meter": "-+-+-+--+-++-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Was ist im Geisterhimmel das Amt der Seraphim?\u00ab \u2013", "tokens": ["Was", "ist", "im", "Geis\u00b7ter\u00b7him\u00b7mel", "das", "Amt", "der", "Se\u00b7ra\u00b7phim", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "VAFIN", "APPRART", "NN", "ART", "NN", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203asie schaun das Vaterantlitz, das heilge, sonder H\u00fclle,", "tokens": ["\u203a", "sie", "schaun", "das", "Va\u00b7ter\u00b7ant\u00b7litz", ",", "das", "heil\u00b7ge", ",", "son\u00b7der", "H\u00fcl\u00b7le", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "$,", "ART", "ADJA", "$,", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Endlos in Kraft und Sch\u00f6nheit, in g\u00f6ttlichreicher F\u00fclle.\u2039", "tokens": ["End\u00b7los", "in", "Kraft", "und", "Sch\u00f6n\u00b7heit", ",", "in", "g\u00f6tt\u00b7li\u00b7ch\u00b7rei\u00b7cher", "F\u00fcl\u00b7le", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,", "APPR", "ADJA", "NN", "$.", "$("], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}}, "stanza.10": {"line.1": {"text": "\u00bbund von den Cherubinen und Thronen gieb mir Kunde!\u00ab", "tokens": ["\u00bb", "und", "von", "den", "Che\u00b7ru\u00b7bi\u00b7nen", "und", "Thro\u00b7nen", "gieb", "mir", "Kun\u00b7de", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "APPR", "ART", "NN", "KON", "NN", "VVIMP", "PPER", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u203asuchst Du des Lichts Geheimniss, Faust, im D\u00e4monenmunde?", "tokens": ["\u203a", "suchst", "Du", "des", "Lichts", "Ge\u00b7heim\u00b7niss", ",", "Faust", ",", "im", "D\u00e4\u00b7mo\u00b7nen\u00b7mun\u00b7de", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "NN", "$,", "NN", "$,", "APPRART", "NN", "$."], "meter": "+--+-+-+--+-+-", "measure": "iambic.hexa.invert"}, "line.3": {"text": "Des Lichtes Boten freuen sich an der Macht des Herrn,", "tokens": ["Des", "Lich\u00b7tes", "Bo\u00b7ten", "freu\u00b7en", "sich", "an", "der", "Macht", "des", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wir aber nennen, denken, verk\u00fcnden sie nicht gern.\u2039", "tokens": ["Wir", "a\u00b7ber", "nen\u00b7nen", ",", "den\u00b7ken", ",", "ver\u00b7k\u00fcn\u00b7den", "sie", "nicht", "gern", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "VVINF", "$,", "VVINF", "$,", "VVFIN", "PPER", "PTKNEG", "ADV", "$.", "$("], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbso schweige mir vom Himmel, daraus man Dich verstiess;", "tokens": ["\u00bb", "so", "schwei\u00b7ge", "mir", "vom", "Him\u00b7mel", ",", "da\u00b7raus", "man", "Dich", "ver\u00b7stiess", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$,", "PAV", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch wirst Du treu mir k\u00fcnden: wo liegt das Paradies?\u00ab", "tokens": ["Doch", "wirst", "Du", "treu", "mir", "k\u00fcn\u00b7den", ":", "wo", "liegt", "das", "Pa\u00b7ra\u00b7dies", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "VVFIN", "PPER", "VVFIN", "$.", "PWAV", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203aso weit ist das entlegen, dass Du mit Deines Gleichen", "tokens": ["\u203a", "so", "weit", "ist", "das", "ent\u00b7le\u00b7gen", ",", "dass", "Du", "mit", "Dei\u00b7nes", "Glei\u00b7chen"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADJD", "VAFIN", "ART", "ADJA", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Auf Schwingen selbst des Sturmwinds, es nimmer m\u00f6gt erreichen.\u2039", "tokens": ["Auf", "Schwin\u00b7gen", "selbst", "des", "Sturm\u00b7winds", ",", "es", "nim\u00b7mer", "m\u00f6gt", "er\u00b7rei\u00b7chen", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "ADV", "ART", "NN", "$,", "PPER", "ADV", "VMFIN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "\u203avier heilge Str\u00f6m' umarmen das gottgeliebte Land;", "tokens": ["\u203a", "vier", "heil\u00b7ge", "Str\u00f6m'", "um\u00b7ar\u00b7men", "das", "gott\u00b7ge\u00b7lieb\u00b7te", "Land", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "CARD", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Sie werden Glaube, Liebe, Hoffnung und Treu' genannt.", "tokens": ["Sie", "wer\u00b7den", "Glau\u00b7be", ",", "Lie\u00b7be", ",", "Hoff\u00b7nung", "und", "Treu'", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Inmitten hebt die Kronen der ewge Lebensbaum;", "tokens": ["In\u00b7mit\u00b7ten", "hebt", "die", "Kro\u00b7nen", "der", "ew\u00b7ge", "Le\u00b7bens\u00b7baum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gedenkst ", "tokens": ["Ge\u00b7denkst"], "token_info": ["word"], "pos": ["NN"], "meter": "-+", "measure": "iambic.single"}}, "stanza.13": {"line.1": {"text": "\u00bbh\u00f6hnst Du? \u2013 Gleich sag' mir Antwort auf andre Fragen an:", "tokens": ["\u00bb", "h\u00f6hnst", "Du", "?", "\u2013", "Gleich", "sag'", "mir", "Ant\u00b7wort", "auf", "and\u00b7re", "Fra\u00b7gen", "an", ":"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$.", "$(", "ADV", "VVFIN", "PPER", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "W\u00e4rst Faustus ", "tokens": ["W\u00e4rst", "Faus\u00b7tus"], "token_info": ["word", "word"], "pos": ["VAFIN", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "\u203amit ", "tokens": ["\u203a", "mit"], "token_info": ["punct", "word"], "pos": ["$(", "APPR"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Mit ", "tokens": ["Mit"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}, "stanza.14": {"line.1": {"text": "\u00bbmoralmann, blieb Dir Hoffnung? Was hab' ich dann gewagt?\u00ab", "tokens": ["\u00bb", "mo\u00b7ral\u00b7mann", ",", "blieb", "Dir", "Hoff\u00b7nung", "?", "Was", "hab'", "ich", "dann", "ge\u00b7wagt", "?", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "$,", "VVFIN", "PPER", "NN", "$.", "PWS", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u203aschr wenig, Faustus, wenig, drum sei nur unverzagt!\u2039", "tokens": ["\u203a", "schr", "we\u00b7nig", ",", "Faus\u00b7tus", ",", "we\u00b7nig", ",", "drum", "sei", "nur", "un\u00b7ver\u00b7zagt", "!", "\u2039"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PIS", "$,", "NE", "$,", "PIS", "$,", "PAV", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.3": {"text": "\u00bbsprich, Diener: von der H\u00f6lle, was ist das f\u00fcr ein Ort?", "tokens": ["\u00bb", "sprich", ",", "Die\u00b7ner", ":", "von", "der", "H\u00f6l\u00b7le", ",", "was", "ist", "das", "f\u00fcr", "ein", "Ort", "?"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NN", "$.", "APPR", "ART", "NN", "$,", "PWS", "VAFIN", "PDS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Man tr\u00e4umt von ihren Qualen, sprich, warst Du lange dort?\u00ab", "tokens": ["Man", "tr\u00e4umt", "von", "ih\u00b7ren", "Qua\u00b7len", ",", "sprich", ",", "warst", "Du", "lan\u00b7ge", "dort", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "ADJD", "$,", "VAFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "\u203adie H\u00f6lle ruht im Nachtgraun, das Keiner noch durchschaut,", "tokens": ["\u203a", "die", "H\u00f6l\u00b7le", "ruht", "im", "Nacht\u00b7graun", ",", "das", "Kei\u00b7ner", "noch", "durch\u00b7schaut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VVFIN", "APPRART", "NN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und Kunde hat gegeben, wie sie gef\u00fcgt, gebaut.", "tokens": ["Und", "Kun\u00b7de", "hat", "ge\u00b7ge\u00b7ben", ",", "wie", "sie", "ge\u00b7f\u00fcgt", ",", "ge\u00b7baut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "VVPP", "$,", "PWAV", "PPER", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der H\u00f6lle Qualen m\u00fcssen in sich die S\u00fcnder tragen,", "tokens": ["Der", "H\u00f6l\u00b7le", "Qua\u00b7len", "m\u00fcs\u00b7sen", "in", "sich", "die", "S\u00fcn\u00b7der", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VMFIN", "APPR", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "O qu\u00e4le mich nicht l\u00e4nger, nicht Dich mit solchen Fragen!\u2039", "tokens": ["O", "qu\u00e4\u00b7le", "mich", "nicht", "l\u00e4n\u00b7ger", ",", "nicht", "Dich", "mit", "sol\u00b7chen", "Fra\u00b7gen", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKNEG", "ADJD", "$,", "PTKNEG", "PPER", "APPR", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "\u00bbha, bist Du schon ermattet? Ersch\u00f6pft Dich die Begier", "tokens": ["\u00bb", "ha", ",", "bist", "Du", "schon", "er\u00b7mat\u00b7tet", "?", "Er\u00b7sch\u00f6pft", "Dich", "die", "Be\u00b7gier"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ITJ", "$,", "VAFIN", "PPER", "ADV", "VVPP", "$.", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Das Dunkel zu durchdringen, die ewig wach in mir?", "tokens": ["Das", "Dun\u00b7kel", "zu", "durch\u00b7drin\u00b7gen", ",", "die", "e\u00b7wig", "wach", "in", "mir", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "ADJD", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Weshalb denn klopft' ich donnernd an Eure Pforten an,", "tokens": ["We\u00b7shalb", "denn", "klopft'", "ich", "don\u00b7nernd", "an", "Eu\u00b7re", "Pfor\u00b7ten", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Als weil sich meiner Sehnsucht kein Lichtthor aufgethan?\u00ab \u2013", "tokens": ["Als", "weil", "sich", "mei\u00b7ner", "Sehn\u00b7sucht", "kein", "Licht\u00b7thor", "auf\u00b7ge\u00b7than", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KOUS", "KOUS", "PRF", "PPOSAT", "NN", "PIAT", "NN", "VVPP", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "\u00bbich suche nur ", "tokens": ["\u00bb", "ich", "su\u00b7che", "nur"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Um den sich Deine Klugheit dereinst als Schlange wand!\u00ab", "tokens": ["Um", "den", "sich", "Dei\u00b7ne", "Klug\u00b7heit", "de\u00b7reinst", "als", "Schlan\u00b7ge", "wand", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "ART", "PRF", "PPOSAT", "NN", "ADV", "KOUS", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203adir soll Erkenntniss werden, so viel ich geben kann,", "tokens": ["\u203a", "dir", "soll", "Er\u00b7kennt\u00b7niss", "wer\u00b7den", ",", "so", "viel", "ich", "ge\u00b7ben", "kann", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "NN", "VAINF", "$,", "ADV", "ADV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch zum Schulmeister w\u00e4hle Dir einen andern Mann.\u2039", "tokens": ["Doch", "zum", "Schul\u00b7meis\u00b7ter", "w\u00e4h\u00b7le", "Dir", "ei\u00b7nen", "an\u00b7dern", "Mann", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$.", "$("], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}}, "stanza.18": {"line.1": {"text": "\u203awas willst Du von den Engeln, vom Paradies, von Gott?", "tokens": ["\u203a", "was", "willst", "Du", "von", "den", "En\u00b7geln", ",", "vom", "Pa\u00b7ra\u00b7dies", ",", "von", "Gott", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PWS", "VMFIN", "PPER", "APPR", "ART", "NN", "$,", "APPRART", "NN", "$,", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Spott ist nur Deine Frage, wie meine Antwort Spott.", "tokens": ["Spott", "ist", "nur", "Dei\u00b7ne", "Fra\u00b7ge", ",", "wie", "mei\u00b7ne", "Ant\u00b7wort", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "PPOSAT", "NN", "$,", "PWAV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Was fragst Du nach der H\u00f6lle, bangt Dir vor ihrer Gluth?", "tokens": ["Was", "fragst", "Du", "nach", "der", "H\u00f6l\u00b7le", ",", "bangt", "Dir", "vor", "ih\u00b7rer", "Gluth", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Du hast doch Ammenm\u00e4hrchen zu l\u00e4ugnen sonst den Muth?!\u2039 \u2013", "tokens": ["Du", "hast", "doch", "Am\u00b7men\u00b7m\u00e4hr\u00b7chen", "zu", "l\u00e4ug\u00b7nen", "sonst", "den", "Muth", "?!", "\u2039", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "PTKZU", "VVINF", "VMFIN", "ART", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Im gr\u00fcnen Walde wandeln zwei M\u00e4nner schweigend hin,", "tokens": ["Im", "gr\u00fc\u00b7nen", "Wal\u00b7de", "wan\u00b7deln", "zwei", "M\u00e4n\u00b7ner", "schwei\u00b7gend", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "CARD", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der eine finster blickend mit unmuthd\u00fcstrem Sinn,", "tokens": ["Der", "ei\u00b7ne", "fins\u00b7ter", "bli\u00b7ckend", "mit", "un\u00b7muth\u00b7d\u00fcst\u00b7rem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Tr\u00fcb d\u00e4mmert ihm die Ahnung von des Gef\u00e4hrten List,", "tokens": ["Tr\u00fcb", "d\u00e4m\u00b7mert", "ihm", "die", "Ah\u00b7nung", "von", "des", "Ge\u00b7f\u00e4hr\u00b7ten", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und dass f\u00fcr manch Geheimniss kein Thor erschlossen ist. \u2013", "tokens": ["Und", "dass", "f\u00fcr", "manch", "Ge\u00b7heim\u00b7niss", "kein", "Thor", "er\u00b7schlos\u00b7sen", "ist", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "KOUS", "APPR", "PIAT", "NN", "PIAT", "NN", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}}}}