{"dta.poem.1695": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Verb\u00fcndnis-Regeln der Gesellschafft zum  \n weltlichen Einsiedler.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Wer kommen will in dieses Hau\u00df/ ", "tokens": ["Wer", "kom\u00b7men", "will", "in", "die\u00b7ses", "Hau\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVINF", "VMFIN", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Darff nicht die ungetreuen Sinnen", "tokens": ["Darff", "nicht", "die", "un\u00b7ge\u00b7treu\u00b7en", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit falschen Farben zieren aus;", "tokens": ["Mit", "fal\u00b7schen", "Far\u00b7ben", "zie\u00b7ren", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein treues Hertz allein ist angenehm hierinnen.", "tokens": ["Ein", "treu\u00b7es", "Hertz", "al\u00b7lein", "ist", "an\u00b7ge\u00b7nehm", "hie\u00b7rin\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VAFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wer in die treu-verkn\u00fcpffte Zahl", "tokens": ["Wer", "in", "die", "treu\u00b7ver\u00b7kn\u00fcpff\u00b7te", "Zahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Will willig werden auffgenommen/", "tokens": ["Will", "wil\u00b7lig", "wer\u00b7den", "auff\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mu\u00df durch geneigter Stimmen Wahl", "tokens": ["Mu\u00df", "durch", "ge\u00b7neig\u00b7ter", "Stim\u00b7men", "Wahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erlaubnis neben uns zu treten \u00fcberkommen.", "tokens": ["Er\u00b7laub\u00b7nis", "ne\u00b7ben", "uns", "zu", "tre\u00b7ten", "\u00fc\u00b7ber\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Auff gleiche Jahr und gleichen Stand", "tokens": ["Auff", "glei\u00b7che", "Jahr", "und", "glei\u00b7chen", "Stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Pflegt unser w\u00e4hlen sich zu gr\u00fcnden/", "tokens": ["Pflegt", "un\u00b7ser", "w\u00e4h\u00b7len", "sich", "zu", "gr\u00fcn\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "VVFIN", "PRF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Tugend reichen wir die Hand/", "tokens": ["Der", "Tu\u00b7gend", "rei\u00b7chen", "wir", "die", "Hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch Demutt und Gedult kan bey uns Stelle finden.", "tokens": ["Auch", "De\u00b7mutt", "und", "Ge\u00b7dult", "kan", "bey", "uns", "Stel\u00b7le", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "NN", "VMFIN", "APPR", "PPER", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Wer in di\u00df B\u00fcndni\u00df schreitet ein", "tokens": ["Wer", "in", "di\u00df", "B\u00fcn\u00b7dni\u00df", "schrei\u00b7tet", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "PDS", "NN", "VVFIN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df dreyerley zuvor versprechen:", "tokens": ["Mu\u00df", "drey\u00b7er\u00b7ley", "zu\u00b7vor", "ver\u00b7spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Best\u00e4ndig/ Andachts-voll zu seyn/", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "/", "An\u00b7dachts\u00b7voll", "zu", "seyn", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADJD", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sich zu keiner Zeit Gehorsams zu entbrechen.", "tokens": ["Und", "sich", "zu", "kei\u00b7ner", "Zeit", "Ge\u00b7hor\u00b7sams", "zu", "ent\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Wo Andacht in dem Hertzen brennt/", "tokens": ["Wo", "An\u00b7dacht", "in", "dem", "Hert\u00b7zen", "brennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "L\u00e4st sie sich auch durch Wercke sp\u00fcren/", "tokens": ["L\u00e4st", "sie", "sich", "auch", "durch", "Wer\u00b7cke", "sp\u00fc\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer sich ein frommes Mitglied nennt/", "tokens": ["Wer", "sich", "ein", "from\u00b7mes", "Mit\u00b7glied", "nennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird unsre Wohnungs-Statt durch ein Ged\u00e4chtnis zieren.", "tokens": ["Wird", "uns\u00b7re", "Woh\u00b7nungs\u00b7Statt", "durch", "ein", "Ge\u00b7d\u00e4cht\u00b7nis", "zie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der beste Zeit-Vertreib und Spiel", "tokens": ["Der", "bes\u00b7te", "Zeit\u00b7Ver\u00b7treib", "und", "Spiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Besteht in schw\u00e4tzen oder singen:", "tokens": ["Be\u00b7steht", "in", "schw\u00e4t\u00b7zen", "o\u00b7der", "sin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wem nicht die Stimme folgen will", "tokens": ["Wem", "nicht", "die", "Stim\u00b7me", "fol\u00b7gen", "will"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "ART", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kan Lieder nach Befehl der andern Schwestern bringen.", "tokens": ["Kan", "Lie\u00b7der", "nach", "Be\u00b7fehl", "der", "an\u00b7dern", "Schwes\u00b7tern", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "APPR", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die Andacht leitet auch dahin/", "tokens": ["Die", "An\u00b7dacht", "lei\u00b7tet", "auch", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man ein t\u00e4glich Angedencken", "tokens": ["Da\u00df", "man", "ein", "t\u00e4g\u00b7lich", "An\u00b7ge\u00b7den\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Soll in dem Hertzen lassen bl\u00fchn/", "tokens": ["Soll", "in", "dem", "Hert\u00b7zen", "las\u00b7sen", "bl\u00fchn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVINF", "VVINF", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wenn Zeit und Gl\u00fccks-Fall uns durch schweren Abschied", "tokens": ["Wenn", "Zeit", "und", "Gl\u00fccks\u00b7Fall", "uns", "durch", "schwe\u00b7ren", "Ab\u00b7schied"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Best\u00e4ndigkeit macht uns verpflicht/", "tokens": ["Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "macht", "uns", "ver\u00b7pflicht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "VVFIN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Bey diesem Stande treu zu leben/", "tokens": ["Bey", "die\u00b7sem", "Stan\u00b7de", "treu", "zu", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und keinem fremden Orden nicht/", "tokens": ["Und", "kei\u00b7nem", "frem\u00b7den", "Or\u00b7den", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bi\u00df sieben Jahre sind vorbey/ sich zu ergeben.", "tokens": ["Bi\u00df", "sie\u00b7ben", "Jah\u00b7re", "sind", "vor\u00b7bey", "/", "sich", "zu", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VAFIN", "ADV", "$(", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Auch lehret uns Best\u00e4ndigkeit", "tokens": ["Auch", "leh\u00b7ret", "uns", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey einerley Gedancken bleiben/", "tokens": ["Bey", "ei\u00b7ner\u00b7ley", "Ge\u00b7dan\u00b7cken", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Den Nahmen den wir uns geweyht", "tokens": ["Den", "Nah\u00b7men", "den", "wir", "uns", "ge\u00b7weyht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit Gold und Diamant in Sinn und Hertze schreiben.", "tokens": ["Mit", "Gold", "und", "Di\u00b7a\u00b7mant", "in", "Sinn", "und", "Hert\u00b7ze", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NN", "KON", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Gehorsam ist jedwedes Glied", "tokens": ["Ge\u00b7hor\u00b7sam", "ist", "jed\u00b7we\u00b7des", "Glied"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem Orden schuldig zu erweisen/", "tokens": ["Dem", "Or\u00b7den", "schul\u00b7dig", "zu", "er\u00b7wei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wohin es sein Verordnen zieht/", "tokens": ["Wo\u00b7hin", "es", "sein", "Ver\u00b7ord\u00b7nen", "zieht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bey h\u00f6chster Ungenad und Straffe zu verreisen.", "tokens": ["Bey", "h\u00f6chs\u00b7ter", "Un\u00b7ge\u00b7nad", "und", "Straf\u00b7fe", "zu", "ver\u00b7rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Ein Ku\u00df soll jedem seyn verg\u00fcnnt", "tokens": ["Ein", "Ku\u00df", "soll", "je\u00b7dem", "seyn", "ver\u00b7g\u00fcnnt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PIS", "VAINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beym Wiederkommen und beym Scheiden/", "tokens": ["Beym", "Wie\u00b7der\u00b7kom\u00b7men", "und", "beym", "Schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer straffens-w\u00fcrdig sich befindt/", "tokens": ["Wer", "straf\u00b7fen\u00b7sw\u00fcr\u00b7dig", "sich", "be\u00b7findt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "PRF", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll/ was ihm aufferlegt/ mit allem Willen leiden.", "tokens": ["Soll", "/", "was", "ihm", "auf\u00b7fer\u00b7legt", "/", "mit", "al\u00b7lem", "Wil\u00b7len", "lei\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$(", "PWS", "PPER", "VVPP", "$(", "APPR", "PIS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wer sich mit List gedrungen ein/", "tokens": ["Wer", "sich", "mit", "List", "ge\u00b7drun\u00b7gen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "NN", "VVPP", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer Treu und H\u00f6fligkeit verletzet/", "tokens": ["Wer", "Treu", "und", "H\u00f6f\u00b7lig\u00b7keit", "ver\u00b7let\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer irrt/ und ungestrafft will seyn/", "tokens": ["Wer", "irrt", "/", "und", "un\u00b7ge\u00b7strafft", "will", "seyn", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$(", "KON", "ADJD", "VMFIN", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird durch gemeinen Schlu\u00df aus unsrer Zahl gesetzet.", "tokens": ["Wird", "durch", "ge\u00b7mei\u00b7nen", "Schlu\u00df", "aus", "uns\u00b7rer", "Zahl", "ge\u00b7set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Wer der Gesellschafft sich entreist/", "tokens": ["Wer", "der", "Ge\u00b7sell\u00b7schafft", "sich", "en\u00b7treist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PRF", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und einen andern Stand will fassen/", "tokens": ["Und", "ei\u00b7nen", "an\u00b7dern", "Stand", "will", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Soll von uns werden ausgeweist/", "tokens": ["Soll", "von", "uns", "wer\u00b7den", "aus\u00b7ge\u00b7weist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und seines Wanckelmutts ein Denckmahl hinterlassen.", "tokens": ["Und", "sei\u00b7nes", "Wan\u00b7ckel\u00b7mutts", "ein", "Denck\u00b7mahl", "hin\u00b7ter\u00b7las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}