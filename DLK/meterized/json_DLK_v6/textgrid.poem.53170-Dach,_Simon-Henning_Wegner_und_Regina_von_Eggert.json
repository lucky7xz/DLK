{"textgrid.poem.53170": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "Henning Wegner und Regina von Eggert", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist in der gantzen Welt,", "tokens": ["Was", "ist", "in", "der", "gant\u00b7zen", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Das sich gleich der Liebe h\u00e4lt,", "tokens": ["Das", "sich", "gleich", "der", "Lie\u00b7be", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle Sachen gehen ein,", "tokens": ["Al\u00b7le", "Sa\u00b7chen", "ge\u00b7hen", "ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie besteht Jahr aus Jahr ein.", "tokens": ["Sie", "be\u00b7steht", "Jahr", "aus", "Jahr", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Heut und Gestern hebet man", "tokens": ["Heut", "und", "Ge\u00b7stern", "he\u00b7bet", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "NN", "VVFIN", "PIS"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Erst die newe Jahrs-Zeit an,", "tokens": ["Erst", "die", "ne\u00b7we", "Jahr\u00b7sZeit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Stracks thut Liebe sich hervor", "tokens": ["Stracks", "thut", "Lie\u00b7be", "sich", "her\u00b7vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NN", "PRF", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd schleust auff der Zeit das Thor.", "tokens": ["Vnd", "schleust", "auff", "der", "Zeit", "das", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Eh sonst etwas wird gethan,", "tokens": ["Eh", "sonst", "et\u00b7was", "wird", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Machet sie sich auff die Bahn,", "tokens": ["Ma\u00b7chet", "sie", "sich", "auff", "die", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vnd wil aller Ding' allein", "tokens": ["Vnd", "wil", "al\u00b7ler", "Ding'", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PIAT", "NN", "ADV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Anfang, Haupt und Vorsprung seyn.", "tokens": ["An\u00b7fang", ",", "Haupt", "und", "Vor\u00b7sprung", "seyn", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Vberall wird Ruh gesp\u00fcrt,", "tokens": ["Vbe\u00b7rall", "wird", "Ruh", "ge\u00b7sp\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Nicht ein Hammer wird ger\u00fchrt,", "tokens": ["Nicht", "ein", "Ham\u00b7mer", "wird", "ge\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sag und H\u00f6fel fleucht die Hand", "tokens": ["Sag", "und", "H\u00f6\u00b7fel", "fleucht", "die", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "VVFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd hangt m\u00fcssig an der Wand.", "tokens": ["Vnd", "hangt", "m\u00fcs\u00b7sig", "an", "der", "Wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Auch der Weisen B\u00fccher Flei\u00df", "tokens": ["Auch", "der", "Wei\u00b7sen", "B\u00fc\u00b7cher", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Hat anietzt noch schlechten Prei\u00df,", "tokens": ["Hat", "an\u00b7ietzt", "noch", "schlech\u00b7ten", "Prei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Beydes Raht-Hau\u00df und Gericht", "tokens": ["Bey\u00b7des", "Raht\u00b7Hau\u00df", "und", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Wei\u00df so bald von Arbeit nicht.", "tokens": ["Wei\u00df", "so", "bald", "von", "Ar\u00b7beit", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Aber sie h\u00e4lt in der Lufft", "tokens": ["A\u00b7ber", "sie", "h\u00e4lt", "in", "der", "Lufft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Nicht ohn grossen Zeug und rufft,", "tokens": ["Nicht", "ohn", "gros\u00b7sen", "Zeug", "und", "rufft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df von ihrer Stimme Wald", "tokens": ["Da\u00df", "von", "ih\u00b7rer", "Stim\u00b7me", "Wald"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd Gebirge wiederschallt:", "tokens": ["Vnd", "Ge\u00b7bir\u00b7ge", "wie\u00b7der\u00b7schallt", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Meint ihr, weil ihr m\u00fcssig geht,", "tokens": ["Meint", "ihr", ",", "weil", "ihr", "m\u00fcs\u00b7sig", "geht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df mir frey zu feyren steht?", "tokens": ["Da\u00df", "mir", "frey", "zu", "fey\u00b7ren", "steht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, gleich wie der Sonnen Rad", "tokens": ["Nein", ",", "gleich", "wie", "der", "Son\u00b7nen", "Rad"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "KOKOM", "ART", "NN", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Keinen Blick zur Musse hat,", "tokens": ["Kei\u00b7nen", "Blick", "zur", "Mus\u00b7se", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie der Mond auch immer eilt,", "tokens": ["Wie", "der", "Mond", "auch", "im\u00b7mer", "eilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd Merkur sich nie verweilt,", "tokens": ["Vnd", "Mer\u00b7kur", "sich", "nie", "ver\u00b7weilt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die Str\u00f6m' auff nasser Bahn", "tokens": ["Wie", "die", "Str\u00f6m'", "auff", "nas\u00b7ser", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Stets gehn in den Ocean,", "tokens": ["Stets", "gehn", "in", "den", "O\u00b7cean", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-++-", "measure": "unknown.measure.tri"}}, "stanza.9": {"line.1": {"text": "So mu\u00df ich im gleichen fort", "tokens": ["So", "mu\u00df", "ich", "im", "glei\u00b7chen", "fort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPRART", "ADJA", "PTKVZ"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "Hie und sonst an allem Ort,", "tokens": ["Hie", "und", "sonst", "an", "al\u00b7lem", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "APPR", "PIS", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Vberall werd ich begehrt,", "tokens": ["Vbe\u00b7rall", "werd", "ich", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin aller Sachen Wehrt.", "tokens": ["Ich", "bin", "al\u00b7ler", "Sa\u00b7chen", "Wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Wenn zur s\u00fcssen Ruh sich legt", "tokens": ["Wenn", "zur", "s\u00fcs\u00b7sen", "Ruh", "sich", "legt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "ADJA", "NN", "PRF", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was sich hin und wieder regt,", "tokens": ["Was", "sich", "hin", "und", "wie\u00b7der", "regt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "PTKVZ", "KON", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00fcllet Mensch und Vieh sich ein,", "tokens": ["H\u00fcl\u00b7let", "Mensch", "und", "Vieh", "sich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PRF", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mu\u00df ich immer wache seyn.", "tokens": ["Mu\u00df", "ich", "im\u00b7mer", "wa\u00b7che", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJA", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich bin der Natur Gestalt,", "tokens": ["Ich", "bin", "der", "Na\u00b7tur", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mutter, Leben, Vnterhalt,", "tokens": ["Mut\u00b7ter", ",", "Le\u00b7ben", ",", "Vn\u00b7ter\u00b7halt", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Erde, Lufft und Himmels-Zier", "tokens": ["Er\u00b7de", ",", "Lufft", "und", "Him\u00b7mels\u00b7Zier"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd die See geh\u00f6ret mir.", "tokens": ["Vnd", "die", "See", "ge\u00b7h\u00f6\u00b7ret", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Was? Ich schwere bey der Glut,", "tokens": ["Was", "?", "Ich", "schwe\u00b7re", "bey", "der", "Glut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die auch ausd\u00f6rrt Tieff' und Flut,", "tokens": ["Die", "auch", "aus\u00b7d\u00f6rrt", "Tief\u00b7f'", "und", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVPP", "NN", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Bey dem Hertzen, dessen Brand", "tokens": ["Bey", "dem", "Hert\u00b7zen", ",", "des\u00b7sen", "Brand"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vberall kriegt oberhand,", "tokens": ["Vbe\u00b7rall", "kriegt", "o\u00b7ber\u00b7hand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Da\u00df, im fall ich solt' entstehn,", "tokens": ["Da\u00df", ",", "im", "fall", "ich", "solt'", "ent\u00b7stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPRART", "NN", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles unter-m\u00fc\u00dfte-gehn.", "tokens": ["Al\u00b7les", "un\u00b7ter\u00b7m\u00fc\u00df\u00b7te\u00b7gehn", "."], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die G\u00f6ttinn also schreyt,", "tokens": ["Wie", "die", "G\u00f6t\u00b7tinn", "al\u00b7so", "schreyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird ihr V\u00f6lcklein hoch erfrewt,", "tokens": ["Wird", "ihr", "V\u00f6l\u00b7ck\u00b7lein", "hoch", "er\u00b7frewt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}, "stanza.14": {"line.1": {"text": "Da\u00df sich ihr gern unterstellt", "tokens": ["Da\u00df", "sich", "ihr", "gern", "un\u00b7ter\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "PPER", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd durch sie sich blo\u00df erh\u00e4lt,", "tokens": ["Vnd", "durch", "sie", "sich", "blo\u00df", "er\u00b7h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Was von Schencken \u00fcberall,", "tokens": ["Was", "von", "Schen\u00b7cken", "\u00fc\u00b7be\u00b7rall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jauchtzt mit grossem Frewden-Schall.", "tokens": ["Jauchtzt", "mit", "gros\u00b7sem", "Fre\u00b7wden\u00b7Schall", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Stuben-Rauch und Fewer-Herd,", "tokens": ["Stu\u00b7ben\u00b7Rauch", "und", "Fe\u00b7wer\u00b7Herd", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was sich vor der Hochzeit nehrt,", "tokens": ["Was", "sich", "vor", "der", "Hoch\u00b7zeit", "nehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kinder, M\u00e4gde, Weib und Mann", "tokens": ["Kin\u00b7der", ",", "M\u00e4g\u00b7de", ",", "Weib", "und", "Mann"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Beten Sie die G\u00f6ttinn an.", "tokens": ["Be\u00b7ten", "Sie", "die", "G\u00f6t\u00b7tinn", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "H\u00f6ff' und G\u00e4rten in gemein", "tokens": ["H\u00f6ff'", "und", "G\u00e4r\u00b7ten", "in", "ge\u00b7mein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "NN", "APPR", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "M\u00fcssen stracks gesaubert seyn,", "tokens": ["M\u00fcs\u00b7sen", "stracks", "ge\u00b7sau\u00b7bert", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schilde werden auffgehenckt,", "tokens": ["Schil\u00b7de", "wer\u00b7den", "auff\u00b7ge\u00b7henckt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd die Willkomm au\u00dfgeschwenckt.", "tokens": ["Vnd", "die", "Will\u00b7komm", "au\u00df\u00b7ge\u00b7schwenckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Erato stimmt ietzt wie vor", "tokens": ["E\u00b7ra\u00b7to", "stimmt", "ietzt", "wie", "vor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "KOKOM", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Viol und das Bandor,", "tokens": ["Die", "Vi\u00b7ol", "und", "das", "Ban\u00b7dor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "--+-++-", "measure": "anapaest.init"}, "line.3": {"text": "Auch die andern Instrument,", "tokens": ["Auch", "die", "an\u00b7dern", "Inst\u00b7ru\u00b7ment", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil das grosse Wachs-Liecht brennt.", "tokens": ["Weil", "das", "gros\u00b7se", "Wachs\u00b7Liecht", "brennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Welcher Br\u00e4utgam schwingt die Fahn,", "tokens": ["Wel\u00b7cher", "Br\u00e4ut\u00b7gam", "schwingt", "die", "Fahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd bricht allen erst die Bahn?", "tokens": ["Vnd", "bricht", "al\u00b7len", "erst", "die", "Bahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sch\u00e4rfft erst die Feder mir?", "tokens": ["Wer", "sch\u00e4rfft", "erst", "die", "Fe\u00b7der", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mein Herr Wegner, das seyd ihr.", "tokens": ["Mein", "Herr", "Weg\u00b7ner", ",", "das", "seyd", "ihr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "$,", "PDS", "VAFIN", "PPER", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}}, "stanza.19": {"line.1": {"text": "Wir sind Zeugen allerseit", "tokens": ["Wir", "sind", "Zeu\u00b7gen", "al\u00b7ler\u00b7seit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ewrer langen Trawrigkeit,", "tokens": ["Ew\u00b7rer", "lan\u00b7gen", "Traw\u00b7rig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn wird ewer Witwenstand", "tokens": ["Wenn", "wird", "e\u00b7wer", "Wit\u00b7wen\u00b7stand"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "VAFIN", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Dann in Heyraht umbgewand?", "tokens": ["Dann", "in", "Hey\u00b7raht", "umb\u00b7ge\u00b7wand", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Nun, ihr gebt der Liebe Raht", "tokens": ["Nun", ",", "ihr", "gebt", "der", "Lie\u00b7be", "Raht"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Vnd des Himmels Satzung stat,", "tokens": ["Vnd", "des", "Him\u00b7mels", "Sat\u00b7zung", "stat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Habet euch ein Lieb erkiest,", "tokens": ["Ha\u00b7bet", "euch", "ein", "Lieb", "er\u00b7kiest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So recht ewers gleichen ist.", "tokens": ["So", "recht", "e\u00b7wers", "glei\u00b7chen", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "ADJA", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Ihr seyd beyde gleicher Glut,", "tokens": ["Ihr", "seyd", "bey\u00b7de", "glei\u00b7cher", "Glut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Beyde B\u00fcrgermeisters Blut,", "tokens": ["Bey\u00b7de", "B\u00fcr\u00b7ger\u00b7meis\u00b7ters", "Blut", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Beyde gleich an Zucht und Trew", "tokens": ["Bey\u00b7de", "gleich", "an", "Zucht", "und", "Trew"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd an Tugend mancherley.", "tokens": ["Vnd", "an", "Tu\u00b7gend", "man\u00b7cher\u00b7ley", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "PIAT", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Pallas hat mit milder Hand,", "tokens": ["Pal\u00b7las", "hat", "mit", "mil\u00b7der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Br\u00e4utgam, euch sich zugewand,", "tokens": ["Br\u00e4ut\u00b7gam", ",", "euch", "sich", "zu\u00b7ge\u00b7wand", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "PRF", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Juno ziert die Braut mit Pracht,", "tokens": ["Ju\u00b7no", "ziert", "die", "Braut", "mit", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Venus mit der Sch\u00f6nheit Macht,", "tokens": ["Ve\u00b7nus", "mit", "der", "Sch\u00f6n\u00b7heit", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}}, "stanza.23": {"line.1": {"text": "Cynthia mit keuscher Zucht,", "tokens": ["Cyn\u00b7thia", "mit", "keu\u00b7scher", "Zucht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.2": {"text": "O der sch\u00f6nen Liebe Frucht,", "tokens": ["O", "der", "sch\u00f6\u00b7nen", "Lie\u00b7be", "Frucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die als solcher Tugend Lohn,", "tokens": ["Die", "als", "sol\u00b7cher", "Tu\u00b7gend", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "KOKOM", "PIAT", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seyn wird ewres Hauses Krohn.", "tokens": ["Seyn", "wird", "ew\u00b7res", "Hau\u00b7ses", "Krohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "Auff und s\u00e4umt euch l\u00e4nger nicht,", "tokens": ["Auff", "und", "s\u00e4umt", "euch", "l\u00e4n\u00b7ger", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KON", "VVFIN", "PPER", "ADJD", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Luna wacht mit ihrem Liecht,", "tokens": ["Lu\u00b7na", "wacht", "mit", "ih\u00b7rem", "Liecht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auch des Abend-Sternes Gold", "tokens": ["Auch", "des", "A\u00b7ben\u00b7dS\u00b7ter\u00b7nes", "Gold"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wil, da\u00df ihr euch f\u00f6rtern sollt.", "tokens": ["Wil", ",", "da\u00df", "ihr", "euch", "f\u00f6r\u00b7tern", "sollt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "KOUS", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Wil die Braut es nicht verstehn,", "tokens": ["Wil", "die", "Braut", "es", "nicht", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht gern von dem Tantze gehn,", "tokens": ["Nicht", "gern", "von", "dem", "Tant\u00b7ze", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Br\u00e4utgam, greifft sie ernstlich an,", "tokens": ["Br\u00e4ut\u00b7gam", ",", "greifft", "sie", "ernst\u00b7lich", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vnd seyd in der Zeit ihr Mann.", "tokens": ["Vnd", "seyd", "in", "der", "Zeit", "ihr", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Wendet sie wo Einfalt vor,", "tokens": ["Wen\u00b7det", "sie", "wo", "Ein\u00b7falt", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PWAV", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gebt der Ausflucht nicht ein Ohr,", "tokens": ["Gebt", "der", "Aus\u00b7flucht", "nicht", "ein", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "NN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Keine Wissenschafft ist je", "tokens": ["Kei\u00b7ne", "Wis\u00b7sen\u00b7schafft", "ist", "je"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Leichter ausgelernt als die.", "tokens": ["Leich\u00b7ter", "aus\u00b7ge\u00b7lernt", "als", "die", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "KOKOM", "ART", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}