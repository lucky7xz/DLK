{"textgrid.poem.53983": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Deutsch f\u00fcr Amerikaner", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eingang verboten.", "tokens": ["Ein\u00b7gang", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": " ausgang verboten.", "tokens": ["aus\u00b7gang", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": " durchgang verboten.", "tokens": ["durch\u00b7gang", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": " herr Gep\u00e4cktr\u00e4ger, tun Sie diese Koffer auf die leichte Schulter nehmen?", "tokens": ["herr", "Ge\u00b7p\u00e4ck\u00b7tr\u00e4\u00b7ger", ",", "tun", "Sie", "die\u00b7se", "Kof\u00b7fer", "auf", "die", "leich\u00b7te", "Schul\u00b7ter", "neh\u00b7men", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$,", "VVFIN", "PPER", "PDAT", "NN", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+--+-+-+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.5": {"text": " ich werde mir einen Sonnabend daraus machen, mein Herr.", "tokens": ["ich", "wer\u00b7de", "mir", "ei\u00b7nen", "Sonn\u00b7a\u00b7bend", "da\u00b7raus", "ma\u00b7chen", ",", "mein", "Herr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "PAV", "VVINF", "$,", "PPOSAT", "NN", "$."], "meter": "-+--+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": " ist jene Automobildroschke ledig?", "tokens": ["ist", "je\u00b7ne", "Au\u00b7to\u00b7mo\u00b7bil\u00b7droschke", "le\u00b7dig", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "ADJD", "$."], "meter": "-+-+---+--", "measure": "unknown.measure.tri"}, "line.7": {"text": " warten Sie, wir haben noch einen Golfhauer sowie zwei H\u00fctesch\u00e4chtel.", "tokens": ["war\u00b7ten", "Sie", ",", "wir", "ha\u00b7ben", "noch", "ei\u00b7nen", "Golf\u00b7hau\u00b7er", "so\u00b7wie", "zwei", "H\u00fc\u00b7te\u00b7sch\u00e4ch\u00b7tel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "KON", "CARD", "NN", "$."], "meter": "+-+-+--+-++--+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.8": {"text": " dies hier ist Ihr Getr\u00e4nkegeld, ist es nicht?", "tokens": ["dies", "hier", "ist", "Ihr", "Ge\u00b7tr\u00e4n\u00b7ke\u00b7geld", ",", "ist", "es", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VAFIN", "PPOSAT", "NN", "$,", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.9": {"text": " bez\u00fcglich dessen scheint es mir ein wenig wenig. (Sprich: \u00bbkrieje noch fummssich Fennje!\u00ab)", "tokens": ["be\u00b7z\u00fcg\u00b7lich", "des\u00b7sen", "scheint", "es", "mir", "ein", "we\u00b7nig", "we\u00b7nig", ".", "(", "Sprich", ":", "\u00bb", "krie\u00b7je", "noch", "fumms\u00b7sich", "Fenn\u00b7je", "!", "\u00ab", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADJD", "PDS", "VVFIN", "PPER", "PPER", "ART", "PIAT", "PIS", "$.", "$(", "VVIMP", "$.", "$(", "VVFIN", "ADV", "ADJD", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.10": {"text": " autotreiber! Geh an! Ich ziehe das Christliche Hospiz vor!", "tokens": ["au\u00b7to\u00b7trei\u00b7ber", "!", "Geh", "an", "!", "Ich", "zie\u00b7he", "das", "Christ\u00b7li\u00b7che", "Hos\u00b7piz", "vor", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "NE", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+--+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.11": {"text": " rauchen verboten.", "tokens": ["rau\u00b7chen", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.12": {"text": " parken verboten.", "tokens": ["par\u00b7ken", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.13": {"text": " durchfahrt verboten.", "tokens": ["durch\u00b7fahrt", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Guten Tag, wie f\u00fchlen Sie?", "tokens": ["Gu\u00b7ten", "Tag", ",", "wie", "f\u00fch\u00b7len", "Sie", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": " heute ist ein wahrlich feiner Tag, ist es nicht?", "tokens": ["heu\u00b7te", "ist", "ein", "wahr\u00b7lich", "fei\u00b7ner", "Tag", ",", "ist", "es", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADV", "ADJA", "NN", "$,", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": " sie sehen aus wie Ihre eigne Gro\u00dfmutter, gn\u00e4dige Frau!", "tokens": ["sie", "se\u00b7hen", "aus", "wie", "Ih\u00b7re", "eig\u00b7ne", "Gro\u00df\u00b7mut\u00b7ter", ",", "gn\u00e4\u00b7di\u00b7ge", "Frau", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "KOKOM", "PPOSAT", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+--+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": " darf ich Ihnen meinen lieben Mann vorstellen; nein, dieser hier!", "tokens": ["darf", "ich", "Ih\u00b7nen", "mei\u00b7nen", "lie\u00b7ben", "Mann", "vor\u00b7stel\u00b7len", ";", "nein", ",", "die\u00b7ser", "hier", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "PPOSAT", "ADJA", "NN", "VVINF", "$.", "PTKANT", "$,", "PRELS", "ADV", "$."], "meter": "+-+-+-+-+-+--+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.5": {"text": " ich bin sehr froh, Sie zu sehen; wie geht es Ihrem Herrn Stiefzwilling?", "tokens": ["ich", "bin", "sehr", "froh", ",", "Sie", "zu", "se\u00b7hen", ";", "wie", "geht", "es", "Ih\u00b7rem", "Herrn", "Stief\u00b7zwil\u00b7ling", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$.", "PWAV", "VVFIN", "PPER", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+--+--+-+-++-+", "measure": "iambic.octa.plus.relaxed"}, "line.6": {"text": " werfen Sie das h\u00e4\u00dfliche Kind weg, gn\u00e4dige Frau; ich mache Ihnen ein neues, ein viel sch\u00f6neres.", "tokens": ["wer\u00b7fen", "Sie", "das", "h\u00e4\u00df\u00b7li\u00b7che", "Kind", "weg", ",", "gn\u00e4\u00b7di\u00b7ge", "Frau", ";", "ich", "ma\u00b7che", "Ih\u00b7nen", "ein", "neu\u00b7es", ",", "ein", "viel", "sch\u00f6\u00b7ne\u00b7res", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$,", "ADJA", "NN", "$.", "PPER", "VVFIN", "PPER", "ART", "ADJA", "$,", "ART", "PIAT", "ADJA", "$."], "meter": "+-+-+--++-+-+-+-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.7": {"text": " guten Morgen! (sprich: Mahlzeit!)", "tokens": ["gu\u00b7ten", "Mor\u00b7gen", "!", "(", "sprich", ":", "Mahl\u00b7zeit", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "ADJD", "$.", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": " guten Tag! (sprich: Mahlzeit!)", "tokens": ["gu\u00b7ten", "Tag", "!", "(", "sprich", ":", "Mahl\u00b7zeit", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "ADJD", "$.", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.9": {"text": " guten Abend! (sprich: Mahlzeit!)", "tokens": ["gu\u00b7ten", "A\u00b7bend", "!", "(", "sprich", ":", "Mahl\u00b7zeit", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$.", "$(", "ADJD", "$.", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.10": {"text": " danke, es geht uns gut \u2013 wir leben von der Differenz.", "tokens": ["dan\u00b7ke", ",", "es", "geht", "uns", "gut", "\u2013", "wir", "le\u00b7ben", "von", "der", "Dif\u00b7fe\u00b7renz", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$(", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "+--+-+-+-+-+-+", "measure": "iambic.septa.invert"}}, "stanza.3": {"line.1": {"text": "Dieser Schalter ist geschlossen.", "tokens": ["Die\u00b7ser", "Schal\u00b7ter", "ist", "ge\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": " sie m\u00fcssen sich auf den Hintern anstellen.", "tokens": ["sie", "m\u00fcs\u00b7sen", "sich", "auf", "den", "Hin\u00b7tern", "an\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": " ich erwarte schon seit Jahren eine gr\u00f6\u00dfere Geldsendung.", "tokens": ["ich", "er\u00b7war\u00b7te", "schon", "seit", "Jah\u00b7ren", "ei\u00b7ne", "gr\u00f6\u00b7\u00dfe\u00b7re", "Geld\u00b7sen\u00b7dung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+--+--", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": " wo ist die Schaltung f\u00fcr freie Marken und die Briefschaukel?", "tokens": ["wo", "ist", "die", "Schal\u00b7tung", "f\u00fcr", "frei\u00b7e", "Mar\u00b7ken", "und", "die", "Brief\u00b7schau\u00b7kel", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": " wollen Sie so kindlich sein, hinten meine Marke anzulecken?", "tokens": ["wol\u00b7len", "Sie", "so", "kind\u00b7lich", "sein", ",", "hin\u00b7ten", "mei\u00b7ne", "Mar\u00b7ke", "an\u00b7zu\u00b7le\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "VAINF", "$,", "ADV", "PPOSAT", "NN", "VVIZU", "$."], "meter": "+-+-+--+-+-+-+-+-", "measure": "trochaic.octa.plus.relaxed"}, "line.6": {"text": " in dieser Telefonzelle riecht man nicht gut.", "tokens": ["in", "die\u00b7ser", "Te\u00b7le\u00b7fon\u00b7zel\u00b7le", "riecht", "man", "nicht", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PIS", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": " hallo! Ich w\u00fcnsche eine Nummer zu haben, aber der Telefonfr\u00e4ulein gew\u00e4hrt sie mir nicht.", "tokens": ["hal\u00b7lo", "!", "Ich", "w\u00fcn\u00b7sche", "ei\u00b7ne", "Num\u00b7mer", "zu", "ha\u00b7ben", ",", "a\u00b7ber", "der", "Te\u00b7le\u00b7fonf\u00b7r\u00e4u\u00b7lein", "ge\u00b7w\u00e4hrt", "sie", "mir", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPER", "VVFIN", "ART", "NN", "PTKZU", "VAINF", "$,", "ADV", "ART", "NN", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "+--+-+-+--+-+--+-+-+-+--+", "measure": "iambic.octa.plus.invert"}, "line.8": {"text": " meine N\u00e4m ist Patterson; ich bin keine Deutsch; hier ist mein Pa\u00dfhafen.", "tokens": ["mei\u00b7ne", "N\u00e4m", "ist", "Pat\u00b7ter\u00b7son", ";", "ich", "bin", "kei\u00b7ne", "Deutsch", ";", "hier", "ist", "mein", "Pa\u00df\u00b7ha\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NE", "$.", "PPER", "VAFIN", "PIAT", "NN", "$.", "ADV", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-++-+--++-+", "measure": "trochaic.octa.plus.relaxed"}}, "stanza.4": {"line.1": {"text": "Geben Sie mir einen guten Platz.", "tokens": ["Ge\u00b7ben", "Sie", "mir", "ei\u00b7nen", "gu\u00b7ten", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "ART", "ADJA", "NN", "$."], "meter": "----+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": " wir haben keine guten Pl\u00e4tze; wir haben nur Orchesterfauteuils.", "tokens": ["wir", "ha\u00b7ben", "kei\u00b7ne", "gu\u00b7ten", "Pl\u00e4t\u00b7ze", ";", "wir", "ha\u00b7ben", "nur", "Or\u00b7ches\u00b7ter\u00b7fau\u00b7teu\u00b7ils", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+--+--+--+-+", "measure": "iambic.octa.plus.relaxed"}, "line.3": {"text": " wird Ernst Deutsch diesen Abend spielen?", "tokens": ["wird", "Ernst", "Deutsch", "die\u00b7sen", "A\u00b7bend", "spie\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": " wie Sie sehen, haben wir Festspiele; infolgedaher wird er nicht vorhanden sein.", "tokens": ["wie", "Sie", "se\u00b7hen", ",", "ha\u00b7ben", "wir", "Fest\u00b7spie\u00b7le", ";", "in\u00b7fol\u00b7ge\u00b7da\u00b7her", "wird", "er", "nicht", "vor\u00b7han\u00b7den", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVINF", "$,", "VAFIN", "PPER", "NN", "$.", "ADV", "VAFIN", "PPER", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "+-+-+--++--+-+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.5": {"text": " dies ist ein guter Platz; man h\u00f6rt nicht viel.", "tokens": ["dies", "ist", "ein", "gu\u00b7ter", "Platz", ";", "man", "h\u00f6rt", "nicht", "viel", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "PIS", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": " von wem ist dieses St\u00fcck?", "tokens": ["von", "wem", "ist", "die\u00b7ses", "St\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": " dieses St\u00fcck ist von Brecht.", "tokens": ["die\u00b7ses", "St\u00fcck", "ist", "von", "Brecht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": " von wem ist also dieses St\u00fcck?", "tokens": ["von", "wem", "ist", "al\u00b7so", "die\u00b7ses", "St\u00fcck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "ADV", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": " zeigen Sie mir die blaue Bluse der Romantik.", "tokens": ["zei\u00b7gen", "Sie", "mir", "die", "blau\u00b7e", "Blu\u00b7se", "der", "Ro\u00b7man\u00b7tik", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+----+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Sie sind ein S\u00fc\u00dfherz, mein Liebling, tun Sie so?", "tokens": ["Sie", "sind", "ein", "S\u00fc\u00df\u00b7herz", ",", "mein", "Lieb\u00b7ling", ",", "tun", "Sie", "so", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": " das ist mir zu teuer.", "tokens": ["das", "ist", "mir", "zu", "teu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": " ei, mein Fr\u00e4ulein, k\u00f6nnten Sie sich dazu verstehen, mich durch den Abend zu streifen?", "tokens": ["ei", ",", "mein", "Fr\u00e4u\u00b7lein", ",", "k\u00f6nn\u00b7ten", "Sie", "sich", "da\u00b7zu", "ver\u00b7ste\u00b7hen", ",", "mich", "durch", "den", "A\u00b7bend", "zu", "strei\u00b7fen", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPOSAT", "NN", "$,", "VMFIN", "PPER", "PRF", "PAV", "VVINF", "$,", "PRF", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+----+-+--+-+--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.4": {"text": " in Paris gibt es solche H\u00e4user; sie sind sehr praktisch.", "tokens": ["in", "Pa\u00b7ris", "gibt", "es", "sol\u00b7che", "H\u00e4u\u00b7ser", ";", "sie", "sind", "sehr", "prak\u00b7tisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "PIAT", "NN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": " h\u00e4tten Sie wohl die Gewogenheit, auch die Str\u00fcmpfe abzulegen?", "tokens": ["h\u00e4t\u00b7ten", "Sie", "wohl", "die", "Ge\u00b7wo\u00b7gen\u00b7heit", ",", "auch", "die", "Str\u00fcmp\u00b7fe", "ab\u00b7zu\u00b7le\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "NN", "$,", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "+--+--+--+-+-+-+-", "measure": "dactylic.tri.plus"}, "line.6": {"text": " in Amerika tun wir so etwas nicht.", "tokens": ["in", "A\u00b7me\u00b7ri\u00b7ka", "tun", "wir", "so", "et\u00b7was", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": " dies ist wahrlich teuer; Sie sind ein Vamp.", "tokens": ["dies", "ist", "wahr\u00b7lich", "teu\u00b7er", ";", "Sie", "sind", "ein", "Vamp", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$.", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": " danke, meine Dame, ich habe schon eine Beziehung; sie (er) hat meine g\u00e4nzliche Liebe.", "tokens": ["dan\u00b7ke", ",", "mei\u00b7ne", "Da\u00b7me", ",", "ich", "ha\u00b7be", "schon", "ei\u00b7ne", "Be\u00b7zie\u00b7hung", ";", "sie", "(", "er", ")", "hat", "mei\u00b7ne", "g\u00e4nz\u00b7li\u00b7che", "Lie\u00b7be", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "ADV", "ART", "NN", "$.", "PPER", "$(", "PPER", "$(", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+--+--+--+---+--+--+-", "measure": "trochaic.octa.plus.relaxed"}}}}}