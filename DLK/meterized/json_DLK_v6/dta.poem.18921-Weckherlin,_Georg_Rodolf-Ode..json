{"dta.poem.18921": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Ode.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.99"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Der Menschen wohn ist falsch/ betr\u00fcglich die ver-", "tokens": ["Der", "Men\u00b7schen", "wohn", "ist", "falsch", "/", "be\u00b7tr\u00fcg\u00b7lich", "die", "ver"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VAFIN", "ADJD", "$(", "ADJD", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "j\u00e4hung/", "tokens": ["j\u00e4\u00b7hung", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Als ob des Glicks allmacht/ der ewigkeit versehung/", "tokens": ["Als", "ob", "des", "Glicks", "all\u00b7macht", "/", "der", "e\u00b7wig\u00b7keit", "ver\u00b7se\u00b7hung", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ART", "NN", "ADJD", "$(", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vnd des himmels gesatz (mit zwang der G\u00f6tter", "tokens": ["Vnd", "des", "him\u00b7mels", "ge\u00b7satz", "(", "mit", "zwang", "der", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NE", "$(", "APPR", "VVFIN", "ART", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.5": {"text": "hand", "tokens": ["hand"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Verk\u00fcrtzend) ohn jhr schuld ver\u00e4nderten den stand", "tokens": ["Ver\u00b7k\u00fcrt\u00b7zend", ")", "ohn", "jhr", "schuld", "ver\u00b7\u00e4n\u00b7der\u00b7ten", "den", "stand"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$(", "APPR", "PPER", "ADJD", "VVFIN", "ART", "VVFIN"], "meter": "-+--+--+---+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Der Menschen vnd der Welt. Das werck recht zube-", "tokens": ["Der", "Men\u00b7schen", "vnd", "der", "Welt", ".", "Das", "werck", "recht", "zu\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "ART", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "sehen", "tokens": ["se\u00b7hen"], "token_info": ["word"], "pos": ["VVINF"], "meter": "+-", "measure": "trochaic.single"}, "line.9": {"text": "So mu\u00df der Mensch/ da\u00df er die vrsach selbs/ gestehe\u0304.", "tokens": ["So", "mu\u00df", "der", "Mensch", "/", "da\u00df", "er", "die", "vr\u00b7sach", "selbs", "/", "ge\u00b7steh\u0113", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$(", "KOUS", "PPER", "ART", "NN", "ADV", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Da\u0303 ja ein jeder mensch/ dem gr\u00f6sten K\u00f6nig gleich/", "tokens": ["D\u00e3", "ja", "ein", "je\u00b7der", "mensch", "/", "dem", "gr\u00f6s\u00b7ten", "K\u00f6\u00b7nig", "gleich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "PIAT", "NN", "$(", "ART", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hat der Anmuhtungen vnd der begirden reich", "tokens": ["Hat", "der", "An\u00b7muh\u00b7tun\u00b7gen", "vnd", "der", "be\u00b7gir\u00b7den", "reich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "NN", "KON", "ART", "ADJA", "ADJD"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "(die seine vernunfft stehts solt maistern) zu regieren:", "tokens": ["(", "die", "sei\u00b7ne", "ver\u00b7nunfft", "stehts", "solt", "mais\u00b7tern", ")", "zu", "re\u00b7gie\u00b7ren", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "PPOSAT", "NN", "VVFIN", "VMFIN", "VVINF", "$(", "PTKZU", "VVINF", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vnd Sie/ was farb vnd schein Sie auch in dem", "tokens": ["Vnd", "Sie", "/", "was", "farb", "vnd", "schein", "Sie", "auch", "in", "dem"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "$(", "PWS", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "APPR", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "schilt f\u00fchren/", "tokens": ["schilt", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Zu b\u00fcssen jhren lust (als schmaichler) jhres thails", "tokens": ["Zu", "b\u00fcs\u00b7sen", "jhren", "lust", "(", "als", "schmaich\u00b7ler", ")", "jhres", "thails"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "$(", "KOUS", "ADJA", "$(", "PPOSAT", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Vergessen offt des Reichs vnd jhres F\u00fcrsten hayls.", "tokens": ["Ver\u00b7ges\u00b7sen", "offt", "des", "Reichs", "vnd", "jhres", "F\u00fcrs\u00b7ten", "hayls", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "KON", "PPOSAT", "NN", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.3": {"line.1": {"text": "Da wil des menschen hertz der Sch\u00f6nheit sich er-", "tokens": ["Da", "wil", "des", "men\u00b7schen", "hertz", "der", "Sch\u00f6n\u00b7heit", "sich", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "ART", "NN", "PRF", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "geben;", "tokens": ["ge\u00b7ben", ";"], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Dort ein krau\u00dflechtes haar kan seine seel verweben;", "tokens": ["Dort", "ein", "krau\u00df\u00b7lech\u00b7tes", "haar", "kan", "sei\u00b7ne", "seel", "ver\u00b7we\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hie eines augs anblick/ mehr dan ein scharpfer plitz", "tokens": ["Hie", "ei\u00b7nes", "augs", "an\u00b7blick", "/", "mehr", "dan", "ein", "scharp\u00b7fer", "plitz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NE", "$(", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Dort eine weisse hand beraubet jhn der witz;", "tokens": ["Dort", "ei\u00b7ne", "weis\u00b7se", "hand", "be\u00b7rau\u00b7bet", "jhn", "der", "witz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja/ ein geschm\u00f6ll/ ein wort/ ein seuftz k\u0101 nach gefallen", "tokens": ["Ja", "/", "ein", "ge\u00b7schm\u00f6ll", "/", "ein", "wort", "/", "ein", "seuftz", "k\u0101", "nach", "ge\u00b7fal\u00b7len"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "ART", "ADJD", "$(", "ART", "NN", "$(", "ART", "NN", "VVFIN", "APPR", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Vernunfft Mayestet zu fu\u00df jhm machen fallen.", "tokens": ["Der", "Ver\u00b7nunfft", "Ma\u00b7ye\u00b7stet", "zu", "fu\u00df", "jhm", "ma\u00b7chen", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "PTKZU", "PTKVZ", "PPER", "VVINF", "VVINF", "$."], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Bald hochmuht/ hoffnung/ lust/ frewd/ ehrgeitz/", "tokens": ["Bald", "hoch\u00b7muht", "/", "hoff\u00b7nung", "/", "lust", "/", "frewd", "/", "ehr\u00b7geitz", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "NN", "$(", "VVFIN", "$(", "NN", "$(", "NE", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "schimpff vnd schmach/", "tokens": ["schimpff", "vnd", "schmach", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Bald kleinmuht/ forcht/ neyd/ hassz/ verdru\u00df/ layd/", "tokens": ["Bald", "klein\u00b7muht", "/", "forcht", "/", "neyd", "/", "hassz", "/", "ver\u00b7dru\u00df", "/", "layd", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "VVFIN", "$(", "NN", "$(", "NE", "$(", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "zorn vnd raach", "tokens": ["zorn", "vnd", "raach"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "XY"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Verf\u00fcnstern seinen tag/ als jhres Herrens Mayster/", "tokens": ["Ver\u00b7f\u00fcns\u00b7tern", "sei\u00b7nen", "tag", "/", "als", "jhres", "Her\u00b7rens", "Mays\u00b7ter", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$(", "KOUS", "PPOSAT", "NN", "NE", "$("], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Vnd fewren seine macht/ als vngehewre gayster/", "tokens": ["Vnd", "few\u00b7ren", "sei\u00b7ne", "macht", "/", "als", "vn\u00b7ge\u00b7hew\u00b7re", "gays\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "VVFIN", "$(", "KOUS", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So da\u00df der arme Mensch (torrecht vnd vngerecht)", "tokens": ["So", "da\u00df", "der", "ar\u00b7me", "Mensch", "(", "tor\u00b7recht", "vnd", "vn\u00b7ge\u00b7recht", ")"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "$(", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ein K\u00f6nig von geburt/ wird seiner knechten Knecht.", "tokens": ["Ein", "K\u00f6\u00b7nig", "von", "ge\u00b7burt", "/", "wird", "sei\u00b7ner", "knech\u00b7ten", "Knecht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$(", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Vn\u0303 wie Er auch sein lob vermeinet zuverbl\u00fcmen/", "tokens": ["V\u00f1", "wie", "Er", "auch", "sein", "lob", "ver\u00b7mei\u00b7net", "zu\u00b7ver\u00b7bl\u00fc\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "PPOSAT", "NN", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So hat doch billich Er vollkom\u0303en nichts zur\u00fchmen.", "tokens": ["So", "hat", "doch", "bil\u00b7lich", "Er", "voll\u00b7kom\u0303en", "nichts", "zu\u00b7r\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJD", "PPER", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ein hagel/ ein sturmwind/ ein wogen in dem Meer/", "tokens": ["Ein", "ha\u00b7gel", "/", "ein", "sturm\u00b7wind", "/", "ein", "wo\u00b7gen", "in", "dem", "Meer", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJD", "$(", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Ein schu\u00df/ straich/ stich/ fall/ thier/ so leichtlich als ein", "tokens": ["Ein", "schu\u00df", "/", "straich", "/", "stich", "/", "fall", "/", "thier", "/", "so", "leicht\u00b7lich", "als", "ein"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ADJD", "$(", "ADJD", "$(", "NN", "$(", "NN", "$(", "ADV", "ADJD", "KOKOM", "ART"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "heer/", "tokens": ["heer", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Ja des hofs vberflu\u00df/ der St\u00e4tt vn\u0303 D\u00f6rffer s\u00fcnden", "tokens": ["Ja", "des", "hofs", "vberf\u00b7lu\u00df", "/", "der", "St\u00e4tt", "v\u00f1", "D\u00f6rf\u00b7fer", "s\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "ART", "ADJA", "NN", "$(", "ART", "NN", "NE", "NE", "ADJA"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "(die nach lust wider vns bald einen vortheil finden)", "tokens": ["(", "die", "nach", "lust", "wi\u00b7der", "vns", "bald", "ei\u00b7nen", "vor\u00b7theil", "fin\u00b7den", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "APPR", "VVFIN", "APPR", "PPER", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dem Ackerman die ernd/ dem Kauffma\u0303 all sein gut", "tokens": ["Dem", "A\u00b7cker\u00b7man", "die", "ernd", "/", "dem", "Kauff\u00b7m\u00e3", "all", "sein", "gut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "VVPP", "$(", "ART", "NN", "PIAT", "PPOSAT", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "D\u1ebd Hofma\u0303 seinen pracht/ d\u1ebd Kriegsma\u0303 seinen muht/", "tokens": ["D\u1ebd", "Hof\u00b7m\u00e3", "sei\u00b7nen", "pracht", "/", "d\u1ebd", "Kriegs\u00b7m\u00e3", "sei\u00b7nen", "muht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPOSAT", "NN", "$(", "ADJA", "NN", "PPOSAT", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dem B\u00fcrgern seine ruh/ vnd jedem noch das leben", "tokens": ["Dem", "B\u00fcr\u00b7gern", "sei\u00b7ne", "ruh", "/", "vnd", "je\u00b7dem", "noch", "das", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$(", "KON", "PIS", "ADV", "PDS", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Beraubend/ Sollen vns vnd jedem die lehr geben", "tokens": ["Be\u00b7rau\u00b7bend", "/", "Sol\u00b7len", "vns", "vnd", "je\u00b7dem", "die", "lehr", "ge\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$(", "VMFIN", "PPER", "KON", "PIS", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-++--", "measure": "unknown.measure.hexa"}, "line.12": {"text": "Da\u00df wer von grossem layd/ von sorg/ anfecht\u0169g/ pein", "tokens": ["Da\u00df", "wer", "von", "gros\u00b7sem", "layd", "/", "von", "sorg", "/", "an\u00b7fecht\u0169g", "/", "pein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PWS", "APPR", "ADJA", "NN", "$(", "APPR", "NE", "$(", "VVFIN", "$(", "NE"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Begehret/ wa nicht frey doch etwas lo\u00df zu sein/", "tokens": ["Be\u00b7ge\u00b7hret", "/", "wa", "nicht", "frey", "doch", "et\u00b7was", "lo\u00df", "zu", "sein", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "XY", "PTKNEG", "ADJD", "ADV", "ADV", "ADJD", "PTKZU", "VAINF", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.14": {"text": "Das beste mittel ist/ Sich zu dem kreutz zubiegen/", "tokens": ["Das", "bes\u00b7te", "mit\u00b7tel", "ist", "/", "Sich", "zu", "dem", "kreutz", "zu\u00b7bie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "PRF", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Vnd mit der armut sich verbindend zuvern\u00fcegen.", "tokens": ["Vnd", "mit", "der", "ar\u00b7mut", "sich", "ver\u00b7bin\u00b7dend", "zu\u00b7ver\u00b7n\u00fce\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}