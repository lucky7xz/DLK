{"dta.poem.19718": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Das Prager Lied .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "O allersch\u00f6nstes Jesulein,               ", "tokens": ["O", "al\u00b7ler\u00b7sch\u00f6ns\u00b7tes", "Je\u00b7su\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Pragerisches, lieb und klein,", "tokens": ["Du", "Pra\u00b7ge\u00b7ri\u00b7sches", ",", "lieb", "und", "klein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Klein an Gestalt, gro\u00df in der Macht,", "tokens": ["Klein", "an", "Ge\u00b7stalt", ",", "gro\u00df", "in", "der", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wie in Erfahrnu\u00df schon gebracht.", "tokens": ["Wie", "in", "Er\u00b7fahr\u00b7nu\u00df", "schon", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Du Zierd des ganzen Erdenreich,", "tokens": ["Du", "Zierd", "des", "gan\u00b7zen", "Er\u00b7den\u00b7reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit deiner H\u00fclf nicht von uns weich,", "tokens": ["Mit", "dei\u00b7ner", "H\u00fclf", "nicht", "von", "uns", "weich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "APPR", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Weil du zu uns ankommen bist,", "tokens": ["Weil", "du", "zu", "uns", "an\u00b7kom\u00b7men", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem\u00fcthig sey von uns gegr\u00fc\u00dft.", "tokens": ["De\u00b7m\u00fct\u00b7hig", "sey", "von", "uns", "ge\u00b7gr\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du kommst zu uns aus B\u00f6hmen Land,", "tokens": ["Du", "kommst", "zu", "uns", "aus", "B\u00f6h\u00b7men", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ach, mach dein H\u00fclf auch hier bekannt,", "tokens": ["Ach", ",", "mach", "dein", "H\u00fclf", "auch", "hier", "be\u00b7kannt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir fallen dir zu F\u00fc\u00dfen all,", "tokens": ["Wir", "fal\u00b7len", "dir", "zu", "F\u00fc\u00b7\u00dfen", "all", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "PIAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Gnad uns zeige \u00fcberall.", "tokens": ["Dein", "Gnad", "uns", "zei\u00b7ge", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "O allersch\u00f6nstes Jesulein,", "tokens": ["O", "al\u00b7ler\u00b7sch\u00f6ns\u00b7tes", "Je\u00b7su\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie konnt es denn doch m\u00f6glich sein,", "tokens": ["Wie", "konnt", "es", "denn", "doch", "m\u00f6g\u00b7lich", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df man so wenig dich geacht,", "tokens": ["Da\u00df", "man", "so", "we\u00b7nig", "dich", "ge\u00b7acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "PIS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So lang dich in Vergessung bracht?", "tokens": ["So", "lang", "dich", "in", "Ver\u00b7ges\u00b7sung", "bracht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Sieben Jahr dauerte dein Elend,", "tokens": ["Sie\u00b7ben", "Jahr", "dau\u00b7er\u00b7te", "dein", "E\u00b7lend", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zerbrochen wurden dir deine H\u00e4nd,", "tokens": ["Zer\u00b7bro\u00b7chen", "wur\u00b7den", "dir", "dei\u00b7ne", "H\u00e4nd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Bis endlich deiner Gnaden Strahlen", "tokens": ["Bis", "end\u00b7lich", "dei\u00b7ner", "Gna\u00b7den", "Strah\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Auf einen treuen Diener gefallen.", "tokens": ["Auf", "ei\u00b7nen", "treu\u00b7en", "Die\u00b7ner", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Der ohngef\u00e4hr zu Prag ankam,", "tokens": ["Der", "ohn\u00b7ge\u00b7f\u00e4hr", "zu", "Prag", "an\u00b7kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dein Abwesenheit wahrnahm;", "tokens": ["Und", "dein", "Ab\u00b7we\u00b7sen\u00b7heit", "wahr\u00b7nahm", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Cirillus ware er genannt,", "tokens": ["Ci\u00b7ril\u00b7lus", "wa\u00b7re", "er", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem deine Gnaden schon bekannt.", "tokens": ["Dem", "dei\u00b7ne", "Gna\u00b7den", "schon", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Er suchte dich gleich einem Schaz,", "tokens": ["Er", "such\u00b7te", "dich", "gleich", "ei\u00b7nem", "Schaz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durchgehet alle Ort und Plaz,", "tokens": ["Durch\u00b7ge\u00b7het", "al\u00b7le", "Ort", "und", "Plaz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "KON", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Verworfen durch der Juden List,", "tokens": ["Ver\u00b7wor\u00b7fen", "durch", "der", "Ju\u00b7den", "List", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Findt er dich unter Staub und Mist.", "tokens": ["Findt", "er", "dich", "un\u00b7ter", "Staub", "und", "Mist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Mit Jubel und auch Herzens Freud", "tokens": ["Mit", "Ju\u00b7bel", "und", "auch", "Her\u00b7zens", "Freud"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADV", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er dich erblicket hat mit Freud,", "tokens": ["Er", "dich", "er\u00b7bli\u00b7cket", "hat", "mit", "Freud", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVFIN", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gr\u00fc\u00dfte dich mit Herz und Mund,", "tokens": ["Gr\u00fc\u00df\u00b7te", "dich", "mit", "Herz", "und", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht gnug dich bedauern kund.", "tokens": ["Nicht", "gnug", "dich", "be\u00b7dau\u00b7ern", "kund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Nach M\u00f6glichkeit th\u00e4t er dich ehren,", "tokens": ["Nach", "M\u00f6g\u00b7lich\u00b7keit", "th\u00e4t", "er", "dich", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Er muste auch von dir anh\u00f6ren:", "tokens": ["Er", "mus\u00b7te", "auch", "von", "dir", "an\u00b7h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "\u201egebt mir nur meine H\u00e4ndelein,", "tokens": ["\u201e", "gebt", "mir", "nur", "mei\u00b7ne", "H\u00e4n\u00b7del\u00b7ein", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u201eso geb ich euch den Segen mein.\u201c", "tokens": ["\u201e", "so", "geb", "ich", "euch", "den", "Se\u00b7gen", "mein", ".", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PRF", "ART", "NN", "PPOSAT", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dies mu\u00df die ganze Prager Stadt", "tokens": ["Dies", "mu\u00df", "die", "gan\u00b7ze", "Pra\u00b7ger", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bekennen, dies erfahren hat,", "tokens": ["Be\u00b7ken\u00b7nen", ",", "dies", "er\u00b7fah\u00b7ren", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie du vom Schweden sie erl\u00f6\u00dft,", "tokens": ["Wie", "du", "vom", "Schwe\u00b7den", "sie", "er\u00b7l\u00f6\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NE", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der in ihr feindlich war zuerst.", "tokens": ["Der", "in", "ihr", "feind\u00b7lich", "war", "zu\u00b7erst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "ADJD", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Auch zu der gro\u00dfen Pesten Zeit", "tokens": ["Auch", "zu", "der", "gro\u00b7\u00dfen", "Pes\u00b7ten", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hast du sie von der Pest befreit,", "tokens": ["Hast", "du", "sie", "von", "der", "Pest", "be\u00b7freit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Jesulein streck aus deine Hand,", "tokens": ["O", "Je\u00b7su\u00b7lein", "streck", "aus", "dei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Besch\u00fcz das liebe Vaterland.", "tokens": ["Be\u00b7sch\u00fcz", "das", "lie\u00b7be", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}