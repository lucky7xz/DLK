{"textgrid.poem.40034": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: In H\u00e4usern findet man, zur Winters-Zeit,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In H\u00e4usern findet man, zur Winters-Zeit,", "tokens": ["In", "H\u00e4u\u00b7sern", "fin\u00b7det", "man", ",", "zur", "Win\u00b7ter\u00b7sZeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Solch' eine wunderbar formirte Zierlichkeit,", "tokens": ["Solch'", "ei\u00b7ne", "wun\u00b7der\u00b7bar", "for\u00b7mir\u00b7te", "Zier\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die keiner t\u00fcchtig zu beschreiben,", "tokens": ["Die", "kei\u00b7ner", "t\u00fcch\u00b7tig", "zu", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn die gefrornen Fenster-Scheiben,", "tokens": ["Wenn", "die", "ge\u00b7fror\u00b7nen", "Fens\u00b7ter\u00b7Schei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von tausend zierlich und sch\u00f6nen Creaturen,", "tokens": ["Von", "tau\u00b7send", "zier\u00b7lich", "und", "sch\u00f6\u00b7nen", "Crea\u00b7tu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Uns tausend zierliche Figuren,", "tokens": ["Uns", "tau\u00b7send", "zier\u00b7li\u00b7che", "Fi\u00b7gu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "In solcher zarten Nettigkeit,", "tokens": ["In", "sol\u00b7cher", "zar\u00b7ten", "Net\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "In solcher lieblichen Vollkommenheit,", "tokens": ["In", "sol\u00b7cher", "lieb\u00b7li\u00b7chen", "Voll\u00b7kom\u00b7men\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Die doch in dunckler Nacht gezeugt, fr\u00fch uns zeigen.", "tokens": ["Die", "doch", "in", "dunck\u00b7ler", "Nacht", "ge\u00b7zeugt", ",", "fr\u00fch", "uns", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "VVPP", "$,", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Man siehet in den kalten Zimmern", "tokens": ["Man", "sie\u00b7het", "in", "den", "kal\u00b7ten", "Zim\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Oft Th\u00e4ler, Felsen-Br\u00fcch', erhab'ne Berge, Felder,", "tokens": ["Oft", "Th\u00e4\u00b7ler", ",", "Fel\u00b7sen\u00b7Br\u00fcch'", ",", "er\u00b7hab'\u00b7ne", "Ber\u00b7ge", ",", "Fel\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "$,", "ADJA", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nebst ungez\u00e4hlten krausen Zweigen,", "tokens": ["Nebst", "un\u00b7ge\u00b7z\u00e4hl\u00b7ten", "krau\u00b7sen", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als wenn sie in Krystall geschnitten w\u00e4ren, schimmern.", "tokens": ["Als", "wenn", "sie", "in", "Krys\u00b7tall", "ge\u00b7schnit\u00b7ten", "w\u00e4\u00b7ren", ",", "schim\u00b7mern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "APPR", "NN", "VVPP", "VAFIN", "$,", "VVFIN", "$."], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.5": {"text": "Man siehet Wolcken, Buschwerck, W\u00e4lder,", "tokens": ["Man", "sie\u00b7het", "Wol\u00b7cken", ",", "Busc\u00b7hwerck", ",", "W\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So Tannen bald, Palm- und Eichen,", "tokens": ["So", "Tan\u00b7nen", "bald", ",", "Pal\u00b7m", "und", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "An Baum-Schlag, Zweig- und St\u00e4mmen, gleichen:", "tokens": ["An", "Baum\u00b7Schlag", ",", "Zweig", "und", "St\u00e4m\u00b7men", ",", "glei\u00b7chen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "TRUNC", "KON", "NN", "$,", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Von Bluhmen, Sternchen, V\u00f6geln, Thieren,", "tokens": ["Von", "Bluh\u00b7men", ",", "Stern\u00b7chen", ",", "V\u00f6\u00b7geln", ",", "Thie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Von Feder-B\u00fcschen, Fliegen, M\u00fccken,", "tokens": ["Von", "Fe\u00b7der\u00b7B\u00fc\u00b7schen", ",", "Flie\u00b7gen", ",", "M\u00fc\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sich mancherley Gestalt formiren,", "tokens": ["Sich", "man\u00b7cher\u00b7ley", "Ge\u00b7stalt", "for\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ja sich zuweilen gar mit rechten Schl\u00f6ssern schm\u00fccken.", "tokens": ["Ja", "sich", "zu\u00b7wei\u00b7len", "gar", "mit", "rech\u00b7ten", "Schl\u00f6s\u00b7sern", "schm\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PRF", "ADV", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Schl\u00f6sser aus gefronem Duft,", "tokens": ["Die", "Schl\u00f6s\u00b7ser", "aus", "ge\u00b7fro\u00b7nem", "Duft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So man, im Frost, am Fenster schauet,", "tokens": ["So", "man", ",", "im", "Frost", ",", "am", "Fens\u00b7ter", "schau\u00b7et", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vergleichen sich den Schl\u00f6ssern in der Luft,", "tokens": ["Ver\u00b7glei\u00b7chen", "sich", "den", "Schl\u00f6s\u00b7sern", "in", "der", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die mancher sich des Nachts auf seinem Lager bauet,", "tokens": ["Die", "man\u00b7cher", "sich", "des", "Nachts", "auf", "sei\u00b7nem", "La\u00b7ger", "bau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "PRF", "ART", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die nicht von l\u00e4ng'rer Daur, als eines Traumes Freude.", "tokens": ["Die", "nicht", "von", "l\u00e4ng'\u00b7rer", "Daur", ",", "als", "ei\u00b7nes", "Trau\u00b7mes", "Freu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "APPR", "ADJA", "NN", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Denn eh man sichs versieht, sind beyde schnell dahin,", "tokens": ["Denn", "eh", "man", "sichs", "ver\u00b7sieht", ",", "sind", "bey\u00b7de", "schnell", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PIS", "VVFIN", "$,", "VAFIN", "PIS", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die dort aus dem Gesicht, die hier aus unserm Sinn:", "tokens": ["Die", "dort", "aus", "dem", "Ge\u00b7sicht", ",", "die", "hier", "aus", "un\u00b7serm", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Sonnen Strahl vereitelt alle beyde.", "tokens": ["Der", "Son\u00b7nen", "Strahl", "ver\u00b7ei\u00b7telt", "al\u00b7le", "bey\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PIAT", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ein jedes Scheiben-Glas gleicht einer Schilderey,", "tokens": ["Ein", "je\u00b7des", "Schei\u00b7ben\u00b7Glas", "gleicht", "ei\u00b7ner", "Schil\u00b7de\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In einem glatten Rahm von Bley,", "tokens": ["In", "ei\u00b7nem", "glat\u00b7ten", "Rahm", "von", "Bley", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So eine Winter-Landschaft zeiget:", "tokens": ["So", "ei\u00b7ne", "Win\u00b7ter\u00b7Land\u00b7schaft", "zei\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ein jedes ist so sch\u00f6n, so wunder- sch\u00f6n geschm\u00fcckt,", "tokens": ["Ein", "je\u00b7des", "ist", "so", "sch\u00f6n", ",", "so", "wun\u00b7der", "sch\u00f6n", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "VAFIN", "ADV", "ADJD", "$,", "ADV", "TRUNC", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Bilder so subtil und deutlich ausgedr\u00fcckt,", "tokens": ["Die", "Bil\u00b7der", "so", "sub\u00b7til", "und", "deut\u00b7lich", "aus\u00b7ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df es nicht nur das Aug' ergetzet,", "tokens": ["Da\u00df", "es", "nicht", "nur", "das", "Aug'", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das Hertz selbst in Vergn\u00fcgung setzet,", "tokens": ["Das", "Hertz", "selbst", "in", "Ver\u00b7gn\u00fc\u00b7gung", "set\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So gar, da\u00df, wer es sieht und diese Pracht ermisst,", "tokens": ["So", "gar", ",", "da\u00df", ",", "wer", "es", "sieht", "und", "die\u00b7se", "Pracht", "er\u00b7misst", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "$,", "PWS", "PPER", "VVFIN", "KON", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der strengsten K\u00e4lte selbst dar\u00fcber gantz vergisst.", "tokens": ["Der", "strengs\u00b7ten", "K\u00e4l\u00b7te", "selbst", "da\u00b7r\u00fc\u00b7ber", "gantz", "ver\u00b7gisst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PAV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zumahl wenn an- und durch die klaren Spitzen", "tokens": ["Zu\u00b7mahl", "wenn", "an", "und", "durch", "die", "kla\u00b7ren", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "TRUNC", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Der Morgenr\u00f6the Strahlen blitzen,", "tokens": ["Der", "Mor\u00b7gen\u00b7r\u00f6\u00b7the", "Strah\u00b7len", "blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und an dem weissen Eis' ihr lieblich r\u00f6thlich Licht", "tokens": ["Und", "an", "dem", "weis\u00b7sen", "Eis'", "ihr", "lieb\u00b7lich", "r\u00f6th\u00b7lich", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPOSAT", "ADJD", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Auf tausend Arten sich im Wiederschlagen bricht;", "tokens": ["Auf", "tau\u00b7send", "Ar\u00b7ten", "sich", "im", "Wie\u00b7der\u00b7schla\u00b7gen", "bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So schw\u00fcre man darauf, da es so sch\u00f6n durchstrahlet,", "tokens": ["So", "schw\u00fc\u00b7re", "man", "da\u00b7rauf", ",", "da", "es", "so", "sch\u00f6n", "durch\u00b7strah\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PAV", "$,", "KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Als w\u00e4r ein jeder Strich, als w\u00e4r' ein jedes Bild,", "tokens": ["Als", "w\u00e4r", "ein", "je\u00b7der", "Strich", ",", "als", "w\u00e4r'", "ein", "je\u00b7des", "Bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "PIAT", "NN", "$,", "KOKOM", "VAFIN", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein jegliches Gew\u00e4chs, womit es angef\u00fcllt,", "tokens": ["Ein", "jeg\u00b7li\u00b7ches", "Ge\u00b7w\u00e4chs", ",", "wo\u00b7mit", "es", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mit Diamntnem Staub entwofen und gemahlet.", "tokens": ["Mit", "Di\u00b7amnt\u00b7nem", "Staub", "ent\u00b7wo\u00b7fen", "und", "ge\u00b7mah\u00b7let", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "KON", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.18": {"text": "Allein, indem sie recht im h\u00f6chsten Schimmer prangen,", "tokens": ["Al\u00b7lein", ",", "in\u00b7dem", "sie", "recht", "im", "h\u00f6chs\u00b7ten", "Schim\u00b7mer", "pran\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sind sie vergangen.", "tokens": ["Sind", "sie", "ver\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Seh' ich so manche sch\u00f6n- und zierliche Figur", "tokens": ["Seh'", "ich", "so", "man\u00b7che", "sch\u00f6n", "und", "zier\u00b7li\u00b7che", "Fi\u00b7gur"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In einem Augenblick zerfliessen und verschwinden;", "tokens": ["In", "ei\u00b7nem", "Au\u00b7gen\u00b7blick", "zer\u00b7flies\u00b7sen", "und", "ver\u00b7schwin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So deucht mich, von der sich verwandelnden Natur,", "tokens": ["So", "deucht", "mich", ",", "von", "der", "sich", "ver\u00b7wan\u00b7deln\u00b7den", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "PRELS", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als ihrem Urbild selbst, ein schreckend Bild zu finden.", "tokens": ["Als", "ih\u00b7rem", "Ur\u00b7bild", "selbst", ",", "ein", "schre\u00b7ckend", "Bild", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "$,", "ART", "ADJD", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "In der, hierdurch auch mich bedrohnenden, Gefahr", "tokens": ["In", "der", ",", "hier\u00b7durch", "auch", "mich", "be\u00b7droh\u00b7nen\u00b7den", ",", "Ge\u00b7fahr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "$,", "PAV", "ADV", "PPER", "VVINF", "$,", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ist die\u00df mein Trost: Ich werde doch bestehen.", "tokens": ["Ist", "die\u00df", "mein", "Trost", ":", "Ich", "wer\u00b7de", "doch", "be\u00b7ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "La\u00df alles schwinden und vergehen;", "tokens": ["La\u00df", "al\u00b7les", "schwin\u00b7den", "und", "ver\u00b7ge\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}