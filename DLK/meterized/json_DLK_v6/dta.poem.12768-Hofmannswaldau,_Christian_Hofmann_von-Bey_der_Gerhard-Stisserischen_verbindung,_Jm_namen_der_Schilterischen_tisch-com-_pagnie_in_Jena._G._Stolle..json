{"dta.poem.12768": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Bey der Gerhard-Stisserischen  \n verbindung,  \n  Jm namen der Schilterischen tisch-com-  \n pagnie in Jena.  \n G. Stolle.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1710", "urn": "urn:nbn:de:kobv:b4-20284-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Edler G\u00f6nner! das vergn\u00fcgen", "tokens": ["Ed\u00b7ler", "G\u00f6n\u00b7ner", "!", "das", "ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Reicht dir \u00fcberall die hand.", "tokens": ["Reicht", "dir", "\u00fc\u00b7be\u00b7rall", "die", "hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deine tugend, dein verstand", "tokens": ["Dei\u00b7ne", "tu\u00b7gend", ",", "dein", "ver\u00b7stand"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "K\u00f6nnen nicht verborgen liegen:", "tokens": ["K\u00f6n\u00b7nen", "nicht", "ver\u00b7bor\u00b7gen", "lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jene sieht man sonnen-klar,", "tokens": ["Je\u00b7ne", "sieht", "man", "son\u00b7nen\u00b7klar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wo du nur einmal gewesen;", "tokens": ["Wo", "du", "nur", "ein\u00b7mal", "ge\u00b7we\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Dieser macht sich offenbar,", "tokens": ["Die\u00b7ser", "macht", "sich", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenn wir deine schrifften lesen.", "tokens": ["Wenn", "wir", "dei\u00b7ne", "schriff\u00b7ten", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Solten wir an Bre\u00dflau dencken,", "tokens": ["Sol\u00b7ten", "wir", "an", "Bre\u00df\u00b7lau", "den\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NE", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und auf deine vater-stadt,", "tokens": ["Und", "auf", "dei\u00b7ne", "va\u00b7ter\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die dich n\u00e4chst verlanget hat,", "tokens": ["Die", "dich", "n\u00e4chst", "ver\u00b7lan\u00b7get", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVFIN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Die vergn\u00fcgten augen lencken;", "tokens": ["Die", "ver\u00b7gn\u00fcg\u00b7ten", "au\u00b7gen", "len\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was vor g\u00f6nner w\u00fcrden nicht", "tokens": ["Was", "vor", "g\u00f6n\u00b7ner", "w\u00fcr\u00b7den", "nicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ADJA", "VAFIN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Da von deinen gaben zeugen!", "tokens": ["Da", "von", "dei\u00b7nen", "ga\u00b7ben", "zeu\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "VVFIN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Doch es heist ein n\u00e4her licht", "tokens": ["Doch", "es", "heist", "ein", "n\u00e4\u00b7her", "licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Uns itzt von der ferne schweigen.", "tokens": ["Uns", "itzt", "von", "der", "fer\u00b7ne", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ART", "ADJA", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "W\u00e4re Schurtzfleisch noch am leben,", "tokens": ["W\u00e4\u00b7re", "Schurtz\u00b7fleisch", "noch", "am", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPRART", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schurtzfleisch, Wittenberges zier;", "tokens": ["Schurtz\u00b7fleisch", ",", "Wit\u00b7ten\u00b7ber\u00b7ges", "zier", ";"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$,", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "O! was w\u00fcrde dieser dir", "tokens": ["O", "!", "was", "w\u00fcr\u00b7de", "die\u00b7ser", "dir"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "PWS", "VAFIN", "PDAT", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor ein sch\u00f6nes zeugni\u00df geben!", "tokens": ["Vor", "ein", "sch\u00f6\u00b7nes", "zeug\u00b7ni\u00df", "ge\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Doch wir lassen ihn nun ruhn;", "tokens": ["Doch", "wir", "las\u00b7sen", "ihn", "nun", "ruhn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Was uns dieser nicht kan weisen,", "tokens": ["Was", "uns", "die\u00b7ser", "nicht", "kan", "wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PDS", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Kan der weise R\u00f6schel thun,", "tokens": ["Kan", "der", "wei\u00b7se", "R\u00f6\u00b7schel", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "K\u00f6nnen andre lehrer preisen.", "tokens": ["K\u00f6n\u00b7nen", "and\u00b7re", "leh\u00b7rer", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Leipzig, das die Plei\u00dfe netzet,", "tokens": ["Leip\u00b7zig", ",", "das", "die", "Plei\u00b7\u00dfe", "net\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nebst dem Hypocrenen-flu\u00df:", "tokens": ["Nebst", "dem", "Hy\u00b7po\u00b7cre\u00b7nen\u00b7flu\u00df", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo dich Olearius", "tokens": ["Wo", "dich", "O\u00b7lea\u00b7rius"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "NE"], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.4": {"text": "Durch der Griechen licht ergetzet.", "tokens": ["Durch", "der", "Grie\u00b7chen", "licht", "er\u00b7get\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo dir Titius erkl\u00e4rt,", "tokens": ["Wo", "dir", "Ti\u00b7tius", "er\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NE", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wie das recht recht anzufangen,", "tokens": ["Wie", "das", "recht", "recht", "an\u00b7zu\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ADV", "ADJD", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "L\u00e4st, was Wittenberg gew\u00e4hrt,", "tokens": ["L\u00e4st", ",", "was", "Wit\u00b7ten\u00b7berg", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "NE", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Dich auch da nach wunsch erlangen.", "tokens": ["Dich", "auch", "da", "nach", "wunsch", "er\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "APPR", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was dir nirgends war versaget,", "tokens": ["Was", "dir", "nir\u00b7gends", "war", "ver\u00b7sa\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nahmest du zu Jena an,", "tokens": ["Nah\u00b7mest", "du", "zu", "Je\u00b7na", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wo du auf der weisheits-bahn", "tokens": ["Wo", "du", "auf", "der", "weis\u00b7heits\u00b7bahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich zur ehren-burg gewaget.", "tokens": ["Dich", "zur", "eh\u00b7ren\u00b7burg", "ge\u00b7wa\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Wo du dich so wohl gezeigt:", "tokens": ["Wo", "du", "dich", "so", "wohl", "ge\u00b7zeigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wo dein grund-gelehrtes wissen", "tokens": ["Wo", "dein", "grun\u00b7dge\u00b7lehr\u00b7tes", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "So durch mund und feder steigt,", "tokens": ["So", "durch", "mund", "und", "fe\u00b7der", "steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Da\u00df wir dich bewundern m\u00fcssen.", "tokens": ["Da\u00df", "wir", "dich", "be\u00b7wun\u00b7dern", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier hat Themis ihre sch\u00e4tze", "tokens": ["Hier", "hat", "The\u00b7mis", "ih\u00b7re", "sch\u00e4t\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dir erw\u00fcnscht bekant gemacht.", "tokens": ["Dir", "er\u00b7w\u00fcnscht", "be\u00b7kant", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Drum hat Halle dich bedacht,", "tokens": ["Drum", "hat", "Hal\u00b7le", "dich", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "NE", "PPER", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und zum lehrer der gesetze", "tokens": ["Und", "zum", "leh\u00b7rer", "der", "ge\u00b7set\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Dich vor w\u00fcrdig n\u00e4chst erkannt.", "tokens": ["Dich", "vor", "w\u00fcr\u00b7dig", "n\u00e4chst", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJD", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wie du dich hierbey gewiesen,", "tokens": ["Wie", "du", "dich", "hier\u00b7bey", "ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "PAV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das hat tugend und verstand", "tokens": ["Das", "hat", "tu\u00b7gend", "und", "ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Schon an dir voraus gepriesen.", "tokens": ["Schon", "an", "dir", "vo\u00b7raus", "ge\u00b7prie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Weimar, wo es an patronen", "tokens": ["Wei\u00b7mar", ",", "wo", "es", "an", "pat\u00b7ro\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "PPER", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der gelahrtheit nicht gebricht,", "tokens": ["Der", "ge\u00b7lahr\u00b7theit", "nicht", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unterlie\u00df deswegen nicht,", "tokens": ["Un\u00b7ter\u00b7lie\u00df", "des\u00b7we\u00b7gen", "nicht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PAV", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deine tugend zu belohnen;", "tokens": ["Dei\u00b7ne", "tu\u00b7gend", "zu", "be\u00b7loh\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn sein Hertzog, welcher sich", "tokens": ["Denn", "sein", "Hert\u00b7zog", ",", "wel\u00b7cher", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPOSAT", "NE", "$,", "PRELS", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Gro\u00df erweist an rath und thaten,", "tokens": ["Gro\u00df", "er\u00b7weist", "an", "rath", "und", "tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Macht aus hoher gnade dich", "tokens": ["Macht", "aus", "ho\u00b7her", "gna\u00b7de", "dich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ADJA", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zum Regierungs-advocaten.", "tokens": ["Zum", "Re\u00b7gie\u00b7rungs\u00b7ad\u00b7vo\u00b7ca\u00b7ten", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch es steiget dein vergn\u00fcgen,", "tokens": ["Doch", "es", "stei\u00b7get", "dein", "ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Edler Gerhard! weiter fort.", "tokens": ["Ed\u00b7ler", "Ger\u00b7hard", "!", "wei\u00b7ter", "fort", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "ADV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn es heist ein fremder ort", "tokens": ["Denn", "es", "heist", "ein", "frem\u00b7der", "ort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dich auf sanfften k\u00fcssen liegen.", "tokens": ["Dich", "auf", "sanff\u00b7ten", "k\u00fcs\u00b7sen", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Qvedlinburg l\u00e4st deinen geist", "tokens": ["Qved\u00b7lin\u00b7burg", "l\u00e4st", "dei\u00b7nen", "geist"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Durch die sch\u00f6nste glut erqvicken:", "tokens": ["Durch", "die", "sch\u00f6ns\u00b7te", "glut", "er\u00b7qvi\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn was Dorothea weist,", "tokens": ["Denn", "was", "Do\u00b7ro\u00b7thea", "weist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NE", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Mu\u00df den Ephraim entz\u00fccken.", "tokens": ["Mu\u00df", "den", "Eph\u00b7raim", "ent\u00b7z\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NE", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.9": {"line.1": {"text": "Nun ist nichts mehr, das dir fehlet:", "tokens": ["Nun", "ist", "nichts", "mehr", ",", "das", "dir", "feh\u00b7let", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nun ist dein vergn\u00fcgen gantz;", "tokens": ["Nun", "ist", "dein", "ver\u00b7gn\u00fc\u00b7gen", "gantz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "ADJA", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil du dir den hochzeit-crantz", "tokens": ["Weil", "du", "dir", "den", "hoch\u00b7zeit\u00b7crantz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf den Doctor-hut erwehlet.", "tokens": ["Auf", "den", "Doc\u00b7tor\u00b7hut", "er\u00b7weh\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jener kan, wenn dieser dr\u00fcckt,", "tokens": ["Je\u00b7ner", "kan", ",", "wenn", "die\u00b7ser", "dr\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "VMFIN", "$,", "KOUS", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Alle last ertr\u00e4glich machen:", "tokens": ["Al\u00b7le", "last", "er\u00b7tr\u00e4g\u00b7lich", "ma\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn wen so ein schatz erqvickt,", "tokens": ["Denn", "wen", "so", "ein", "schatz", "er\u00b7qvickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ART", "ADJD", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Der mu\u00df auch bey dornen lachen.", "tokens": ["Der", "mu\u00df", "auch", "bey", "dor\u00b7nen", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "APPR", "ADV", "VVINF", "$."], "meter": "+---+-+-", "measure": "dactylic.init"}}, "stanza.10": {"line.1": {"text": "Edler Freund! so gr\u00fcnt und bl\u00fchet", "tokens": ["Ed\u00b7ler", "Freund", "!", "so", "gr\u00fcnt", "und", "bl\u00fc\u00b7het"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "ADV", "ADJD", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dein vergn\u00fcgen \u00fcberall.", "tokens": ["Dein", "ver\u00b7gn\u00fc\u00b7gen", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch du bleibest an der Saal,", "tokens": ["Doch", "du", "blei\u00b7best", "an", "der", "Saal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Weil dein Schatz nach Jena ziehet.", "tokens": ["Weil", "dein", "Schatz", "nach", "Je\u00b7na", "zie\u00b7het", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Gott, der dieses also f\u00fcgt,", "tokens": ["Gott", ",", "der", "die\u00b7ses", "al\u00b7so", "f\u00fcgt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PDAT", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Geb\u2019 auch ferner sein gedeyen!", "tokens": ["Geb'", "auch", "fer\u00b7ner", "sein", "ge\u00b7de\u00b7yen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "PPOSAT", "VVINF", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.7": {"text": "So ist Dorothee vergn\u00fcgt,", "tokens": ["So", "ist", "Do\u00b7ro\u00b7thee", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "So kan Ephraim sich freuen.", "tokens": ["So", "kan", "Eph\u00b7raim", "sich", "freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}