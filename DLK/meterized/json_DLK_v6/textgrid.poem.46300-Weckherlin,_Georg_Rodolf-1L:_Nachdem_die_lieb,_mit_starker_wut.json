{"textgrid.poem.46300": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "1L: Nachdem die lieb, mit starker wut", "genre": "verse", "period": "N.A.", "pub_year": 1618, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nachdem die lieb, mit starker wut", "tokens": ["Nach\u00b7dem", "die", "lieb", ",", "mit", "star\u00b7ker", "wut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "erheizigend mein junges blut,", "tokens": ["er\u00b7hei\u00b7zi\u00b7gend", "mein", "jun\u00b7ges", "blut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mich mit verw\u00f6hnten pein und plagen", "tokens": ["mich", "mit", "ver\u00b7w\u00f6hn\u00b7ten", "pein", "und", "pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN", "KON", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "hat machen seufzen, weinen, klagen:", "tokens": ["hat", "ma\u00b7chen", "seuf\u00b7zen", ",", "wei\u00b7nen", ",", "kla\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VAFIN", "VVINF", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach! so befind ich, da\u00df ich mu\u00df,", "tokens": ["Ach", "!", "so", "be\u00b7find", "ich", ",", "da\u00df", "ich", "mu\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "weil meine thorheit nu mit bu\u00df", "tokens": ["weil", "mei\u00b7ne", "thor\u00b7heit", "nu", "mit", "bu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "sich endet, da\u00df, was ich begangen", "tokens": ["sich", "en\u00b7det", ",", "da\u00df", ",", "was", "ich", "be\u00b7gan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PRF", "VVFIN", "$,", "KOUS", "$,", "PWS", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "recht zu beklagen, erst anfangen.", "tokens": ["recht", "zu", "be\u00b7kla\u00b7gen", ",", "erst", "an\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Zwar meiner ersten klag ursach", "tokens": ["Zwar", "mei\u00b7ner", "ers\u00b7ten", "klag", "ur\u00b7sach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "war eine sch\u00f6nheit zart und schwach,", "tokens": ["war", "ei\u00b7ne", "sch\u00f6n\u00b7heit", "zart", "und", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auch wunderreich und hoch bedenklich,", "tokens": ["auch", "wun\u00b7der\u00b7reich", "und", "hoch", "be\u00b7denk\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "doch auch, wie alles fleisch, zerg\u00e4nglich:", "tokens": ["doch", "auch", ",", "wie", "al\u00b7les", "fleisch", ",", "zer\u00b7g\u00e4ng\u00b7lich", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "PIS", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hingegen meiner zweiten klag", "tokens": ["Hin\u00b7ge\u00b7gen", "mei\u00b7ner", "zwei\u00b7ten", "klag"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "und lieb quell ist der glanz, der tag,", "tokens": ["und", "lieb", "quell", "ist", "der", "glanz", ",", "der", "tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "das liecht, das leben aller seelen,", "tokens": ["das", "liecht", ",", "das", "le\u00b7ben", "al\u00b7ler", "see\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PDS", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "da\u00df niemand, dem nichts zu verhehlen.", "tokens": ["da\u00df", "nie\u00b7mand", ",", "dem", "nichts", "zu", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.3": {"line.1": {"text": "O meiner seelen sonn, o schein,", "tokens": ["O", "mei\u00b7ner", "see\u00b7len", "sonn", ",", "o", "schein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "NN", "$,", "FM", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "o der du, unbeflecklich rein,", "tokens": ["o", "der", "du", ",", "un\u00b7be\u00b7fleck\u00b7lich", "rein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["FM", "ART", "NE", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "kanst das herz wie das aug regieren,", "tokens": ["kanst", "das", "herz", "wie", "das", "aug", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "KOKOM", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "mit wahrer lehr und reichtum zieren!", "tokens": ["mit", "wah\u00b7rer", "lehr", "und", "reich\u00b7tum", "zie\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Durch deiner sch\u00f6nheit und klarheit", "tokens": ["Durch", "dei\u00b7ner", "sch\u00f6n\u00b7heit", "und", "klar\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "allmacht und ewige wahrheit", "tokens": ["all\u00b7macht", "und", "e\u00b7wi\u00b7ge", "wahr\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "vertreib von meiner seel und augen,", "tokens": ["ver\u00b7treib", "von", "mei\u00b7ner", "seel", "und", "au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "was sie kan zu betriegen taugen.", "tokens": ["was", "sie", "kan", "zu", "be\u00b7trie\u00b7gen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VMFIN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Hab dein gesch\u00f6pf, zwar deiner hand", "tokens": ["Hab", "dein", "ge\u00b7sch\u00f6pf", ",", "zwar", "dei\u00b7ner", "hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "allreichen allmacht wunderpfand,", "tokens": ["all\u00b7rei\u00b7chen", "all\u00b7macht", "wun\u00b7der\u00b7pfand", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ich mensch verblindet und betrogen,", "tokens": ["ich", "mensch", "ver\u00b7blin\u00b7det", "und", "be\u00b7tro\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dir, got und sch\u00f6pfer, f\u00fcrgezogen:", "tokens": ["dir", ",", "got", "und", "sch\u00f6p\u00b7fer", ",", "f\u00fcr\u00b7ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "KON", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So bit ich nu mit wahrer reu,", "tokens": ["So", "bit", "ich", "nu", "mit", "wah\u00b7rer", "reu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "durch deine gnad von blindheit frei,", "tokens": ["durch", "dei\u00b7ne", "gnad", "von", "blind\u00b7heit", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "mir meine thorheit zu verzeihen", "tokens": ["mir", "mei\u00b7ne", "thor\u00b7heit", "zu", "ver\u00b7zei\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und wahre weisheit zu verleihen.", "tokens": ["und", "wah\u00b7re", "weis\u00b7heit", "zu", "ver\u00b7lei\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach herr! durch deiner lieb inbrunst", "tokens": ["Ach", "herr", "!", "durch", "dei\u00b7ner", "lieb", "in\u00b7brunst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ITJ", "$.", "APPR", "PPOSAT", "ADJD", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "vertreib der vorigen lieb dunst,", "tokens": ["ver\u00b7treib", "der", "vo\u00b7ri\u00b7gen", "lieb", "dunst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und mit dir mein herz zu besch\u00f6nen,", "tokens": ["und", "mit", "dir", "mein", "herz", "zu", "be\u00b7sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "----+--+-", "measure": "iambic.di.relaxed"}, "line.4": {"text": "gib da\u00df mit neuer hitz und thr\u00e4nen", "tokens": ["gib", "da\u00df", "mit", "neu\u00b7er", "hitz", "und", "thr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "KOUS", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Ich reinige mein alte brust,", "tokens": ["Ich", "rei\u00b7ni\u00b7ge", "mein", "al\u00b7te", "brust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.6": {"text": "auf da\u00df du m\u00f6gest selbs mit lust", "tokens": ["auf", "da\u00df", "du", "m\u00f6\u00b7gest", "selbs", "mit", "lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "VMFIN", "ADV", "APPR", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "in ihr, mich allzeit zu regieren,", "tokens": ["in", "ihr", ",", "mich", "all\u00b7zeit", "zu", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "hinf\u00fcr gef\u00e4lliglich losieren.", "tokens": ["hin\u00b7f\u00fcr", "ge\u00b7f\u00e4l\u00b7lig\u00b7lich", "lo\u00b7sie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Herr, leite mich mit deiner hand,", "tokens": ["Herr", ",", "lei\u00b7te", "mich", "mit", "dei\u00b7ner", "hand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "erleuchte mich durch deinen brand,", "tokens": ["er\u00b7leuch\u00b7te", "mich", "durch", "dei\u00b7nen", "brand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "da\u00df mich hinf\u00fcr nichts m\u00f6g verirren", "tokens": ["da\u00df", "mich", "hin\u00b7f\u00fcr", "nichts", "m\u00f6g", "ver\u00b7ir\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIS", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "[und ab von deinen wegen f\u00fchren],", "tokens": ["und", "ab", "von", "dei\u00b7nen", "we\u00b7gen", "f\u00fch\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PTKVZ", "APPR", "PPOSAT", "APPR", "VVINF", "$(", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Da\u00df ich allzeit mit deiner huld", "tokens": ["Da\u00df", "ich", "all\u00b7zeit", "mit", "dei\u00b7ner", "huld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "all meine werk, mit keiner schuld", "tokens": ["all", "mei\u00b7ne", "werk", ",", "mit", "kei\u00b7ner", "schuld"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "PPOSAT", "NN", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "dich, allein mein lieb, zu verdrie\u00dfen,", "tokens": ["dich", ",", "al\u00b7lein", "mein", "lieb", ",", "zu", "ver\u00b7drie\u00b7\u00dfen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ADV", "PPOSAT", "ADJD", "$,", "PTKZU", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "m\u00f6g wol anfangen, wol beschlie\u00dfen.", "tokens": ["m\u00f6g", "wol", "an\u00b7fan\u00b7gen", ",", "wol", "be\u00b7schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "VVINF", "$,", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}