{"textgrid.poem.67960": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "28. Lied vom Hofe", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wer sich nimmt an,", "tokens": ["Wer", "sich", "nimmt", "an", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Und 's R\u00e4dlein kan", "tokens": ["Und", "'s", "R\u00e4d\u00b7lein", "kan"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "NN", "VMFIN"], "meter": "-++-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "H\u00fcbsch auf der Bahn", "tokens": ["H\u00fcbsch", "auf", "der", "Bahn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ART", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Lahn umher gahn,", "tokens": ["Lahn", "um\u00b7her", "gahn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Und schmeichlen sch\u00f6n", "tokens": ["Und", "schmeich\u00b7len", "sch\u00f6n"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Findt jedermann", "tokens": ["Findt", "je\u00b7der\u00b7mann"], "token_info": ["word", "word"], "pos": ["VVFIN", "PIS"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Ein Feil und Wahn,", "tokens": ["Ein", "Feil", "und", "Wahn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Ist jezt im Korb der beste Hahn.", "tokens": ["Ist", "jezt", "im", "Korb", "der", "bes\u00b7te", "Hahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "(oder der geht zu Hof jezt oben an.", "tokens": ["(", "o\u00b7der", "der", "geht", "zu", "Hof", "jezt", "o\u00b7ben", "an", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ART", "VVFIN", "APPR", "NN", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Oder der ist zu Hof am besten dran.)", "tokens": ["O\u00b7der", "der", "ist", "zu", "Hof", "am", "bes\u00b7ten", "dran", ".", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PDS", "VAFIN", "APPR", "NN", "PTKA", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Denn wer ged\u00e4cht'", "tokens": ["Denn", "wer", "ge\u00b7d\u00e4cht'"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWS", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Zu leben schlecht,", "tokens": ["Zu", "le\u00b7ben", "schlecht", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Fromm und gerecht", "tokens": ["Fromm", "und", "ge\u00b7recht"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "ADJD"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Die Wahrheit br\u00e4cht';", "tokens": ["Die", "Wahr\u00b7heit", "br\u00e4cht'", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Der wird durch\u00e4cht", "tokens": ["Der", "wird", "durc\u00b7h\u00e4cht"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "VVPP"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Und gar geschw\u00e4cht", "tokens": ["Und", "gar", "ge\u00b7schw\u00e4cht"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADV", "VVPP"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Geh\u00f6nt, geschm\u00e4[ch]t", "tokens": ["Ge\u00b7h\u00f6nt", ",", "ge\u00b7schm\u00e4", "ch", "t"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["VVPP", "$,", "ADJD", "$(", "NE", "$(", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und bleibt allzeit der andern Knecht.", "tokens": ["Und", "bleibt", "all\u00b7zeit", "der", "an\u00b7dern", "Knecht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Beym Schmeichelstab'", "tokens": ["Beym", "Schmei\u00b7chel\u00b7stab'"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Gewinnt mancher Knab'", "tokens": ["Ge\u00b7winnt", "man\u00b7cher", "Knab'"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "PIAT", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Gro\u00df Gut und Haab',", "tokens": ["Gro\u00df", "Gut", "und", "Haab'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "KON", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Geld, Gunst und Gab'", "tokens": ["Geld", ",", "Gunst", "und", "Gab'"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Prei\u00df, Ehr und Lob", "tokens": ["Prei\u00df", ",", "Ehr", "und", "Lob"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "++-+", "measure": "iambic.di"}, "line.6": {"text": "St\u00f6\u00dft andre herab,", "tokens": ["St\u00f6\u00dft", "and\u00b7re", "her\u00b7ab", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Da\u00df Er hoch trab'", "tokens": ["Da\u00df", "Er", "hoch", "trab'"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "So geht die Welt jezt auf und ab.", "tokens": ["So", "geht", "die", "Welt", "jezt", "auf", "und", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer solchs nicht kann", "tokens": ["Wer", "solchs", "nicht", "kann"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PIS", "PTKNEG", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Zu Hofe than;", "tokens": ["Zu", "Ho\u00b7fe", "than", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Thue sich davon,", "tokens": ["Thue", "sich", "da\u00b7von", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PAV", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Ihm wird zu Lohn", "tokens": ["Ihm", "wird", "zu", "Lohn"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Nur Spott und Hohn:", "tokens": ["Nur", "Spott", "und", "Hohn", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Denn Heuchelmann", "tokens": ["Denn", "Heu\u00b7chel\u00b7mann"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Und Sp\u00f6tterzahn", "tokens": ["Und", "Sp\u00f6t\u00b7ter\u00b7zahn"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Ist jezt zu Hof am besten dran.", "tokens": ["Ist", "jezt", "zu", "Hof", "am", "bes\u00b7ten", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}