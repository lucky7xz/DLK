{"textgrid.poem.42492": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das Automobil ist vorgefahren.", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Automobil ist vorgefahren.", "tokens": ["Das", "Au\u00b7to\u00b7mo\u00b7bil", "ist", "vor\u00b7ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und in den geschmacklosen, schrecklichen Schrein", "tokens": ["Und", "in", "den", "ge\u00b7schmack\u00b7lo\u00b7sen", ",", "schreck\u00b7li\u00b7chen", "Schrein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "VVPP", "$,", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Steigen vier junge Komtessen hinein.", "tokens": ["Stei\u00b7gen", "vier", "jun\u00b7ge", "Kom\u00b7tes\u00b7sen", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "ADJA", "NN", "PTKVZ", "$."], "meter": "+--+-----+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Alle vermummt wie beim Femgericht.", "tokens": ["Al\u00b7le", "ver\u00b7mummt", "wie", "beim", "Fem\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KOKOM", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Und gegen Insekten, Staub, Regen und Licht", "tokens": ["Und", "ge\u00b7gen", "In\u00b7sek\u00b7ten", ",", "Staub", ",", "Re\u00b7gen", "und", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+--+-++--+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Tragen sie schwarze Brillen sogar,", "tokens": ["Tra\u00b7gen", "sie", "schwar\u00b7ze", "Bril\u00b7len", "so\u00b7gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "ADV", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Und sind jetzt all ihrer Sch\u00f6nheit bar.", "tokens": ["Und", "sind", "jetzt", "all", "ih\u00b7rer", "Sch\u00f6n\u00b7heit", "bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ach, diese reizenden M\u00e4dchengestalten", "tokens": ["Ach", ",", "die\u00b7se", "rei\u00b7zen\u00b7den", "M\u00e4d\u00b7chen\u00b7ge\u00b7stal\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PDAT", "ADJA", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Sind w\u00fcst verschwunden in Futter und Falten.", "tokens": ["Sind", "w\u00fcst", "ver\u00b7schwun\u00b7den", "in", "Fut\u00b7ter", "und", "Fal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Ins Kloster, ins Kloster, ihr vier Komtessen,", "tokens": ["Ins", "Klos\u00b7ter", ",", "ins", "Klos\u00b7ter", ",", "ihr", "vier", "Kom\u00b7tes\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "PPOSAT", "CARD", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "Lebt wohl, ihr armen Chanoinessen.", "tokens": ["Lebt", "wohl", ",", "ihr", "ar\u00b7men", "Cha\u00b7no\u00b7i\u00b7nes\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}}, "stanza.2": {"line.1": {"text": "Auf der Freitreppe oben, tief im Grame,", "tokens": ["Auf", "der", "Frei\u00b7trep\u00b7pe", "o\u00b7ben", ",", "tief", "im", "Gra\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+-++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Steht eine alte Exzellenzendame.", "tokens": ["Steht", "ei\u00b7ne", "al\u00b7te", "Ex\u00b7zel\u00b7len\u00b7zen\u00b7da\u00b7me", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie ruft indigniert und ruft ganz laut:", "tokens": ["Sie", "ruft", "in\u00b7di\u00b7gniert", "und", "ruft", "ganz", "laut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von all diesem bin ich wenig erbaut!", "tokens": ["Von", "all", "die\u00b7sem", "bin", "ich", "we\u00b7nig", "er\u00b7baut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.5": {"text": "Gr\u00e4\u00dfliches Bild! Mir wird \u00fcbel zumute,", "tokens": ["Gr\u00e4\u00df\u00b7li\u00b7ches", "Bild", "!", "Mir", "wird", "\u00fc\u00b7bel", "zu\u00b7mu\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PPER", "VAFIN", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Und nun noch dazu das infame Getute!", "tokens": ["Und", "nun", "noch", "da\u00b7zu", "das", "in\u00b7fa\u00b7me", "Ge\u00b7tu\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PAV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Pfui, der Geruch! Eau de Cologne her!", "tokens": ["Pfui", ",", "der", "Ge\u00b7ruch", "!", "E\u00b7a\u00b7u", "de", "Co\u00b7log\u00b7ne", "her", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$.", "NE", "NE", "NE", "PTKVZ", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.8": {"text": "Ich rieche Benzin und Geschmier und Schmeer.", "tokens": ["Ich", "rie\u00b7che", "Ben\u00b7zin", "und", "Ge\u00b7schmier", "und", "Schmeer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Vier adliche F\u00fcchse, das war ein Geleit!", "tokens": ["Vier", "ad\u00b7li\u00b7che", "F\u00fcch\u00b7se", ",", "das", "war", "ein", "Ge\u00b7leit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "O Gott, wo blieb meine alte Zeit!", "tokens": ["O", "Gott", ",", "wo", "blieb", "mei\u00b7ne", "al\u00b7te", "Zeit", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PWAV", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Von dannen mit Stank und mit Ungest\u00fcm", "tokens": ["Von", "dan\u00b7nen", "mit", "Stank", "und", "mit", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Saust das fauchende Unget\u00fcm.", "tokens": ["Saust", "das", "fau\u00b7chen\u00b7de", "Un\u00b7ge\u00b7t\u00fcm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Die alte Exzellenz geht verstimmt in den Saal,", "tokens": ["Die", "al\u00b7te", "Ex\u00b7zel\u00b7lenz", "geht", "ver\u00b7stimmt", "in", "den", "Saal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Noch immer scheint ihr \u00bbdas Bild\u00ab fatal.", "tokens": ["Noch", "im\u00b7mer", "scheint", "ihr", "\u00bb", "das", "Bild", "\u00ab", "fa\u00b7tal", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "$(", "ART", "NN", "$(", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Da l\u00e4rmt ihr, kindertoll und verwegen,", "tokens": ["Da", "l\u00e4rmt", "ihr", ",", "kin\u00b7der\u00b7toll", "und", "ver\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das j\u00fcngste, f\u00fcnfj\u00e4hrige Gr\u00e4fchen entgegen,", "tokens": ["Das", "j\u00fcngs\u00b7te", ",", "f\u00fcnf\u00b7j\u00e4h\u00b7ri\u00b7ge", "Gr\u00e4f\u00b7chen", "ent\u00b7ge\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.7": {"text": "Umarmt ihre H\u00fcften, sieht zu ihr empor,", "tokens": ["Um\u00b7armt", "ih\u00b7re", "H\u00fcf\u00b7ten", ",", "sieht", "zu", "ihr", "em\u00b7por", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Mit seinen leuchtenden Augen empor:", "tokens": ["Mit", "sei\u00b7nen", "leuch\u00b7ten\u00b7den", "Au\u00b7gen", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "\u00bbsie fuhren aus, sei doch nicht b\u00f6se,", "tokens": ["\u00bb", "sie", "fuh\u00b7ren", "aus", ",", "sei", "doch", "nicht", "b\u00f6\u00b7se", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PTKVZ", "$,", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ich bin ja noch da.\u00ab Und im Spielget\u00f6se", "tokens": ["Ich", "bin", "ja", "noch", "da", ".", "\u00ab", "Und", "im", "Spiel\u00b7ge\u00b7t\u00f6\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "$.", "$(", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Neigt sie sich, wie zum Frieden bereit,", "tokens": ["Neigt", "sie", "sich", ",", "wie", "zum", "Frie\u00b7den", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PWAV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Und k\u00fc\u00dft ihm die Locken: \u00bbDie ", "tokens": ["Und", "k\u00fc\u00dft", "ihm", "die", "Lo\u00b7cken", ":", "\u00bb", "Die"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$.", "$(", "ART"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}