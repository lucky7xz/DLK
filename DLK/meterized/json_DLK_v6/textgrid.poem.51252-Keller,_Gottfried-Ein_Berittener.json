{"textgrid.poem.51252": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Ein Berittener", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein H\u00e4uptling ritt geehrt im Land", "tokens": ["Ein", "H\u00e4upt\u00b7ling", "ritt", "ge\u00b7ehrt", "im", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVPP", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gleich einem der Propheten;", "tokens": ["Gleich", "ei\u00b7nem", "der", "Pro\u00b7phe\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als er im Feld sich einsam fand,", "tokens": ["Als", "er", "im", "Feld", "sich", "ein\u00b7sam", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hub er den Arm, zu beten:", "tokens": ["Hub", "er", "den", "Arm", ",", "zu", "be\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "\u00bbmich traf das \u00dcbel Schlag auf Schlag,", "tokens": ["\u00bb", "mich", "traf", "das", "\u00dc\u00b7bel", "Schlag", "auf", "Schlag", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es war ein wildes Toben;", "tokens": ["Es", "war", "ein", "wil\u00b7des", "To\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als schuldig ich im Staube lag,", "tokens": ["Als", "schul\u00b7dig", "ich", "im", "Stau\u00b7be", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab ich mich selbst erhoben!", "tokens": ["Hab", "ich", "mich", "selbst", "er\u00b7ho\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Es wu\u00dfte keiner, da\u00df ich lag,", "tokens": ["Es", "wu\u00df\u00b7te", "kei\u00b7ner", ",", "da\u00df", "ich", "lag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als du, o Herr, dort oben!", "tokens": ["Als", "du", ",", "o", "Herr", ",", "dort", "o\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "FM", "NN", "$,", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und f\u00fcr dein Schweigen diesen Tag", "tokens": ["Und", "f\u00fcr", "dein", "Schwei\u00b7gen", "die\u00b7sen", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Will ich dich Stillen loben!\u00ab", "tokens": ["Will", "ich", "dich", "Stil\u00b7len", "lo\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "PRF", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Da hallt 'es durch den \u00c4ther rein:", "tokens": ["Da", "hallt", "'es", "durch", "den", "\u00c4\u00b7ther", "rein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdein Lob, nicht kann's mir taugen;", "tokens": ["\u00bb", "dein", "Lob", ",", "nicht", "kann's", "mir", "tau\u00b7gen", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PTKNEG", "VMFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wenn du dich sch\u00e4mst, ein Mensch zu sein,", "tokens": ["Wenn", "du", "dich", "sch\u00e4mst", ",", "ein", "Mensch", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$,", "ART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So reit mir aus den Augen!\u00ab", "tokens": ["So", "reit", "mir", "aus", "den", "Au\u00b7gen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}