{"textgrid.poem.56303": {"metadata": {"author": {"name": "Chamisso, Adelbert von", "birth": "N.A.", "death": "N.A."}, "title": "4", "genre": "verse", "period": "N.A.", "pub_year": 1809, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und bald sprang auf ein verschlossenes Tor;", "tokens": ["Und", "bald", "sprang", "auf", "ein", "ver\u00b7schlos\u00b7se\u00b7nes", "Tor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Pabst Anselmo trat hervor,", "tokens": ["Der", "Pabst", "An\u00b7sel\u00b7mo", "trat", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ward geweiht in Sankt Petri Dom;", "tokens": ["Und", "ward", "ge\u00b7weiht", "in", "Sankt", "Pe\u00b7tri", "Dom", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "APPR", "VVFIN", "NE", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ihm jauchzte entgegen das heilige Rom.", "tokens": ["Ihm", "jauchz\u00b7te", "ent\u00b7ge\u00b7gen", "das", "hei\u00b7li\u00b7ge", "Rom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "NE", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Darauf von den hohen Stufen herab", "tokens": ["Da\u00b7rauf", "von", "den", "ho\u00b7hen", "Stu\u00b7fen", "her\u00b7ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "APPR", "ART", "ADJA", "NN", "ADV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er urbi et orbi den Segen gab,", "tokens": ["Er", "ur\u00b7bi", "et", "or\u00b7bi", "den", "Se\u00b7gen", "gab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "FM", "FM", "FM", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und sah vor seiner Heiligkeit", "tokens": ["Und", "sah", "vor", "sei\u00b7ner", "Hei\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich beugen die s\u00e4mtliche Christenheit.", "tokens": ["Sich", "beu\u00b7gen", "die", "s\u00e4mt\u00b7li\u00b7che", "Chris\u00b7ten\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Dann eilten herbei von nah und fern", "tokens": ["Dann", "eil\u00b7ten", "her\u00b7bei", "von", "nah", "und", "fern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ADJD", "KON", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Abgesandten der F\u00fcrsten und Herrn,", "tokens": ["Die", "Ab\u00b7ge\u00b7sand\u00b7ten", "der", "F\u00fcrs\u00b7ten", "und", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den Fu\u00df in Demut zu k\u00fcssen bestellt", "tokens": ["Den", "Fu\u00df", "in", "De\u00b7mut", "zu", "k\u00fcs\u00b7sen", "be\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "VVFIN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Dem dreimalgekr\u00f6nten Beherrscher der Welt.", "tokens": ["Dem", "drei\u00b7mal\u00b7ge\u00b7kr\u00f6n\u00b7ten", "Be\u00b7herr\u00b7scher", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.4": {"line.1": {"text": "Drauf sa\u00df er geruhig im Vatikan,", "tokens": ["Drauf", "sa\u00df", "er", "ge\u00b7ru\u00b7hig", "im", "Va\u00b7ti\u00b7kan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der niedern Sorgen abgetan,", "tokens": ["Der", "nie\u00b7dern", "Sor\u00b7gen", "ab\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nicht war an Lust und Freuden karg", "tokens": ["Und", "nicht", "war", "an", "Lust", "und", "Freu\u00b7den", "karg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "VAFIN", "APPR", "NN", "KON", "NN", "VVFIN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Der enge Raum, der ihn verbarg.", "tokens": ["Der", "en\u00b7ge", "Raum", ",", "der", "ihn", "ver\u00b7barg", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der Tisch war gut, die Pf\u00fchle weich,", "tokens": ["Der", "Tisch", "war", "gut", ",", "die", "Pf\u00fch\u00b7le", "weich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der K\u00e4mmerling dem ge\u00fcbtesten gleich;", "tokens": ["Der", "K\u00e4m\u00b7mer\u00b7ling", "dem", "ge\u00b7\u00fcb\u00b7tes\u00b7ten", "gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "ADV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ein Kardinal ging ihm zur Hand,", "tokens": ["Ein", "Kar\u00b7di\u00b7nal", "ging", "ihm", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Lesen und Schreiben trefflich verstand.", "tokens": ["Der", "Le\u00b7sen", "und", "Schrei\u00b7ben", "treff\u00b7lich", "ver\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADJD", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Und was das l\u00e4stige Volk betrifft,", "tokens": ["Und", "was", "das", "l\u00e4s\u00b7ti\u00b7ge", "Volk", "be\u00b7tr\u00b7ifft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das nicht zufrieden noch mit der Schrift,", "tokens": ["Das", "nicht", "zu\u00b7frie\u00b7den", "noch", "mit", "der", "Schrift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Redselig uns oft viel Kummer macht, \u2013", "tokens": ["Red\u00b7se\u00b7lig", "uns", "oft", "viel", "Kum\u00b7mer", "macht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Da hielten die Pf\u00f6rtner schon gute Wacht.", "tokens": ["Da", "hiel\u00b7ten", "die", "Pf\u00f6rt\u00b7ner", "schon", "gu\u00b7te", "Wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADJA", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.7": {"line.1": {"text": "Die Sonne stieg am Morgen auf,", "tokens": ["Die", "Son\u00b7ne", "stieg", "am", "Mor\u00b7gen", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Beschlo\u00df am Abend ihren Lauf,", "tokens": ["Be\u00b7schlo\u00df", "am", "A\u00b7bend", "ih\u00b7ren", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es wurde Tag, es wurde Nacht,", "tokens": ["Es", "wur\u00b7de", "Tag", ",", "es", "wur\u00b7de", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und alles ging, wie hergebracht.", "tokens": ["Und", "al\u00b7les", "ging", ",", "wie", "her\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "PWAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Der Fr\u00fchling kam mild, der Sommer warm,", "tokens": ["Der", "Fr\u00fch\u00b7ling", "kam", "mild", ",", "der", "Som\u00b7mer", "warm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der Herbst kam reich, der Winter arm;", "tokens": ["Der", "Herbst", "kam", "reich", ",", "der", "Win\u00b7ter", "arm", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es wurde Tag, und wurde Nacht,", "tokens": ["Es", "wur\u00b7de", "Tag", ",", "und", "wur\u00b7de", "Nacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "KON", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und alles ging, wie hergebracht.", "tokens": ["Und", "al\u00b7les", "ging", ",", "wie", "her\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "PWAV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Da wiegte der Heilige Vater sein Haupt", "tokens": ["Da", "wieg\u00b7te", "der", "Hei\u00b7li\u00b7ge", "Va\u00b7ter", "sein", "Haupt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Und sprach: \u00bbIch h\u00e4tte nimmer geglaubt,", "tokens": ["Und", "sprach", ":", "\u00bb", "Ich", "h\u00e4t\u00b7te", "nim\u00b7mer", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Bevor ich selber die Macht erreicht,", "tokens": ["Be\u00b7vor", "ich", "sel\u00b7ber", "die", "Macht", "er\u00b7reicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Es sei die Welt zu regieren so leicht.\u00ab", "tokens": ["Es", "sei", "die", "Welt", "zu", "re\u00b7gie\u00b7ren", "so", "leicht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "ADV", "ADJD", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Und wie im Traum ein Bild uns erscheint,", "tokens": ["Und", "wie", "im", "Traum", "ein", "Bild", "uns", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "APPRART", "NN", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Das l\u00e4ngst wir tot und verschollen gemeint,", "tokens": ["Das", "l\u00e4ngst", "wir", "tot", "und", "ver\u00b7schol\u00b7len", "ge\u00b7meint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "KON", "VVINF", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Trat einst ein Vergessener mahnend vor ihn,", "tokens": ["Trat", "einst", "ein", "Ver\u00b7ges\u00b7se\u00b7ner", "mah\u00b7nend", "vor", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "APPR", "PPER", "$,"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der schier ihm unheimlich, gespenstisch erschien:", "tokens": ["Der", "schier", "ihm", "un\u00b7heim\u00b7lich", ",", "ge\u00b7spens\u00b7tisch", "er\u00b7schien", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "ADJD", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-++--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.11": {"line.1": {"text": "\u00bbich bin's, Herr Vetter; erkennt Ihr mich nicht?", "tokens": ["\u00bb", "ich", "bin's", ",", "Herr", "Vet\u00b7ter", ";", "er\u00b7kennt", "Ihr", "mich", "nicht", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "NN", "NE", "$.", "VVFIN", "PPER", "PRF", "PTKNEG", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Es ist Yglano, der mit Euch spricht;", "tokens": ["Es", "ist", "Yg\u00b7la\u00b7no", ",", "der", "mit", "Euch", "spricht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NE", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Ich lie\u00df Euch Zeit, ich hatte Geduld;", "tokens": ["Ich", "lie\u00df", "Euch", "Zeit", ",", "ich", "hat\u00b7te", "Ge\u00b7duld", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "$,", "PPER", "VAFIN", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Nun komm ich einzufodern die Schuld.\u00ab", "tokens": ["Nun", "komm", "ich", "ein\u00b7zu\u00b7fo\u00b7dern", "die", "Schuld", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.12": {"line.1": {"text": "Err\u00f6tend, erblassend in einem Nu,", "tokens": ["Er\u00b7r\u00f6\u00b7tend", ",", "er\u00b7blas\u00b7send", "in", "ei\u00b7nem", "Nu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "APPR", "ART", "ADV", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sprang auf der Pabst und schrie ihm zu:", "tokens": ["Sprang", "auf", "der", "Pabst", "und", "schrie", "ihm", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbhinweg aus meinem Angesicht!", "tokens": ["\u00bb", "hin\u00b7weg", "aus", "mei\u00b7nem", "An\u00b7ge\u00b7sicht", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hinweg! entfleuch! ich kenne dich nicht.\u00ab", "tokens": ["Hin\u00b7weg", "!", "ent\u00b7fleuch", "!", "ich", "ken\u00b7ne", "dich", "nicht", ".", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.13": {"line.1": {"text": "Yglano blieb geruhig, und trat", "tokens": ["Yg\u00b7la\u00b7no", "blieb", "ge\u00b7ru\u00b7hig", ",", "und", "trat"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "ADJD", "$,", "KON", "VVFIN"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zwei Schritte noch vor, dann l\u00e4chelnd tat", "tokens": ["Zwei", "Schrit\u00b7te", "noch", "vor", ",", "dann", "l\u00e4\u00b7chelnd", "tat"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["CARD", "NN", "ADV", "PTKVZ", "$,", "ADV", "ADJD", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er auf den Mund mit leisem Hohn,", "tokens": ["Er", "auf", "den", "Mund", "mit", "lei\u00b7sem", "Hohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und sprach in schaurig fl\u00fcsterndem Ton:", "tokens": ["Und", "sprach", "in", "schau\u00b7rig", "fl\u00fcs\u00b7tern\u00b7dem", "Ton", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.14": {"line.1": {"text": "\u00bbo Dankbarkeit, du s\u00fc\u00dfe Pflicht,", "tokens": ["\u00bb", "o", "Dank\u00b7bar\u00b7keit", ",", "du", "s\u00fc\u00b7\u00dfe", "Pflicht", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du Himmelslust, du Himmelslicht!", "tokens": ["Du", "Him\u00b7mels\u00b7lust", ",", "du", "Him\u00b7mels\u00b7licht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie hat sich dieser dich eingepr\u00e4gt?", "tokens": ["Wie", "hat", "sich", "die\u00b7ser", "dich", "ein\u00b7ge\u00b7pr\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PRF", "PDAT", "PPER", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wie hat er stets dich heilig gehegt?", "tokens": ["Wie", "hat", "er", "stets", "dich", "hei\u00b7lig", "ge\u00b7hegt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "VVFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Ich zog dich, Wurm, aus deinem Staub,", "tokens": ["Ich", "zog", "dich", ",", "Wurm", ",", "aus", "dei\u00b7nem", "Staub", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und m\u00e4stete dich mit der Kirche Raub;", "tokens": ["Und", "m\u00e4s\u00b7te\u00b7te", "dich", "mit", "der", "Kir\u00b7che", "Raub", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Du stiegest und stiegest im schwindelnden Flug", "tokens": ["Du", "stie\u00b7gest", "und", "stie\u00b7gest", "im", "schwin\u00b7deln\u00b7den", "Flug"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Auf meinen Fl\u00fcgeln, nichts galt dir genug.", "tokens": ["Auf", "mei\u00b7nen", "Fl\u00fc\u00b7geln", ",", "nichts", "galt", "dir", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PIS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-++--+", "measure": "iambic.penta.chol"}}, "stanza.16": {"line.1": {"text": "Ich machte, nach deiner gierigen Wahl,", "tokens": ["Ich", "mach\u00b7te", ",", "nach", "dei\u00b7ner", "gie\u00b7ri\u00b7gen", "Wahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zum Bischof dich, zum Kardinal,", "tokens": ["Zum", "Bi\u00b7schof", "dich", ",", "zum", "Kar\u00b7di\u00b7nal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und machte dich gar am Ende zum Pabst, \u2013", "tokens": ["Und", "mach\u00b7te", "dich", "gar", "am", "En\u00b7de", "zum", "Pabst", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "APPRART", "NN", "$,", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wo blieb das Wort, das du mir gabst?\u00ab", "tokens": ["Wo", "blieb", "das", "Wort", ",", "das", "du", "mir", "gabst", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Der Heilige Vater hub an zu schrein:", "tokens": ["Der", "Hei\u00b7li\u00b7ge", "Va\u00b7ter", "hub", "an", "zu", "schrein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00bbwer lie\u00df mir den groben Gesellen herein?", "tokens": ["\u00bb", "wer", "lie\u00df", "mir", "den", "gro\u00b7ben", "Ge\u00b7sel\u00b7len", "her\u00b7ein", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Trabanten und Wachen herbei! wir sind", "tokens": ["Tra\u00b7ban\u00b7ten", "und", "Wa\u00b7chen", "her\u00b7bei", "!", "wir", "sind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "NN", "PTKVZ", "$.", "PPER", "VAFIN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Gef\u00e4hrdet, ergreift den Alten geschwind!\u00ab", "tokens": ["Ge\u00b7f\u00e4hr\u00b7det", ",", "er\u00b7greift", "den", "Al\u00b7ten", "ge\u00b7schwind", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "$,", "VVFIN", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "Da keiner erschien, fuhr Yglano fort:", "tokens": ["Da", "kei\u00b7ner", "er\u00b7schien", ",", "fuhr", "Yg\u00b7la\u00b7no", "fort", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "\u00bberf\u00fclle mir, Pabst, dein gegebenes Wort;", "tokens": ["\u00bb", "er\u00b7f\u00fcl\u00b7le", "mir", ",", "Pabst", ",", "dein", "ge\u00b7ge\u00b7be\u00b7nes", "Wort", ";"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Zum andern, zum dritten, fodr ich dich auf,", "tokens": ["Zum", "an\u00b7dern", ",", "zum", "drit\u00b7ten", ",", "fodr", "ich", "dich", "auf", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "APPRART", "ADJA", "$,", "VVFIN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich, welcher noch lenkt des Geschickes Lauf.\u00ab", "tokens": ["Ich", ",", "wel\u00b7cher", "noch", "lenkt", "des", "Ge\u00b7schi\u00b7ckes", "Lauf", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "VVFIN", "ART", "NN", "NN", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.19": {"line.1": {"text": "Und laut und lauter inzwischen erscholl", "tokens": ["Und", "laut", "und", "lau\u00b7ter", "in\u00b7zwi\u00b7schen", "er\u00b7scholl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Stimme des Pabstes, er schrie wie toll:", "tokens": ["Die", "Stim\u00b7me", "des", "Pabs\u00b7tes", ",", "er", "schrie", "wie", "toll", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PPER", "VVFIN", "KOKOM", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "\u00bbverruchter! Zauberer! Ketzer! dein Lohn,", "tokens": ["\u00bb", "ver\u00b7ruch\u00b7ter", "!", "Zau\u00b7be\u00b7rer", "!", "Ket\u00b7zer", "!", "dein", "Lohn", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$.", "NN", "$.", "NN", "$.", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der Scheiterhaufen erwartet dich schon!\u00ab", "tokens": ["Der", "Schei\u00b7ter\u00b7hau\u00b7fen", "er\u00b7war\u00b7tet", "dich", "schon", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "Yglano darauf: \u00bbHerr Vetter, Ihr wi\u00dft", "tokens": ["Yg\u00b7la\u00b7no", "da\u00b7rauf", ":", "\u00bb", "Herr", "Vet\u00b7ter", ",", "Ihr", "wi\u00dft"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "PAV", "$.", "$(", "NN", "NE", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Aus Erfahrung jetzt, was des Brauches ist:", "tokens": ["Aus", "Er\u00b7fah\u00b7rung", "jetzt", ",", "was", "des", "Brau\u00b7ches", "ist", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "$,", "PRELS", "ART", "NN", "VAFIN", "$."], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Ein jeder f\u00fcr sich; \u2013 was frommte mir nun", "tokens": ["Ein", "je\u00b7der", "f\u00fcr", "sich", ";", "\u2013", "was", "fromm\u00b7te", "mir", "nun"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "PRF", "$.", "$(", "PWS", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Das Allergeringste f\u00fcr Euch zu tun?\u00ab", "tokens": ["Das", "Al\u00b7ler\u00b7ge\u00b7rings\u00b7te", "f\u00fcr", "Euch", "zu", "tun", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "APPR", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.21": {"line.1": {"text": "Dann trat er vor ihn und gab ihm zugleich", "tokens": ["Dann", "trat", "er", "vor", "ihn", "und", "gab", "ihm", "zu\u00b7gleich"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "KON", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit fliegender Hand einen Backenstreich;", "tokens": ["Mit", "flie\u00b7gen\u00b7der", "Hand", "ei\u00b7nen", "Ba\u00b7cken\u00b7streich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Anselmo starrte erwachend empor;", "tokens": ["An\u00b7sel\u00b7mo", "starr\u00b7te", "er\u00b7wa\u00b7chend", "em\u00b7por", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Ihm schallten die letzten Worte im Ohr.", "tokens": ["Ihm", "schall\u00b7ten", "die", "letz\u00b7ten", "Wor\u00b7te", "im", "Ohr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "Er sah sich um; im B\u00fcchersaal", "tokens": ["Er", "sah", "sich", "um", ";", "im", "B\u00fc\u00b7cher\u00b7saal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$.", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Yglanos stand er, wie dazumal;", "tokens": ["Yg\u00b7la\u00b7nos", "stand", "er", ",", "wie", "da\u00b7zu\u00b7mal", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "$,", "PWAV", "ADV", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Zerlumpt, das Stundenglas in der Hand,", "tokens": ["Zer\u00b7lumpt", ",", "das", "Stun\u00b7den\u00b7glas", "in", "der", "Hand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und unvermindert rann der Sand.", "tokens": ["Und", "un\u00b7ver\u00b7min\u00b7dert", "rann", "der", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Dort stand Frau Martha und schenkte den Wein", "tokens": ["Dort", "stand", "Frau", "Mar\u00b7tha", "und", "schenk\u00b7te", "den", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "NE", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit erhobener Hand in den Humpen ein,", "tokens": ["Mit", "er\u00b7ho\u00b7be\u00b7ner", "Hand", "in", "den", "Hum\u00b7pen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Und wie er gef\u00fcllt bis zum Rande war,", "tokens": ["Und", "wie", "er", "ge\u00b7f\u00fcllt", "bis", "zum", "Ran\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVPP", "APPR", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "So reichte sie ihn dem Hausherrn dar.", "tokens": ["So", "reich\u00b7te", "sie", "ihn", "dem", "Haus\u00b7herrn", "dar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Yglano nahm den Humpen und trank,", "tokens": ["Yg\u00b7la\u00b7no", "nahm", "den", "Hum\u00b7pen", "und", "trank", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "KON", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Und setzte ihn weg, und sagte: \u00bbSch\u00f6n Dank!\u00ab", "tokens": ["Und", "setz\u00b7te", "ihn", "weg", ",", "und", "sag\u00b7te", ":", "\u00bb", "Sch\u00f6n", "Dank", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "$.", "$(", "NE", "NN", "$.", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Erbat sich sodann das Stundenglas,", "tokens": ["Er\u00b7bat", "sich", "so\u00b7dann", "das", "Stun\u00b7den\u00b7glas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und stellte es hin zu dem Tintenfa\u00df.", "tokens": ["Und", "stell\u00b7te", "es", "hin", "zu", "dem", "Tin\u00b7ten\u00b7fa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.25": {"line.1": {"text": "Und sprach: \u00bbWir haben uns bedacht,", "tokens": ["Und", "sprach", ":", "\u00bb", "Wir", "ha\u00b7ben", "uns", "be\u00b7dacht", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Frau Martha; ein einziges Huhn zu Nacht. \u2013", "tokens": ["Frau", "Mar\u00b7tha", ";", "ein", "ein\u00b7zi\u00b7ges", "Huhn", "zu", "Nacht", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NE", "$.", "ART", "ADJA", "NN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es tut, Herr Vetter, mir herzlich leid", "tokens": ["Es", "tut", ",", "Herr", "Vet\u00b7ter", ",", "mir", "herz\u00b7lich", "leid"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "NN", "NE", "$,", "PPER", "ADJD", "ADJD"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Da\u00df Ihr zu fasten gesonnen seid.", "tokens": ["Da\u00df", "Ihr", "zu", "fas\u00b7ten", "ge\u00b7son\u00b7nen", "seid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKZU", "VVINF", "VVPP", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.26": {"line.1": {"text": "So lebt denn wohl! \u2013 Frau Martha, das Licht,", "tokens": ["So", "lebt", "denn", "wohl", "!", "\u2013", "Frau", "Mar\u00b7tha", ",", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "$.", "$(", "NN", "NE", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Da\u00df nicht der Vetter den Hals noch bricht;", "tokens": ["Da\u00df", "nicht", "der", "Vet\u00b7ter", "den", "Hals", "noch", "bricht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ART", "NN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihr leuchtet ihm h\u00fcbsch die Treppe hinab,", "tokens": ["Ihr", "leuch\u00b7tet", "ihm", "h\u00fcbsch", "die", "Trep\u00b7pe", "hin\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und schlie\u00dft die Haust\u00fcr hinter ihm ab.\u00ab", "tokens": ["Und", "schlie\u00dft", "die", "Haus\u00b7t\u00fcr", "hin\u00b7ter", "ihm", "ab", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}}}}