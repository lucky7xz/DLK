{"dta.poem.20929": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Lettice von Hort an Ti-  \n balden.", "genre": "Lyrik; Prosa; Drama", "period": "N.A.", "pub_year": "1679", "urn": "urn:nbn:de:kobv:b4-20289-1", "language": ["de:0.99"], "booktitle": "Hofmann von Hofmannswaldau, Christian: Deutsche Ubersetzungen und Gedichte. Breslau, 1679."}, "poem": {"stanza.1": {"line.1": {"text": "Dj\u00df was der Himmel noch gedenckt aus mir zu-", "tokens": ["Dj\u00df", "was", "der", "Him\u00b7mel", "noch", "ge\u00b7denckt", "aus", "mir", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PRELS", "ART", "NN", "ADV", "VVPP", "APPR", "PPER", "TRUNC"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.2": {"text": "machen/", "tokens": ["ma\u00b7chen", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Und wa\u00df mein Hertzog ietzt in seinem Schilde", "tokens": ["Und", "wa\u00df", "mein", "Hert\u00b7zog", "ietzt", "in", "sei\u00b7nem", "Schil\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "f\u00fchrt/", "tokens": ["f\u00fchrt", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Ist allzuhoch vor mich/ es seyn mir frembde Sachen/", "tokens": ["Ist", "all\u00b7zu\u00b7hoch", "vor", "mich", "/", "es", "seyn", "mir", "fremb\u00b7de", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "$(", "PPER", "VAFIN", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich habe noch allhier den Zweck nicht recht gesp\u00fchrt.", "tokens": ["Ich", "ha\u00b7be", "noch", "all\u00b7hier", "den", "Zweck", "nicht", "recht", "ge\u00b7sp\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich mu\u00df gestorben seyn/ doch darf ich nicht verwesen/", "tokens": ["Ich", "mu\u00df", "ge\u00b7stor\u00b7ben", "seyn", "/", "doch", "darf", "ich", "nicht", "ver\u00b7we\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVPP", "VAINF", "$(", "ADV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich lerne wie mich hat der gantze Hoff beklagt/", "tokens": ["Ich", "ler\u00b7ne", "wie", "mich", "hat", "der", "gant\u00b7ze", "Hoff", "be\u00b7klagt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich kan ietzt den Bericht von meinem Tode lesen/", "tokens": ["Ich", "kan", "ietzt", "den", "Be\u00b7richt", "von", "mei\u00b7nem", "To\u00b7de", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und h\u00f6ren was wir hat die Grabschrifft nachgesagt.", "tokens": ["Und", "h\u00f6\u00b7ren", "was", "wir", "hat", "die", "Grab\u00b7schrifft", "nach\u00b7ge\u00b7sagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "PWS", "PPER", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dort l\u00e4utet man mir aus/ hier soll ich Briese schreiben/", "tokens": ["Dort", "l\u00e4u\u00b7tet", "man", "mir", "aus", "/", "hier", "soll", "ich", "Brie\u00b7se", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "PTKVZ", "$(", "ADV", "VMFIN", "PPER", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Todten Messe geht mich noch zur Zeit nicht an/", "tokens": ["Die", "Tod\u00b7ten", "Mes\u00b7se", "geht", "mich", "noch", "zur", "Zeit", "nicht", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich kan noch unverblast bey andern Menschen bleiben/", "tokens": ["Ich", "kan", "noch", "un\u00b7ver\u00b7blast", "bey", "an\u00b7dern", "Men\u00b7schen", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die F\u00e4ulnis hat mir noch kein grosses Leid gethan.", "tokens": ["Die", "F\u00e4ul\u00b7nis", "hat", "mir", "noch", "kein", "gros\u00b7ses", "Leid", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wird aber dieses Spiel zuletzt uns auch gelingen?", "tokens": ["Wird", "a\u00b7ber", "die\u00b7ses", "Spiel", "zu\u00b7letzt", "uns", "auch", "ge\u00b7lin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PDAT", "NN", "ADV", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ein Mensch der gl\u00e4ubet oft was er nicht tadeln darf/", "tokens": ["Ein", "Mensch", "der", "gl\u00e4u\u00b7bet", "oft", "was", "er", "nicht", "ta\u00b7deln", "darf", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "ADV", "PWS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wir k\u00f6nnen wohl den Mund/ doch nicht die Hertzen", "tokens": ["Wir", "k\u00f6n\u00b7nen", "wohl", "den", "Mund", "/", "doch", "nicht", "die", "Hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "$(", "ADV", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "zwingen/", "tokens": ["zwin\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Und die verschmitzte Welt schaut itzund allzuscharf:", "tokens": ["Und", "die", "ver\u00b7schmitz\u00b7te", "Welt", "schaut", "it\u00b7zund", "all\u00b7zu\u00b7scharf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Der Hof/ so mich vielleicht zum Scheine will beklagen/", "tokens": ["Der", "Hof", "/", "so", "mich", "viel\u00b7leicht", "zum", "Schei\u00b7ne", "will", "be\u00b7kla\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ADV", "PPER", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und der so meinen Tod dem Volcke kund gethan/", "tokens": ["Und", "der", "so", "mei\u00b7nen", "Tod", "dem", "Vol\u00b7cke", "kund", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "PPOSAT", "NN", "ART", "NN", "PTKVZ", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Spricht etwan bey sich selbst/ was hat man hingetra-", "tokens": ["Spricht", "et\u00b7wan", "bey", "sich", "selbst", "/", "was", "hat", "man", "hin\u00b7ge\u00b7tra"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PRF", "ADV", "$(", "PWS", "VAFIN", "PIS", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "gen/", "tokens": ["gen", "/"], "token_info": ["word", "punct"], "pos": ["APPR", "$("], "meter": "-", "measure": "single.down"}, "line.24": {"text": "Di\u00df/ was der Hertzog liebt und nicht verlassen kan.", "tokens": ["Di\u00df", "/", "was", "der", "Hert\u00b7zog", "liebt", "und", "nicht", "ver\u00b7las\u00b7sen", "kan", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$(", "PWS", "ART", "NE", "VVFIN", "KON", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und die Gemahlin selbst/ so meinen Todt beweinet/", "tokens": ["Und", "die", "Ge\u00b7mah\u00b7lin", "selbst", "/", "so", "mei\u00b7nen", "Todt", "be\u00b7wei\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "$(", "ADV", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Die weint wohl/ da\u00df sie mich nicht recht vor Leiche h\u00e4lt/", "tokens": ["Die", "weint", "wohl", "/", "da\u00df", "sie", "mich", "nicht", "recht", "vor", "Lei\u00b7che", "h\u00e4lt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "$(", "KOUS", "PPER", "PRF", "PTKNEG", "ADJD", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wer alles was er sieht/ gantz wahr zuseyn vermeinet/", "tokens": ["Wer", "al\u00b7les", "was", "er", "sieht", "/", "gantz", "wahr", "zu\u00b7seyn", "ver\u00b7mei\u00b7net", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PWS", "PPER", "VVFIN", "$(", "ADV", "ADJD", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Erkennet noch nicht recht die Farben dieser Welt.", "tokens": ["Er\u00b7ken\u00b7net", "noch", "nicht", "recht", "die", "Far\u00b7ben", "die\u00b7ser", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADJD", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wir dencken manchesmahl den Nechsten zuber\u00fccken/", "tokens": ["Wir", "den\u00b7cken", "man\u00b7ches\u00b7mahl", "den", "Nechs\u00b7ten", "zu\u00b7be\u00b7r\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Und er/ ja wir durch ihn ber\u00fccken uns zugleich/", "tokens": ["Und", "er", "/", "ja", "wir", "durch", "ihn", "be\u00b7r\u00fc\u00b7cken", "uns", "zu\u00b7gleich", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PTKANT", "PPER", "APPR", "PPER", "VVFIN", "PPER", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Granaten seyn voll Kern\u2019/ und Menschen voller T\u00fc-", "tokens": ["Gra\u00b7na\u00b7ten", "seyn", "voll", "Kern'", "/", "und", "Men\u00b7schen", "vol\u00b7ler", "T\u00fc"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "ADJD", "NN", "$(", "KON", "NN", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "cken/", "tokens": ["cken", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "-", "measure": "single.down"}, "line.33": {"text": "An Wercken bettelarm/ und an Gedancken reich.", "tokens": ["An", "Wer\u00b7cken", "bet\u00b7tel\u00b7arm", "/", "und", "an", "Ge\u00b7dan\u00b7cken", "reich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$(", "KON", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Du meinst/ der F\u00fcrhang sey vern\u00fcnfftig f\u00fcrgezogen/", "tokens": ["Du", "meinst", "/", "der", "F\u00fcr\u00b7hang", "sey", "ver\u00b7n\u00fcnff\u00b7tig", "f\u00fcr\u00b7ge\u00b7zo\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "ART", "NN", "VAFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Und dieses/ was du spielst/ verst\u00fcnde keiner nicht/", "tokens": ["Und", "die\u00b7ses", "/", "was", "du", "spielst", "/", "ver\u00b7st\u00fcn\u00b7de", "kei\u00b7ner", "nicht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "$(", "PWS", "PPER", "VVFIN", "$(", "VVFIN", "PIS", "PTKNEG", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Ach dieser Spiel Platz hat den Spieler oft betrogen/", "tokens": ["Ach", "die\u00b7ser", "Spiel", "Platz", "hat", "den", "Spie\u00b7ler", "oft", "be\u00b7tro\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PDAT", "NN", "NN", "VAFIN", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Und unser Heimligkeit gestellet an das Licht.", "tokens": ["Und", "un\u00b7ser", "Heim\u00b7lig\u00b7keit", "ge\u00b7stel\u00b7let", "an", "das", "Licht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVPP", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Gesetzt mich hielte nun der Schatten gantz umgeben/", "tokens": ["Ge\u00b7setzt", "mich", "hiel\u00b7te", "nun", "der", "Schat\u00b7ten", "gantz", "um\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "PPER", "VVFIN", "ADV", "ART", "NN", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Es glaubte Nord und West ich leg\u2019 in einer Gruft/", "tokens": ["Es", "glaub\u00b7te", "Nord", "und", "West", "ich", "leg'", "in", "ei\u00b7ner", "Gruft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "VVFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Es hiesse mich die Zeit ohn alle Sorgen schweben/", "tokens": ["Es", "hies\u00b7se", "mich", "die", "Zeit", "ohn", "al\u00b7le", "Sor\u00b7gen", "schwe\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Wir hetten alles di\u00df was unser Seele ruft.", "tokens": ["Wir", "het\u00b7ten", "al\u00b7les", "di\u00df", "was", "un\u00b7ser", "See\u00b7le", "ruft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PDS", "PRELS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Wie lange wird uns wohl die dicke Wolcke wehren?", "tokens": ["Wie", "lan\u00b7ge", "wird", "uns", "wohl", "die", "di\u00b7cke", "Wol\u00b7cke", "weh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Wie lange wird uns wohl umh\u00fcllen diese Nacht?", "tokens": ["Wie", "lan\u00b7ge", "wird", "uns", "wohl", "um\u00b7h\u00fcl\u00b7len", "die\u00b7se", "Nacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Die Brunst wird endlich selbst bekand zuseyn begehren/", "tokens": ["Die", "Brunst", "wird", "end\u00b7lich", "selbst", "be\u00b7kand", "zu\u00b7seyn", "be\u00b7geh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Die nach Gewohnheit sich zu einer Glocke macht.", "tokens": ["Die", "nach", "Ge\u00b7wohn\u00b7heit", "sich", "zu", "ei\u00b7ner", "Glo\u00b7cke", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Du weist es/ Lieb und Gluth l\u00e4st selten sich verdecken/", "tokens": ["Du", "weist", "es", "/", "Lieb", "und", "Gluth", "l\u00e4st", "sel\u00b7ten", "sich", "ver\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$(", "NN", "KON", "NN", "VVFIN", "ADJD", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Es ist ihr heisser Grund von gleicher Eigenschafft/", "tokens": ["Es", "ist", "ihr", "heis\u00b7ser", "Grund", "von", "glei\u00b7cher", "Ei\u00b7gen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Sie findet Raum und Luft an allen End und Ecken/", "tokens": ["Sie", "fin\u00b7det", "Raum", "und", "Luft", "an", "al\u00b7len", "End", "und", "E\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Und suchet durch den Zwang offt ihre beste Krafft.", "tokens": ["Und", "su\u00b7chet", "durch", "den", "Zwang", "offt", "ih\u00b7re", "bes\u00b7te", "Krafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Beym F\u00fcrhang unsrer Brunst irrt vielmahl Hand", "tokens": ["Beym", "F\u00fcr\u00b7hang", "uns\u00b7rer", "Brunst", "irrt", "viel\u00b7mahl", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "VVFIN", "ADV", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.51": {"text": "und Hertze/", "tokens": ["und", "Hert\u00b7ze", "/"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.52": {"text": "Inwillens f\u00fcrzuziehn/ so ziehn wir alles auf/", "tokens": ["In\u00b7wil\u00b7lens", "f\u00fcr\u00b7zu\u00b7ziehn", "/", "so", "ziehn", "wir", "al\u00b7les", "auf", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "$(", "ADV", "VVFIN", "PPER", "PIS", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Wir fassen vor den Stab oft eine helle Kertze/", "tokens": ["Wir", "fas\u00b7sen", "vor", "den", "Stab", "oft", "ei\u00b7ne", "hel\u00b7le", "Kert\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Und unsre T\u00e4mmung macht oft einen Wasser Lauf.", "tokens": ["Und", "uns\u00b7re", "T\u00e4m\u00b7mung", "macht", "oft", "ei\u00b7nen", "Was\u00b7ser", "Lauf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Anstatt verh\u00fcllt zuseyn l\u00e4st man den Mantel fahren/", "tokens": ["An\u00b7statt", "ver\u00b7h\u00fcllt", "zu\u00b7seyn", "l\u00e4st", "man", "den", "Man\u00b7tel", "fah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAINF", "VVFIN", "PIS", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Vor Riegel kommen uns die Schl\u00fcssel in die Handt/", "tokens": ["Vor", "Rie\u00b7gel", "kom\u00b7men", "uns", "die", "Schl\u00fcs\u00b7sel", "in", "die", "Handt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Vor dem Beschauer zeigt man oft verbothne Wahren/", "tokens": ["Vor", "dem", "Be\u00b7schau\u00b7er", "zeigt", "man", "oft", "ver\u00b7both\u00b7ne", "Wah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PIS", "ADV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Und ein zufreyes Nein/ macht unser Ja bekannt.", "tokens": ["Und", "ein", "zuf\u00b7re\u00b7yes", "Nein", "/", "macht", "un\u00b7ser", "Ja", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$(", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.59": {"text": "Es scheint uns manchesmahl/ es ist der Liebe Weise/", "tokens": ["Es", "scheint", "uns", "man\u00b7ches\u00b7mahl", "/", "es", "ist", "der", "Lie\u00b7be", "Wei\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$(", "PPER", "VAFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Besonders/ wo sie recht die Wurtzel hat gestreckt/", "tokens": ["Be\u00b7son\u00b7ders", "/", "wo", "sie", "recht", "die", "Wurt\u00b7zel", "hat", "ge\u00b7streckt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PWAV", "PPER", "ADV", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Als giengen wir auf Filtz/ und th\u00e4ten wunderleise/", "tokens": ["Als", "gien\u00b7gen", "wir", "auf", "Filtz", "/", "und", "th\u00e4\u00b7ten", "wun\u00b7der\u00b7lei\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "NE", "$(", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Und w\u00fcrden durch den Schild von unsrer Kunst be-", "tokens": ["Und", "w\u00fcr\u00b7den", "durch", "den", "Schild", "von", "uns\u00b7rer", "Kunst", "be"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.63": {"text": "deckt.", "tokens": ["deckt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}, "line.64": {"text": "Da doch ein iedes Kind auf uns mit Fingern zeiget/", "tokens": ["Da", "doch", "ein", "ie\u00b7des", "Kind", "auf", "uns", "mit", "Fin\u00b7gern", "zei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "PIAT", "NN", "APPR", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Und saget: Dieser ists/ der dis und jenes sucht.", "tokens": ["Und", "sa\u00b7get", ":", "Die\u00b7ser", "ists", "/", "der", "dis", "und", "je\u00b7nes", "sucht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PDS", "VAFIN", "$(", "ART", "PDS", "KON", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wir armen Menschen seyn uns allzusehr geneiget/", "tokens": ["Wir", "ar\u00b7men", "Men\u00b7schen", "seyn", "uns", "all\u00b7zu\u00b7sehr", "ge\u00b7nei\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "VAINF", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Und h\u00f6ren oft ein Lob wenn uns die Welt verflucht.", "tokens": ["Und", "h\u00f6\u00b7ren", "oft", "ein", "Lob", "wenn", "uns", "die", "Welt", "ver\u00b7flucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "KOUS", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Es spielt der Selbstbetrug uns stetig um das Hertze/", "tokens": ["Es", "spielt", "der", "Selbst\u00b7be\u00b7trug", "uns", "ste\u00b7tig", "um", "das", "Hert\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADJD", "APPR", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Er setzt uns Prillen auf/ dadurch man nichts erkiest/", "tokens": ["Er", "setzt", "uns", "Pril\u00b7len", "auf", "/", "da\u00b7durch", "man", "nichts", "er\u00b7kiest", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "APPR", "$(", "PAV", "PIS", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Und da\u00df ich nicht zusehr auf Ei\u00df und Stacheln schertze/", "tokens": ["Und", "da\u00df", "ich", "nicht", "zu\u00b7sehr", "auf", "Ei\u00df", "und", "Sta\u00b7cheln", "schert\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Der Himmel hasset dis/ was unsre Wollust ist.", "tokens": ["Der", "Him\u00b7mel", "has\u00b7set", "dis", "/", "was", "uns\u00b7re", "Wol\u00b7lust", "ist", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PDS", "$(", "PWS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Wird dieser/ der mit Blitz und scharffen Donner schre-", "tokens": ["Wird", "die\u00b7ser", "/", "der", "mit", "Blitz", "und", "scharf\u00b7fen", "Don\u00b7ner", "schre"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "$(", "ART", "APPR", "NN", "KON", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "cket/", "tokens": ["cket", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "-", "measure": "single.down"}, "line.74": {"text": "Auch dieses geile Spiel zust\u00f6hren mit der Zeit?", "tokens": ["Auch", "die\u00b7ses", "gei\u00b7le", "Spiel", "zu\u00b7st\u00f6h\u00b7ren", "mit", "der", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Vor dem/ der alles sieht/ bleibt keine that verdecket/", "tokens": ["Vor", "dem", "/", "der", "al\u00b7les", "sieht", "/", "bleibt", "kei\u00b7ne", "that", "ver\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$(", "ART", "PIS", "VVFIN", "$(", "VVFIN", "PIAT", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Und h\u00e4tt\u2019 auch Atlas sie mit seinem Schnee bestreut.", "tokens": ["Und", "h\u00e4tt'", "auch", "At\u00b7las", "sie", "mit", "sei\u00b7nem", "Schnee", "be\u00b7streut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NE", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Der kan den Zucker uns zu herben Wermuth machen/", "tokens": ["Der", "kan", "den", "Zu\u00b7cker", "uns", "zu", "her\u00b7ben", "Wer\u00b7muth", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ART", "NN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Und dessen Liebligkeit verkehren in ein Gift/", "tokens": ["Und", "des\u00b7sen", "Lieb\u00b7lig\u00b7keit", "ver\u00b7keh\u00b7ren", "in", "ein", "Gift", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Er kan in Ach und Weh verwandlen unser Lachen/", "tokens": ["Er", "kan", "in", "Ach", "und", "Weh", "ver\u00b7wand\u00b7len", "un\u00b7ser", "La\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Und schaffen da\u00df uns Spott und aller Jammer trift.", "tokens": ["Und", "schaf\u00b7fen", "da\u00df", "uns", "Spott", "und", "al\u00b7ler", "Jam\u00b7mer", "trift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "PPER", "NN", "KON", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Doch wei\u00df/ mein Hertzog/ ich dir nicht zuwiederstreben/", "tokens": ["Doch", "wei\u00df", "/", "mein", "Hert\u00b7zog", "/", "ich", "dir", "nicht", "zu\u00b7wie\u00b7der\u00b7stre\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PPOSAT", "NE", "$(", "PPER", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Ich weis wie hoch ich dir als Magd verbunden bin/", "tokens": ["Ich", "weis", "wie", "hoch", "ich", "dir", "als", "Magd", "ver\u00b7bun\u00b7den", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "KOKOM", "ADJD", "PPER", "PPER", "KOUS", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Es hie\u00df mich deine Gunst in Gold und Purpur leben/", "tokens": ["Es", "hie\u00df", "mich", "dei\u00b7ne", "Gunst", "in", "Gold", "und", "Pur\u00b7pur", "le\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "So nim was dir behagt auch wieder von mir hin.", "tokens": ["So", "nim", "was", "dir", "be\u00b7hagt", "auch", "wie\u00b7der", "von", "mir", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PWS", "PPER", "VVFIN", "ADV", "ADV", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Denn deiner H\u00e4nde Werck will ich mich ewig nennen/", "tokens": ["Denn", "dei\u00b7ner", "H\u00e4n\u00b7de", "Werck", "will", "ich", "mich", "e\u00b7wig", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "VMFIN", "PPER", "PRF", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Du hast mich aus dem Thal auf Zinnen hingestellt/", "tokens": ["Du", "hast", "mich", "aus", "dem", "Thal", "auf", "Zin\u00b7nen", "hin\u00b7ge\u00b7stellt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "APPR", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Auf Wincken deiner Lust soll dir mein Hertze brennen/", "tokens": ["Auf", "Win\u00b7cken", "dei\u00b7ner", "Lust", "soll", "dir", "mein", "Hert\u00b7ze", "bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VMFIN", "PPER", "PPOSAT", "VVFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "So dir/ so gut es kan/ auch itzt zu Fusse f\u00e4llt.", "tokens": ["So", "dir", "/", "so", "gut", "es", "kan", "/", "auch", "itzt", "zu", "Fus\u00b7se", "f\u00e4llt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$(", "ADV", "ADJD", "PPER", "VMFIN", "$(", "ADV", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Auf deinem Brunst Altar in Asche zuverstieben", "tokens": ["Auf", "dei\u00b7nem", "Brunst", "Al\u00b7tar", "in", "A\u00b7sche", "zu\u00b7ver\u00b7stie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Soll meiner treuen Pflicht an statt des Himmels seyn/", "tokens": ["Soll", "mei\u00b7ner", "treu\u00b7en", "Pflicht", "an", "statt", "des", "Him\u00b7mels", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ADJA", "NN", "APPR", "APPR", "ART", "NN", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Beschleust der Hertzog mich als seine Magd zulieben/", "tokens": ["Be\u00b7schleust", "der", "Hert\u00b7zog", "mich", "als", "sei\u00b7ne", "Magd", "zu\u00b7lie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "KOUS", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "So stell\u2019 als Opffer ich mich seinen Flammen ein.", "tokens": ["So", "stell'", "als", "Opf\u00b7fer", "ich", "mich", "sei\u00b7nen", "Flam\u00b7men", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "NN", "PPER", "PRF", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Ich will immittelst hier in meinem Grabe bleiben/", "tokens": ["Ich", "will", "im\u00b7mit\u00b7telst", "hier", "in", "mei\u00b7nem", "Gra\u00b7be", "blei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Wo di\u00df dem Grabe gleicht/ wo Gold und Perle gl\u00e4ntzt/", "tokens": ["Wo", "di\u00df", "dem", "Gra\u00b7be", "gleicht", "/", "wo", "Gold", "und", "Per\u00b7le", "gl\u00e4ntzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDS", "ART", "NN", "VVFIN", "$(", "PWAV", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Wo mir die sch\u00f6ne Zeit die Langmuth kan vertreiben/", "tokens": ["Wo", "mir", "die", "sch\u00f6\u00b7ne", "Zeit", "die", "Lang\u00b7muth", "kan", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Und gr\u00fcner B\u00e4ume Pracht das hohe Schlo\u00df um-", "tokens": ["Und", "gr\u00fc\u00b7ner", "B\u00e4u\u00b7me", "Pracht", "das", "ho\u00b7he", "Schlo\u00df", "um"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "NN", "ART", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.97": {"text": "gr\u00e4ntzt.", "tokens": ["gr\u00e4ntzt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}, "line.98": {"text": "Ich will mir auch ein Schlo\u00df in diesem Schlosse bau-", "tokens": ["Ich", "will", "mir", "auch", "ein", "Schlo\u00df", "in", "die\u00b7sem", "Schlos\u00b7se", "bau"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "NN", "APPR", "PDAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "en/", "tokens": ["en", "/"], "token_info": ["word", "punct"], "pos": ["FM", "$("], "meter": "-", "measure": "single.down"}, "line.100": {"text": "Dahin ich mit der Zeit den Hertzog f\u00fchren will/", "tokens": ["Da\u00b7hin", "ich", "mit", "der", "Zeit", "den", "Hert\u00b7zog", "f\u00fch\u00b7ren", "will", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "APPR", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Du solst alsdenn mit Lust den s\u00fcssen Willen schauen/", "tokens": ["Du", "solst", "als\u00b7denn", "mit", "Lust", "den", "s\u00fcs\u00b7sen", "Wil\u00b7len", "schau\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Trifft meine D\u00fcrfftigkeit gleich nicht das rechte Ziehl.", "tokens": ["Trifft", "mei\u00b7ne", "D\u00fcr\u00b7ff\u00b7tig\u00b7keit", "gleich", "nicht", "das", "rech\u00b7te", "Ziehl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.103": {"text": "K\u00f6nt\u2019 ich in Honigseim mir meinen Mund verkehren/", "tokens": ["K\u00f6nt'", "ich", "in", "Ho\u00b7ni\u00b7gseim", "mir", "mei\u00b7nen", "Mund", "ver\u00b7keh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "K\u00f6nt\u2019 ich in Schwanen doch verkleiden meine Brust/", "tokens": ["K\u00f6nt'", "ich", "in", "Schwa\u00b7nen", "doch", "ver\u00b7klei\u00b7den", "mei\u00b7ne", "Brust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "NN", "ADV", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "K\u00f6nt\u2019 ich mit linder Hand dir eine Lust gewehren/", "tokens": ["K\u00f6nt'", "ich", "mit", "lin\u00b7der", "Hand", "dir", "ei\u00b7ne", "Lust", "ge\u00b7weh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "ADJA", "NN", "PPER", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Die auch die Liebligkeit zuvor nicht hat gekost.", "tokens": ["Die", "auch", "die", "Lieb\u00b7lig\u00b7keit", "zu\u00b7vor", "nicht", "hat", "ge\u00b7kost", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ADV", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "K\u00f6nt\u2019 ich als Balsam doch auf deiner Scho\u00df zerfl\u00fcs-", "tokens": ["K\u00f6nt'", "ich", "als", "Bal\u00b7sam", "doch", "auf", "dei\u00b7ner", "Scho\u00df", "zer\u00b7fl\u00fcs"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "ADV", "APPR", "PPOSAT", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "sen/", "tokens": ["sen", "/"], "token_info": ["word", "punct"], "pos": ["VVINF", "$("], "meter": "-", "measure": "single.down"}, "line.109": {"text": "So meint\u2019 ich/ da\u00df das Weib/ durch die die Sonne", "tokens": ["So", "meint'", "ich", "/", "da\u00df", "das", "Weib", "/", "durch", "die", "die", "Son\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$(", "KOUS", "ART", "NN", "$(", "APPR", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.110": {"text": "mu\u00df/", "tokens": ["mu\u00df", "/"], "token_info": ["word", "punct"], "pos": ["VMFIN", "$("], "meter": "+", "measure": "single.up"}, "line.111": {"text": "Mir an der W\u00fcrdigkeit wohl w\u00fcrde weichen m\u00fcssen/", "tokens": ["Mir", "an", "der", "W\u00fcr\u00b7dig\u00b7keit", "wohl", "w\u00fcr\u00b7de", "wei\u00b7chen", "m\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADV", "VAFIN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Denn Ich bin mehr als Sie/ Sie krieget keinen Ku\u00df.", "tokens": ["Denn", "Ich", "bin", "mehr", "als", "Sie", "/", "Sie", "krie\u00b7get", "kei\u00b7nen", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "KOUS", "PPER", "$(", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}