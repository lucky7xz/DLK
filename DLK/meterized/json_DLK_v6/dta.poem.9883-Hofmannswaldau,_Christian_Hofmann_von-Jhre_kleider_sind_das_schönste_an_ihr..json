{"dta.poem.9883": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Jhre kleider sind das sch\u00f6nste an ihr.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Phillis meinet/ ihres gleichen", "tokens": ["Phil\u00b7lis", "mei\u00b7net", "/", "ih\u00b7res", "glei\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "$(", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Findt sich nicht in dieser welt/", "tokens": ["Findt", "sich", "nicht", "in", "die\u00b7ser", "welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "APPR", "PDAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Habe sie gleich nicht viel geld/", "tokens": ["Ha\u00b7be", "sie", "gleich", "nicht", "viel", "geld", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "PIAT", "NN", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "M\u00fcssen ihr doch andre weichen/", "tokens": ["M\u00fcs\u00b7sen", "ihr", "doch", "and\u00b7re", "wei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADV", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil ihr ungemeiner pracht", "tokens": ["Weil", "ihr", "un\u00b7ge\u00b7mei\u00b7ner", "pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sie vor andern herrlich macht.", "tokens": ["Sie", "vor", "an\u00b7dern", "herr\u00b7lich", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Jhre wunder-sch\u00f6ne kleider/", "tokens": ["Ih\u00b7re", "wun\u00b7der\u00b7sch\u00f6\u00b7ne", "klei\u00b7der", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die sie offt verwechseln kan/", "tokens": ["Die", "sie", "offt", "ver\u00b7wech\u00b7seln", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VMFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Stehen ihr so trefflich an/", "tokens": ["Ste\u00b7hen", "ihr", "so", "treff\u00b7lich", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df das gute m\u00e4gdchen leider!", "tokens": ["Da\u00df", "das", "gu\u00b7te", "m\u00e4gd\u00b7chen", "lei\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles/ was ihr wird geschenckt/", "tokens": ["Al\u00b7les", "/", "was", "ihr", "wird", "ge\u00b7schenckt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$(", "PWS", "PPER", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wieder an den hintern henckt.", "tokens": ["Wie\u00b7der", "an", "den", "hin\u00b7tern", "henckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Gleichwohl hat sie vorzusch\u00fctzen/", "tokens": ["Gleich\u00b7wohl", "hat", "sie", "vor\u00b7zu\u00b7sch\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df der blosse kleider-pracht", "tokens": ["Da\u00df", "der", "blos\u00b7se", "klei\u00b7der\u00b7pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sie zu einer dame macht/", "tokens": ["Sie", "zu", "ei\u00b7ner", "da\u00b7me", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sonsten kan sie wenig n\u00fctzen/", "tokens": ["Sons\u00b7ten", "kan", "sie", "we\u00b7nig", "n\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Weil es ihr am angesicht", "tokens": ["Weil", "es", "ihr", "am", "an\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Mehr als allzu viel gebricht.", "tokens": ["Mehr", "als", "all\u00b7zu", "viel", "ge\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PTKA", "PIS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn sie ist gantz schwartz von farben/", "tokens": ["Denn", "sie", "ist", "gantz", "schwartz", "von", "far\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch mit gelben untermengt/", "tokens": ["Doch", "mit", "gel\u00b7ben", "un\u00b7ter\u00b7mengt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie die schweine so man sengt/", "tokens": ["Wie", "die", "schwei\u00b7ne", "so", "man", "sengt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "ADV", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit viel tausend pocken-narben/", "tokens": ["Mit", "viel", "tau\u00b7send", "po\u00b7cken\u00b7na\u00b7rben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "CARD", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Und die nase samt dem mund", "tokens": ["Und", "die", "na\u00b7se", "samt", "dem", "mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Wiegen ein und zwantzig pfund.", "tokens": ["Wie\u00b7gen", "ein", "und", "zwant\u00b7zig", "pfund", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "CARD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wenn sie liebe will erwecken/", "tokens": ["Wenn", "sie", "lie\u00b7be", "will", "er\u00b7we\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mu\u00df sie seyn darauf bedacht/", "tokens": ["Mu\u00df", "sie", "seyn", "da\u00b7rauf", "be\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VAINF", "PAV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sie gute anstalt macht/", "tokens": ["Da\u00df", "sie", "gu\u00b7te", "an\u00b7stalt", "macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJA", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jhr gefichte zu bedecken/", "tokens": ["Ihr", "ge\u00b7fich\u00b7te", "zu", "be\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Liesse sie es unbedeckt/", "tokens": ["Lies\u00b7se", "sie", "es", "un\u00b7be\u00b7deckt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPER", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "W\u00fcrde man nur abgeschreckt.", "tokens": ["W\u00fcr\u00b7de", "man", "nur", "ab\u00b7ge\u00b7schreckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Drum so ist sie ja zu loben/", "tokens": ["Drum", "so", "ist", "sie", "ja", "zu", "lo\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VAFIN", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df sie mehr als andre prangt/", "tokens": ["Da\u00df", "sie", "mehr", "als", "and\u00b7re", "prangt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KOUS", "PIS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil es an den kleidern hangt/", "tokens": ["Weil", "es", "an", "den", "klei\u00b7dern", "hangt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df sie h\u00f6her wird erhoben/", "tokens": ["Da\u00df", "sie", "h\u00f6\u00b7her", "wird", "er\u00b7ho\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Als nach aller leute wahn", "tokens": ["Als", "nach", "al\u00b7ler", "leu\u00b7te", "wahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PIAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Jhrem stand geb\u00fchren kan.", "tokens": ["Ih\u00b7rem", "stand", "ge\u00b7b\u00fch\u00b7ren", "kan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VVFIN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}