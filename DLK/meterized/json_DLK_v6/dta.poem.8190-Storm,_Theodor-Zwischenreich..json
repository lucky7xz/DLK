{"dta.poem.8190": {"metadata": {"author": {"name": "Storm, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Zwischenreich.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1852", "urn": "urn:nbn:de:kobv:b4-200905196098", "language": ["de:0.99"], "booktitle": "Storm, Theodor: Gedichte. Kiel, 1852."}, "poem": {"stanza.1": {"line.1": {"text": "Ach, ich kenne sie nicht mehr;", "tokens": ["Ach", ",", "ich", "ken\u00b7ne", "sie", "nicht", "mehr", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur mit Tanten und Pastoren", "tokens": ["Nur", "mit", "Tan\u00b7ten", "und", "Pas\u00b7to\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat das liebe Herz Verkehr.", "tokens": ["Hat", "das", "lie\u00b7be", "Herz", "Ver\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Jene s\u00fc\u00dfe Himmelsdemuth,", "tokens": ["Je\u00b7ne", "s\u00fc\u00b7\u00dfe", "Him\u00b7mels\u00b7de\u00b7muth", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Die der S\u00fcnder Hoffart schilt,", "tokens": ["Die", "der", "S\u00fcn\u00b7der", "Hof\u00b7fart", "schilt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat das ganze Schelmenantlitz", "tokens": ["Hat", "das", "gan\u00b7ze", "Schel\u00b7men\u00b7ant\u00b7litz"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie mit grauem Flor verh\u00fcllt.", "tokens": ["Wie", "mit", "grau\u00b7em", "Flor", "ver\u00b7h\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ja, die brennend rothen Lippen", "tokens": ["Ja", ",", "die", "bren\u00b7nend", "ro\u00b7then", "Lip\u00b7pen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PRELS", "ADJD", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Predigen Entsagung euch;", "tokens": ["Pre\u00b7di\u00b7gen", "Ent\u00b7sa\u00b7gung", "euch", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Diese gar zu schwarzen Augen", "tokens": ["Die\u00b7se", "gar", "zu", "schwar\u00b7zen", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schmachten nach dem Himmelreich.", "tokens": ["Schmach\u00b7ten", "nach", "dem", "Him\u00b7mel\u00b7reich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auf die Titiansche Venus", "tokens": ["Auf", "die", "Ti\u00b7ti\u00b7an\u00b7sche", "Ve\u00b7nus"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Ist ein Heilgenbild gemalt;", "tokens": ["Ist", "ein", "Heil\u00b7gen\u00b7bild", "ge\u00b7malt", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ach, ich kenne sie nicht wieder,", "tokens": ["Ach", ",", "ich", "ken\u00b7ne", "sie", "nicht", "wie\u00b7der", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die so sch\u00f6n mit uns gedahlt.", "tokens": ["Die", "so", "sch\u00f6n", "mit", "uns", "ge\u00b7dahlt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Nirgends mehr f\u00fcr blaue M\u00e4rchen", "tokens": ["Nir\u00b7gends", "mehr", "f\u00fcr", "blau\u00b7e", "M\u00e4r\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein einzig' Pl\u00e4tzchen leer;", "tokens": ["Ist", "ein", "ein\u00b7zig'", "Pl\u00e4tz\u00b7chen", "leer", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "PIAT", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nur Tract\u00e4tlein und Asceten", "tokens": ["Nur", "Trac\u00b7t\u00e4t\u00b7lein", "und", "A\u00b7sce\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "NN", "KON", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Liegen haufenweis umher.", "tokens": ["Lie\u00b7gen", "hau\u00b7fen\u00b7weis", "um\u00b7her", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wahrlich, zum Verzweifeln w\u00e4r' es \u2014", "tokens": ["Wahr\u00b7lich", ",", "zum", "Ver\u00b7zwei\u00b7feln", "w\u00e4r'", "es"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPRART", "NN", "VAFIN", "PPER", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aber, Schatz, wir wissen schon,", "tokens": ["A\u00b7ber", ",", "Schatz", ",", "wir", "wis\u00b7sen", "schon", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "PPER", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Deinen ganzen G\u00f6tzenplunder", "tokens": ["Dei\u00b7nen", "gan\u00b7zen", "G\u00f6t\u00b7zen\u00b7plun\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wirft ein einzger Mann vom Thron.", "tokens": ["Wirft", "ein", "einz\u00b7ger", "Mann", "vom", "Thron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}