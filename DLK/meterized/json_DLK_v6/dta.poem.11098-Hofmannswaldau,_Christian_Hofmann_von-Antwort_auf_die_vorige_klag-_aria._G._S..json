{"dta.poem.11098": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Antwort auf die vorige klag- aria.  \n  G. S.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Was singest du vom sterben?", "tokens": ["Was", "sin\u00b7gest", "du", "vom", "ster\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPRART", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das kalte grab ist nicht vor dich.", "tokens": ["Das", "kal\u00b7te", "grab", "ist", "nicht", "vor", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PTKNEG", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des grausen todes bleicher strich", "tokens": ["Des", "grau\u00b7sen", "to\u00b7des", "blei\u00b7cher", "strich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mu\u00df keine frische lippen f\u00e4rben.", "tokens": ["Mu\u00df", "kei\u00b7ne", "fri\u00b7sche", "lip\u00b7pen", "f\u00e4r\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein aug\u2019 ist allzu sch\u00f6n dazu,", "tokens": ["Dein", "aug'", "ist", "all\u00b7zu", "sch\u00f6n", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PTKA", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sich auf die d\u00fcstre grufft zu lencken.", "tokens": ["Sich", "auf", "die", "d\u00fcst\u00b7re", "grufft", "zu", "len\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Das alter sucht die lange ruh;", "tokens": ["Das", "al\u00b7ter", "sucht", "die", "lan\u00b7ge", "ruh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die jugend darff daran nicht ohne zittern dencken.", "tokens": ["Die", "ju\u00b7gend", "darff", "da\u00b7ran", "nicht", "oh\u00b7ne", "zit\u00b7tern", "den\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PAV", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Der scepter, den ein k\u00f6nig", "tokens": ["Der", "scep\u00b7ter", ",", "den", "ein", "k\u00f6\u00b7nig"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Aus lieb in deinen schos gelegt,", "tokens": ["Aus", "lieb", "in", "dei\u00b7nen", "schos", "ge\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "APPR", "PPOSAT", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ist doch kein baum, der dornen tr\u00e4gt.", "tokens": ["Ist", "doch", "kein", "baum", ",", "der", "dor\u00b7nen", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "$,", "PRELS", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist diese gunst vielleicht zu wenig?", "tokens": ["Ist", "die\u00b7se", "gunst", "viel\u00b7leicht", "zu", "we\u00b7nig", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDAT", "NN", "ADV", "PTKA", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie viele lebten h\u00f6chst-vergn\u00fcgt,", "tokens": ["Wie", "vie\u00b7le", "leb\u00b7ten", "h\u00f6chst\u00b7ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn sie ein eintzig strahl beschienen!", "tokens": ["Wenn", "sie", "ein", "eint\u00b7zig", "strahl", "be\u00b7schie\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und Bellamire seufftzt und liegt,", "tokens": ["Und", "Be\u00b7lla\u00b7mi\u00b7re", "seufftzt", "und", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Da gantze sternen ihr zu der Erquickung dienen.", "tokens": ["Da", "gant\u00b7ze", "ster\u00b7nen", "ihr", "zu", "der", "Er\u00b7quic\u00b7kung", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "VVFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Da\u00df dich mein mund gek\u00fcsset,", "tokens": ["Da\u00df", "dich", "mein", "mund", "ge\u00b7k\u00fcs\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ist trost genung vor deinen geist;", "tokens": ["Ist", "trost", "ge\u00b7nung", "vor", "dei\u00b7nen", "geist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die kost, so das gem\u00fcthe speist,", "tokens": ["Die", "kost", ",", "so", "das", "ge\u00b7m\u00fc\u00b7the", "speist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bleibt dessentwegen unvermisset.", "tokens": ["Bleibt", "des\u00b7sent\u00b7we\u00b7gen", "un\u00b7ver\u00b7mis\u00b7set", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein k\u00f6nig liebt dich mehr, als vor;", "tokens": ["Dein", "k\u00f6\u00b7nig", "liebt", "dich", "mehr", ",", "als", "vor", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor bahnet\u2019 ihm der schnee der glieder", "tokens": ["Vor", "bah\u00b7net'", "ihm", "der", "schnee", "der", "glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "VVFIN", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die glatte bahn zum liebes-thor:", "tokens": ["Die", "glat\u00b7te", "bahn", "zum", "lie\u00b7bes\u00b7thor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Jtzt legt sich blos sein geist zu deinem geiste nieder.", "tokens": ["Jtzt", "legt", "sich", "blos", "sein", "geist", "zu", "dei\u00b7nem", "geis\u00b7te", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "PPOSAT", "NN", "APPR", "PPOSAT", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Drum, kluge Bellamire!", "tokens": ["Drum", ",", "klu\u00b7ge", "Be\u00b7lla\u00b7mi\u00b7re", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJA", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "Besiehl dem munde, da\u00df er schweigt,", "tokens": ["Be\u00b7siehl", "dem", "mun\u00b7de", ",", "da\u00df", "er", "schweigt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So offt ein fleischlich ach! aufsteigt,", "tokens": ["So", "offt", "ein", "fleischlich", "ach", "!", "auf\u00b7steigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJD", "ITJ", "$.", "VVPP", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Damit ich dich nicht gantz verliere.", "tokens": ["Da\u00b7mit", "ich", "dich", "nicht", "gantz", "ver\u00b7lie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die sch\u00f6nheit hat genung erlangt,", "tokens": ["Die", "sch\u00f6n\u00b7heit", "hat", "ge\u00b7nung", "er\u00b7langt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So eines helden faust gebunden;", "tokens": ["So", "ei\u00b7nes", "hel\u00b7den", "faust", "ge\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Damit dein witz nun h\u00f6her prangt,", "tokens": ["Da\u00b7mit", "dein", "witz", "nun", "h\u00f6\u00b7her", "prangt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So zeige, da\u00df er selbst den sieger \u00fcberwunden.", "tokens": ["So", "zei\u00b7ge", ",", "da\u00df", "er", "selbst", "den", "sie\u00b7ger", "\u00fc\u00b7berw\u00b7un\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die eyfernden gedancken", "tokens": ["Die", "ey\u00b7fern\u00b7den", "ge\u00b7dan\u00b7cken"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Stehn keinem grossen hertzen an.", "tokens": ["Stehn", "kei\u00b7nem", "gros\u00b7sen", "hert\u00b7zen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die k\u00f6nigliche liebes-bahn", "tokens": ["Die", "k\u00f6\u00b7nig\u00b7li\u00b7che", "lie\u00b7bes\u00b7bahn"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schlie\u00dft sich nicht in gemeine schrancken.", "tokens": ["Schlie\u00dft", "sich", "nicht", "in", "ge\u00b7mei\u00b7ne", "schran\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "APPR", "ADJA", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Man schaut mehr als ein schlaf-gemach", "tokens": ["Man", "schaut", "mehr", "als", "ein", "schlaf\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PIS", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor einen f\u00fcrsten zubereitet.", "tokens": ["Vor", "ei\u00b7nen", "f\u00fcrs\u00b7ten", "zu\u00b7be\u00b7rei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Armandus folgt der sonne nach,", "tokens": ["Ar\u00b7man\u00b7dus", "folgt", "der", "son\u00b7ne", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die ihren g\u00f6ldnen glantz auf berg\u2019 und th\u00e4ler breitet.", "tokens": ["Die", "ih\u00b7ren", "g\u00f6ld\u00b7nen", "glantz", "auf", "ber\u00b7g'", "und", "th\u00e4\u00b7ler", "brei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "APPR", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Was wilst du demnach weinen?", "tokens": ["Was", "wilst", "du", "dem\u00b7nach", "wei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PAV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dein ancker bricht noch nicht entzwey:", "tokens": ["Dein", "an\u00b7cker", "bricht", "noch", "nicht", "ent\u00b7zwey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Dein schiff ist aller st\u00fcrme frey:", "tokens": ["Dein", "schiff", "ist", "al\u00b7ler", "st\u00fcr\u00b7me", "frey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "VAFIN", "PIAT", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du siehst den Pharus helle scheinen.", "tokens": ["Du", "siehst", "den", "Pha\u00b7rus", "hel\u00b7le", "schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Drum seegel ungehindert fort!", "tokens": ["Drum", "see\u00b7gel", "un\u00b7ge\u00b7hin\u00b7dert", "fort", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dein witz l\u00e4\u00dft dich was grosses hoffen:", "tokens": ["Dein", "witz", "l\u00e4\u00dft", "dich", "was", "gros\u00b7ses", "hof\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PRF", "PWS", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Verschlie\u00dft dir Venus ihren port;", "tokens": ["Ver\u00b7schlie\u00dft", "dir", "Ve\u00b7nus", "ih\u00b7ren", "port", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "So h\u00e4lt die klugheit dir der tugend hafen offen.", "tokens": ["So", "h\u00e4lt", "die", "klug\u00b7heit", "dir", "der", "tu\u00b7gend", "ha\u00b7fen", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}